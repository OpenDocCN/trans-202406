<html><head></head><body><section data-pdf-bookmark="Chapter 8. Running Containers" data-type="chapter" epub:type="chapter"><div class="chapter" id="idm45979386878208">&#13;
<h1><span class="label">Chapter 8. </span>Running Containers</h1>&#13;
&#13;
<blockquote class="epigraph">&#13;
<p>If you have a tough question that you can’t answer, start by tackling a simpler question that you can’t answer.</p>&#13;
<p data-type="attribution">Max Tegmark</p>&#13;
</blockquote>&#13;
&#13;
<p><a data-primary="Kubernetes" data-secondary="container management" data-type="indexterm" id="ix_08-containers-adoc0"/>In previous chapters, we’ve focused mostly on the operational aspects of Kubernetes: where to get your clusters, how to maintain them, and how to manage your cluster resources. Let’s turn now to the most fundamental Kubernetes object: the <em>container</em>. We’ll look at how containers work on a technical level, how they relate to Pods, and how to deploy container images to Kubernetes.</p>&#13;
&#13;
<p>In this chapter, we’ll also cover the important topic of container security, and how to use the security features in Kubernetes to deploy your applications in a secure way, according to best practices. Finally, we’ll look at how to mount disk volumes on Pods, allowing containers to share and persist data.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Containers and Pods" data-type="sect1"><div class="sect1" id="idm45979385036304">&#13;
<h1>Containers and Pods</h1>&#13;
&#13;
<p>We’ve already introduced Pods in <a data-type="xref" href="ch02.html#firststeps">Chapter 2</a>, and talked about how Deployments use ReplicaSets to maintain a set of replica Pods, but we haven’t really looked at Pods themselves in much detail. Pods are the unit of scheduling in Kubernetes. A Pod object represents a container or group of containers, and everything that runs in Kubernetes does so by means of a Pod:</p>&#13;
<blockquote>A Pod represents a collection of application containers and volumes running in the same execution environment. Pods, not containers, are the smallest deployable artifact in a Kubernetes cluster. This means all of the containers in a Pod always land on the same machine.&#13;
<p data-type="attribution">Kelsey Hightower et al., <cite><em>Kubernetes Up &amp; Running</em></cite></p>&#13;
</blockquote>&#13;
&#13;
<p>So far in this book the terms <em>Pod</em> and <em>container</em> have been used more or less interchangeably: the demo application Pod only has one container in it. In more complex applications, though, it’s quite likely that a Pod will include two or more containers. So let’s look at how that works, and see when and why you might want to group containers together in Pods.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What Is a Container?" data-type="sect2"><div class="sect2" id="whatsacontainer">&#13;
<h2>What Is a Container?</h2>&#13;
&#13;
<p><a data-primary="containers" data-secondary="internals" data-type="indexterm" id="idm45979385028736"/>Before asking why you might want to have multiple containers in a Pod, let’s take a moment to revisit what a container actually is.</p>&#13;
&#13;
<p>You know from <a data-type="xref" href="ch01.html#containers-intro">“The Coming of Containers”</a> that a container is a standardized package that contains a piece of software together with its dependencies, configuration, data, and so on: everything it needs to run. How does that actually work, though?</p>&#13;
&#13;
<p><a data-primary="containers" data-secondary="processes" data-type="indexterm" id="idm45979385025760"/>In Linux, and most other operating systems, everything that runs on a machine does so by means of a <em>process</em>. A process represents the binary code and memory state of a running application, such as Chrome, <code>top</code>, or Visual Studio Code. All processes exist in the same global namespace: they can all see and interact with each other, they all share the same pool of resources, such as CPU, memory, and filesystem. (A Linux namespace is a bit like a Kubernetes namespace, though not the same thing technically.)</p>&#13;
&#13;
<p>From the operating system’s point of view, a container represents an isolated process (or group of processes) that exists in its own namespace. Processes inside the container can’t see processes outside it, and vice versa. A container can’t access resources belonging to another container, or processes outside of a container. The container boundary is like a ring-fence that stops processes running wild and using up each other’s resources.</p>&#13;
&#13;
<p>As far as the process inside the container is concerned, it’s running on its own machine, with complete access to all its resources, and there are no other processes running. You can see this if you run a few commands inside a container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><strong><code class="go">kubectl run busybox --image busybox:1.28 --rm -it --restart=Never /bin/sh</code></strong><code class="go">&#13;
</code><code class="go">If you don't see a command prompt, try pressing enter.&#13;
</code><code class="go">/ # </code><strong><code class="go">ps ax</code></strong><code class="go">&#13;
</code><code class="go">PID   USER     TIME  COMMAND&#13;
</code><code class="go">    1 root      0:00 /bin/sh&#13;
</code><code class="go">    8 root      0:00 ps ax&#13;
</code><code class="go">&#13;
</code><code class="go">/ # </code><strong><code class="go">hostname</code></strong><code class="go">&#13;
</code><code class="go">busybox</code></pre>&#13;
&#13;
<p>Normally, the <code>ps ax</code> command will list all processes running on the machine, and there are usually a lot of them (a few hundred on a typical Linux server). But there are only two processes shown here: <code>/bin/sh</code>, and <code>ps ax</code>. The only processes visible inside the container, therefore, are the ones actually running in the container.</p>&#13;
&#13;
<p>Similarly, the <code>hostname</code> command, which would normally show the name of the host machine, returns <code>busybox</code>: in fact, this is the name of the container. So it looks to the <code>busybox</code> container as if it’s running on a machine called <code>busybox</code>, and it has the whole machine to itself. This is true for each of the containers running on the same machine.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>It’s a fun exercise to create a container yourself, without the benefit of a container runtime like Docker. <a data-primary="Rice, Liz" data-type="indexterm" id="idm45979385003856"/>Liz Rice’s excellent talk on <a href="https://oreil.ly/KRMP7">“What is a Container, Really?”</a> shows how to do this from scratch in a Go program.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Container Runtimes in Kubernetes" data-type="sect2"><div class="sect2" id="idm45979385001840">&#13;
<h2>Container Runtimes in Kubernetes</h2>&#13;
&#13;
<p><a data-primary="containers" data-secondary="runtime" data-type="indexterm" id="idm45979384978464"/>As we mentioned in <a data-type="xref" href="ch03.html#gettingk8s">Chapter 3</a>, Docker is not the only way to run containers. <a data-primary="Container Runtime Interface (CRI)" data-type="indexterm" id="idm45979384976240"/><a data-primary="CRI (Container Runtime Interface)" data-type="indexterm" id="idm45979384975600"/>In fact, in December 2020, the maintainers <a href="https://oreil.ly/D8jVd">announced</a> that the Docker runtime in Kubernetes will be deprecated and replaced with alternatives that use the <a href="https://oreil.ly/K5qJw">Container Runtime Interface (CRI)</a>. This does not mean that Docker containers will no longer work in Kubernetes in the future, nor does it mean that Docker will cease to be a useful tool for interacting with containers outside of the context of Kubernetes. As long as a container conforms to the standards defined by the <a href="https://oreil.ly/OXs0C">Open Container Initiative (OCI)</a> then it should run in Kubernetes, and containers built using Docker do meet these standards. You can read more about this change, and the impact, in <a href="https://oreil.ly/PMTXH">“Dockershim Removal FAQ” on the Kubernetes blog</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What Belongs in a Container?" data-type="sect2"><div class="sect2" id="idm45979384971248">&#13;
<h2>What Belongs in a Container?</h2>&#13;
&#13;
<p>There’s no technical reason why you can’t run as many processes as you want to inside a container: you could run a complete Linux distribution, with multiple running applications, network services, and so on, all inside the same container. This is why you sometimes hear containers referred to as <em>lightweight virtual machines</em>. But this isn’t the best way to use containers, because then you don’t get the benefits of resource isolation.</p>&#13;
&#13;
<p>If processes don’t need to know about each other, then they don’t need to run in the same container. A good rule of thumb with a container is that it should <em>do one thing</em>. For example, our demo application container listens on a network port, and sends the string <code>Hello, 世界</code> to anyone who connects to it. That’s a simple, self-contained service: it doesn’t rely on any other programs or services, and in turn, nothing relies on it. It’s a perfect candidate for having its own container.</p>&#13;
&#13;
<p><a data-primary="containers" data-secondary="entrypoint" data-type="indexterm" id="idm45979384967008"/>A container also has an <em>entrypoint</em>: a command that is run when the container starts. That usually results in the creation of a single process to run the command, though some applications often start a few subprocesses to act as helpers or workers. To start multiple separate processes in a container, you’d need to write a wrapper script to act as the entrypoint, which would in turn start the processes you want.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Each container should run just one main process. If you’re running a large group of unrelated processes in a container, you’re not taking full advantage of the power of containers, and you should think about splitting your application up into multiple, communicating containers.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What Belongs in a Pod?" data-type="sect2"><div class="sect2" id="whatbelongsinapod">&#13;
<h2>What Belongs in a Pod?</h2>&#13;
&#13;
<p>Now that you know what a container is, you can see why it’s useful to group them together in Pods. A Pod represents a group of containers that need to communicate and share data with each other; they need to be scheduled together, they need to be started and stopped together, and they need to run on the same physical machine.</p>&#13;
&#13;
<p>A good example of this is an application that stores data in a local cache, such as <a href="https://memcached.org/about">Memcached</a>. You’ll need to run two processes: your application, and the <code>memcached</code> server process that handles storing and retrieving data. Although you could run both processes inside a single container, that’s unnecessary—they only need to communicate via a network socket. Better to split them into two separate containers, each of which only needs to worry about building and running its own process.</p>&#13;
&#13;
<p>You can use a public Memcached container image, <a href="https://hub.docker.com/_/memcached">available from Docker Hub</a>, which is already set up to work as part of a Pod with another container.</p>&#13;
&#13;
<p>So you create a Pod with two containers: Memcached, and your application. The application can talk to Memcached by making a network connection, and because the two containers are in the same Pod, that connection will always be local: the two containers will always run on the same node.</p>&#13;
&#13;
<p>Similarly, imagine a web application, which consists of a web server container, such as NGINX, and a blog application that generates HTML webpages, files, images, and so on. The blog container writes data to disk, and because containers in a Pod can share a disk volume, the data can also be available to the NGINX container to serve over HTTP. You can find such an example on the <a href="https://oreil.ly/Jpueo">Kubernetes docs site</a>.</p>&#13;
<blockquote class="less_space pagebreak-before"><a data-primary="Pod objects" data-secondary="multiple containers in" data-type="indexterm" id="idm45979384955536"/>In general, the right question to ask yourself when designing Pods is, “Will these containers work correctly if they land on different machines?” If the answer is “no,” a Pod is the correct grouping for the containers. If the answer is “yes,” multiple Pods is the probably the correct solution.&#13;
<p data-type="attribution">Kelsey Hightower et al., <cite><em>Kubernetes Up &amp; Running</em></cite></p>&#13;
</blockquote>&#13;
&#13;
<p>The containers in a Pod should all be working together to do one job. If you only need one container to do that job, fine: use one container. If you need two or three, that’s OK. If you have more than that, you might want to think about whether the containers could actually be split into separate Pods.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Container Manifests" data-type="sect1"><div class="sect1" id="idm45979384951984">&#13;
<h1>Container Manifests</h1>&#13;
&#13;
<p><a data-primary="containers" data-secondary="manifest" data-type="indexterm" id="ix_08-containers-adoc1"/>We’ve outlined what containers are, what should go in a container, and when containers should be grouped together in Pods. So how do we actually run a container in Kubernetes?</p>&#13;
&#13;
<p>When you created your first Deployment, in <a data-type="xref" href="ch04.html#deploymentmanifests">“Deployment Manifests”</a>, it contained a <code>template.spec</code> section specifying the container to run (only one container, in that example):</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">spec</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><strong><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">ports</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">containerPort</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">8888</code></strong></pre>&#13;
&#13;
<p>Here’s an example of what the <code>template.spec</code> section for a Deployment with two containers would look like:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">spec</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><strong><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">container1</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">example/container1</code><code class="w">&#13;
</code><code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">container2</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">example/container2</code></strong></pre>&#13;
&#13;
<p>The only required fields in each container’s spec are the <code>name</code> and <code>image</code>: a container has to have a name, so that other resources can refer to it, and you have to tell Kubernetes what image to run in the container.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Image Identifiers" data-type="sect2"><div class="sect2" id="image-identifiers">&#13;
<h2>Image Identifiers</h2>&#13;
&#13;
<p><a data-primary="containers" data-secondary="image identifier" data-type="indexterm" id="idm45979384861824"/>You’ve already used some different container image identifiers so far in this book; for example, <code>cloudnatived/demo:hello</code>, <code>alpine</code> and <code>busybox:1.28</code>.</p>&#13;
&#13;
<p>There are actually four different parts to an image identifier: the <em>registry hostname</em>, the <em>repository namespace</em>, the <em>image repository</em>, and the <em>tag</em>. All but the image name are optional. An image identifier using all of those parts looks like this:</p>&#13;
&#13;
<p><code>docker.io/cloudnatived/demo:hello</code></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The registry hostname in this example is <code>docker.io</code>; in fact, that’s the default for Docker images, so we don’t need to specify it. If your image is stored in another registry, though, you’ll need to give its hostname. For example, Google Container Registry images are prefixed by <code>gcr.io</code>.</p>&#13;
</li>&#13;
<li>&#13;
<p>The repository namespace is <code>cloudnatived</code>: that’s us (hello!). If you don’t specify the repository namespace, then the default namespace (called <code>library</code>) is used. This is a set of <a href="https://oreil.ly/nCHJn">official images</a>, which are approved and maintained by Docker, Inc. Popular official images include OS base images (<code>alpine</code>, <code>ubuntu</code>, <code>debian</code>, <code>centos</code>), language environments (<code>golang</code>, <code>python</code>, <code>ruby</code>, <code>php</code>, <code>java</code>), and widely used software (<code>mongo</code>, <code>mysql</code>, <code>nginx</code>, <code>redis</code>).</p>&#13;
</li>&#13;
<li>&#13;
<p>The image repository is <code>demo</code>, which identifies a particular container image within the registry and namespace. (See also <a data-type="xref" href="#digests">“Container Digests”</a>.)</p>&#13;
</li>&#13;
<li>&#13;
<p>The tag is <code>hello</code>. Tags identify different versions of the same image.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><a data-primary="tags" data-secondary="purpose of" data-type="indexterm" id="idm45979384813472"/>It’s up to you what tags to put on a container: some common choices include:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A semantic version tag, like <code>v1.3.0</code>. This usually refers to the version of the application.</p>&#13;
</li>&#13;
<li>&#13;
<p>A Git SHA tag, like <code>5ba6bfd...</code>. This identifies the specific commit in the source repo that was used to build the container (see <a data-type="xref" href="ch14.html#gitshatags">“Git SHA Tags”</a>).</p>&#13;
</li>&#13;
<li>&#13;
<p>The environment it represents, such as <code>staging</code> or <code>production</code>.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>You can add as many tags as you want to a given image.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The latest Tag" data-type="sect2"><div class="sect2" id="latesttag">&#13;
<h2>The latest Tag</h2>&#13;
&#13;
<p><a data-primary="containers" data-secondary="tag" data-type="indexterm" id="idm45979384804368"/><a data-primary="latest tag" data-type="indexterm" id="idm45979384803392"/><a data-primary="tags" data-secondary="default (latest)" data-type="indexterm" id="idm45979384802720"/>If you don’t specify a tag when pulling an image, the default tag for Docker images is <code>latest</code>. For example, when you run an <code>alpine</code> image with no tag specified, you’ll get <code>alpine:latest</code>.</p>&#13;
&#13;
<p>The <code>latest</code> tag is a default tag that’s added to an image when you build or push it without specifying a tag. It doesn’t necessarily identify the most recent image, just the most recent image that wasn’t explicitly tagged. This makes <code>latest</code> <a href="https://oreil.ly/cVp7N">rather unhelpful</a> as an identifier.</p>&#13;
&#13;
<p>That’s why it’s important to always use a specific tag when deploying production containers to Kubernetes. When you’re just running a quick one-off container for troubleshooting or experimentation, like the <code>alpine</code> container, it’s fine to omit the tag and get the latest image. For real applications, though, you want to make sure that if you deploy the Pod tomorrow, you’ll get the exact same container image as when you deployed it today:</p>&#13;
<blockquote>&#13;
 <p>You should avoid using the <code>latest</code> tag when deploying containers in production as it is harder to track which version of the image is running, and more difficult to roll back properly.</p>&#13;
 <p data-type="attribution"><a href="https://oreil.ly/ZmTBp">The Kubernetes documentation</a></p>&#13;
</blockquote>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Container Digests" data-type="sect2"><div class="sect2" id="digests">&#13;
<h2>Container Digests</h2>&#13;
&#13;
<p><a data-primary="containers" data-secondary="digests" data-type="indexterm" id="idm45979384792288"/>As we’ve seen, the <code>latest</code> tag doesn’t always mean what you think it will, and even a semantic version or Git SHA tag doesn’t uniquely and permanently identify a particular container image. If the maintainer decides to push a different image with the same tag, the next time you deploy, you’ll get that updated image. In technical terms, a tag is <em>nondeterministic</em>.</p>&#13;
&#13;
<p>Sometimes it’s desirable to have <em>deterministic</em> deployments: in other words, to guarantee that a deployment will always reference the exact container image you specified. You can do this using the container’s <em>digest</em>: a cryptographic hash of the image’s contents that immutably identifies that image.</p>&#13;
&#13;
<p>Images can have many tags, but only one digest. This means that if your container manifest specifies the image digest, you can guarantee deterministic deployments. An image identifier with a digest looks like this:</p>&#13;
&#13;
<p><code>cloudnatived/demo@sha256:aeae1e551a6cbd60bcfd56c3b4ffec732c45b8012b7cb758c6c4a34...</code></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Base Image Tags" data-type="sect2"><div class="sect2" id="idm45979384787552">&#13;
<h2>Base Image Tags</h2>&#13;
&#13;
<p><a data-primary="base image tags" data-type="indexterm" id="idm45979384786208"/>When you reference a base image in a Dockerfile, if you do not specify a tag, you will get <code>latest</code>, just as you do when running a container. This can be confusing if one day your builds stop working and you find out that the <code>latest</code> image you were using now points to a different version of the image that introduces some breaking change to your application.</p>&#13;
&#13;
<p>For this reason, you may want to use a more specific tag for the base images on your <code>FROM</code> lines in your Dockerfile. But which tag should you use? Or should you use an exact digest? This largely depends on your development situation and preferences.</p>&#13;
&#13;
<p>Let’s use the <a href="https://oreil.ly/VOII3">official Python image</a> on Docker Hub as an example. You have the option of using <code>python:3</code>, <code>python:3.9</code>, <code>python:3.9.7</code>, or many other variations of version tags, and also different base operating systems like Windows, Alpine, and Debian.</p>&#13;
&#13;
<p>The advantage of using a less-specific tag, such as <code>python:3</code>, is that you will automatically be pulling in any updates and security patches, along with whichever is the newest minor release version of Python 3 every time you build a new image. The downside is that sometimes these updates could cause issues if something like a system package gets renamed or removed. Your application may work perfectly fine on Python 3.9, but then start failing from changes introduced in a new 3.10 release if you build a new image and do not realize that your base image <code>python:3</code> actually moved from 3.9 to 3.10.</p>&#13;
&#13;
<p>If you use a more specific tag, such as <code>python:3.9.7</code>, your base image is less likely to change unexpectedly. However, you will need to pay attention and manually update your Dockerfile when there is a new version available so that you can pull in those important security and bug fixes. You may prefer this style of development where you have greater control of your builds, but it is important to regularly check for updates to your base images so that they do not lag behind, as they will be missing security fixes that have been pushed up by the maintainers.</p>&#13;
&#13;
<p>The image tag you use will largely depend on your team preferences, release cadence, and development style. You should weigh the pros and cons of whichever tag system you choose and check in regularly to ensure that you have a process that provides reasonably reliable builds with regular updates at a sustainable pace.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Ports" data-type="sect2"><div class="sect2" id="idm45979384777744">&#13;
<h2>Ports</h2>&#13;
&#13;
<p>You’ve already seen the <code>ports</code> field used with our demo application back in <a data-type="xref" href="ch04.html#services">“Service Resources”</a>. It specifies the network port numbers the application will listen on, and can be matched up with, a <a href="https://oreil.ly/N3EvV">Service</a> for routing requests to the container.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Resource Requests and Limits" data-type="sect2"><div class="sect2" id="idm45979384773888">&#13;
<h2>Resource Requests and Limits</h2>&#13;
&#13;
<p>We have already covered resource requests and limits for containers in detail, in <a data-type="xref" href="ch05.html#resources">Chapter 5</a>, so a brief recap here will suffice.</p>&#13;
&#13;
<p>Each container can supply one or more of the following as part of its spec:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>resources.requests.cpu</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>resources.requests.memory</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>resources.limits.cpu</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>resources.limits.memory</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Although requests and limits are specified on individual containers, we usually talk in terms of the Pod’s total resource requests and limits. A Pod’s resource request is the sum of the resource requests for all containers in that Pod, and so on.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Image Pull Policy" data-type="sect2"><div class="sect2" id="idm45979384765440">&#13;
<h2>Image Pull Policy</h2>&#13;
&#13;
<p>Before a container can be run on a node, the image has to be <em>pulled</em>, or downloaded, from the appropriate container registry. <a data-primary="imagePullPolicy" data-type="indexterm" id="idm45979384763392"/>The <code>imagePullPolicy</code> field on a container governs how often Kubernetes will do this. It can take one of three values: <code>Always</code>, <code>IfNotPresent</code>, or <code>Never</code>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Always</code> will pull the image every time the container is started. Assuming that you specify a tag—which you should (see <a data-type="xref" href="#latesttag">“The latest Tag”</a>)—then this is probably unnecessary, and could be wasting time and bandwidth.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>IfNotPresent</code>, the default, is correct for most situations. If the image is not already present on the node, it will be downloaded. After that, unless you change the image spec, the saved image will be used every time the container starts, and Kubernetes will not attempt to redownload it.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>Never</code> will never update the image at all. With this policy, Kubernetes will never fetch the image from a registry: if it’s already present on the node, it will be used, but if it’s not, the container will fail to start. You’re unlikely to want this.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>If you run into strange problems (for example, a Pod not updating when you’ve pushed a new container image), check your image pull policy.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Environment Variables" data-type="sect2"><div class="sect2" id="envvars">&#13;
<h2>Environment Variables</h2>&#13;
&#13;
<p><a data-primary="environment variables" data-secondary="benefits and drawbacks of" data-type="indexterm" id="idm45979384752960"/>Environment variables are a common, if limited, way to pass information to containers at runtime. Common, because all Linux executables have access to environment variables, and even programs that were written long before containers existed can use their environment for configuration. Limited, because environment variables can only be string values: no arrays, no keys and values, no structured data in general. The total size of a process’s environment is also limited to 32 KiB, so you can’t pass large data files in the environment.</p>&#13;
&#13;
<p><a data-primary="env" data-type="indexterm" id="idm45979384751632"/>To set an environment variable, list it in the container’s <code>env</code> field:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">containers</code><code class="p">:</code><code class="w"/>&#13;
<code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">env</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">GREETING</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">value</code><code class="p">:</code><code class="w"> </code><code class="s">"Hello</code><code class="nv"> </code><code class="s">from</code><code class="nv"> </code><code class="s">the</code><code class="nv"> </code><code class="s">environment"</code><code class="w"/></pre>&#13;
&#13;
<p>If the container image itself specifies environment variables (set in the Dockerfile, for example), then the Kubernetes <code>env</code> settings will override them. This can be useful for altering the default configuration of a container.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>A more flexible way of passing configuration data to containers is to use a Kubernetes ConfigMap or Secret object: see <a data-type="xref" href="ch10.html#config">Chapter 10</a> for more about these.<a data-startref="ix_08-containers-adoc1" data-type="indexterm" id="idm45979384714800"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Container Security" data-type="sect1"><div class="sect1" id="containersecurity">&#13;
<h1>Container Security</h1>&#13;
&#13;
<p><a data-primary="containers" data-secondary="container security" data-type="indexterm" id="ix_08-containers-adoc2"/>You might have noticed in <a data-type="xref" href="#whatsacontainer">“What Is a Container?”</a> that when we looked at the process list in the container with the <code>ps ax</code> command, the processes were all running as the root user. In Linux and other Unix-derived operating systems, <code>root</code> is the superuser, which has privileges to read any data, modify any file, and perform any operation on the system.</p>&#13;
&#13;
<p>While on a full Linux system some processes need to run as <code>root</code> (for example <code>init</code>, which manages all other processes), that’s not usually the case with a container.</p>&#13;
&#13;
<p>Indeed, running processes as the root user when you don’t need to is a bad idea. <a data-primary="principle of least privilege" data-type="indexterm" id="idm45979384706672"/>It contravenes the <a href="https://oreil.ly/Q5h79"><em>principle of least privilege</em></a>. This says that a program should only be able to access the information and resources that it actually needs to do its job.</p>&#13;
&#13;
<p>Programs have bugs—this is a fact of life apparent to anyone who’s written one. Some bugs allow malicious users to hijack the program to do things it’s not supposed to, like read secret data or execute arbitrary code. To mitigate this, it’s important to run containers with the minimum possible privileges.</p>&#13;
&#13;
<p>This starts with not allowing them to run as <code>root</code>, but instead assigning them an <em>ordinary</em> user: one that has no special privileges, such as reading other users’ files:</p>&#13;
<blockquote>&#13;
 <p>Just like you wouldn’t (or shouldn’t) run anything as root on your server, you shouldn’t run anything as root in a container on your server. Running binaries that were created elsewhere requires a significant amount of trust, and the same is true for binaries in containers.</p>&#13;
 <p data-type="attribution"><a href="https://oreil.ly/RlmNm">Marc Campbell</a></p>&#13;
</blockquote>&#13;
&#13;
<p>It’s also possible for attackers to exploit bugs in the container runtime to “escape” from the container, and get the same powers and privileges on the host machine that they did in the container.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running Containers as a Non-Root User" data-type="sect2"><div class="sect2" id="idm45979384664592">&#13;
<h2>Running Containers as a Non-Root User</h2>&#13;
&#13;
<p><a data-primary="containers" data-secondary="user" data-type="indexterm" id="idm45979384663248"/>Here’s an example of a container spec that tells Kubernetes to run the container as a specific user:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">securityContext</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><strong><code class="nt">runAsUser</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">1000</code></strong></pre>&#13;
&#13;
<p><a data-primary="runAsUser" data-type="indexterm" id="idm45979384640816"/>The value for <code>runAsUser</code> is a <em>UID</em> (a numerical user identifier). On many Linux systems, UID 1000 is assigned to the first non-root user created on the system, so it’s generally safe to choose values of 1000 or above for container UIDs. It doesn’t matter whether or not a Unix user with that UID <em>exists</em> in the container, or even if there is an operating system in the container; this works just as well with scratch containers.</p>&#13;
&#13;
<p>If a <code>runAsUser</code> UID is specified, it will override any user configured in the container image. If there is no <code>runAsUser</code>, but the container specifies a user, Kubernetes will run it as that user. If no user is specified either in the manifest or the image, the container will run as <code>root</code> (which, as we’ve seen, is a bad idea).</p>&#13;
&#13;
<p>For maximum security, you should choose a different UID for each container. That way, if a container should be compromised somehow, or accidentally overwrite data, it only has permission to access its own data, and not that of other containers.</p>&#13;
&#13;
<p>On the other hand, if you want two or more containers to be able to access the same data (via a mounted volume, for example), you should assign them the same UID.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Blocking Root Containers" data-type="sect2"><div class="sect2" id="idm45979384635328">&#13;
<h2>Blocking Root Containers</h2>&#13;
&#13;
<p>To help prevent this situation, Kubernetes allows you to block containers from running if they would run as the root user.</p>&#13;
&#13;
<p><a data-primary="runAsNonRoot" data-type="indexterm" id="idm45979384608096"/>The <code>runAsNonRoot: true</code> setting will do this:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">securityContext</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><strong><code class="nt">runAsNonRoot</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">true</code></strong></pre>&#13;
&#13;
<p>When Kubernetes runs this container, it will check to see if the container wants to run as root. If so, it will refuse to start it. This will protect you against forgetting to set a non-root user in your containers, or running third-party containers that are configured to run as root.</p>&#13;
&#13;
<p><a data-primary="CreateContainerConfigError" data-type="indexterm" id="idm45979384585584"/>If this happens, you’ll see the Pod status shown as <code>CreateContainerConfigError</code>, and when you <code>kubectl describe</code> the Pod, you’ll see this error:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="go">Error: container has runAsNonRoot and image will run as root</code></pre>&#13;
<div data-type="tip"><h1>Best Practice</h1>&#13;
<p>Run containers as non-root users, and block root containers from running, using the <code>runAsNonRoot: true</code> setting.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Setting a Read-Only Filesystem" data-type="sect2"><div class="sect2" id="idm45979384579760">&#13;
<h2>Setting a Read-Only Filesystem</h2>&#13;
&#13;
<p><a data-primary="readOnlyRootFilesystem" data-type="indexterm" id="idm45979385715936"/>Another useful security context setting is <code>readOnlyRootFilesystem</code>, which will prevent the container from writing to its own filesystem. It’s possible to imagine a container taking advantage of a bug in Docker or Kubernetes, for example, where writing to its filesystem could affect files on the host node. If its filesystem is read-only, that can’t happen; the container will get an I/O error:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">securityContext</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><strong><code class="nt">readOnlyRootFilesystem</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">true</code></strong></pre>&#13;
&#13;
<p>Many containers don’t need to write anything to their own filesystem, so this setting won’t interfere with them. It’s <a href="https://oreil.ly/JGiKP">good practice</a> to always set <span class="keep-together"><code>readOnlyRootFilesystem</code></span> unless the container really does need to write to files.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Disabling Privilege Escalation" data-type="sect2"><div class="sect2" id="idm45979384511328">&#13;
<h2>Disabling Privilege Escalation</h2>&#13;
&#13;
<p><a data-primary="setuid binaries" data-type="indexterm" id="idm45979384509952"/>Normally, Linux binaries run with the same privileges as the user that executes them. There is an exception, though: binaries that use the <code>setuid</code> mechanism can temporarily gain the privileges of the user that <em>owns</em> the binary (usually <code>root</code>).</p>&#13;
&#13;
<p>This is a potential problem in containers, since even if the container is running as a regular user (UID 1000, for example), if it contains a <code>setuid</code> binary, that binary can gain root privileges by default.</p>&#13;
&#13;
<p><a data-primary="allowPrivilegeEscalation" data-type="indexterm" id="idm45979384506400"/>To prevent this, set the <code>allowPrivilegeEscalation</code> field of the container’s security policy to <code>false</code>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">securityContext</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><strong><code class="nt">allowPrivilegeEscalation</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">false</code></strong></pre>&#13;
&#13;
<p>Modern Linux programs don’t need <code>setuid</code>; they can use a more flexible and fine-grained privilege mechanism called <em>capabilities</em> to achieve the same thing.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Capabilities" data-type="sect2"><div class="sect2" id="idm45979384458000">&#13;
<h2>Capabilities</h2>&#13;
&#13;
<p><a data-primary="capabilities" data-type="indexterm" id="idm45979384456592"/><a data-primary="containers" data-secondary="capabilities" data-type="indexterm" id="idm45979384455888"/>Traditionally, Unix programs had two levels of privileges: <em>normal</em> and <em>superuser</em>. Normal programs have no more privileges than the user who runs them, while superuser programs can do anything, bypassing all kernel security checks.</p>&#13;
&#13;
<p>The Linux capabilities mechanism improves on this by defining various specific things that a program can do: load kernel modules, perform direct network I/O operations, access system devices, and so on. Any program that needs a specific privilege can be granted it, but no others.</p>&#13;
&#13;
<p>For example, a web server that listens on port 80 would normally need to run as <code>root</code> to do this; port numbers below 1024 are considered privileged <em>system</em> ports. Instead, the program can be granted the <code>NET_BIND_SERVICE</code> capability, which allows it to bind to any port, but gives it no other special privileges.</p>&#13;
&#13;
<p>The default set of capabilities for Docker containers is fairly generous. This is a pragmatic decision based on a trade-off of security against usability: giving containers <em>no</em> capabilities by default would require operators to set capabilities on many containers in order for them to run.</p>&#13;
&#13;
<p>On the other hand, the principle of least privilege says that a container should have no capabilities it doesn’t need. Kubernetes security contexts allow you to drop any capabilities from the default set and add ones as they’re needed, like this example shows:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">securityContext</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><strong><code class="nt">capabilities</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">      </code><code class="nt">drop</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">CHOWN</code><code class="s">"</code><code class="p-Indicator">,</code><code class="w"> </code><code class="s">"</code><code class="s">NET_RAW</code><code class="s">"</code><code class="p-Indicator">,</code><code class="w"> </code><code class="s">"</code><code class="s">SETPCAP</code><code class="s">"</code><code class="p-Indicator">]</code><code class="w">&#13;
</code><code class="w">      </code><code class="nt">add</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">NET_ADMIN</code><code class="s">"</code><code class="p-Indicator">]</code></strong></pre>&#13;
&#13;
<p>The container will have the <code>CHOWN</code>, <code>NET_RAW</code>, and <code>SETPCAP</code> capabilities removed, and the <code>NET_ADMIN</code> capability added.</p>&#13;
&#13;
<p>The Docker <a href="https://oreil.ly/TOz3a">documentation</a> lists all the capabilities that are set on containers by default, and that can be added as necessary.</p>&#13;
&#13;
<p>For maximum security, you should drop all capabilities for every container and only add specific capabilities if they’re needed:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">securityContext</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><strong><code class="nt">capabilities</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">      </code><code class="nt">drop</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">all</code><code class="s">"</code><code class="p-Indicator">]</code><code class="w">&#13;
</code><code class="w">      </code><code class="nt">add</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">NET_BIND_SERVICE</code><code class="s">"</code><code class="p-Indicator">]</code></strong></pre>&#13;
&#13;
<p>The capability mechanism puts a hard limit on what processes inside the container can do, even if they’re running as root. Once a capability has been dropped at the container level, it can’t be regained, even by a malicious process with maximum privileges.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pod Security Contexts" data-type="sect2"><div class="sect2" id="idm45979384457408">&#13;
<h2>Pod Security Contexts</h2>&#13;
&#13;
<p><a data-primary="Pod objects" data-secondary="security context" data-type="indexterm" id="idm45979384306800"/><a data-primary="securityContext" data-type="indexterm" id="idm45979384305824"/>We’ve covered security context settings at the level of individual containers, but you can also set some of them at the Pod level:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w">&#13;
</code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Pod</code><code class="w">&#13;
</code><code class="nn">...</code><code class="w">&#13;
</code><code class="nt">spec</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><strong><code class="nt">securityContext</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">runAsUser</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">1000</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">runAsNonRoot</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">false</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">allowPrivilegeEscalation</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">false</code></strong></pre>&#13;
&#13;
<p>These settings will apply to all containers in the Pod, unless the container overrides a given setting in its own security context.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pod Service Accounts" data-type="sect2"><div class="sect2" id="serviceaccounts">&#13;
<h2>Pod Service Accounts</h2>&#13;
&#13;
<p><a data-primary="Pod objects" data-secondary="service account" data-type="indexterm" id="idm45979384242752"/>Pods run with the permissions of the default service account for the namespace, unless you specify otherwise (see <a data-type="xref" href="ch11.html#rbac-apps">“Applications and Deployment”</a>). If you need to grant extra permissions for some reason (such as viewing Pods in other namespaces), create a dedicated service account for the app, bind it to the required roles, and configure the Pod to use the new service account.</p>&#13;
&#13;
<p><a data-primary="serviceAccountName" data-type="indexterm" id="idm45979384240208"/>To do that, set the <code>serviceAccountName</code> field in the Pod spec to the name of the service account:<a data-startref="ix_08-containers-adoc2" data-type="indexterm" id="idm45979384238960"/></p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w">&#13;
</code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Pod</code><code class="w">&#13;
</code><code class="nn">...</code><code class="w">&#13;
</code><code class="nt">spec</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><strong><code class="nt">serviceAccountName</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">deploy-tool</code></strong></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Volumes" data-type="sect1"><div class="sect1" id="idm45979384713120">&#13;
<h1>Volumes</h1>&#13;
&#13;
<p><a data-primary="volumes" data-type="indexterm" id="ix_08-containers-adoc3"/>As you may recall, each container has its own filesystem, which is accessible only to that container, and is <em>ephemeral</em>: any data that is not part of the container image will be lost when the container is restarted.</p>&#13;
&#13;
<p>Often, this is fine; the demo application, for example, is a stateless server which therefore needs no persistent storage. Nor does it need to share files with any other container.</p>&#13;
&#13;
<p>More complex applications, though, may need both the ability to share data with other containers in the same Pod and to have it persist across restarts. A Kubernetes Volume object can provide both of these.</p>&#13;
&#13;
<p>There are many different types of Volume that you can attach to a Pod. Whatever the underlying storage medium, a Volume mounted on a Pod is accessible to all the containers in the Pod. Containers that need to communicate by sharing files can do so using a Volume of one kind or another. We’ll look at some of the more important types in the following sections.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="emptyDir Volumes" data-type="sect2"><div class="sect2" id="idm45979384187840">&#13;
<h2>emptyDir Volumes</h2>&#13;
&#13;
<p><a data-primary="emptyDir" data-type="indexterm" id="idm45979384186240"/><a data-primary="volumes" data-secondary="emptyDir" data-type="indexterm" id="idm45979384185536"/>The simplest Volume type is <code>emptyDir</code>. This is a piece of ephemeral storage that starts out empty—hence the name—and stores its data on the node (either in memory, or on the node’s disk). It persists only as long as the Pod is running on that node.</p>&#13;
&#13;
<p>An <code>emptyDir</code> is useful when you want to provision some extra storage for a container, but it’s not critical to have the data persist forever or move with the container if it should be scheduled on another node. Some examples include caching downloaded files or generated content, or using a scratch workspace for data processing jobs.</p>&#13;
&#13;
<p>Similarly, if you just want to share files between containers in a Pod, but don’t need to keep the data around for a long time, an <code>emptyDir</code> Volume is ideal.</p>&#13;
&#13;
<p>Here’s an example of a Pod that creates an <code>emptyDir</code> Volume and mounts it on a container:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Pod</code><code class="w"/>&#13;
<code class="nn">...</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">volumes</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cache-volume</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">emptyDir</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{}</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">volumeMounts</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">mountPath</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">/cache</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cache-volume</code><code class="w"/></pre>&#13;
&#13;
<p>First, in the <code>volumes</code> section of the Pod spec, we create an <code>emptyDir</code> Volume named <code>cache-volume</code>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">volumes</code><code class="p">:</code><code class="w">&#13;
</code><code class="p-Indicator">-</code><code class="w"> </code><strong><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cache-volume</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">emptyDir</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{</code><code class="p-Indicator">}</code></strong></pre>&#13;
&#13;
<p>Now the <code>cache-volume</code> Volume is available for any container in the Pod to mount and use. To do that, we list it in the <code>volumeMounts</code> section of the <code>demo</code> container:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="nt">volumeMounts</code><code class="p">:</code><code class="w">&#13;
</code><code class="p-Indicator">-</code><code class="w"> </code><strong><code class="nt">mountPath</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">/cache</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cache-volume</code></strong></pre>&#13;
&#13;
<p>The container doesn’t have to do anything special to use the new storage: anything it writes to the path <code>/cache</code> will be written to the Volume, and will be visible to other containers that mount the same Volume. All containers mounting the Volume can read and write to it.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Be careful writing to shared Volumes. Kubernetes doesn’t enforce any locking on disk writes. If two containers try to write to the same file at once, data corruption can result. To avoid this, either implement your own write-lock mechanism, or use a Volume type that supports locking, such as <code>nfs</code> or <code>glusterfs</code>.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Persistent Volumes" data-type="sect2"><div class="sect2" id="persistent">&#13;
<h2>Persistent Volumes</h2>&#13;
&#13;
<p><a data-primary="persistent volumes" data-type="indexterm" id="idm45979383992272"/><a data-primary="volumes" data-secondary="persistent" data-type="indexterm" id="idm45979383991568"/>While an ephemeral <code>emptyDir</code> Volume is ideal for cache and temporary file sharing, some applications need to store persistent data; for example, any kind of database. In general, we don’t recommend that you start out trying to run databases in Kubernetes. You’re almost always better served by using a cloud service instead: for example, most cloud providers have managed solutions for relational databases such as MySQL and PostgreSQL, as well as key-value (NoSQL) stores.</p>&#13;
&#13;
<p>As we saw in <a data-type="xref" href="ch01.html#nodbsink8s">“Kubernetes Is Not a Panacea”</a>, Kubernetes is best at managing stateless applications, which means no persistent data. Storing persistent data significantly complicates the Kubernetes configuration for your app. You’ll need to ensure that your persistent storage is reliable, performant, secure, and backed up.</p>&#13;
&#13;
<p>If you need to use persistent volumes with Kubernetes, the PersistentVolume resource is what you’re looking for. We won’t go into great detail about that here, because the details tend to be specific to your cloud provider; you can read more about PersistentVolumes in the Kubernetes <a href="https://oreil.ly/FQvRN">documentation</a>.</p>&#13;
&#13;
<p><a data-primary="PersistentVolumeClaim" data-type="indexterm" id="idm45979383961392"/>The most flexible way to use PersistentVolumes in Kubernetes is to create a PersistentVolumeClaim object. This represents a request for a particular type and size of PersistentVolume; for example, a 10 GiB Volume of high-speed, read-write storage.</p>&#13;
&#13;
<p>The Pod can then add this PersistentVolumeClaim as a Volume, where it will be available for containers to mount and use:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">volumes</code><code class="p">:</code><code class="w"/>&#13;
<code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">data-volume</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">persistentVolumeClaim</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">claimName</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">data-pvc</code><code class="w"/></pre>&#13;
&#13;
<p>You can create a pool of PersistentVolumes in your cluster to be claimed by Pods in this way. Alternatively, you can set up <a href="https://oreil.ly/4VNTz"><em>dynamic provisioning</em></a>: when a <span class="keep-together">PersistentVolumeClaim</span> like this is mounted, a suitable chunk of storage will be automatically provisioned and connected to the Pod.<a data-startref="ix_08-containers-adoc3" data-type="indexterm" id="idm45979383942416"/></p>&#13;
&#13;
<p>We will cover this more in <a data-type="xref" href="ch09.html#statefulsets">“StatefulSets”</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Restart Policies" data-type="sect1"><div class="sect1" id="restartpolicies">&#13;
<h1>Restart Policies</h1>&#13;
&#13;
<p><a data-primary="containers" data-secondary="restart policy" data-type="indexterm" id="idm45979383937008"/><a data-primary="restartPolicy" data-type="indexterm" id="idm45979383935808"/>We saw in <a data-type="xref" href="ch07.html#runningcxrs">“Running Containers for Troubleshooting”</a> that Kubernetes always restarts a Pod when it exits, unless you tell it otherwise. The default restart policy is thus <code>Always</code>, but you can change this to <code>OnFailure</code> (restart only if the container exited with a nonzero status), or <code>Never</code>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w">&#13;
</code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Pod</code><code class="w">&#13;
</code><code class="nn">...</code><code class="w">&#13;
</code><code class="nt">spec</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><strong><code class="nt">restartPolicy</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">OnFailure</code></strong></pre>&#13;
&#13;
<p>If you want to run a Pod to completion and then have it exit, rather than being restarted, you can use a Job resource to do this (see <a data-type="xref" href="ch09.html#jobs">“Jobs”</a>).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Image Pull Secrets" data-type="sect1"><div class="sect1" id="idm45979383890768">&#13;
<h1>Image Pull Secrets</h1>&#13;
&#13;
<p><a data-primary="containers" data-secondary="image pull secrets" data-type="indexterm" id="idm45979383889328"/><a data-primary="imagePullSecrets" data-type="indexterm" id="idm45979383888352"/>Kubernetes will download your specified image from the container registry if it isn’t already present on the node. However, what if you’re using a private registry? How can you give Kubernetes the credentials to authenticate to the registry?</p>&#13;
&#13;
<p>The <code>imagePullSecrets</code> field on a Pod allows you to configure this. First, you need to store the registry credentials in a Secret object (see <a data-type="xref" href="ch10.html#secrets">“Kubernetes Secrets”</a> for more about this). Now you can tell Kubernetes to use this Secret when pulling any containers in the Pod. For example, if your Secret is named <code>registry-creds</code>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w">&#13;
</code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Pod</code><code class="w">&#13;
</code><code class="nn">...</code><code class="w">&#13;
</code><code class="nt">spec</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><strong><code class="nt">imagePullSecrets</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">registry-creds</code></strong></pre>&#13;
&#13;
<p>The exact format of the registry credentials data is described in the Kubernetes <a href="https://oreil.ly/AfdOF">documentation</a>.</p>&#13;
&#13;
<p>You can also attach <code>imagePullSecrets</code> to a service account (see <a data-type="xref" href="#serviceaccounts">“Pod Service Accounts”</a>). Any Pods created using this service account will automatically have the attached registry credentials available.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Init Containers" data-type="sect1"><div class="sect1" id="init-containers">&#13;
<h1>Init Containers</h1>&#13;
&#13;
<p><a data-primary="init containers" data-type="indexterm" id="idm45979383835808"/>If you find yourself in a situation where you need to run a container prior to running your main applications, you can use an <a href="https://oreil.ly/Obo5B">Init container</a>.</p>&#13;
&#13;
<p>Init containers are defined in the Pod spec and work mostly the same as regular containers, but they do not use liveness or readiness probes. Instead init containers must run and exit successfully before other containers in the Pod are started:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w">&#13;
</code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Pod</code><code class="w">&#13;
</code><code class="nn">...</code><code class="w">&#13;
</code><code class="nt">spec</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">cloudnatived/demo:hello</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">initContainers</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">init-demo</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">busybox</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">command</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><em><code class="nv">sh</code></em><code class="p-Indicator">,</code><code class="w"> </code><em><code class="nv">-c</code></em><code class="p-Indicator">,</code><code class="w"> </code><em><code class="nv">echo</code><code class="nv"> </code><code class="nv">Hello</code><code class="nv"> </code><code class="nv">from</code><code class="nv"> </code><code class="nv">initContainer</code></em><code class="p-Indicator">]</code></pre>&#13;
&#13;
<p>These can be useful for doing pre-flight checks before starting your app, or running any sort of bootstrap script needed to get things ready for your app. One common use-case for an init container is grabbing Secrets from an external Secret store and mounting them into your application with a Volume before startup. Just make sure that your init containers are idempotent and can be safely retried if you decide to use them.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45979383837184">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In order to understand Kubernetes, you first need to understand containers. In this chapter, we’ve outlined the basic idea of what a container is, how they work together in Pods, and what options are available for you to control how containers run in Kubernetes.</p>&#13;
&#13;
<p>The bare essentials:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A Linux container, at the kernel level, is an isolated set of processes, with ring-fenced resources. From inside a container, it looks as though the container has a Linux machine to itself.</p>&#13;
</li>&#13;
<li>&#13;
<p>Containers are not virtual machines. Each container should run one primary process.</p>&#13;
</li>&#13;
<li>&#13;
<p>A Pod usually contains one container that runs a primary application, plus optional <em>helper</em> containers that support it.</p>&#13;
</li>&#13;
<li>&#13;
<p>Container image specifications can include a registry hostname, a repository namespace, an image repository, and a tag; for example, <code>docker.io/cloudnatived/demo:hello</code>. Only the image name is required.</p>&#13;
</li>&#13;
<li>&#13;
<p>For reproducible deployments, always specify a tag for the container image. Otherwise, you’ll get whatever happens to be <code>latest</code>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Programs in containers should not run as the root user. Instead, assign them an ordinary user.</p>&#13;
</li>&#13;
<li>&#13;
<p>You can set the <code>runAsNonRoot: true</code> field on a container to block any container that wants to run as <code>root</code>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Other useful security settings on containers include <code>readOnlyRootFilesystem: true</code> and <code>allowPrivilegeEscalation: false</code>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Linux capabilities provide a fine-grained privilege control mechanism, but the default capabilities for containers may be too generous. You can lock down your Pods by dropping all capabilities for containers, then granting specific capabilities if a container needs them.</p>&#13;
</li>&#13;
<li>&#13;
<p>Containers in the same Pod can share data by reading and writing a mounted Volume. The simplest Volume is of type <code>emptyDir</code>, which starts out empty and preserves its contents only as long as the Pod is running.</p>&#13;
</li>&#13;
<li>&#13;
<p>A PersistentVolume, on the other hand, preserves its contents as long as needed. Pods can dynamically provision new PersistentVolumes using PersistentVolumeClaims.</p>&#13;
</li>&#13;
<li>&#13;
<p>Init containers can be useful for doing inital setup before your application is started in a Pod.<a data-startref="ix_08-containers-adoc0" data-type="indexterm" id="idm45979383696240"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>