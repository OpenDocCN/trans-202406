<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 5. Linear Algebra"><div class="chapter" id="idm45807805412256">
<h1><span class="label">Chapter 5. </span>Linear Algebra</h1>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45807805411248">
<h5>A Note for Early Release Readers</h5>
<p>With Early Release ebooks, you get books in their earliest form‚Äîthe author‚Äôs raw and unedited content as they write‚Äîso you can take advantage of these technologies long before the official release of these titles.</p>

<p>This will be the 10th chapter of the final book. Please note that the GitHub repo will be made active later on.</p>

<p>If you have comments about how we might improve the content and/or examples in this book, or if you notice missing material within this chapter, please reach out to the author at <em>learnmodcppfinance@gmail.com</em>.</p>
</div></aside>






<section data-type="sect1" data-pdf-bookmark="Introduction"><div class="sect1" id="idm45807805407792">
<h1>Introduction</h1>

<p>Linear algebra is an essential part of computational finance, and as such it is a necessary and fundamental component for financial C++ software development.  Options existing at present in the Standard Library are mostly limited to the <code>valarray</code> container, to be discussed briefly below.  Over the last 15 years or so, some very good open source matrix algebra libraries have emerged that have been adopted by the financial software industry, as well as other computationally intensive domains such as data science and medical research.  Progress is also being made toward linear algebra capabilities eventually being adopted into the Standard Library in C++23 and C++26.</p>

<p>As C++ did not have all the convenient built-in multidimensional array capabilities that came with Fortran platforms, quantitative programmers making the transition to C++ back in the 1990‚Äôs often found themselves in an inconvenient situation with limited options.  These included building up this functionality mostly from scratch, wrestling with interfaces to numerical Fortran libraries such as BLAS and LAPACK, or somehow convincing management to invest in a third-party C++ commercial library.</p>

<p>Contrived DIY solutions that were sometimes employed, based on what was available in C++ at the time, included representing a matrix as a <code>vector</code> of <code>vector</code>(s), or holding data in a two-dimensional dynamic C-array.  Neither of these was particular palatable, with the former being cumbersome and inefficient, and the latter exposing the software to the risks associated with raw pointers and dynamic memory management.  One seemingly useful feature available in the Standard Library, but not without controversy, was <code>std::valarray</code>.  It has survived to the current day, and it provides vectorized operations and functions highly suitable for matrix and vector math.  Its pros and cons will be presented momentarily.</p>

<p>The situation has improved substantially over the years with the release of multiple open-source linear algebra libraries for C++.  Among these, two that have gained considerable critical mass in computational finance are the <a href="https://eigen.tuxfamily.org">Eigen</a> library <strong>{1}</strong>, and <a href="http://arma.sourceforge.net">Armadillo</a> <strong>{2}</strong>.  A third option that has risen to some prominence in high-performance computing (HPC) is the <a href="https://bitbucket.org/blaze-lib/blaze">Blaze</a> library <strong>{3}</strong>.  An earlier library, <a href="https://www.boost.org/doc/libs/1_81_0/libs/numeric/ublas/doc/index.html">uBLAS</a>, <strong>{4}</strong> is also available as part of the Boost libraries; however, it does not include the matrix decompositions and other capabilities available in the aforementioned offerings.</p>

<p>As a side note, open source R interface packages are available for each of these libraries. <strong>{5}</strong>  These packages enable the integration of C++ code dependent on one or more of these libraries into R packages, usually to enhance run-time performance.</p>

<p>More recently, NVIDIA has released  <a href="https://developer.nvidia.com/gpu-accelerated-libraries#linear-algebra">GPU-accelerated C++ linear algebra libraries</a> as part of its HPC SDK. <strong>{6}</strong>.</p>

<p>A comparative list of both open source and commercial C++ linear algebra libraries, including those mentioned here, can be found on <a href="https://en.wikipedia.org/wiki/Comparison_of_linear_algebra_libraries">Wikipedia</a>.<strong>{7}</strong>  A more in-depth view of the Eigen library follows later in this chapter.</p>

<p>New features planned for C++23 and C++26 look set to finally provide the Standard Library with long overdue robust and well-supported linear algebra capabilities.  Central among these new features is the <code>std::mdspan</code> multi-dimensional array representation planned for C++23.  C++26 should then be updated with both a standardized interface to external BLAS-compatible libraries, as well as its own set of linear algebra facilities.</p>

<p>Below, we will first take a trip back in time and examine convenient mathematical features of <code>valarray</code>, and then demonstrate how it can be used as a proxy for a matrix.  Following that, we will dive into the Eigen library of the present and demonstrate the basic matrix operations, along with matrix decompositions frequently used in financial modeling.  Finally, a glimpse of the proposals for near-future Standard Library releases will also be presented.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="valarray and Matrix Operations"><div class="sect1" id="idm45807805388768">
<h1>valarray and Matrix Operations</h1>

<p>The workhorse STL container <code>std::vector</code>, as we have seen, is an option for representing a vector in the mathematical sense.  Common vector arithmetic, such as inner products, can be performed using STL algorithms.  However, having been ‚Äúdesigned to be a general mechanism for holding values‚Ä¶‚Äãand to fit into the architecture of containers, iterators, and algorithms‚Äù {2.5 Stroustrup, Tour 2E} <strong>{8}</strong>, the common arithmetic vector operators such as addition and multiplication were not included as members in its implementation.</p>

<p>A Standard Library container class separate from the STL, called <code>valarray</code>, does support arithmetic operators and provides ‚Äúoptimizations that are often considered essential for serious numerical work‚Äù {ibid}.  With slice and stride functions also accompanying the <code>valarray</code> class, it can also facilitate representation arrays of higher dimension, in particular a matrix.</p>

<p>While <code>valarray</code> has these very useful properties that would seem to make it an obvious choice for matrix math, it has played to mixed reviews.  This dates back to its original specification which was never fully complete due to debates over whether to require a new technique at the time, expression templates (to be introduced shortly), that can significantly optimize performance.  In the end, this was not mandated.  As a result, <a href="https://wg21.link/p1673">‚Äúinitial implementations were slow, and thus users did not want to rely on it.‚Äù</a> <strong>{9}</strong></p>

<p>As of the time of this writing, however, two of the mainstream Standard Library distributions have implemented expression template versions of <code>valarray</code>, namely those that accompany the gcc and Clang compilers.  In addition, the <a href="https://www.intel.com/content/www/us/en/developer/articles/tool/oneapi-standalone-components.html#dpcpp-cpp">Intel oneAPI DPC++/C++ Compiler</a> <strong>{10}</strong> ships with its own high-performance implementation of <code>valarray</code>.  And as an incidental remark, specializations of <code>begin</code> and <code>end</code> functions were included as enhancements in C++11.</p>

<p>The moral of the story seems to be:  know the capabilities of the implementation you intend to use.  If its performance is suitable for your needs, then it can potentially be a very convenient option for matrix/vector operations, and vectorized versions of common mathematical functions.  In addition, examining the properties of <code>valarray</code> may provide some context for future linear algebra enhancements planned for the Standard Library, with similar functionality in some cases, even though the implementations behind the scenes will be considerably different.</p>








<section data-type="sect2" data-pdf-bookmark="Arithmetic Operators and Math functions"><div class="sect2" id="idm45807806010560">
<h2>Arithmetic Operators and Math functions</h2>

<p>The <code>valarray</code> container supports the standard arithmetic operators on an element-by-element basis, as well as scalar multiplication.</p>

<p>For example, the vector sum expression <math alttext="3 bold v 1 plus one-half bold v 2">
  <mrow>
    <mn>3</mn>
    <msub><mi>ùêØ</mi> <mn>1</mn> </msub>
    <mo>+</mo>
    <mfrac><mn>1</mn> <mn>2</mn></mfrac>
    <msub><mi>ùêØ</mi> <mn>2</mn> </msub>
  </mrow>
</math> can be naturally transcribed from a mathematical statement into C++ using <code>valarray</code> objects:</p>

<pre data-type="programlisting">import &lt;valarray&gt;;
. . .

	std::valarray&lt;double&gt; v1{ 1.0, 2.0, 3.0,
				  1.5, 2.5 };

	std::valarray&lt;double&gt; v2{ 10.0, -20.0, 30.0,
				 -15.0, 25.0 };

	double vec_sum = 3.0 * v1 + 0.5 * v2;    // vec_sum is also a valarray &lt;double&gt;</pre>

<p>The result is</p>

<pre data-type="programlisting">8 -4 24 -3 20</pre>

<p><em>Element-by-element</em> multiplication is also implemented with the <code>*</code> operator:</p>

<pre data-type="programlisting">double prod = v1 * v2;</pre>

<p>This gives us</p>

<pre data-type="programlisting">10 -40 90 -22.5 62.5</pre>

<p>The dot (or inner) product of <math alttext="v 1">
  <msub><mi>v</mi> <mn>1</mn> </msub>
</math> and <math alttext="v 2">
  <msub><mi>v</mi> <mn>2</mn> </msub>
</math> is easily obtained by summing the preceding result by invoking the <code>sum()</code> member function on the <code>valarray</code> class:</p>

<pre data-type="programlisting">double dot_prod = prod.sum();  	// Result = 100</pre>

<p>In addition to <code>sum</code>, <code>valarray</code> also has <code>max</code> and <code>min</code> functions, along with an <code>apply(.)</code> member function that applies an auxiliary function similar to <code>std::transform</code>:</p>

<pre data-type="programlisting">double v1_max = v1.max();	// 3.0
double v1_min = v1.min();	// 1.0

// u and w are valarray&lt;double&gt; types
auto u = v1.apply([](double x) -&gt; double {return x * x; });
// Result: 1, 4, 9, 2.25, 6.25

auto w = v1.apply([](double x) -&gt; double {return std::sin(x) + std::cos(x);});
// Result: 1.38177 0.493151 -0.848872 1.06823 -0.202671</pre>

<p>A subset of the <code>cmath</code> functions is conveniently defined for vectorized operations on the entirety of a <code>valarray</code>.  For example, the following operations will return a <code>valarray</code> containing the images of the respective functions applied to each element in <code>v1</code> and <code>neg_val</code> below.  Note that we can also negate each element in the same way as a plain numerical type with the subtraction operator.</p>

<pre data-type="programlisting">// The result in each is a valarray&lt;double&gt;
auto sine_v1 = std::sin(v1);
auto log_v1 = std::log(v1);
auto abs_v1 = std::abs(neg_val);
auto exp_v1 = std::exp(neg_val);
auto neg_v1 = - v1;</pre>

<p>Finally, as of C++11, specializations of the <code>begin</code> and <code>end</code> functions analagous to those provided for STL containers have been implemented for <code>valarray</code>.  A simple example is as follows:</p>

<pre data-type="programlisting">template&lt;typename T&gt;
void print(T t) { cout &lt;&lt; t &lt;&lt; " "; }

std::for_each(std::begin(w), std::end(w), print&lt;double&gt;);</pre>

<p>Given the <code>apply(.)</code> member function on <code>valarray</code> and the built-in vectorized mathematical functions that are already available, STL algorithms <code>for_each</code> and <code>transform</code> might not be needed as often in the case of <code>valarray</code> compared to STL containers, however.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="valarray as a Matrix Proxy"><div class="sect2" id="idm45807805984544">
<h2>valarray as a Matrix Proxy</h2>

<p><code>valarray</code> provides the facilities to represent multidimensional arrays.  In our case, we are specifically concerned with representing a two-dimensional array as a proxy for a matrix.  This can be achieved with the <code>slice(.)</code> member function that can extract a reference to an individual row or column.</p>

<p>To demonstrate this, let us first lighten the notation by defining the alias</p>

<pre data-type="programlisting">using mtx_array = std::valarray&lt;double&gt;;</pre>

<p>Then, create a <code>valarray</code> object <code>val</code>, with the code formatted in a way to make it look like a 4 <math alttext="times">
  <mo>√ó</mo>
</math> 3 matrix:</p>

<pre data-type="programlisting">mtx_array val{ 1.0, 2.0, 3.0,
			   1.5, 2.5, 3.5,
			   7.0, 8.0, 9.0,
			   7.5, 8.5, 9.5};</pre>

<p>The first row can be retrieved using the <code>std::slice</code> function, defined for a <code>valarray</code>, using the square bracket operator.</p>

<pre data-type="programlisting">auto slice_row01 = val[std::slice(0, 3, 1)];</pre>

<p>What this says is:</p>

<ul>
<li>
<p>Go to the first element of the <code>valarray</code>:  index 0, value = 1.0.</p>
</li>
<li>
<p>Choose 3 elements, beginning with the first</p>
</li>
<li>
<p>Using a <em>stride</em> of 1, which in this case means to choose three consecutive rowwise elements</p>
</li>
</ul>

<p>Similarly, the second column can be retrieved, using in this case a stride of 3, the number of columns:</p>

<pre data-type="programlisting">auto slice_col02 = val[std::slice(1, 4, 3)];		// The 2nd rowwise element has index 1</pre>

<p>It is important to note the <code>slice(.)</code> function returns a lighter <code>slice_array</code> type‚Äâ‚Äî‚Äâthat acts as a reference to the selected elements‚Äâ‚Äî‚Äârather than a full <code>valarray</code>.  It does not, however, provide the necessary member functions and operators to access individual elements or compute, say, new rows comprising a matrix product.  If we want to apply these functions to row or column data, we will need to construct corresponding new <code>valarray</code> objects.  This will be seen in the next example, computing the dot product of a row in one matrix by the column in another, a necessary option in carrying out matrix multiplication.</p>

<p>To demonstrate this, suppose we have a 5 <math alttext="times">
  <mo>√ó</mo>
</math> 3 and a 3 <math alttext="times">
  <mo>√ó</mo>
</math> 5 matrix, each represented as a <code>valarray</code>.  Note that we are also storing the number of rows and columns of each in separate variables.</p>

<pre data-type="programlisting">mtx_array va01{ 1.0, 2.0, 3.0,
 	            1.5, 2.5, 3.5,
		        4.0, 5.0, 6.0,
		        4.5, 5.5, 6.5,
			    7.0, 8.0, 9.0 };

unsigned va01_rows{ 5 }, va01_cols{ 3 };

mtx_array va02{ 1.0, 2.0, 3.0, 4.0, 5.0,
			    1.5, 2.5, 3.5, 4.5, 5.5,
		  	    5.0, 6.0, 7.0, 8.0, 8.5 };

unsigned va02_rows{ 3 }, va02_cols{ 5 };</pre>

<p>If we were to apply matrix multiplication, it would require taking the dot product of each row of the first ‚Äúmatrix‚Äù by each column of the second.  As an example, in order to get the dot product of the third row by the second column, we would first need the slice for each:</p>

<pre data-type="programlisting">auto slice_01_row_03 = va01[std::slice(9, va01_cols, 1)];
auto slice_02_col_02 = va02[std::slice(1, va02_rows, 5)];</pre>

<p>However, neither element-by-element multiplication nor the <code>sum()</code> member function is defined on a <code>slice_array</code>, so we need to construct corresponding <code>valarray</code> objects:</p>

<pre data-type="programlisting">mtx_array va01_row03{ slice_01_row_03 };
mtx_array va02_col02{ slice_02_col_02 };</pre>

<p>The dot product is then computed in the usual way:</p>

<pre data-type="programlisting">double dot_prod = (va01_row03 * va02_col02).sum();</pre>
<div data-type="caution"><h6>Caution</h6>
<p>As previously noted, a <code>slice_array</code> acts as a reference to a block within a <code>valarray</code>.  Operations and member functions such as <code>\*</code> and <code>sum</code> are not defined on <code>slice_array</code>, but assignment operators such as <code>*=</code> and <code>+=</code> are.  Therefore, modification of a <code>slice_array</code> such as in the following example will also be reflected in the <code>valarray</code> itself.  If we take the first row of <code>va01</code> as a slice:</p>

<pre data-type="programlisting">auto slice_01_row_01 = va01[std::slice(0, va01_cols, 1)];</pre>

<p>and then apply assignment operators</p>

<pre data-type="programlisting">slice_01_row_01[0] *= 10.0;
slice_01_row_01[1] += 1.0;
slice_01_row_01[2] -= 3.0;</pre>

<p>then the <code>valarray</code> contents would be</p>

<pre data-type="programlisting">10	3	0
1.5	2.5	3.5
7	8	9
7.5	8.5	9.5</pre>
</div>

<p>In summary, <code>valarray</code> conveniently provides the ability to apply mathematical operators and functions on an entire array, similar to Fortran 90, as well as more math-focused languages such as R and Matlab .  As a reminder, however, performance can be highly dependent on the implementation used in your Standard Library distribution.</p>

<p>More information about <code>valarray</code>, its history, and its pros and cons can be found in  <a href="http://www.cppstdlib.com/cppstdlib_supplementary.pdf">the online supplemental chapter accompanying Josuttis, _The C++ Standard Library, second edition</a>). <strong>{11}</strong></p>

<p>Subsequent to <code>valarray</code> and C++98, there have been some very positive developments regarding linear algebra in C++, some of which will now be presented.</p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Eigen"><div class="sect1" id="idm45807805944112">
<h1>Eigen</h1>

<p>The first release of the Eigen library became available in 2006.  Since then, it has been expanded to version 3.4.0 as of August of 2021.  Starting with version 3.3.1, it has been licensed under the reasonably liberal Mozilla Public License (MPL) 2.0.</p>

<p>Eigen is comprised of template code that makes inclusion into other C++ projects very easy, in that in its standard installation there is no linking necessary to external binary files.  Its incorporation of expression templates, facilitating lazy evaluation, provides for enhanced computational performance.  It also received a a further boost in popularity after being chosen for incorporation into the well-respected <a href="https://www.tensorflow.org">TensorFlow</a> <strong>{12}</strong> machine learning library, as well as the <a href="https://mc-stan.org/users/interfaces/math">Stan Math Library</a>. <strong>{13}</strong>  More background on its suitability and popularity in finance is presented in a recent <a href="https://www.quantstart.com/articles/Eigen-Library-for-Matrix-Algebra-in-C/">Quantstart</a> article <strong>{14}</strong>.</p>

<p>Finally, the Eigen library is very well documented, with a tutorial and examples to help the newcomer get up and running quickly.</p>








<section data-type="sect2" data-pdf-bookmark="Lazy Evaluation"><div class="sect2" id="idm45807805937280">
<h2>Lazy Evaluation</h2>

<p>Lazy evaluation defers and minimizes the number of operations required in matrix and vector operations.  Expression templates in C++ are used to encapsulate arithmetic operations ‚Äì that is, expressions ‚Äì inside templates such that they are delayed until they are actually needed.  This can reduce the total number of operations, assignments, and temporary objects that are created when using conventional approaches.</p>

<p>An example of lazy evaluation that follows is based on a more comprehensive and illustrative discussion in the book by <a href="https://www.pearson.com/en-us/subject-catalog/p/discovering-modern-c-/P200000000286/9780136677642">Peter Gottschling on modern C++ for scientific programing</a>. <strong>{15}</strong></p>

<p>Suppose you have four vectors in the mathematical sense, each with the same fixed number of elements, say</p>
<div data-type="equation">
<math alttext="bold v 1 comma bold v 2 comma bold v 3 comma bold v 4" display="block">
  <mrow>
    <msub><mi>ùêØ</mi> <mn>1</mn> </msub>
    <mo>,</mo>
    <msub><mi>ùêØ</mi> <mn>2</mn> </msub>
    <mo>,</mo>
    <msub><mi>ùêØ</mi> <mn>3</mn> </msub>
    <mo>,</mo>
    <msub><mi>ùêØ</mi> <mn>4</mn> </msub>
  </mrow>
</math>
</div>

<p>and you wish to store their sum in a vector <em>y</em>.  The traditional approach would be to define the addition operator, take successive sums and store them in temporary objects, ultimately computing the final sum and assigning it to <em>y</em>.</p>

<p>In code, the operator could be defined in the generic sense such that vector addition would be defined for any arithmetic type:</p>

<pre data-type="programlisting">template &lt;typename T&gt;
std::vector&lt;T&gt; operator + (const std::vector&lt;T&gt;&amp; a,
	const std::vector&lt;T&gt;&amp; b)
{
	std::vector&lt;T&gt; res(a.size());
	for (size_t i = 0; i &lt; a.size(); ++i)
		res[i] = a[i] + b[i];
	return res;
}</pre>

<p>Computing the sum of four vectors as follows</p>

<pre data-type="programlisting">	vector&lt;double&gt; v1{ 1.0, 2.0, 3.0 };
	vector&lt;double&gt; v2{ 1.5, 2.5, 3.5 };
	vector&lt;double&gt; v3{ 4.0, 5.0, 6.0 };
	vector&lt;double&gt; v4{ 4.5, 5.5, 6.5 };

	auto y = v1 + v2 + v3 + v4;</pre>

<p>results in the following:</p>

<ul>
<li>
<p>4 - 1 = 3 <code>vector</code> instances created (two temporary plus one final <code>y</code> instance)</p>
</li>
<li>
<p>(4 - 1) <math alttext="times">
  <mo>√ó</mo>
</math> 3 assignments of <code>double</code> variables</p>
</li>
</ul>

<p>As the number of vectors (say <em>m</em>) and the number of elements in each vector (say <em>n</em>) get larger, this generalizes to</p>

<ul>
<li>
<p>m ‚Äì 1 <code>vector</code> objects allocated on the heap: m - 2 temporary, plus one return object (<code>y</code>)</p>
</li>
<li>
<p><math alttext="left-parenthesis m minus 1 right-parenthesis n">
  <mrow>
    <mo>(</mo>
    <mi>m</mi>
    <mo>-</mo>
    <mn>1</mn>
    <mo>)</mo>
    <mi>n</mi>
  </mrow>
</math> assignments</p>
</li>
</ul>

<p>With lazy evaluation, we can reduce the total number of steps, and thus improve efficiency for ‚Äúlarge‚Äù <em>m</em> and <em>n</em>.  More specifically, this can be accomplished by delaying the addition until all the data is ready, and then only at that time perform the sums for each element in the result.  In code, this could be accomplished by writing a function as follows.</p>

<pre data-type="programlisting">template &lt;typename T&gt;
std::vector&lt;T&gt; sum_four_vectors(const std::vector&lt;T&gt;&amp; a, const std::vector&lt;T&gt;&amp; b,
	const std::vector&lt;T&gt;&amp; c, const std::vector&lt;T&gt;&amp; d)
{
	// Assume a, b, c, and d all contain the same
	// number of elements:
	std::vector&lt;T&gt; sum(a.size());

	for (size_t i = 0; i &lt; a.size(); ++i)
	{
		sum[i] = a[i] + b[i] + c[i] + d[i];
	}

	return sum;
}</pre>

<p>Now, in this case,</p>

<ul>
<li>
<p>There are <em>no</em> temporary <code>vector</code> objects created; only the <code>sum</code> result is necessary</p>
</li>
<li>
<p>The number of assignments is reduced to <em>n</em> = 4</p>
</li>
</ul>

<p>The Eigen documentation provides additional background in the section <a href="https://eigen.tuxfamily.org/dox/TopicLazyEvaluation.html">Lazy Evaluation and Aliasing</a>.</p>

<p>The previous example demonstrates how lazy evaluation can work, but the obvious problem is it would be unrealistic to write individual sum functions for all possible fixed numbers of vectors.  Generalizing with expression templates is a far more challenging problem that will not be included here, but more information can be found in the Gottschling book {ibid 12}, as well as in Chapter 27 of the comprehensive book on C++ templates by <a href="http://tmplbook.com/">Vandevoorde, Josuttis, and Gregor</a> <strong>{16}</strong>.</p>

<p>Like any other optimization tool, it should not be applied blindly in the belief it will automatically make your code more efficient, as again there are cases where performance could actually be degraded.</p>

<p>Finally, for a very interesting presentation of a real-world case study of expression templates in financial risk management, a talk on the subject <a href="https://www.youtube.com/watch?v=4IUCBx5fIv0">presented by Bowie Owens at CppCon 2019</a> <strong>{17}</strong> is very well worth watching.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Eigen Matrices and Vectors"><div class="sect2" id="idm45807805904176">
<h2>Eigen Matrices and Vectors</h2>

<p>The heart of the Eigen library is, not surprisingly, the <code>Matrix</code> template class.  It is scoped with the <code>Eigen</code> namespace and requires the <code>Dense</code> header file be included.  At the time of this writing, corresponding module imports have not yet been standardized.  This means the header file will need to be included in the global fragment of a module.</p>

<p>The <code>Matrix</code> class carries six template parameters, but a variety of aliases are provided as specific types.  These include fixed square matrix dimensions up to a maximum of four, as well as dynamic types for arbitrary numbers of rows and columns.  The numerical type that a <code>Matrix</code> holds is also a template parameter, but this setting is also incorporated into individual aliases.  For example, the following code will construct and display a fixed 3 <math alttext="times">
  <mo>√ó</mo>
</math> 3 matrix of <code>double</code> values, and a 4 <math alttext="times">
  <mo>√ó</mo>
</math> 4 matrix of `int`s.  Braced (uniform) initialization by row can be used to load the data at construction.</p>

<pre data-type="programlisting">#include &lt;Eigen/Dense&gt;
. . .

Eigen::Matrix3d dbl_mtx			// Contains 'double' elements
{
	{10.6, 41.2, 2.16},
	{41.9, 5.31, 13.68},
	{22.47, 57.43, 8.82}
};

Eigen::Matrix4i int_mtx			// Contains 'int' elements
{
	{24, 0, 23, 13},
	{8, 75, 0, 98},
	{11, 60, 1, 3 },
	{422, 55, 11, 55}
};

cout &lt;&lt; dbl_mtx &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; int_mtx &lt;&lt; endl &lt;&lt; endl;</pre>

<p>Note also that the <code>&lt;&lt;</code> stream operator is overloaded, so the result can be easily displayed on the screen (in row-major order).</p>

<pre data-type="programlisting"> 10.6  87.4 58.63
 41.9  53.1 13.68
22.47 57.43  88.2

 24   0  23  13
  8  75   0  98
 11  60   1   3
422  55  11  55</pre>

<p>Individual rows and columns can also be accessed, using 0-based indexing.  The first column of the first matrix, and the third column of the second, for example are obtained with respective accessor functions:</p>

<pre data-type="programlisting">cout &lt;&lt; dbl_mtx.col(0) &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; int_mtx.row(2) &lt;&lt; endl &lt;&lt; endl;</pre>

<p>This results in the following screen output:</p>

<pre data-type="programlisting">10.6
41.9
22.47

11 60  1  3</pre>

<p>Technically speaking, the type returned by either the <code>row</code> or <code>col</code> accessor is an <code>Eigen::Block</code>.  It is similar to a <code>slice_array</code> accessed from a <code>valarray</code>, in that it acts as a lighter weight reference to the data.  Unlike <code>slice_array</code>, it does not carry any mathematical operators such as <code>+=</code>.</p>

<p>For most of the financial examples considered in this book, the dimensions of a matrix will not be known a priori, nor will they necessarily be of a square matrix.  In addition, the contents will usually be real numbers.  For these reasons, we will primarily be concerned with the Eigen dynamic form for <code>double</code> types, aliased as <code>Eigen::MatrixXd</code>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6><ol>
<li>
<p>As just mentioned, we will primarily use the dynamic Eigen <code>MatrixXd</code> form of a matrix (with <code>d</code> indicating <code>double</code> numerical elements); however, member and non-member functions will usually apply to any class derived from the <code>Matrix</code> template class.  Where these functions are discussed, their relations with <code>Matrix</code> rather than <code>MatrixXd</code> may also be mentioned.  Similarly, vector representation in Eigen will use <code>VectorXd</code>.</p>
</li>
<li>
<p>Linear algebra will inevitably involve subscripts and superscripts, eg <math alttext="x Subscript i j">
  <msub><mi>x</mi> <mrow><mi>i</mi><mi>j</mi></mrow> </msub>
</math>, where in mathematical notation <em>i</em> might run from 1 to <em>m</em>, and <em>j</em> from 1 to <em>n</em>.  However, C++ is 0-indexed, so a mathematical statement where <em>i</em> = 1 will be represented by <code>i = 0</code> in C++, <em>j</em> = <em>n</em> by <code>j = n - 1</code>, and so forth.</p>
</li>

</ol>
</div>

<p>Construction of a <code>MatrixXd</code> can take on many forms.  Data can be entered as before in row-major order, with the number of rows and columns implied by uniform initialization of individual rows.  Alternatively, the dimensions can be used as constructor arguments, with the data input by streaming in row-major order.  And, one more approach is to set each element one-by-one.  An example of each is shown here:</p>

<pre data-type="programlisting">using Eigen::MatrixXd;
. . .

MatrixXd mtx0
{
	{1.0, 2.0, 3.0},
	{4.0, 5.0, 6.0},
	{7.0, 8.0, 9.0},
	{10.0, 11.0, 12.0}
};

MatrixXd mtx1{4, 3};		// 4 rows, 3 columns
mtx1 &lt;&lt; 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0;

MatrixXd mtx3{2, 2};
mtx3(0, 0) = 3.0;
mtx3(1, 0) = 2.5;
mtx3(0, 1) = -1.0;
mtx3(1, 1) = mtx3(1, 0) + mtx3(0, 1);</pre>

<p>Note that the round bracket operator serves as both a mutator and an accessor, as demonstrated in the third example.</p>

<p>Two special cases, where either the number of columns or rows is one, are aliased as <code>VectorXd</code> and <code>RowVectorXd</code>.  Construction options are similar to the <code>MatrixXd</code> examples above, again as shown in the Eigen documentation:</p>

<pre data-type="programlisting">using Eigen::VectorXd;
using Eigen::RowVectorXd;
. . .

VectorXd a 	{ {1.5, 2.5, 3.5} };             // A column-vector with 3 coefficients
RowVectorXd b { {1.0, 2.0, 3.0, 4.0} };      // A row-vector with 4 coefficients

Eigen::VectorXd v(2);
v(0) = 4.0;
v(1) = v(0) - 1.0;</pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Matrix and Vector Math Operations"><div class="sect2" id="idm45807805869472">
<h2>Matrix and Vector Math Operations</h2>

<p>Matrix addition and subtraction are are conveniently implemented as overloads of the <code>+</code> and <code>-</code> operators, not unlike <code>valarray</code>.  Similarly, these apply to vectors.  Unlike <code>valarray</code>, however, the multiplication operator <code>*</code> refers to matrix multiplication rather than an element-by-element product.  A separate set of functions is available for a wide range of element-by-element operations.</p>

<p>To multiply two matrices <code>A</code> and <code>B</code>, the code follows in natural mathematical order:</p>

<pre data-type="programlisting">MatrixXd A
{
	{1.0, 2.0, 3.0},
	{1.5, 2.5, 3.5},
	{4.0, 5.0, 6.0},
	{4.5, 5.5, 6.5},
	{7.0, 8.0, 9.0}
};

MatrixXd B
{
	{1.0, 2.0, 3.0, 4.0, 5.0},
	{1.5, 2.5, 3.5, 4.5, 5.5},
	{5.0, 6.0, 7.0, 8.0, 8.5}
};

MatrixXd prod_ab = A * B;</pre>

<p>This gives us as output:</p>

<pre data-type="programlisting">   19    25    31    37  41.5
22.75 30.25 37.75 45.25    51
 41.5  56.5  71.5  86.5  98.5
45.25 61.75 78.25 94.75   108
   64    88   112   136 155.5</pre>
<div data-type="caution"><h6>Caution</h6>
<p>In the Eigen documentation, it is strongly recommended to ‚Äúnot use the auto keywords with Eigen‚Äôs expressions, unless you are 100% sure about what you are doing. In particular, do not use the auto keyword as a replacement for a <code>Matrix&lt;&gt;</code> type.‚Äù</p>

<p>The reasons behind this require an advanced discussion about templates that tie in with lazy evaluation.  Lazy Evaluation provides advantages in efficiency, but it also can involve return types using <code>auto</code> that might be in the form of a reference rather than a full <code>Matrix</code> type.  This can result in unexpected or undefined behavior.  It becomes less of an issue as you become more familiar with various Eigen types, but for this introductory presentation, we will mostly heed this admonishment.</p>

<p>More information can be found <a href="https://eigen.tuxfamily.org/dox/TopicPitfalls.html">in the documentation</a>. <strong>{18}</strong></p>
</div>

<p>The <code>*</code> operator is also overloaded for matrix-vector and row vector-matrix multiplication.  As an example, suppose we have a portfolio of three funds, with correlation matrix of the returns and the vector of individual fund volatilities given (annualized).  As is a typical problem, we might need to construct the covariance matrix given the data in this form in order to calculate the portfolio volatility.  First, to form the covariance matrix, we would pre- and post-multiply the correlation matrix by diagonal matrices containing the fund volatilities:</p>

<pre data-type="programlisting">MatrixXd corr_mtx
{
	{1.0, 0.5, 0.25},
	{0.5, 1.0, -0.7},
	{0.25, -0.7, 1.0}
};

VectorXd vols{ {0.2, 0.1, 0.4 } };

MatrixXd cov_mtx = vols.asDiagonal() * corr_mtx * vols.asDiagonal();</pre>

<p>Note how the <code>VectorXd</code> member function <code>asDiagonal()</code> conveniently forms a diagonal matrix with the vector elements along the diagonal.</p>

<p>Then, given a vector of fund weights <math alttext="omega">
  <mi>œâ</mi>
</math> adding to 1, the portfolio volatility is then the square root of the quadratic form</p>
<div data-type="equation">
<math alttext="omega Superscript sans-serif upper T Baseline bold upper Sigma omega" display="block">
  <mrow>
    <msup><mi>œâ</mi> <mi>ùñ≥</mi> </msup>
    <mi>Œ£</mi>
    <mi>œâ</mi>
  </mrow>
</math>
</div>

<p>where <math alttext="bold upper Sigma">
  <mi>Œ£</mi>
</math> is the covariance matrix:</p>

<pre data-type="programlisting">VectorXd fund_weights{ {0.6, -0.3, 0.7 } };
double port_vol = std::sqrt(fund_weights.transpose() * cov_mtx * fund_weights);</pre>

<p>For element-by-element matrix multiplication, use the <code>cwiseProduct</code> member function.  As an example, to multiply the individual elements in matrices of like dimension, say <math alttext="bold upper A">
  <mi>ùêÄ</mi>
</math> and <math alttext="bold upper B Superscript sans-serif upper T">
  <msup><mi>ùêÅ</mi> <mi>ùñ≥</mi> </msup>
</math>, we would write:</p>

<pre data-type="programlisting">MatrixXd cwise_prod = A.cwiseProduct(B.transpose());</pre>

<p>There is in fact a set of <code>cwise...</code> (meaning <em>coefficient-wise</em>) member functions on an Eigen <code>Matrix</code> that perform element-by-element operations on two compatible matrices, such as  <code>cwiseQuotient</code> and <code>cwiseNotEqual</code>.  There are also unary <code>cwise</code> member functions that return the absolute value and square root of each element.  These can be found in the <a href="https://eigen.tuxfamily.org/dox/group__QuickRefPage.html#title6">Eigen documentation</a> here. <strong>{19}</strong></p>

<p>The result of the <code>*</code> operator when applied to two vectors depends upon which vector is transposed.  For two vectors u and v, the dot (inner) product is computed as</p>
<div data-type="equation">
<math alttext="bold u Superscript sans-serif upper T Baseline bold v" display="block">
  <mrow>
    <msup><mi>ùêÆ</mi> <mi>ùñ≥</mi> </msup>
    <mi>ùêØ</mi>
  </mrow>
</math>
</div>

<p>while the outer product results when the transpose is applied to v:</p>
<div data-type="equation">
  <math display="block">
  <msup>
    <mstyle style="font-weight:bold">
      <mi>u</mi>
      <mi>v</mi>
    </mstyle>
    <mi>T</mi>
  </msup>
</math>
</div>

<p>So, one needs to be careful when using the <code>*</code> operator with vectors.  Suppose we have:</p>

<pre data-type="programlisting">VectorXd u{ {1.0, 2.0, 3.0} };
VectorXd v{ {0.5, -0.5, 1.0} };</pre>

<p>The respective results of the following vector multiplications will be different:</p>

<pre data-type="programlisting">double dp = u.transpose() * v;			// Returns 'double'
MatrixXd op = u * v.transpose();		// Returns a Matrix</pre>

<p>The first would result in a real value of 2.5, while the second would give us a singular 3 <math alttext="times">
  <mo>√ó</mo>
</math> 3 matrix:</p>

<pre data-type="programlisting">  0.5 -0.5   1
   1   -1    2
 1.5 -1.5    3</pre>

<p>To make life easier, Eigen provides a member function, <code>dot</code>, on the <code>VectorXd</code> class.  By instead writing</p>

<pre data-type="programlisting">dp = u.dot(v);</pre>

<p>it should perhaps make it clearer which product we want.  The result would be the same as before, plus the operation is commutative.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="STL Compatibility"><div class="sect2" id="idm45807805826288">
<h2>STL Compatibility</h2>

<p>A very nice feature of both the Eigen <code>Vector</code> and <code>Matrix</code> classes is their compatibility with the Standard Template Library.  This means you can iterate through an Eigen container, apply STL algorithms, and exchange data with STL containers.</p>










<section data-type="sect3" data-pdf-bookmark="STL and VectorXd"><div class="sect3" id="idm45807805823744">
<h3>STL and <code>VectorXd</code></h3>

<p>As a first example, suppose you wish to generate 12 random variates from a t-distribution and place the results in a <code>VectorXd</code> container.  The process is essentially the same as what we saw using a <code>std::vector</code> and applying the <code>std::generate</code> algorithm with a lambda auxiliary function:</p>

<pre data-type="programlisting">VectorXd u(12);							// 12 elements
std::mt19937_64 mt(100);				// Mersenne Twister engine, seed = 100
std::student_t_distribution&lt;&gt; tdist(5);	// 5 degrees of freedom
std::generate(u.begin(), u.end(), [&amp;mt, &amp;tdist]() {return tdist(mt); });</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Prior to the recent Eigen 3.4 release, the <code>begin</code> and <code>end</code> member functions were not defined.  In this case, you would need to instead use the <code>data</code> and <code>size</code> functions, as follows:</p>

<pre data-type="programlisting">std::generate(u.data()), u.data() + u.size(),
[&amp;mt, &amp;tdist]() {return tdist(mt); });</pre>
</div>

<p>Non-modifying algorithms such as <code>std::max_element</code> are also valid:</p>

<pre data-type="programlisting">auto max_u = std::max_element(u.begin(), u.end());		// Returns iterator</pre>

<p>Numeric algorithms, for example <code>std::inner_product</code>, can also be applied:</p>

<pre data-type="programlisting">double dot_prod = std::inner_product(u.begin(), u.end(), v.begin(), 0.0);</pre>

<p>The cleaner C++20 range versions are also supported on <code>VectorXd</code>:</p>

<pre data-type="programlisting">VectorXd w(v.size());
std::ranges::transform(u, v, w.begin(), std::plus{});</pre>
</div></section>










<section data-type="sect3" data-pdf-bookmark="Constructing a Matrix from STL Container Data"><div class="sect3" id="idm45807806473536">
<h3>Constructing a Matrix from STL Container Data</h3>

<p>Matrix data can also be obtained from STL containers.  This is convenient, as data can often arrive via interfaces from other sources where Eigen might not be included.  The key is to use an <code>Eigen::Map</code>, which sets up a reference to (view of) the <code>vector</code> data rather than taking a copy of it.</p>

<p>As a first example, data residing in a <code>std::vector</code> container can be transferred to an <code>Eigen::Map</code>, which in turn can be used as the constructor argument for a <code>MatrixXd</code>.  Note that the <code>Map</code> takes in a pointer to the first element in the <code>vector</code> (using the <code>data</code> member function), and the number of rows and columns, in its constructor.</p>

<pre data-type="programlisting">std::vector&lt;double&gt; v{ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0,
	7.0, 8.0, 9.0, 10.0, 11.0, 12.0 };

Eigen::Map&lt;MatrixXd&gt; mtx_map(v.data(), 4, 3);</pre>

<p>By default, <code>mtx_map</code> will provide row/column access to the data.  Note that unlike creating a <code>MatrixXd</code> as before with an initializer list of data, the order will be column-major rather than row-major.  Using <code>cout</code> yields the following output:</p>

<pre data-type="programlisting">1  5  9
2  6  10
3  7  11
4  8  12</pre>

<p>As a <code>Map</code> is a lighter weight view of the data in <code>v</code>, it does not carry with it all of the functionality as found on a <code>Matrix</code> object, in a sense similar to a slice taken from a`valarray`.  If you need this functionality, then you can construct a <code>MatrixXd</code> instance by putting the <code>Map</code> object in its constructor:</p>

<pre data-type="programlisting">MatrixXd mtx_from_std_vector{ mtx_map };</pre>

<p>The default arrangement of the data in a <code>Map</code> will be in <em>column-major order</em>, which is different from the earlier <code>MatrixXd</code> examples constructed with numerical data.  If row-major is required, you can specify row-major at the outset, but this will require an <code>Eigen::Matrix</code> template parameter with storage explicitly set to <code>RowMajor</code>, as <code>MatrixXd</code> does not have its own template parameter for storage method:</p>

<pre data-type="programlisting">Eigen::Map&lt;Eigen::Matrix&lt;double, 4, 3, Eigen::RowMajor&gt;&gt;
    mtx_row_major_map{ v.data(), 4, 3 };</pre>

<p>If the matrix is square, you can just transpose the <code>Map</code> in place to put it in row-major order:</p>

<pre data-type="programlisting">// Square matrix, place in row-major order:
std::vector&lt;double&gt; sq_data{ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0,
	7.0, 8.0, 9.0 };

Eigen::Map&lt;MatrixXd&gt; sq_mtx_map{ sq_data.data(), 3, 3 };
sq_mtx_map.transposeInPlace();</pre>

<p>The result is then:</p>

<pre data-type="programlisting">1 2 3
4 5 6
7 8 9</pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Attempting to transpose a non-square matrix using <code>Map</code> can result in a program crash.  In this case, you will need to create a full <code>MatrixXd</code> object before applying <code>transposeInPlace</code>.</p>
</div>
</div></section>










<section data-type="sect3" data-pdf-bookmark="Applying STL Algorithms to a Matrix"><div class="sect3" id="idm45807806450416">
<h3>Applying STL Algorithms to a Matrix</h3>

<p>STL algorithms can also be applied to matrices row by row, or column by column.  Suppose we have a 4 <math alttext="times">
  <mo>√ó</mo>
</math> 3 matrix as follows:</p>

<pre data-type="programlisting">	MatrixXd vals
	{
		{ 9.0, 8.0, 7.0 },
		{ 3.0, 2.0, 1.0 },
		{ 9.5, 8.5, 7.5 },
		{ 3.5, 2.5, 1.5 }
	};</pre>

<p>The <code>rowwise()</code> member function on an Eigen <code>Matrix</code> sets up an iteration by row.  Each <code>row</code> is a reference to (view of) the respective data, so we can square each element of the matrix in place as follows:</p>

<pre data-type="programlisting">for (auto row : vals.rowwise())
{
	std::ranges::transform(row, row.begin(), [](double x) {return x * x; });
}</pre>

<p>The <code>colwise()</code> member function is similar, in this case sorting each column of the matrix:</p>

<pre data-type="programlisting">for (auto col : vals.colwise())
{
	std::ranges::sort(col);
}</pre>

<p>The end result after applying both algorithms gives us</p>

<pre data-type="programlisting">    9     4     1
12.25  6.25  2.25
   81    64    49
90.25 72.25 56.25</pre>

<p>Each element has been squared, and each column has been rearranged in ascending order.</p>

<p>Financial programmers often need to write code that will compute the log returns on a set of equity or fund prices.  For example, suppose we have a set of 11 monthly prices for three ETF‚Äôs, in the following three columns:</p>

<pre data-type="programlisting">25.5  8.0 70.5
31.0  7.5 71.0
29.5  8.5 77.5
33.5  5.5 71.5
26.5  9.5 72.5
34.5  8.5 75.5
28.5  9.0 72.0
23.5  7.5 73.5
28.0  8.0 72.5
31.5  9.0 73.0
32.5  9.5 74.5</pre>

<p>The first step in computing log returns is to compute the natural log of each price.  This can be done by applying the <code>transform</code> algorithm row by row:</p>

<pre data-type="programlisting">for (auto row : prices_to_returns.rowwise())
{
	std::ranges::transform(row, row.begin(), [](double x) {return std::log(x); });
}</pre>

<p>Then, to get the log returns, we need to subtract from each log price its predecessor.  For this, we can apply the <code>adjacent_difference</code> numeric algorithm to each column:</p>

<pre data-type="programlisting">for (auto col : prices_to_returns.colwise())
{
	std::adjacent_difference(col.begin(), col.end(), col.begin());
}</pre>

<p>This result is still an 11 <math alttext="times">
  <mo>√ó</mo>
</math> 3 matrix, with the first row still containing the logs of the prices in the first row.</p>

<pre data-type="programlisting">   3.23868    2.07944    4.25561
  0.195309 -0.0645385 0.00706717
-0.0495969   0.125163  0.0875981
  0.127155  -0.435318 -0.0805805
 -0.234401   0.546544  0.0138891
  0.263815  -0.111226  0.0405461
 -0.191055  0.0571584 -0.0474665
 -0.192904  -0.182322  0.0206193
  0.175204  0.0645385 -0.0136988
  0.117783   0.117783 0.00687288
 0.0312525  0.0540672  0.0203397</pre>

<p>What we want are the monthly returns alone, so we need to remove the first row.  This can be achieved by applying the <code>seq</code> function, introduced in Eigen 3.4, which provides an intuitive way of extracting a submatrix view (an <code>Eigen::Block</code>) from a <code>Matrix</code> object.  The example here shows how to extract all rows below the first:</p>

<pre data-type="programlisting">MatrixXd returns_mtx{ prices_to_returns(Eigen::seq(1, Eigen::last),
	Eigen::seq(0, Eigen::last)) };</pre>

<p>What this says is:</p>
<ol>
<li>
<p>Start with the second row (index 1) and include all rows down to the last row:  <code>Eigen::seq(1, Eigen::last)</code></p>
</li>
<li>
<p>Take all columns from the first (index 0) to the last:  <code>Eigen::seq(0, Eigen::last)</code></p>
</li>
<li>
<p>Use this submatrix data alone in the constructor for the resulting <code>returns_mtx</code></p>
</li>

</ol>

<p>The results held in <code>returns_mtx</code> are then the log returns alone:</p>

<pre data-type="programlisting">  0.195309 -0.0645385 0.00706717
-0.0495969   0.125163  0.0875981
  0.127155  -0.435318 -0.0805805
 -0.234401   0.546544  0.0138891
  0.263815  -0.111226  0.0405461
 -0.191055  0.0571584 -0.0474665
 -0.192904  -0.182322  0.0206193
  0.175204  0.0645385 -0.0136988
  0.117783   0.117783 0.00687288
 0.0312525  0.0540672  0.0203397</pre>

<p>Now, suppose the portfolio allocation is fixed at 35%, 40%, and 25% for each respective fund (columnwise).  We can get the monthly portfolio returns by multiplying the vector of allocations by <code>returns_mtx</code>:</p>

<pre data-type="programlisting">VectorXd monthly_returns = returns_mtx * allocations;</pre>

<p>The result is</p>

<pre data-type="programlisting"> 0.0443094
 0.0546058
 -0.149768
   0.14005
 0.0579814
-0.0558726
  -0.13529
 0.0837121
 0.0900555
 0.0376502</pre>
</div></section>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Matrix Decompositions and Applications"><div class="sect2" id="idm45807806420784">
<h2>Matrix Decompositions and Applications</h2>

<p>Matrix decompositions are of course essential for a variety of financial engineering problems.  Below, we will discuss a few examples.</p>










<section data-type="sect3" data-pdf-bookmark="Systems of Linear Equations and the LU Decomposition"><div class="sect3" id="idm45807806419200">
<h3>Systems of Linear Equations and the LU Decomposition</h3>

<p>Systems of linear equations are ubiquitous in finance and economics, particularly in optimization, hedging, and forecasting problems.  To show how solutions can be found in Eigen, let us just look at a generic problem and implement it in code.  The LU (Lower/Upper-triangular matrix) decomposition is a common approach in numerical methods.  As opposed to coding it ourselves, Eigen can get the job done in two lines of code.</p>

<p>Suppose we want to solve the following system of linear equations for <math alttext="x 1">
  <msub><mi>x</mi> <mn>1</mn> </msub>
</math>, <math alttext="x 2">
  <msub><mi>x</mi> <mn>2</mn> </msub>
</math>, and <math alttext="x 3">
  <msub><mi>x</mi> <mn>3</mn> </msub>
</math>:</p>
<div data-type="equation">
<math alttext="3 x 1 minus 5 x 2 plus x 3 equals 0" display="block">
  <mrow>
    <mn>3</mn>
    <msub><mi>x</mi> <mn>1</mn> </msub>
    <mo>-</mo>
    <mn>5</mn>
    <msub><mi>x</mi> <mn>2</mn> </msub>
    <mo>+</mo>
    <msub><mi>x</mi> <mn>3</mn> </msub>
    <mo>=</mo>
    <mn>0</mn>
  </mrow>
</math>
</div>
<div data-type="equation">
<math alttext="minus x 1 minus x 2 plus x 3 equals negative 4" display="block">
  <mrow>
    <mo>-</mo>
    <msub><mi>x</mi> <mn>1</mn> </msub>
    <mo>-</mo>
    <msub><mi>x</mi> <mn>2</mn> </msub>
    <mo>+</mo>
    <msub><mi>x</mi> <mn>3</mn> </msub>
    <mo>=</mo>
    <mo>-</mo>
    <mn>4</mn>
  </mrow>
</math>
</div>
<div data-type="equation">
<math alttext="2 x 1 minus 4 x 2 plus x 3 equals negative 1" display="block">
  <mrow>
    <mn>2</mn>
    <msub><mi>x</mi> <mn>1</mn> </msub>
    <mo>-</mo>
    <mn>4</mn>
    <msub><mi>x</mi> <mn>2</mn> </msub>
    <mo>+</mo>
    <msub><mi>x</mi> <mn>3</mn> </msub>
    <mo>=</mo>
    <mo>-</mo>
    <mn>1</mn>
  </mrow>
</math>
</div>

<p>This sets up the usual matrix equation</p>
<div data-type="equation">
<math alttext="bold upper A bold x equals bold b" display="block">
  <mrow>
    <mi>ùêÄùê±</mi>
    <mo>=</mo>
    <mi>ùêõ</mi>
  </mrow>
</math>
</div>

<p>where</p>
<div data-type="equation">
<math alttext="bold x equals Start 1 By 3 Matrix 1st Row 1st Column x 1 2nd Column x 2 3rd Column x 3 EndMatrix Superscript sans-serif upper T" display="block">
  <mrow>
    <mi>ùê±</mi>
    <mo>=</mo>
    <msup><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>x</mi> <mn>1</mn> </msub></mtd><mtd><msub><mi>x</mi> <mn>2</mn> </msub></mtd><mtd><msub><mi>x</mi> <mn>3</mn> </msub></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi> </msup>
  </mrow>
</math>
</div>

<p>The matrix <math alttext="bold upper A">
  <mi>ùêÄ</mi>
</math> contains the coefficients, and the column vector <math alttext="bold b">
  <mi>ùêõ</mi>
</math> contains the constants on the right-hand side of the equations.  The LU algorithm decomposes the matrix <math alttext="bold upper A">
  <mi>ùêÄ</mi>
</math> into the product of lower- and upper-triangular matrices <math alttext="bold upper L">
  <mi>ùêã</mi>
</math> and <math alttext="bold upper U">
  <mi>ùêî</mi>
</math> in order to solve for <math alttext="bold x">
  <mi>ùê±</mi>
</math>.</p>

<p>In Eigen, form the matrix <math alttext="bold upper A">
  <mi>ùêÄ</mi>
</math> and the vector <math alttext="bold b">
  <mi>ùêõ</mi>
</math>:</p>

<p>_</p>

<pre data-type="programlisting">MatrixXd A		// Row-major
{
	{3.0, -5.0, 1.0},
	{-1.0, -1.0, 1.0},
	{2.0, -4.0, 1.0}
};

VectorXd b
{
	{0.0, -4.0, 1.0}
};</pre>

<p>The next step is to create an instance of the <code>Eigen::FullPivLU</code> class with template parameter <code>MatrixXd</code>.  This sets up the LU decomposition.  To find the vector containing the solution, all that is left to do is call the <code>solve(.)</code> member function on this object.  This means two lines of code, as promised:</p>

<pre data-type="programlisting">Eigen::FullPivLU&lt;MatrixXd&gt; lu(A);
VectorXd x = lu.solve(b);</pre>

<p>The solution for <code>x</code> is then (from top to bottom <math alttext="x 1">
  <msub><mi>x</mi> <mn>1</mn> </msub>
</math>, <math alttext="x 2">
  <msub><mi>x</mi> <mn>2</mn> </msub>
</math>, <math alttext="x 3">
  <msub><mi>x</mi> <mn>3</mn> </msub>
</math>)</p>

<p>_</p>

<pre data-type="programlisting">2.5
1.5
  0</pre>

<p>Several other decomposition methods are available in Eigen for solving linear systems, where as is often the case a choice between speed and accuracy needs to be considered.  The LU decomposition in the example above is among the best for accuracy, although there are others that may be faster but do not offer the same level of stability.  The complete list can be found here:</p>

<p><a href="http://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html">Basic linear solving</a> <strong>{20}</strong></p>

<p>A comparison of the matrix decomposition methods in Eigen is also available:</p>

<p><a href="http://eigen.tuxfamily.org/dox/group__TopicLinearAlgebraDecompositions.html">Catalogue of decompositions offered by Eigen</a> <strong>{21}</strong></p>
</div></section>










<section data-type="sect3" data-pdf-bookmark="Fund Tracking with Multiple Regression and the Singular Value Decomposition"><div class="sect3" id="idm45807806386944">
<h3>Fund Tracking with Multiple Regression and the Singular Value Decomposition</h3>

<p>Another common programming problem in finance is fund tracking with multiple regression.  Examples include</p>

<ul>
<li>
<p>Tracking whether a fund of hedge funds is following its stated allocation targets by regressing its returns on a set of hedge fund style index returns.</p>
</li>
<li>
<p>Tracking the sensitivity of a portfolio to changes in different market sectors.</p>
</li>
<li>
<p>Tracking the goodness of fit of mutual funds offered in guaranteed investment products such as variable annuities, with respect to their respective fund group benchmarks.</p>
</li>
</ul>

<p>In multiple regression, one is tasked with finding a vector</p>
<div data-type="equation">
<math alttext="ModifyingAbove beta With caret equals Start 1 By 4 Matrix 1st Row 1st Column beta 1 2nd Column beta 2 3rd Column  ellipsis 4th Column beta Subscript n EndMatrix Superscript sans-serif upper T Baseline slash slash ModifyingAbove beta With caret equals Start 1 By 4 Matrix 1st Row 1st Column beta 1 2nd Column beta 2 3rd Column  ellipsis 4th Column beta Subscript n EndMatrix Superscript down-tack Baseline slash slash Start 1 By 4 Matrix 1st Row 1st Column beta 1 2nd Column beta 2 3rd Column  ellipsis 4th Column beta Subscript n Baseline EndMatrix slash slash ModifyingAbove beta With caret equals Start 1 By 4 Matrix 1st Row 1st Column beta 1 2nd Column beta 2 3rd Column  ellipsis 4th Column beta Subscript n Baseline EndMatrix slash slash ModifyingAbove beta With caret equals Start 1 By 4 Matrix 1st Row 1st Column beta 1 2nd Column beta 2 3rd Column  ellipsis 4th Column beta Subscript n EndMatrix Superscript sans-serif upper T Baseline slash slash Start 1 By 3 Matrix 1st Row 1st Column w Subscript t Superscript left-parenthesis 1 right-parenthesis Baseline 2nd Column  ellipsis 3rd Column w Subscript t Superscript left-parenthesis m right-parenthesis Baseline EndMatrix slash slash ModifyingAbove beta With caret equals left-bracket beta 1 beta 2 ellipsis beta Subscript n Baseline right-bracket Superscript sans-serif upper T" display="block">
  <mrow>
    <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <msup><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>Œ≤</mi> <mn>1</mn> </msub></mtd><mtd><msub><mi>Œ≤</mi> <mn>2</mn> </msub></mtd><mtd><mo>‚ãØ</mo></mtd><mtd><msub><mi>Œ≤</mi> <mi>n</mi> </msub></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi> </msup>
    <mo>/</mo>
    <mo>/</mo>
    <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <msup><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>Œ≤</mi> <mn>1</mn> </msub></mtd><mtd><msub><mi>Œ≤</mi> <mn>2</mn> </msub></mtd><mtd><mo>‚ãØ</mo></mtd><mtd><msub><mi>Œ≤</mi> <mi>n</mi> </msub></mtd></mtr></mtable></mfenced> <mi>‚ä§</mi> </msup>
    <mo>/</mo>
    <mo>/</mo>
    <mfenced open="[" close="]">
      <mtable>
        <mtr>
          <mtd>
            <msub><mi>Œ≤</mi> <mn>1</mn> </msub>
          </mtd>
          <mtd>
            <msub><mi>Œ≤</mi> <mn>2</mn> </msub>
          </mtd>
          <mtd>
            <mo>‚ãØ</mo>
          </mtd>
          <mtd>
            <msub><mi>Œ≤</mi> <mi>n</mi> </msub>
          </mtd>
        </mtr>
      </mtable>
    </mfenced>
    <mo>/</mo>
    <mo>/</mo>
    <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <mfenced open="[" close="]">
      <mtable>
        <mtr>
          <mtd>
            <mrow>
              <msub><mi>Œ≤</mi> <mn>1</mn> </msub>
              <mspace width="4pt"/>
            </mrow>
          </mtd>
          <mtd>
            <msub><mi>Œ≤</mi> <mn>2</mn> </msub>
          </mtd>
          <mtd>
            <mo>‚ãØ</mo>
          </mtd>
          <mtd>
            <msub><mi>Œ≤</mi> <mi>n</mi> </msub>
          </mtd>
        </mtr>
      </mtable>
    </mfenced>
    <mo>/</mo>
    <mo>/</mo>
    <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <msup><mfenced open="[" close="]"><mtable><mtr><mtd><mrow><msub><mi>Œ≤</mi> <mn>1</mn> </msub><mspace width="4pt"/></mrow></mtd><mtd><msub><mi>Œ≤</mi> <mn>2</mn> </msub></mtd><mtd><mo>‚ãØ</mo></mtd><mtd><msub><mi>Œ≤</mi> <mi>n</mi> </msub></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi> </msup>
    <mo>/</mo>
    <mo>/</mo>
    <mfenced open="[" close="]">
      <mtable>
        <mtr>
          <mtd>
            <msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow> </msubsup>
          </mtd>
          <mtd>
            <mo>‚ãØ</mo>
          </mtd>
          <mtd>
            <msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow> </msubsup>
          </mtd>
        </mtr>
      </mtable>
    </mfenced>
    <mo>/</mo>
    <mo>/</mo>
    <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <msup><mrow><mo>[</mo><msub><mi>Œ≤</mi> <mn>1</mn> </msub><mspace width="0.277778em"/><msub><mi>Œ≤</mi> <mn>2</mn> </msub><mo>‚ãØ</mo><msub><mi>Œ≤</mi> <mi>n</mi> </msub><mo>]</mo></mrow> <mi>ùñ≥</mi> </msup>
  </mrow>
</math>
</div>

<p>that satisfies the matrix form of the normal equations</p>
<div data-type="equation">
<math display="block">
  <mrow>
    <mover>
      <mi>ùõÉ</mi>
      <mo stretchy="false" style="math-style:normal;math-depth:0;">^</mo>
    </mover>
    <mo>=</mo>
    <msup>
      <mrow>
        <mo fence="true" form="prefix">[</mo>
        <mtable columnalign="center">
          <mtr>
            <mtd>
              <mrow>
                <msup>
                  <mi mathvariant="bold">X</mi>
                  <mi>ùñ≥</mi>
                </msup>
                <mi mathvariant="bold">X</mi>
              </mrow>
            </mtd>
          </mtr>
        </mtable>
        <mo fence="true" form="postfix">]</mo>
      </mrow>
      <mrow>
        <mo>‚àí</mo>
        <mn>1</mn>
      </mrow>
    </msup>
    <msup>
      <mi mathvariant="bold">X</mi>
      <mi>ùñ≥</mi>
    </msup>
    <mi mathvariant="bold">Y</mi>
    <mo lspace="0em" rspace="0em">‚ÅÑ</mo>
    <mo lspace="0em" rspace="0em">‚ÅÑ</mo>
    <mover>
      <mi>ùõÉ</mi>
      <mo stretchy="false" style="math-style:normal;math-depth:0;">^</mo>
    </mover>
    <mo>=</mo>
    <mo form="prefix" stretchy="false">[</mo>
    <msup>
      <mi mathvariant="bold">X</mi>
      <mi>ùñ≥</mi>
    </msup>
    <mi mathvariant="bold">X</mi>
    <msup>
      <mo form="postfix" stretchy="false">]</mo>
      <mrow>
        <mo>‚àí</mo>
        <mn>1</mn>
      </mrow>
    </msup>
    <msup>
      <mi mathvariant="bold">X</mi>
      <mi>ùñ≥</mi>
    </msup>
    <mi>ùê≤</mi>
  </mrow>
</math>
</div>

<p>where <math alttext="bold upper X">
  <mi>ùêó</mi>
</math> is the design matrix containing <em>p</em> columns of independent variable data, and <em>n</em> observations (rows), with the number of observations <em>n</em> ‚Äúcomfortably‚Äù greater than the number of data columns <em>p</em> to ensure stability.  This is typically the case in these types of fund tracking applications.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>For fund tracking applications, the intercept term <math alttext="beta 0">
  <msub><mi>Œ≤</mi> <mn>0</mn> </msub>
</math> can usually be dropped, so it is omitted here.  For regression cases where an intercept is required, a final column of ones needs to be appended to the design matrix when using Eigen.
_</p>
</div>

<p>A commonly employed solution is the compact Singular Value Decomposition (SVD), which replaces the matrix <math alttext="bold upper X">
  <mi>ùêó</mi>
</math> with the decomposition <math alttext="bold upper U bold upper Sigma bold upper V Superscript upper T">
  <mrow>
    <mi>ùêî</mi>
    <mi>Œ£</mi>
    <msup><mi>ùêï</mi> <mi>T</mi> </msup>
  </mrow>
</math>, where <math alttext="bold upper U">
  <mi>ùêî</mi>
</math> is an <math alttext="n times p">
  <mrow>
    <mi>n</mi>
    <mo>√ó</mo>
    <mi>p</mi>
  </mrow>
</math> matrix, <math alttext="bold upper V">
  <mi>ùêï</mi>
</math> is <math alttext="p times p">
  <mrow>
    <mi>p</mi>
    <mo>√ó</mo>
    <mi>p</mi>
  </mrow>
</math>, and <math alttext="bold upper Sigma">
  <mi>Œ£</mi>
</math> is a <math alttext="p times p">
  <mrow>
    <mi>p</mi>
    <mo>√ó</mo>
    <mi>p</mi>
  </mrow>
</math>
diagonal matrix of strictly positive values.  Making this substitution in the original formula for <math alttext="ModifyingAbove beta With caret">
  <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover>
</math>, we get</p>
<div data-type="equation">
<math alttext="ModifyingAbove beta With caret equals bold upper V bold upper Sigma bold upper U Superscript sans-serif upper T Baseline bold y" display="block">
  <mrow>
    <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <mi>ùêï</mi>
    <mi>Œ£</mi>
    <msup><mi>ùêî</mi> <mi>ùñ≥</mi> </msup>
    <mi>ùê≤</mi>
  </mrow>
</math>
</div>

<p>Eigen provides two SVD solvers that can be used for obtaining the least squares estimates of the regression
coefficients.  The first of these, as described in the Eigen documentation, is the <a href="https://eigen.tuxfamily.org/dox-devel/classEigen_1_1JacobiSVD.html">Jacobi SVD decomposition of a rectangular matrix_</a> <strong>{22}</strong>.  The documentation also states the Jacobi version is recommended for design matrices of 16 columns or less, which is sometimes sufficient for fund tracking problems.</p>

<p>The way this works is given the design matrix predictor data contained in a <code>MatrixXd X</code>, Eigen sets up the SVD logic inside the class template <code>Eigen::JacobiSVD</code>.  Then, given the response data contained in a <code>VectorXd Y</code>, solving for  <math alttext="ModifyingAbove beta With caret">
  <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover>
</math> is again just two lines of code:</p>

<pre data-type="programlisting">Eigen::JacobiSVD&lt;MatrixXd&gt; svd{ X, Eigen::ComputeThinU | Eigen::ComputeThinV };
VectorXd beta = svd.solve(Y);</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The <code>Eigen::ComputeThinU | Eigen::ComputeThinV</code> bitwise-or parameter instructs the program to use the compact version of SVD.  If the full SVD is desired, then the above <code>JacobiSVD</code> instantiation would be:</p>

<pre data-type="programlisting">Eigen::JacobiSVD&lt;MatrixXd&gt; svd{ X, Eigen::ComputeFullU | Eigen::ComputeFullV };</pre>

<p>In this case, the <math alttext="bold upper U">
  <mi>ùêî</mi>
</math> matrix will be <math alttext="n times n">
  <mrow>
    <mi>n</mi>
    <mo>√ó</mo>
    <mi>n</mi>
  </mrow>
</math>, and <math alttext="bold upper Sigma">
  <mi>Œ£</mi>
</math> will be an <math alttext="n times p">
  <mrow>
    <mi>n</mi>
    <mo>√ó</mo>
    <mi>p</mi>
  </mrow>
</math> pseudoinverse.</p>

<p>There are no default settings.</p>
</div>

<p>As an example, suppose we have three sector ETF‚Äôs and wish to examine their relationship to the broader market (eg the S&amp;P 500), and suppose we have 30 daily observations.</p>

<p>The design matrix will contain the three ETF returns and is stored in a <code>MatrixXd</code> called <code>X</code>, as follows:</p>

<pre data-type="programlisting">MatrixXd X{ 3, 30 };	// 3 sector funds, 30 observations (will transpose)
X	&lt;&lt;
	// Sector fund 1
	-0.044700388, -0.007888394, 0.042980064, 0.016416586, -0.01779658, -0.016714149,
	0.019472031, 0.029853293, 0.023126097, -0.033879088, -0.00338369, -0.018474493,
	-0.012509815, -0.01834808, 0.010626754, 0.036669407, 0.010811115, -0.035571742,
	0.027474007, 0.005406069, -0.010159427, -0.006145632, -0.0103273, -0.010435171,
	0.011127197, -0.023793709, -0.028009362, 0.00218235, 0.008683152, 0.001440032,

	// Sector fund 2
	-0.019002703, 0.026036835, 0.03782709, 0.010629292, -0.008382267, 0.001121697,
	-0.004494407, 0.017304537, -0.006106293, 0.012174645, -0.003305029, 0.027219671,
	-0.036089287, -0.00222959, -0.015748493, -0.02061919, -0.011641386, 0.023148757,
	-0.002290732, 0.006288094, -0.012038397, -0.029258743, 0.011219297, -0.008846992,
	-0.033738048, 0.02061908, -0.012077677, 0.015672887, 0.041012907, 0.052195282,

	// Sector fund 3
	-0.030629136, 0.024918984, -0.001715798, 0.008561614, 0.003406931, -0.010823864,
	-0.010361097, -0.009302434, 0.008142014, -0.004064208, 0.000584335, 0.004640294,
	0.031893332, -0.013544321, -0.023573641, -0.004665085, -0.006446259, -0.005311412,
	0.045096308, -0.007374697, -0.00514201, -0.001715798, -0.005176363, -0.002884991,
	0.002309361, -0.014521608, -0.017711709, 0.001192088, -0.00238233, -0.004395918;

X.transposeInPlace();</pre>

<p>Similarly, the market returns are stored in a <code>VectorXd</code> array <code>Y</code>:</p>

<pre data-type="programlisting">VectorXd Y{ 30 };	// 30 observations of market returns
Y &lt;&lt;
	-0.039891316, 0.00178709, -0.0162018, 0.056452057, 0.00342504, -0.012038314,
	-0.009997657, 0.013452043, 0.013485674, -0.007898137, 0.008111428, -0.015424523,
	-0.002161451, -0.028752191, 0.011292655, -0.007958389, -0.004002386, -0.031690771,
	0.026776892, 0.009803957, 0.000886608, 0.01495181, -0.004155781, -0.001535225,
	0.013517306, -0.021228542, 0.001988701, -0.02051788, 0.005841347, 0.011248933;</pre>

<p>Obtaining the regression coefficients is just a matter of compiling and running the SVD using the two lines of code shown at the outset, which gives us for <code>beta</code>:</p>

<pre data-type="programlisting">  0.352339
-0.0899004
  0.391252</pre>

<p>The <math alttext="bold upper U">
  <mi>ùêî</mi>
</math> and <math alttext="bold upper V">
  <mi>ùêï</mi>
</math> matrices can also be obtained if desired, along with the <math alttext="bold upper Sigma">
  <mi>Œ£</mi>
</math> matrix, using the following accessor functions:</p>

<pre data-type="programlisting">cout &lt;&lt; svd.matrixU() &lt;&lt; endl;			// U: n x p = 30 x 3
cout &lt;&lt; svd.matrixV() &lt;&lt; endl;			// V: p x p = 3 x 3
cout &lt;&lt; svd.singularValues().asDiagonal() &lt;&lt; endl;		// Sigma: p x p = 3 x 3</pre>

<p>An alternative SVD solver, the <a href="https://eigen.tuxfamily.org/dox-devel/classEigen_1_1BDCSVD.html"><em>Bidiagonal Divide and Conquer SVD</em></a>, <strong>{23}</strong> is also available in Eigen.  Per the documentation, it is recommended for design matrices with greater than 16 columns for better performance.</p>

<p>The setup is the same as the Jacobi case, but using the <code>BDCSVD</code> class in place of <code>JacobiSVD</code>:</p>

<pre data-type="programlisting">Eigen::BDCSVD&lt;MatrixXd&gt; svd(X, Eigen::ComputeThinU | Eigen::ComputeThinV);
VectorXd beta = svd.solve(Y);</pre>

<p>It should be noted Eigen also provides QR decompositions as well as the capability of just coding in the normal equations with Eigen matrices and operations.  As noted in the documentation, <a href="https://eigen.tuxfamily.org/dox-devel/group__LeastSquares.html"><em>Solving linear least squares systems</em></a>, these can be faster than SVD methods, but they can be less accurate. <strong>{24}</strong>  These are alternatives you might want to consider if speed is an issue, but under the right conditions.</p>
</div></section>










<section data-type="sect3" data-pdf-bookmark="Correlated Random Equity Paths and the Cholesky Decomposition"><div class="sect3" id="idm45807806306928">
<h3>Correlated Random Equity Paths and the Cholesky Decomposition</h3>

<p>The Cholesky decomposition is a popular tool in finance for generating correlated Monte Carlo equity path simulations.  For example, when pricing basket options, covariances between movements in the basket securities need to be accounted for, specifically in generating correlated random normal draws.  This is in contrast to generating a random price path for a single underlying security, as we saw in Chapter 8:</p>
<div data-type="equation">
<math alttext="upper S Subscript t Baseline equals upper S Subscript t minus 1 Baseline e Superscript left-parenthesis StartFraction r minus sigma squared Over 2 EndFraction right-parenthesis normal upper Delta t plus sigma epsilon Super Subscript t Superscript StartRoot normal upper Delta t EndRoot" display="block">
  <mrow>
    <msub><mi>S</mi> <mi>t</mi> </msub>
    <mo>=</mo>
    <msub><mi>S</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub>
    <msup><mi>e</mi> <mrow><mrow><mo>(</mo><mfrac><mrow><mi>r</mi><mo>-</mo><msup><mi>œÉ</mi> <mn>2</mn> </msup></mrow> <mn>2</mn></mfrac><mo>)</mo></mrow><mi>Œî</mi><mi>t</mi><mo>+</mo><mi>œÉ</mi><msub><mi>Œµ</mi> <mi>t</mi> </msub><msqrt><mrow><mi>Œî</mi><mi>t</mi></mrow></msqrt></mrow> </msup>
  </mrow>
</math>
</div>

<p>where again <math alttext="epsilon Subscript t Baseline tilde upper N left-parenthesis 0 comma 1 right-parenthesis">
  <mrow>
    <msub><mi>Œµ</mi> <mi>t</mi> </msub>
    <mo>‚àº</mo>
    <mi>N</mi>
    <mrow>
      <mo>(</mo>
      <mn>0</mn>
      <mo>,</mo>
      <mn>1</mn>
      <mo>)</mo>
    </mrow>
  </mrow>
</math>, <math alttext="sigma">
  <mi>œÉ</mi>
</math> is the equity volatility, and <math alttext="r">
  <mi>r</mi>
</math> represents the risk-free interest rate,</p>

<p>In the case of a basket option, we now need to generate a path for each of say <em>m</em> assets at each time <math alttext="t">
  <mi>t</mi>
</math>, where the <math alttext="sigma epsilon Subscript t">
  <mrow>
    <mi>œÉ</mi>
    <msub><mi>Œµ</mi> <mi>t</mi> </msub>
  </mrow>
</math> term is replaced by a random term <math alttext="w Subscript t Superscript left-parenthesis i right-parenthesis">
  <msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msubsup>
</math> that is again based on a standard normal draw, but whose fluctuations also contain correlations with the other assets in the basket.  Therefore, we need to generate a set of prices <math alttext="StartSet upper S Subscript t Superscript left-parenthesis i right-parenthesis Baseline EndSet">
  <mfenced separators="" open="{" close="}">
    <msubsup><mi>S</mi> <mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msubsup>
  </mfenced>
</math> where</p>
<div data-type="equation">
<math alttext="upper S Subscript t Superscript left-parenthesis 1 right-parenthesis Baseline equals upper S Subscript t minus 1 Superscript left-parenthesis 1 right-parenthesis Baseline e Superscript left-parenthesis StartFraction r minus sigma squared Over 2 EndFraction right-parenthesis normal upper Delta t plus w Super Subscript t Super Superscript left-parenthesis 1 right-parenthesis Superscript StartRoot normal upper Delta t EndRoot Baseline left-parenthesis asterisk right-parenthesis" display="block">
  <mrow>
    <msubsup><mi>S</mi> <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow> </msubsup>
    <mo>=</mo>
    <msubsup><mi>S</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow> </msubsup>
    <msup><mi>e</mi> <mrow><mrow><mo>(</mo><mfrac><mrow><mi>r</mi><mo>-</mo><msup><mi>œÉ</mi> <mn>2</mn> </msup></mrow> <mn>2</mn></mfrac><mo>)</mo></mrow><mi>Œî</mi><mi>t</mi><mo>+</mo><msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow> </msubsup><msqrt><mrow><mi>Œî</mi><mi>t</mi></mrow></msqrt></mrow> </msup>
    <mrow>
      <mo>(</mo>
      <mo>*</mo>
      <mo>)</mo>
    </mrow>
  </mrow>
</math>
</div>
<div data-type="equation">
<math alttext="period" display="block">
  <mo>.</mo>
</math>
</div>
<div data-type="equation">
<math alttext="period" display="block">
  <mo>.</mo>
</math>
</div>
<div data-type="equation">
<math alttext="period" display="block">
  <mo>.</mo>
</math>
</div>
<div data-type="equation">
<math alttext="upper S Subscript t Superscript left-parenthesis m right-parenthesis Baseline equals upper S Subscript t minus 1 Superscript left-parenthesis m right-parenthesis Baseline e Superscript left-parenthesis StartFraction r minus sigma squared Over 2 EndFraction right-parenthesis normal upper Delta t plus w Super Subscript t Super Superscript left-parenthesis m right-parenthesis Superscript StartRoot normal upper Delta t EndRoot" display="block">
  <mrow>
    <msubsup><mi>S</mi> <mi>t</mi> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow> </msubsup>
    <mo>=</mo>
    <msubsup><mi>S</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow> </msubsup>
    <msup><mi>e</mi> <mrow><mrow><mo>(</mo><mfrac><mrow><mi>r</mi><mo>-</mo><msup><mi>œÉ</mi> <mn>2</mn> </msup></mrow> <mn>2</mn></mfrac><mo>)</mo></mrow><mi>Œî</mi><mi>t</mi><mo>+</mo><msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow> </msubsup><msqrt><mrow><mi>Œî</mi><mi>t</mi></mrow></msqrt></mrow> </msup>
  </mrow>
</math>
</div>

<p>for each asset <math alttext="i equals 1 comma ellipsis comma m">
  <mrow>
    <mi>i</mi>
    <mo>=</mo>
    <mn>1</mn>
    <mo>,</mo>
    <mo>‚ãØ</mo>
    <mo>,</mo>
    <mi>m</mi>
  </mrow>
</math> at each time step <math alttext="t Subscript j Baseline comma j equals 1 comma ellipsis comma n">
  <mrow>
    <msub><mi>t</mi> <mi>j</mi> </msub>
    <mo>,</mo>
    <mi>j</mi>
    <mo>=</mo>
    <mn>1</mn>
    <mo>,</mo>
    <mo>‚ãØ</mo>
    <mo>,</mo>
    <mi>n</mi>
  </mrow>
</math>.  Our task is to calculate the random but correlated vector</p>
<div data-type="equation">
<math alttext="Start 1 By 3 Matrix 1st Row 1st Column w Subscript t Superscript left-parenthesis 1 right-parenthesis 2nd Column  ellipsis 3rd Column w Subscript t Superscript left-parenthesis m right-parenthesis EndMatrix Superscript sans-serif upper T" display="block">
  <msup><mfenced open="[" close="]"><mtable><mtr><mtd><msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow> </msubsup></mtd><mtd><mo>‚ãØ</mo></mtd><mtd><msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow> </msubsup></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi> </msup>
</math>
</div>

<p>for each time <math alttext="t">
  <mi>t</mi>
</math>.  This is where the Cholesky decomposition ‚Äì available in Eigen ‚Äì comes into play.  For an <math alttext="n times n">
  <mrow>
    <mi>n</mi>
    <mo>√ó</mo>
    <mi>n</mi>
  </mrow>
</math> covariance matrix <math alttext="bold upper Sigma">
  <mi>Œ£</mi>
</math>, assuming it is positive definite, will have a Cholesky decomposition</p>
<div data-type="equation">
<math alttext="bold upper Sigma equals upper L upper L Superscript sans-serif upper T" display="block">
  <mrow>
    <mi>Œ£</mi>
    <mo>=</mo>
    <mi>L</mi>
    <msup><mi>L</mi> <mi>ùñ≥</mi> </msup>
  </mrow>
</math>
</div>

<p>where <em>L</em>  is a lower triangular matrix.  Then, for a vector of standard normal variates <math alttext="bold z">
  <mi>ùê≥</mi>
</math>,</p>
<div data-type="equation">
<math alttext="Start 1 By 4 Matrix 1st Row 1st Column z 1 2nd Column z 2 3rd Column  ellipsis 4th Column z Subscript m EndMatrix Superscript sans-serif upper T" display="block">
  <msup><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>z</mi> <mn>1</mn> </msub></mtd><mtd><msub><mi>z</mi> <mn>2</mn> </msub></mtd><mtd><mo>‚ãØ</mo></mtd><mtd><msub><mi>z</mi> <mi>m</mi> </msub></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi> </msup>
</math>
</div>

<p>the <math alttext="n times 1">
  <mrow>
    <mi>n</mi>
    <mo>√ó</mo>
    <mn>1</mn>
  </mrow>
</math> vector generated by <math alttext="bold upper L bold z Superscript sans-serif upper T">
  <mrow>
    <mi>ùêã</mi>
    <msup><mi>ùê≥</mi> <mi>ùñ≥</mi> </msup>
  </mrow>
</math> will provide a set of correlated volatilities that can be used to generate in a single time step a random scenario of prices for each underlying security.  For each time step <math alttext="t">
  <mi>t</mi>
</math>, we replace <math alttext="bold z">
  <mi>ùê≥</mi>
</math> with <math alttext="bold z Subscript bold t">
  <msub><mi>ùê≥</mi> <mi>ùê≠</mi> </msub>
</math> to then arrive at our desired result:</p>
<div data-type="equation">
<math alttext="bold w Subscript bold t Baseline equals bold upper L bold z Subscript t Superscript sans-serif upper T" display="block">
  <mrow>
    <msub><mi>ùê∞</mi> <mi>ùê≠</mi> </msub>
    <mo>=</mo>
    <msubsup><mi>ùêãùê≥</mi> <mi>t</mi> <mi>ùñ≥</mi> </msubsup>
  </mrow>
</math>
</div>

<p>This can then be extended an arbitrary number of n time steps by placing each vector <math alttext="bold z Subscript bold t">
  <msub><mi>ùê≥</mi> <mi>ùê≠</mi> </msub>
</math> into a column of a matrix, say <math alttext="bold upper Z">
  <mi>ùêô</mi>
</math>.  Then, we can generate the entire set of vectors of correlated random variables in one step, and place the results in a matrix</p>
<div data-type="equation">
<math alttext="bold upper W equals bold upper L bold upper Z" display="block">
  <mrow>
    <mi>ùêñ</mi>
    <mo>=</mo>
    <mi>ùêãùêô</mi>
  </mrow>
</math>
</div>

<p>Eigen provides a Cholesky decomposition of a <code>MatrixXd</code> object, using the <code>Eigen::LLT</code> class template with parameter <code>MatrixXd</code>.  It again consists of creating an object of this class, and then calling a member function, <code>matrixL</code>, which returns the matrix <math alttext="bold upper L">
  <mi>ùêã</mi>
</math> above.</p>

<p>As an example, suppose we have four securities in the basket, with the following covariance matrix.</p>

<pre data-type="programlisting">MatrixXd cov_basket
{
    { 0.01263, 0.00025, -0.00017, 0.00503},
    { 0.00025, 0.00138,  0.00280, 0.00027},
    {-0.00017, 0.00280,  0.03775, 0.00480},
    { 0.00503, 0.00027,  0.00480, 0.02900}
};</pre>

<p>The Cholesky decomposition is set up when the matrix data is used to construct the <code>Eigen::LLT</code> object.  Calling the member function <code>matrixL()</code> computes the decomposition and returns the resulting lower triangle matrix:</p>

<pre data-type="programlisting">Eigen::LLT&lt;Eigen::MatrixXd&gt; chol{ cov_basket };
MatrixXd chol_mtx = chol.matrixL();</pre>

<p>This gives us</p>

<pre data-type="programlisting">    0.1124          0          0          0
  0.002226  0.0370332          0          0
-0.0015544  0.0756179   0.178975          0
 0.0447889 0.00464393  0.0252348   0.162289</pre>

<p>Suppose now there will be six time steps in the Monte Carlo model over a period of one year.  This means we will need six vectors containing four standard normal variates each.  For this, we can use the Standard Library <code>&lt;random&gt;</code> functions and generate a 4 <math alttext="times">
  <mo>√ó</mo>
</math> 6 matrix, and place the random vectors in consecutive columns.</p>

<p>First, create a <code>MatrixXd</code> object with four rows and six columns:</p>

<pre data-type="programlisting">MatrixXd corr_norms{ 4, 6 };</pre>

<p>The first step will be to populate this matrix with uncorrelated standard normal draws.  As we did previously (in Chapter 8), we can set up a random engine and distribution, and capture these in a lambda to generate the standard normal variates:</p>

<pre data-type="programlisting">std::mt19937_64 mt_norm{ 100 };		// Seed is arbitrary, just set to 100 again
std::normal_distribution&lt;&gt; std_nd;

auto std_norm = [&amp;mt_norm, &amp;std_nd](double x)
{
    return std_nd(mt_norm);
};</pre>

<p>Because each column in a <code>MatrixXd</code> can be accessed as a <code>VectorXd</code>, we can again iterate columnwise through the matrix and apply the <code>std::ranges::transform</code> algorithm to each in a range-based <code>for</code> loop.</p>

<pre data-type="programlisting">for (auto col : corr_norms.colwise())
{
    std::ranges::transform(col,
        col.begin(), std_norm);
}</pre>

<p>This interim result would resemble the following, with actual results depending on the compiler (in this case using the Microsoft Visual Studio 2022 compiler):</p>

<pre data-type="programlisting">   0.201395    0.197482     1.22857     1.40751     1.82789   -0.150014
 -0.0769593   0.0830647     1.86252    0.122389   -0.949222    0.667817
   0.936051     1.16233   -0.642932    0.538005    -1.82688   -0.451039
-0.00916217    -2.79186   -0.434655  -0.0553752     1.46312    0.345527</pre>

<p>Then, to get the <em>correlated</em> normal values, multiply the above result by the Cholesky matrix, and reassign <code>corr_norms</code> to the result.</p>

<pre data-type="programlisting">MatrixXd corr_norms = chol_mtx * corr_norms;</pre>

<p>This result, which corresponds to the matrix <math alttext="bold upper W">
  <mi>ùêñ</mi>
</math> in the mathematical derivation, comes out to be:</p>

<pre data-type="programlisting">  0.0226368   0.0221969    0.138091    0.158204    0.205455  -0.0168616
-0.00240174  0.00351574   0.0717097  0.00766557  -0.0310838   0.0243974
   0.161397    0.214002   0.0238613    0.103356   -0.401585  -0.0299926
  0.0307971   -0.414526  -0.0230881   0.0681989    0.268808   0.0410757</pre>

<p>Each successive column in <code>corr_norms</code> will provide a set of four correlated random variates that can be substituted in for <math alttext="w Subscript t Superscript left-parenthesis 1 right-parenthesis Baseline ellipsis w Subscript t Superscript left-parenthesis 4 right-parenthesis">
  <mrow>
    <msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow> </msubsup>
    <mo>‚ãØ</mo>
    <msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mn>4</mn><mo>)</mo></mrow> </msubsup>
  </mrow>
</math>  at each time <math alttext="t equals 1 comma ellipsis comma 6">
  <mrow>
    <mi>t</mi>
    <mo>=</mo>
    <mn>1</mn>
    <mo>,</mo>
    <mo>‚ãØ</mo>
    <mo>,</mo>
    <mn>6</mn>
  </mrow>
</math> in (*) above.  First, we will need the spot prices of the four underlying equities, which can be stored in an Eigen <code>VectorXd</code> (pretend they are retrieved from a live market feed).  For example:</p>

<pre data-type="programlisting">VectorXd spots(4);          // Init spot prices from market
spots &lt;&lt; 100.0, 150.0, 25.0, 50.0;</pre>

<p>Next, we will need a matrix in which to store a random price path for each equity, starting with each spot price, to be stored in an additional first column, making it a 4 <math alttext="times">
  <mo>√ó</mo>
</math> 7 matrix.</p>

<pre data-type="programlisting">MatrixXd integ_scens{ corr_norms.rows(), corr_norms.cols() + 1 }	// 4 x 7 matrix
integ_scens.col(0) = spots;</pre>

<p>Suppose then, the time to maturity is one year, divided into six equal time steps.  From this, we can get the <math alttext="normal upper Delta t">
  <mrow>
    <mi>Œî</mi>
    <mi>t</mi>
  </mrow>
</math> value, say <code>dt</code>.</p>

<pre data-type="programlisting">double time_to_maturity = 1.0;
unsigned num_time_steps = 6;
double dt = time_to_maturity / num_time_steps;</pre>

<p>Each successive price for a given underlying equity, as shown in (*), can be computed in a lambda, where <code>price</code> is the previous price in the scenario, and <code>vol</code> is the volatility of the particular equity.</p>

<pre data-type="programlisting">auto gen_price = [dt, rf_rate](double price, double vol, double corr_norm) -&gt; double
{
    double expArg1 = (rf_rate - ((vol * vol) / 2.0)) * dt;
    double expArg2 = corr_norm * std::sqrt(dt);
    double next_price = price * std::exp(expArg1 + expArg2);
    return next_price;
};</pre>

<p>Finally, for each underlying equity at each time step, we can set up an iteration and call the lambda at each step:</p>

<pre data-type="programlisting">for (unsigned j = 1; j &lt; integ_scens.cols(); ++j)
{
    for (unsigned i = 0; i &lt; integ_scens.rows(); ++i)
    {
        integ_scens(i, j) = gen_price(integ_scens(i, j - 1), vols(i), corr_norms(i, j - 1));
    }
}</pre>

<p>For this example, the results are</p>

<pre data-type="programlisting">100		100.99		101.972		107.952		115.226		125.384		124.6
150		150.086 	150.535 	155.248 	155.976 	154.248 	156.034
25 		26.6633 	29.0545 	29.2955 	30.5129 	25.8607 	25.5082
50 		50.5946 	42.6858 	42.2536  	43.414 		48.4132 	49.1949</pre>

<p>Again, results may vary due to differences in the implementation of <code>&lt;random&gt;</code> between different Standard Library releases among vendors.</p>
</div></section>










<section data-type="sect3" data-pdf-bookmark="Yield Curve Dynamics and Principal Components Analysis"><div class="sect3" id="idm45807805358976">
<h3>Yield Curve Dynamics and Principal Components Analysis</h3>

<p>Principal Components Analysis (PCA) is a go-to tool for determining the sources and magnitudes of variation that drive changes in the shape of a yield curve.  Given a covariance matrix of daily changes in yields spanning a range of bond maturities, PCA is employed by first calculating the eigenvalues of this matrix, and ordering them from highest to lowest.  Then, the weightings are calculated by dividing each eigenvalue by the some of all the eigenvalues.</p>

<p>Empirical research has shown the contribution of first three eigenvalues will comprise nearly the entirety of the weightings, where the first weighting corresponds to parallel shifts in the yield curve, the second corresponds to variations in its ‚Äútilt‚Äù or ‚Äúslope‚Äù, and the third to the curvature.  The reasons and details behind this can be found in Chapter 18 of the very fine computational finance book by <a href="https://link.springer.com/book/10.1007/978-1-4939-2614-5">Ruppert and Matteson</a> <strong>{25}</strong>, and in Chapter 3 of the classic text on interest rate derivatives by Rebonato <strong>{26}</strong>.</p>

<p>Rigorous statistical tests exist for measuring significance, but the weights alone can provide a  relative estimated measure of each source of variation.</p>

<p>Section 18.2 of the text by Ruppert and Matteson {op cit 25} provides an excellent example on how to apply principal components analysis to publicly available US Treasury yield data {put URL here}.  The resulting covariance matrix‚Äâ‚Äî‚Äâinput as constructor data for the following <code>MatrixXd</code> object, is based on fluctuations in differenced <a href="https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&amp;field_tdr_date_value_month=202212">US Treasury yields</a> <strong>{28}</strong> for eleven different maturities, ranging from one month to 30 years.  The underlying data is taken from the period from January 1990 to October 2008.</p>

<p>To calculate the eigenvalues, first load the covariance matrix data into the upper triangular region of a <code>MatrixXd</code> instance.</p>

<pre data-type="programlisting">	MatrixXd term_struct_cov_mtx
	{
		// 1 month
		{ 0.018920,	0.009889, 0.005820,	0.005103, 0.003813,	0.003626,
			0.003136, 0.002646, 0.002015, 0.001438, 0.001303 },

		// 3 months
		{ 0.0, 0.010107, 0.006123, 0.004796, 0.003532, 0.003414,
			0.002893, 0.002404, 0.001815, 0.001217, 0.001109},

		// 6 months
		{ 0.0, 0.0, 0.005665, 0.004677, 0.003808, 0.003790,
			0.003255, 0.002771, 0.002179, 0.001567, 0.001400 },

		// 1 year
			{ 0.0, 0.0, 0.0, 0.004830, 0.004695, 0.004672,
				0.004126, 0.003606, 0.002952, 0.002238, 0.002007},

		// 2 years
		{ 0.0, 0.0, 0.0, 0.0, 0.006431, 0.006338,
			0.005789, 0.005162, 0.004337, 0.003343, 0.003004},

		// 3 years
		{ 0.0, 0.0, 0.0, 0.0, 0.0, 0.006524,
			0.005947, 0.005356, 0.004540, 0.003568, 0.003231 },

		// 5 years
		{ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
			0.005800, 0.005291, 0.004552, 0.003669, 0.003352 },

		// 7 years
		{ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
			0.0, 0.004985, 0.004346, 0.003572, 0.003288 },

		// 10 years
		{ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
			0.0, 0.0, 0.003958, 0.003319, 0.003085 },

		// 20 years
		{ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
			0.0, 0.0, 0.0, 0.003062, 0.002858 },

		// 30 years
		{ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
			0.0, 0.0, 0.0, 0.0, 0.002814 }
	};</pre>

<p>As a real symmetric matrix is trivially self-adjoint (no complex components), Eigen can apply a function <code>selfadjointView&lt;.&gt;()</code> to an upper (or lower) triangular matrix to define a view of a symmetric covariance matrix.  The eigenvalues (all real) can then be obtained by applying the <code>eigenvalues()</code> function on the symmetric result:</p>

<pre data-type="programlisting">VectorXd eigenvals = term_struct_cov_mtx.selfadjointView&lt;Eigen::Upper&gt;().eigenvalues();</pre>

<p>In order to determine the weight of each principal component, we need to divide each eigenvalue by the sum of all the eigenvalues:</p>

<pre data-type="programlisting">double total_ev = std::accumulate(eigenvals.cbegin(), eigenvals.cend(), 0.0);
std::ranges::transform(eigenvals, eigenvals.begin(),
	[total_ev](double x) {return x / total_ev; });</pre>

<p>And finally, to view the results in order of the principal components, the weighted values need to be arranged from largest to smallest:</p>

<pre data-type="programlisting">std::ranges::sort(eigenvals, std::greater{});</pre>

<p>Examining the contents of <code>eigenvals</code>, we would find the following results:</p>

<pre data-type="programlisting">0.67245 0.213209 0.073749
0.023811 0.00962511 0.00275773
0.0016744 0.00114298 0.000740139
0.000528862 0.000311391</pre>

<p>From this, we can see the effects of parallel shifts and the ‚Äútilt‚Äù of the yield curve are the dominant effects, with relative weights of 67.2% and and 21.3%, while the curvature effect is smaller at 7.4%.</p>
</div></section>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Future Directions:  Linear Algebra in the Standard Library"><div class="sect1" id="idm45807805340304">
<h1>Future Directions:  Linear Algebra in the Standard Library</h1>

<p>Three proposals related to linear algebra have been submitted to the ISO C++ committee.</p>

<ul>
<li>
<p><code>std::mdspan</code>:  <a href="https://wg21.link/p0009">A polymorphic multidimensional array reference (P0009)</a> <strong>{28}</strong></p>
</li>
<li>
<p><a href="https://wg21.link/p1673">A free function linear algebra interface based on the BLAS (P1673)</a> <strong>{29}</strong></p>
</li>
<li>
<p><a href="https://wg21.link/p1385">Add linear algebra support to the C++ standard library (P1385)</a> <strong>{30}</strong></p>
</li>
</ul>

<p><code>mdspan</code> (P0009) can impose a multidimensional array structure on a reference to a container, such as an STL <code>vector</code>.  Using the example of a <code>vector</code> containing the data, and a referring <code>mdspan</code> representing a matrix, the number of rows and columns are set at construction of the <code>mdspan</code>.  An <code>mdspan</code> can also take the form of higher dimensional arrays, but for our purposes we will concern ourselves with the two-dimensional case for matrix representations.  <code>mdspan</code> is officially slated for release in C++23.</p>

<p>The second proposal (P1673) is for a standard interface to external linear algebra ‚Äúbased on the dense Basic Linear Algebra Subroutines (BLAS)‚Äù, corresponding ‚Äúto a subset of the BLAS Standard.‚Äù  {op cit 29}.  In other words, code could be written independently of whichever external linear algebra library is used, making code maintenance much easier and less error-prone.  As noted in the proposal, the ‚Äúinterface is designed in the spirit of the C++ Standard Library‚Äôs algorithms‚Äù, and ‚Äúuses mdspan‚Ä¶‚Äã, to represent matrices and vectors‚Äù {ibid}.  Furthermore, the ‚Äúinterface is designed in the spirit of the C++ Standard Library‚Äôs algorithms"{ibid}.  It is currently planned for C++26.</p>

<p>The third proposal (P1385) is to provide actual BLAS-type functionality within the Standard Library.  Its primary goal is to ‚Äúprovide a (sic) matrix vocabulary types for representing the mathematical objects and fundamental operations relevant to linear algebra‚Äù (op cit {30}).  This proposal is also currently planned for release with C++26.</p>








<section data-type="sect2" data-pdf-bookmark="mdspan (P0009)"><div class="sect2" id="idm45807805327504">
<h2>mdspan (P0009)</h2>

<p>As mentioned above, for representing a matrix, <code>mdspan</code> establishes a reference to a contiguous container and then imposes the number of rows and columns.  If these parameters are known at compile time, creating an <code>mdspan</code> is easy:</p>

<pre data-type="programlisting">vector&lt;int&gt; v{ 101, 102, 103, 104, 105, 106 };
auto mds1 = std::mdspan{ v.data(), 3, 2 };</pre>

<p>Note that <code>mdspan</code> uses the <code>data()</code> member function on <code>vector</code> to access its contents.</p>

<p>In <code>mdspan</code> parlance, rows and columns are referred to as <em>extents</em>, with the number of rows and columns accessed by the index of each, 0 for rows and 1 for columns.  The total number of extents is referred to as the <em>rank</em>, so in this case, the rank is 2.  For higher-order multidimensional arrays, the rank would be greater than two.</p>

<pre data-type="programlisting">size_t n_rows{ mds1.extent(0) };		// 3
size_t n_cols{ mds1.extent(1) };		// 2
size_t n_extents{ mds1.rank() };		// 2</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The term <em>rank</em> as applied to <code>mdspan</code> is not the same as the mathematical definition of the rank of a matrix.  This naming might unfortunately seem confusing, but it‚Äôs something one should be aware of.</p>
</div>

<p>Elements of the <code>mdspan</code> object will be accessible with another new feature in C++23, namely the square bracket operator with multiple indices:</p>

<pre data-type="programlisting">for (size_t i = 0; i &lt; mds1.extent(0); ++i)
{
	for (size_t j = 0; j &lt; mds1.extent(1); ++j)
		cout &lt;&lt; mds1[i, j] &lt;&lt; "\t";

	cout &lt;&lt; "\n";
}</pre>

<p>This is a welcome improvement, as it will no longer be necessary to put each index in a separate bracket pair, as was the case with C-style arrays:</p>

<pre data-type="programlisting">double ** a[3][2];		// Ugh

// Could put a[2, 1] if it were an mdspan instead:
a[2][1] = 5.4;

...

delete [] a;</pre>

<p>The run-time result of the previous nested loop displays a 3 <math alttext="times">
  <mo>√ó</mo>
</math> 2 matrix:</p>

<pre data-type="programlisting">101     102
103     104
105     106</pre>

<p>It is also possible to define a matrix with different dimensions to the same data:</p>

<pre data-type="programlisting">auto mds2 = std::mdspan(v.data(), 2, 3);		// 2 x 3</pre>

<p>Applying the same loop above, but replacing <code>mds1</code> with <code>mds2</code> would then display as expected:</p>

<pre data-type="programlisting">101     102     103
104     105     106</pre>

<p>One thing to be careful of is modifying data in the <code>mdspan</code> object or in the original <code>vector</code> will change it in both locations due to the referential relationship between the two.  For example, modification of the last element of the vector</p>

<pre data-type="programlisting">v[5] = 874;</pre>

<p>will show up in both of the <code>mdspan</code> objects.  <code>mds1</code> becomes</p>

<pre data-type="programlisting">101     102
103     104
105     874</pre>

<p>and <code>mds2</code> is now</p>

<pre data-type="programlisting">101     102     103
104     105     874</pre>

<p>Likewise, changing the value of an element in <code>mds2</code> will be reflected in both <code>mds1</code> and the vector <code>v</code>.</p>

<p>In quant finance applications, it will often be the case where the fixed number of rows and columns are not known at compile time.  Suppose <code>m</code> and <code>n</code> are the numbers of rows and columns to be determined at runtime.  These dimensions can be set dynamically by replacing the fixed settings of 2 and 3 in the previous example</p>

<pre data-type="programlisting">auto mds2 = std::mdspan(v.data(), 2, 3);</pre>

<p>with the <code>std::extents{m, n}</code> object, as shown in the <code>mdspan</code> definition here:</p>

<pre data-type="programlisting">void dynamic_mdspan(size_t m, size_t n, vector&lt;double&gt; vec)
{

	std::mdspan md{ vec.data(), std::extents{m, n} };

	. . .

}</pre>

<p>The <code>std::extents{m, n}</code> parameter represents the number of elements in each extent‚Äâ‚Äî‚Äâie in each row (<code>m</code>) and column (<code>n</code>)‚Äâ‚Äî‚Äâwhich are determined dynamically at runtime.</p>

<p>Pretend we have the following data set at runtime:</p>

<pre data-type="programlisting">vector&lt;double&gt; w{ 10.1, 10.2, 10.3, 10.4, 10.5, 10.6 };
size_t m{3};
size_t n{2};</pre>

<p>Using these as inputs to the <code>dynamic_mdspan(.)</code> function above will then generate a 3 <math alttext="times">
  <mo>√ó</mo>
</math> 2 <code>mdspan</code> matrix:</p>

<pre data-type="programlisting">10.1    10.2
10.3    10.4
10.5    10.6</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The above examples make use of <em>Class Template Auto Deduction</em>, commonly referred to as <em>CTAD</em>.  Both <code>mdspan</code> and <code>extents</code> are class templates, but because <code>w</code> in the example just above is a <code>vector</code> of <code>double</code> types, and the size of the <code>vector</code> being of type <code>size_t</code>, when substituted in for <code>vec</code> in the <code>dynamic_mdspan</code> function,  the compiler will deduce that the <code>mdspan</code> and <code>extents</code> objects are to use <code>double</code> and <code>size_t</code> as template parameters.</p>

<p>Without CTAD, the function would be written something like:</p>

<pre data-type="programlisting">template&lt;typename T, typename S&gt;
void dynamic_mdspan(S m, S n, T vec)
{
	using ext_t = std::extents&lt;S, std::dynamic_extent, std::dynamic_extent&gt;;
	std::mdspan&lt;T, ext_t&gt; mds_dyn{ vec.data(), m, n };

	. . .

}</pre>

<p>The discussion in this chapter will rely on CTAD, but in cases where more generality is required, it will be necessary to to write out the template arguments in full.</p>
</div>

<p>One more thing to note is in each of the examples so far, <code>mdspan</code> will arrange the data in row-major order by default.  Arranging it in column-major order requires defining a <code>layout_left</code> policy <em>mapping</em>, in this case called <code>col_major</code>, as shown here:</p>

<pre data-type="programlisting">std::layout_left::mapping col_major{ std::extents{ m, n } };</pre>

<p>The corresponding column-major matrix can then be defined by substituting this mapping in the extents argument in the <code>mdspan</code> constructor.</p>

<pre data-type="programlisting">std::mdspan md{ v.data(), col_major };</pre>

<p>The result is the column-major version of the matrix:</p>

<pre data-type="programlisting">10.1    10.4
10.2    10.5
10.3    10.6</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Row-major order can also be set explicitly with the <code>std::layout_right</code> mapping.</p>
</div>

<p>The <code>mdspan</code> proposal also includes a ‚Äúslicing‚Äù function called <code>submdspan(.)</code> to return a reference to an individual row or column from a matrix represented by an mdspan.  More generally, this would extend to subsets of higher-dimensional arrays.</p>

<p>Returning to the row-major integer 3 <math alttext="times">
  <mo>√ó</mo>
</math> 2 <code>mds1</code> example, if we wanted to extract a reference to the first row (index 0), it could be obtained as follows, with the index in the first extent (row) argument of <code>submdspan</code>:</p>

<pre data-type="programlisting">auto row_1 = std::submdspan(mds1, 0, std::full_extent)</pre>

<p>This would give us:</p>

<pre data-type="programlisting">row_1[0] = 101  row_1[1] = 102</pre>

<p>Rows 2 and 3 could also be referenced by replacing the <code>0</code> with <code>1</code> and <code>2</code>, respectively.</p>

<p>By explicitly setting the second (column) extent argument to the column size less 1, we could also access the last column:</p>

<pre data-type="programlisting">auto col_last = std::submdspan(mds1, std::full_extent, mds1.extent(1)-1);</pre>

<p>This would then be comprised of:</p>

<pre data-type="programlisting">col_2[0] = 102  col_2[1] = 104  col_2[2] = 106</pre>

<p>As <code>submdspan</code> is a reference (view) to an <code>mdspan</code> containing a row or column, it will obviate generating an additional <code>mdspan</code>, in contrast to the issue with a <code>slice_array</code> taken from a <code>valarray</code>.  Any public member function on <code>mdspan</code> can be applied to a <code>submdspan</code>.  On the downside, this would not include the vectorized mathematical operators or functions that are provided with <code>valarray</code>, although a different approach to the operators will be provided in <code>P1673</code>, to be discussed in the next section.</p>

<p>On the flip side, also because it is a reference, modifying an element of a <code>submdspan</code> will also modify the underlying <code>mdspan</code> object.  Suppose the last element in <code>col_last</code> is reset:</p>

<pre data-type="programlisting">col_2[2] = 3333;</pre>

<p>The original <code>mds1</code> would then become:</p>

<pre data-type="programlisting">101     102
103     104
105     3333</pre>

<p>One final remark is a proposal for a multi-dimensional array (P1684), called <code>mdarray</code>, is also in review.  As noted in the <a href="https://wg21.link/p1684">proposal</a> <strong>{31}</strong>, "<code>mdarray</code> is as similar as possible to mdspan, except with container semantics instead of reference semantics‚Äù.  In other words, an <code>mdarray</code> object ‚Äúowns‚Äù its data‚Äâ‚Äî‚Äâsimilar to a <code>vector</code>‚Äâ‚Äî‚Äâas opposed to existing as a reference to data ‚Äúowned‚Äù by another container as in the case of <code>mdspan</code>.  The earliest it would be released is also C++26.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The code examples for <code>mdspan</code> above can be compiled in C++20 using the working code currently available on the <a href="https://github.com/kokkos/mdspan/blob/stable/include/experimental/__p0009_bits/mdspan.hpp">P1673 GitHub site</a> <strong>{31}</strong>.  Installation and building instructions are included with the repository, but two particular items to know are first, the code is currently under the namespace <code>std::experimental</code>, and second, as the square bracket operator for multiple indices is set for C++23, you can replace it with the round bracket operator for C++20 and earlier; viz,</p>

<p>_</p>

<pre data-type="programlisting">namespace stdex = std::experimental;
auto mds1 = stdex::mdspan{ v.data(), 3, 2 };

// Replace the square brackets here:
for (size_t i = 0; i &lt; n_rows; ++i)
{
	for (size_t j = 0; j &lt; n_cols; ++j)
		cout &lt;&lt; mds1[i, j]			&lt;&lt; "\t";
}

// with round brackets:
for (size_t i = 0; i &lt; n_rows; ++i)
{
	for (size_t j = 0; j &lt; n_cols; ++j)
		cout &lt;&lt; mds1(i, j) &lt;&lt; "\t";
}</pre>
</div>
</div></section>








<section data-type="sect2" data-pdf-bookmark="BLAS Interface (P1673)"><div class="sect2" id="idm45807805243936">
<h2>BLAS Interface (P1673)</h2>

<p>This proposal is for ‚Äúa C++ Standard Library dense linear algebra interface based on the dense Basic Linear Algebra Subroutines (BLAS)‚Äù {op cit 29}, also simply referred to as ‚ÄústdBLAS‚Äù.  BLAS libraries date back a number of decades and were originally written in Fortran, but it evolved into a standard in the early 2000‚Äôs, with implementations in other languages such as C (OpenBLAS) and CUDA C++ (NVIDIA) now available, as well as C bindings to Fortran.</p>

<p>Fortran BLAS distributions support four numerical types :  <code>FLOAT</code>, <code>DOUBLE</code>, <code>COMPLEX</code>, and <code>DOUBLE COMPLEX</code>.  The C++ equivalents are <code>float</code>, <code>double</code>, <code>std::complex&lt;float&gt;</code>, and <code>std::complex&lt;double&gt;</code>.  BLAS libraries contain several matrix formats (standard, symmetric, upper/lower triangular), matrix and vector operations such as element-by-element addition and matrix/vector multiplication.</p>

<p>With implementation of this proposal, it would be possible to apply the same C++ code base to any compatible library containing BLAS functionality, provided an interface has been made available, presumably by the library vendor.  This will allow for portable code, independent of the underlying library being used.  It remains to be seen at this stage which vendors will eventually come on board, but one major development is NVIDIA‚Äôs implementation both of <code>mdspan</code> and stdBLAS, now available in their <a href="https://developer.nvidia.com/hpc-sdk">HPC SDK</a> <strong>{33}</strong>.</p>

<p>It should be noted stdBLAS itself would only provide access to a particular subset of matrix operations‚Äâ‚Äî‚Äâto be discussed next‚Äâ‚Äî‚Äâeven if the underlying library provides additional features such as matrix decompositions, linear and least squares solvers, etc.</p>

<p>BLAS functions are preceded by the type contained in the matrix and/or vector to which they are applied.  For example, the function for multiplication of a matrix by a vector is of the form</p>

<pre data-type="programlisting">xGEMV(.)</pre>

<p>where the <code>x</code> can be <code>S</code>, <code>D</code>, <code>C</code>, or <code>Z</code>, meaning single precision (<code>REAL</code> in Fortran), double precision (<code>DOUBLE</code>), complex (<code>COMPLEX</code>), and double precision complex (<code>DOUBLE COMPLEX</code>) respectively.</p>

<p>The C++ equivalent in the proposal, <code>matrix_vector_product</code> would instead take in <code>mdspan</code> objects representing a matrix and a vector.  For example, we can look at a case involving <code>double</code> values, using <code>m</code> and <code>n</code> for the number of rows and columns as before.</p>

<pre data-type="programlisting">std::vector&lt;double&gt; A_vec(m * n);
std::vector&lt;double&gt; x_vec(n);

// A_vec and x_vec are then populated with data...

std::vector&lt;double&gt; y_vec(n);		// empty vector

std::mdspan A{ A_vec.data(), std::extents{m, n} };
std::mdspan x{ x_vec.data(), std::extents{n} };
std::mdspan y{ y_vec.data(), std::extents{m} };</pre>

<p>Then, performing the multiplication, the vector product is stored in <code>y</code>:</p>

<pre data-type="programlisting">std::linalg::matrix_vector_product(A, x, y); 	// y = A * x</pre>

<p>The following table provides a subset of BLAS functions proposed in P1673 that should be useful in financial programming.  The BLAS functions are assumed to be double precision, and any given matrix/vector expressions can be assumed to be of appropriate dimensions.</p>
<table>
<caption><span class="label">Table 5-1. </span>Selected BLAS Functions in Proposal P1673</caption>
<thead>
<tr>
<th>BLAS Function</th>
<th>P1673 Function</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>DSCAL</p></td>
<td><p><code>scale</code></p></td>
<td><p>Scalar multiplication of a vector</p></td>
</tr>
<tr>
<td><p>DCOPY</p></td>
<td><p><code>copy</code></p></td>
<td><p>Copy a vector into another</p></td>
</tr>
<tr>
<td><p>DAXPY</p></td>
<td><p><code>add</code></p></td>
<td><p>Calculates <math alttext="alpha bold x plus bold y">
  <mrow>
    <mi>Œ±</mi>
    <mi>ùê±</mi>
    <mo>+</mo>
    <mi>ùê≤</mi>
  </mrow>
</math>, vectors <math alttext="bold x">
  <mi>ùê±</mi>
</math> &amp; <math alttext="bold y">
  <mi>ùê≤</mi>
</math>, scalar <math alttext="alpha">
  <mi>Œ±</mi>
</math></p></td>
</tr>
<tr>
<td><p>DDOT</p></td>
<td><p><code>dot</code></p></td>
<td><p>Dot product of two vectors</p></td>
</tr>
<tr>
<td><p>DNRM2</p></td>
<td><p><code>vector_norm2</code></p></td>
<td><p>Euclidean norm of a vector</p></td>
</tr>
<tr>
<td><p>DGEMV</p></td>
<td><p><code>matrix_vector_product</code></p></td>
<td><p>Calculates <math alttext="alpha bold upper A bold x plus beta bold y">
  <mrow>
    <mi>Œ±</mi>
    <mi>ùêÄùê±</mi>
    <mo>+</mo>
    <mi>Œ≤</mi>
    <mi>ùê≤</mi>
  </mrow>
</math>, matrix <math alttext="bold upper A">
  <mi>ùêÄ</mi>
</math>, vector <math alttext="bold y">
  <mi>ùê≤</mi>
</math>, scalars <math alttext="alpha">
  <mi>Œ±</mi>
</math> &amp; <math alttext="beta">
  <mi>Œ≤</mi>
</math></p></td>
</tr>
<tr>
<td><p>DSYMV</p></td>
<td><p><code>symmetric_matrix_vector_product</code></p></td>
<td><p>Same as DGEMV (<code>matrix_vector_product</code>) but where <math alttext="bold upper A">
  <mi>ùêÄ</mi>
</math> is symmetric</p></td>
</tr>
<tr>
<td><p>DGEMM</p></td>
<td><p><code>matrix_product</code></p></td>
<td><p>Calculates <math alttext="alpha bold upper A bold upper B plus beta bold upper C">
  <mrow>
    <mi>Œ±</mi>
    <mi>ùêÄùêÅ</mi>
    <mo>+</mo>
    <mi>Œ≤</mi>
    <mi>ùêÇ</mi>
  </mrow>
</math>, for matrices <math alttext="bold upper A">
  <mi>ùêÄ</mi>
</math>, <math alttext="bold upper B">
  <mi>ùêÅ</mi>
</math>, &amp; <math alttext="bold upper C">
  <mi>ùêÇ</mi>
</math>, and scalars <math alttext="alpha">
  <mi>Œ±</mi>
</math> &amp; <math alttext="beta">
  <mi>Œ≤</mi>
</math></p></td>
</tr>
</tbody>
</table>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Linear Algebra (P1385)"><div class="sect2" id="idm45807805188576">
<h2>Linear Algebra (P1385)</h2>

<p>The authors of this proposal specifically recognized the importance of linear algebra in financial modeling, along with other applications such as medical imaging, machine learning, and high performance computing. {op cit 28}.</p>

<p>Initial technical requirements for a linear algebra library in C++ were outlined in a <a href="https://wg21.link/p1166">preceding proposal (P1166)</a> <strong>{34}</strong>, directly quoted here (in italics):</p>

<p><em>The set of types and functions should be the minimal set required to perform functions in
finite dimensional spaces. This includes</em>:</p>

<ul>
<li>
<p><em>A matrix template</em></p>
</li>
<li>
<p><em>Binary operations for addition, subtraction and multiplication of matrices</em></p>
</li>
<li>
<p><em>Binary operations for scalar multiplication and division of matrices</em></p>
</li>
</ul>

<p>Building on this, the P1385 proposal states two primary goals, namely that the library should be easy to use, with ‚Äúrun-time computational performance that is close to what {users} could obtain with an equivalent sequence of function calls to a more ‚Äútraditional‚Äù linear algebra library, such as LAPACK, Blaze, Eigen, etc.‚Äù {op cit 30}</p>

<p>At a high level, a matrix is generically represented by a <em>MathObj</em> type, and an <em>engine</em>  ‚Äúis an implementation type that manages the resources associated with a <em>MathObj</em> instance.‚Äù  Discussions are ongoing over the details, but ‚Äúa <em>MathObj</em> might own the memory in which it stores its elements, or it might employ some non-owning view type, like <code>mdspan</code>, to manipulate elements owned by some other object‚Äù. {ibid}.  An <em>engine</em> object is proposed to be a private member on a <em>MathObj</em>, and a <em>MathObj</em> may have either fixed or dynamic dimensions.</p>

<p>More details should emerge over the next few years on the form the P1385 linear albegra library will assume, but for now, this hopefully provides an initial high-level glimpse of something that should be a very welcome addition to C++ for financial software developers.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Summary (Linear Algebra Proposals)"><div class="sect2" id="idm45807805174688">
<h2>Summary (Linear Algebra Proposals)</h2>

<p>Recalling the results we saw with <code>valarray</code>, with the above proposals in place, some of the same convenient functionality should be in place by C++26, this time with rigorous, efficient, and consistent specifications that should avoid the problems that plagued <code>valarray</code>.  While <code>mdspan</code> differs from <code>valarray</code> as a non-owning reference, it will still allow array storage,  such as a <code>vector</code>, to be adapted to a matrix proxy by specifiying the number of rows and columns.  <code>submdspan</code> will assume a similar role as a <code>valarray</code> slice, but without the performance penalty due to object copy.  P1673 will provide a common interface to libraries containing BLAS functions, and function naming, as as with <code>matrix_vector_product</code>, will be more expressive than their cryptic Fortran equivalents such as <code>DGEMV(.)</code>.  And, the <code>+</code>, <code>-</code>, and <code>*</code> operators in P1385 will provide the ability to  to implement linear algebra expressions in a natural mathematical format similar to the results we saw with <code>valarray</code>.</p>

<p>This is an exciting development that will finally provide efficient and reliable methods for implementing basic matrix calculations that are long overdue for C++.  Hopefully we will also eventually see implementations of P1673 BLAS interfaces for popular open source libraries such as Eigen and others mentioned above, but as of the time of this writing, this remains to be seen.</p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Chapter Summary"><div class="sect1" id="idm45807805165520">
<h1>Chapter Summary</h1>

<p>This chapter has examined the past, present, and expected future of two-dimensional array management and linear algebra in C++.  <code>valarray</code>, dating back to C++98, offered matrix-like capabilities for which quantitative developers certainly would have found ample use cases.  It is unforunate it never received the attention and support of the Committee and community, even as C++ was being touted in the late 1990‚Äôs as the language of the future for computational finance.  For specific compilers, it might remain a viable option, but given the inconsistency of its implementations across Standard Library vendors, it can limit code reuse across different platforms.</p>

<p>In the late 2000‚Äôs, high quality open-source linear algebra libraries such as Eigen and Armadillo came on the scene and were well-received by the financial quant C++ programming community.  In the present day, these libraries contain not only much of the same functionality found in the BLAS standard, but also a plethora of matrix decompositions that are frequently used in financial applications.</p>

<p>Finally, the future also looks brighter for ISO C++ with the three proposals‚Äâ‚Äî‚Äâ<code>mdspan</code> (P0009), BLAS interface (P1673), and linear algebra library (P1385)‚Äâ‚Äî‚Äâslated for inclusion in the Standard Library within the next three years.  These are arguably features that are long overdue, but they will provide a big step in satisfying demand not just from the financial industry, but also other computationally intensive domains.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="References"><div class="sect1" id="idm45807805161664">
<h1>References</h1>

<p>US Daily Treasury Par Yield Curve Rates
<a href="https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&amp;field_tdr_date_value_month=202211" class="bare"><em class="hyperlink">https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&amp;field_tdr_date_value_month=202211</em></a>
_</p>

<p><a href="http://www.cppstdlib.com/cppstdlib_supplementary.pdf">Supplemental Chapter, _The C++ Standard Library, 2E</a></p>

<p>{2.5} Stroustrup, <em>A Tour of C++</em> (2E, but now in 3E)</p>

<p>Quantstart article on Eigen <a href="https://www.quantstart.com/articles/Eigen-Library-for-Matrix-Algebra-in-C/" class="bare"><em class="hyperlink">https://www.quantstart.com/articles/Eigen-Library-for-Matrix-Algebra-in-C/</em></a></p>

<p>Gottschling _Discovering Modern C++</p>

<p>Bowie Owens, CppCon 2019, <a href="https://www.youtube.com/watch?v=4IUCBx5fIv0" class="bare"><em class="hyperlink">https://www.youtube.com/watch?v=4IUCBx5fIv0</em></a></p>

<p>More information on the Jacobi and Bidiagonal Divide and Conquer SVD classes:</p>

<p><a href="https://eigen.tuxfamily.org/dox-devel/classEigen_1_1JacobiSVD.html">Two-sided Jacobi SVD decomposition of a rectangular matrix</a></p>

<p><a href="https://eigen.tuxfamily.org/dox-devel/classEigen_1_1BDCSVD.html">Bidiagonal Divide and Conquer SVD</a></p>

<p>asciidoctor-latex -b html Ch10_v10_Split_LinearAlgebraOnly.adoc</p>

<p>{5} Rcpp Packages:</p>

<p><a href="https://cran.r-project.org/web/packages/RcppEigen/vignettes/RcppEigen-Introduction.pdf">RcppEigen</a></p>

<p><a href="https://cran.r-project.org/web/packages/RcppArmadillo/vignettes/RcppArmadillo-intro.pdf">RcppArmadillo</a></p>

<p><a href="https://github.com/ChingChuan-Chen/RcppBlaze3">RcppBlaze3</a></p>

<p><a href="https://www.rdocumentation.org/packages/BH/versions/1.78.0-0">Boost Headers, including uBLAS</a></p>
</div></section>
</div></section></div></body></html>