- en: Chapter 9\. Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Kubernetes, scaling can mean different things to different users. We distinguish
    between two cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster scaling
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes called *cluster elasticity*, this refers to the (automated) process
    of adding or removing worker nodes based on cluster utilization.
  prefs: []
  type: TYPE_NORMAL
- en: Application-level scaling
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes called *pod scaling*, this refers to the (automated) process of manipulating
    pod characteristics based on a variety of metrics, from low-level signals such
    as CPU utilization to higher-level ones, such as HTTP requests served per second,
    for a given pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two kinds of pod-level scalers exist:'
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal pod autoscalers (HPAs)
  prefs: []
  type: TYPE_NORMAL
- en: HPAs automatically increase or decrease the number of pod replicas depending
    on certain metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Vertical pod autoscalers (VPAs)
  prefs: []
  type: TYPE_NORMAL
- en: VPAs automatically increase or decrease the resource requirements of containers
    running in a pod.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we first examine cluster elasticity for GKE, AKS, and EKS and
    then discuss pod scaling with HPAs.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Scaling a Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You have a deployment and want to scale it horizontally.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use the `kubectl scale` command to scale out a deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s reuse the `fancyapp` deployment from [Recipe 4.5](ch04.html#deployments),
    with five replicas. If it’s not running yet, create it with `kubectl apply -f
    fancyapp.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now suppose that the load has decreased and you don’t need five replicas anymore;
    three is enough. To scale the deployment down to three replicas, do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Rather than manually scaling a deployment, you can automate this process; see
    [Recipe 9.2](#auto_app_scaling_hpa) for an example.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2 Using Horizontal Pod Autoscaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to automatically increase or decrease the number of pods in a deployment,
    depending on the load present.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use an HPA, as described here.
  prefs: []
  type: TYPE_NORMAL
- en: To use HPAs, the Kubernetes Metrics API must be available. To install the Kubernetes
    Metrics Server, see [Recipe 2.7](ch02.html#metrics_server).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create an app—a PHP environment and server—that you can use as the target
    of the HPA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create an HPA and define the trigger parameter `--cpu-percent=40`, which
    means that the CPU utilization should not exceed 40%:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In a second terminal session, keep an eye on the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, in a third terminal session, launch the load generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Since there are three terminal sessions involved in parallel, an overview of
    the whole situation is provided in [Figure 9-1](#horizontal-pod-autoscaler-terminal).
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the terminal sessions for setting up an HPA](assets/kcb2_0901.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-1\. Terminal sessions for setting up an HPA
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In [Figure 9-2](#horizontal-pod-autoscaler-dashboard) showing the Kubernetes
    dashboard, you can see the effect of the HPA on the `appserver` deployment.
  prefs: []
  type: TYPE_NORMAL
- en: '![Screen Shot Of The Kubernetes Dashboard, Showing The Effect Of An HPA](assets/kcb2_0902.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-2\. Kubernetes dashboard, showing the effect of an HPA
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Kubernetes Event-driven Autoscaling](https://keda.sh)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The HPA walkthrough in the Kubernetes documentation](https://oreil.ly/b6Pwx)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.3 Automatically Resizing a Cluster in GKE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want the number of nodes in your GKE cluster to automatically grow or shrink,
    depending on the utilization.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use the GKE Cluster Autoscaler. This recipe assumes you’ve got the `gcloud`
    command installed and the environment set up (i.e., you’ve created a project and
    enabled billing).
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a cluster with one worker node and cluster autoscaling enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: At this point in time, when looking at the Google Cloud console, you should
    see something like what is shown in [Figure 9-3](#gke-cluster-autoscale-1-node).
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot Of The Google Cloud Console, Showing The Initial Cluster Size
    of One Node](assets/kcb2_0903.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-3\. Google Cloud console, showing the initial cluster size of one node
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, launch three pods using a deployment and request cluster resources to
    trigger the cluster autoscaling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After a while, the deployment will be updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You should now have a cluster of two nodes, as depicted in [Figure 9-4](#gke-cluster-autoscale-2-nodes).
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the Google Cloud console, showing the resulting cluster scaled
    to two nodes](assets/kcb2_0904.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-4\. Google Cloud console, showing the resulting cluster scaled to two
    nodes
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Cluster autoscaling can be enabled or updated on a GKE cluster after it has
    been created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The choice of [machine type](https://oreil.ly/lz7wQ) used in the cluster nodes
    is an important factor to consider and depends on the resources required to run
    your workloads. If your workloads demand more resources, then you should consider
    using a larger machine type.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike pod scaling, cluster scaling dynamically adds resources to your cluster,
    which could significantly increase your cloud bill. Ensure that you configure
    the maximum node count of your GKE cluster appropriately to avoid exceeding your
    spending limit.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you don’t need the cluster anymore, you should delete it to avoid being
    charged for unused compute resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Cluster Autoscaler](https://oreil.ly/QHik5) in the *kubernetes/autoscaler*
    repo'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cluster Autoscaler](https://oreil.ly/g8lfr) in the GKE docs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.4 Automatically Resizing an Amazon EKS Cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want the number of nodes in your AWS EKS cluster to automatically grow or
    shrink, depending on the utilization.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use the [Cluster Autoscaler](https://oreil.ly/6opBo), a Helm package leveraging
    AWS autoscaling groups. Follow [Recipe 6.1](ch06.html#helm_install) to install
    the Helm client that’s required to install the package.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a cluster with one worker node and make sure you can access it
    with `kubectl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, deploy the Cluster Autoscaler Helm chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, the cluster has only one node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, launch five pods using a deployment and request cluster resources to trigger
    the cluster autoscaling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After a while, the deployment will be updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now your cluster should have scaled up to accommodate the requested resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'To avoid being charged for unused resources, delete the cluster if you don’t
    need it anymore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
