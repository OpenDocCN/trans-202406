<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. Fundamentals"><div class="chapter" id="fundamentals">
<h1><span class="label">Chapter 2. </span>Fundamentals</h1>


<p>As discussed in <a data-type="xref" href="ch01.xhtml#introduction_to_cloud_native">Chapter 1</a>, cloud native applications are applications that are distributed in nature and utilize cloud infrastructure. There are many technologies and tools that are being used to implement cloud native applications, but from a compute perspective, it is mainly <em>functions</em> and <em>containers</em>. <a data-type="indexterm" data-primary="functions" id="idm45987080570232"/>From an architectural perspective, <em>microservices architectures</em> have gained a lot of popularity. More often than not, those terms are mistakenly used, and often believed to be one and the same. In reality, functions and containers are different technologies, each serving a particular purpose, whereas microservices describes an architectural style. That said, understanding how to best use functions and containers, along with <em>eventing</em> or <em>messaging</em> technologies, allows developers to design, develop, and operate a new generation of cloud native microservices-based applications in the most efficient and agile way. To make the correct architectural decisions to design those types of applications, it is important to understand the basics of the underlying terms and technologies. This chapter explains important technologies used with cloud native applications and concludes by providing an overview of the microservices architectural style.</p>






<section data-type="sect1" data-pdf-bookmark="Containers"><div class="sect1" id="containers">
<h1>Containers</h1>

<p>Initially, containers were brought into the spotlight by startups and born-in-the-cloud companies, but over the past couple of years, containers have become synonymous with application modernization.<a data-type="indexterm" data-primary="containers" data-secondary="about" id="idm45987080566376"/> Today there are very few companies that are not using containers or at least considering using containers in the future, which means that architects and developers alike need to understand what containers offer and what they don’t offer.</p>

<p>When people talk about containers today, they refer to “Docker containers” most of the time, because it’s Docker that has really made containers popular.<a data-type="indexterm" data-primary="Docker" data-secondary="containers" id="idm45987080557480"/><a data-type="indexterm" data-primary="Linux" data-secondary="containers" id="idm45987080562568"/> However, in the Linux operating system (OS) world, containers date back more than 10 years. The initial idea of containers was to slice up an OS so that you can securely run multiple applications without them interfering with one another. The required isolation is accomplished through namespaces and control groups, which are Linux kernel features.<a data-type="indexterm" data-primary="namespaces" data-secondary="in Linux" data-secondary-sortas="Linux" id="idm45987080563656"/> Namespaces allow the different components of the OS to be sliced up and thus create isolated workspaces.<a data-type="indexterm" data-primary="control groups (Linux)" id="idm45987080565352"/> Control groups then allow fine-grained control of resource utilization, effectively stopping one container from consuming all system resources.</p>

<p>Because the interaction with kernel features was not exactly what we would call developer friendly, Linux containers (LXC) were introduced to abstract away some of the complexity of composing the various technology underpinnings of what is now commonly call a “container.” Eventually it was Docker that made containers mainstream by introducing a developer-friendly packaging of the kernel features. Docker defines containers as a “standardized unit of software.” The “unit of software”—or, more accurately, the service or application running within a container—has full, private access to their own isolated view of OS constructs. In other words, you can view containers as encapsulated, individually deployable components running as isolated instances on the same kernel with virtualization happening on the OS level.</p>

<figure><div id="vms_and_containers_in_a_single_host" class="figure">
<img src="Images/clna_0201.png" alt="clna 0201" width="1402" height="599"/>
<h6><span class="label">Figure 2-1. </span>VMs and containers on a single host</h6>
</div></figure>

<p>In addition, containers use the copy-on-write filesystem strategy, which allows multiple containers to share the same data, and the OS provides a copy of the data to the container that needs to modify or write data. This allows containers to be very lightweight in terms of memory and disk space usage, resulting in faster startup times, which is one of the great benefits of using containers.<a data-type="indexterm" data-primary="deterministic deployments with containers" id="idm45987080564680"/><a data-type="indexterm" data-primary="portability" data-secondary="between environments" data-secondary-sortas="environments" id="idm45987080563960"/> Other benefits are <em>deterministic deployments</em>, allowing portability between environments, isolation, and higher density. For modern cloud native applications, container images have become the unit of deployment encapsulating the application or service code, its runtime, dependencies, system libraries, and so on. Due to their fast startup times, containers are an ideal technology for scale-out scenarios, which are very common in cloud native <span class="keep-together">applications.</span> <a data-type="xref" href="#vms_and_containers_in_a_single_host">Figure 2-1</a> shows the difference between virtual machines (VMs) and containers on a single host.<a data-type="indexterm" data-primary="virtual machines (VMs)" data-secondary="containers vs., on a single host" id="idm45987080543192"/><a data-type="indexterm" data-primary="containers" data-secondary="versus VMs on a signle host" id="idm45987080542344"/></p>








<section data-type="sect2" data-pdf-bookmark="Container Isolation Levels"><div class="sect2" id="container_isolation_levels">
<h2>Container Isolation Levels</h2>

<p>Because containers are based on OS virtualization, they share the same kernel when running on the same host.<a data-type="indexterm" data-primary="isolation" data-secondary="container isolation levels" id="idm45987080540824"/><a data-type="indexterm" data-primary="containers" data-secondary="isolation levels" id="idm45987080552856"/> Although this is sufficient enough isolation for most scenarios, it falls short of the isolation level that hardware-based virtualization options such as VMs provide. Following are some of<a data-type="indexterm" data-primary="virtual machines (VMs)" data-secondary="downsides of using as basis of cloud native applications" id="idm45987080551800"/> the downsides of using VMs as the foundation of cloud native applications:</p>

<ul>
<li>
<p>VMs can take a considerable amount of time to start because they boot a full OS.</p>
</li>
<li>
<p>The size of the VM can be an issue. A VM contains an entire OS, which can easily be several gigabytes in size. Copying this image across a network—for example, if they are kept in a central image repository—will take a lot of time.</p>
</li>
<li>
<p>Scaling of VMs has its challenges. Scaling up (adding more resources) requires a new, larger VM (more CPU, memory, storage, etc.) to be provisioned and booted. Scaling out might not be fast enough to respond to demand; it takes time for new instances to start.</p>
</li>
<li>
<p>VMs have more overhead and use considerably more resources such as memory, CPU, and disk. This limits the density, or number of VMs that can run on a single host machine.</p>
</li>
</ul>

<p>The most common scenarios that demand high isolation on a hardware virtualization level are hostile multitenant scenarios in which you typically need to protect against malicious escape and breakout attempts into other targets on the same host or on the shared infrastructure. Cloud providers have been using technologies internally that provide VM-level isolation while maintaining the expected speed and efficiency of containers.<a data-type="indexterm" data-primary="Hyper-V containers" id="idm45987080537960"/><a data-type="indexterm" data-primary="sandboxed containers" id="idm45987080537240"/><a data-type="indexterm" data-primary="MicroVMs" id="idm45987080536296"/> These technologies are known as <em>Hyper-V containers</em>, <em>sandboxed containers</em>, or <em>MicroVMs</em>. Here are the most popular MicroVM technologies (in nonspecific order):</p>
<dl>
<dt><a href="https://nabla-containers.github.io/">Nabla containers</a></dt>
<dd>
<p>These enable better isolation by taking advantage of unikernel techniques, specifically<a data-type="indexterm" data-primary="Nabla containers" id="idm45987080528296"/> those from the <a href="https://github.com/Solo5/solo5">Solo5 project</a>, to limit system calls from the container to host kernel. The Nabla container runtime (runc) is an Open Container Initiative (OCI)-compliant runtime. OCI will be explained in a bit more detail later in this chapter.<a data-type="indexterm" data-primary="open container initiative (OCI)" data-secondary="container runtimes" id="idm45987080529272"/></p>
</dd>
<dt><a href="https://github.com/google/gvisor">Google’s gVisor</a></dt>
<dd>
<p>This is a container runtime and user space kernel written in Go. The new kernel is a “user space” process that addresses the container’s system call needs, <span class="keep-together">preventing</span> direct interaction with the host OS.<a data-type="indexterm" data-primary="gVisor" id="idm45987080524392"/> The gVisor runtime (runSC) is an OCI-compliant runtime, and it supports Kubernetes orchestration as well.</p>
</dd>
<dt><a href="https://oreil.ly/5njcd">Microsoft’s Hyper-V containers</a></dt>
<dd>
<p>Microsoft’s Hyper-V containers were introduced a couple of years ago and are based on VM Worker Process (<em>vmwp.exe</em>).<a data-type="indexterm" data-primary="VM Worker Process" id="idm45987080520824"/><a data-type="indexterm" data-primary="Microsoft, Hyper-V containers" id="idm45987080520216"/> Those containers provide full VM-level isolation and are OCI compliant. As for running <a href="http://bit.ly/33vZb7U">Hyper-V containers in Kubernetes</a> in production, you will want to wait for general availability of Kubernetes on Windows.<a data-type="indexterm" data-primary="Hyper-V containers" id="idm45987080516280"/></p>
</dd>
<dt><a href="https://katacontainers.io/">Kata containers</a></dt>
<dd>
<p>Kata containers are a combination of Hyper.sh and Intel’s clear containers and provide classic hardware-assisted virtualization.<a data-type="indexterm" data-primary="Kata containers" id="idm45987080515768"/> Kata containers are compatible with the OCI specification for Docker containers and CRI for Kubernetes.</p>
</dd>
<dt>Amazon’s Firecracker</dt>
<dd>
<p>Firecracker is powering Amazon’s Lambda infrastructure and has been open sourced under the Apache 2.0 license.<a data-type="indexterm" data-primary="Amazon Firecracker" id="idm45987080514248"/> Firecracker is a user-mode VM solution that sits on top of the KVM API and is designed to run modern Linux kernels.<a data-type="indexterm" data-primary="virtual machines (VMs)" data-secondary="Amazon Firecracker" id="idm45987080513864"/><a data-type="indexterm" data-primary="Firecracker (Amazon)" id="idm45987080512600"/><a data-type="indexterm" data-primary="Linux" data-secondary="containers, running with Amazon Firecracker" id="idm45987080512216"/> The goal of Firecracker is to provide support for running Linux containers in a hypervisor-isolated fashion similar to other more isolated container technologies such as Kata containers. Note that, as of this writing, you are not able to use Firecracker with Kubernetes, Docker, or Kata containers.</p>
</dd>
</dl>

<p><a data-type="xref" href="#isolation_levels_for_vms_comma_container">Figure 2-2</a> provides an overview of the isolation levels of the these technologies.</p>

<figure><div id="isolation_levels_for_vms_comma_container" class="figure">
<img src="Images/clna_0202.png" alt="clna 0202" width="1330" height="472"/>
<h6><span class="label">Figure 2-2. </span>Isolation levels for VMs, containers, and processes</h6>
</div></figure>
</div></section>













<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Container Orchestration"><div class="sect2" id="container_orchestration">
<h2>Container Orchestration</h2>

<p>To manage the life cycle of containers at scale, you need to use a container orchestrator. <a data-type="indexterm" data-primary="orchestrators (container)" data-secondary="tasks of" id="idm45987080502152"/><a data-type="indexterm" data-primary="containers" data-secondary="orchestration" id="idm45987080501640"/>The tasks of a container orchestrator are the following:</p>

<ul>
<li>
<p>The provisioning and deployment of containers onto the cluster nodes</p>
</li>
<li>
<p>Resource management of containers, meaning placing containers on nodes that provide sufficient resources or moving containers to other nodes if the resource limits of a node is reached<a data-type="indexterm" data-primary="nodes" data-secondary="placing containers on" id="idm45987080499976"/></p>
</li>
<li>
<p>Health monitoring of the containers and the nodes to initiaing restarted and rescheduling in case of failures on a container or node level</p>
</li>
<li>
<p>Scaling in or out containers within a cluster</p>
</li>
<li>
<p>Providing mappings for containers to connect to networking</p>
</li>
<li>
<p>Internal load balancing between containers</p>
</li>
</ul>

<p>There are multiple container orchestrators available, but there is no doubt that Kubernetes is by far the most popular choice for cluster management and the scheduling of container-centric workloads in a cluster.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Kubernetes Overview"><div class="sect2" id="kubernetes_overview">
<h2>Kubernetes Overview</h2>

<p>Kubernetes (often abbreviated as k8s) is an open source project for running and managing containers.<a data-type="indexterm" data-primary="Kubernetes" data-secondary="overview" id="idm45987080489720"/> Google open sourced the project in 2014, and Kubernetes is often viewed as a container platform, microservices platform, and/or a cloud portability layer. All of the major cloud vendors have a managed Kubernetes offering today.<a data-type="indexterm" data-primary="orchestrators (container)" data-seealso="Kubernetes" id="idm45987080491864"/><a data-type="indexterm" data-primary="k8s" data-see="Kubernetes" id="idm45987080491096"/></p>

<p>A Kubernetes cluster runs multiple components that can be grouped in one of three categories: <em>master components</em>, <em>node components</em>, or <em>addons</em>. Master components provide the cluster control plane.<a data-type="indexterm" data-primary="components" data-secondary="categories of, in Kubernetes" id="idm45987080485752"/><a data-type="indexterm" data-primary="control plane" data-secondary="in Kubernetes" id="idm45987080484904"/> These components are responsible for making cluster-wide decisions like scheduling tasks in the cluster or responding to events, such as starting new tasks if one fails or does not meet the desired number of replicas.<a data-type="indexterm" data-primary="master components (Kubernetes)" id="idm45987080487576"/><a data-type="indexterm" data-primary="nodes" data-secondary="node components (Kubernetes)" id="idm45987080483816"/><a data-type="indexterm" data-primary="addons (Kubernetes)" id="idm45987080482872"/> The master components can run on any node in the cluster, but are commonly deployed to dedicated master nodes. Managed Kubernetes offerings from cloud providers will handle the management of the control plane, including on-demand upgrades and patches.</p>

<p>Kubernetes master components include the following:</p>
<dl>
<dt>kube-apiserver</dt>
<dd>
<p>Exposes the Kubernetes API and is the frontend for the Kubernetes control plane<a data-type="indexterm" data-primary="kube-apiserver" id="idm45987080478008"/></p>
</dd>
<dt>etcd</dt>
<dd>
<p>A key/value store used<a data-type="indexterm" data-primary="etcd" id="idm45987080478968"/> for all cluster data</p>
</dd>
<dt>kube-scheduler</dt>
<dd>
<p>Monitors newly created <em>pods</em> (a Kubernetes-specific management wrapper around containers, which we explain in more detail later in this chapter) that are not assigned to a node and finds an available node<a data-type="indexterm" data-primary="kube-scheduler" id="idm45987080474568"/></p>
</dd>
<dt>kube-controller-manager</dt>
<dd>
<p>Manages a number of controllers that are responsible for responding to nodes that go down or maintaining<a data-type="indexterm" data-primary="kube-controller-manager" id="idm45987080472936"/> the correct number of replicas</p>
</dd>
<dt>cloud-controller-manager</dt>
<dd>
<p>Run controllers that interact with the underlying cloud providers<a data-type="indexterm" data-primary="Cloud Controller Manager (Kubernetes)" id="idm45987080468728"/></p>
</dd>
</dl>

<p>Node components run on every node in the cluster, which is also referred to as the <em>data plane</em>, and are responsible for maintaining running pods and the environment for the node to which they are deployed.<a data-type="indexterm" data-primary="data plane" data-secondary="in Kubernetes clusters" id="idm45987080467960"/></p>

<p>Kubernetes node components include the following:</p>
<dl>
<dt>kubelet</dt>
<dd>
<p>An agent that runs on each node in the cluster and is responsible for running containers in pods based on their pod specification<a data-type="indexterm" data-primary="kubelet" id="idm45987080465336"/></p>
</dd>
<dt>kube-proxy</dt>
<dd>
<p>Maintains network<a data-type="indexterm" data-primary="kube-proxy" id="idm45987080463256"/> rules on the nodes and performs connection forwarding</p>
</dd>
<dt>container runtime</dt>
<dd>
<p>The software responsible for<a data-type="indexterm" data-primary="container runtime (Kubernetes)" id="idm45987080460072"/> running containers (see <a data-type="xref" href="#kubernetes_and_containers">“Kubernetes and Containers”</a>)</p>
</dd>
</dl>

<p><a data-type="xref" href="#kubernetes_master_and_worker_node_compon">Figure 2-3</a> shows the Kubernetes master and worker node components.</p>

<figure><div id="kubernetes_master_and_worker_node_compon" class="figure">
<img src="Images/clna_0203.png" alt="clna 0203" width="1193" height="706"/>
<h6><span class="label">Figure 2-3. </span>Kubernetes master and worker node components</h6>
</div></figure>

<p>Kubernetes is commonly deployed with addons that are managed by the master and worker node components. These addons will include services like Domain Name System (DNS) and a management user interface (UI).</p>

<p>A deep dive into Kubernetes is beyond the scope of this book. There are, however, some fundamental concepts that are important for you to understand:</p>
<dl>
<dt>Pods</dt>
<dd>
<p>A pod is basically a management wrapper around one or multiple containers, storage resources, or a unique network IP, that governs the container life cycle. <a data-type="indexterm" data-primary="pods (Kubernetes)" id="idm45987080453960"/>Although Kubernetes supports multiple containers per pod, most of the time there is only one application container per pod. That said, the pattern of <em>sidecar containers</em>, which extends<a data-type="indexterm" data-primary="sidecar containers" id="idm45987080453080"/> or enhances the functionality of the application container, is very popular. Service meshes like Istio rely heavily on sidecars, as you can see in <a data-type="xref" href="ch03.xhtml#designing_cloud-native_applications">Chapter 3</a>.</p>
</dd>
<dt>Services</dt>
<dd>
<p>A Kubernetes service provides a steady endpoint to a grouping of pods that are running on the cluster.<a data-type="indexterm" data-primary="services" data-secondary="Kubernetes" id="idm45987080446104"/> Kubernetes uses label selectors to identify which pods are targeted by a service.</p>
</dd>
<dt>ReplicaSets</dt>
<dd>
<p>The easiest way to think about ReplicaSets is to think about service instances. <a data-type="indexterm" data-primary="ReplicaSets" id="idm45987080443992"/>You basically define how many replicas of a pod you need, and Kubernetes makes sure that you have that number of replicas running at any given time.</p>
</dd>
<dt>Deployments</dt>
<dd>
<p>The Kubernetes Deployment documentation states that you “describe a desired state in a Deployment object, and the Deployment controller <a data-type="indexterm" data-primary="deployments" data-secondary="Deployment objects in Kubernetes" id="idm45987080441784"/>changes the actual state to the desired state at a controlled rate.” In other words, you should use Deployments for rolling out and monitoring ReplicaSets, scaling ReplicaSets, updating pods, rolling back to earlier Deployments versions, and cleaning up older ReplicaSets.</p>
</dd>
</dl>

<p><a data-type="xref" href="#fundamental_kubernetes_concepts">Figure 2-4</a> provides a logical view of the fundamental Kubernetes concepts and how they interact with one another.</p>

<figure><div id="fundamental_kubernetes_concepts" class="figure">
<img src="Images/clna_0204.png" alt="clna 0204" width="1101" height="566"/>
<h6><span class="label">Figure 2-4. </span>Fundamental Kubernetes concepts</h6>
</div></figure>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Kubernetes and Containers"><div class="sect2" id="kubernetes_and_containers">
<h2>Kubernetes and Containers</h2>

<p>Kubernetes is simply the orchestration platform for containers, so it needs a container runtime to manage the container life cycle.<a data-type="indexterm" data-primary="container runtime (Kubernetes)" id="idm45987080436664"/><a data-type="indexterm" data-primary="containers" data-secondary="Kubernetes and" id="ix_cntrKube"/><a data-type="indexterm" data-primary="Kubernetes" data-secondary="and containers" id="ix_Kubectr"/> The Docker runtime was supported from day one in Kubernetes, but it isn’t the only container runtime available on the market. As a consequence, the Kubernetes community has pushed for a generic way to integrate container runtimes into Kubernetes. Interfaces have proven to be a good software pattern for providing contracts between two systems, so the community created the <a href="http://bit.ly/31y3pdC">Container Runtime Interface (CRI)</a>.<a data-type="indexterm" data-primary="container runtime interface (CRI)" id="idm45987080426760"/> The CRI avoids “hardcoding” specific runtime requirements into the Kubernetes codebase, with the consequence of always needing to update the Kubernetes codebase when there are changes to a container runtime. Instead, the CRI describes the functions that need to be implemented by a container runtime to be CRI compliant. The functions that the CRI describes handle the life cycle of container pods (start, stop, pause, kill, delete), container image management (e.g., download images from a registry), and some helper functions around observability, such as log and metric collections and networking. <a data-type="xref" href="#docker_versus_kata_container_on_kubernet">Figure 2-5</a> shows high-level CRI example architectures for Docker and Kata <span class="keep-together">containers.</span><a data-type="indexterm" data-primary="Docker" data-secondary="container runtime interface" id="idm45987080420472"/><a data-type="indexterm" data-primary="Kata containers" data-secondary="container runtime interface" id="idm45987080431784"/></p>

<figure><div id="docker_versus_kata_container_on_kubernet" class="figure">
<img src="Images/clna_0205.png" alt="clna 0205" width="1110" height="663"/>
<h6><span class="label">Figure 2-5. </span>Docker versus Kata container on Kubernetes</h6>
</div></figure>

<p>The following list provides other container-related technologies that might be useful:</p>
<dl>
<dt>OCI</dt>
<dd>
<p>The OCI is a <a href="https://en.wikipedia.org/wiki/Linux_Foundation">Linux Foundation</a> project that aims to design open standards for container images and runtimes. Many container technologies implement an OCI-compliant runtime and image specification.<a data-type="indexterm" data-primary="open container initiative (OCI)" id="idm45987080421128"/></p>
</dd>
<dt>containerd</dt>
<dd>
<p>containerd is an industry-standard container runtime used by Docker and Kubernetes CRI, just to name the most popular ones.<a data-type="indexterm" data-primary="containerd" id="idm45987080418536"/> It is available as a daemon for Linux and Windows, which can manage the complete container life cycle of its host system, including container image management, container execution, low-level storage, and network attachments.</p>
</dd>
<dt>Moby</dt>
<dd>
<p>Moby is a set of open source tools created by Docker to enable and accelerate software containerization.<a data-type="indexterm" data-primary="Moby" id="idm45987080421976"/> The toolkit includes container build tools, a container registry, orchestration tools, a runtime, and more, and you can use these as building blocks in conjunction with other tools and projects. Moby is using containerd as the default container runtime.<a data-type="indexterm" data-primary="containers" data-secondary="Kubernetes and" data-startref="ix_cntrKube" id="idm45987080421592"/><a data-type="indexterm" data-primary="Kubernetes" data-secondary="and containers" data-startref="ix_Kubectr" id="idm45987080416024"/></p>
</dd>
</dl>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Serverless Computing"><div class="sect1" id="serverless_computing">
<h1>Serverless Computing</h1>

<p>Serverless computing means that scale and the underlying infrastructure is managed by the cloud provider; <a data-type="indexterm" data-primary="serverless computing" id="idm45987080412296"/>that is, your application automatically drives the allocation and deallocation of resources, and you do not need to worry about managing the underlying infrastructure at all. All management and operations are abstracted away from the user and managed by cloud providers such as Microsoft Azure, Amazon Web <span class="keep-together">Services</span> (AWS), and Google Cloud Platform (GCP). From a developer perspective, serverless often adds an event-driven programming model, and from an economic perspective, you pay only per execution (CPU time consumed).</p>

<p>Many people think Function as a Service (FaaS) is serverless. <a data-type="indexterm" data-primary="Function as a Service (FaaS)" id="idm45987080408984"/>This is technically true, but FaaS is only one variation of serverless computing.<a data-type="indexterm" data-primary="Microsoft Azure" data-secondary="container instances (ACI) and Azure SF Mesh" id="idm45987080407960"/> Microsoft Azure’s Container Instances (ACI) and Azure SF Mesh, as well as AWS Fargate and GCP’s Serverless Containers on Cloud Functions, are good examples.<a data-type="indexterm" data-primary="Amazon Web Services (AWS)" data-secondary="Fargate" id="idm45987080409432"/> ACI and AWS Fargate are serverless container offerings also known as Container as a Service (CaaS), which allow you to deploy containerized applications without needing to know about the underlying infrastructure. <a data-type="indexterm" data-primary="Container as a Service (CaaS)" id="idm45987080406712"/>Other examples of serverless offerings are API management and machine learning services—basically, any service that lets you consume functionality without managing the underlying infrastructure and a pay-only-for-what-you-use model qualifies as serverless offering.<a data-type="indexterm" data-primary="FaaS" data-see="Function as a Service" id="idm45987080403064"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Functions"><div class="sect1" id="functions">
<h1>Functions</h1>

<p>When talking about functions, people typically talk about FaaS offerings such as AWS Lambda, Azure Functions, and Google Cloud Functions, which are implemented on serverless infrastructure.<a data-type="indexterm" data-primary="Microsoft Azure" data-secondary="Azure Functions" id="idm45987080399736"/><a data-type="indexterm" data-primary="Amazon Web Services (AWS)" data-secondary="Lambda" id="idm45987080398904"/><a data-type="indexterm" data-primary="Google Cloud Platform" data-secondary="Google Cloud Functions" id="idm45987080401640"/><a data-type="indexterm" data-primary="functions" id="idm45987080400568"/> The advantages of serverless computing—fast startup and execution time, plus the simplification of their applications—makes FaaS offerings very compelling to developers because it allows them to focus solely on writing code.</p>

<p>From a development perspective, a function is the unit of work, which means that your code has a start and a finish. Functions are usually triggered by events that are emitted by either other functions or platform services. For example, a function can be triggered by adding an entry to a database service or eventing service.<a data-type="indexterm" data-primary="events" data-secondary="functions triggered by" id="idm45987080400440"/><a data-type="indexterm" data-primary="functions" data-secondary="building applications with, considerations" id="idm45987080392760"/> There are quite a few things to consider when you want to build a large, complex application just with functions. You will need to manage more independent code, you will need to ensure state is being taken care of, and you will need to implement patterns if functions must depend on one another, just to name a few.<a data-type="indexterm" data-primary="microservices" data-secondary="containerized" id="idm45987080391720"/><a data-type="indexterm" data-primary="containers" data-secondary="containerized microservices vs. Function as a Service" id="idm45987080390344"/><a data-type="indexterm" data-primary="Function as a Service (FaaS)" data-secondary="containerized microservices vs." id="idm45987080389400"/> Containerized microservices share a lot of the same patterns, so there have been quite a few discussions around when to use FaaS or a container. <a data-type="xref" href="#comparison_of_faas_and_containerized_ser">Table 2-1</a> provides some high-level guidance between FaaS and containers, and  <a data-type="xref" href="ch03.xhtml#designing_cloud-native_applications">Chapter 3</a> covers the trade-offs in more detail.</p>
<table id="comparison_of_faas_and_containerized_ser">
<caption><span class="label">Table 2-1. </span>Comparison of FaaS and containerized services</caption>
<thead>
<tr>
<th>FaaS</th>
<th>Containerized service</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>Does one thing</p></td>
<td><p>Does more than one thing</p></td>
</tr>
<tr>
<td><p>Can’t deploy dependencies</p></td>
<td><p>Can deploy dependencies</p></td>
</tr>
<tr>
<td><p>Must respond to one kind of event</p></td>
<td><p>Can respond to more than one kind of event</p></td>
</tr>
</tbody>
</table>

<p>There are two scenarios in which using FaaS offerings might not be ideal, although it offers the best economics. First, you want to avoid vendor lock-in. Because you need to develop your function specific to the FaaS offering and consume higher-level cloud services from a provider, your entire application becomes less portable. Second, you want to run functions on-premises or your own clusters. <a data-type="indexterm" data-primary="Function as a Service (FaaS)" data-secondary="open source FaaS runtimes" id="idm45987080380264"/>There are a bunch of FaaS runtimes that are available as open source runtimes and that you can run on any Kubernetes cluster. Kubeless, OpenFaaS, Serverless, and Apache OpenWhisk are among the most popular installable FaaS platforms, with Azure Functions gaining more popularity since it has been open sourced. Installable FaaS platforms are typically deployed through containers and allow the developer to simply deploy small bits of code (functions) without needing to worry about the underlying infrastructure. Many installable FaaS frameworks use Kubernetes resources for routing, autoscaling, and monitoring.</p>

<p>A critical aspect of any FaaS implementation, no matter whether it runs on a cloud provider’s serverless infrastructure or is installed on your own clusters, is the startup time. In general, you expect functions to execute very quickly after they have been triggered, which implies that their underlying technology needs to provide very fast boot-up times. As previously discussed, containers provide good startup times, but do not necessarily offer the best isolation.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="From VMs to Cloud Native"><div class="sect1" id="from_vms_to_cloud_native">
<h1>From VMs to Cloud Native</h1>

<p>To understand how we ended up with the next generation of cloud native applications, it is worth looking at how applications evolve from running on VMs to functions.<a data-type="indexterm" data-primary="cloud native applications" data-secondary="from VMs to" id="ix_clnaVMs"/><a data-type="indexterm" data-primary="virtual machines (VMs)" data-secondary="from VMs to cloud native" id="ix_VMstoclna"/> Describing the journey should give you a good idea of how the IT industry is changing to put developer productivity into focus and how you can take advantage of all the new technologies. There are really two different paths to the cloud native world. The first one is mainly used for <em>brownfield scenarios</em>, which means that you have an existing application, and typically follows a lift-and-shift, application modernization, and eventually an application optimization process.<a data-type="indexterm" data-primary="brownfield scenarios" id="idm45987080367304"/><a data-type="indexterm" data-primary="greenfield scenarios" id="idm45987080373768"/> The second one is a <em>greenfield scenario</em> in which you start your application from scratch.</p>








<section data-type="sect2" data-pdf-bookmark="Lift-and-Shift"><div class="sect2" id="lift_and_shift">
<h2>Lift-and-Shift</h2>

<p>Installing software directly on machines in the cloud is still the very first step for many customers to move to the cloud. The benefits are mainly in the capital and operational expense areas given that customers do not need to operate their own datacenters or can at least reduce operations and, therefore, the costs. From a technical perspective, lift-and-shift into Infrastructure as a Service (IaaS) gives you the most control over the entire stack.<a data-type="indexterm" data-primary="Infrastructure as a Service (IaaS)" data-secondary="lift-and-shift into" id="idm45987080370664"/><a data-type="indexterm" data-primary="virtual machines (VMs)" data-secondary="from VMs to cloud native" data-tertiary="lift and shift" id="idm45987080370984"/><a data-type="indexterm" data-primary="cloud native applications" data-secondary="from VMs to" data-tertiary="lift and shift" id="idm45987080365608"/> With control comes responsibility, and installing software directly on machines often resulted in errors caused by missing dependencies, runtime versioning conflicts, resource contention, and isolation. The next logical step is to move applications into a Platform as a Service (PaaS) environment.<a data-type="indexterm" data-primary="Platform as a Service (PaaS)" data-secondary="moving applications into" id="idm45987080361240"/> PaaS existed long before containers became popular; for example, Azure Cloud Services dates back to 2010. In most past PaaS environments, access to the underlying VMs is restricted or in some cases prohibited so that moving to the cloud requires some rewriting of the applications. The benefit for developers is not to worry about the underlying infrastructure anymore. Operational tasks such as patching the OS were handled by the cloud providers, but some of the problems, like missing dependencies, remained. Because many PaaS services were based on VMs, scaling in burst scenarios was still a challenge due to the downsides of VMs, which we discussed previously, and for economic reasons.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Application Modernization"><div class="sect2" id="application_modernization">
<h2>Application Modernization</h2>

<p>Besides offering super-fast startup times, containers drastically removed the issues of missing dependencies, because everything an application needed is packaged inside a container. <a data-type="indexterm" data-primary="containers" data-secondary="application modernization to" id="idm45987080358136"/><a data-type="indexterm" data-primary="dependencies" data-secondary="containers and" id="idm45987080363672"/><a data-type="indexterm" data-primary="virtual machines (VMs)" data-secondary="from VMs to cloud native" data-tertiary="application modernization" id="idm45987080362536"/><a data-type="indexterm" data-primary="cloud native applications" data-secondary="from VMs to" data-tertiary="application modernization" id="idm45987080356776"/>It didn’t take long for developers to begin to love the concept of containers as a packaging format, and now pretty much every new application is using containers, and more and more monolithic legacy applications are being containerized. Many customers see the containerization of an existing application as an opportunity to also move to a more suitable architecture for cloud native environments.<a data-type="indexterm" data-primary="microservices" data-secondary="benefits of breaking monolithic applications into" id="idm45987080349432"/> Microservices is the obvious choice, but as you will see later in the chapter, moving to such an architecture comes with some disadvantages. There are a few very obvious reasons, though, why you want to break up your monolith:</p>

<ul>
<li>
<p>Time to deployment is faster.</p>
</li>
<li>
<p>Certain components need to update more frequently than others.</p>
</li>
<li>
<p>Certain components need different scale requirements.</p>
</li>
<li>
<p>Certain components should be developed in a different technology.</p>
</li>
<li>
<p>The codebase has gotten too big and complex.</p>
</li>
</ul>

<p>Although the methodology to break up a monolith goes beyond the scope of this book, it is worth mentioning the two major patterns to move from a monolithic application to microservices.</p>
<dl>
<dt><em>Strangler</em> pattern</dt>
<dd>
<p>With the Strangler pattern, you strangle the monolithic application.<a data-type="indexterm" data-primary="strangler pattern" id="idm45987080344600"/> New services or existing components are implemented as microservices. A facade or gateway routes user requests to the correct application. Over time, more and more features are moved to the new architecture until the monolithic application has been entirely transformed into a microservices application.</p>
</dd>
<dt><em>Anticorruption Layer</em> pattern</dt>
<dd>
<p>This is similar to the Strangler pattern but is used when new services need to access the legacy application.<a data-type="indexterm" data-primary="anticorruption layer pattern" id="idm45987080342872"/> The layer then translates the concepts from existing app to new, and vice versa.</p>
</dd>
</dl>

<p>We describe both patterns in more detail in <a data-type="xref" href="ch06.xhtml#best_practices">Chapter 6</a>.</p>

<p>With applications being packaged in container images, orchestrators began to play a more important role. Even though there were several choices in the beginning, Kubernetes has become the most popular choice today; in fact, it is considered the new cloud OS. Orchestrators, however, added another variable to the equation insomuch as development and operations teams needed to understand them. The management part of the environment has become better, as pretty much every cloud vendor now offers “orchestrators” as a service. As with any cloud provider, “managed” Kubernetes means that the setup and runtime part of the Kubernetes service is managed. From an economical point of view, users are typically being charged for compute hours, which means that you pay as long as the nodes of the cluster are up and running even though the application might be sitting idle or utilizing low resources.</p>

<p>From a developer perspective, you still need to understand how Kubernetes works if you want to build microservices applications on top of it given that Kubernetes does not offer any PaaS or CaaS features out of the box.<a data-type="indexterm" data-primary="Kubernetes" data-secondary="building microservices on top of" id="idm45987080339752"/></p>

<p>For example, a Kubernetes service does not really represent the service code within a container, it just provides an endpoint to it, so that the code within the container can always be accessed through the same endpoint. In addition to needing to understand Kubernetes, developers are also being introduced to distributed systems patterns to handle resiliency, diagnostics, and routing, just to name a few.</p>

<p>Service meshes such as Istio or Linkerd are gaining popularity because they are moving some of the distributed systems complexity into the platform layer.<a data-type="indexterm" data-primary="Istio" id="idm45987080335000"/><a data-type="indexterm" data-primary="Linkerd" id="idm45987080337656"/><a data-type="indexterm" data-primary="service meshes" id="idm45987080337048"/> <a data-type="xref" href="ch03.xhtml#designing_cloud-native_applications">Chapter 3</a> covers service meshes in great detail, but for now you can think of a service mesh as being a dedicated networking infrastructure layer that handles the service-to-service communication. Among other things, service meshes enable resiliency features such as retries and circuit breakers, distributed tracing, and routing.</p>

<p>The next step of application evolution is to use serverless infrastructure for containerized workloads, aka CaaS offerings such as Azure Container Instances or AWS Fargate. <a data-type="indexterm" data-primary="Container as a Service (CaaS)" data-secondary="Virtual Kubelet project" id="idm45987080330168"/><a data-type="indexterm" data-primary="Virtual Kubelet" id="idm45987080329208"/><a data-type="indexterm" data-primary="Microsoft Azure" data-secondary="melding of managed Kubernetes service with CaaS offering, ACI" id="idm45987080332360"/>Microsoft Azure has done a great job to meld the world of its managed Kubernetes Service (AKS) with its CaaS offering, ACI, by using <em>virtual nodes</em>.<a data-type="indexterm" data-primary="virtual nodes" id="idm45987080327928"/> Virtual nodes is based on Microsoft’s open source project called Virtual Kubelet, which allows any compute resource to act as a Kubernetes node and use the Kubernetes control plane.<a data-type="indexterm" data-primary="Kubernetes" data-secondary="virtual nodes and" id="idm45987080332840"/> In the case of AKS virtual nodes, you are able to schedule your application on AKS and burst into ACI without needing to set up additional nodes in case your cluster cannot offer any more resources in a scale-out scenario. <a data-type="xref" href="#modernized_application_with_feature_3_be">Figure 2-6</a> shows how an existing monolithic application (Legacy App) is broken down into smaller microservices (Feature 3). The legacy application and the new microservice (Feature 3) are on a service mesh on Kubernetes. In this case Feature 3 has independent scale needs and can be scaled out into a CaaS offering using Virtual Kubelet.</p>

<figure><div id="modernized_application_with_feature_3_be" class="figure">
<img src="Images/clna_0206.png" alt="clna 0206" width="1306" height="690"/>
<h6><span class="label">Figure 2-6. </span>Modernized application with Feature 3 being scaled out into CaaS using Virtual Kubelet</h6>
</div></figure>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Application Optimization"><div class="sect2" id="application_optimization">
<h2>Application Optimization</h2>

<p>The next step is to improve the application in terms not only of further cost optimization, but also of code optimization.<a data-type="indexterm" data-primary="cloud native applications" data-secondary="from VMs to" data-tertiary="application optimization" id="idm45987080320024"/><a data-type="indexterm" data-primary="virtual machines (VMs)" data-secondary="from VMs to cloud native" data-tertiary="application optimization" id="idm45987080326296"/><a data-type="indexterm" data-primary="functions" data-secondary="application optimization with" id="idm45987080318680"/> Functions really excel in short-lived compute scenarios, such as updating records, sending emails, transforming messages, and so on. To take advantage of functions, you can identify short-lived compute functionality in your service codebase and implement it using functions. A good example is an order service in which the containerized microservice does all the Create, Read, Update, and Delete (CRUD) operations, and a function sends the notification of a successfully placed order. To trigger the function, eventing or messaging systems are being used. Eventually, you could decide to build the entire order service using functions, with each function executing one of the CRUD operations.<a data-type="indexterm" data-primary="cloud native applications" data-secondary="from VMs to" data-startref="ix_clnaVMs" id="idm45987080317832"/><a data-type="indexterm" data-primary="virtual machines (VMs)" data-secondary="from VMs to cloud native" data-startref="ix_VMstoclna" id="idm45987080316600"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Microservices"><div class="sect1" id="microservices">
<h1>Microservices</h1>

<p>Microservices is a term commonly used to refer to a microservices architecture style, or the individual services in a microservices architecture.<a data-type="indexterm" data-primary="microservices" id="ix_mcroser"/> A microservices architecture is a service-oriented architecture in which applications are decomposed into small, loosely coupled services by area of functionality. It’s important that services remain relatively small, are loosely coupled, and are decomposed around business <span class="keep-together">capability</span>.</p>

<p>Microservices architectures are often compared and contrasted with monolithic architectures. Instead of managing a single codebase, a shared datastore, and data structure, as in a monolith, in a microservices architecture an application is composed of smaller codebases, created and managed by independent teams. Each service is owned and operated by a small team, with all elements of the service contributing to a single well-defined task. Services run in separate processes and communicate through APIs that are either synchronous or asynchronous message based.</p>

<p>Each service can be viewed as its very own application with an independent team, tests, builds, data, and deployments. <a data-type="xref" href="#inventory_service_in_a_microservices_arc">Figure 2-7</a> shows the concept of a microservices architecture, using the Inventory service as an example.</p>

<figure><div id="inventory_service_in_a_microservices_arc" class="figure">
<img src="Images/clna_0207.png" alt="clna 0207" width="1391" height="545"/>
<h6><span class="label">Figure 2-7. </span>Inventory service in a microservices architecture</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="Benefits of a Microservices Architecture"><div class="sect2" id="benefits_of_a_microservices_architecture">
<h2>Benefits of a Microservices Architecture</h2>

<p>A properly implemented microservices architecture will increase the release velocity of large applications, enabling businesses to deliver value to customers faster and more reliably.<a data-type="indexterm" data-primary="microservices" data-secondary="benefits of microservice architecture" id="idm45987080304408"/></p>










<section data-type="sect3" data-pdf-bookmark="Agility"><div class="sect3" id="agility">
<h3>Agility</h3>

<p>Fast, reliable deployments can be challenging with large, monolithic applications.<a data-type="indexterm" data-primary="microservices" data-secondary="benefits of microservice architecture" data-tertiary="agility" id="idm45987080299032"/><a data-type="indexterm" data-primary="agility with microservices" id="idm45987080298056"/> A deployment of a small change to a module in one feature area can be held up by a change to another feature. As an application grows, testing of the application will increase and it can take a considerable amount of time to deliver new value to stakeholders. A change to one feature will require the entire application to be redeployed and rolled forward or back if there is an issue with that change. By decomposing an application into smaller services, the time needed to verify and release changes can be reduced and deployed more reliably.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Continuous innovation"><div class="sect3" id="continuous_innovation">
<h3>Continuous innovation</h3>

<p>Companies need to move increasingly faster in order to remain relevant today. This requires<a data-type="indexterm" data-primary="microservices" data-secondary="benefits of microservice architecture" data-tertiary="continuous innovation" id="idm45987080294520"/><a data-type="indexterm" data-primary="continuous innovation (with microservices)" id="idm45987080293848"/> organizations to be agile and capable of quickly adapting to fast-changing market conditions. Companies can no longer wait years or months to deliver new value to customers: they must often deliver new value daily. A microservices architecture can make it easier to deliver value to stakeholders in a reliable way. Small independent teams are able to release features and perform A/B testing to improve conversions or user experience during even the busiest times.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Evolutionary design"><div class="sect3" id="evolutionary_design">
<h3>Evolutionary design</h3>

<p>With a large monolithic application, it can be very difficult to adopt new technologies or techniques because this will often require that the entire application be rewritten or care needs to be taken to ensure that some new dependency can run side-by-side with a previous one.<a data-type="indexterm" data-primary="microservices" data-secondary="benefits of microservice architecture" data-tertiary="evolutionary design" id="idm45987080293304"/><a data-type="indexterm" data-primary="evolutionary design (microservices)" id="idm45987080292072"/> Loose coupling and high functional cohesion is important to a system design that is able to evolve through changing technologies. By decomposing an application by features into small, loosely coupled services, it can be much easier to change individual services without affecting the entire application. Different languages, frameworks, and libraries can be used across the different services if needed to support the business.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Small, focused teams"><div class="sect3" id="small_comma_focused_teams">
<h3>Small, focused teams</h3>

<p>Structuring engineering teams at scale and keeping them focused and productive can be challenging. <a data-type="indexterm" data-primary="microservices" data-secondary="benefits of microservice architecture" data-tertiary="small, focused teams" id="idm45987080285448"/><a data-type="indexterm" data-primary="teams, small and focused, with microservices" id="idm45987080284216"/>Making people responsible for designing, running, and operating what they build can also be challenging if what you are building is heavily intertwined with what everyone else is building. It can sometimes take new team members days, weeks, or even months to get up to speed and begin contributing because they are burdened with understanding aspects of a system that are unrelated to their area of focus. By decomposing an application into smaller services, small agile teams are able to focus on a smaller concern and move quickly. It can be much easier for a new member joining because they need to be concerned with only a smaller service. Team members can more easily operate and take accountability for the services they build.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Fault isolation"><div class="sect3" id="fault_isolation">
<h3>Fault isolation</h3>

<p>In a monolithic application, a single library or module can cause problems for the entire application.<a data-type="indexterm" data-primary="fault isolation (in microservices)" id="idm45987080280472"/><a data-type="indexterm" data-primary="microservices" data-secondary="benefits of microservice architecture" data-tertiary="fault isolation" id="idm45987080280088"/> A memory leak in one module not only can affect the stability and performance of the entire application, but can often be difficult to isolate and identify. By decomposing features of the application into independent services, teams can isolate a defect in one service to that service.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Improved scale and resource usage"><div class="sect3" id="improved_scale_and_resource_usage">
<h3>Improved scale and resource usage</h3>

<p>Applications are generally scaled up or out.<a data-type="indexterm" data-primary="microservices" data-secondary="benefits of microservice architecture" data-tertiary="improved scale and resource usage" id="idm45987080278136"/><a data-type="indexterm" data-primary="scaling" data-secondary="improved scale with microservices" id="idm45987080277000"/><a data-type="indexterm" data-primary="resources" data-secondary="improved usage with microservices" id="idm45987080276040"/> They are scaled up by increasing the size or type of machine, and scaled out by increasing the number of instances deployed and routing users across these instances. Different features of an application will sometimes have different resource requirements; for example, memory, CPU, disk, and so on. Application features will often have different scale requirements. Some features might easily scale out with very few resources required for each instance, whereas other features might require large amounts of memory with limited ability to scale out. By decoupling these features into independent services, teams can configure the services to run in environments that best meet the services, individual resource and scale requirements.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Improved observability"><div class="sect3" id="improved_observability">
<h3>Improved observability</h3>

<p>In a monolithic application it can be difficult to measure and observe the individual components of an application without careful and detailed instrumentation throughout the application.<a data-type="indexterm" data-primary="observability" data-secondary="improved, with microservices" id="idm45987080268968"/><a data-type="indexterm" data-primary="microservices" data-secondary="benefits of microservice architecture" data-tertiary="improved observability" id="idm45987080270136"/> By decomposing features of an application into separate services, teams can use tools to gain deeper insights into the behavior of the individual features and interactions with other features. System metrics such as process utilization and memory usage can now easily be tied back to the feature team because it’s running in a separate process or container.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Challenges with a Microservices Architecture"><div class="sect2" id="challenges_with_a_microservices_architec">
<h2>Challenges with a Microservices Architecture</h2>

<p>Despite all the benefits of a microservices architecture, there are trade-offs, and a microservices architecture does have its own set of challenges.<a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" id="idm45987080261240"/> Tooling and technologies have begun to address some of these challenges, but many of them still remain. A microservices architecture might not be the best choice for all applications today, but we can still apply many of the concepts and practices to other architectures. The best approach often lies somewhere in between.</p>










<section data-type="sect3" data-pdf-bookmark="Complexity"><div class="sect3" id="complexity">
<h3>Complexity</h3>

<p>Distributed systems are inherently complex. <a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" data-tertiary="complexity" id="idm45987080261848"/>As we decompose the application into individual services, network calls are necessary for the individual services to communicate.<a data-type="indexterm" data-primary="networks" data-secondary="in distributed systems, fallacies of" id="idm45987080259096"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="fallacies of" id="idm45987080266616"/><a data-type="indexterm" data-primary="complexity of distributed systems" id="idm45987080265640"/> Networks calls add latency and experience transient failures, and the operations can run on different machines with a different clock, each having a slightly different sense of the current time. We cannot assume that the network is reliable, latency is zero, bandwidth is infinite, the network is secure, the topology will not change, there is one administrator, transport costs are zero, and that the network is homogenous. Many developers are not familiar with distributed systems and often make false assumptions when entering that world. The <em>Fallacies of Distributed Computing</em>, as discussed in <a data-type="xref" href="ch01.xhtml#introduction_to_cloud_native">Chapter 1</a>, is a set of assertions describing those false assumptions commonly made by developers. They were first documented by L. Peter Deutsch and other Sun Microsystems engineers and are covered in numerous blog articles. <a data-type="xref" href="ch06.xhtml#best_practices">Chapter 6</a> provides more information about best practices, tools, and techniques for dealing with the complexities of distributed systems.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Data integrity and consistency"><div class="sect3" id="data_integrity_and_consistency">
<h3>Data integrity and consistency</h3>

<p>Decentralized data means that data will often exist in multiple places with relationships spanning different systems. <a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" data-tertiary="data integrity and consistency" id="idm45987080256952"/><a data-type="indexterm" data-primary="data integrity and consistency, challenges of, in microservices" id="idm45987080256264"/><a data-type="indexterm" data-primary="consistency" data-secondary="challenges of in microservice architecture" id="idm45987080255880"/>Performing transactions across these systems can be difficult, and we need to employ a different approach to data management. One service might have a relationship to data in another service; for example, an order service might have a reference to a customer in an account service. Data might have been copied from the account service in order to satisfy some performance requirements. If the customer is removed or disabled, it can be important that the order service is updated to indicate this status. Dealing with data will require a different approach. <a data-type="xref" href="ch04.xhtml#working_with_data">Chapter 4</a> covers patterns for dealing with this.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Performance"><div class="sect3" id="performance">
<h3>Performance</h3>

<p>Networking requests and data serialization add overhead. <a data-type="indexterm" data-primary="performance" data-secondary="in microservice architectures" id="idm45987080241672"/><a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" data-tertiary="performance" id="idm45987080240824"/><a data-type="indexterm" data-primary="networks" data-secondary="networking requests for microservices" id="idm45987080247976"/>In a microservices-based architecture the number of network requests will increase. Remember, components are libraries that are no longer making direct calls; this is happening over a network. A call to one service can result in a call to another dependent service. It might take a number of requests to multiple services in order to satisfy the original request. We can implement some patterns and best practices to mitigate potential performance overhead in a microservices architecture, which we look at in <a data-type="xref" href="ch06.xhtml#best_practices">Chapter 6</a>.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Development and testing"><div class="sect3" id="development_and_testing">
<h3>Development and testing</h3>

<p>Development can be a bit more challenging because the tools and practices used today don’t work with a microservices architecture.<a data-type="indexterm" data-primary="development" data-secondary="challenges in microservice architectures" id="idm45987080235464"/><a data-type="indexterm" data-primary="testing" data-secondary="challenges in microservice architectures" id="idm45987080238952"/><a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" data-tertiary="development and testing" id="idm45987080238040"/> Given the velocity of change and the fact that there are many more external dependencies, it can be challenging to run a complete test suite on versions of the dependent services that will be running in production.<a data-type="indexterm" data-primary="continuous integration/continuous deployment (CI/CD) pipeline" id="idm45987080234216"/> We can implement a different approach to testing to address these challenges, and a proper Continuous Integration/Continuous Deployment (CI/CD) pipeline will be necessary. Development tooling and test strategies have evolved over the years to better accommodate a microservices architecture. <a data-type="xref" href="ch05.xhtml#devops">Chapter 5</a> covers many of the tools, techniques, and best practices.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Versioning and integration"><div class="sect3" id="versioning_and_integration">
<h3>Versioning and integration</h3>

<p>Changing an interface in a monolithic application can require some refactoring, but the changes are often built, tested, and deployed as a single cohesive unit.<a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" data-tertiary="versioning and integraton" id="idm45987080230808"/><a data-type="indexterm" data-primary="dependencies" data-secondary="in microservice architectures" id="idm45987080245688"/><a data-type="indexterm" data-primary="versioning" data-secondary="in microservice architectures" id="idm45987080244728"/><a data-type="indexterm" data-primary="integration" data-secondary="in microservice architectures" id="idm45987080229864"/> In a microservices architecture service, dependencies are changing and evolving independently of the consumers. Careful attention to forward and backward compatibility is necessary when dealing with service versioning. In addition to maintaining forward and backward compatibility with service changes, it might be possible to deploy an entirely new version of the service, running it side-by-side with the previous version for some period of time. <a data-type="xref" href="ch05.xhtml#devops">Chapter 5</a> explores service versioning and integration <span class="keep-together">strategies.</span></p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Monitoring and logging"><div class="sect3" id="monitoring_and_logging">
<h3>Monitoring and logging</h3>

<p>Many organizations struggle with monitoring and logging of monolithic applications, even when they are using a common shared logging library.<a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" data-tertiary="monitoring and logging" id="idm45987080222728"/><a data-type="indexterm" data-primary="monitoring" data-secondary="in microservice architectures" id="idm45987080221752"/><a data-type="indexterm" data-primary="logging" data-secondary="in microservice architectures" id="idm45987080224904"/> Inconsistencies in naming, data types, and values make it difficult to correlate relevant log events. In a microservices architecture, when relevant events span multiple services—all potentially using different logging implementations—correlating these events can be even more challenging. Planning and early attention to the importance of logging and monitoring can help address much of this, which we examine in <a data-type="xref" href="ch05.xhtml#devops">Chapter 5</a>.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Service dependency management"><div class="sect3" id="service_dependency_management">
<h3>Service dependency management</h3>

<p>With a monolithic application, dependencies on libraries are generally compiled into a single package and tested.<a data-type="indexterm" data-primary="dependencies" data-secondary="service dependency management for microservices" id="idm45987080220824"/><a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" data-tertiary="service dependency management" id="idm45987080220088"/> In a microservices architecture, service dependencies are managed differently, requiring environment-specific routing and discovery. Service discovery and routing tools and technologies have come a long way in addressing these challenges. <a data-type="xref" href="ch03.xhtml#designing_cloud-native_applications">Chapter 3</a> looks at these in depth.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Availability"><div class="sect3" id="availability">
<h3>Availability</h3>

<p>Although a microservices architecture can help isolate faults to individual services, if other services or the application as a whole is unable to function without that service, the application will be unavailable.<a data-type="indexterm" data-primary="availability" data-secondary="challenges in microservice architectures" id="idm45987080213448"/><a data-type="indexterm" data-primary="microservices" data-secondary="challenges of microservice architecture" data-tertiary="availability" id="idm45987080212504"/> As the number of services increases, the chance that one of those services experiences a failure also increases. Services will need to implement resilient design patterns, or some functionality downgraded in the event of a service outage. <a data-type="xref" href="ch06.xhtml#best_practices">Chapter 6</a> covers patterns and best practices for building highly available applications and provides more detail on the specific challenges.<a data-type="indexterm" data-primary="microservices" data-startref="ix_mcroser" id="idm45987080208280"/></p>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="summary-id1">
<h1>Summary</h1>

<p>Every application, whether cloud native or traditional, needs infrastructure on which to be hosted, technology that addresses pain points with development and deployment, and an architectural style that helps with achieving the business objectives, such as time to market. The goal of this chapter was to provide the basic knowledge for cloud native applications. By now you should understand that there are various container technologies with different isolation levels, how functions relate to containers, and that serverless infrastructure does not always need to be FaaS. Further, you should have a basic understanding of microservices architectures and of how you can migrate and modernize an existing application to be a cloud native application.</p>

<p>The upcoming chapters build on this knowledge and go deep into how to design, develop, and operate cloud native applications.</p>
</div></section>







</div></section></div>



  </body></html>