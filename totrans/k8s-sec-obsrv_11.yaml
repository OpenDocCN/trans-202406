- en: Chapter 11\. Threat Defense and Intrusion Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we will explore how you can implement threat defense for your
    Kubernetes cluster. We have covered the stages of your Kubernetes deployment (build,
    deploy, runtime) in earlier chapters. This chapter focuses on threat defense,
    which is security for the runtime stage. We will cover the following concepts
    to help you understand threat defense in a Kubernetes cluster and why you need
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Threat defense for a Kubernetes cluster, including why you need it and how it
    differs from traditional security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intrusion detection for Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced threat defense techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s explore each of these in detail. We start with threat defense and why
    it is important.
  prefs: []
  type: TYPE_NORMAL
- en: Threat Defense for Kubernetes (Stages of an Attack)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To understand threat defense, a great place to start is to review the cybersecurity
    kill chain, which breaks down an attack into several stages. This is then used
    to build a strategy to defend against the attack. The cyber kill chain has the
    following stages:'
  prefs: []
  type: TYPE_NORMAL
- en: Reconnaissance
  prefs: []
  type: TYPE_NORMAL
- en: Adversaries probe the target and gather information.
  prefs: []
  type: TYPE_NORMAL
- en: Weaponization
  prefs: []
  type: TYPE_NORMAL
- en: The adversary creates a method to attack, which could be a new vulnerability,
    a variant of an existing vulnerability, or a simple exploit of an insecure configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Delivery
  prefs: []
  type: TYPE_NORMAL
- en: The adversary creates a method to deliver the vulnerability or exploit to the
    target or a location that can be used to attack the target.
  prefs: []
  type: TYPE_NORMAL
- en: Exploitation
  prefs: []
  type: TYPE_NORMAL
- en: The adversary implements methods to trigger the attack.
  prefs: []
  type: TYPE_NORMAL
- en: Installation
  prefs: []
  type: TYPE_NORMAL
- en: The adversary installs the malware and typically software to create a backdoor
    to communicate with the malware.
  prefs: []
  type: TYPE_NORMAL
- en: Command and Control
  prefs: []
  type: TYPE_NORMAL
- en: The adversary establishes a communication channel with the malicious software
    to control the software.
  prefs: []
  type: TYPE_NORMAL
- en: Actions on Objective
  prefs: []
  type: TYPE_NORMAL
- en: The adversary achieves the intended outcome of the attack (e.g., stealing data,
    encryption of data, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: 'Several organizations have adapted this framework to incorporate real-world
    attacks and more use cases. Microsoft has adapted it for Kubernetes as described
    in its blog post [“blog"Secure Containerized Environments with Updated Threat
    Matrix for Kubernetes”](https://oreil.ly/gebGs). Let’s review the kill-chain stages
    (threat matrix) that are specific to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: Initial access
  prefs: []
  type: TYPE_NORMAL
- en: The adversary uses various exposed interfaces in your Kubernetes deployments
    (for example, Kubeflow) via stolen credentials, compromised images, or other application
    vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Execution
  prefs: []
  type: TYPE_NORMAL
- en: The adversary executes a malicious command or software in your cluster. There
    are several ways this can happen; some known techniques are creating a new container
    in your cluster, running an additional container in any pod as a sidecar, and
    using a known application vulnerability to execute malicious commands.
  prefs: []
  type: TYPE_NORMAL
- en: Persistence
  prefs: []
  type: TYPE_NORMAL
- en: The adversary will try to persist the malicious software in the Kubernetes cluster
    so it can be accessed at a later time. This is typically achieved by creating
    a writage storage path on the host, leveraging Kubernetes scheduled jobs (known
    as cron jobs) to periodically run malicious software, or in some cases, compromising
    the Kubernetes admission controller so requests to the API server can be tampered
    with to carry out an attack. In this stage adversaries will also try to establish
    a backdoor communication channel to their control server so they can control the
    malicious software. This is known as a command-and-control server (C&C server).
  prefs: []
  type: TYPE_NORMAL
- en: Privilege escalation
  prefs: []
  type: TYPE_NORMAL
- en: The adversary gains privileged access by leveraging a resource in your cluster
    that has privileged access. For example, they might run malicious software in
    a container with privileged access by exploiting a vulnerability in the privileged
    container.
  prefs: []
  type: TYPE_NORMAL
- en: Defense evasion
  prefs: []
  type: TYPE_NORMAL
- en: The adversary works to keep the attack undetected by using techniques like clearing
    logs or deleting events, so detection systems using logs and events do not detect
    the presence of malicious activity. Another technique that is used is to exploit
    a vulnerability in only one pod of a Kubernetes deployment backed by many pods,
    and use that to further the attack.
  prefs: []
  type: TYPE_NORMAL
- en: Credential access
  prefs: []
  type: TYPE_NORMAL
- en: The adversary works to get access to credentials (Kubernetes secrets) in your
    cluster. In case you are using managed services, the cloud provider offers a token
    to access cloud resources, and this token is accessible to certain privileged
    pods and service accounts. The adversary will use impersonation or privilege escalation
    to gain access to the credentials and then use access to cloud resources to further
    the attack.
  prefs: []
  type: TYPE_NORMAL
- en: Discovery
  prefs: []
  type: TYPE_NORMAL
- en: The adversary will work to do a reconnaissance of the cluster network to understand
    what is running in your cluster. This can be achieved by using tools for network
    mapping like [Nmap](https://nmap.org) on Linux systems, or access to the Kubenetes
    dashboard. This stage is the precursor to an important stage of the attack where
    adversaries can move around in your cluster to find what they are seeking.
  prefs: []
  type: TYPE_NORMAL
- en: Lateral movement
  prefs: []
  type: TYPE_NORMAL
- en: By the time the attack reaches this stage, the attack is fairly advanced, and
    the adversary has an established presence; they now will use the installed malicious
    software to access other pods and resources in the network. A couple of common
    techniques are to spoof IP addresses or domain names of other pods and impersonate
    other pods to get past segmentation rules inside the cluster. The adversaries
    also look for other applications running inside the cluster, as they now have
    access to them. During this stage the malicious software is communicating with
    the command-and-control server to get instructions to further the attack. In this
    stage adversaries rely on overloading well-known protocols like DNS or HTTP to
    send command-and-control requests as a part of these protocols, which allows them
    to bypass perimeter security–based controls as the traffic looks like a normal
    DNS or HTTP request.
  prefs: []
  type: TYPE_NORMAL
- en: Impact
  prefs: []
  type: TYPE_NORMAL
- en: This is the final stage of the attack, where the outcome is usually the stealing
    of sensitive data. This is achieved by a technique called data exfiltration, encryption
    of data for ransomware, or even using resources for cryptomining.
  prefs: []
  type: TYPE_NORMAL
- en: Threat defense comprises a set of techniques that help you defend against each
    of these stages and enable you to defend against attacks. It can be overwhelming
    to think about all these stages and techniques adversaries can use. We want to
    mention that while adversaries need to succeed in most (if not all) of these stages
    to carry out a successful attack, you only need to block them in any one stage
    to thwart the attack. So the odds are in your favor. Understanding these stages
    and how they apply to Kubernetes is a first step in building an effective defense
    mechanism. Adversaries are always innovating, and therefore you should focus on
    all the stages and use tools and techniques relevant to each stage to give yourself
    the greatest chance to successfully thwart attacks.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.xhtml#infrastructure_security), we covered infrastructure
    security, showing you how to create secure infrastructure for running your workloads.
    In [Chapter 3](ch03.xhtml#workload_deployment_controls), we covered best practices
    and techniques you can use to securely deploy workloads. [Chapter 4](ch04.xhtml#workload_runtime_security)
    covers security policies you can apply to your workloads to secure the workload
    runtime environment, and [Chapter 6](ch06.xhtml#observability_and_security) covers
    how you can apply network policy to implement network access control for your
    workloads. We recommend you review these chapters in the context of the kill-chain
    stages described here. You will find that these techniques are very effective
    with the initial access, privilege escalation, credential access, persistence,
    and execution stages.
  prefs: []
  type: TYPE_NORMAL
- en: We will now describe tools and techniques you can use to secure the other stages
    of the kill chain. It is important to note that Kubernetes is a distributed system
    and its cluster network is crucial to its operation; therefore, securing the network
    is a very effective technique. For example, a successful privilege escalation
    or a successful exploit of an application vulnerability is rendered ineffective
    if the adversary cannot further the attack due to an inability to use the cluster
    network for discovery, command and control, lateral movement, or data exfiltration.
    It is not enough to have network segmentation based on IP addresses/ports, as
    adversaries will find ways to further an attack even with techniques like network
    segmentation protecting your cluster. For example, you need to allow HTTP traffic
    to your service and pods backing the service, so the attack can be a part of the
    HTTP header that triggers a privilege escalation.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered concepts for threat defense, let’s explore intrusion
    detection.
  prefs: []
  type: TYPE_NORMAL
- en: Intrusion Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section we will cover intrusion detection and how it applies to Kubernetes
    clusters. To understand this, we will review the various methods of intrusion
    and the role of an intrusion detection system.
  prefs: []
  type: TYPE_NORMAL
- en: Intrusion Detection Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An intrusion detection system (IDS), as the name suggests, is a system that
    monitors network activity, detects anomalous patterns, and reports suspicious
    behavior. These systems also monitor violations to existing controls (like network
    policy, host hardening) and report these violations. The response actions for
    an IDS are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Alerting
  prefs: []
  type: TYPE_NORMAL
- en: Generate an alert and send it to a SIEM for further analysis and action.
  prefs: []
  type: TYPE_NORMAL
- en: Intrusion prevention
  prefs: []
  type: TYPE_NORMAL
- en: The system takes action to prevent the intrusion by leveraging existing controls
    (e.g., network policies, Kubernetes pod security policies, host hardening policies)
    and redirecting the attack to canary resources especially set up to analyze these
    types of attack. When an IDS is also able to prevent the intrusion, it is called
    an intrusion prevention system (IPS).
  prefs: []
  type: TYPE_NORMAL
- en: A good intrusion detection system should be able to associate a set of related
    anomalies by tracking the behavior of a system. We recommend you review user and
    entity behavior analytics (UEBA) and how it applies to security. [Microsoft Azure
    UEBA](https://oreil.ly/LqYWk) is an excellent resource for you to review. Please
    note that for Kubernetes, entity behavioral analytics is applicable. The details
    of how to implement it are outside the scope of this book, but UEBA helps in reducing
    the number of alerts and generating high-fidelity alerts. Please note that more
    alerts is not necessarily good; they cause downstream systems (e.g., SIEMs) to
    be immune to alerts. Later we will review how to leverage machine learning systems
    to generate high-fidelity alerts.
  prefs: []
  type: TYPE_NORMAL
- en: We will now review intrusion detection methods and how they apply to Kubernetes
    clusters.
  prefs: []
  type: TYPE_NORMAL
- en: IP Address and Domain Name Threat Feeds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As explained in the cybersecurity kill chain, adversaries will often use malicious
    software to contact a server that is controlled by them. These servers are used
    to remotely control the malicious software, get information about the system,
    download more software, and further the attack. Security research teams around
    the world review attacks and identify known C&C servers by IP address/domains.
    These are published as threat feeds and as a part of the indicators of compromise
    and are regularly updated. There are several well-known threat feeds both open
    source and commercial. [STIX](https://oreil.ly/6mw8s) is a well-known standard
    to describe threat intelligence, and [TAXII](https://oreil.ly/w9DSn) is the standard
    to deliver the intelligence. You can find several open source engines that parse
    the STIX and TAXII feeds and provide intelligence (e.g., AlienVault). [Feodo tracker](https://oreil.ly/c0ccW)
    and [Snort](https://oreil.ly/1isJX) are examples of open source feeds that provide
    IP address block lists.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes adversaries will use VPNs (virtual private networks), which are overlay
    networks that run over physical networks and are useful to conceal a user’s location.
    Tor is another well-known overlay network that is used for this purpose. Similar
    to threat feeds for C&C servers, feeds are available for known [VPNs](https://oreil.ly/RGtxT)
    and [IPs from the Tor network](https://oreil.ly/VHGkZ).
  prefs: []
  type: TYPE_NORMAL
- en: We will now cover how you can use these feeds in your Kubernetes cluster to
    implement IDS/IPS. [Figure 11-1](#implementing_idssolidusips_using_threat) shows
    a sample implementation of applying suspicious IP addresses and domains in your
    Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ksao_1101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-1\. Implementing IDS/IPS using threat feeds
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 11-1](#implementing_idssolidusips_using_threat) shows what you need
    to implement support for threat feeds in your cluster and also describes the high-level
    workflow to achieve IDS/IPS capabilities. The figure shows the following components
    as a part of your Kubernetes cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: Threat feed controller
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This component is responsible for retrieving threat feeds from a configured
    source (typically a URL). This can be implemented in many ways. For the purposes
    of this discussion, we assume that is a pod that watches a configuration resource
    (example in a moment) and reaches out to the specified URL and stores the threat
    feed data in the Kubernetes datastore for other components. The following is an
    example of configuration for the threat feed controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, the threat feed controller is configured to pull the threat
    feed from the specified URL and then stores the list of IP addresses as a custom
    Kubernetes resource named globalnetworkset. This is then used by the network policy
    implementation to enforce policies based on this resource. The following is an
    example of a policy that can be defined using the globalnetworkset resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Network policy engine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the component that implements network policies in your cluster and is
    used to define policies to block traffic to and from IP addresses that are a part
    of threat feeds. Please note that an IP address list can contain a large number
    of IP addresses and can change periodically. Therefore, the network policy implementation
    you choose should scale based on this requirement. As a hint, we recommend you
    pick an engine that supports the ipsets extension in an iptables-based dataplane,
    where matching sets of IP addresses is optimized. If you are using an eBPF-based
    dataplane, please ensure the implementation has support for eBPF maps to implement
    functionality equivalent to ipsets.
  prefs: []
  type: TYPE_NORMAL
- en: Log processing engine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This component is responsible for reporting flow logs from your cluster that
    contain IP addresses that match any IP addresses that are part of the threat feed
    and generate an alert. Please note this can be a resource-intensive operation,
    given the large amount of flow data. One way to address this is to have the network
    policy engine add an annotation to the flow log to name the feed that contained
    the IP address in the flow log when the dataplane detects a match. It is very
    efficient to do this operation inline instead of doing a match after data is collected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we understand the various components of the IDS, let’s review the
    step-by-step operation:'
  prefs: []
  type: TYPE_NORMAL
- en: The threat feed controller polls the threat feed periodically.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The threat feed controller processes the feed and creates the globalnetworkset
    resource in the Kubernetes datastore for the threat feed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The network policy engine and the log processing engine read the threat feed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a network policy is defined, the network policy engine implements the network
    policy for the threat feed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The log engine processes flow logs from the flow log datastore and generates
    alerts for flows matching IP addresses in the threat feed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In step 4, we are able to prevent an intrusion, and step 5 is where we can detect
    an intrusion.
  prefs: []
  type: TYPE_NORMAL
- en: Special Considerations for Domain Name Feeds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned before, threat feeds can be a list of IP addresses or domain names.
    In case of domain names, the network policy engine must support domain name–based
    policies, and the log processing engine must support capturing domain names in
    flow logs and matching domain names from feeds in a flow log.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the technique described detects and enables controls to protect against
    malicious activity, so it makes the implementation an intrusion prevention system.
  prefs: []
  type: TYPE_NORMAL
- en: Deep packet inspection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep packet inspection (DPI) is an intrusion detection technique where network
    traffic is inspected and matched against known malicious network traffic patterns.
    This requires inspection of the packet beyond Layer 3/Layer 4 and understanding
    of application protocols (e.g., HTTP, MySQL, etc.). Similar to threat feeds for
    IP and domains, signatures-based feeds are also available. [OWASP Top 10](https://oreil.ly/270Fw)
    and [SANs Top 25](https://oreil.ly/OmO85) are signatures for well-known application
    software risks and software vulnerabilities that can be used to detect malicious
    traffic in network and application layers of the packet. When you think about
    implementing DPI in your cluster, you need to consider a few factors.
  prefs: []
  type: TYPE_NORMAL
- en: First, where should you implement DPI? One option is to implement it at the
    ingress, which is the point where traffic enters/exits the cluster. Ingress is
    a resource in Kubernetes that allows users to expose services to clients outside
    the cluster. This topic is covered in depth in [Chapter 8](ch08.xhtml#managing_trust_across_teams).
    For this discussion we assume that the services are exposed as URLs. So in this
    case you would implement DPI at the ingress (e.g., load balancers or on nodes
    for traffic going through node ports). This is a good option, but in this scenario
    the limitation is that you can detect a malicious network flow, but the information
    is not complete, as the detection is early in the cycle. You will not have visibility
    into which pod the malicious flow was destined to, and will have to review all
    possible destination pods and then co-relate the activity of each pod backing
    the service to understand the attack. Also, if the attack uses another mechanism
    to trigger the exploit (e.g., an API server, a kube-proxy vulnerability, or a
    node OS image vulnerability), the malicious flow originates inside the cluster
    and will not be detected at the ingress. Therefore, it is better to implement
    DPI for the service inside the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: So if you choose the option to implement DPI inside the cluster for each service,
    you need to consider that the amount of traffic inside the cluster is very large
    due to the distributed nature of Kubernetes. This presents a challenge as DPI
    involves packet parsing and can potentially impact latency for applications as
    well as increase the resource utilization. In order to address the application
    latency challenge, we recommend you consider DPI as a mechanism to detect malicious
    activity and not prevent the attack. This means the DPI engine does not need to
    be inline and can work with a copy of each packet in the flow; the original packet
    flow is not impacted by this, and hence there is no impact to latency-sensitive
    applications. There is still the concern about resource utilization due to packet
    parsing. In order to address this, we recommend you use context in the Kubernetes
    cluster to select traffic for services that need DPI. This could be as simple
    as labeling services that are critical and have compliance requirements and enabling
    DPI using label-based selectors, or you can use DPI as a response action to anomalous
    traffic that is identified by a SIEM or your logging and alerting engine.
  prefs: []
  type: TYPE_NORMAL
- en: Another important consideration is that the DPI engine needs traffic to be unencrypted,
    so if you are using encryption for traffic inside the cluster (e.g., HTTPS), you
    need to implement decryption along with your DPI engine or choose an encryption
    technology like WireGuard, where you can implement DPI prior to encryption for
    egress traffic and after decryption for ingress traffic. You should consider a
    proxy like Envoy that allows traffic to be redirected to it, decrypted, inspected,
    encrypted, and sent to its destination.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have established that DPI needs to be implemented inside the cluster
    as an IDS mechanism and needs to be selectively enabled to limit resource consumption,
    let’s explore a sample reference architecture for a DPI implementation for your
    Kubernetes cluster. [Figure 11-2](#implementation_of_dpi_using_envoy) shows a
    reference implementation. Before we review the reference implementation, we want
    to introduce some well-known IDS engines that are available for you to integrate
    in your cluster. [Snort](https://oreil.ly/yDteh) and [Suricata](https://oreil.ly/1Ka1q)
    are a couple of open source IDS engines that are available; however, you can choose
    any IDS engine that is suitable for your use case, including implementing your
    own IDS engine.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ksao_1102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-2\. Implementation of DPI using Envoy
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 11-2](#implementation_of_dpi_using_envoy) shows a Kubernetes cluster
    namespace that has a few microservices that are part of an application. The figure
    shows Envoy is deployed as a daemonset on every node. Envoy is a well-known proxy
    that is used in Kubernetes clusters to proxy traffic for analysis and for additional
    controls. We recommend you use Envoy as a transparent proxy, where it terminates
    connections destined to a pod backing a service and after analysis sends the traffic
    to the pod backing a service. In this case for the second microservice, the DPI
    engine is implemented as an integration to Envoy, and Envoy is configured to redirect
    traffic destined for pods backing the service to itself. DPI is then performed,
    and Envoy takes care of completing the connection. The transparent mode for Envoy
    means that the application sees no difference in the packet (e.g., TCP/IP header).
    As discussed before, if a malicious flow is detected by the DPI engine, the resulting
    alert will show the pod that received the flow, and it is then trivial to examine
    activity by that pod and co-relate it to the malicious flow. In [Figure 11-2](#implementation_of_dpi_using_envoy),
    DPI is enabled for traffic destined to one service as an example. DPI can be enabled
    for any service or a combination of pods; the approach is similar, but the difference
    is in how Envoy is configured for traffic redirection.'
  prefs: []
  type: TYPE_NORMAL
- en: We recommend that you use Envoy with your DPI engine, but there are other ways
    to integrate a DPI engine in your Kubernetes cluster. For example, if you have
    a cluster running an eBPF dataplane, you can get copies of the packet in the BPF
    program and send them to the IDS engine for analysis. Likewise, if you are using
    [VPP](https://fd.io) as the dataplane, it is also possible to integrate a DPI
    engine to inspect traffic.
  prefs: []
  type: TYPE_NORMAL
- en: You can choose the option that works for you, but it is important that you consider
    integration of a DPI engine in your Kubernetes cluster for signature-based malware
    detection. Next, let’s examine logging and visibility and its role in the threat
    defense strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Logging and visibility
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A very important part of security is visibility of the activity in your cluster
    (e.g., pod creation, Kubernetes resource access/changes, application activity,
    network activity). This is achieved by enabling logging in your cluster. We cover
    log collection and metrics collection in detail in [Chapter 5](ch05.xhtml#observability-id000002).
    For this section we want to reiterate the following as key aspects of logging
    and visibility:'
  prefs: []
  type: TYPE_NORMAL
- en: Traditional logging for network flows with the five-tuple is insufficient. You
    need to use a tool that supports Kubernetes context-rich logging where network
    flows between pods, deployments, replica sets, and services are part of the log
    collected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logs at collection time need to be annotated with Kubernetes metadata like labels,
    policies in use, node information, and even process information (processes running
    in the container). This is important due to the ephemeral nature of Kubernetes;
    all of these change, and it is difficult to associate a malicious network flow
    with Kubernetes metadata when the network flows and the Kubernetes metadata are
    collected independent of each other.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DNS activity logs are critical and must also be annotated with Kubernetes metadata
    as described earlier for network flow logs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application protocol–based flow logs (e.g., HTTP header, MySQL) are also critical
    and again must be collected with Kubernetes metadata.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, Kubernetes audit logs (activity logs) are very important and must be
    collected, as these will help detect abnormal activity by malicious users (e.g.,
    repeated denied access to a resource, creation of a service account, etc.).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are several tools and mechanisms available to you to implement log collection.
    The cloud providers have logging capabilities (e.g., Stackdriver in Google, CloudWatch
    in AWS); you can also choose to implement logging using tools like Sysdig, Datadog,
    and Calico Enterprise, which offer logging capabilities with Kubernetes context.
    In addition to the log collection described earlier, the tool you choose must
    support the following simple capabilities that are critical to your IDS strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: The tool must support an alerting capability that allows you to query logs and
    set up alerts for rule-based anomalies (e.g., excessive NXDOMAIN requests, imbalance
    in network throughput for a given protocol like HTTP or DNS between inbound and
    outbound traffic, unexpected connections to certain pods from certain namespaces,
    excessive network policy denied logs).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tools must support the baselining of various metrics (e.g., number of connections
    to a service, HTTP requests from a rare user-agent in the header) using basic
    machine learning techniques and report anomalies as alerts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tools must support forwarding logs and alerts to an external SIEM (like
    Splunk, QRadar, Sumo Logic) or the cloud provider’s security center (Azure Security
    Center).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previous sections covered the collection and analysis of logs. While logging
    is available in most Kubernetes environments, you need to ensure that the tool
    you choose to implement logging is effective for your IDS strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Threat Defense Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section we will cover some advanced threat defense techniques you can
    use in your cluster. These are techniques that are designed to be effective in
    a Kubernetes environment, especially for detecting the lateral movement and exfiltration
    stages of the attack life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Canary Pods/Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The use of honeypots is a well-known technique to detect bad actors within your
    cluster and gain insight on what they are doing by exposing simulated or intentionally
    vulnerable applications in your cluster and monitoring access to these applications.
    These applications act as a canary to notify the blue team of the intrusion and
    stall the attacker’s progress from reaching actual sensitive applications and
    data. Once the blue team is aware of the situation, the attack can be traced back
    to the initial vector. The attack can then be contained and even removed from
    the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Applying this technique in a Kubernetes environment works exceedingly well due
    to the declarative nature of applying manifests to deploy workloads. Whether the
    cluster is standalone or part of a complex pipeline, workload communications are
    defined by the application’s code. Any communication that’s not defined can be
    deemed suspicious at a minimum, and the source resource may have been compromised.
    By introducing fake workloads and services around production workloads, when a
    workload gets compromised, the attacker cannot differentiate between other real
    and fake workloads. The asymmetric knowledge between the attacker and the cluster
    operator makes it easy to detect lateral movement from compromised workloads.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 11-3](#sample_implementation_of_honeypots_in_a) shows an example of
    how this is achieved in a Kubernetes cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ksao_1103.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-3\. Sample implementation of honeypots in a Kubernetes cluster
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Calico Enterprise has a honeypots feature that provides a supplementary detection
    method when strict network policies or monitoring is not feasible. Calico Enterprise
    honeypots work by deploying canary workloads and services in sensitive namespaces
    and monitoring for access. By leveraging Calico Enterprise’s monitoring and alerting
    capabilities, any connections made to these canary workloads will generate an
    alert and can be traced back to the source. Canary traffic should be inspected
    using a DPI engine to provide signature-based detection to provide high-fidelity
    alerts and significantly reduce false positives.
  prefs: []
  type: TYPE_NORMAL
- en: DNS-Based Attacks and Defense
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you look at activity in a Kubernetes cluster, DNS is critical to your applications
    that are running. Kubernetes supports DNS as an infrastructure, and DNS support
    is available for using DNS names for pods and services. CoreDNS is the recommended
    DNS server for your Kubernetes cluster. Since DNS is critical to cluster operation,
    DNS traffic needs to be allowed inside the cluster and even for external lookups.
    This makes DNS an attractive option for adversaries to target. In this section
    we will cover domain generation algorithm (DGA) attacks that are used by adversaries
    to establish a connection to their command-and-control center and then for exfiltration
    of data.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 11-4](#dga_based_attack) shows how a domain generation attack works.
    The adversary first downloads an exploit inside the cluster that uses a known
    seed and an algorithm to generate domain names. The exploit then queries the algorithm-generated
    domain names. The same algorithm is run to spin up a DNS server that responds
    to DNS queries, and this cycle repeats till the client and the server domains
    match. Upon a successful match, the cluster has established a successful connection
    to the command-and-control server for the malware.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ksao_1104.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-4\. DGA-based attack
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Since domain names are generated randomly using an algorithm and the queries
    are legitimate DNS queries, it is not possible to detect these types of attacks
    using DNS threat feeds or at the perimeter using DPI. Also, the fact that there
    is a relatively large amount of DNS activity in the cluster means it is easy for
    the malware to hide its activity inside the cluster. The way to detect these types
    of attacks is to use a machine learning technique that can predict a malicious
    domain just by analyzing the domain name. Another mechanism that can be effective
    is to use machine learning to baseline the number of DNS responses that do not
    resolve to a valid server and report an anomaly if there is an increase in such
    failed DNS queries.
  prefs: []
  type: TYPE_NORMAL
- en: You can implement a DGA detection mechanism by having the security research
    team collaborate with the data science team to build this mechanism. Calico Enterprise
    provides a DGA implementation integrated with its alerting engine.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we covered how you can implement threat defense in your Kubernetes
    cluster. The following are the key takeaways from the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The techniques presented are based on our current research, and this area is
    constantly evolving, with adversaries using newer techniques and security teams
    working on solutions to counter these threats. We recommend your security team
    focus on threats seen, analyze them to evaluate if they are applicable to Kubernetes,
    and work on mitigation techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes is a new technology, and we are starting to see it become a focus
    area for adversaries, so an effective threat defense strategy is required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s very important to understand the cybersecurity kill chain and how it applies
    to Kubernetes in order to build an effective threat defense strategy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important for you to apply threat feeds and DPI-based techniques to traffic
    inside your cluster to detect attacks that originate inside the cluster. It is
    not adequate to rely on these techniques being applied only at the perimeter,
    as traffic originating inside the cluster may not traverse through devices at
    the perimeter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Honeypots and DGA-based attacks are examples of advanced threat defense techniques
    for your Kubernetes cluster that you should implement to thwart sophisticated
    attacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
