<html><head></head><body><section data-pdf-bookmark="Chapter 4. Observability" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch_monitoring">&#13;
<h1><span class="label">Chapter 4. </span>Observability</h1>&#13;
&#13;
&#13;
<p>This chapter is dedicated to observing Node.js services that run on remote machines. Locally, tools like the debugger or <code>console.log()</code> make this a straightforward process. However, once a service is running in a faraway land, you’ll need to reach for a different set of tools.</p>&#13;
&#13;
<p>When debugging locally, you’re usually concerned with a single request. You might ask yourself, “When I pass this value into a request, why do I get that value in the response?” By logging the inner workings of a function, you gain insight into why a function behaved in an unanticipated way. This chapter looks at technologies useful for debugging individual requests as well. <a data-type="xref" href="#ch_monitoring_sec_log">“Logging with ELK”</a> looks at log generation, which is a way to keep track of information on a per-request basis, much like you might print with <code>console.log()</code>. Later, <a data-type="xref" href="#ch_monitoring_sec_trace">“Distributed Request Tracing with Zipkin”</a> looks at a tool for tracking requests as they’re passed around, associating related logs generated by different services.</p>&#13;
&#13;
<p>You often need insight into situations that wouldn’t normally be considered a hard bug when dealing with production traffic. For example, you might have to ask, “Why are HTTP requests 100ms slower for users created before April 2020?” Such timing might not be worrying with a single request, but when such metrics are considered in aggregate over many requests, you’re able to spot trends of negative performance. <a data-type="xref" href="#ch_monitoring_sec_metrics">“Metrics with Graphite, StatsD, and Grafana”</a> covers this in more detail.</p>&#13;
&#13;
<p>These tools mostly display information passively in a dashboard of some sort, which an engineer can later consult to determine the source of a problem. <a data-type="xref" href="#ch_monitoring_sec_alert">“Alerting with Cabot”</a> covers how to send a warning to a developer when an application’s performance dips below a certain threshold, thus allowing the engineer to &#13;
<span class="keep-together">prevent</span> an outage before it happens.</p>&#13;
&#13;
<p>So far these concepts have been reactive, where a developer must look at data captured from an application. Other times it’s necessary to be more proactive. <a data-type="xref" href="#ch_monitoring_sec_health">“Health Checks”</a> covers how an application can determine if it’s healthy and able to serve requests or if it’s unhealthy and deserves to be terminated.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Environments" data-type="sect1"><div class="sect1" id="ch_monitoring_sec_env">&#13;
<h1>Environments</h1>&#13;
&#13;
<p><em>Environments</em> are a concept <a data-primary="monitoring" data-secondary="environments" data-type="indexterm" id="mon_env"/><a data-primary="environments" data-type="indexterm" id="env"/>for differentiating running instances of an application, as well as databases, from each other. They’re important for various reasons, including choosing which instances to route traffic to, keeping metrics and logs separate (which is particularly important in this chapter), segregating services for security, and gaining confidence that a checkout of application code is going to be stable in one &#13;
<span class="keep-together">environment</span> before it is deployed to production.</p>&#13;
&#13;
<p>Environments should remain <a data-primary="environments" data-secondary="segregating" data-type="indexterm" id="idm46291190097416"/>segregated from one another. If you control your own hardware, this could mean running different environments on different physical servers. If you’re deploying your application to the cloud, this more likely means setting up different VPCs (Virtual Private Clouds)—a concept supported by both AWS and GCP.</p>&#13;
&#13;
<p>At an absolute minimum, any application <a data-primary="environments" data-secondary="production" data-type="indexterm" id="idm46291190095544"/><a data-primary="production environment" data-type="indexterm" id="idm46291190094568"/>will need at least a single <em>production</em> environment. This is the environment responsible for handling requests made by public users. However, you’re going to want a few more environments than that, especially as your application grows in complexity.</p>&#13;
&#13;
<p>As a convention, Node.js applications generally <a data-primary="environment variables" data-secondary="NODE_ENV" data-type="indexterm" id="idm46291190092632"/><a data-primary="NODE_ENV environment variable" data-type="indexterm" id="idm46291190091656"/>use the <code>NODE_ENV</code> environment variable to specify which environment an instance is running in. This value can be set in different ways. For testing, it can be set manually, like with the following example, but for production use, whatever tool you use for deploying will abstract this process away:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code><code class="nb">export </code><code class="nv">NODE_ENV</code><code class="o">=</code>production&#13;
<code class="nv">$ </code>node server.js</pre>&#13;
&#13;
<p>Philosophies for choosing <em>what</em> code to deploy to different environments, which branching and merging strategies to use, and even which VCS (version control system) to choose are outside the scope of this book. But, ultimately, a particular snapshot of the codebase is chosen to be deployed to a particular environment.</p>&#13;
&#13;
<p>Choosing <em>which</em> environments to support is also important, and also outside the scope of this book. Usually companies will have, at a minimum, the following &#13;
<span class="keep-together">environments:</span></p>&#13;
<dl>&#13;
<dt>Development</dt>&#13;
<dd>&#13;
<p>Used for local development. Perhaps <a data-primary="environments" data-secondary="development" data-type="indexterm" id="idm46291190082232"/><a data-primary="development environment" data-type="indexterm" id="idm46291190081256"/>other services know to ignore messages associated with this environment. Doesn’t need some of the backing stores required by production; for example, logs might be written to <em>stdout</em> instead of being transmitted to a collector.</p>&#13;
</dd>&#13;
<dt>Staging</dt>&#13;
<dd>&#13;
<p>Represents an <a data-primary="environments" data-secondary="staging" data-type="indexterm" id="idm46291190078568"/><a data-primary="staging environment" data-type="indexterm" id="idm46291190076376"/>exact copy of the <em>production</em> environment, such as machine specs and operating system versions. Perhaps an anonymized database snapshot from production is copied to a <em>staging</em> database via a nightly cron job.</p>&#13;
</dd>&#13;
<dt>Production</dt>&#13;
<dd>&#13;
<p>Where the real <a data-primary="environments" data-secondary="production" data-type="indexterm" id="idm46291190073272"/><a data-primary="production environment" data-type="indexterm" id="idm46291190072264"/>production traffic is processed. There may be more service instances here than in <em>staging</em>; for example, maybe <em>staging</em> runs two application instances (always run more than one) but <em>production</em> runs eight.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>The environment string must remain <a data-primary="environments" data-secondary="strings" data-type="indexterm" id="idm46291190069640"/>consistent across all applications, both those written using Node.js and those on other platforms. This consistency will prevent many headaches. If one team refers to an environment as <em>staging</em> and the other as <em>preprod</em>, querying logs for related messages then becomes an error-prone process.</p>&#13;
&#13;
<p>The environment value shouldn’t necessarily be used for configuration—for example, having a lookup map where environment name is associated with a hostname for a database. Ideally, any dynamic configuration should be provided via environment variables. Instead, the <a data-primary="environment variables" data-type="indexterm" id="idm46291190066792"/><a data-primary="variables" data-secondary="environment variables" data-type="indexterm" id="idm46291190066088"/>environment value is mostly used for things related to observability. For example, log messages should have the environment attached in order to help associate any logs with the given environment, which is especially important if a logging service does get shared across environments. <a data-type="xref" href="ch10.html#ch_security_sec_config">“Application Configuration”</a> takes a <a data-primary="monitoring" data-secondary="environments" data-startref="mon_env" data-type="indexterm" id="idm46291190043496"/><a data-primary="environments" data-startref="env" data-type="indexterm" id="idm46291190042408"/>deeper look at configuration.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Logging with ELK" data-type="sect1"><div class="sect1" id="ch_monitoring_sec_log">&#13;
<h1>Logging with ELK</h1>&#13;
&#13;
<p><em>ELK</em>, or more specifically, <em>the ELK stack</em>, is a <a data-primary="ELK stack" data-secondary="logging with" data-type="indexterm" id="idm46291190038568"/><a data-primary="logging" data-secondary="ELK stack and" data-type="indexterm" id="log_ELK"/><a data-primary="monitoring" data-secondary="logging with ELK stack" data-type="indexterm" id="mon_ELK"/>reference to <em>Elasticsearch</em>, <em>Logstash</em>, and <em>Kibana</em>, three open source tools built by <a class="orm:hideurl" href="https://elastic.co">Elastic</a>. When combined, these powerful tools are often the platform of choice for collecting logs on-prem. Individually, each of these tools serves a different purpose:</p>&#13;
<dl>&#13;
<dt>Elasticsearch</dt>&#13;
<dd>&#13;
<p>A database with a powerful <a data-primary="ELK stack" data-secondary="Elasticsearch" data-type="indexterm" id="idm46291190030904"/><a data-primary="Elasticsearch, ELK stack and" data-type="indexterm" id="idm46291190029928"/>query syntax, supporting features like natural text searching. It is useful in many more situations than what are covered in this book and is worth considering if you ever need to build a search engine. It exposes an HTTP API and has a default port of <code>:9200</code>.</p>&#13;
</dd>&#13;
<dt>Logstash</dt>&#13;
<dd>&#13;
<p>A service for <a data-primary="ELK stack" data-secondary="Logstash" data-type="indexterm" id="idm46291190027112"/><a data-primary="Logstash, ELK stack and" data-type="indexterm" id="idm46291190026104"/>ingesting and transforming logs from multiple sources. You’ll create an interface so that it can ingest logs via User Diagram Protocol (UDP). It doesn’t have a default port, so we’ll just use <code>:7777</code>.</p>&#13;
</dd>&#13;
<dt>Kibana</dt>&#13;
<dd>&#13;
<p>A web service for <a data-primary="ELK stack" data-secondary="Kibana" data-type="indexterm" id="idm46291190023368"/><a data-primary="Kibana" data-secondary="ELK stack and" data-type="indexterm" id="idm46291190022360"/>building dashboards that visualize data stored in Elasticsearch. It exposes an HTTP web service over the port <code>:5601</code>.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p><a data-type="xref" href="#fig_elk">Figure 4-1</a> diagrams these services and their relationships, as well as how they’re encapsulated using Docker in the upcoming examples.</p>&#13;
&#13;
<figure><div class="figure" id="fig_elk">&#13;
<img alt="Administrator uses Kibana, Kibana talks to Elasticsearch, Applications logs to Logstash, and Logstash stores in Elasticsearch" src="assets/dsnj_0401.png"/>&#13;
<h6><span class="label">Figure 4-1. </span>The ELK stack</h6>&#13;
</div></figure>&#13;
&#13;
<p>Your application is expected to transmit <a data-primary="JSON" data-secondary="logs" data-type="indexterm" id="idm46291190016776"/>well-formed JSON logs, typically an object that’s one or two levels deep. These objects contain generic metadata about the message being logged, such as timestamp and host and IP address, as well as information specific to the message itself, such as level/severity, environment, and a human-readable message. There are multiple ways to configure ELK to receive such messages, such as writing logs to a file and using Elastic’s Filebeat tool to collect them. The approach used in this section will configure Logstash to listen for <a data-primary="logging" data-secondary="ELK stack and" data-startref="log_ELK" data-type="indexterm" id="idm46291190015128"/>incoming UDP messages.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running ELK via Docker" data-type="sect2"><div class="sect2" id="idm46291190013656">&#13;
<h2>Running ELK via Docker</h2>&#13;
&#13;
<p>In order to get your hands <a data-primary="ELK stack" data-secondary="Docker and" data-type="indexterm" id="ELK_doc"/><a data-primary="Docker" data-secondary="ELK stack and" data-type="indexterm" id="Doc_ELK"/>dirty, you’re going to run a single Docker container containing all three services. (Be sure to have Docker installed—see <a data-type="xref" href="app02.html#appendix_install_docker">Appendix B</a> for more information.) These examples won’t enable disk persistence. Within a larger organization, each of these services would perform better when installed on dedicated machines, and of course, persistence is vital.</p>&#13;
&#13;
<p>In order to configure Logstash to listen for UDP messages, a configuration file must first be created. The content for this file is available in <a data-type="xref" href="#ex_elk_udp">Example 4-1</a> and can be placed in a new directory at <em>misc/elk/udp.conf</em>. Once the file is created, you’ll make it available to the Logstash service running inside of the Docker container. This is done by using the <code>-v</code> volume flag, which allows a local filesystem path to be mounted inside of the container’s filesystem.</p>&#13;
<div data-type="example" id="ex_elk_udp">&#13;
<h5><span class="label">Example 4-1. </span><em>misc/elk/udp.conf</em></h5>&#13;
&#13;
<pre data-type="programlisting">input {&#13;
  udp {&#13;
    id =&gt; "nodejs_udp_logs"&#13;
    port =&gt; 7777&#13;
    codec =&gt; json&#13;
  }&#13;
}&#13;
output {&#13;
  elasticsearch {&#13;
    hosts =&gt; ["localhost:9200"]&#13;
    document_type =&gt; "nodelog"&#13;
    manage_template =&gt; false&#13;
    index =&gt; "nodejs-%{+YYYY.MM.dd}"&#13;
  }&#13;
}</pre></div>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For brevity’s sake, these examples use UDP for sending messages. This approach doesn’t come with the same features as others, such as delivery guarantees or back pressure support, but it does come with reduced overhead for the application. Be sure to research the best tool for your use-case.</p>&#13;
</div>&#13;
&#13;
<p>Once the file has been created you’re ready to run the container using the commands in <a data-type="xref" href="#ex_elk_docker">Example 4-2</a>. If you’re running Docker on a system-based Linux machine, you’ll need to run <a data-primary="sysctl command" data-type="indexterm" id="idm46291190000760"/><a data-primary="commands" data-secondary="sysctl" data-type="indexterm" id="idm46291190000088"/>the <code>sysctl</code> command before the container will properly run, and you may omit the <code>-e</code> flag if you want. Otherwise, if you’re running Docker on a macOS machine, skip the <code>sysctl</code> flag.</p>&#13;
<div data-type="example" id="ex_elk_docker">&#13;
<h5><span class="label">Example 4-2. </span>Running ELK within Docker</h5>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>sudo sysctl -w vm.max_map_count<code class="o">=</code><code class="m">262144</code> <code class="c"># Linux Only</code>&#13;
<code class="nv">$ </code>docker run -p 5601:5601 -p 9200:9200 <code class="se">\</code>&#13;
  -p 5044:5044 -p 7777:7777/udp <code class="se">\</code>&#13;
  -v <code class="nv">$PWD</code>/misc/elk/udp.conf:/etc/logstash/conf.d/99-input-udp.conf <code class="se">\</code>&#13;
  -e <code class="nv">MAX_MAP_COUNT</code><code class="o">=</code><code class="m">262144</code> <code class="se">\</code>&#13;
  -it --name distnode-elk sebp/elk:683</pre></div>&#13;
&#13;
<p>This command downloads files from Dockerhub and configures the service and may take a few minutes to run. Once your console calms down a bit, visit <em>http://localhost:5601</em> in your browser. If you see a successful message, then the service is now ready to receive <a data-primary="ELK stack" data-secondary="Docker and" data-startref="ELK_doc" data-type="indexterm" id="idm46291189978408"/><a data-primary="Docker" data-secondary="ELK stack and" data-startref="Doc_ELK" data-type="indexterm" id="idm46291189977224"/>messages.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Transmitting Logs from Node.js" data-type="sect2"><div class="sect2" id="idm46291189975752">&#13;
<h2>Transmitting Logs from Node.js</h2>&#13;
&#13;
<p>For this example, you’re going to again <a data-primary="logging" data-secondary="ELK stack and" data-tertiary="transmitting" data-type="indexterm" id="logELKtrans"/>start by modifying an existing application. Copy the <em>web-api/consumer-http-basic.js</em> file created in <a data-type="xref" href="ch01.html#ex_consumer">Example 1-7</a> to <em>web-api/consumer-http-logs.js</em> as a starting point. Next, modify the file to look like the code in <a data-type="xref" href="#ex_consumer_logs">Example 4-3</a>.</p>&#13;
<div data-type="example" id="ex_consumer_logs">&#13;
<h5><span class="label">Example 4-3. </span><em>web-api/consumer-http-logs.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node&#13;
</code><code>&#13;
</code><code class="c1">// npm install fastify@3.2 node-fetch@2.6 middie@5.1&#13;
</code><code class="kr">const</code><code> </code><code class="nx">server</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'fastify'</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">fetch</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'node-fetch'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">HOST</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">HOST</code><code> </code><code class="o">||</code><code> </code><code class="s1">'127.0.0.1'</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">PORT</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code><code> </code><code class="o">||</code><code> </code><code class="mi">3000</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">TARGET</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">TARGET</code><code> </code><code class="o">||</code><code> </code><code class="s1">'localhost:4000'</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">log</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'./logstash.js'</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO1-1" id="co_observability_CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
&#13;
</code><code class="p">(</code><code class="nx">async</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="nx">await</code><code> </code><code class="nx">server</code><code class="p">.</code><code class="nx">register</code><code class="p">(</code><code class="nx">require</code><code class="p">(</code><code class="s1">'middie'</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO1-2" id="co_observability_CO1-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">use</code><code class="p">(</code><code class="p">(</code><code class="nx">req</code><code class="p">,</code><code> </code><code class="nx">res</code><code class="p">,</code><code> </code><code class="nx">next</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code> </code><a class="co" href="#callout_observability_CO1-3" id="co_observability_CO1-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
    </code><code class="nx">log</code><code class="p">(</code><code class="s1">'info'</code><code class="p">,</code><code> </code><code class="s1">'request-incoming'</code><code class="p">,</code><code> </code><code class="p">{</code><code> </code><a class="co" href="#callout_observability_CO1-4" id="co_observability_CO1-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
      </code><code class="nx">path</code><code class="o">:</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">url</code><code class="p">,</code><code> </code><code class="nx">method</code><code class="o">:</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">method</code><code class="p">,</code><code> </code><code class="nx">ip</code><code class="o">:</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">ip</code><code class="p">,</code><code>&#13;
      </code><code class="nx">ua</code><code class="o">:</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">headers</code><code class="p">[</code><code class="s1">'user-agent'</code><code class="p">]</code><code> </code><code class="o">||</code><code> </code><code class="kc">null</code><code> </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="nx">next</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">setErrorHandler</code><code class="p">(</code><code class="nx">async</code><code> </code><code class="p">(</code><code class="nx">error</code><code class="p">,</code><code> </code><code class="nx">req</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="nx">log</code><code class="p">(</code><code class="s1">'error'</code><code class="p">,</code><code> </code><code class="s1">'request-failure'</code><code class="p">,</code><code> </code><code class="p">{</code><code class="nx">stack</code><code class="o">:</code><code> </code><code class="nx">error</code><code class="p">.</code><code class="nx">stack</code><code class="p">,</code><code> </code><a class="co" href="#callout_observability_CO1-5" id="co_observability_CO1-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
      </code><code class="nx">path</code><code class="o">:</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">url</code><code class="p">,</code><code> </code><code class="nx">method</code><code class="o">:</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">method</code><code class="p">,</code><code> </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="k">return</code><code> </code><code class="p">{</code><code> </code><code class="nx">error</code><code class="o">:</code><code> </code><code class="nx">error</code><code class="p">.</code><code class="nx">message</code><code> </code><code class="p">}</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="kr">const</code><code> </code><code class="nx">url</code><code> </code><code class="o">=</code><code> </code><code class="sb">`</code><code class="sb">http://</code><code class="si">${</code><code class="nx">TARGET</code><code class="si">}</code><code class="sb">/recipes/42</code><code class="sb">`</code><code class="p">;</code><code>&#13;
    </code><code class="nx">log</code><code class="p">(</code><code class="s1">'info'</code><code class="p">,</code><code> </code><code class="s1">'request-outgoing'</code><code class="p">,</code><code> </code><code class="p">{</code><code class="nx">url</code><code class="p">,</code><code> </code><code class="nx">svc</code><code class="o">:</code><code> </code><code class="s1">'recipe-api'</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO1-6" id="co_observability_CO1-6"><img alt="6" src="assets/6.png"/></a><code>&#13;
    </code><code class="kr">const</code><code> </code><code class="nx">req</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">fetch</code><code class="p">(</code><code class="nx">url</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="kr">const</code><code> </code><code class="nx">producer_data</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">json</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="k">return</code><code> </code><code class="p">{</code><code> </code><code class="nx">consumer_pid</code><code class="o">:</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">pid</code><code class="p">,</code><code> </code><code class="nx">producer_data</code><code> </code><code class="p">}</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/error'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code> </code><code class="k">throw</code><code> </code><code class="k">new</code><code> </code><code class="nb">Error</code><code class="p">(</code><code class="s1">'oh no'</code><code class="p">)</code><code class="p">;</code><code> </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="nx">PORT</code><code class="p">,</code><code> </code><code class="nx">HOST</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="nx">log</code><code class="p">(</code><code class="s1">'verbose'</code><code class="p">,</code><code> </code><code class="s1">'listen'</code><code class="p">,</code><code> </code><code class="p">{</code><code class="nx">host</code><code class="o">:</code><code> </code><code class="nx">HOST</code><code class="p">,</code><code> </code><code class="nx">port</code><code class="o">:</code><code> </code><code class="nx">PORT</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO1-7" id="co_observability_CO1-7"><img alt="7" src="assets/7.png"/></a><code>&#13;
  </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO1-1" id="callout_observability_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The new <em>logstash.js</em> file is now being loaded.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-2" id="callout_observability_CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The <code>middie</code> package allows Fastify to use generic middleware.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-3" id="callout_observability_CO1-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>A middleware to log incoming requests.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-4" id="callout_observability_CO1-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>A call to the logger that passes in request data.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-5" id="callout_observability_CO1-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>A generic middleware for logging errors.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-6" id="callout_observability_CO1-6"><img alt="6" src="assets/6.png"/></a></dt>&#13;
<dd><p>Information about outbound requests is logged.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-7" id="callout_observability_CO1-7"><img alt="7" src="assets/7.png"/></a></dt>&#13;
<dd><p>Information about server starts is also logged.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This file logs some key pieces of information. The first thing logged is when the server starts. The second set of information is by way of a generic middleware handler. It logs data about any incoming request, including the path, the method, the IP address, and the user agent. This is similar to the access log for a traditional web server. Finally, the application tracks outbound requests to <a data-primary="recipe-api" data-secondary="outbound requests" data-type="indexterm" id="idm46291189473160"/>the <em>recipe-api</em> service.</p>&#13;
&#13;
<p>The contents of the <em>logstash.js</em> file might be <a data-primary="Logstash.js file" data-type="indexterm" id="idm46291189470888"/>more interesting. There are many libraries available on npm for transmitting logs to Logstash (<code>@log4js-node/logstashudp</code> is one such package). These libraries support a few methods for transmission, UDP included. Since the mechanism for sending logs is so simple, you’re going to reproduce a version from scratch. This is great for educational purposes, but a full-featured package from npm will make a better choice for a production application.</p>&#13;
&#13;
<p>Create a new file called <em>web-api/logstash.js</em>. Unlike <a data-primary="web-api/Logstash.js" data-type="indexterm" id="idm46291189468376"/>the other JavaScript files you’ve created so far, this one won’t be executed directly. Add the content from <a data-type="xref" href="#ex_logstash">Example 4-4</a> to this file.</p>&#13;
<div data-type="example" id="ex_logstash">&#13;
<h5><span class="label">Example 4-4. </span><em>web-api/logstash.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code><code> </code><code class="nx">client</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'dgram'</code><code class="p">)</code><code class="p">.</code><code class="nx">createSocket</code><code class="p">(</code><code class="s1">'udp4'</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO2-1" id="co_observability_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">host</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'os'</code><code class="p">)</code><code class="p">.</code><code class="nx">hostname</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="p">[</code><code class="nx">LS_HOST</code><code class="p">,</code><code> </code><code class="nx">LS_PORT</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">LOGSTASH</code><code class="p">.</code><code class="nx">split</code><code class="p">(</code><code class="s1">':'</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO2-2" id="co_observability_CO2-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">NODE_ENV</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">NODE_ENV</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">module</code><code class="p">.</code><code class="nx">exports</code><code> </code><code class="o">=</code><code> </code><code class="kd">function</code><code class="p">(</code><code class="nx">severity</code><code class="p">,</code><code> </code><code class="nx">type</code><code class="p">,</code><code> </code><code class="nx">fields</code><code class="p">)</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">payload</code><code> </code><code class="o">=</code><code> </code><code class="nx">JSON</code><code class="p">.</code><code class="nx">stringify</code><code class="p">(</code><code class="p">{</code><code> </code><a class="co" href="#callout_observability_CO2-3" id="co_observability_CO2-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
    </code><code class="s1">'@timestamp'</code><code class="o">:</code><code> </code><code class="p">(</code><code class="k">new</code><code> </code><code class="nb">Date</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">.</code><code class="nx">toISOString</code><code class="p">(</code><code class="p">)</code><code class="p">,</code><code>&#13;
    </code><code class="s2">"@version"</code><code class="o">:</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="nx">app</code><code class="o">:</code><code> </code><code class="s1">'web-api'</code><code class="p">,</code><code> </code><code class="nx">environment</code><code class="o">:</code><code> </code><code class="nx">NODE_ENV</code><code class="p">,</code><code>&#13;
    </code><code class="nx">severity</code><code class="p">,</code><code> </code><code class="nx">type</code><code class="p">,</code><code> </code><code class="nx">fields</code><code class="p">,</code><code> </code><code class="nx">host</code><code>&#13;
  </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="nx">payload</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">client</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="nx">payload</code><code class="p">,</code><code> </code><code class="nx">LS_PORT</code><code class="p">,</code><code> </code><code class="nx">LS_HOST</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO2-1" id="callout_observability_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The built-in <code>dgram</code> module sends UDP messages.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO2-2" id="callout_observability_CO2-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The Logstash location is stored in <code>LOGSTASH</code>.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO2-3" id="callout_observability_CO2-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Several fields are sent in the log message.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This basic Logstash module exports a function that application code calls to send a log. Many of the fields are automatically generated, like <code>@timestamp</code>, which represents the current time. The <code>app</code> field is the name of the running application and doesn’t need to be overridden by the caller. Other fields, like <code>severity</code> and <code>type</code>, are fields that the application is going to change all the time. The <code>fields</code> field represents additional key/value pairs the app might want to provide.</p>&#13;
&#13;
<p>The <code>severity</code> field (often called the <em>log level</em> in other logging frameworks) refers to the importance of the log. Most logging packages support the following six values, originally made popular by the npm client: <em>error</em>, <em>warn</em>, <em>info</em>, <em>verbose</em>, <em>debug</em>, <em>silly</em>. It’s a <a data-primary="environment variables" data-secondary="logging threshold" data-type="indexterm" id="idm46291189236024"/><a data-primary="logging" data-secondary="threshold, environment variables" data-type="indexterm" id="idm46291189235288"/><a data-primary="logging" data-secondary="severity field" data-type="indexterm" id="idm46291189234440"/>common pattern with more “complete” logging packages to set a logging threshold via environment variable. For example, by setting the minimum severity to <em>verbose</em>, any messages with a lower severity (namely <em>debug</em> and <em>silly</em>) will get dropped. The overly simple <em>logstash.js</em> module doesn’t support this.</p>&#13;
&#13;
<p>Once the payload has been constructed, it’s then converted <a data-primary="JSON" data-secondary="strings" data-type="indexterm" id="idm46291189231624"/>into a JSON string and printed to the console to help tell what’s going on. Finally, the process attempts to transmit the message to the Logstash server (there is no way for the application to know if the message was delivered; this is the shortcoming of UDP).</p>&#13;
&#13;
<p>With the two files created, it’s now time to test the application. Run the commands in <a data-type="xref" href="#ex_logstash_run_app">Example 4-5</a>. This will start an instance of the new <em>web-api</em> service, an instance of the previous <em>recipe-api</em> service, and will also send a series of requests to the <em>web-api</em>. A log will be immediately sent once the <em>web-api</em> has been started, and two additional logs will be sent for each incoming HTTP request. Note that the <code>watch</code> commands <a data-primary="watch command" data-type="indexterm" id="idm46291189226888"/><a data-primary="commands" data-secondary="watch" data-type="indexterm" id="idm46291189226280"/>continuously execute the command following on the same line and will need to be run in separate terminal windows.</p>&#13;
<div data-type="example" id="ex_logstash_run_app">&#13;
<h5><span class="label">Example 4-5. </span>Running <em>web-api</em> and generating logs</h5>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ NODE_ENV</code><code class="o">=</code>development <code class="nv">LOGSTASH</code><code class="o">=</code>localhost:7777 <code class="se">\</code>&#13;
  node web-api/consumer-http-logs.js&#13;
<code class="nv">$ </code>node recipe-api/producer-http-basic.js&#13;
<code class="nv">$ </code>brew install watch <code class="c"># required for macOS</code>&#13;
<code class="nv">$ </code>watch -n5 curl http://localhost:3000&#13;
<code class="nv">$ </code>watch -n13 curl http://localhost:3000/error</pre></div>&#13;
&#13;
<p>Isn’t that exciting? Well, not quite yet. Now you’ll jump into Kibana and take a look at the logs being sent. Let the <code>watch</code> commands continue running in the background; they’ll keep the data fresh while you’re <a data-primary="logging" data-secondary="ELK stack and" data-startref="logELKtrans" data-tertiary="transmitting" data-type="indexterm" id="idm46291189215128"/>using Kibana.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Creating a Kibana Dashboard" data-type="sect2"><div class="sect2" id="idm46291189975128">&#13;
<h2>Creating a Kibana Dashboard</h2>&#13;
&#13;
<p>Now that the application is sending <a data-primary="ELK stack" data-secondary="Kibana" data-tertiary="dashboard" data-type="indexterm" id="elkkibdash"/><a data-primary="Kibana" data-secondary="dashboard" data-type="indexterm" id="kibdash"/>data to Logstash and Logstash is storing the data in Elasticsearch, it’s time to open Kibana and explore this data. Open your browser and visit <a href="http://localhost:5601"><em class="hyperlink">http://localhost:5601</em></a>. At this point you should be greeted with the Kibana dashboard.</p>&#13;
&#13;
<p>Within the dashboard, click the last tab on the left, titled <a class="orm:hideurl" href="http://localhost:5601/app/kibana#/management">Management</a>. Next, locate the Kibana section of options and then click the Index Patterns option. Click Create index pattern. For Step 1, type in an Index pattern of <code>nodejs-*</code>. You should see a small Success! message below as Kibana correlates your query to a result. Click Next step. For Step 2, click the Time Filter drop-down menu and then click the <code>@timestamp</code> field. Finally, click Create index pattern. You’ve now created an index named &#13;
<span class="keep-together"><code>nodejs-*</code></span> that will allow you to query those values.</p>&#13;
&#13;
<p>Click the second tab on the left, titled <a class="orm:hideurl" href="http://localhost:5601/app/kibana#/visualize">Visualize</a>. Next, click the Create new visualization button in the center of the screen. You’ll be given several different options for creating a visualization, including the ones shown in <a data-type="xref" href="#fig_kibana_visualizations">Figure 4-2</a>, but for now just click the Vertical Bar graph option.</p>&#13;
&#13;
<figure><div class="figure" id="fig_kibana_visualizations">&#13;
<img alt="Kibana Icons: Gauge, Goal, Heat Map, Horizontal Bar, Line, Maps, Markdown, Metric" src="assets/dsnj_0402.png"/>&#13;
<h6><span class="label">Figure 4-2. </span>Kibana visualizations</h6>&#13;
</div></figure>&#13;
&#13;
<p>Select the <code>nodejs-*</code> index that you just created. Once that’s done, you’ll be taken to a new screen to fine-tune the visualization. The default graph isn’t too interesting; it’s a single bar showing a count of all logs matching the <code>nodejs-*</code> index. But not for long.</p>&#13;
&#13;
<p>The goal now is to create a graph that displays the rate at which incoming requests are received by the <em>web-api</em> service. So, first add a few filters to narrow down the results to only contain applicable entries. Click the Add a Filter link near the upper-left corner of the screen. For the Field drop-down menu, enter the value <code>type</code>. For the Operator field, set it to <code>is</code>. For the Value field, enter the value <code>request-incoming</code> and then click Save. Next, click Add a Filter again and do the same thing, but this time set Field to <code>app</code>, then set Operator to <code>is</code> again, and set Value to <code>web-api</code>.</p>&#13;
&#13;
<p>For the Metrics section, leave it displaying the count, since it should display the number of requests and the matching log messages correlate one to one with real requests.</p>&#13;
&#13;
<p>For the Buckets section, it should be changed to group by time. Click the Add buckets link and select X-Axis. For the Aggregation drop-down menu, select Date Histogram. Click on the blue button with a play symbol above the Metrics section (it has a title of Apply changes), and the graph will update. The default setting of grouping by <span class="keep-together"><code>@timestamp</code></span> with an automatic interval is fine.</p>&#13;
&#13;
<p>In the upper-right corner is a drop-down menu for changing the time range of the logs being queried. Click the drop-down menu and configure it to display logs from the last hour, and then click the large Refresh button to the right of the drop-down menu. If all goes to plan, your screen should look like <a data-type="xref" href="#fig_kibana-vis-complete">Figure 4-3</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig_kibana-vis-complete">&#13;
<img alt="A Kibana graph of timestamps over time" src="assets/dsnj_0403.png"/>&#13;
<h6><span class="label">Figure 4-3. </span>Requests over time in Kibana</h6>&#13;
</div></figure>&#13;
&#13;
<p>Once your graph is complete, click the Save link at the top of the Kibana screen. Name the visualization <em>web-api incoming requests</em>. Next, create a similar visualization but this time, set the <em>type</em> field to <code>request-outgoing</code> and name that visualization <em>web-api outgoing requests</em>. Finally, create a third visualization with a <em>type</em> field of <code>listen</code> and name it <em>web-api server starts</em>.</p>&#13;
&#13;
<p>Next, you’ll create a dashboard for these three visualizations. Select the third option in the sidebar titled Dashboard. Then, click Create new dashboard. A modal window will appear with your three visualizations in it. Click each visualization, and it will be added to the dashboard. Once you’ve added each visualization, dismiss the modal. Click the Save link at the top of the screen and save the dashboard as <em>web-api</em> &#13;
<span class="keep-together"><em>overview</em>.</span></p>&#13;
&#13;
<p>Congratulations! You’ve created a dashboard containing information <a data-primary="ELK stack" data-secondary="Kibana" data-startref="elkkibdash" data-tertiary="dashboard" data-type="indexterm" id="idm46291189160120"/><a data-primary="Kibana" data-secondary="dashboard" data-startref="kibdash" data-type="indexterm" id="idm46291189158792"/>extracted from your application.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running Ad-Hoc Queries" data-type="sect2"><div class="sect2" id="idm46291189206184">&#13;
<h2>Running Ad-Hoc Queries</h2>&#13;
&#13;
<p>Sometimes you’ll need to <a data-primary="ELK stack" data-secondary="Kibana" data-tertiary="ad-hoc queries" data-type="indexterm" id="elkkibadhoc"/><a data-primary="Kibana" data-secondary="ad-hoc queries" data-type="indexterm" id="kibadhoc"/><a data-primary="ad-hoc queries, Kibana" data-type="indexterm" id="adkib"/>run arbitrary queries against the data that’s being logged without a correlating dashboard. This is helpful in one-off debugging situations. &#13;
<span class="keep-together">In this</span> section, you’ll write <a data-primary="errors" data-secondary="extracting, queries" data-type="indexterm" id="idm46291189151832"/>arbitrary queries in order to extract errors about the &#13;
<span class="keep-together">application.</span></p>&#13;
&#13;
<p>Click the first tab in the left sidebar, the one titled Discover. This is a convenient playground for running queries without needing to commit them to a dashboard. By default, a listing of all recently received messages is displayed. Click inside of the Search field at the top of the screen. Then, type the following query into the search field and press Enter:</p>&#13;
&#13;
<pre data-type="programlisting">app:"web-api" AND (severity:"error" OR severity:"warn")</pre>&#13;
&#13;
<p>The syntax of this query is written <a data-primary="KQL (Kibana Query Language)" data-type="indexterm" id="idm46291189148360"/>in the <em>Kibana</em> <em>Query Language</em> (KQL). Essentially, there are three clauses. It’s asking for logs belonging to the <em>web-api</em> application and whose <em>severity</em> levels are set to either <em>error</em> or <em>warn</em> (in other words, things that are very important).</p>&#13;
&#13;
<p>Click the arrow symbol next to one of the log entries in the list that follows. This will expand the individual log entry and allow you to view the entire JSON payload associated with the log. The ability to view arbitrary log messages like this is what makes logging so powerful. With this tool you’re now able to find all the errors being logged from the service.</p>&#13;
&#13;
<p>By logging more data, you’ll gain the ability to drill down into the details of specific error situations. For example, you might find that errors occur when a specific endpoint within an application is being hit under certain circumstances (like a user updating a recipe via <code>PUT /recipe</code> in a more full-featured application). With access to the stack trace, and enough contextual information about the requests, you’re then able to re-create the conditions locally, reproduce the bug, and come up with a fix.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>This section looks at transmitting logs from within an application, an inherently asynchronous operation. Unfortunately, logs generated when a process crashes might not be sent in time. Many deployment tools can read messages from <em>stdout</em> and transmit them on behalf of the application, which increases the likelihood of them being delivered.</p>&#13;
</div>&#13;
&#13;
<p>This section looked at storing logs. Certainly, these logs can be used to display numeric information in graphs, but it isn’t necessarily the most efficient system for doing so since the logs store complex objects. The next section, <a data-type="xref" href="#ch_monitoring_sec_metrics">“Metrics with Graphite, StatsD, and Grafana”</a>, looks at storing more interesting numeric data using a different set of tools.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291189140120">&#13;
<h5>Alternatives to ELK</h5>&#13;
<p>There are many alternatives <a data-primary="ELK stack" data-secondary="alternatives" data-type="indexterm" id="idm46291189138760"/>to the ELK stack, especially when it comes to paid alternatives. Elastic, for example, provides a <a class="orm:hideurl" href="https://elastic.co">Cloud Version of ELK</a>, for those who don’t want to manage an on-prem solution. Several other companies offer their own versions, each with different price ranges and feature sets, including <a class="orm:hideurl" href="https://datadoghq.com">Datadog</a>, <a class="orm:hideurl" href="https://sumologic.com">Sumo Logic</a>, and <a class="orm:hideurl" href="https://splunk.com">Splunk</a>.</p>&#13;
&#13;
<p>A standard for transmitting logs called syslog is also available. This can be used to collect and aggregate logs across multiple servers, removing the message delivery responsibility from the application.</p>&#13;
&#13;
<p>If you’re deploying to cloud infrastructure, there are built-in logging tools that might prove to be easier to integrate with. If you use AWS, you’re likely to end up using AWS CloudWatch. And, if GCE is your home, you might end up with Stackdriver. Like with any tool, you should <a data-primary="ELK stack" data-secondary="Kibana" data-startref="elkkibadhoc" data-tertiary="ad-hoc queries" data-type="indexterm" id="idm46291189132856"/><a data-primary="Kibana" data-secondary="ad-hoc queries" data-startref="kibadhoc" data-type="indexterm" id="idm46291189131528"/><a data-primary="ad-hoc queries, Kibana" data-startref="adkib" data-type="indexterm" id="idm46291189130440"/><a data-primary="monitoring" data-secondary="logging with ELK stack" data-startref="mon_ELK" data-type="indexterm" id="idm46291189129592"/>compare features and pricing when making a decision.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Metrics with Graphite, StatsD, and Grafana" data-type="sect1"><div class="sect1" id="ch_monitoring_sec_metrics">&#13;
<h1>Metrics with Graphite, StatsD, and Grafana</h1>&#13;
&#13;
<p><a data-type="xref" href="#ch_monitoring_sec_log">“Logging with ELK”</a> looked at <a data-primary="metrics" data-type="indexterm" id="idm46291189125944"/><a data-primary="monitoring" data-secondary="metrics" data-type="indexterm" id="mon_metric"/>transmitting logs from a running Node.js process. Such logs are formatted as JSON <a data-primary="JSON" data-secondary="logs" data-type="indexterm" id="idm46291189124120"/><a data-primary="logging" data-secondary="JSON" data-type="indexterm" id="idm46291189123272"/>and are indexable and searchable on a per-log basis. This is perfect for reading messages related to a particular running process, such as reading variables and stack traces. However, sometimes you don’t necessarily care about individual pieces of numeric data, and instead you want to know about aggregations of data, usually as these values grow and shrink over time.</p>&#13;
&#13;
<p>This section looks at sending <em>metrics</em>. A metric is numeric data associated with time. This can include things like request rates, the number of <em>2XX</em> versus <em>5XX</em> HTTP responses, latency between the application and a backing service, memory and disk use, and even business stats like dollar revenue or cancelled payments. Visualizing such information is important to understanding application health and system load.</p>&#13;
&#13;
<p>Much like in the logging section, a stack of tools will be used instead of a single one. However, this stack doesn’t really have a catchy acronym like ELK, and it’s fairly common to swap out different components. The stack considered here is that of <em>Graphite</em>, <em>StatsD</em>, and <em>Grafana</em>:</p>&#13;
<dl>&#13;
<dt>Graphite</dt>&#13;
<dd>&#13;
<p>A combination of a service (<em>Carbon</em>) and <a data-primary="Graphite" data-type="indexterm" id="idm46291189116056"/><a data-primary="Whisper" data-type="indexterm" id="idm46291189115448"/><a data-primary="GraphiteWeb" data-type="indexterm" id="idm46291189114840"/>time series database (<em>Whisper</em>). It also comes with a UI (<em>Graphite Web</em>), though the more powerful Grafana interface is often used.</p>&#13;
</dd>&#13;
<dt>StatsD</dt>&#13;
<dd>&#13;
<p>A daemon (built with Node.js) <a data-primary="StatsD" data-type="indexterm" id="idm46291189112312"/>for collecting metrics. It can listen for stats over TCP or UDP before sending aggregations to a backend such as Graphite.</p>&#13;
</dd>&#13;
<dt>Grafana</dt>&#13;
<dd>&#13;
<p>A web service that <a data-primary="Grafana" data-type="indexterm" id="idm46291189110280"/>queries time series backends (like Graphite) and displays information in configurable dashboards.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p><a data-type="xref" href="#fig_graphite">Figure 4-4</a> shows a diagram of these services and how they’re related. The Docker boundaries represent what the upcoming examples will use.</p>&#13;
&#13;
<figure><div class="figure" id="fig_graphite">&#13;
<img alt="Administrator uses Grafana, Grafana talks to Graphite, Applications sends metrics to StatsD, and StatsD stores in Graphite" src="assets/dsnj_0404.png"/>&#13;
<h6><span class="label">Figure 4-4. </span>Graphite, StatsD, and Grafana</h6>&#13;
</div></figure>&#13;
&#13;
<p>Much like in the logging section, these examples will transmit data using UDP. Due to the nature of metrics being rapidly produced, using UDP will help keep the application from getting overwhelmed.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running via Docker" data-type="sect2"><div class="sect2" id="idm46291189105544">&#13;
<h2>Running via Docker</h2>&#13;
&#13;
<p><a data-type="xref" href="#ex_metrics_docker">Example 4-6</a> starts two <a data-primary="Docker" data-secondary="StatsD" data-type="indexterm" id="idm46291189103144"/><a data-primary="Docker" data-secondary="Graphite" data-type="indexterm" id="idm46291189102296"/><a data-primary="StatsD" data-secondary="Docker and" data-type="indexterm" id="idm46291189101448"/><a data-primary="Graphite" data-secondary="Docker and" data-type="indexterm" id="idm46291189100600"/>separate Docker containers. The first one, <em>graphiteapp/graphite-statsd</em> contains StatsD and Graphite. Two ports from this container are exposed. The Graphite UI/API is exposed via port <code>:8080</code>, while the StatsD UDP metrics collector is exposed as <code>:8125</code>. The <a data-primary="Docker" data-secondary="Grafana" data-type="indexterm" id="idm46291189098344"/><a data-primary="Grafana" data-secondary="Docker and" data-type="indexterm" id="idm46291189097496"/>second, <em>grafana/grafana</em>, contains Grafana. A single port for the web interface, <code>:8000</code>, is exposed for this container.</p>&#13;
<div data-type="example" id="ex_metrics_docker">&#13;
<h5><span class="label">Example 4-6. </span>Running StatsD + Graphite, and Grafana</h5>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker run <code class="se">\</code>&#13;
  -p 8080:80 <code class="se">\</code>&#13;
  -p 8125:8125/udp <code class="se">\</code>&#13;
  -it --name distnode-graphite graphiteapp/graphite-statsd:1.1.6-1&#13;
<code class="nv">$ </code>docker run <code class="se">\</code>&#13;
  -p 8000:3000 <code class="se">\</code>&#13;
  -it --name distnode-grafana grafana/grafana:6.5.2</pre></div>&#13;
&#13;
<p>Once the containers are up and <a data-primary="Grafana" data-secondary="dashboard" data-type="indexterm" id="idm46291189090904"/>running, open a web browser and visit the Grafana dashboard at <a href="http://localhost:8000/"><em class="hyperlink">http://localhost:8000/</em></a>. You’ll be asked to log in at this point. The default login credentials are <em>admin</em> / <em>admin</em>. Once you successfully log in, you’ll then be prompted to change the password to something else. This password will be used to administer Grafana, though it won’t be used in code.</p>&#13;
&#13;
<p>Once the password has been set, <a data-primary="Grafana" data-secondary="configuring" data-type="indexterm" id="idm46291189086568"/>you’ll be taken to a wizard for configuring Grafana. The next step is to configure Grafana to communicate with the Graphite image. Click the Add Data Source button and then click the Graphite option. On the Graphite configuration screen, input the values displayed in <a data-type="xref" href="#table_graphite_config">Table 4-1</a>.</p>&#13;
<div style="page-break-after: always;"/>&#13;
<table id="table_graphite_config">&#13;
<caption><span class="label">Table 4-1. </span>Configuring Grafana to use Graphite</caption>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Name</p></td>&#13;
<td><p>Dist Node Graphite</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>URL</p></td>&#13;
<td><p>http://&lt;LOCAL_IP&gt;:8080</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Version</p></td>&#13;
<td><p>1.1.x</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Due to the way these Docker containers are being run, you won’t be able to use <code>localhost</code> for the <code>&lt;LOCAL_IP&gt;</code> placeholder. Instead, you’ll need to use your local IP address. If you’re on Linux, try running <strong><code>hostname -I</code></strong>, and if you’re on macOS, try running <span class="keep-together"><code>ipconfig getifaddr en0</code></span>. If you’re running this on a laptop and your IP address changes, you’ll need to reconfigure the data source in Grafana to use the new IP address, or else you won’t get data.</p>&#13;
</div>&#13;
&#13;
<p>Once you’ve entered the data, click Save &amp; Test. If you see the message “Data source is working,” then Grafana was able to talk to Graphite and you can click the Back button. If you get HTTP Error Bad Gateway, make sure the Graphite container is running and that the settings have been entered correctly.</p>&#13;
&#13;
<p>Now that Graphite and Grafana are talking to each other, it’s time to modify one of the Node.js services to start sending metrics.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Transmitting Metrics from Node.js" data-type="sect2"><div class="sect2" id="idm46291189104952">&#13;
<h2>Transmitting Metrics from Node.js</h2>&#13;
&#13;
<p>The <a class="orm:hideurl" href="https://github.com/statsd/statsd">protocol used by StatsD</a> is <a data-primary="metrics" data-secondary="transmitting" data-type="indexterm" id="idm46291189063736"/><a data-primary="transmitting metrics" data-type="indexterm" id="idm46291189062728"/><a data-primary="Node.js" data-secondary="metrics transmission" data-type="indexterm" id="transnode"/>extremely simple, arguably even simpler than the one used by Logstash UDP. An example message that increments a metric named <code>foo.bar.baz</code> looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">foo.bar.baz:1|c</pre>&#13;
&#13;
<p>Such interactions could very easily be rebuilt using the <code>dgram</code> module, like in the previous section. However, this code sample will make use of an existing package. There are a few out there, but this example uses the <code>statsd-client</code> package.</p>&#13;
&#13;
<p>Again, start by rebuilding a version of the consumer service. Copy the <em>web-api/consumer-http-basic.js</em> file created in <a data-type="xref" href="ch01.html#ex_consumer">Example 1-7</a> to <em>web-api/consumer-http-metrics.js</em> as a starting point. From there, modify the file to resemble <a data-type="xref" href="#ex_statsd_consumer">Example 4-7</a>. Be sure to run the <code>npm install</code> command to get the required package as well.</p>&#13;
<div data-type="example" id="ex_statsd_consumer">&#13;
<h5><span class="label">Example 4-7. </span><em>web-api/consumer-http-metrics.js</em> (first half)</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node&#13;
</code><code>&#13;
</code><code class="c1">// npm install fastify@3.2 node-fetch@2.6 statsd-client@0.4.4 middie@5.1&#13;
</code><code class="kr">const</code><code> </code><code class="nx">server</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'fastify'</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">fetch</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'node-fetch'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">HOST</code><code> </code><code class="o">=</code><code> </code><code class="s1">'127.0.0.1'</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">PORT</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code><code> </code><code class="o">||</code><code> </code><code class="mi">3000</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">TARGET</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">TARGET</code><code> </code><code class="o">||</code><code> </code><code class="s1">'localhost:4000'</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">SDC</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'statsd-client'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">statsd</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="p">(</code><code class="nx">require</code><code class="p">(</code><code class="s1">'statsd-client'</code><code class="p">)</code><code class="p">)</code><code class="p">(</code><code class="p">{</code><code class="nx">host</code><code class="o">:</code><code> </code><code class="s1">'localhost'</code><code class="p">,</code><code>&#13;
  </code><code class="nx">port</code><code class="o">:</code><code> </code><code class="mi">8125</code><code class="p">,</code><code> </code><code class="nx">prefix</code><code class="o">:</code><code> </code><code class="s1">'web-api'</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO3-1" id="co_observability_CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
&#13;
</code><code class="p">(</code><code class="nx">async</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="nx">await</code><code> </code><code class="nx">server</code><code class="p">.</code><code class="nx">register</code><code class="p">(</code><code class="nx">require</code><code class="p">(</code><code class="s1">'middie'</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">use</code><code class="p">(</code><code class="nx">statsd</code><code class="p">.</code><code class="nx">helpers</code><code class="p">.</code><code class="nx">getExpressMiddleware</code><code class="p">(</code><code class="s1">'inbound'</code><code class="p">,</code><code> </code><code class="p">{</code><code> </code><a class="co" href="#callout_observability_CO3-2" id="co_observability_CO3-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
    </code><code class="nx">timeByUrl</code><code class="o">:</code><code> </code><code class="kc">true</code><code class="p">}</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="kr">const</code><code> </code><code class="nx">begin</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="nb">Date</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="kr">const</code><code> </code><code class="nx">req</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">fetch</code><code class="p">(</code><code class="sb">`</code><code class="sb">http://</code><code class="si">${</code><code class="nx">TARGET</code><code class="si">}</code><code class="sb">/recipes/42</code><code class="sb">`</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">timing</code><code class="p">(</code><code class="s1">'outbound.recipe-api.request-time'</code><code class="p">,</code><code> </code><code class="nx">begin</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO3-3" id="co_observability_CO3-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
    </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">increment</code><code class="p">(</code><code class="s1">'outbound.recipe-api.request-count'</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO3-4" id="co_observability_CO3-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
    </code><code class="kr">const</code><code> </code><code class="nx">producer_data</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">json</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
    </code><code class="k">return</code><code> </code><code class="p">{</code><code> </code><code class="nx">consumer_pid</code><code class="o">:</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">pid</code><code class="p">,</code><code> </code><code class="nx">producer_data</code><code> </code><code class="p">}</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/error'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code> </code><code class="k">throw</code><code> </code><code class="k">new</code><code> </code><code class="nb">Error</code><code class="p">(</code><code class="s1">'oh no'</code><code class="p">)</code><code class="p">;</code><code> </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">server</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="nx">PORT</code><code class="p">,</code><code> </code><code class="nx">HOST</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`</code><code class="sb">Consumer running at http://</code><code class="si">${</code><code class="nx">HOST</code><code class="si">}</code><code class="sb">:</code><code class="si">${</code><code class="nx">PORT</code><code class="si">}</code><code class="sb">/</code><code class="sb">`</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO3-1" id="callout_observability_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Metric names are prefixed with <code>web-api</code>.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO3-2" id="callout_observability_CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>A generic middleware that automatically tracks inbound requests.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO3-3" id="callout_observability_CO3-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>This tracks the perceived timing to <em>recipe-api</em>.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO3-4" id="callout_observability_CO3-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>The number of outbound requests is also tracked.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>A few things are going on with this new set of changes. First, it requires the <code>statsd-client</code> package and <a data-primary="statsd-client package" data-type="indexterm" id="idm46291188669416"/><a data-primary="packages" data-secondary="statsd-client" data-type="indexterm" id="idm46291188668824"/>configures a connection to the StatsD service listening at <span class="keep-together"><code>localhost:8125</code></span>. It also configures the package to use a prefix value of <code>web-api</code>. This value represents the name of the service reporting the metrics (likewise, if you made similar changes to <em>recipe-api</em>, you’d set its prefix accordingly). Graphite works by using a hierarchy for naming metrics, so metrics sent from this service will all have the same prefix to differentiate them from metrics sent by another service.</p>&#13;
&#13;
<p>The code makes use of a generic middleware provided by the <code>statsd-client</code> package. As the method name implies, it was originally designed for <em>Express</em>, but Fastify mostly supports the same middleware interface, so this application is able to reuse it. The first argument is another prefix name, and <code>inbound</code> implies that the metrics being sent here are associated with incoming requests.</p>&#13;
&#13;
<p>Next, two values are manually tracked. The first is the amount of time the <em>web-api</em> perceives the <em>recipe-api</em> to have taken. Note that this time should always be longer than the time <em>recipe-api</em> believes the response took. This is due to the overhead of sending a request over the network. This timing value is written to a metric named <code>outbound.recipe-api.request-time</code>. The application also tracks how many requests are sent. This value is provided as <code>outbound.recipe-api.request-count</code>. You could even get more granular here. For example, for a production application, the status codes that the <em>recipe-api</em> responds <a data-primary="recipe-api" data-secondary="response codes" data-type="indexterm" id="idm46291189019352"/>with could also be tracked, which would allow an increased rate of failures to be visible.</p>&#13;
&#13;
<p>Next, run the following commands each in a separate terminal window. This will start your newly created service, run a copy of the producer, run Autocannon to get a stream of good requests, and also trigger some bad requests:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ NODE_DEBUG</code><code class="o">=</code>statsd-client node web-api/consumer-http-metrics.js&#13;
<code class="nv">$ </code>node recipe-api/producer-http-basic.js&#13;
<code class="nv">$ </code>autocannon -d <code class="m">300</code> -R <code class="m">5</code> -c <code class="m">1</code> http://localhost:3000&#13;
<code class="nv">$ </code>watch -n1 curl http://localhost:3000/error</pre>&#13;
&#13;
<p>Those commands will generate a stream of data, which gets passed to StatsD before being sent to Graphite. Now that you have some data, you’re ready to create a dashboard to <a data-primary="Node.js" data-secondary="metrics transmission" data-startref="transnode" data-type="indexterm" id="idm46291188948472"/>view it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Creating a Grafana Dashboard" data-type="sect2"><div class="sect2" id="idm46291189065768">&#13;
<h2>Creating a Grafana Dashboard</h2>&#13;
&#13;
<p>As the owner <a data-primary="Grafana" data-secondary="dashboard" data-tertiary="creating" data-type="indexterm" id="graf_dash"/>of the <em>web-api</em> service, there are (at least) three different sets of metrics that should be extracted so that you can measure its health. This includes the incoming requests and, importantly, differentiating 200 from 500. It also includes the amount of time that <em>recipe-api</em>, <a data-primary="recipe-api" data-secondary="reply time" data-type="indexterm" id="idm46291188585576"/>an upstream service, takes to reply. The final set of required information is the rate of requests to the <em>recipe-api</em> service. If you determine the <em>web-api</em> service is slow, you might use this information to discover that the <em>recipe-api</em> service is slowing it down.</p>&#13;
&#13;
<p>Switch back to your web browser with the Grafana interface. There is a large plus symbol in the sidebar; click it to be taken to the <a class="orm:hideurl" href="http://localhost:8000/dashboard/new">New dashboard</a> screen. On this screen you’ll see a New Panel rectangle. Inside of it is an Add Query button. Click that button to be taken to the query editor screen.</p>&#13;
&#13;
<p>On this new screen, you’ll see an empty graph at the top and inputs to describe the graph below. The UI lets you describe the query using two fields. The first is called Series and is where you can input the hierarchical metric name. The second field is called Functions. Both of these fields provide autocomplete for matching metric names. First, start with the Series field.&#13;
Click the “select metric” text next to the Series label and then click <code>stats_count</code> from the drop-down menu.&#13;
Then click “select metric” again and select <code>web-api</code>. Continue this for the values <code>inbound</code>, <code>response_code</code>, and finally <code>*</code> (the <code>*</code> is a wildcard and will match any value). At this point, the graph has been updated and should show two sets of entries.</p>&#13;
&#13;
<p>The graph labels aren’t too friendly just yet. They’re displaying the entire hierarchy name instead of <a data-primary="Grafana" data-secondary="functions" data-type="indexterm" id="idm46291188964040"/><a data-primary="functions" data-secondary="Grafana" data-type="indexterm" id="idm46291188963064"/>just the easy-to-read values 200 and 500. A <em>Function</em> can be used to fix this. Click the plus sign next to the Functions label, then click Alias, and then click &#13;
<span class="keep-together">aliasByNode()</span>. This will insert the function and also automatically provide a default argument of 4. This is because the asterisk in the query is the 4th entry in the (zero-based) hierarchy metric name. The graph labels have been updated to display just 200 and 500.</p>&#13;
&#13;
<p>In the upper-right corner of the panel with the Series and Functions fields, there’s a pencil icon with a tooltip titled Toggle <a data-primary="Grafana" data-secondary="dashboard" data-tertiary="text edit mode" data-type="indexterm" id="idm46291188959960"/>text edit mode. Click that, and the graphical entry will change into a text version. This is helpful for quickly writing a query. The value you should have looks like the following:</p>&#13;
&#13;
<pre data-type="programlisting">aliasByNode(stats_counts.web-api.inbound.response_code.*, 4)</pre>&#13;
&#13;
<p>In the left column, click the gear icon labeled General. On this screen you’re able to modify generic <a data-primary="Grafana" data-secondary="dashboard" data-tertiary="settings" data-type="indexterm" id="idm46291188957192"/>settings about this particular graph. Click the Title field, and input a value of Incoming Status Codes. Once that’s done, click the large arrow in the upper-left corner of the screen. This will take you from the panel editor screen and back to the dashboard edit screen. At this point, your dashboard will have a single panel.</p>&#13;
&#13;
<p>Next, click the Add panel button in the upper-right corner of the screen and then click the Add query button again. This will allow you to add a second panel to the dashboard. This next panel will track the time it takes to query the <em>recipe-api</em>. Create the appropriate Series and Functions entries to reproduce the following:</p>&#13;
&#13;
<pre data-type="programlisting">aliasByNode(stats.timers.web-api.outbound.*.request-time.upper_90, 4)</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>StatsD is generating some of these metric names for you. For example, <code>stats.timers</code> is a StatsD prefix, <code>web-api.outbound.recipe-api.request-time</code> is provided by the application, and the timing-related metric names under that (such as <code>upper_90</code>) are again calculated by StatsD. In this case, the query is looking at TP90 timing values.</p>&#13;
</div>&#13;
&#13;
<p>Since this graph measures time and is not a generic counter, the units should be modified as well (this information is measured in milliseconds). Click the second tab on the left, with a tooltip of Visualization. Then, scroll down the section labeled Axes, find the group titled Left Y, and then click the Unit drop-down menu. Click Time, then click milliseconds (ms). The graph will then be updated with proper units.</p>&#13;
&#13;
<p>Click the third General tab again and set the panel’s title to Outbound Service Timing. Click the back arrow again to return to the dashboard edit screen.</p>&#13;
&#13;
<p>Finally, click the Add panel button again and go through creating a final panel. This panel will be titled Outbound Request Count, won’t need any special units, and will use the following query:</p>&#13;
&#13;
<pre data-type="programlisting">aliasByNode(stats_counts.web-api.outbound.*.request-count, 3)</pre>&#13;
&#13;
<p>Click the back button a final time to return to the dashboard editor screen. In the upper-right corner of the screen, click the Save dashboard icon, give the dashboard a name of Web API Overview, and save the dashboard. The dashboard is now saved and will have a URL associated with it. If you were using an instance of Grafana permanently installed for your organization, this URL would be a permalink that you could provide to others and would make a great addition to your project’s README.</p>&#13;
&#13;
<p>Feel free to drag the panels <a data-primary="Grafana" data-secondary="dashboard" data-tertiary="panels" data-type="indexterm" id="idm46291189001256"/>around and resize them until you get something that is aesthetically pleasing. In the upper right corner of the screen, you can also change the time range. Set it to “Last 15 minutes,” since you likely don’t have data much older than that. Once you’re done, your dashboard should look something like <a data-type="xref" href="#fig_grafana">Figure 4-5</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig_grafana">&#13;
<img alt="Grafana dashboard showing Incoming Status Codes, Outbound Service Timing, and Outbound Request Count" src="assets/dsnj_0405.png"/>&#13;
<h6><span class="label">Figure 4-5. </span>Completed Grafana dashboard</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Node.js Health Indicators" data-type="sect2"><div class="sect2" id="idm46291188950568">&#13;
<h2>Node.js Health Indicators</h2>&#13;
&#13;
<p>There is some generic health <a data-primary="Grafana" data-secondary="dashboard" data-tertiary="health information" data-type="indexterm" id="idm46291188995400"/><a data-primary="health indicators" data-type="indexterm" id="healthind"/>information about a running Node.js process that is also worth collecting for the dashboard. Modify your <em>web-api/consumer-http-metrics.js</em> file by adding the code from <a data-type="xref" href="#ex_statsd_consumer_extra">Example 4-8</a> to the end of the file. Restart the service and keep an eye on the data that is being generated. These new metrics represent values that can increase or decrease over time and are better represented as <em>Gauges</em>.</p>&#13;
<div data-type="example" id="ex_statsd_consumer_extra">&#13;
<h5><span class="label">Example 4-8. </span><em>web-api/consumer-http-metrics.js</em> (second half)</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code><code> </code><code class="nx">v8</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'v8'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">fs</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'fs'</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">setInterval</code><code class="p">(</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">gauge</code><code class="p">(</code><code class="s1">'server.conn'</code><code class="p">,</code><code> </code><code class="nx">server</code><code class="p">.</code><code class="nx">server</code><code class="p">.</code><code class="nx">_connections</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO4-1" id="co_observability_CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">m</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">memoryUsage</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO4-2" id="co_observability_CO4-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
  </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">gauge</code><code class="p">(</code><code class="s1">'server.memory.used'</code><code class="p">,</code><code> </code><code class="nx">m</code><code class="p">.</code><code class="nx">heapUsed</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">gauge</code><code class="p">(</code><code class="s1">'server.memory.total'</code><code class="p">,</code><code> </code><code class="nx">m</code><code class="p">.</code><code class="nx">heapTotal</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">h</code><code> </code><code class="o">=</code><code> </code><code class="nx">v8</code><code class="p">.</code><code class="nx">getHeapStatistics</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO4-3" id="co_observability_CO4-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
  </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">gauge</code><code class="p">(</code><code class="s1">'server.heap.size'</code><code class="p">,</code><code> </code><code class="nx">h</code><code class="p">.</code><code class="nx">used_heap_size</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">gauge</code><code class="p">(</code><code class="s1">'server.heap.limit'</code><code class="p">,</code><code> </code><code class="nx">h</code><code class="p">.</code><code class="nx">heap_size_limit</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
  </code><code class="nx">fs</code><code class="p">.</code><code class="nx">readdir</code><code class="p">(</code><code class="s1">'/proc/self/fd'</code><code class="p">,</code><code> </code><code class="p">(</code><code class="nx">err</code><code class="p">,</code><code> </code><code class="nx">list</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="k">if</code><code> </code><code class="p">(</code><code class="nx">err</code><code class="p">)</code><code> </code><code class="k">return</code><code class="p">;</code><code>&#13;
    </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">gauge</code><code class="p">(</code><code class="s1">'server.descriptors'</code><code class="p">,</code><code> </code><code class="nx">list</code><code class="p">.</code><code class="nx">length</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO4-4" id="co_observability_CO4-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
  </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">begin</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="nb">Date</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">setTimeout</code><code class="p">(</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code> </code><code class="nx">statsd</code><code class="p">.</code><code class="nx">timing</code><code class="p">(</code><code class="s1">'eventlag'</code><code class="p">,</code><code> </code><code class="nx">begin</code><code class="p">)</code><code class="p">;</code><code> </code><code class="p">}</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO4-5" id="co_observability_CO4-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
</code><code class="p">}</code><code class="p">,</code><code> </code><code class="mi">10</code><code class="nx">_000</code><code class="p">)</code><code class="p">;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO4-1" id="callout_observability_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Number of connections to server</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO4-2" id="callout_observability_CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Process heap utilization</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO4-3" id="callout_observability_CO4-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>V8 heap utilization</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO4-4" id="callout_observability_CO4-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Open file descriptors, ironically using a file descriptor</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO4-5" id="callout_observability_CO4-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Event loop lag</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This code will poll the Node.js underbelly every 10 seconds for key information about the process. As an exercise of your newfound Grafana skills, create five new dashboards containing this newly captured data. In the metric namespace hierarchy, the guage metrics begin with <code>stats.gauges</code>, while the timer starts with <code>stats.timers</code>.</p>&#13;
&#13;
<p>The first set of data, provided as <code>server.conn</code>, is the number of active connections to the web server. Most Node.js web frameworks expose this value in some manner; check out the documentation for your framework of choice.</p>&#13;
&#13;
<p>Information about <a data-primary="Grafana" data-secondary="process memory" data-type="indexterm" id="idm46291188315560"/><a data-primary="memory" data-secondary="process memory, Grafana" data-type="indexterm" id="idm46291188314712"/><a data-primary="process memory, Grafana" data-type="indexterm" id="idm46291188313864"/>the process memory usage is also captured. This is being recorded as two values, <code>server.memory.used</code> and <code>server.memory.total</code>. When creating a graph for these values, their unit should be set to Data/Bytes, and Grafana is smart enough to display more specific units like MB. A very similar panel could then be made based on the V8 heap size and limit.</p>&#13;
&#13;
<p>The event loop lag <a data-primary="metrics" data-secondary="event loops, lag" data-type="indexterm" id="idm46291188311736"/><a data-primary="event loops" data-secondary="lag" data-type="indexterm" id="idm46291188310888"/>metric displays how long it takes the application to call a function that was scheduled to run as early as zero milliseconds from the time <code>setTimeout()</code> was <a data-primary="setTimeout() function" data-type="indexterm" id="idm46291188309368"/><a data-primary="functions" data-secondary="setTimeout()" data-type="indexterm" id="idm46291188308760"/>called. This graph should display the value in milliseconds. A healthy event loop should have a number between zero and two. Overwhelmed services might start taking tens of milliseconds.</p>&#13;
&#13;
<p>Finally, the number of open file descriptors can indicate a leak in a Node.js application. Sometimes files will be opened but will never be closed, and this can lead to consumption of server resources and result in a process crash.</p>&#13;
&#13;
<p>Once you’ve added the new panels, your dashboard may then resemble <a data-type="xref" href="#fig_grafana_advanced">Figure 4-6</a>. Save the modified dashboard so that you don’t lose your changes.</p>&#13;
&#13;
<figure><div class="figure" id="fig_grafana_advanced">&#13;
<img alt="Grafana dashboard showing server memory usage, V8 memory usage, and open file descriptors" src="assets/dsnj_0406.png"/>&#13;
<h6><span class="label">Figure 4-6. </span>Updated Grafana dashboard</h6>&#13;
</div></figure>&#13;
&#13;
<p>This section only covers the basics of what can be done with the StatsD, Graphite, and Grafana stack. There are many query functions that haven’t been covered, including other forms of visualizations, how to manually color individual time series entries (like green for 2XX, yellow for 4XX, and red for 5XX), and so on.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291188303016">&#13;
<h5>Alternatives to Graphite + StatsD + Grafana</h5>&#13;
<p>There is a bit of overlap between <a data-primary="logging" data-secondary="metrics and" data-type="indexterm" id="idm46291188301992"/><a data-primary="metrics" data-secondary="logs and" data-type="indexterm" id="idm46291188301144"/>logs and metrics. As covered in <a data-type="xref" href="#ch_monitoring_sec_log">“Logging with ELK”</a>, numeric data can be extracted from logs and be displayed in a graph. This means several of the tools that work as alternatives for logging also work as alternatives for metrics. Hosted cloud solutions like Datadog, AWS CloudWatch, and GCE Stackdriver each support metric extraction to various degrees.</p>&#13;
&#13;
<p>Different components of the stack covered in this section can be swapped out. &#13;
<span class="keep-together">With StatsD</span> and Graphite, the application pushes data to the StatsD service and stores data using Graphite. An alternative backend, Prometheus, works by polling &#13;
<span class="keep-together">the application</span> for stats. In this case the application buffers stats in memory and flushes the values once polled. Although Graphite emphasizes a hierarchy of stats, &#13;
<span class="keep-together">Prometheus</span> &#13;
<span class="keep-together">emphasizes</span> key/value data pairs called labels that are attached to metrics. Grafana can use Prometheus as a data source.</p>&#13;
&#13;
<p>Another common stack <a data-primary="Telegraf" data-type="indexterm" id="idm46291188295384"/>consists of Telegraf, a daemon that collects metrics; InfluxDB, another time-series database; and Grafana (again) for dashboards. As always, be sure to research which model fits your organization the best before deciding which technology to <a data-primary="Grafana" data-secondary="dashboard" data-startref="graf_dash" data-type="indexterm" id="idm46291188294392"/><a data-primary="monitoring" data-secondary="metrics" data-startref="mon_metric" data-type="indexterm" id="idm46291188293304"/><a data-primary="health indicators" data-startref="healthind" data-type="indexterm" id="idm46291188292216"/>implement.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Distributed Request Tracing with Zipkin" data-type="sect1"><div class="sect1" id="ch_monitoring_sec_trace">&#13;
<h1>Distributed Request Tracing with Zipkin</h1>&#13;
&#13;
<p><a data-type="xref" href="#ch_monitoring_sec_log">“Logging with ELK”</a> looked at storing <a data-primary="metrics" data-secondary="distributed request tracing" data-type="indexterm" id="met_dist"/><a data-primary="distributed request tracing" data-type="indexterm" id="met_dist1"/><a data-primary="Zipkin" data-type="indexterm" id="idm46291188286872"/><a data-primary="monitoring" data-secondary="Zipkin request tracing" data-type="indexterm" id="mon_Zip"/>logs from a Node.js process. Such logs contain information about the internal operations of a process. Likewise, <a data-type="xref" href="#ch_monitoring_sec_metrics">“Metrics with Graphite, StatsD, and Grafana”</a> looked at storing numeric metrics. These metrics are useful for looking at numeric data in aggregate about an application, such as throughput and failure rates for an endpoint. However, neither of these tools allow for associating a specific external request with all the internal requests it may then generate.</p>&#13;
&#13;
<p>Consider, for example, a slightly more complex version of the services covered so far. Instead of just a <em>web-api</em> and a <em>recipe-api</em> service, there’s an additional <em>user-api</em> and a <em>user-store</em> service. The <em>web-api</em> will still call the <em>recipe-api</em> service as before, but now the <em>web-api</em> will also call the <em>user-api</em> service, which <a data-primary="Zipkin" data-secondary="user-api service" data-type="indexterm" id="idm46291188279848"/><a data-primary="Zipkin" data-secondary="user-store service" data-type="indexterm" id="idm46291188279000"/><a data-primary="user-api service, Zipkin" data-type="indexterm" id="idm46291188278152"/><a data-primary="user-store service, Zipkin" data-type="indexterm" id="idm46291188277544"/><a data-primary="errors" data-secondary="HTTP 500 error" data-type="indexterm" id="idm46291188276936"/><a data-primary="HTTP 500 error" data-type="indexterm" id="idm46291188276088"/>will in turn call the <em>user-store</em> service. In this scenario, if any one of the services produces a 500 error, that error will bubble up and the overall request will fail with a 500. How would you find the cause of a specific error with the tools used so far?</p>&#13;
&#13;
<p>Well, if you know that an error occurred on Tuesday at 1:37 P.M., you might be tempted to look through logs stored in ELK between the time of 1:36 P.M. and 1:38 P.M. Goodness knows I’ve done this myself. Unfortunately, if there is a high volume of logs, this could mean sifting through thousands of individual log entries. Worse, other errors happening at the same time can “muddy the water,” making it hard to know which logs are actually associated with the erroneous request.</p>&#13;
&#13;
<p>At a very basic level, requests <a data-primary="request_ID" data-type="indexterm" id="idm46291188273848"/>made deeper within an organization can be associated with a single incoming external request by passing around a <em>request ID</em>. This is a unique identifier that is generated when the first request is received, which is then somehow passed between upstream services. Then, any logs associated with this request will contain some sort of <code>request_id</code> field, which can then be <a data-primary="Kibana" data-secondary="request filtering" data-type="indexterm" id="idm46291188271992"/>filtered using Kibana. This approach solves the associated request conundrum but loses information about the hierarchy of related requests.</p>&#13;
&#13;
<p><em>Zipkin</em>, sometimes referred <a data-primary="OpenZipkin" data-seealso="Zipkin" data-type="indexterm" id="idm46291188270216"/>to as <em>OpenZipkin</em>, is a tool that was created to alleviate situations just like this one. Zipkin is a service that runs and exposes an HTTP API. This API accepts JSON payloads describing request metadata, as they are both sent by clients and received by servers. Zipkin also defines a set of headers that are passed from client to server. These headers allow processes to associate outgoing requests from a client with incoming requests to a server. Timing information is also sent, which then allows Zipkin to display a graphical timeline of a request hierarchy.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="How Does Zipkin Work?" data-type="sect2"><div class="sect2" id="idm46291188268168">&#13;
<h2>How Does Zipkin Work?</h2>&#13;
&#13;
<p>In the aforementioned scenario with the four services, the relationship between services transpires over four requests. When this happens, seven messages will be sent to the Zipkin service. <a data-type="xref" href="#fig_zipkin_overview">Figure 4-7</a> contains a visualization of the service relationships, the passed messages, and the additional headers.</p>&#13;
&#13;
<figure><div class="figure" id="fig_zipkin_overview">&#13;
<img alt="Dependency graph between four services" src="assets/dsnj_0407.png"/>&#13;
<h6><span class="label">Figure 4-7. </span>Example requests and Zipkin data</h6>&#13;
</div></figure>&#13;
&#13;
<p>One concept that has been <a data-primary="latency" data-secondary="Zipkin" data-type="indexterm" id="idm46291188263400"/><a data-primary="Zipkin" data-secondary="latency" data-type="indexterm" id="idm46291188262552"/>repeated a few times so far in this book is that a client will perceive one latency of a request, while a server will perceive another latency. A client will always determine that a request takes longer than the server. This is due to the time it takes a message to be sent over the network, plus other things that are hard to measure, such as a web server package automatically parsing a JSON request before user code can start measuring time.</p>&#13;
&#13;
<p>Zipkin allows you to measure the difference in opinion between client and server. This is why the four requests in the example situation, marked as solid arrows in <a data-type="xref" href="#fig_zipkin_overview">Figure 4-7</a>, result in seven different messages being sent to Zipkin. The first message, terminating with S1, only contains a <em>server message</em>. In this <a data-primary="Zipkin" data-secondary="server message" data-type="indexterm" id="idm46291188259304"/><a data-primary="Zipkin" data-secondary="client message" data-type="indexterm" id="idm46291188258456"/>case, the third-party client isn’t reporting its perceived time, so there’s just the server message. For the three requests terminating in S2, S3, and S4, there is a correlating <em>client message</em>, namely C2, C3, and C4.</p>&#13;
&#13;
<p>The different client and server messages can be sent from the different instances, asynchronously, and can be received in any order. The Zipkin service will then stitch them each together <a data-primary="Zipkin" data-secondary="web UI" data-type="indexterm" id="idm46291188256312"/>and visualize the request hierarchy using the Zipkin web UI. The C2 message will look something like this:</p>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">[{</code>&#13;
  <code class="nt">"id"</code><code class="p">:</code>       <code class="s2">"0000000000000111"</code><code class="p">,</code>&#13;
  <code class="nt">"traceId"</code><code class="p">:</code>  <code class="s2">"0000000000000100"</code><code class="p">,</code>&#13;
  <code class="nt">"parentId"</code><code class="p">:</code> <code class="s2">"0000000000000110"</code><code class="p">,</code>&#13;
  <code class="nt">"timestamp"</code><code class="p">:</code> <code class="mi">1579221096510000</code><code class="p">,</code>&#13;
  <code class="nt">"name"</code><code class="p">:</code> <code class="s2">"get_recipe"</code><code class="p">,</code> <code class="nt">"duration"</code><code class="p">:</code> <code class="mi">80000</code><code class="p">,</code> <code class="nt">"kind"</code><code class="p">:</code> <code class="s2">"CLIENT"</code><code class="p">,</code>&#13;
  <code class="nt">"localEndpoint"</code><code class="p">:</code> <code class="p">{</code>&#13;
    <code class="nt">"serviceName"</code><code class="p">:</code> <code class="s2">"web-api"</code><code class="p">,</code> <code class="nt">"ipv4"</code><code class="p">:</code> <code class="s2">"127.0.0.1"</code><code class="p">,</code> <code class="nt">"port"</code><code class="p">:</code> <code class="mi">100</code>&#13;
  <code class="p">},</code>&#13;
  <code class="nt">"remoteEndpoint"</code><code class="p">:</code> <code class="p">{</code> <code class="nt">"ipv4"</code><code class="p">:</code> <code class="s2">"127.0.0.2"</code><code class="p">,</code> <code class="nt">"port"</code><code class="p">:</code> <code class="mi">200</code> <code class="p">},</code>&#13;
  <code class="nt">"tags"</code><code class="p">:</code> <code class="p">{</code>&#13;
    <code class="nt">"http.method"</code><code class="p">:</code> <code class="s2">"GET"</code><code class="p">,</code> <code class="nt">"http.path"</code><code class="p">:</code> <code class="s2">"/recipe/42"</code><code class="p">,</code> <code class="nt">"diagram"</code><code class="p">:</code> <code class="s2">"C2"</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">}]</code></pre>&#13;
&#13;
<p>These messages can be queued up by an application and occasionally flushed in batches to the Zipkin service, which is why the root JSON entry is an array. In <a data-type="xref" href="#ex_zipkin_consumer">Example 4-9</a>, only a single message is being transmitted.</p>&#13;
&#13;
<p>The client message and server message pairs will end up containing the same <code>id</code>, <code>traceId</code>, and <code>parentId</code> identifiers. The <code>timestamp</code> field represents the time when the client or server first perceived the request to start, and the <code>duration</code> is how long the service thought the request lasted. Both of these fields are measured in microseconds. The Node.js <em>wall clock</em>, attainable <a data-primary="Date.now() function" data-type="indexterm" id="idm46291188174984"/><a data-primary="functions" data-secondary="Date.now()" data-type="indexterm" id="idm46291188174248"/><a data-primary="wall clock" data-type="indexterm" id="idm46291188173304"/>via <code>Date.now()</code>, only has millisecond accuracy, so it’s common to multiply that value by 1,000.<sup><a data-type="noteref" href="ch04.html#idm46291188172088" id="idm46291188172088-marker">1</a></sup> The <code>kind</code> field is set to either <code>CLIENT</code> or <code>SERVER</code>, depending on which side of the request is being logged. The <code>name</code> field represents a name for the endpoint and should have a finite set of values (in other words, don’t use an identifier).</p>&#13;
&#13;
<p>The <code>localEndpoint</code> field represents the service sending the message (the server with a <code>SERVER</code> message or the client with a <code>CLIENT</code> message). The service provides its own name in here, the port it’s listening on, and its own IP address. The <span class="keep-together"><code>remoteEndpoint</code></span> field contains information about the other service (a <code>SERVER</code> message probably won’t know the client’s <code>port</code>, and likely won’t even know the client’s <code>name</code>).</p>&#13;
&#13;
<p>The <code>tags</code> field contains <a data-primary="Zipkin" data-secondary="request metadata" data-type="indexterm" id="idm46291188164168"/>metadata about the request. In this example, information about the HTTP request is provided as <code>http.method</code> and <code>http.path</code>. With other &#13;
<span class="keep-together">protocols,</span> different metadata would be attached, such as a gRPC service and &#13;
<span class="keep-together">method</span> name.</p>&#13;
&#13;
<p>The identifiers sent in the seven different messages have been re-created in <a data-type="xref" href="#table_zipkin_labels">Table 4-2</a>.</p>&#13;
<table id="table_zipkin_labels">&#13;
<caption><span class="label">Table 4-2. </span>Values reported from <a data-type="xref" href="#fig_zipkin_overview">Figure 4-7</a></caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Message</th>&#13;
<th><code>id</code></th>&#13;
<th><code>parentId</code></th>&#13;
<th><code>traceId</code></th>&#13;
<th><code>kind</code></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>S1</p></td>&#13;
<td><p>110</p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p>100</p></td>&#13;
<td><p>SERVER</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>C2</p></td>&#13;
<td><p>111</p></td>&#13;
<td><p>110</p></td>&#13;
<td><p>100</p></td>&#13;
<td><p>CLIENT</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>S2</p></td>&#13;
<td><p>111</p></td>&#13;
<td><p>110</p></td>&#13;
<td><p>100</p></td>&#13;
<td><p>SERVER</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>C3</p></td>&#13;
<td><p>121</p></td>&#13;
<td><p>110</p></td>&#13;
<td><p>100</p></td>&#13;
<td><p>CLIENT</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>S3</p></td>&#13;
<td><p>121</p></td>&#13;
<td><p>110</p></td>&#13;
<td><p>100</p></td>&#13;
<td><p>SERVER</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>C4</p></td>&#13;
<td><p>122</p></td>&#13;
<td><p>121</p></td>&#13;
<td><p>100</p></td>&#13;
<td><p>CLIENT</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>S4</p></td>&#13;
<td><p>122</p></td>&#13;
<td><p>121</p></td>&#13;
<td><p>100</p></td>&#13;
<td><p>SERVER</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Apart from the messages sent to the server, the other important part of Zipkin is the metadata that is sent from client to server. Different protocols have different standards for sending this metadata. With HTTP, the metadata is sent via headers. These headers are provided by C2, C3, and C4 and are received by S2, S3, and S4. Each of these <a data-primary="Zipkin" data-secondary="metadata headers" data-type="indexterm" id="idm46291188128664"/>headers has a different meaning:</p>&#13;
<dl>&#13;
<dt><code>X-B3-TraceId</code></dt>&#13;
<dd>&#13;
<p>Zipkin refers to all related requests as a <em>trace</em>. This value is Zipkin’s concept of a <em>request ID</em>. This value is passed between all related requests, unchanged.</p>&#13;
</dd>&#13;
<dt><code>X-B3-SpanId</code></dt>&#13;
<dd>&#13;
<p>A <em>span</em> represents a single request, as seen from both a client and a server (like C3/S3). Both the client and server will send a message using the same span ID. There can be multiple spans in a trace, forming a tree structure.</p>&#13;
</dd>&#13;
<dt><code>X-B3-ParentSpanId</code></dt>&#13;
<dd>&#13;
<p>A <em>parent span</em> is used for associating a child span with a parent span. This value is missing for the originating external request but is present for deeper requests.</p>&#13;
</dd>&#13;
<dt><code>X-B3-Sampled</code></dt>&#13;
<dd>&#13;
<p>This is a mechanism used for determining if a particular trace should be reported to Zipkin. For example, an organization may choose to track only 1% of requests.</p>&#13;
</dd>&#13;
<dt><code>X-B3-Flags</code></dt>&#13;
<dd>&#13;
<p>This can be used to tell downstream services that this is a debug request. Services are encouraged to then increase their logging verbosity.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Essentially, each service creates a new span ID for each outgoing request. The current span ID is then provided as the parent ID in the outbound request. This is how the hierarchy of relationships is formed.</p>&#13;
&#13;
<p>Now that you understand the intricacies of Zipkin, it’s time to run a local copy of the Zipkin service and modify the applications to interact with it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running Zipkin via Docker" data-type="sect2"><div class="sect2" id="idm46291188267576">&#13;
<h2>Running Zipkin via Docker</h2>&#13;
&#13;
<p>Again, Docker provides a <a data-primary="Docker" data-secondary="Zipkin" data-type="indexterm" id="idm46291188114744"/><a data-primary="Zipkin" data-secondary="Docker and" data-type="indexterm" id="idm46291188113768"/>convenient platform for running the service. Unlike the other tools covered in this chapter, Zipkin provides an API and a UI using the same port. Zipkin uses a default port of <code>9411</code> for this.</p>&#13;
&#13;
<p>Run this command to download and start the Zipkin service:<sup><a data-type="noteref" href="ch04.html#idm46291188111672" id="idm46291188111672-marker">2</a></sup></p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker run -p 9411:9411 <code class="se">\</code>&#13;
  -it --name distnode-zipkin <code class="se">\</code>&#13;
  openzipkin/zipkin-slim:2.19</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Transmitting Traces from Node.js" data-type="sect2"><div class="sect2" id="idm46291188104520">&#13;
<h2>Transmitting Traces from Node.js</h2>&#13;
&#13;
<p>For this example, you’re going <a data-primary="Zipkin" data-secondary="transmitting traces" data-type="indexterm" id="idm46291188102728"/><a data-primary="traces, transmitting" data-type="indexterm" id="tracetrans"/>to again start by modifying an existing application. Copy the <em>web-api/consumer-http-basic.js</em> file created in <a data-type="xref" href="ch01.html#ex_consumer">Example 1-7</a> to <em>web-api/consumer-http-zipkin.js</em> as a starting point. Modify the file to look like the code in <a data-type="xref" href="#ex_zipkin_consumer">Example 4-9</a>.</p>&#13;
<div data-type="example" id="ex_zipkin_consumer">&#13;
<h5><span class="label">Example 4-9. </span><em>web-api/consumer-http-zipkin.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node&#13;
</code><code>&#13;
</code><code class="c1">// npm install fastify@3.2 node-fetch@2.6 zipkin-lite@0.1&#13;
</code><code class="kr">const</code><code> </code><code class="nx">server</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'fastify'</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">fetch</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'node-fetch'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">HOST</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">HOST</code><code> </code><code class="o">||</code><code> </code><code class="s1">'127.0.0.1'</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">PORT</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code><code> </code><code class="o">||</code><code> </code><code class="mi">3000</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">TARGET</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">TARGET</code><code> </code><code class="o">||</code><code> </code><code class="s1">'localhost:4000'</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">ZIPKIN</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">ZIPKIN</code><code> </code><code class="o">||</code><code> </code><code class="s1">'localhost:9411'</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">Zipkin</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'zipkin-lite'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">zipkin</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="nx">Zipkin</code><code class="p">(</code><code class="p">{</code><code> </code><a class="co" href="#callout_observability_CO5-1" id="co_observability_CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
  </code><code class="nx">zipkinHost</code><code class="o">:</code><code> </code><code class="nx">ZIPKIN</code><code class="p">,</code><code>&#13;
  </code><code class="nx">serviceName</code><code class="o">:</code><code> </code><code class="s1">'web-api'</code><code class="p">,</code><code> </code><code class="nx">servicePort</code><code class="o">:</code><code> </code><code class="nx">PORT</code><code class="p">,</code><code> </code><code class="nx">serviceIp</code><code class="o">:</code><code> </code><code class="nx">HOST</code><code class="p">,</code><code>&#13;
  </code><code class="nx">init</code><code class="o">:</code><code> </code><code class="s1">'short'</code><code> </code><a class="co" href="#callout_observability_CO5-2" id="co_observability_CO5-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">addHook</code><code class="p">(</code><code class="s1">'onRequest'</code><code class="p">,</code><code> </code><code class="nx">zipkin</code><code class="p">.</code><code class="nx">onRequest</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO5-3" id="co_observability_CO5-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">addHook</code><code class="p">(</code><code class="s1">'onResponse'</code><code class="p">,</code><code> </code><code class="nx">zipkin</code><code class="p">.</code><code class="nx">onResponse</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="nx">req</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="nx">req</code><code class="p">.</code><code class="nx">zipkin</code><code class="p">.</code><code class="nx">setName</code><code class="p">(</code><code class="s1">'get_root'</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO5-4" id="co_observability_CO5-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">url</code><code> </code><code class="o">=</code><code> </code><code class="sb">`</code><code class="sb">http://</code><code class="si">${</code><code class="nx">TARGET</code><code class="si">}</code><code class="sb">/recipes/42</code><code class="sb">`</code><code class="p">;</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">zreq</code><code> </code><code class="o">=</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">zipkin</code><code class="p">.</code><code class="nx">prepare</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO5-5" id="co_observability_CO5-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">recipe</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">fetch</code><code class="p">(</code><code class="nx">url</code><code class="p">,</code><code> </code><code class="p">{</code><code> </code><code class="nx">headers</code><code class="o">:</code><code> </code><code class="nx">zreq</code><code class="p">.</code><code class="nx">headers</code><code> </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">zreq</code><code class="p">.</code><code class="nx">complete</code><code class="p">(</code><code class="s1">'GET'</code><code class="p">,</code><code> </code><code class="nx">url</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">producer_data</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">recipe</code><code class="p">.</code><code class="nx">json</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
  </code><code class="k">return</code><code> </code><code class="p">{</code><code class="nx">pid</code><code class="o">:</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">pid</code><code class="p">,</code><code> </code><code class="nx">producer_data</code><code class="p">,</code><code> </code><code class="nx">trace</code><code class="o">:</code><code> </code><code class="nx">req</code><code class="p">.</code><code class="nx">zipkin</code><code class="p">.</code><code class="nx">trace</code><code class="p">}</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="nx">PORT</code><code class="p">,</code><code> </code><code class="nx">HOST</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`</code><code class="sb">Consumer running at http://</code><code class="si">${</code><code class="nx">HOST</code><code class="si">}</code><code class="sb">:</code><code class="si">${</code><code class="nx">PORT</code><code class="si">}</code><code class="sb">/</code><code class="sb">`</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO5-1" id="callout_observability_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The <code>zipkin-lite</code> package is required and instantiated.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO5-2" id="callout_observability_CO5-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p><em>web-api</em> accepts outside requests and can generate trace IDs.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO5-3" id="callout_observability_CO5-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Hooks are called when requests start and finish.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO5-4" id="callout_observability_CO5-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Each endpoint will need to specify its name.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO5-5" id="callout_observability_CO5-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Outbound requests are manually instrumented.</p></dd>&#13;
</dl></div>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>These examples use <a data-primary="zipkin-lite" data-type="indexterm" id="idm46291187746072"/>the <code>zipkin-lite</code> package. This package requires manual instrumentation, which is a fancy way of saying that you, the developer, must call different hooks to interact with the package. I chose it for this project to help demonstrate the different parts of the Zipkin reporting process. For a production app, the official Zipkin package, <a class="orm:hideurl" href="https://www.npmjs.com/package/zipkin"><code>zipkin</code></a>, would make for a better choice.</p>&#13;
</div>&#13;
&#13;
<p>The consumer service represents the first service that an external client will communicate with. Because of this, the <code>init</code> configuration flag has been enabled. This will allow the service to generate a new trace ID. In theory, a reverse proxy can be configured to also generate initial identifier values. The <code>serviceName</code>, <code>servicePort</code>, and <code>serviceIp</code> fields are each used for reporting information about the running service to Zipkin.</p>&#13;
&#13;
<p>The <code>onRequest</code> and <code>onResponse</code> hooks allow the <code>zipkin-lite</code> package to interpose on requests. The <code>onRequest</code> handler runs first. It records the time the request starts and injects a <code>req.zipkin</code> property that can be used throughout the life cycle of the request. Later, the <code>onResponse</code> handler is called. This then calculates the overall time the request took and sends a <code>SERVER</code> message to the Zipkin server.</p>&#13;
&#13;
<p>Within a request handler, two things need to happen. The first is that the name of the endpoint has to be set. This is done by calling <code>req.zipkin.setName()</code>. The second is that for each outbound request that is sent, the appropriate headers need to be applied and the time the request took should be calculated. This is done by first calling <code>req.zipkin.prepare()</code>. When this is called, another time value is recorded and a new span ID is generated. This ID and the other necessary headers are provided in the returned value, which is assigned here to the variable <code>zreq</code>.</p>&#13;
&#13;
<p>These headers are then provided to the request via <code>zreq.headers</code>. Once the request is complete, a call to <code>zreq.complete()</code> is made, passing in the request method and URL. Once this happens, the overall time taken is calculated, and the <code>CLIENT</code> message is then sent to the Zipkin server.</p>&#13;
&#13;
<p>Next up, the producing service should also be modified. This is important because not only should the timing as perceived by the client be reported (<em>web-api</em> in this case), but the timing from the server’s point of view (<em>recipe-api</em>) should be reported as well. Copy the <em>recipe-api/producer-http-basic.js</em> file created in <a data-type="xref" href="ch01.html#ex_producer">Example 1-6</a> to <em>recipe-api/producer-http-zipkin.js</em> as a starting point. Modify the file to look like the code in <a data-type="xref" href="#ex_zipkin_producer">Example 4-10</a>. Most of the file can be left as is, so only the required changes are &#13;
<span class="keep-together">displayed.</span></p>&#13;
<div data-type="example" id="ex_zipkin_producer">&#13;
<h5><span class="label">Example 4-10. </span><em>recipe-api/producer-http-zipkin.js</em> (truncated)</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">PORT</code> <code class="o">=</code> <code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code> <code class="o">||</code> <code class="mi">4000</code><code class="p">;</code>&#13;
<code class="kr">const</code> <code class="nx">ZIPKIN</code> <code class="o">=</code> <code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">ZIPKIN</code> <code class="o">||</code> <code class="s1">'localhost:9411'</code><code class="p">;</code>&#13;
<code class="kr">const</code> <code class="nx">Zipkin</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'zipkin-lite'</code><code class="p">);</code>&#13;
<code class="kr">const</code> <code class="nx">zipkin</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">Zipkin</code><code class="p">({</code>&#13;
  <code class="nx">zipkinHost</code><code class="o">:</code> <code class="nx">ZIPKIN</code><code class="p">,</code>&#13;
  <code class="nx">serviceName</code><code class="o">:</code> <code class="s1">'recipe-api'</code><code class="p">,</code> <code class="nx">servicePort</code><code class="o">:</code> <code class="nx">PORT</code><code class="p">,</code> <code class="nx">serviceIp</code><code class="o">:</code> <code class="nx">HOST</code><code class="p">,</code>&#13;
<code class="p">});</code>&#13;
<code class="nx">server</code><code class="p">.</code><code class="nx">addHook</code><code class="p">(</code><code class="s1">'onRequest'</code><code class="p">,</code> <code class="nx">zipkin</code><code class="p">.</code><code class="nx">onRequest</code><code class="p">());</code>&#13;
<code class="nx">server</code><code class="p">.</code><code class="nx">addHook</code><code class="p">(</code><code class="s1">'onResponse'</code><code class="p">,</code> <code class="nx">zipkin</code><code class="p">.</code><code class="nx">onResponse</code><code class="p">());</code>&#13;
&#13;
<code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/recipes/:id'</code><code class="p">,</code> <code class="nx">async</code> <code class="p">(</code><code class="nx">req</code><code class="p">,</code> <code class="nx">reply</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="nx">req</code><code class="p">.</code><code class="nx">zipkin</code><code class="p">.</code><code class="nx">setName</code><code class="p">(</code><code class="s1">'get_recipe'</code><code class="p">);</code>&#13;
  <code class="kr">const</code> <code class="nx">id</code> <code class="o">=</code> <code class="nb">Number</code><code class="p">(</code><code class="nx">req</code><code class="p">.</code><code class="nx">params</code><code class="p">.</code><code class="nx">id</code><code class="p">);</code></pre></div>&#13;
&#13;
<p><a data-type="xref" href="#ex_zipkin_producer">Example 4-10</a> doesn’t act as a root service, so the <code>init</code> configuration flag has been omitted. If it receives a request directly, it won’t generate a trace ID, unlike the <em>web-api</em> service. Also, note that the same <code>req.zipkin.prepare()</code> method is <a data-primary="recipe-api" data-secondary="req.zipkin.prepare() method" data-type="indexterm" id="idm46291187500744"/>available in this new <em>recipe-api</em> service, even though the example isn’t using it. When implementing Zipkin within services you own, you’ll want to pass the Zipkin headers to as many upstream services as you can.</p>&#13;
&#13;
<p>Be sure to run the <strong><code>npm install zipkin-lite@0.1</code></strong> command in both project &#13;
<span class="keep-together">directories.</span></p>&#13;
&#13;
<p>Once you’ve created the two new service files, run them and then generate a request to the <em>web-api</em> by running the following commands:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>node recipe-api/producer-http-zipkin.js&#13;
<code class="nv">$ </code>node web-api/consumer-http-zipkin.js&#13;
<code class="nv">$ </code>curl http://localhost:3000/</pre>&#13;
&#13;
<p>A new field, named <code>trace</code>, should now be present in the output <a data-primary="curl command" data-type="indexterm" id="idm46291187495400"/><a data-primary="commands" data-secondary="curl" data-type="indexterm" id="idm46291187494792"/>of the <code>curl</code> command. This is the trace ID for the series of requests that have been passed between the services. The value should be 16 hexadecimal <a data-primary="traces, transmitting" data-startref="tracetrans" data-type="indexterm" id="idm46291187493176"/>characters, and in my case, I received the value <code>e232bb26a7941aab</code>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Visualizing a Request Tree" data-type="sect2"><div class="sect2" id="idm46291188104024">&#13;
<h2>Visualizing a Request Tree</h2>&#13;
&#13;
<p>Data about the requests have <a data-primary="visualization" data-secondary="request trees" data-type="indexterm" id="idm46291187488792"/><a data-primary="request trees" data-type="indexterm" id="idm46291187487816"/>been sent to your Zipkin server instance. It’s now time to open the web interface and see how that data is visualized. Open the following URL in your browser:</p>&#13;
&#13;
<pre data-type="programlisting">http://localhost:9411/zipkin/</pre>&#13;
&#13;
<p>You should now be greeted with the Zipkin web interface. It’s not too exciting just yet. The left sidebar contains two links. The first one, which looks like a magnifying glass, is to the current Discover screen. The second link, resembling network nodes, links to the Dependencies screen. At the top of the screen is a plus sign, which can be used for specifying which requests to search for. With this tool you can specify criteria like the service name or tags. But for now you can ignore those. In the upper-right corner is a simple search button, one that will display recent requests. Click the magnifying glass icon, which will perform the search.</p>&#13;
&#13;
<p><a data-type="xref" href="#fig_zipkin_discover">Figure 4-8</a> is an example of what the interface should look like after you’ve performed a search. Assuming you ran the <code>curl</code> command just once, you should see only a &#13;
<span class="keep-together">single</span> entry.</p>&#13;
&#13;
<figure><div class="figure" id="fig_zipkin_discover">&#13;
<img alt="Screenshot of a Zipkin Discover page" src="assets/dsnj_0408.png"/>&#13;
<h6><span class="label">Figure 4-8. </span>Zipkin discover interface</h6>&#13;
</div></figure>&#13;
&#13;
<p>Click the entry to be taken to the timeline view page. This page displays content in two columns. The column on the left displays a timeline of requests. The horizontal axis represents time. The units on the top of the timeline display how much time has passed since the very first <code>SERVER</code> trace was made with the given trace ID. The vertical rows represent the depth of the request; as each subsequent service makes another request, a new row will be added.</p>&#13;
&#13;
<p>For your timeline, you should see two rows. The first row was generated by the <em>web-api</em> and has a call named <em>get_root</em>. The second row was generated by the <em>recipe-api</em> and has a call named <em>get_recipe</em>. A <a data-primary="recipe-api" data-secondary="get_recipe call" data-type="indexterm" id="idm46291187476904"/>more complex version of the timeline you’re seeing, based on the previously mentioned system with an additional <em>user-api</em> and <em>user-store</em>, is displayed in <a data-type="xref" href="#fig_zipkin_timeline">Figure 4-9</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig_zipkin_timeline">&#13;
<img alt="Screenshot of a Zipkin Trace timeline" src="assets/dsnj_0409.png"/>&#13;
<h6><span class="label">Figure 4-9. </span>Example Zipkin trace timeline</h6>&#13;
</div></figure>&#13;
&#13;
<p>Click the second row. The right column will be updated to display additional metadata about the request. The Annotations bar displays a timeline for the span you clicked. Depending on the speed of the request, you will see between two and four dots. The furthest left and furthest right dots represent the time that the client perceived the request to take. If the request was slow enough, you should see two inner dots, and those will represent the time the server perceived the request to take. Since these services are so fast, the dots might overlap and will be hidden by the Zipkin interface.</p>&#13;
&#13;
<p>The Tags section displays the tags associated with the request. This can be used to debug which endpoints are taking the longest time to process and which service instances (by using the IP address and port) are to blame.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Visualizing Microservice Dependencies" data-type="sect2"><div class="sect2" id="idm46291187489736">&#13;
<h2>Visualizing Microservice Dependencies</h2>&#13;
&#13;
<p>The Zipkin interface can also be used <a data-primary="microservice dependencies, visualization" data-type="indexterm" id="idm46291187447960"/><a data-primary="dependencies" data-secondary="microservices and" data-tertiary="visualization" data-type="indexterm" id="idm46291187447224"/><a data-primary="visualization" data-secondary="dependencies" data-type="indexterm" id="idm46291187446008"/>to show aggregate information about the requests that it receives. Click the Dependencies link in the sidebar to be taken to the dependencies screen. The screen should be mostly blank, with a selector at the top to specify a time range and perform a search. The default values should be fine, so click the magnifying glass icon to perform a search.</p>&#13;
&#13;
<p>The screen will then be updated to display two nodes. Zipkin has searched through the different spans it found that matched the time range. Using this information, it has determined how the services are related to each other. With the two example applications, the interface isn’t all that interesting. On the left, you should see a node representing the <em>web-api</em> (where requests originate), and on the right, you should see a node representing the <em>recipe-api</em> (the deepest service in the stack). Small dots move from the left of the screen to the right, showing the relative amount of traffic between the two nodes.</p>&#13;
&#13;
<p>If you were using Zipkin with many different services within an organization, you would see a much more complex map of the relationships between services. <a data-type="xref" href="#fig_zipkin_dependencies">Figure 4-10</a> is an example of what the relationships between the four services in the more complex example would look like.</p>&#13;
&#13;
<figure><div class="figure" id="fig_zipkin_dependencies">&#13;
<img alt="Pseudo screenshot of a Zipkin Dependencies view" src="assets/dsnj_0410.png"/>&#13;
<h6><span class="label">Figure 4-10. </span>Example Zipkin dependency view</h6>&#13;
</div></figure>&#13;
&#13;
<p>Assuming every service within an organization uses Zipkin, such a diagram would be a very powerful tool for understanding the interconnections between services.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291187438504">&#13;
<h5>Alternatives to Zipkin</h5>&#13;
<p><a class="orm:hideurl" href="https://jaegertracing.io">Jaeger</a>, originally developed by Uber, is a newer alternative to Zipkin. While the Zipkin service is mostly self-contained in a single process, Jaeger is a bit more spread out and has an emphasis on having its components deployed to Kubernetes (discussed in <a data-type="xref" href="ch07.html#ch_kubernetes">Chapter 7</a>).</p>&#13;
&#13;
<p>While not necessarily an alternative, <a class="orm:hideurl" href="https://opentelemetry.io">OpenTelemetry</a> is a vendor-neutral specification for describing and implementing a tracing system. Both Zipkin and Jaeger can <a data-primary="metrics" data-secondary="distributed request tracing" data-startref="met_dist" data-type="indexterm" id="idm46291187433608"/><a data-primary="distributed request tracing" data-startref="met_dist1" data-type="indexterm" id="idm46291187432344"/><a data-primary="monitoring" data-secondary="Zipkin request tracing" data-startref="mon_Zip" data-type="indexterm" id="idm46291187431384"/>be compatible with the OpenTelemetry specification.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Health Checks" data-type="sect1"><div class="sect1" id="ch_monitoring_sec_health">&#13;
<h1>Health Checks</h1>&#13;
&#13;
<p><a data-type="xref" href="ch03.html#ch_scaling_sec_rp_subsec_health">“Load Balancing and Health Checks”</a> looked <a data-primary="health checks" data-type="indexterm" id="idm46291187427416"/><a data-primary="HAProxy" data-secondary="health check" data-type="indexterm" id="idm46291187426712"/><a data-primary="monitoring" data-secondary="health check" data-type="indexterm" id="mon_health"/>at how HAProxy can be configured to automatically remove and re-add a running service instance to the pool of candidate instances for routing requests to. HAProxy can do this by making an HTTP request to an endpoint of your choosing and checking the status code. Such an endpoint is also useful for checking the <em>liveness</em> of a service—which is a term meaning a newly deployed service has finished the startup stage and is ready to receive requests (like establishing a database connection). Kubernetes, which is covered in <a data-type="xref" href="ch07.html#ch_kubernetes">Chapter 7</a>, can also make use of such a liveness check. It is generally useful for an application to know if it’s healthy or not.</p>&#13;
&#13;
<p>An application can usually be considered healthy if it is able to respond to incoming requests with correct data without ill side effects. The specifics of how to measure this will change depending on the application. If an application needs to make a connection to a database, and such a connection is lost, then the application probably won’t be able to process the requests it receives. (Note that your application should attempt to reconnect to databases; this is covered in <a data-type="xref" href="ch08.html#ch_resilience_sec_db">“Database Connection Resilience”</a>.) In such a case, it would make sense to have the application declare itself unhealthy.</p>&#13;
&#13;
<p>On the other hand, some features are a bit of a grey area. For example, if a service is unable to establish a connection to a caching service but is still able to connect to a database and serve requests, it is probably fine to declare itself healthy. The grey area in this case is with response time. If the service is no longer able to achieve its SLA, then it might be dangerous to run because it could cost your organization money. In this situation, it might make sense to declare the service <em>degraded</em>.</p>&#13;
&#13;
<p>What would happen in this situation if the degraded service were to declare itself unhealthy? The service might be restarted by some sort of deployment management tool. However, if the problem is that the caching service is down, then perhaps every single service would be restarted. This can lead to situations where no service is available to serve requests. This scenario will be covered in <a data-type="xref" href="#ch_monitoring_sec_alert">“Alerting with Cabot”</a>. For now, consider slow/degraded services healthy.</p>&#13;
&#13;
<p>Health checks are usually run periodically. Sometimes they are triggered by a request from an external service, such as HAProxy making an HTTP request (an operation that defaults to every two seconds). Sometimes they are triggered internally, such as a <code>setInterval()</code> call that checks the application’s health before reporting to an external discovery service like <em>Consul</em> that it is healthy (a check that runs perhaps every 10 seconds). In any case, the overhead of running the health check should not be so high that the process is slowed down or the database is overwhelmed.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Building a Health Check" data-type="sect2"><div class="sect2" id="idm46291187415704">&#13;
<h2>Building a Health Check</h2>&#13;
&#13;
<p>In this section you will <a data-primary="health checks" data-secondary="building" data-type="indexterm" id="healthbuild"/>build a health check for a rather boring service. This application will have both a connection to a Postgres <a data-primary="Postgres databases" data-type="indexterm" id="idm46291187399704"/><a data-primary="Redis" data-type="indexterm" id="idm46291187399096"/>database, resembling a persistent data store, as well as a connection to Redis, which will represent a cache.</p>&#13;
&#13;
<p>Before you start writing code, you’ll need to run the two backing services. Run the commands in <a data-type="xref" href="#ex_postgres_redis">Example 4-11</a> to get a copy of Postgres and Redis running. You’ll need to run each command in a new terminal window. Ctrl + C can be used to kill either service.</p>&#13;
<div data-type="example" id="ex_postgres_redis">&#13;
<h5><span class="label">Example 4-11. </span>Running Postgres and Redis</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>docker run <code class="se">\</code>&#13;
  --rm <code class="se">\</code>&#13;
  -p 5432:5432 <code class="se">\</code>&#13;
  -e <code class="nv">POSTGRES_PASSWORD</code><code class="o">=</code>hunter2 <code class="se">\</code>&#13;
  -e <code class="nv">POSTGRES_USER</code><code class="o">=</code>tmp <code class="se">\</code>&#13;
  -e <code class="nv">POSTGRES_DB</code><code class="o">=</code>tmp <code class="se">\</code>&#13;
  postgres:12.3&#13;
<code class="nv">$ </code>docker run <code class="se">\</code>&#13;
  --rm <code class="se">\</code>&#13;
  -p 6379:6379 <code class="se">\</code>&#13;
  redis:6.0</pre></div>&#13;
&#13;
<p>Next, create a new file from scratch named <em>basic-http-healthcheck.js</em>. Insert the content from <a data-type="xref" href="#ex_health_check">Example 4-12</a> into your newly created file.</p>&#13;
<div data-type="example" id="ex_health_check">&#13;
<h5><span class="label">Example 4-12. </span><em>basic-http-healthcheck.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node&#13;
</code><code>&#13;
</code><code class="c1">// npm install fastify@3.2 ioredis@4.17 pg@8.3&#13;
</code><code class="kr">const</code><code> </code><code class="nx">server</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'fastify'</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">HOST</code><code> </code><code class="o">=</code><code> </code><code class="s1">'0.0.0.0'</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">PORT</code><code> </code><code class="o">=</code><code> </code><code class="mi">3300</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">redis</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="p">(</code><code class="nx">require</code><code class="p">(</code><code class="s2">"ioredis"</code><code class="p">)</code><code class="p">)</code><code class="p">(</code><code class="p">{</code><code class="nx">enableOfflineQueue</code><code class="o">:</code><code> </code><code class="kc">false</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO6-1" id="co_observability_CO6-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">pg</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="p">(</code><code class="nx">require</code><code class="p">(</code><code class="s1">'pg'</code><code class="p">)</code><code class="p">.</code><code class="nx">Client</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">pg</code><code class="p">.</code><code class="nx">connect</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code> </code><code class="c1">// Note: Postgres will not reconnect on failure&#13;
</code><code>&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/health'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="nx">req</code><code class="p">,</code><code> </code><code class="nx">reply</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="k">try</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="kr">const</code><code> </code><code class="nx">res</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">pg</code><code class="p">.</code><code class="nx">query</code><code class="p">(</code><code class="s1">'SELECT $1::text as status'</code><code class="p">,</code><code> </code><code class="p">[</code><code class="s1">'ACK'</code><code class="p">]</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="k">if</code><code> </code><code class="p">(</code><code class="nx">res</code><code class="p">.</code><code class="nx">rows</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">.</code><code class="nx">status</code><code> </code><code class="o">!==</code><code> </code><code class="s1">'ACK'</code><code class="p">)</code><code> </code><code class="nx">reply</code><code class="p">.</code><code class="nx">code</code><code class="p">(</code><code class="mi">500</code><code class="p">)</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="s1">'DOWN'</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code> </code><code class="k">catch</code><code class="p">(</code><code class="nx">e</code><code class="p">)</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="nx">reply</code><code class="p">.</code><code class="nx">code</code><code class="p">(</code><code class="mi">500</code><code class="p">)</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="s1">'DOWN'</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO6-2" id="co_observability_CO6-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
  </code><code class="p">}</code><code>&#13;
  </code><code class="c1">// ... other down checks ...&#13;
</code><code>  </code><code class="kd">let</code><code> </code><code class="nx">status</code><code> </code><code class="o">=</code><code> </code><code class="s1">'OK'</code><code class="p">;</code><code>&#13;
  </code><code class="k">try</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="k">if</code><code> </code><code class="p">(</code><code class="nx">await</code><code> </code><code class="nx">redis</code><code class="p">.</code><code class="nx">ping</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">!==</code><code> </code><code class="s1">'PONG'</code><code class="p">)</code><code> </code><code class="nx">status</code><code> </code><code class="o">=</code><code> </code><code class="s1">'DEGRADED'</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code> </code><code class="k">catch</code><code class="p">(</code><code class="nx">e</code><code class="p">)</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="nx">status</code><code> </code><code class="o">=</code><code> </code><code class="s1">'DEGRADED'</code><code class="p">;</code><code> </code><a class="co" href="#callout_observability_CO6-3" id="co_observability_CO6-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
  </code><code class="p">}</code><code>&#13;
  </code><code class="c1">// ... other degraded checks ...&#13;
</code><code>  </code><code class="nx">reply</code><code class="p">.</code><code class="nx">code</code><code class="p">(</code><code class="mi">200</code><code class="p">)</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="nx">status</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="nx">PORT</code><code class="p">,</code><code> </code><code class="nx">HOST</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`</code><code class="sb">http://</code><code class="si">${</code><code class="nx">HOST</code><code class="si">}</code><code class="sb">:</code><code class="si">${</code><code class="nx">PORT</code><code class="si">}</code><code class="sb">/</code><code class="sb">`</code><code class="p">)</code><code class="p">)</code><code class="p">;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO6-1" id="callout_observability_CO6-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Redis requests will fail when offline.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO6-2" id="callout_observability_CO6-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Completely fail if Postgres cannot be reached.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO6-3" id="callout_observability_CO6-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Pass with a degraded state if Redis cannot be reached.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This file makes use of the <code>ioredis</code> package <a data-primary="ioredis package" data-type="indexterm" id="idm46291187360424"/><a data-primary="packages" data-secondary="ioredis" data-type="indexterm" id="idm46291187359800"/><a data-primary="Redis" data-secondary="ioredis module" data-type="indexterm" id="idm46291187217640"/><a data-primary="Redis" data-secondary="health check building" data-type="indexterm" id="idm46291187216696"/><a data-primary="Postgres databases" data-secondary="health check building" data-type="indexterm" id="idm46291187215752"/>for connecting to and issuing queries for Redis. It also makes use of the <code>pg</code> package for working with Postgres. When <code>ioredis</code> is instantiated it will default to connecting to a locally running service, which is why connection details aren’t necessary. The <code>enableOfflineQueue</code> flag specifies if commands should be queued up when the Node.js process can’t connect to the Redis instance. It defaults to <code>true</code>, meaning requests can be queued up. Since Redis is being used as a caching service—not as a primary data store—the flag should set to <code>false</code>. Otherwise, a queued-up request to access the cache could be slower than connecting to the real data store.</p>&#13;
&#13;
<p>The <code>pg</code> package also <a data-primary="environment variables" data-secondary="Postgres instances" data-type="indexterm" id="idm46291187198072"/><a data-primary="Postgres databases" data-secondary="environment variables" data-type="indexterm" id="idm46291187197064"/>defaults to connecting to a Postgres instance running locally, but it will still need some connection information. That will be provided using environment variables.</p>&#13;
&#13;
<p>This health check endpoint is configured to first check for features that are critical to run. If any of those features are lacking, then the endpoint will immediately fail. In this case, only the Postgres check applies, but a real application might have more. After that, the checks that will result in a degraded service are run. Only the Redis check applies in this situation. Both of these checks work by querying the backing store and checking for a sane response.</p>&#13;
&#13;
<p>Note that a degraded service will return a 200 status code. HAProxy could, for example, be configured to still direct requests to this service. If the service is degraded, then an alert could be generated (see <a data-type="xref" href="#ch_monitoring_sec_alert">“Alerting with Cabot”</a>). Figuring out <em>why</em> the cache isn’t working is something that our application shouldn’t be concerned about. The issue might be that Redis itself has crashed or that there is a &#13;
<span class="keep-together">network</span> issue.</p>&#13;
&#13;
<p>Now that the service file is ready, run the following command to start the service:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ PGUSER</code><code class="o">=</code>tmp <code class="nv">PGPASSWORD</code><code class="o">=</code>hunter2 <code class="nv">PGDATABASE</code><code class="o">=</code>tmp <code class="se">\</code>&#13;
  node basic-http-healthcheck.js</pre>&#13;
&#13;
<p>The Postgres connection variables have been provided as environment variables and are used by the underlying <code>pg</code> package. Explicitly naming the variables in code is a better approach for production code, and these variables are only used for brevity.</p>&#13;
&#13;
<p>Now that your service is running, it’s time <a data-primary="health checks" data-secondary="building" data-startref="healthbuild" data-type="indexterm" id="idm46291187304856"/>to try using the health checks.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Testing the Health Check" data-type="sect2"><div class="sect2" id="idm46291187401768">&#13;
<h2>Testing the Health Check</h2>&#13;
&#13;
<p>With the process running <a data-primary="health checks" data-secondary="testing" data-type="indexterm" id="idm46291187185304"/>and connecting to the databases, it should be considered in a healthy state. Issue the following request to check the status of the application:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl -v http://localhost:3300/health</pre>&#13;
&#13;
<p>The response should contain the message <code>OK</code> and have an associated 200 status code.</p>&#13;
&#13;
<p>Now we can simulate a degraded situation. Switch focus to the Redis service and press Ctrl + C to kill the process. You should see <a data-primary="error messages, printing" data-type="indexterm" id="idm46291187165688"/>some error messages printed from the Node.js process. They will start off quickly and then slow down as the <code>ioredis</code> module uses <em>exponential backoff</em> when attempting to reconnect to the Redis server. This means that it retries rapidly and then slows down.</p>&#13;
&#13;
<p>Now that the application is no longer <a data-primary="curl command" data-type="indexterm" id="idm46291187210424"/><a data-primary="commands" data-secondary="curl" data-type="indexterm" id="idm46291187209832"/>connected to Redis, run the same <code>curl</code> command again. This time, the response body should contain the message <code>DEGRADED</code>, though it will still have a 200 status code.</p>&#13;
&#13;
<p>Switch back to the terminal window you previously ran Redis with. Start the Redis service again, switch back to the terminal where you ran <code>curl</code>, and run the request again. Depending on your timing, you might still receive the <code>DEGRADED</code> message,&#13;
<span class="keep-together">but you</span> will eventually get the <code>OK</code> message once <code>ioredis</code> is able to reestablish a &#13;
<span class="keep-together">connection.</span></p>&#13;
&#13;
<p>Note that killing Postgres in this manner will cause the application to crash. The <code>pg</code> library doesn’t provide the same automatic reconnection feature that <code>ioredis</code> provides. Additional <a data-primary="monitoring" data-secondary="health check" data-startref="mon_health" data-type="indexterm" id="idm46291187325384"/>reconnection logic will need to be added to the application to get that working. <a data-type="xref" href="ch08.html#ch_resilience_sec_db">“Database Connection Resilience”</a> contains an example &#13;
<span class="keep-together">of this.</span></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Alerting with Cabot" data-type="sect1"><div class="sect1" id="ch_monitoring_sec_alert">&#13;
<h1>Alerting with Cabot</h1>&#13;
&#13;
<p>There are certain issues that simply <a data-primary="health checks" data-secondary="Cabot" data-type="indexterm" id="healCabot"/><a data-primary="Cabot" data-secondary="health check" data-type="indexterm" id="healthCabot"/><a data-primary="alerting with Cabot" data-type="indexterm" id="alertCabot"/><a data-primary="monitoring" data-secondary="Cabot" data-type="indexterm" id="mon_Cabot"/>cannot be resolved by automatically killing and restarting a process. Issues related to stateful services, like the downed Redis service mentioned in the previous section, are an example. Elevated 5XX error rates are another common example. In these situations it’s often necessary to alert a developer to find the root cause of an issue and correct it. If such errors can cause a loss of revenue, then it becomes necessary to wake developers up in the middle of the night.</p>&#13;
&#13;
<p>In these situations a cellphone is usually the best medium for waking a developer, often by triggering an actual phone call. Other message formats, such as emails, chat room messages, and text messages, usually aren’t accompanied by an annoying ringing sound and often won’t suffice for alerting the developer.</p>&#13;
&#13;
<p>In this section, you’ll set up an instance of <a class="orm:hideurl" href="https://cabotapp.com"><em>Cabot</em></a>, which is an open source tool for polling the health of an application and triggering alerts. Cabot supports multiple forms of health checks, such as querying Graphite and comparing reported values to a threshold, as well as pinging a host. Cabot also supports making an HTTP request, which is what is covered in this section.</p>&#13;
&#13;
<p>In this section, you’ll also create a free <em>Twilio</em> trial account. Cabot can use this account to both send SMS messages and make phone calls. You can skip this part if you would prefer not to create a Twilio account. In that case, you’ll just see a dashboard changing colors from a happy green to an angry red.</p>&#13;
&#13;
<p>The examples in this section will have you create a single user in Cabot, and that user will receive all the alerts. In practice, an organization will set up schedules, usually referred to as the on-call rotation. In these situations, the person who will receive an alert will depend on the schedule. For example, the person on call might be Alice on call week one, Bob on week two, Carol on week three, and back to Alice on week four.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Another important feature in a <a data-primary="runbooks" data-type="indexterm" id="idm46291186945208"/>real organization is something called a <em>runbook</em>. A runbook is usually a page in a wiki and is associated with a given alert. The runbook contains information on how to diagnose and fix an issue. That way, when an engineer gets a notification at 2 A.M. about the <em>Database Latency</em> alert, they can read about how to access the database and run a query. You won’t create a runbook for this example, but you must be diligent in doing so for real-world alerts.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Create a Twilio Trial Account" data-type="sect2"><div class="sect2" id="idm46291187160680">&#13;
<h2>Create a Twilio Trial Account</h2>&#13;
&#13;
<p>At this point, head over <a data-primary="Twilio" data-type="indexterm" id="idm46291187159112"/>to <a href="https://twilio.com"><em class="hyperlink">https://twilio.com</em></a> and create a trial account. When you create an account, you will get two pieces of data that you will need for configuring Cabot. The first piece of information is called an <em>Account SID</em>. This is a string that starts with <code>AC</code> and contains a bunch of hexadecimal characters. The second piece &#13;
<span class="keep-together">of information</span> is the <em>Auth Token</em>. This value just looks like normal hexadecimal &#13;
<span class="keep-together">characters.</span></p>&#13;
&#13;
<p>Using the interface, you’ll also need to configure a <em>Trial Number</em>. This is a virtual phone number that you can use with this project. The phone number begins with a plus sign followed by a country code and the rest of the number. You’ll need to use this number within your project, including the plus sign and country code. The number you receive might look like <em>+15551234567</em>.</p>&#13;
&#13;
<p>Finally, you’ll need to configure your personal cellphone’s phone number to be a <em>Verified Number</em>/<em>Verified Caller ID</em> in Twilio. This allows you to confirm with Twilio that the phone number you have belongs to you and that you’re not just using Twilio to send spam texts to strangers, a process that is a limitation of the Twilio trial account. After you verify your phone number, you’ll be able to configure Cabot to send an SMS message to it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running Cabot via Docker" data-type="sect2"><div class="sect2" id="ch_monitoring_sec_alert_subsec_cabot">&#13;
<h2>Running Cabot via Docker</h2>&#13;
&#13;
<p>Cabot is a little more complex <a data-primary="Docker" data-secondary="Cabot" data-type="indexterm" id="dock_cabot"/>than the other services covered in this chapter. It requires several Docker images, not just a single one. For that reason you’ll need to use <em>Docker Compose</em> to launch several containers, instead of launching a single one using Docker. Run the following commands to pull the git repository and check out a commit that is known to be compatible with this example:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>git clone git@github.com:cabotapp/docker-cabot.git cabot&#13;
<code class="nv">$ </code><code class="nb">cd </code>cabot&#13;
<code class="nv">$ </code>git checkout 1f846b96</pre>&#13;
&#13;
<p>Next, create a new file located at <em>conf/production.env</em> within this repository. Note that it’s not within the <em>distributed-node</em> directory that you’ve been creating all your other project files in. Add the content from <a data-type="xref" href="#ex_cabot_config">Example 4-13</a> to this file.</p>&#13;
<div data-type="example" id="ex_cabot_config">&#13;
<h5><span class="label">Example 4-13. </span><em>config/production.env</em></h5>&#13;
&#13;
<pre data-code-language="ini" data-type="programlisting"><code class="na">TIME_ZONE</code><code class="o">=</code><code class="s">America/Los_Angeles </code><a class="co" href="#callout_observability_CO7-1" id="co_observability_CO7-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code class="na">ADMIN_EMAIL</code><code class="o">=</code><code class="s">admin@example.org</code><code>&#13;
</code><code class="na">CABOT_FROM_EMAIL</code><code class="o">=</code><code class="s">cabot@example.org</code><code>&#13;
</code><code class="na">DJANGO_SECRET_KEY</code><code class="o">=</code><code class="s">abcd1234</code><code>&#13;
</code><code class="na">WWW_HTTP_HOST</code><code class="o">=</code><code class="s">localhost:5000</code><code>&#13;
</code><code class="na">WWW_SCHEME</code><code class="o">=</code><code class="s">http</code><code>&#13;
&#13;
</code><code class="c1"># GRAPHITE_API=http://&lt;YOUR-IP-ADDRESS&gt;:8080/ </code><a class="co" href="#callout_observability_CO7-2" id="co_observability_CO7-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
&#13;
</code><code class="na">TWILIO_ACCOUNT_SID</code><code class="o">=</code><code class="s">&lt;YOUR_TWILIO_ACCOUNT_SID&gt; </code><a class="co" href="#callout_observability_CO7-3" id="co_observability_CO7-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code class="na">TWILIO_AUTH_TOKEN</code><code class="o">=</code><code class="s">&lt;YOUR_TWILIO_AUTH_TOKEN&gt;</code><code>&#13;
</code><code class="na">TWILIO_OUTGOING_NUMBER</code><code class="o">=</code><code class="s">&lt;YOUR_TWILIO_NUMBER&gt;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO7-1" id="callout_observability_CO7-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Set this value to your <a class="orm:hideurl" href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">TZ Time Zone</a>.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO7-2" id="callout_observability_CO7-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>For extra credit, configure a Graphite source using your IP address.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO7-3" id="callout_observability_CO7-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Omit these lines if you’re not using Twilio. Be sure to prefix the phone number with a plus sign and country code.</p></dd>&#13;
</dl></div>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>If you’re feeling adventurous, configure the <code>GRAPHITE_API</code> line to use the same Graphite instance that you created in <a data-type="xref" href="#ch_monitoring_sec_metrics">“Metrics with Graphite, StatsD, and Grafana”</a>. Later, when using the <a data-primary="Cabot" data-secondary="Graphite instance" data-type="indexterm" id="idm46291186837800"/><a data-primary="Graphite" data-secondary="Cabot and" data-type="indexterm" id="idm46291186836952"/>Cabot interface, you can choose which metrics to create an alert on. This is useful for taking a metric, like request timing, and alerting once it surpasses a certain threshold, such as 200ms. However, for brevity, this section won’t cover how to set it up, and you can omit the line.</p>&#13;
</div>&#13;
&#13;
<p>Once you’ve finished configuring Cabot, run the following command to start the Cabot service:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker-compose up</pre>&#13;
&#13;
<p>This will cause several Docker containers to start running. In the terminal, you should see progress as each image is downloaded, followed by colored output associated with each container once it’s running. Once things have settled down, you’re ready to move on to the next <a data-primary="Docker" data-secondary="Cabot" data-startref="dock_cabot" data-type="indexterm" id="idm46291186812104"/>step.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Creating a Health Check" data-type="sect2"><div class="sect2" id="idm46291187150600">&#13;
<h2>Creating a Health Check</h2>&#13;
&#13;
<p>For this example, use the same <em>basic-http-healthcheck.js</em> file from <a data-type="xref" href="#ex_health_check">Example 4-12</a> that you made in the previous section. Execute that file and run the Postgres service as configured in <a data-type="xref" href="#ex_postgres_redis">Example 4-11</a>. Once that is done, Cabot can be configured to make use of the <em>/health</em> endpoint the Node.js service exposes.</p>&#13;
&#13;
<p>With the Node.js service now running, open the Cabot web service using your web browser by visiting <a href="http://localhost:5000"><em class="hyperlink">http://localhost:5000</em></a>.</p>&#13;
&#13;
<p>You’ll first be prompted to create an administrative account. Use the default username <code>admin</code>. Next, put in your email address and a password and click Create. Then, you’ll be prompted to log in. Type <code>admin</code> for the username field, enter your password again, then click Log in. You’ll finally be taken to the services screen that will contain no entries.</p>&#13;
&#13;
<p>On the empty services screen, click the large plus symbol to be taken to the <a class="orm:hideurl" href="http://localhost:5000/service/create/">New service</a> screen. Then, input the information from <a data-type="xref" href="#table_cabot_create_service">Table 4-3</a> into the create service form.</p>&#13;
<table id="table_cabot_create_service">&#13;
<caption><span class="label">Table 4-3. </span>Fields for creating a service in Cabot</caption>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Name</p></td>&#13;
<td><p>Dist Node Service</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Url</p></td>&#13;
<td><p>http://&lt;LOCAL_IP&gt;:3300/</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Users to notify</p></td>&#13;
<td><p>admin</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Alerts</p></td>&#13;
<td><p>Twilio SMS</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Alerts enabled</p></td>&#13;
<td><p>checked</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Again, you’ll need to replace <code>&lt;LOCAL_IP&gt;</code> with your IP address. Once you’ve entered the information, click the Submit button. This will take you to a screen where you can view the <a class="orm:hideurl" href="http://localhost:5000/service/1/">Dist Node Service</a> overview.</p>&#13;
&#13;
<p>On this screen, scroll down to the Http checks section and click the plus sign to be taken to the <a class="orm:hideurl" href="https://oreil.ly/voFxA">New check</a> screen. On this screen, input the information from <a data-type="xref" href="#table_cabot_create_check">Table 4-4</a> into the “create check” form.</p>&#13;
<table id="table_cabot_create_check">&#13;
<caption><span class="label">Table 4-4. </span>Fields for creating an HTTP check in Cabot</caption>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Name</p></td>&#13;
<td><p>Dist Node HTTP Health</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Endpoint</p></td>&#13;
<td><p>http://&lt;LOCAL_IP&gt;:3300/health</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Status code</p></td>&#13;
<td><p>200</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Importance</p></td>&#13;
<td><p>Critical</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Active</p></td>&#13;
<td><p>checked</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Service set</p></td>&#13;
<td><p>Dist Node Service</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Once you’ve entered that information, click the Submit button. This will take you back to the <a class="orm:hideurl" href="http://localhost:5000/service/1/">Dist Node Service</a> overview screen.</p>&#13;
&#13;
<p>Next, the <code>admin</code> account needs to be configured to receive alerts using Twilio SMS. In the <a data-primary="Twilio" data-secondary="SMS" data-type="indexterm" id="idm46291186777704"/>upper-right corner of the screen, click the admin drop-down menu, then click Profile settings. On the left sidebar, click the Twilio Plugin link. This form will ask you for your phone number. Enter your phone number, beginning with a plus symbol and the country code. This number should match the verified number that you previously entered in your Twilio account. Once you’re done, click the Submit button.</p>&#13;
&#13;
<p>Once you’re done setting your phone number, click the Checks link in the top navigation bar. This will take you to the <a class="orm:hideurl" href="http://localhost:5000/check/1/">Checks</a> listing page, which should contain the one entry you’ve created. Click the single entry, <a class="orm:hideurl" href="http://localhost:5000/check/1/">Dist Node HTTP Health</a>, to be taken to the health check history listing. At this point, you should only see one or two entries since they run once every five minutes. These entries should have a green “succeeded” label next to them. Click the circular arrow icon in the upper right to trigger another health check.</p>&#13;
&#13;
<p>Now switch back to the terminal window where your Node.js service is running. Kill it with Ctrl + C. Then, switch back to Cabot and click the icon to run the test again. This time the test will fail, and you’ll get a new entry in the list with a red background and the word “failed.”</p>&#13;
&#13;
<p>You should also get a text message containing information about the alert. The message I received is shown here:</p>&#13;
&#13;
<pre data-type="programlisting">Sent from your Twilio trial account - Service&#13;
Dist Node Service reporting CRITICAL status:&#13;
http://localhost:5000/service/1/</pre>&#13;
&#13;
<p>If Cabot were properly installed on a real server somewhere with a real hostname, the text message would contain a working link that could then be opened on your phone. However, since Cabot is probably running on your laptop, the URL doesn’t make a lot of sense in this context.</p>&#13;
&#13;
<p>Click the Services link at the top of the screen, then click the Dist Node Service link again. On this screen, you’ll now see a graph displaying the status of the service, as well as a banner stating that the service is critical, like in <a data-type="xref" href="#fig_cabot_status">Figure 4-11</a>. Now click the Acknowledge alert button to pause the alerts for 20 minutes. This is useful for giving you time to work on the issue without being alerted over and over. It’s now time to fix the failing service.</p>&#13;
&#13;
<figure><div class="figure" id="fig_cabot_status">&#13;
<img alt="A screenshot of Cabot showing the failing Dist Node Service, with a warning banner and an acknowledge button" src="assets/dsnj_0411.png"/>&#13;
<h6><span class="label">Figure 4-11. </span>Cabot service status screenshot</h6>&#13;
</div></figure>&#13;
&#13;
<p>Switch back to the terminal where you ran the Node.js process and start it again. Then, switch back to the browser. Navigate back to the HTTP check you created. Click the icon to trigger the check again. This time the check should succeed, and it will switch back to a green “succeeded” message.</p>&#13;
&#13;
<p>Cabot, as well as other alerting tools, offers the ability to assign different users to different services. This is important since different teams within an organization will own different services. When you created an HTTP alert, it was also possible to provide a regex to be applied against the body. This can be used to differentiate a degraded service from an unhealthy service. Cabot can then be configured to have an unhealthy service alert an engineer but have a degraded service merely be highlighted in the UI.</p>&#13;
&#13;
<p>At this point you’re done with the Cabot Docker containers. Switch to the window where you were running Cabot and press Ctrl + C to kill it. Then run the following command to remove the containers from your system:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">$</code> <code class="nx">docker</code> <code class="nx">rm</code> <code class="nx">cabot_postgres_1</code> <code class="nx">cabot_rabbitmq_1</code> <code class="o">\</code>&#13;
  <code class="nx">cabot_worker_1</code> <code class="nx">cabot_beat_1</code> <code class="nx">cabot_web_1</code></pre>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291186748136">&#13;
<h5>Alternatives to Cabot</h5>&#13;
<p>Grafana, the service covered in <a data-type="xref" href="#ch_monitoring_sec_metrics">“Metrics with Graphite, StatsD, and Grafana”</a> for visualizing Graphite metrics, has <a data-primary="Grafana" data-secondary="alerting and" data-type="indexterm" id="idm46291186755432"/>alerting capability built in. It won’t be able to perform HTTP checks, but it will be able to query metrics and report if a value is off. For example, a service might report its livelihood every 10 seconds and generate an alert if 30 seconds pass without a metric.</p>&#13;
&#13;
<p>In all honesty, you probably won’t use Cabot within a larger organization. By its very nature, alerting needs to be able to report an unhealthy infrastructure situation to developers. If one area of your infrastructure is having issues, then other areas likely will too. If a bad configuration deploy causes your infrastructure to be firewalled from the internet, how can the developer be alerted? For this reason, off-site SaaS tools are usually more appropriate than self-hosted tools.</p>&#13;
&#13;
<p><a class="orm:hideurl" href="https://pagerduty.com">PagerDuty</a> is probably the most popular SaaS tool for generating alerts for developers. The npm package <code>pagerduty</code> can be used for programmatically creating, acknowledging, and resolving alerts. <a class="orm:hideurl" href="https://nagios.org">Nagios</a> targets enterprise users and has agents that can run on a server to collect tons of health metrics. <a class="orm:hideurl" href="https://pingdom.com">Pingdom</a> is a popular tool <a data-primary="health checks" data-secondary="Cabot" data-startref="healCabot" data-type="indexterm" id="idm46291186743560"/><a data-primary="Cabot" data-secondary="health check" data-startref="healthCabot" data-type="indexterm" id="idm46291186742280"/><a data-primary="alerting with Cabot" data-startref="alertCabot" data-type="indexterm" id="idm46291186741064"/><a data-primary="monitoring" data-secondary="Cabot" data-startref="mon_Cabot" data-type="indexterm" id="idm46291186740120"/>for performing HTTP health checks, alerting when a status code is off, the document contains or doesn’t contain a particular string, or a response is slow.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm46291188172088"><sup><a href="ch04.html#idm46291188172088-marker">1</a></sup> Note that <code>process.hrtime()</code> is only useful for getting relative time and can’t be used to get the current time with microsecond accuracy.</p><p data-type="footnote" id="idm46291188111672"><sup><a href="ch04.html#idm46291188111672-marker">2</a></sup> This example doesn’t persist data to disk and isn’t appropriate for production use.</p></div></div></section></body></html>