["```\n$ node -e \"process.exit(42)\" ; echo $?\n```", "```\nfunction checkConfig(config) {\n  if (!config.host) {\n    console.error(\"Configuration is missing 'host' parameter!\");\n    process.exit(1);\n  }\n}\n```", "```\n$ node -e \"throw new Error()\" ; echo $?\n```", "```\nconst lib = require('some-library');\ntry {\n  lib.start();\n} catch(e) {} // Sometimes lib throws even though it works\nlib.send('message');\n```", "```\ncatch(e) {\n  if (e instanceof lib.Errors.ConnectionFallback) {\n    // swallow error\n  } else {\n    throw e; // re-throw\n  }\n}\n```", "```\n/tmp/error.js:1\nthrow new Error('oh no');\n^\nError: oh no\n    at Object.<anonymous> (/tmp/foo.js:1:7)\n    ... TRUNCATED ...\n    at internal/main/run_main_module.js:17:47\n```", "```\nconst logger = require('./lib/logger.js');\nprocess.on('uncaughtException', (error) => {\n  logger.send(\"An uncaught exception has occured\", error, () => {\n    console.error(error);\n    process.exit(1);\n  });\n});\n```", "```\nPromise.reject(new Error('oh no'));\n\n(async () => {\n  throw new Error('oh no');\n})();\n```", "```\n(node:52298) UnhandledPromiseRejectionWarning: Error: oh no\n    at Object.<anonymous> (/tmp/reject.js:1:16)\n    ... TRUNCATED ...\n    at internal/main/run_main_module.js:17:47\n(node:52298) UnhandledPromiseRejectionWarning: Unhandled promise\n  rejection. This error originated either by throwing inside of an\n  async function without a catch block, or by rejecting a promise\n  which was not handled with .catch().\n```", "```\nprocess.on('unhandledRejection', (reason, promise) => {});\n```", "```\nevents.js:306\n    throw err; // Unhandled 'error' event\n    ^\nError [ERR_UNHANDLED_ERROR]: Unhandled error. (undefined)\n    at EventEmitter.emit (events.js:304:17)\n    at Object.<anonymous> (/tmp/foo.js:1:40)\n    ... TRUNCATED ...\n    at internal/main/run_main_module.js:17:47 {\n  code: 'ERR_UNHANDLED_ERROR',\n  context: undefined\n}\n```", "```\n#!/usr/bin/env node\nconsole.log(`Process ID: ${process.pid}`);\nprocess.on('SIGHUP', () => console.log('Received: SIGHUP'));\nprocess.on('SIGINT', () => console.log('Received: SIGINT'));\nsetTimeout(() => {}, 5 * 60 * 1000); // keep process alive\n```", "```\n$ kill -s SIGHUP <PROCESS_ID>\n```", "```\n$ node -e \"process.kill(<PROCESS_ID>, 'SIGHUP')\"\n```", "```\n$ kill -9 <PROCESS_ID>\n```", "```\nError: uv_signal_start EINVAL\n```", "```\nserver.patch('/v1/foo/:id', async (req) => {\n  const id = req.params.id;\n  const body = await req.body();\n  await fetch(`http://ds1/foo/${id}`, { method: 'patch', body });\n  doSomethingRisky();\n  await fetch(`http://ds2/foo/${id}`, { method: 'patch', body });\n  return 'OK';\n});\n```", "```\nconst accounts = new Map();\n\nmodule.exports.set = (account_id, account) => {\n  accounts.set(account_id, account);\n};\n```", "```\nprocess.namespaces = {};\n\nfunction createNamespace(name) {\n  process.namespaces[name] = namespace;\n}\n\nfunction destroyNamespace(name) {\n  process.namespaces[name] = null;\n}\n```", "```\n#!/usr/bin/env node \n// npm install fastify@3.2 lru-cache@6.0 node-fetch@2.6 const fetch = require('node-fetch');\nconst server = require('fastify')();\nconst lru = new (require('lru-cache'))({ ![1](assets/1.png)\n  max: 4096,\n  length: (payload, key) => payload.length + key.length,\n  maxAge: 10 * 60 * 1_000\n});\nconst PORT = process.env.PORT || 3000;\n\nserver.get('/account/:account', async (req, reply) => {\n  return getAccount(req.params.account);\n});\nserver.listen(PORT, () => console.log(`http://localhost:${PORT}`));\n\nasync function getAccount(account) {\n  const cached = lru.get(account); ![2](assets/2.png)\n  if (cached) { console.log('cache hit'); return JSON.parse(cached); }\n  console.log('cache miss');\n  const result = await fetch(`https://api.github.com/users/${account}`);\n  const body = await result.text();\n  lru.set(account, body); ![3](assets/3.png)\n  return JSON.parse(body);\n}\n```", "```\n$ node caching/server.js\n$ time curl http://localhost:3000/account/tlhunter\n$ time curl http://localhost:3000/account/nodejs\n$ time curl http://localhost:3000/account/tlhunter\n```", "```\n$ PORT=4000 node server.js\n$ time curl http://localhost:4000/account/tlhunter\n```", "```\n$ docker run \\\n  --name distnode-memcached \\\n  -p 11211:11211 \\\n  -it --rm memcached:1.6-alpine \\\n  memcached -m 64 -vv\n```", "```\n#!/usr/bin/env node \n// npm install fastify@3.2 memjs@1.2 node-fetch@2.6 const fetch = require('node-fetch');\nconst server = require('fastify')();\nconst memcache = require('memjs')\n  .Client.create('localhost:11211'); ![1](assets/1.png)\nconst PORT = process.env.PORT || 3000;\n\nserver.get('/account/:account', async (req, reply) => {\n  return getAccount(req.params.account);\n});\nserver.listen(PORT, () => console.log(`http://localhost:${PORT}`));\n\nasync function getAccount(account) {\n  const { value: cached } = await memcache.get(account); ![2](assets/2.png)\n  if (cached) { console.log('cache hit'); return JSON.parse(cached); }\n  console.log('cache miss');\n  const result = await fetch(`https://api.github.com/users/${account}`);\n  const body = await result.text();\n  await memcache.set(account, body, {}); ![3](assets/3.png)\n  return JSON.parse(body);\n}\n```", "```\n$ node caching/server-ext.js\n$ PORT=4000 node caching/server-ext.js\n```", "```\n$ time curl http://localhost:3000/account/tlhunter # miss\n$ time curl http://localhost:3000/account/tlhunter # hit\n$ time curl http://localhost:4000/account/tlhunter # hit\n```", "```\n{\n  \"account\": {\n    \"id\": 7,\n    \"balance\": 100\n  }\n}\n```", "```\n{\n  \"id\": \"7\",\n  \"balance\": 100\n}\n```", "```\nasync function reduceBalance(account_id, item_cost) {\n  const key = `account-info-${account_id}`;\n  const account = await cache.get(key);\n  const new_balance = account.account.balance - item_cost;\n  return new_balance;\n}\n```", "```\n  const new_balance = account.balance - item_cost;\n```", "```\n$ docker run \\\n  --name distnode-postgres \\\n  -it --rm \\\n  -p 5432:5432 \\\n  -e POSTGRES_PASSWORD=hunter2 \\\n  -e POSTGRES_USER=user \\\n  -e POSTGRES_DB=dbconn \\\n  postgres:12.3\n```", "```\n#!/usr/bin/env node \n// npm install fastify@3.2 pg@8.2 const DatabaseReconnection = require('./db.js'); ![1](assets/1.png)\nconst db = new DatabaseReconnection({\n  host: 'localhost', port: 5432,\n  user: 'user', password: 'hunter2',\n  database: 'dbconn', retry: 1_000\n});\ndb.connect(); ![2](assets/2.png)\ndb.on('error', (err) => console.error('db error', err.message));\ndb.on('reconnect', () => console.log('reconnecting...')); ![3](assets/3.png)\ndb.on('connect', () => console.log('connected.'));\ndb.on('disconnect', () => console.log('disconnected.'));\n```", "```\nconst server = require('fastify')();\nserver.get('/foo/:foo_id', async (req, reply) => {\n  try {\n    var res = await db.query( ![1](assets/1.png)\n      'SELECT NOW() AS time, $1 AS echo', [req.params.foo_id]);\n  } catch (e) {\n    reply.statusCode = 503;\n    return e;\n  }\n  return res.rows[0];\n});\nserver.get('/health', async(req, reply) => { ![2](assets/2.png)\n  if (!db.connected) { throw new Error('no db connection'); }\n  return 'OK';\n});\nserver.listen(3000, () => console.log(`http://localhost:3000`));\n```", "```\nconst { Client } = require('pg');\nconst { EventEmitter } = require('events');\n\nclass DatabaseReconnection extends EventEmitter {\n  #client = null;       #conn = null;\n  #kill = false;        connected = false;\n\n  constructor(conn) {\n    super();\n    this.#conn = conn;\n  }\n```", "```\n  connect() {\n    if (this.#client) this.#client.end(); ![1](assets/1.png)\n    if (this.kill) return;\n    const client = new Client(this.#conn);\n    client.on('error', (err) => this.emit('error', err));\n    client.once('end', () => { ![2](assets/2.png)\n      if (this.connected) this.emit('disconnect');\n      this.connected = false;\n      if (this.kill) return;\n      setTimeout(() => this.connect(), this.#conn.retry || 1_000);\n    });\n    client.connect((err) => {\n      this.connected = !err;\n      if (!err) this.emit('connect');\n    });\n    this.#client = client;\n    this.emit('reconnect');\n  }\n```", "```\n  async query(q, p) {\n    if (this.#kill || !this.connected) throw new Error('disconnected');\n    return this.#client.query(q, p);\n  }\n\n  disconnect() {\n    this.#kill = true;\n    this.#client.end();\n  }\n}\nmodule.exports = DatabaseReconnection;\n```", "```\n$ curl http://localhost:3000/foo/hello\n> {\"time\":\"2020-05-18T00:31:58.494Z\",\"echo\":\"hello\"}\n$ curl http://localhost:3000/health\n> OK\n```", "```\nconnected.\ndb error terminating connection due to administrator command\ndb error Connection terminated unexpectedly\ndisconnected.\nreconnecting...\nreconnecting...\n```", "```\n$ curl http://localhost:3000/foo/hello\n> {\"statusCode\":503,\"error\":\"Service Unavailable\",\n>   \"message\":\"disconnected\"}\n$ curl http://localhost:3000/health\n> {\"statusCode\":error\":\"Internal Server Error\",\n>   \"message\":\"no db connection\"}\n```", "```\nreconnecting...\nreconnecting...\nconnected.\n```", "```\n#!/usr/bin/env node\n\n// npm install fastify@3.2 pg@8.2\nconst { Pool } = require('pg');\nconst db = new Pool({\n  host: 'localhost', port: 5432,\n  user: 'user', password: 'hunter2',\n  database: 'dbconn', max: process.env.MAX_CONN || 10\n});\ndb.connect();\n\nconst server = require('fastify')();\nserver.get('/', async () => (\n  await db.query(\"SELECT NOW() AS time, 'world' AS hello\")).rows[0]);\nserver.listen(3000, () => console.log(`http://localhost:3000`));\n```", "```\n$ MAX_CONN=100 node ./dbconn/pool.js\n$ autocannon -c 200 http://localhost:3000/\n```", "```\n$ MAX_CONN=101 node ./dbconn/pool.js\n$ autocannon -c 200 http://localhost:3000/\n```", "```\nSELECT * FROM pg_settings WHERE name = 'max_connections';\n```", "```\n100 / 2 = 50 ; 50 / 6 = 8.3\n```", "```\n#!/usr/bin/env node // npm install pg@8.2 const { Client } = require('pg');\nconst db = new Client({\n  host: 'localhost', port: 5432,\n  user: 'user', password: 'hunter2',\n  database: 'dbconn'\n});\ndb.connect();\n(async () => {\n  const start = Date.now();\n  await Promise.all([ ![1](assets/1.png)\n    db.query(\"SELECT pg_sleep(2);\"),\n    db.query(\"SELECT pg_sleep(2);\"),\n  ]);\n  console.log(`took ${(Date.now() - start) / 1000} seconds`);\n  db.end();\n})();\n```", "```\n000001.sql  000001-reverse.sql\n000002.sql  000002-reverse.sql\n000003.sql  000003-reverse.sql\n```", "```\n20200523133741_create_users.js\n20200524122328_create_groups.js\n20200525092142_make_admins.js\n```", "```\n$ mkdir migrations && cd migrations\n$ npm init -y\n$ npm install knex@0.21 pg@8.2\n$ npm install -g knex@0.21\n$ knex init\n```", "```\nmodule.exports = {\n  development: {\n    client: 'pg',\n    connection: {\n      host: 'localhost', port: 5432,\n      user: 'user', password: 'hunter2',\n      database: 'dbconn'\n    }\n  }\n};\n```", "```\n$ knex migrate:currentVersion\n> Using environment: development\n> Current Version: none\n```", "```\n$ knex migrate:make create_users\n$ ls migrations\n```", "```\nmodule.exports.up = async (knex) => {\n  await knex.schema.createTable('users', (table) => {\n    table.increments('id').unsigned().primary();\n    table.string('username', 24).unique().notNullable();\n  });\n\n  await knex('users')\n    .insert([\n      {username: 'tlhunter'},\n      {username: 'steve'},\n      {username: 'bob'},\n    ]);\n};\n\nmodule.exports.down = (knex) => knex.schema.dropTable('users');\n```", "```\n$ knex migrate:list\n> No Completed Migration files Found.\n> Found 1 Pending Migration file/files.\n> 20200525141008_create_users.js\n```", "```\n$ knex migrate:up\n> Batch 1 ran the following migrations:\n> 20200525141008_create_users.js\n```", "```\n$ docker exec \\\n  -it distnode-postgres \\\n  psql -U user -W dbconn\n```", "```\n Schema |         Name         | Type  | Owner\n--------+----------------------+-------+-------\n public | knex_migrations      | table | user\n public | knex_migrations_lock | table | user\n public | users                | table | user\n```", "```\n id | username\n----+----------\n  1 | tlhunter\n  2 | steve\n  3 | bob\n```", "```\nCREATE TABLE users (\n  id serial NOT NULL,\n  username varchar(24) NOT NULL,\n  CONSTRAINT users_pkey PRIMARY KEY (id),\n  CONSTRAINT users_username_unique UNIQUE (username));\n```", "```\n id |              name              | batch |      migration_time\n----+--------------------------------+-------+---------------------------\n  2 | 20200525141008_create_users.js |     1 | 2020-05-25 22:17:19.15+00\n```", "```\n$ knex migrate:make create_groups\n```", "```\nmodule.exports.up = async (knex) => {\n  await knex.raw(`CREATE TABLE groups (\n id SERIAL PRIMARY KEY,\n name VARCHAR(24) UNIQUE NOT NULL)`);\n  await knex.raw(`INSERT INTO groups (id, name) VALUES\n (1, 'Basic'), (2, 'Mods'), (3, 'Admins')`);\n  await knex.raw(`ALTER TABLE users ADD COLUMN\n group_id INTEGER NOT NULL REFERENCES groups (id) DEFAULT 1`);\n};\n\nmodule.exports.down = async (knex) => {\n  await knex.raw(`ALTER TABLE users DROP COLUMN group_id`);\n  await knex.raw(`DROP TABLE groups`);\n};\n```", "```\n$ knex migrate:latest\n```", "```\n$ knex migrate:down\n```", "```\nBatch 2 rolled back the following migrations:\n20200525172807_create_groups.js\n```", "```\n-- WARNING: DESTRUCTIVE MIGRATION!\n-- MIGRATE UP\nALTER TABLE users DROP COLUMN username;\n-- MIGRATE DOWN\nALTER TABLE users ADD COLUMN username VARCHAR(24) UNIQUE NOT NULL;\n```", "```\nCREATE TABLE people (\n  id SERIAL,\n  fname VARCHAR(20) NOT NULL,\n  lname VARCHAR(20) NOT NULL);\n```", "```\nasync function getUser(id) {\n  const result = await db.raw(\n    'SELECT fname, lname FROM people WHERE id = $1', [id]);\n  const person = result.rows[0];\n  return { id, fname: person.fname, lname: person.lname };\n}\n\nasync function setUser(id, fname, lname) {\n  await db.raw(\n  'UPDATE people SET fname = $1, lname = $2 WHERE id = $3',\n    [fname, lname, id]);\n}\n```", "```\nALTER TABLE people ADD COLUMN name VARCHAR(41) NULL;\nALTER TABLE people ALTER COLUMN fname DROP NOT NULL;\nALTER TABLE people ALTER COLUMN lname DROP NOT NULL;\n```", "```\nasync function getUser(id) {\n  const result = await db.raw(\n    'SELECT * FROM people WHERE id = $1', [id]);\n  const person = result.rows[0];\n  const name = person.name || `${person.fname} ${person.lname}`;\n  return { id, name };\n}\n\nasync function setUser(id, name) {\n  await db.raw(\n  'UPDATE people SET name = $1 WHERE id = $2',\n    [name, id]);\n}\n```", "```\nUPDATE people SET name = CONCAT(fname, ' ', lname) WHERE name IS NULL;\n```", "```\nWHERE name IS NULL AND id >= 103000 AND id < 104000\n```", "```\nALTER TABLE people ALTER COLUMN name SET NOT NULL;\nALTER TABLE people DROP COLUMN fname;\nALTER TABLE people DROP COLUMN lname;\n```", "```\nasync function getUser(id) {\n  const result = await db.raw(\n    'SELECT name FROM people WHERE id = $1', [id]);\n  return { id, name: result.rows[0].name };\n}\n```", "```\n100ms  | 250ms | 500ms | 1000ms | 2500ms | 5000ms | 5000ms | ...\n```", "```\nconst Redis = require('ioredis');\nconst DEFAULT = 5000;\nconst SCHEDULE = [100, 250, 500, 1000, 2500];\nconst redis = new Redis({\n  retryStrategy: (times) => {\n    return SCHEDULE[times] || DEFAULT;\n  }\n});\n```", "```\n10ms | 20ms | 40ms | quit\n```", "```\nconst redis = new Redis({\n  retryStrategy: (times) => {\n    let time = SCHEDULE[times] || DEFAULT;\n    return Math.random() * (time * 0.2) + time * 0.9; // Â±10%\n  }\n});\n```", "```\nconst PERIOD = 60_000;\nconst OFFSET = Math.random() * PERIOD;\nsetTimeout(() => {\n  setInterval(() => {\n    syncStats();\n  }, PERIOD);\n}, OFFSET);\n```", "```\n071 077 102 131 137 162 191 197 222\n```", "```\n060 060 060 120 120 120 180 180 180\n```", "```\nif (process.env.NODE_ENV === 'staging') {\n  const LIFESPAN = Math.random() * 100_000_000; // 0 - 30 hours\n  setTimeout(() => {\n    console.error('chaos exit');\n    process.exit(99);\n  }, LIFESPAN);\n}\n```", "```\nconst TIMER = 100_000;\nfunction slow() {\n  fibonacci(1_000_000n);\n  setTimeout(slow, Math.random() * TIMER);\n}\nsetTimeout(slow, Math.random() * TIMER);\n```", "```\nconst THRESHOLD = 10_000;\nasync function chaosQuery(query) {\n  if (math.random() * THRESHOLD <= 1) {\n    throw new Error('chaos query');\n  }\n  return db.query(query);\n}\nconst result = await chaosQuery('SELECT foo FROM bar LIMIT 1');\nreturn result.rows[0];\n```"]