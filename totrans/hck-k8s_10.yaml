- en: Chapter 10\. Organizations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Kubernetes cluster doesn’t run in a vacuum but in an environment, which could
    be an on-premises setup such as your own datacenter, or you could be using the
    offering of a cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast to previous chapters, in this chapter we look in detail at the
    “wetware,” a somewhat tongue-in-cheek term referring to humans rather than the
    software or hardware used. We will make the point that, despite all the technology
    available at your hands, running Kubernetes clusters and workloads securely requires
    you to focus on a nontech piece of the puzzle: humans and their natural (work)
    habitat, that is, organizations.'
  prefs: []
  type: TYPE_NORMAL
- en: Turns out that humans are, oftentimes, the weakest link in the chain. For example,
    an attacker may target email, PKI, and administrative interfaces to get behind
    the walls and steal secrets from the inside out, exfiltrate data, or leak sensitive
    information to the public.
  prefs: []
  type: TYPE_NORMAL
- en: In general, things external to a cluster can bypass its security if they are
    compromised—for example, the account with a cloud provider, admin credentials,
    encryption keys, or really anything along the software supply chain.
  prefs: []
  type: TYPE_NORMAL
- en: The shared responsibility model used by cloud providers puts certain security
    processes on the shoulders of users, while the cloud provides services that are
    themselves secure. This means that you need to consider the build-out of the infrastructure
    topology, data flows, and security configuration as well as its usage.
  prefs: []
  type: TYPE_NORMAL
- en: So, let’s see what our swarthy ol’ Captain Hashjack is facing in this context.
    The Captain has exhausted all angles of technical attack, and is looking for another
    way in. It may be easier to attack an organization directly to get it to its secrets.
  prefs: []
  type: TYPE_NORMAL
- en: The Weakest Link
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Figure 10-1](#fig-org-pyramid) you see the organizational pyramid. This
    is a conceptual representation of the dependencies a service or application you’re
    offering to a customer has. The basic idea is that there are a number of layers
    that exist in organization that are dependent on each other, and only if the foundations
    are stable and well developed can we trust that higher layers can work properly:'
  prefs: []
  type: TYPE_NORMAL
- en: Individual people
  prefs: []
  type: TYPE_NORMAL
- en: Platform and ops folks, developers, managers, the summer intern, the CEO’s aunt—all
    of them represent “the base” that everything else builds atop. Here you should
    not forget about your vendors, such as folks working at your cloud provider of
    choice, from account managers to support.
  prefs: []
  type: TYPE_NORMAL
- en: Teams and hierarchy
  prefs: []
  type: TYPE_NORMAL
- en: The next layer captures how you organize your team from a functional perspective.
    The smaller the organization, the less hierarchy, but no matter how small, usually
    teams with more or less defined scope are present.
  prefs: []
  type: TYPE_NORMAL
- en: Docs, knowledge bases, and training
  prefs: []
  type: TYPE_NORMAL
- en: An important layer, sometimes overlooked. Lumping up all kind of written material
    or otherwise (activities such as a course) in the “documentation, knowledge bases
    (KB), and training” layer. The majority of people read or depend on them; only
    few produce and maintain them.
  prefs: []
  type: TYPE_NORMAL
- en: Policies
  prefs: []
  type: TYPE_NORMAL
- en: Next up are policies, as discussed in [Chapter 8](ch08.xhtml#ch-policy). The
    policies themselves are abstract and can be internal or external, regulatory or
    business types, but in any case they need to be (formally) defined and enforced,
    which happens in the next layer.
  prefs: []
  type: TYPE_NORMAL
- en: Tools
  prefs: []
  type: TYPE_NORMAL
- en: The collection of tools—software from Linux to CI pipelines to Kubernetes. This
    is the “tangible” and mostly visible part that most of us deal with to get our
    job done.
  prefs: []
  type: TYPE_NORMAL
- en: The tip of the iceberg, if you like, at the summit of the pyramid ([Figure 10-1](#fig-org-pyramid))
    is your application or service. That is, this is the thing you own and want to
    release and which should be the focus of your attention, be it in terms of adding
    new features and/or fixing bugs, from a developer’s point of view.
  prefs: []
  type: TYPE_NORMAL
- en: If you are in a more platform-centric or ops role you typically care more about
    the “tools” layer in the pyramid and have, toward the developer, more of a coaching
    function. Given that Kubernetes established an operational vocabulary that both
    developers and infrastructure operators can use, the communication should, at
    least in theory, be a better one compared to earlier times.
  prefs: []
  type: TYPE_NORMAL
- en: '![Organizational pyramid](Images/haku_1001.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-1\. Organizational pyramid
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Up until now we’ve mainly been talking about the top two layers; that is, about
    tools and policies. We now focus on topics relevant to the other layers of the
    pyramid.
  prefs: []
  type: TYPE_NORMAL
- en: 'To be more precise, in the remainder of this chapter we will discuss organizational
    challenges structured along the environments in which you use Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we look at cloud computing and its providers ([“Cloud Providers”](#cloud-providers)),
    discussing constraints and good practices in such environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We then move on to on-premises environments/datacenters ([“On-Premises Environments”](#on-premises-envs)),
    highlighting challenges unique to those.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, in [“Common Considerations”](#common-env-considerations), we review
    common considerations; that is, organizational things relevant for both cloud
    or on-prem environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So let’s jump into the deep end, with cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Providers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As per the National Institute of Standards and Technology (NIST) [Special Publication
    800-145](https://oreil.ly/XdW3R), cloud computing, from a conceptual point of
    view, has to exhibit some essential characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: On-demand self-service
  prefs: []
  type: TYPE_NORMAL
- en: You can unilaterally provision computing, storage, or networking; no human interaction
    with service provider required.
  prefs: []
  type: TYPE_NORMAL
- en: Broad network access
  prefs: []
  type: TYPE_NORMAL
- en: Capabilities are available over the (public) network and accessed through standard
    mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Resource pooling
  prefs: []
  type: TYPE_NORMAL
- en: Cloud provider’s computing resources are pooled to serve multiple consumers
    using a multitenant model.
  prefs: []
  type: TYPE_NORMAL
- en: Rapid elasticity
  prefs: []
  type: TYPE_NORMAL
- en: The capabilities can be elastically acquired and released, virtually appearing
    to be unlimited.
  prefs: []
  type: TYPE_NORMAL
- en: Metered consumption
  prefs: []
  type: TYPE_NORMAL
- en: Automatic control and optimization of resource use by leveraging a metering
    capability.
  prefs: []
  type: TYPE_NORMAL
- en: We will scope our discussion here based on the preceding NIST definition of
    cloud computing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, cluster security depends on organizational practices. To strengthen
    the organizational muscle, consider holding internal events or participate in
    external ones, something akin to what was offered, for example, at KubeCon:'
  prefs: []
  type: TYPE_NORMAL
- en: Attacking and Defending Kubernetes Clusters, presented at [KubeCon NA 2019 CTF](https://oreil.ly/Vwqcp).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [Cloud Native Security Tutorial](https://oreil.ly/4ItS2) at KubeCon EU 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The TAG Security CTF wrap up videos at [KubeCon NA 2020](https://oreil.ly/E940b)
    and [KubeCon EU 2021](https://oreil.ly/proxS).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s now have a closer look at good practices, on the individual and team level,
    for using Kubernetes in a cloud computing environment.
  prefs: []
  type: TYPE_NORMAL
- en: Shared Responsibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Typically, cloud providers describe the way security and compliance is handled
    by defining what part of a service is their responsibility and which part is yours.
    Often you find this in the service-level agreements (SLAs) that also define contractual
    penalties or compensation if a certain service isn’t available. For example, AWS
    has the [Shared Responsibility Model](https://oreil.ly/7FR6v), likewise Azure’s
    [variant](https://oreil.ly/jKkOH), and the more specific Google documents on the
    [shared responsibility model in GKE](https://oreil.ly/KmpDY) and [Anthos shared
    responsibility](https://oreil.ly/rcZD3). In addition, the Center for Internet
    Security (CIS) provides foundational security benchmarks for the three major cloud
    providers.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what, exactly, are your responsibilities in the context of a managed Kubernetes
    cluster? There a number of aspects to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: When standardizing on Kubernetes to, for example, create more interoperable
    systems or to avoid vendor lock-in, the API focus shifts from a cloud provider–centric
    one to a Kubernetes-centric one. This means Kubernetes abstracts away many, if
    not all, resources. While this is great from an interop POV it also means that
    more responsibility is now on your plate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Serverless offerings such as Fargate and Cloud Run usually mean that more of
    the responsibility is with the cloud provider. For example, no need to patch nodes
    in case a new CVE is released.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For example, let’s look at EKS. The AWS Shared Responsibility Model states
    that Amazon is responsible for the security *of the cloud* and customers are responsible
    for security *in the cloud*, meaning operations and patching of any and all applications
    they run using the service, including the control plane, such as custom controllers
    or CNI plug-ins. Say there’s a security issue with an Amazon-owned Helm chart
    (for an [ACK controller](https://oreil.ly/wPhqE), for example): Amazon is responsible
    for patching the controller and providing updated images and charts, whereas you
    as the customer are responsible for updating the controller in your cluster, using
    the latest, patched version provided by Amazon.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Where you are responsible, be cognizant of the configurations of the software
    you’re running as well as the version. You can use common standards and benchmarks
    to validate your configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[DevSec Hardening for Docker](https://oreil.ly/tpqr6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DevSec Hardening for Kubernetes](https://oreil.ly/uvm1B)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Account Hygiene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Access to resources, be it in-cluster as discussed in [Chapter 8](ch08.xhtml#ch-policy)
    or to the environment (cloud provider) is a basic requirement to get any work
    done, for developers and ops folks alike. Oftentimes, the challenge is that one
    either has a secure or a usable setup. Using a combination of (forcibly rotating)
    passwords, YubiKeys, one-time passcodes from OTP devices, and other things to
    establish your identity can be tiresome. So people come up with shortcuts, trying
    to outsmart the security controls. There are promising approaches available, such
    as Google’s [BeyondCorp](https://oreil.ly/Kz3qR), however, many companies are
    not ready for it, yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Until the time the identity and access challenge is addressed otherwise, allow
    us to propose a structured approach to account hygiene in the context of cloud.
    This three-phased process for account hygiene looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Onboarding
  prefs: []
  type: TYPE_NORMAL
- en: Most companies get that right. In the process of onboarding a person into the
    organization and further into a team, LDAP or POSIX group memberships are established.
    In addition you want organization-wide policies that define what role has what
    kind of access (read-only or create or whatever) to what resources. For example,
    AWS IAM offers [service control policies](https://oreil.ly/ARKkw) (SCP), allowing
    you to define central control over the maximum available permissions for all accounts
    in an organization.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing and monitoring
  prefs: []
  type: TYPE_NORMAL
- en: During the entire time of a person being part of an org, you want to monitor
    access (inside and from the outside) as well as being able to audit post-facto.
  prefs: []
  type: TYPE_NORMAL
- en: Offboarding
  prefs: []
  type: TYPE_NORMAL
- en: This is where many organizations fall over. Any access, be it to the cluster
    itself, the CI pipeline, the container registry, the Git repo, or the Slack instance,
    must be revocable. That is, when a person leaves the organization, access to all
    resources must be enforced automatically and in an auditable manner.
  prefs: []
  type: TYPE_NORMAL
- en: Do you have all three phases covered? Mostly automated? Try to address as many
    of the preceding points as feasible in the context of your organization.
  prefs: []
  type: TYPE_NORMAL
- en: 'A topic that deserves our special attention is that of long-lasting credentials
    versus temporary credentials. Long-lasting credentials such as passwords or SSH
    keys need to be rotated and/or revoked. Especially in the offboarding phase, long-lasting
    credentials can be a dramatic attack vector. In other words: in the best case
    the person leaving the org has no hard feelings and simply ignores the fact that
    they still can access, say, a Git repo or an S3 bucket with sensitive information
    in it. In the not so good case, a disgruntled or malicious ex-employee might wreak
    havoc after they have left the organization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some tools or protocols, such as SSH, are not (out-of-the-box) very friendly
    concerning the rotation or revocation activity. Though increasingly solutions
    become available—for an example see [DevLog: SSH authentication via OAuth2](https://oreil.ly/gaSPi)—the
    question really should be: why not use temporary credentials in the first place?
    Take, for example, AWS Security Token Service (STS). With STS, you can provide
    users and apps with short-term (minutes to hours) credentials on the fly and with
    that can escape the rotation and revocation hell of long-lasting credentials.
    For example, you could use [Okta as an identity provider](https://oreil.ly/bDyav)
    and single-sign-on solution for EKS, based on short-lived STS tokens. As you would
    expect, all cloud providers offer some sort of temporary creds; for example, Azure’s
    Shared Access Signature (SAS) or Google’s [STS](https://oreil.ly/ta1bD) API.'
  prefs: []
  type: TYPE_NORMAL
- en: Grouping People and Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You almost always *don’t* want to deal with individual people or resources.
    What you want is, based on some characteristic, being able to address a group
    of people (role-based, for example) or a group of resources such as “all pods
    and services, running in the test stage, for application X.” In case of an incident,
    being able to address an incident and foster efficient escalation requires you
    to identify who owns a certain resource such as a cluster or a namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first talk about people. To group people and define team-wide policies,
    different cloud providers offer different options:'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Web Services
  prefs: []
  type: TYPE_NORMAL
- en: With [AWS Organizations](https://oreil.ly/SCNaP) you can programmatically create
    AWS accounts, apply policies to groups, and it also serves as the basis for other
    security-related services such as AWS Single Sign-On (SSO), all usually orchestrated
    using a higher-level service called AWS Control Tower.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure
  prefs: []
  type: TYPE_NORMAL
- en: '[Azure Policy](https://oreil.ly/HvRzj) helps enforce organizational standards
    and to assess compliance across your environments based on business rules. In
    addition, to control user actions, you would use Azure RBAC.'
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Platform
  prefs: []
  type: TYPE_NORMAL
- en: The [Organization Policy Service](https://oreil.ly/Zktbx) from Google enables
    you to define and enforce centralized and programmatic control over your organization’s
    cloud resources. Whereas Google’s IAM allows you to state who can perform an actions
    (permissions), the Organization Policy focuses on the What (configuration scope).
  prefs: []
  type: TYPE_NORMAL
- en: 'To statically or dynamically group resources (from worker nodes to entire clusters
    to cluster-external resources such as load balancers or networked storage like
    S3 or NFS), again, different cloud vendors offer you a range of controls:'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Web Services
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Tags and Resource Groups (RG). While the former was already around for
    a while and you can lean on [best practices for tagging](https://oreil.ly/kRMVs),
    the RGs are a relatively new concept. That is, up to the introduction of RGs (which
    are still optional), you’d essentially have to deal with a flat resource namespace
    on a per-account basis. Good practice these days is to establish or follow [conventions](https://oreil.ly/YHaDg)
    and apply them, as [supported by a service](https://oreil.ly/CuxuK).
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure
  prefs: []
  type: TYPE_NORMAL
- en: While both Azure and AWS have “resource groups” allowing you to organize resources,
    these are not directly comparable. In case of Azure, a resource is always associated
    with exactly one resource group (which can be changed, but multiple, tag-based
    memberships are not supported).
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Platform
  prefs: []
  type: TYPE_NORMAL
- en: 'GCP really pioneered this space: from the very beginning it supported [projects](https://oreil.ly/JZfyg),
    allowing (and forcing) you to enable and use services, billing, managing collaborators,
    and permissions for resources. In addition, GCP supports [labeling](https://oreil.ly/WaIXA)
    of resources, semantically pretty much exactly what you know from Kubernetes.'
  prefs: []
  type: TYPE_NORMAL
- en: Another question in this context is that of cross-account access. Using multiple
    accounts (as enforced by the preceding structure) helps naturally to overcome
    per-account limits or quotas but it also strengthens your security posture. As
    a case study, see the AWS [multiple account strategy](https://oreil.ly/CTEGn)
    whitepaper. Depending on the cloud provider, you might also have policies available
    that are directly applied to a resource (rather than the human or team-centric
    policies) and that can help with cross-account access. For a concrete examplary
    walkthrough, see Satya Vajrapu and Jason Smith’s blog post [“Enabling Cross-Account
    Access to Amazon EKS Cluster Resources”](https://oreil.ly/t1Zfw).
  prefs: []
  type: TYPE_NORMAL
- en: Other Considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to proactive measures such as org-wide policies for grouping resources
    and account hygiene, there are a number of things you can do, in the context of
    the cloud provider environment, to make your Kubernetes setup more resilient and
    secure. Let’s have a look at it.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with root certificate authorities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Authentication over TLS [requires PKI certificates](https://oreil.ly/y4bfP),
    and as such the question arises where to best store private keys and certs for
    the root Certificate Authorities (CA). You want to keep your root CA in a Key
    Management Service (KMS); that is, in a managed service that allows you to manage
    cryptographic keys and define their usage declaratively, org-wide. These KMS are
    typically based on hardware security modules (FIPS 140-2 compliant) and usually
    also support auditing, for example, in case of AWS via CloudTrail.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid leaking credentials
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The beginning of the supply chain ([Chapter 4](ch04.xhtml#ch-apps-supply-chain))
    is where software is written; that is, the developer or ops person creating some
    artifact like source code, a configuration in YAML format, or documentation in,
    say, Markdown format. These source artifacts usually are kept in a version control
    system (VCS) such as Git, a popular distributed VCS enabling collaboration and
    making it possible to revert to previous (good) states.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a dark side to VCS as well: whenever we put stuff into them (commit
    and/or push in the context of a distributed VCS) we potentially risk leaking sensitive
    information.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The following is a cautionary tale on leaking sensitive information that happened
    to one of the authors who shall remain anonymous (hi Michael!). Just before lunch
    time, said author wanted to check in the documentation of a project. The *docs.md*
    file looked innocent enough, describing the steps necessary to connect. There
    was only one problem, and that was that by copying and pasting the verbatim output
    from the command line, the actual access key ID and secret access key was included.
    Within minutes, bad actors monitoring the global GitHub feed noticed the credentials
    and used them to spin up EC2 instances. This story had a good ending as the AWS
    Fraud Detection kicked in immediately (the change in usage pattern was clear—said
    author almost exclusively uses one region) and did the needful: freezing the account
    and reaching out to the account owner to fix the issue. The lesson learned is
    a clear one: never ever commit any passwords or keys in plain text in a repo.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two things you can do about it:'
  prefs: []
  type: TYPE_NORMAL
- en: Enforce compulsory code scanning prior to check-in. For example, you can use
    [git-secrets](https://oreil.ly/29g6M), which helps prevent you from committing
    sensitive information to a Git repository as a pre-commit hook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you need to keep sensitive information in a (public) repo, at least do not
    store it in plain text, encrypt it. For example, Bitnami offers [sealed-secrets](https://oreil.ly/MP7L7),
    allowing for automating the process all the way to the consuming target cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With these considerations out of the way, we now switch gears and look at an
    entirely different environment for running Kubernetes: on-prem setups.'
  prefs: []
  type: TYPE_NORMAL
- en: On-Premises Environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the following we’re using the terms *on-premises environments* and *datacenters*
    somewhat interchangeably. Separate from this are bare-metal deployments, which
    may or may not happen in the cloud (AWS, Equinix) or on-prem.
  prefs: []
  type: TYPE_NORMAL
- en: While in the case of cloud providers the perimeter and its implications are
    clearly defined, in the case of on-prem environments you have to define it yourself.
    For example, in AWS, the account is the basic unit of identity (one customer is
    one account) and at scale it’s an AWS Organization that represents a customer,
    owning dozens if not hundreds of accounts. The same is true for resources that
    belong to exactly one account and can be made accessible for other accounts or
    finer-grained constructs such as a VPC.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of on-prem, you need to come up with the perimeter definition yourself
    and you should consider the unit of compute (is it a Kubernetes cluster? is it
    a Kubernetes namespace?) being part of it, since, depending on the business requirements,
    it may imply multitenancy requirements as discussed in [Chapter 7](ch07.xhtml#ch-hard-multi-tenancy).
  prefs: []
  type: TYPE_NORMAL
- en: There is also the question of whether you should or want to run [Kubernetes
    clusters](https://oreil.ly/5lCpA) yourself. This boils down to competitive advantage
    (are you, for example, rolling your own Linux distro?) and your role (are you
    a vendor or an enduser). Having said this, as per Gartner the overall [cloud adoption
    is still in the 20% range](https://oreil.ly/vfK9d) and around 50% of Kubernetes
    users still have a DIY approach. That is, rather than using a Kubernetes distribution
    such as [Red Hat OpenShift](https://oreil.ly/mIkJe), [Rancher](https://oreil.ly/7LoAV),
    or [Canonical Distribution of Kubernetes](https://oreil.ly/SsMTN), they build
    and maintain their own distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to consider options for the following infrastructure pieces (as
    well as think through their security implications):'
  prefs: []
  type: TYPE_NORMAL
- en: Hardware, including buildings, racks, power supply, generators, blades, etc.
    to run your workloads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Typically some IaaS layer to virtualize the hardware, for example VMware or
    OpenStack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some worker node-level provisioning including host operating system, such as
    Ansible or TerraForm. These provide the basic requirements for Kubernetes to be
    installable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For East-West (in-cluster) network traffic, fulfill the [Kubernetes requirements](https://oreil.ly/FRIPi)
    via SDN or the like.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For North-South network traffic, use a load balancer like metalLB or an F5 offering.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use networked storage like an NFS filer and/or SANs and/or object store (MinIO,
    OpenIO or the like), Gluster, Ceph, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An on-prem certificate management solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A user directory (typically LDAP-based).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use either the Kubernetes built-in DNS or an existing internal DNS server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are the minimal requirements necessary and you also should take into account
    that, in contrast to the cloud, almost every on-prem setup is different. This
    means that recipes—for example, Ansible scripts—to automate tasks usually require
    a lot of customization and testing to ensure they provide useful, production-ready
    output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some useful resources for further reading in this context are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[“On-Premise Kubernetes Clusters”](https://oreil.ly/Q2R8i)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“Build Kubernetes Bare-metal Cluster with External Access”](https://oreil.ly/Nrgfa)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“Bare-Metal Kubernetes”](https://oreil.ly/mc5X1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Further, there are a number of things you should be aware of and need to address.
    Most of them usually already in place if you are not facing a greenfield setup:'
  prefs: []
  type: TYPE_NORMAL
- en: One of the most challenging issues is making sure that physical access to your
    infrastructure is clearly defined and enforced.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The worst-case scenarios like an earthquake or a fire are another thing you
    need to be able to deal with (also: DR plan).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DoS attacks are yet another thing that cloud providers take care of for you
    automatically and usually free of cost. In the on-prem case you need to come up
    with a strategy here as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, capacity planning and intrusion detection (see [Chapter 9](ch09.xhtml#ch-intrusion-detection)),
    are, in the on-prem case, on you.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this short discussion on the [challenges of running Kubernetes on-prem](https://oreil.ly/AfrNT),
    we now move on to considerations relevant to any environment.
  prefs: []
  type: TYPE_NORMAL
- en: Common Considerations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No matter if you are using managed Kubernetes from a cloud provider or you are
    running your own on-prem environment, there are a number of common considerations
    targeting humans (social engineering) as well as regulatory concerns we will discuss
    in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Threat Model Explosion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes is a powerful system, however this also means you have to deal with
    increased complexity when it comes to understanding how the multiple abstraction
    mechanisms and control loop can be exploited by a malicious player.
  prefs: []
  type: TYPE_NORMAL
- en: Have a look at [Figure 10-2](#fig-tm-explosion). Consider the case of a monolith
    (depicted as the `app`), let’s say, a single binary running on a VM. There are
    few moving parts and responsibilities are straightforward. For example, infrastructure
    folks look after VM (patching, upgrading) and developers look after the `app`
    (scanning on dependency-level, avoiding SQL injections, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes vs monolith attack surface](Images/haku_1002.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-2\. Kubernetes versus monolith attack surface
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 10-2](#fig-tm-explosion) is intentionally a little lopsided. Of course,
    in any real-world situation, the monolith would also require a load balancer,
    for example, and there are many more moving parts. The point of the exercise is
    more of the following nature: Kubernetes provides a large number of resources
    and APIs, many more than most people can keep in their heads. It also comes with
    a number of required and optional (but almost always present) components both
    in the control and the data plane. Now, when you are using Kubernetes you can’t
    simply opt out and ignore all of this, even if you only need or are interested
    in a tiny subset. They still are present and offer our Captain a potential way
    to attack. So, take that figure with a grain of salt and simply be aware of the
    many moving parts, trying to consider as many as you can in your threat modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: Now look at the righthand side, the case of the `app` running in the context
    of a containerized microservices setup in Kubernetes. This `app` is now, together
    with, let’s assume, 15 other services, along the request path servicing the user.
    The `app` runs in a pod (a Kubernetes abstraction), which is a collection of containers
    on the same node (with containers being a Linux/OCI abstraction), and only then
    comes the process (group) that runs the `app`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s also the `kubelet` running on the worker node that represents the local
    Kubernetes supervisor using the `CRI` to communicate to the container runtime
    what to do (start, stop, etc.) as we discussed in [Chapter 2](ch02.xhtml#ch-pod-level-resources).
    But it doesn’t stop there: there’s also the connection with the Kubernetes control
    plane, with the container registry (not shown in the figure, to keep it simple),
    the CNI plug-ins, etc.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The complexity introduced with using Kubernetes yields a threat model explosion
    (TME). There are multiple issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Whose responsibility is the end-to-end security? Likely, dev and ops will have
    to work closely together to keep everything secure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The abstractions make it hard to realize what’s going on (in case of an incident),
    and to make sure everything is tested and monitored.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Simply put, the many levels of abstractions offer a larger attack surface compared
    to the monolith.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Number 1 above is partially the driver for the DevSecOps movement and serves
    as a motivation. Numbers 2 and 3 are what we are concerned with and want to provide
    some suggestions for.
  prefs: []
  type: TYPE_NORMAL
- en: 'So what are the concrete things you can do to tackle the TME? Consider adopting
    the following good practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Provide 360-visibility; that is, measure, and don’t just assume. Every component
    in Kubernetes should be monitored and sensible alerts configured. In [“How SLOs
    Can Put Additional Pressure on You”](#slo-pressure) we will drill deeper into
    this topic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use downtimes or periods of low traffic to do hands-on training and do fire
    drills. This helps build up the muscle memory and makes folks more comfortable
    to escalate and do the right steps (contain, observe, capture) when under attack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Automate, automate, automate. No matter whether we’re talking observability
    or escalation path: all essential processes should be automated with the option
    for humans to interfere manually where necessary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With this, we move on to another operational topic: how much downtime is allowed
    and what are the security implications?'
  prefs: []
  type: TYPE_NORMAL
- en: How SLOs Can Put Additional Pressure on You
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From a site reliability engineering (SRE) perspective, service-level objectives
    (SLOs) are a great tool to quantify the tolerated user expectations concerning
    downtimes. Establishing SLOs can be tough (see [“Implementing SLOs”](https://oreil.ly/I12YN)
    for reference), but in our security context let’s look at a different question:
    how can an attacker misuse SLOs to get inside or exfiltrate information?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Things you want to consider in the context of SLOs are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To measure if and to what extent the SLOs have been fulfilled you usually define
    a number of service-level indicators (SLIs). These measurements can be attacked
    and used to fake an SLO violation, tricking you into believing something that
    is, in fact, not true. Whenever we are faced with a stressful situation we potentially
    make mistakes; think of it as the equivalent of a human-centered DoS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, escalation takes place via notification channels such as pages, text
    messages, and emails. Popular services such as PagerDuty can, if not properly
    configured or used, leak sensitive information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the uptake of SLOs/SLIs is not yet that huge, the preceding point is something
    you may want to consider when introducing SRE or DevOps in your organization.
    In early 2021, an initiative called [OpenSLO](https://openslo.com) started to
    standardize the formal representation of SLOs, so there’s a fair to good chance
    that by the time you read this, you can benefit from the fruits of this effort.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll now move on to attacks that do not focus on technical roles: social engineering.'
  prefs: []
  type: TYPE_NORMAL
- en: Social Engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The security economics—for reference, the MIT OpenCourseWare course with the
    same name available via [6.858 Computer Systems Security](https://oreil.ly/Hde78)—oftentimes
    speak for targeting humans rather than software or hardware. As we already hinted
    at in [“The Weakest Link”](#weakest-link), humans are usually the weakest link
    in the defense chain. Additionally, attackers can benefit from the fact that they
    only need to find one weakness in the overall setup (for example, one unmotivated
    or careless human) compared to the Blue Team that has to defend against all attacks
    and has to motivate and nudge all members of an organization to comply and play
    their part.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of social engineering, the reconnaissance phase of the attack—present
    in all major attack models; see [Figure 10-3](#fig-cyber-attack-phases-models)—is
    particularly interesting. There is as of time of writing not enough research and
    collective experience in the practitioners community to provide authoritative
    recommendations for Kubernetes environments. However, Wojciech Mazurczyk and Luca
    Caviglione’s March 2021 Communications of the ACM (CACM) article [“Cyber Reconnaissance
    Techniques”](https://oreil.ly/RUHQb) provides an excellent starting point for
    your own work to secure the human aspect of the perimeter.
  prefs: []
  type: TYPE_NORMAL
- en: '![Cyber attack phases models (source: CACM Cyber Reconnaissance Techniques
    article)](Images/haku_1003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10-3\. Cyber attack phases models (source: [“Cyber Reconnaissance Techniques”](https://oreil.ly/RUHQb))'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Social engineering works particularly well in large and hierachical organizations.
    As disempowered individuals, potentially feeling like a cog in the machine and
    on top of that maybe a lack of ownership (“this is not my money at risk”), you
    are easy prey.
  prefs: []
  type: TYPE_NORMAL
- en: So what are common patterns and techniques to watch out for? How can you combat
    them?
  prefs: []
  type: TYPE_NORMAL
- en: Appeal to authority
  prefs: []
  type: TYPE_NORMAL
- en: You get an email from your skip-level manager saying that, due to a recently
    discovered CVE, your application needs to be patched. Click the following link
    to kick off a Helm upgrade in the CD pipeline. Boom!
  prefs: []
  type: TYPE_NORMAL
- en: 'Mitigation: You want to flag external senders, for example, with an `EXTERNAL`
    in the subject line, ask your team members to regularly do trainings and fire
    drills, and audit everything.'
  prefs: []
  type: TYPE_NORMAL
- en: Urgency
  prefs: []
  type: TYPE_NORMAL
- en: We repeatedly pointed out that under pressure, when the clock is ticking, the
    risk for making mistakes increases dramatically. A popular social engineering
    attack uses some urgency (launch, customer complaints, etc.) to trick you into
    sharing credentials or applying changes to the cluster (“please merge this PR
    quickly to address X”).
  prefs: []
  type: TYPE_NORMAL
- en: 'Mitigation: When under pressure, slow down. Pair up and speak out loud, double
    check and verify before applying any change.'
  prefs: []
  type: TYPE_NORMAL
- en: Indirect
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in detail in [Chapter 4](ch04.xhtml#ch-apps-supply-chain), supply
    chains are prone to being poisoned and malware can be ingested in a less-secure
    environment and activated in the target environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mitigation: Make sure to have a proactive approach re: supply chain management
    and at the very least scan all the items entering your perimeter. For example,
    static container image scanning is tablestakes now.'
  prefs: []
  type: TYPE_NORMAL
- en: These shouldn’t scare you, just make you aware. Let’s move on to some regulatory
    challenges now.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy and Regulatory Concerns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many enterprises, in order to do business in certain legislatures, need to be
    compliant with certain regulations. This can be general-purpose regulations that
    are valid and enforceable in a certain geo, such as the General Data Protection
    Regulation (GDPR) in the EU, or pertaining to vertical-specific concerns such
    as PCI-DSS or Sarbanes–Oxley. No matter if the intention of the regulation is
    to enforce end-user privacy, protect investments, or increase accountability,
    you want to make sure you are familiar with the requirements and find ways to
    implement these policies and controls as required (see [Chapter 8](ch08.xhtml#ch-policy)
    for some technology-related recommendations). In any case, make sure to involve
    legal personnel; we ain’t no lawyers and that’s why we don’t provide any directions
    beyond the technical ones, in this context.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we tried to highlight the fact that technology often is the
    “easy” part and the weakest link, as so often in a security context, is the human.
    Different environments such as cloud or on-prem offer different trade-offs. There
    is no right or wrong, just an awareness of where your priorities are and what
    you want to own yourself and which parts you want to offload.
  prefs: []
  type: TYPE_NORMAL
- en: We also have reached the end of the book, but unfortunately not of the Captain
    and their crew! We nevertheless hope this was useful food for thought for you
    and wish you the best of luck and success in implementing a secure and sustainable
    way to use and benefit from Kubernetes.
  prefs: []
  type: TYPE_NORMAL
