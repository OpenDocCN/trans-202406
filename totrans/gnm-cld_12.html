<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 11. Running Many Workflows Conveniently in Terra"><div class="chapter" id="running_many_workflows_conveniently_in">
<h1><span class="label">Chapter 11. </span>Running Many Workflows <span class="keep-together">Conveniently in Terra</span></h1>

<p>In <a data-type="xref" href="ch10.xhtml#running_single_workflows_at_scale_with">Chapter 10</a>, we gave you a tantalizing first taste of the power of the Cromwell plus Pipelines API combination.<a contenteditable="false" data-primary="Terra platform" data-type="indexterm" id="ix_Terra"/> You learned how to dispatch individual workflows to PAPI, both directly through Cromwell and indirectly through the WDL Runner wrapper. Both approaches enabled you to rapidly marshal arbitrary amounts of cloud compute resources without needing to administer them directly, which is probably the most important lesson you can take from this book. However, as we’ve discussed, both approaches suffer from limitations that would prevent you from achieving the truly great scalability that the cloud has to offer.</p>

<p>In this chapter, we show you how to use a fully featured Cromwell server within <em>Terra</em>, a cloud-based platform operated by the Broad Institute. We begin by introducing you to the platform and walking you through the basics of running workflows in Terra. Along the way, you’ll have the opportunity to experiment with the call caching feature that allows the Cromwell server to resume failed or interrupted workflows from the point of failure. With that experience in hand, you’ll graduate to finally running a full-scale GATK Best Practices pipeline on a whole genome dataset.</p>

<section data-type="sect1" data-pdf-bookmark="Getting Started with Terra"><div class="sect1" id="getting_started_with_terra">
<h1>Getting Started with Terra</h1>

<p>You are just a few short hops away from experiencing the <a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-type="indexterm" id="ix_Terrastrt"/>delights of a fully loaded Cromwell server thanks to <a href="https://terra.bio">Terra</a>, a scalable platform for biomedical research operated by the Broad Institute in collaboration with Verily. Terra is designed to provide researchers with a user-friendly yet flexible environment for doing secure and scalable analysis in GCP.<a contenteditable="false" data-primary="Google Cloud Platform (GCP)" data-secondary="Terra and" data-type="indexterm" id="idm45625614765352"/> Under the hood, Terra includes a persistent <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="persistent server in Terra" data-type="indexterm" id="idm45625614763768"/>Cromwell server configured to dispatch workflows to PAPI and equipped with a dedicated call caching database. <a contenteditable="false" data-primary="Pipelines API (PAPI)" data-secondary="Terra and" data-type="indexterm" id="idm45625614762104"/>On the surface, it provides a point-and-click <span class="keep-together">interface</span> for running and monitoring workflows as well as API access for those who prefer to interact with the system programmatically. Terra also provides rich functionality for accessing and managing data, performing interactive analysis<a contenteditable="false" data-primary="Jupyter Notebook" data-type="indexterm" id="idm45625614759608"/> through Jupyter Notebook, and collaborating securely <a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-tertiary="overview of main capabilities" data-type="indexterm" id="idm45625614758312"/>through robust permissions controls. <a data-type="xref" href="#overview_of_the_terra_platformdot">Figure 11-1</a> summarizes Terra’s current primary capabilities.</p>

<figure><div id="overview_of_the_terra_platformdot" class="figure"><img alt="Overview of the Terra platform." src="Images/gitc_1101.png" width="1440" height="815"/>
<h6><span class="label">Figure 11-1. </span>Overview of the Terra platform.</h6>
</div></figure>

<p>In this section, we focus on the workflow configuration, execution, and monitoring functionality through the web interface, but later in the chapter, we also dig into some interactive analysis in Jupyter.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>As of this writing, the Terra platform is under active development, so you likely will encounter differences between the screenshots here and the live web interface, as well as new features and behaviors. We’ll provide updated instructions and guidance regarding any major changes in <a href="https://oreil.ly/genomics-blog">the blog for this book</a>.</p>
</div>

<section data-type="sect2" data-pdf-bookmark="Creating an Account"><div class="sect2" id="creating_an_account">
<h2>Creating an Account</h2>

<p>You can register<a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-tertiary="creating an account" data-type="indexterm" id="ix_Terrastrtacct"/> for a <a href="https://app.terra.bio">Terra account for free</a>. In the upper-left corner of your browser window, click the three-line symbol to expand the side menu and bring up the Sign in with Google button, as shown in <a data-type="xref" href="#expanded_side_menu_showing_sign_in_butt">Figure 11-2</a>.</p>

<figure class="width-40 no-frame"><div id="expanded_side_menu_showing_sign_in_butt" class="figure"><img alt="Expanded side menu showing sign-in button." src="Images/gitc_1102.png" width="566" height="836"/>
<h6><span class="label">Figure 11-2. </span>Expanded side menu showing sign-in button.</h6>
</div></figure>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Menu symbols and navigation patterns in Terra are often similar to those in the GCP console.<a contenteditable="false" data-primary="GCP console" data-secondary="Terra interface, similarity to" data-type="indexterm" id="idm45625614741544"/> Whenever you see the same symbols, you can safely assume they have the same purpose.</p>
</div>

<p>Sign in with the same account that you have been using so far—the one you used to set up your GCP account, and submit the registration form shown in <a data-type="xref" href="#the_new_user_registration_formdot">Figure 11-3</a>. The contact email can be different from the email you used to sign in; for example, if you are using a personal account to do the work but prefer to get email notifications sent to your work account. Email notifications you might receive from Terra mainly consist of notices about new feature releases and service status (such as planned maintenance or incident alerts). They are relatively infrequent, and you can opt out if you do not want to receive these notifications. The contact email you specify here is also used by the Terra helpdesk ticketing system, which will email you if you ask a question, report a bug, or suggest a feature.</p>

<figure class="width-40 no-frame"><div id="the_new_user_registration_formdot" class="figure"><img alt="The New User Registration form." src="Images/gitc_1103.png" width="860" height="1080"/>
<h6><span class="label">Figure 11-3. </span>The New User Registration form.</h6>
</div></figure>

<p>You’ll need to accept the Terra Terms of Service. We strongly suggest that you follow the recommendation to secure your Google-linked account with two-factor authentication. <a contenteditable="false" data-primary="authentication" data-secondary="Google account linked to Terra" data-type="indexterm" id="idm45625614734952"/>Keep in mind that Terra is designed primarily to enable analysis of human patient data and includes repositories that host data funded by US government agencies with access restrictions, so security is a serious matter on the platform.<a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-startref="ix_Terrastrtacct" data-tertiary="creating an account" data-type="indexterm" id="idm45625614733128"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Creating a Billing Project"><div class="sect2" id="creating_a_billing_project">
<h2>Creating a Billing Project</h2>

<p>After you have completed the registration process, you should find yourself on the Terra portal landing page. <a contenteditable="false" data-primary="billing project" data-secondary="creating for Terra" data-type="indexterm" id="ix_billpr"/><a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-tertiary="creating a billing project" data-type="indexterm" id="ix_TerrastrtBP"/>At the top of the page, you might see a banner advertising free credits, as shown in <a data-type="xref" href="#the_banner_that_you_might_seecomma_adve">Figure 11-4</a>. As of this writing, you can get $300 worth of free credits to try out the platform (on top of the credits you might already be getting directly from GCP), as described in the <a href="https://oreil.ly/RQQun">Terra user guide</a>. Terra is built on top of GCP, and when you do work in Terra that incurs costs, GCP directly bills your account. The Broad Institute will not charge you any surcharges for the use of the platform.</p>

<figure class="no-frame"><div id="the_banner_that_you_might_seecomma_adve" class="figure"><img alt="The banner that you might see, advertising free credits." src="Images/gitc_1104.png" width="1442" height="116"/>
<h6><span class="label">Figure 11-4. </span>The banner that you might see, advertising free credits.</h6>
</div></figure>

<p>We recommend that you take advantage of the free credits opportunity, not only for the credits themselves, but also because the system will automatically set up a billing project that you can immediately use in Terra. This is the fastest way to get started using Terra; just click “Start trial,” accept the Terms of Service (don’t use the free <span class="keep-together">credits</span> to mine bitcoin!), and you’re off to the races. If you check the <a href="https://app.terra.bio/#billing">Billing page</a>, you should see a new billing project with a name following this pattern: <code>fccredits-<em>chemical element</em>-<em>color</em>-<em>number</em></code>.</p>

<p>If you do not see the banner or you don’t want to activate the free trial right away, you’ll need to go to the <a href="https://oreil.ly/WYZyl">Billing page</a> (accessible from the side menu where you signed in) to set up a billing account. You can connect the billing account that you have been using so far by clicking the blue plus symbol and following the instructions that pop up. See the accompanying sidebar for a detailed walkthrough of the process for connecting an existing billing account to use in Terra.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="connecting_an_existing_billing_account">
<h5>Connecting an Existing Billing Account to Use in Terra</h5>

<p>To connect an existing billing account to your <a contenteditable="false" data-primary="billing account for GCP, connecting to Terra" data-type="indexterm" id="idm45625614713128"/>Terra account, you’ll need to add the <em>terra-billing@terra.bio</em> service account as a user on your billing account. To do so, go to <a contenteditable="false" data-primary="GCP console" data-secondary="Billing account permissions page" data-type="indexterm" id="idm45625614711384"/>the GCP console <a href="https://oreil.ly/WEosg">Billing page</a> and navigate to the “Account management” tab. If you don’t see a Permissions panel on the righthand side, click the “Show info panel” button located in the upper-right corner of the page. Then, under Permissions, click the “Add members” button shown in <a data-type="xref" href="#the_gcp_console_billing_account_permiss">Figure 11-5</a>.</p>

<figure class="width-50 no-frame"><div id="the_gcp_console_billing_account_permiss" class="figure"><img alt="The GCP console Billing account permissions panel " src="Images/gitc_1105.png" width="876" height="974"/>
<h6><span class="label">Figure 11-5. </span>The GCP console Billing account permissions panel.</h6>
</div></figure>

<p>Add the <em>terra-billing@terra.bio</em> service account as a “Billing account user,” as illustrated in <a data-type="xref" href="#adding_the_terra_billing_user_account_a">Figure 11-6</a>, and then click SAVE. This allows Terra to provide your billing account details to GCP in order to cover the cost of the resources you use when you do work or store data through Terra.</p>

<figure class="width-60 no-frame"><div id="adding_the_terra_billing_user_account_a" class="figure"><img alt="Adding the Terra billing user account as a user on a GCP billing account " src="Images/gitc_1106.png" width="1112" height="1290"/>
<h6><span class="label">Figure 11-6. </span>Adding the Terra billing user account as a user on a GCP billing account.</h6>
</div></figure>

<p>When you return to the Terra billing page, you should now be able to use your billing account to create a billing project in Terra, as demonstrated in <a data-type="xref" href="#using_an_existing_billing_account_to_cr">Figure 11-7</a>.</p>

<figure class="width-50 no-frame"><div id="using_an_existing_billing_account_to_cr" class="figure"><img alt="Using an existing billing account to create a billing project in Terra." src="Images/gitc_1107.png" width="780" height="494"/>
<h6><span class="label">Figure 11-7. </span>Using an existing billing account to create a billing project in Terra.</h6>
</div></figure>

<p>That completes the setup of your billing project.</p>
</div></aside>

<p>After you have your billing project set up, all you need to go run some workflows is a workspace. In <a data-type="xref" href="ch13.xhtml#assembling_your_own_workspace_in_terra">Chapter 13</a>, we show you how to create your own workspaces from scratch, but for now, you’re simply going to clone a workspace that we set up for you with all the essentials.<a contenteditable="false" data-primary="billing project" data-secondary="creating for Terra" data-startref="ix_billpr" data-type="indexterm" id="idm45625614695384"/><a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-startref="ix_TerrastrtBP" data-tertiary="creating a billing project" data-type="indexterm" id="idm45625614693768"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Cloning the Preconfigured Workspace"><div class="sect2" id="cloning_the_preconfigured_workspace">
<h2>Cloning the Preconfigured Workspace</h2>

<p>You can find <a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-tertiary="cloning preconfigured workspace" data-type="indexterm" id="ix_Terrastrtwksp"/>the Genomics-in-the-Cloud-v1 workspace in the <a href="https://oreil.ly/RdqSW">Library Showcase</a> (which is accessible from the expandable menu on the left) or go straight to <a href="https://oreil.ly/n7oOr">this link</a>. The <a contenteditable="false" data-primary="workspaces  (Terra)" data-secondary="cloning preconfigured workspace" data-type="indexterm" id="ix_wkspcl"/>landing<a contenteditable="false" data-primary="Library Showcase" data-type="indexterm" id="idm45625614684408"/> page, or Dashboard, provides information about its purpose and contents. Take a minute to read the summary description if you’d like, and then we’ll get to work.</p>

<p>This workspace is read-only, so the first thing you need to do is to create a clone that will belong to you and that you can therefore work with. To do so, in the upper-right corner of your browser, click the round symbol with three dots to expand the action menu. Select Clone, as shown in <a data-type="xref" href="#cloning_the_preconfigured_workspacedot">Figure 11-8</a>, to bring up the workspace cloning form.</p>

<figure class="width-90 no-frame"><div id="cloning_the_preconfigured_workspacedot" class="figure"><img alt="Cloning the preconfigured workspace. A) List of available actions; B) cloning form." src="Images/gitc_1108.png" width="1440" height="778"/>
<h6><span class="label">Figure 11-8. </span>Cloning the preconfigured workspace. A) List of available actions; B) cloning form.</h6>
</div></figure>

<p>Select your billing project; that will determine the account GCP will bill when you do work that incurs costs.<a contenteditable="false" data-primary="billing project" data-secondary="selecting for Terra workspace" data-type="indexterm" id="idm45625614678568"/> You can change the workspace name or leave it as is; workspace names must be unique within a billing project but do not need to be unique across all of Terra. Ignore the Authorization domain bit for now; that’s an optional whitelisting option that you don’t need at this time.</p>

<p>When you click the Clone Workspace button, you’re automatically taken to your new workspace. Take a good look around; everything that the light touches belongs to you. There’s a lot there, huh? Actually, you know what, don’t spend too much time looking around. Let’s keep a tight focus on our goal, which is to get you running workflows through Terra’s Cromwell server.<a contenteditable="false" data-primary="workspaces  (Terra)" data-secondary="cloning preconfigured workspace" data-startref="ix_wkspcl" data-type="indexterm" id="idm45625614675832"/><a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-startref="ix_Terrastrtwksp" data-tertiary="cloning preconfigured workspace" data-type="indexterm" id="idm45625614674168"/><a contenteditable="false" data-primary="Terra platform" data-secondary="getting started with" data-startref="ix_Terrastrt" data-type="indexterm" id="idm45625614672232"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Running Workflows with the Cromwell Server in Terra"><div class="sect1" id="running_workflows_with_the_cromwell_ser">
<h1>Running Workflows with the Cromwell Server in Terra</h1>

<p>Alright, it’s showtime.<a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="running workflows with Cromwell server in Terra" data-type="indexterm" id="ix_Crmwrun"/><a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-type="indexterm" id="ix_TerraCrm"/> Head on over to the Workflows section of the workspace, where you should see a list of available workflow configurations, as<a contenteditable="false" data-primary="workflows" data-secondary="configuring in Terra workspace" data-type="indexterm" id="idm45625614664824"/> shown in <a data-type="xref" href="#list_of_available_workflow_configuratio">Figure 11-9</a>.</p>

<figure class="no-frame"><div id="list_of_available_workflow_configuratio" class="figure"><img alt="List of available workflow configurations." src="Images/gitc_1109.png" width="1440" height="375"/>
<h6><span class="label">Figure 11-9. </span>List of available workflow configurations.</h6>
</div></figure>

<p>These are two configurations for the same workflow, which you might recognize from the first part of their names, <em>scatter-hc.</em> That’s right, it’s your favorite parallelized <em>HaplotypeCaller</em> workflow. In case you’re wondering, the key difference between these two configurations is that one is designed to run on a single input sample, whereas the other can run on any arbitrary number of input samples. That sounds exciting, right? Right. But let’s focus on the simple case first.</p>

<section data-type="sect2" data-pdf-bookmark="Running a Workflow on a Single Sample"><div class="sect2" id="running_a_workflow_on_a_single_sample">
<h2>Running a Workflow on a Single Sample</h2>

<p>On the page that lists <a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-tertiary="running on a single sample" data-type="indexterm" id="ix_TerraCrmsin"/>the workflow configurations, click <a contenteditable="false" data-primary="HaplotypeCaller" data-secondary="scattered HaplotypeCaller" data-tertiary="running in Terra with Cromwell server" data-type="indexterm" id="ix_HCscatrnTerra"/>the one called <em>scatter-hc.filepaths</em> to open the configuration page. <a data-type="xref" href="#viewing_the_workflow_information_summar">Figure 11-10</a> shows the summary information, including a one-line synopsis and short description.</p>

<figure class="no-frame"><div id="viewing_the_workflow_information_summar" class="figure"><img alt="Viewing the workflow information summary." src="Images/gitc_1110.png" width="1440" height="331"/>
<h6><span class="label">Figure 11-10. </span>Viewing the workflow information summary.</h6>
</div></figure>

<p>In addition, the summary links to the Source of the workflow. If you follow that link, it will take you to the Broad Institute’s <a href="https://oreil.ly/xBXrU">Methods Repository</a>, an internal repository of workflows. Terra can also import workflows from <a href="https://dockstore.org">Dockstore</a>, as you’ll see in <a data-type="xref" href="ch13.xhtml#assembling_your_own_workspace_in_terra">Chapter 13</a>, but for this exercise, we chose to use the internal repository, which is a little easier to work with on first approach.</p>

<p>Back on the <em>scatter-hc.filepaths</em> configuration page, have a look at the SCRIPT tab, which displays the actual workflow code. Sure enough, it’s the same workflow that we’ve been using for a while.</p>

<p>As shown in <a data-type="xref" href="#viewing_the_workflow_scriptdot">Figure 11-11</a>, the code display uses <em>syntax highlighting</em>: it colors parts of the code based on the syntax of the WDL language.<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="workflow scripts in Terra" data-type="indexterm" id="idm45625614642088"/> It’s not possible to edit the code in this window, but the aforementioned Methods Repository includes a code editor (also with syntax highlighting), which can be quite convenient for making small tweaks without too much hassle.</p>

<figure class="no-frame"><div id="viewing_the_workflow_scriptdot" class="figure"><img alt="Viewing the workflow script." src="Images/gitc_1111.png" width="1440" height="757"/>
<h6><span class="label">Figure 11-11. </span>Viewing the workflow script.</h6>
</div></figure>

<p>So now you know for sure which workflow you’re going to be running, but where do you plug in the inputs?<a contenteditable="false" data-primary="I/O (input/output)" data-secondary="workflow inputs in Terra" data-type="indexterm" id="idm45625614637528"/> When you ran this workflow from the command line, you handed Cromwell a JSON file of inputs along with the WDL file. You can see the functional equivalent here on the Inputs tab, which is shown in part in <a data-type="xref" href="#viewing_the_workflow_inputsdot">Figure 11-12</a>. For each input variable, you<a contenteditable="false" data-primary="variables" data-secondary="input variables in Terra" data-type="indexterm" id="idm45625614634712"/> can see the Task name in the leftmost column and then the name of the Variable as it is defined in the workflow script as well as its Type. Finally, the rightmost column contains the Attribute, or value, that we are giving to each variable.</p>

<figure class="no-frame"><div id="viewing_the_workflow_inputsdot" class="figure"><img alt="Viewing the workflow inputs." src="Images/gitc_1112.png" width="1440" height="370"/>
<h6><span class="label">Figure 11-12. </span>Viewing the workflow inputs.</h6>
</div></figure>

<p>We’ve prefilled the configuration form for you, so you don’t need to edit anything, but please do take a moment to look at how the input values are specified. Especially for<a contenteditable="false" data-primary="File input variables in Terra" data-type="indexterm" id="idm45625614630200"/> the File variables: we’ve provided the full paths to the locations of the files in GCS.<a contenteditable="false" data-primary="Google Cloud Storage (GCS)" data-secondary="full paths to file locations in Terra input variables" data-type="indexterm" id="idm45625614628792"/> This is truly an exact transcription of the contents of the JSON file of inputs. In fact, as you’ll learn in more detail in <a data-type="xref" href="ch12.xhtml#interactive_analysis_in_jupyter_noteboo">Chapter 12</a>, all we had to do to set this up was to upload the JSON file to populate the contents of the form.</p>

<p>So are you ready to click that big blue Run Analysis button? Go for it; you’ve earned it. A small window will pop up asking for confirmation, as shown in <a data-type="xref" href="#the_workflow_launch_dialogdot">Figure 11-13</a>. Press the blue Launch button and sit back while Terra processes your workflow submission.</p>

<figure class="width-75 no-frame"><div id="the_workflow_launch_dialogdot" class="figure"><img alt="The workflow launch dialog." src="Images/gitc_1113.png" width="832" height="348"/>
<h6><span class="label">Figure 11-13. </span>The workflow launch dialog.</h6>
</div></figure>

<p>Under the hood, the system sends<a contenteditable="false" data-primary="workflows" data-secondary="submission in Terra, overview" data-type="indexterm" id="idm45625614621688"/> the built-in Cromwell server a packet of information containing the workflow code and inputs. As usual, Cromwell parses the workflow and starts dispatching individual jobs to PAPI for execution on the Google Compute Engine (GCE), as illustrated in <a data-type="xref" href="#overview_of_workflow_submission_in_terr">Figure 11-14</a>.</p>

<figure><div id="overview_of_workflow_submission_in_terr" class="figure"><img alt="Overview of workflow submission in Terra." src="Images/gitc_1114.png" width="1440" height="817"/>
<h6><span class="label">Figure 11-14. </span>Overview of workflow submission in Terra.</h6>
</div></figure>

<p>Meanwhile, Terra will take you to the Job History section of <a contenteditable="false" data-primary="Job History page in Terra" data-type="indexterm" id="idm45625614616456"/>the workspace, where you can monitor execution and look up the status of any past submissions—after you’ve had a chance to run some, that is. Speaking of which, there will be more to look at here when the workflow you just submitted is further along, so let’s move on and plan to circle back to the Job History later in the chapter.</p>

<p>At this point, assuming everything went fine, you’ve essentially just replicated your earlier achievements of running the scattered <em>HaplotypeCaller</em> workflow, through PAPI, on a single sample. <a contenteditable="false" data-primary="Pipelines API (PAPI)" data-secondary="running scattered HaplotypeCaller workflow using Cromwell server in Terra" data-type="indexterm" id="idm45625614613736"/>That’s nice, but wasn’t the point that we wanted to be able to run workflows on multiple samples at the same time? Why, yes; yes, it was. That’s where the second configuration<a contenteditable="false" data-primary="HaplotypeCaller" data-secondary="scattered HaplotypeCaller" data-startref="ix_HCscatrnTerra" data-tertiary="running in Terra with Cromwell server" data-type="indexterm" id="idm45625614612072"/> comes in.<a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-startref="ix_TerraCrmsin" data-tertiary="running on a single sample" data-type="indexterm" id="idm45625614609896"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Running a Workflow on Multiple Samples in a Data Table"><div class="sect2" id="running_a_workflow_on_multiple_samples">
<h2>Running a Workflow on Multiple Samples in a Data Table</h2>

<p>Let’s go take a look <a contenteditable="false" data-primary="data tables (Terra)" data-secondary="running workflow on multiple samples in data table" data-type="indexterm" id="ix_dataTerr"/>at that other<a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-tertiary="running workflow on multiple samples in data table" data-type="indexterm" id="ix_TerraCrmmul"/> configuration—the one <a contenteditable="false" data-primary="workspaces  (Terra)" data-secondary="Workspace data tables" data-type="indexterm" id="ix_wkspDT"/>called <em>scatter-hc.data-table</em>. As a reminder, you need to navigate to the Workflows pane and then click the configuration. You’ll see mostly the same thing as with the previous one (and the Source link is exactly the same), but if you look closely, there is one important difference. As shown in <a data-type="xref" href="#the_second_workflow_is_set_to_run_on_ro">Figure 11-15</a>, this configuration is set up to “Run workflow(s) with inputs defined by data table,” whereas the <em>.filepaths</em> configuration was set to “Run workflow with inputs defined by file paths” and specified the <em>book_sample</em> table as the source of data, as shown in <a data-type="xref" href="#viewing_the_workflow_information_summar">Figure 11-10</a>.</p>

<figure class="no-frame"><div id="the_second_workflow_is_set_to_run_on_ro" class="figure"><img alt="The second workflow is set to run on rows in a data table." src="Images/gitc_1115.png" width="1440" height="198"/>
<h6><span class="label">Figure 11-15. </span>The second workflow is set to run on rows in a data table.</h6>
</div></figure>

<p>Now take a closer look at how the inputs are defined on the Inputs tab. Do you see anything unfamiliar? For most of the variables, the straightforward values (like the Docker address and the file paths) have been replaced by what looks like more variables: either <code>workspace.*</code> or <code>this.*</code>, as shown in <a data-type="xref" href="#the_workflow_input_configuration_refere">Figure 11-16</a>.</p>

<figure class="no-frame"><div id="the_workflow_input_configuration_refere" class="figure"><img alt="The workflow input configuration references data tables." src="Images/gitc_1116.png" width="1440" height="799"/>
<h6><span class="label">Figure 11-16. </span>The workflow input configuration references data tables.</h6>
</div></figure>

<p>And that’s exactly what those are, references to values that are defined somewhere else. Specifically, they point to values that are stored in metadata tables in the Data section of the workspace. Let’s head over there now and see if we can shed some light on how this all works.</p>

<p>In the Data section, you’ll find a menu of data resources that should look something like <a data-type="xref" href="#viewing_the_menu_of_data_tables_on_the">Figure 11-17</a>. Within that menu, you should see a table called <em>book_sample</em> and another one called <em>Workspace Data</em>. We’re going to start with the <em>Workspace Data</em> table, on the assumption that it’s the least complicated to understand.</p>

<figure class="width-40 no-frame"><div id="viewing_the_menu_of_data_tables_on_the" class="figure"><img alt="Viewing the menu of data tables on the DATA tab." src="Images/gitc_1117.png" width="552" height="652"/>
<h6><span class="label">Figure 11-17. </span>Viewing the menu of data tables on the DATA tab.</h6>
</div></figure>

<p>Click Workspace Data to view the contents of that table, which are shown in <a data-type="xref" href="#the_workspace_data_tabledot">Figure 11-18</a>. As you can see, this is a fairly simple list of key:value pairs; for example, the key <em>gatk_docker</em> is associated with the value <code>us.gcr.io/broad-gatk/gatk:4.1.3.0</code>. Meanwhile, behind the scenes, this <em>Workspace Data</em> table is called <em>workspace</em>. As a result, we can use the expression <code>workspace.gatk_docker</code> in the workflow inputs form, as shown in <a data-type="xref" href="#the_workflow_input_configuration_refere">Figure 11-16</a>, to refer to the value <code>us.gcr.io/broad-gatk/gatk:4.1.3.0</code>, which is stored under the <em>gatk_docker</em> key in the <em>workspace</em> table.</p>

<figure class="no-frame"><div id="the_workspace_data_tabledot" class="figure"><img alt="The Workspace Data table. " src="Images/gitc_1118.png" width="1440" height="554"/>
<h6><span class="label">Figure 11-18. </span>The Workspace Data table.</h6>
</div></figure>

<p>So the <em>workspace</em> keys are essentially serving as a kind of global variable that you can use in multiple configurations within the same workspace. <a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="updating GATK Docker image version in Terra workspace" data-type="indexterm" id="idm45625614573352"/>This is very convenient if you want to update the version of the GATK Docker image in all of your <span class="keep-together">configurations</span> with minimum hassle: just update the key’s value in the <em>Workspace Data</em> table and you’re all set.</p>

<p>The same benefit applies to the resource files that are typically used in multiple workflows across a project, such as the reference genome files or the interval lists. Considering how awkward it can be to wrangle those long <em>gs://</em> file paths, it’s a real blessing to be able to define them just once and then simply refer to them with short pointers everywhere else. The filenames shown in blue and underlined are full file paths to locations in GCS, even though the system shows only the filename.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The keys defined in the <em>Workspace Data</em> table do not need to match the names of the variables from the WDL. We tend to standardize variable names and keys across our workflows in order to make it more obvious which ones go together, but it’s not a requirement of the system. If you wanted, you could set up a key called <em>my_docker</em> and provide it as <em>workspace.my_docker</em> to the <em>gatk_docker</em> variable in the workflow configuration.</p>
</div>

<p>Now let’s have a look at the other table, <em>book_sample</em>. As shown in <a data-type="xref" href="#the_quotation_markbook_samplesquotation">Figure 11-19</a>, this one is a more proper table, with multiple rows and columns. Each row is a different sample, identified by a unique (but for once, very readable) key in the <em>book_sample_id</em> column. Each sample has a file path under the <em>input_bam</em> column and another one under the <em>input_bam_index</em> column. If you peek at the paths, you might recognize these as the sample files of the family trio that we used in the joint calling exercise all the way back in <a data-type="xref" href="ch06.xhtml#best_practices_for_germline_short_varia">Chapter 6</a> (Germline short variant analysis), when the world was new and you were still running individual command lines in your VM.</p>

<figure class="no-frame"><div id="the_quotation_markbook_samplesquotation" class="figure"><img alt="The “book_samples” table." src="Images/gitc_1119.png" width="1440" height="413"/>
<h6><span class="label">Figure 11-19. </span>The book_sample table.</h6>
</div></figure>

<p>So how do we plug the contents of this table into the inputs form? Well, you just learned about the <code>workspace.<em>something</em></code> syntax that we encountered in <a data-type="xref" href="#the_workflow_input_configuration_refere">Figure 11-16</a>; now it’s time to extend that lesson to elucidate the <code>this.<em>something</em></code> syntax. In a nutshell, it’s the same idea, except now the pointer is <code>this</code> instead of <code>workspace</code>. and it’s going to point to any row of data taken from the <em>book_sample</em> table and submitted to the workflow system for processing, instead of pointing to the <em>Workspace Data</em> table.</p>

<p>Too abstract? Let’s use a concrete example. Imagine that you select one row from the <em>book_sample</em> table. That produces what is essentially a list of key:value pairs, just like the <em>Workspace Data</em> table:</p>

<pre data-type="programlisting">
book_sample_id		-&gt;    mother
input_bam      		-&gt;    gs://path/to/mother.bam
input_bam_index		-&gt;    gs://path/to/mother.bai</pre>

<p>You can therefore refer to each value based on the column name, which has been reduced to a simple key by the process of isolating that one row. That is what the <code>this.<em>input_bam</em></code> syntax does. It instructs the system: for every sample row that you run the workflow on, use this row’s <code><em>input_bam</em></code> value as an input for the <code><em>input_bam</em></code> variable, and so on for every variable where we use this syntax. (And again, the fact that the names match is not a requirement, though we do it intentionally for <span class="keep-together">consistency.</span>)</p>

<p>Alright, that was a long explanation, but we know this system trips up a lot of newcomers to Terra, so hopefully it’s been worth it. The feature itself certainly is, because it’s going to allow you to launch workflows on arbitrary numbers of samples at the click of a button. If that weren’t enough, the data table system has another benefit: when you have your workflow wired up to use the data table as input, you can start the process directly from the data table itself.</p>

<p>How would you like to try it out? Go ahead and use the checkboxes to select two of the samples, as shown in <a data-type="xref" href="#initiating_an_analysis_directly_on_a_su">Figure 11-20</a>.</p>

<figure class="no-frame"><div id="initiating_an_analysis_directly_on_a_su" class="figure"><img alt="Initiating an analysis directly on a subset of data.  " src="Images/gitc_1120.png" width="1440" height="494"/>
<h6><span class="label">Figure 11-20. </span>Initiating an analysis directly on a subset of data.</h6>
</div></figure>

<p>Having selected the samples, click the round symbol with three vertical dots located next to the count of selected rows. Click “Open with…” to open the menu of options and select Workflow as shown in <a data-type="xref" href="#specifying_a_workflow_to_run_on_the_sel">Figure 11-21</a>. Options that are not suitable for your data selection are grayed out. When you click Workflow, you’re presented with a list of available workflow configurations. Be sure to pick the one that is set up to use the data table; the system does not automatically filter out workflows that are configured with direct file paths.</p>

<figure class="no-frame"><div id="specifying_a_workflow_to_run_on_the_sel" class="figure"><img alt="Specifying a workflow to run on the selected data." src="Images/gitc_1121.png" width="1440" height="530"/>
<h6><span class="label">Figure 11-21. </span>Specifying a workflow to run on the selected data.</h6>
</div></figure>

<p>After you pick a workflow configuration, you are brought back in the workflows section. Looking at the configuration summary, you’ll see that it’s now set to run on the subset of data that you selected, as shown in <a data-type="xref" href="#configuration_updated_with_data_selecti">Figure 11-22</a>.</p>

<figure class="no-frame"><div id="configuration_updated_with_data_selecti" class="figure"><img alt="Configuration updated with data selection." src="Images/gitc_1122.png" width="1440" height="193"/>
<h6><span class="label">Figure 11-22. </span>Configuration updated with data selection.</h6>
</div></figure>

<p>When you submit this workflow execution request for the first time, the system saves a list of the samples you selected and stores the list as a row in a new data table called <em>sample_set.</em> After that, the system will add rows to the <em>sample_set</em> table every time you run a workflow on samples in this way. Note that you can also create sample sets yourself; you’ll see an example of that in <a data-type="xref" href="ch13.xhtml#assembling_your_own_workspace_in_terra">Chapter 13</a>.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Selecting rows manually is something that we mostly do for testing purposes; it wouldn’t scale terribly well. For a more scalable approach, you can opt to run the workflow on all rows in a table, or you can create sets ahead of time. To access these options, simply click the Select Data link adjacent to the table selection menu. Speaking of which: yes, you can have multiple data tables in a workspace, although you cannot launch a workflow on multiple tables at the same time.</p>
</div>

<p>Finally, there’s nothing left to do but click the Run Analysis button and then confirm the launch. But this time, when you land in the Job History section, stick around so that we can take a <a contenteditable="false" data-primary="workspaces  (Terra)" data-secondary="Workspace data tables" data-startref="ix_wkspDT" data-type="indexterm" id="idm45625614530120"/>look at how your<a contenteditable="false" data-primary="data tables (Terra)" data-secondary="running workflow on multiple samples in data table" data-startref="ix_dataTerr" data-type="indexterm" id="idm45625614528344"/> first workflow<a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-startref="ix_TerraCrmmul" data-tertiary="running workflow on multiple samples in data table" data-type="indexterm" id="idm45625614526440"/> submission fared.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Monitoring Workflow Execution"><div class="sect2" id="monitoring_workflow_execution">
<h2>Monitoring Workflow Execution</h2>

<p>When you’re taken<a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-tertiary="monitoring workflow execution" data-type="indexterm" id="ix_TerraCrmmon"/> to the Job History page after launching a workflow, what you see is the summary page for the submission you just created.<a contenteditable="false" data-primary="Job History page in Terra" data-secondary="monitoring workflow execution" data-type="indexterm" id="ix_JobHis"/> If you wandered off in the meantime and then came back to the Job History page on your own steam, what you’ll see is a list of submissions, as shown in <a data-type="xref" href="#list_of_submissions_in_the_job_historyd">Figure 11-23</a>. If so, you’ll need to click one of them to open it in order to follow the instructions that follow.</p>

<figure class="no-frame"><div id="list_of_submissions_in_the_job_historyd" class="figure"><img alt="List of submissions in the Job History." src="Images/gitc_1123.png" width="1440" height="169"/>
<h6><span class="label">Figure 11-23. </span>List of submissions in the Job History.</h6>
</div></figure>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45625614514792">
<h5>Workflows and Submissions</h5>

<p>The terminology here can become a little ambiguous because the term <em>workflow</em> carries several meanings. At the most fundamental level, a workflow is the sequence of actions that must be applied to the data. But it’s also the script, written in WDL, that implements that series of actions. Finally, we also use <em>workflow</em> to refer to the actual instantiation—the thing that runs in practice. The term <em>job</em>, which has similar ambiguity, can be used to refer to the overall submission, to a single workflow instance, or to individual tasks within the workflow. <em>Submissions</em>, meanwhile, refer to sets of one or more workflow runs that were launched at the same time.</p>
</div></aside>

<p>The submission summary page, shown in <a data-type="xref" href="#the_workflow_submission_summary_pagedot">Figure 11-24</a>, includes a link back to the workflow configuration, information about the data that the workflow was launched on, and a table listing individual workflow executions.</p>

<p>Each row in the table corresponds to an individual run of the workflow. If you used the data table approach to launch the workflow, the Data Entity column shows the identifier of the corresponding row in the data table as well as the name of the table. If you ran the workflow directly on file paths, as we did in the first exercise, that column is left blank. The <em>Workflow ID</em> is a unique tracking number assigned by the system and links to the location of the execution logs in GCS; if you click it, it will take you to the GCP console. Most of the time, you’ll want to ignore that link and use the View link instead, in the leftmost column, to view detailed status information about the workflow run.</p>

<figure class="no-frame"><div id="the_workflow_submission_summary_pagedot" class="figure"><img alt="The workflow submission summary page." src="Images/gitc_1124.png" width="1440" height="560"/>
<h6><span class="label">Figure 11-24. </span>The workflow submission summary page.</h6>
</div></figure>

<p>Go ahead and click the View link in one of the rows to open up the details for that workflow run. The workflow run details page packs in a lot of information, so let’s go through it one piece at a time.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>As of this writing, the workflow run details open on a new page titled Job Manager because it uses a service that is not yet fully integrated into the main Terra portal. You might need to sign in with your Google credentials to access the workflow run details page.</p>
</div>

<p>First, have a look at the overall status summary pane, shown in <a data-type="xref" href="#workflow_in_aright_parenthesis_running">Figure 11-25</a>. If everything goes well, you’ll see your workflow change from Running to Succeeded</p>

<figure class="width-90 no-frame"><div id="workflow_in_aright_parenthesis_running" class="figure"><img alt="Workflow in A) Running state and, B) Succeeded state." src="Images/gitc_1125.png" width="1440" height="399"/>
<h6><span class="label">Figure 11-25. </span>Workflow in A) Running state and, B) Succeeded state.</h6>
</div></figure>

<p>In the unfortunate event that<a contenteditable="false" data-primary="failed workflow runs in Terra" data-type="indexterm" id="idm45625614499336"/> your workflow run failed, the page will display additional details, including any error messages and links to logs, as shown in <a data-type="xref" href="#the_workflow_in_failed_state_with_error">Figure 11-26</a>.</p>

<figure class="no-frame"><div id="the_workflow_in_failed_state_with_error" class="figure"><img alt="The workflow in Failed state with ERRORS summary and Failure Message." src="Images/gitc_1126.png" width="1440" height="547"/>
<h6><span class="label">Figure 11-26. </span>A workflow in Failed state with ERRORS summary and Failure <span class="keep-together">Message</span>.</h6>
</div></figure>

<p>When everything’s working, the panel below the <a contenteditable="false" data-primary="errors summary and failure message in Terra" data-type="indexterm" id="idm45625614493320"/>summary pane, shown in <a data-type="xref" href="#list_of_tasks_and_related_resourcesdot">Figure 11-27</a>, is your go-to for everything you need to monitor the step-by-step execution of your workflow.<a contenteditable="false" data-primary="tasks" data-secondary="list of tasks and related resources in Terra" data-type="indexterm" id="idm45625614490872"/> The list of tasks will be updated as the workflow progresses and will be populated with useful resources like links to each task’s logs, execution directory, inputs, and outputs. To be clear, tasks won’t be listed until the work on them actually starts, so don’t panic when you see only a subset of the tasks in your workflow if you check on its status while it’s still running.</p>

<figure class="no-frame"><div id="list_of_tasks_and_related_resourcesdot" class="figure"><img alt="List of tasks and related resources." src="Images/gitc_1127.png" width="1440" height="299"/>
<h6><span class="label">Figure 11-27. </span>List of tasks and related resources.</h6>
</div></figure>

<p>You might notice that in <a data-type="xref" href="#list_of_tasks_and_related_resourcesdot">Figure 11-27</a>, the <code>HaplotypeCallerGVCF</code> task <a contenteditable="false" data-primary="HaplotypeCallerGVCF task" data-type="indexterm" id="idm45625614484728"/>is represented <a contenteditable="false" data-primary="MergeVCFs task" data-secondary="in list of tasks and related resources in Terra" data-type="indexterm" id="idm45625614483400"/>a bit differently compared to the <code>MergeVCFs</code> task: its name is underlined and there is a symbol on the side that looks like a stack of paper. This is how scattered tasks are represented.<a contenteditable="false" data-primary="scattered tasks, representation in Terra" data-type="indexterm" id="idm45625614481256"/> As shown in <a data-type="xref" href="#viewing_the_status_of_shards_for_a_scat">Figure 11-28</a>, you can hover over the stack symbol to see a status summary for all of the <em>shards</em> generated at that step; that is, the individual tasks resulting from the scatter.</p>

<figure class="width-60 no-frame"><div id="viewing_the_status_of_shards_for_a_scat" class="figure"><img alt="Viewing the status of shards for a scattered task." src="Images/gitc_1128.png" width="744" height="444"/>
<h6><span class="label">Figure 11-28. </span>Viewing the status of shards for a scattered task.</h6>
</div></figure>

<p>The panel<a contenteditable="false" data-primary="shards for scattered task, viewing status of" data-type="indexterm" id="idm45625614475784"/> shown in <a data-type="xref" href="#list_of_tasks_and_related_resourcesdot">Figure 11-27</a> has multiple tabs, so take a minute to explore those, as well.<a contenteditable="false" data-primary="timing diagrams for runtime in Terra" data-type="indexterm" id="idm45625614473464"/> Our favorite tab in this panel is Timing Diagram, shown in <a data-type="xref" href="#a_timing_diagram_showing_the_breakdown">Figure 11-29</a>, which shows you how much time each task took to run. This includes not just the time spent in the User Action stage—running the analysis command (for example, <code>HaplotypeCaller</code>), but also the time spent on getting the VM set up, pulling the container image, localizing files, and so on.</p>

<figure class="no-frame"><div id="a_timing_diagram_showing_the_breakdown" class="figure"><img alt="A timing diagram showing the breakdown of runtime per stage of execution for each task call." src="Images/gitc_1129.png" width="1442" height="383"/>
<h6><span class="label">Figure 11-29. </span>A timing diagram showing the breakdown of runtime per stage of execution for each task call.</h6>
</div></figure>

<p>If you recall the discussion about workflow efficiency in <a data-type="xref" href="ch10.xhtml#running_single_workflows_at_scale_with">Chapter 10</a>, some amount of overhead is associated with each stage. The timing diagram is a great resource for examining this. It can help you identify any bottlenecks in your workflow that you need to address; for example, if your list of genomic intervals is not well balanced or if a particular command is taking far more time than it should.</p>

<p>Want to see it in action?<a contenteditable="false" data-primary="tooltips in Terra workspace" data-type="indexterm" id="idm45625614465960"/> Try hovering your mouse over the colored segments, and you’ll see tooltips appear that indicate the stage you’re looking at and the amount of time it took. For example, in <a data-type="xref" href="#a_timing_diagram_showing_the_breakdown">Figure 11-29</a>, we were looking at the yellow block on the right side, which shows that <code>HaplotypeCaller</code> took just 21 seconds to run on the very short interval we gave it for testing purposes. In comparison, it took 101 seconds to pull the container image!</p>

<p>Finally, you might notice that the name of the <a contenteditable="false" data-primary="preemptible VM instances" data-secondary="workflow configured with in Terra" data-type="indexterm" id="idm45625614462424"/>task in the pop-up window includes <em>attempt 1</em>. This is because the workflow is configured to use preemptible instances, which we also discussed in the section on optimizations in <a data-type="xref" href="ch10.xhtml#running_single_workflows_at_scale_with">Chapter 10</a>. If one of your tasks is preempted and restarted, each run attempt will be represented by a separate line in the diagram, as shown in <a data-type="xref" href="#a_timing_diagram_showing_preempted_call">Figure 11-30</a> (which comes from an unrelated workflow that we ran separately).</p>

<figure class="no-frame"><div id="a_timing_diagram_showing_preempted_call" class="figure"><img alt="A timing diagram showing preempted calls (green bars, at lines 2, 12, and 13 from the top)." src="Images/gitc_1130.png" width="1442" height="730"/>
<h6><span class="label">Figure 11-30. </span>A timing diagram showing preempted calls (green bars, at lines 2, 12, and 13 from the top).</h6>
</div></figure>

<p>The bars representing preempted jobs are displayed in a single solid color because the different stages of operation are not reported.<a contenteditable="false" data-primary="preempted jobs in Terra" data-type="indexterm" id="idm45625614455144"/> As a result, you can usually see fairly clearly whether a pattern of serial preemptions exists; for example, in <a data-type="xref" href="#a_timing_diagram_showing_preempted_call">Figure 11-30</a> a job was started and then interrupted by preemption (line 12 from the top), restarted and interrupted again (line 13 from the top), and then restarted again and this time was successful. You can see from this example, in which even the shortest preempted job ran for almost four hours, that if you run into several preemptions in a row for a job that constitutes a bottleneck in your pipeline, the overall runtime can increase dramatically as a result. This highlights the importance of evaluating carefully whether the cost savings that you can reap from using preemptible instances is worth the risk of your pipelines taking much longer to complete. Our rule of thumb is that if our large-scale data-processing results are due next week, bring on the preemptibles. But if we’re frantically trying to finish a demo for a conference in two days, turn them off and suck up the extra cost.<a contenteditable="false" data-primary="Job History page in Terra" data-secondary="monitoring workflow execution" data-startref="ix_JobHis" data-type="indexterm" id="idm45625614451816"/><a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-startref="ix_TerraCrmmon" data-tertiary="monitoring workflow execution" data-type="indexterm" id="idm45625614450168"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Locating Workflow Outputs in the Data Table"><div class="sect2" id="locating_workflow_outputs_in_the_data_t">
<h2>Locating Workflow Outputs in the Data Table</h2>

<p>As we<a contenteditable="false" data-primary="data tables (Terra)" data-secondary="locating workflow ouptuts in" data-type="indexterm" id="ix_dataTerrwkout"/> noted earlier, the <a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-tertiary="locating workflow outputs in data table" data-type="indexterm" id="ix_TerraCrmwkout"/>workflow details<a contenteditable="false" data-primary="I/O (input/output)" data-secondary="workflow outputs in Terra" data-type="indexterm" id="ix_wkoutTerr"/> shown in <a data-type="xref" href="#list_of_tasks_and_related_resourcesdot">Figure 11-27</a> include pointers to the location of output files. That’s a pretty decent way to locate outputs for a particular workflow run, but that’s not going to scale well when you’re working on hundreds or thousands of samples. Not to mention hundreds <em>of</em> thousands of samples. (Yep, some people are at that point—isn’t it an exciting time to be alive?)</p>

<p>There is a much better way to do it if you used the data table, which you would need to do if you’re working at that scale. <a contenteditable="false" data-primary="GVCF data format" data-secondary="workflow output in Terra data table" data-type="indexterm" id="idm45625614438520"/>Here it is: with a tiny configuration trick, you can get the system to automatically add the workflow outputs to the data table. And, of course, we enabled that in the workflow configuration we made you run, so let’s go have a look at the data table, shown in <a data-type="xref" href="#the_data_table_showing_the_newly_genera">Figure 11-31</a>, to see whether it worked.</p>

<figure class="no-frame"><div id="the_data_table_showing_the_newly_genera" class="figure"><img alt="The data table showing the newly generated &quot;output_gvcf&quot; column." src="Images/gitc_1131.png" width="1440" height="295"/>
<h6><span class="label">Figure 11-31. </span>The data table showing the newly generated output_gvcf column.</h6>
</div></figure>

<p>And there it is! As you can see in <a data-type="xref" href="#the_data_table_showing_the_newly_genera">Figure 11-31</a>, a new column has appeared in the <em>book_sample</em> table, named <em>output_gvcf</em>, and all the samples we ran the workflow on now have file paths corresponding to the GVCFs produced by the workflow runs.</p>

<p>So, where does the name of the new column come from? Let’s return to the <code>scatter-hc.data-table</code> workflow configuration and take a look at the Output tab, which we ignored earlier. As you can see in <a data-type="xref" href="#the_workflow_outputs_configuration_pane">Figure 11-32</a>, we specified the output name and set it to be attached to the row data using the <code>this.</code> syntax, which we described earlier. You can pick an arbitrary name (for example, you could instead use <code><em>this.my_gvcf</em></code>), or you can click “Use defaults” to automatically use the name of the variable as it is specified in the workflow script, as we did here.<a contenteditable="false" data-primary="outputs configuration panel for workflows in Terra" data-type="indexterm" id="idm45625614427320"/></p>

<figure class="no-frame"><div id="the_workflow_outputs_configuration_pane" class="figure"><img alt="The workflow outputs configuration panel." src="Images/gitc_1132.png" width="1440" height="485"/>
<h6><span class="label">Figure 11-32. </span>The workflow outputs configuration panel.</h6>
</div></figure>

<p>Keep in mind that this option is available only if you’re using the data table to define the workflow inputs. In either case, however, the location where the files are written is the same. By default, the system stores all outputs produced by workflows in a bucket that is tightly associated with the workspace. The bucket is created automatically when you create a workspace, and it has the same ownership permissions as the workspace, so if you share the workspace with someone (same menu as for cloning), they will also be able to access the data in your workspace. One important restriction, however, is that you cannot modify the bucket’s permissions outside of Terra.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you delete a workspace, its bucket will also be deleted, along with all its contents. <a contenteditable="false" data-primary="workspaces (Terra)" data-secondary="deleting a workspace" data-type="indexterm" id="idm45625614421784"/>In addition, when you clone a workspace, the data is not copied, and any paths in metadata tables will continue to point to the data’s original location. This is great because it allows you to avoid paying storage fees for multiple copies of the same data that you would otherwise generate. But if you thought you could save a copy of your data by cloning a workspace before deleting the original, well, you can’t.</p>
</div>

<p>Finally, you might <a contenteditable="false" data-primary="Files link on Data page in Terra" data-type="indexterm" id="idm45625614419304"/>have noticed on the Data page that there is a Files link in the lefthand menu, which is visible in <a data-type="xref" href="#the_data_table_showing_the_newly_genera">Figure 11-31</a> among others. <a contenteditable="false" data-primary="storage buckets" data-secondary="file browser showing workflow outputs in Terra workspace bucket" data-type="indexterm" id="idm45625614416856"/>If you go back to that page and click the Files link, it will open a filesystem-like interface that you can use to browse the contents of the bucket without having to leave Terra, as shown in <a data-type="xref" href="#the_file_browser_interface_showing_work">Figure 11-33</a>.</p>

<figure class="no-frame"><div id="the_file_browser_interface_showing_work" class="figure"><img alt="The file browser interface showing workflow outputs in the workspace bucket." src="Images/gitc_1133.png" width="1440" height="439"/>
<h6><span class="label">Figure 11-33. </span>The file browser interface showing workflow outputs in the workspace bucket.</h6>
</div></figure>

<p>You can even add files to your bucket by dragging and dropping them from your desktop into the file browser. That being said, if you prefer, you can always access the bucket through the GCS console<a contenteditable="false" data-primary="I/O (input/output)" data-secondary="workflow outputs in Terra" data-startref="ix_wkoutTerr" data-type="indexterm" id="idm45625614411352"/> and <a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-startref="ix_TerraCrmwkout" data-tertiary="locating workflow outputs in data table" data-type="indexterm" id="idm45625614409464"/> interact with its<a contenteditable="false" data-primary="data tables (Terra)" data-secondary="locating workflow ouptuts in" data-startref="ix_dataTerrwkout" data-type="indexterm" id="idm45625614407352"/> contents through <code>gsutil</code>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Running the Same Workflow Again to Demonstrate Call Caching"><div class="sect2" id="running_the_same_workflow_again_to_demo">
<h2>Running the Same Workflow Again to Demonstrate Call Caching</h2>

<p>Did you think we were done?<a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-tertiary="running workspace again to demonstrate call caching" data-type="indexterm" id="ix_TerraCrmCC"/> Not quite; we couldn’t<a contenteditable="false" data-primary="call caching (Cromwell)" data-type="indexterm" id="ix_callcac"/> possibly let you move on without experiencing the wonder that is Cromwell’s call caching feature. We’ve already gone over its purpose several times—make it so you can avoid running duplicate jobs, and resume a workflow from the last point of failure, interruption or modification—so now let’s see it in action. Go ahead and use the launching process you just learned to run the workflow again on one of the samples that you already ran on earlier. When you land on the Job History page, click through to the workflow monitoring details when the View link becomes available. It might take a couple of minutes, so feel free to go grab yourself a cup of tea, coffee, or other beverage of choice—just don’t spill it on your laptop when you return. And remember to refresh the page; the workflow status doesn’t refresh on its own.</p>

<p>When you’re on the workflow details page, navigate to the Timing Diagram and hover over the widest bar for one of the lines.<a contenteditable="false" data-primary="CallCacheReading stage" data-type="indexterm" id="idm45625614397992"/><a contenteditable="false" data-primary="timing diagrams for runtime in Terra" data-secondary="CallCacheReading stage" data-type="indexterm" id="idm45625614396888"/> You should see something like <a data-type="xref" href="#a_timing_diagram_showing_callcachereadi">Figure 11-34</a>, reporting on a stage named <code>CallCacheReading</code> that took about 10 seconds to run.</p>

<figure class="no-frame"><div id="a_timing_diagram_showing_callcachereadi" class="figure"><img alt="A timing diagram showing CallCacheReading stage runtime." src="Images/gitc_1134.png" width="1442" height="332"/>
<h6><span class="label">Figure 11-34. </span>A timing diagram showing CallCacheReading stage run time.</h6>
</div></figure>

<p>If you hover over the other bars, you’ll also see that you can’t find any of the stages related to pulling the container image or localizing inputs. This shows you that when call caching kicks in for a task, the system doesn’t even go to the trouble of setting up VMs. In fact, Cromwell doesn’t even dispatch anything about that task to PAPI.<a contenteditable="false" data-primary="Pipelines API (PAPI)" data-secondary="Cromwell call caching and" data-type="indexterm" id="idm45625614390792"/></p>

<p>So what exactly does happen? Good question; let’s talk about how call caching works in practice. First, you should know that whenever the Cromwell server runs a task call successfully, it stores a detailed record of that call in its database. This includes the name of the task and all of its input values: files, parameters, container image version, everything—as well as a link to the output file. Then, the next time you send it a workflow to run, it will check each task against its database of past calls before sending it out for execution. If it finds any perfect matches, it will skip execution for that task and simply output a copy of the output file that it had linked to in the last successful execution. <a data-type="xref" href="#overview_of_cromwellapostrophes_call_ca">Figure 11-35</a> illustrates this process.</p>

<figure><div id="overview_of_cromwellapostrophes_call_ca" class="figure"><img alt="Overview of Cromwell’s call caching mechanism." src="Images/gitc_1135.png" width="1440" height="380"/>
<h6><span class="label">Figure 11-35. </span>Overview of Cromwell’s call caching mechanism.</h6>
</div></figure>

<p>In this example, all task calls in the workflow matched the call cache; in other words, <em>call-cached</em> (yep, you can use it as a verb), so nothing actually was run except a few file copying operations done by the Cromwell server itself. If you were to modify the <code>MergeVCFs</code> call even slightly and run this again, the <code>HaplotypeCaller</code> calls would call-cache, but <code>MergeVCFs</code> would not, so Cromwell would send that call to PAPI for execution. You can try this out by changing the version of the container image used by <code>MergeVCFs</code> (try 4.1.4.1) and then have a look at the Timing Diagram.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can disable call caching by clearing the checkbox in the workflow configuration, but why would you even want to do that? Call caching is fantastic. Call...ka-ching! (Because it saves you money.) #dadjokes.</p>
</div>

<p>Alright, time to take a break. How are you feeling? It’s normal to feel a little light-headed at this point; after all, you just got superpowers. Seriously, you are now capable of running real, sophisticated genomics workflows on as many samples as you can get your hands on. That’s no small feat. Yet the proof, as they say, is in the pudding, so grab a spoon and<a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-startref="ix_TerraCrmCC" data-tertiary="running workflow again to demonstrate call caching" data-type="indexterm" id="idm45625614379912"/> let’s go<a contenteditable="false" data-primary="call caching (Cromwell)" data-startref="ix_callcac" data-type="indexterm" id="idm45625614377800"/> bite off something big.<a contenteditable="false" data-primary="Terra platform" data-secondary="running workflows with Cromwell server" data-startref="ix_TerraCrm" data-type="indexterm" id="idm45625614376264"/><a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="running workflows with Cromwell server in Terra" data-startref="ix_Crmwrun" data-type="indexterm" id="idm45625614374552"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Running a Real GATK Best Practices Pipeline at Full Scale"><div class="sect1" id="running_a_real_gatk_best_practices_pipe">
<h1>Running a Real GATK Best Practices Pipeline at Full Scale</h1>

<p>Do you remember<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="running real Best Practices pipeline at full scale in Terra" data-type="indexterm" id="ix_GATKrunTer"/> Mystery <a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale" data-type="indexterm" id="ix_TerraGATK"/>Workflow #2 from <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a>, which turned out to be the Broad Institute’s whole genome analysis pipeline? It’s probably not the biggest genomics pipeline in the world (though it is plenty big), and it’s not the fastest pipeline in the world either (because it needs to be inexpensive). But it might just be the pipeline that has processed the largest number of human whole genome samples in the history of genomics (so far). If you’re looking to learn how to do something fairly standard that will come in handy at some point in the future, this pipeline would be a reasonable choice.</p>

<p>In this last section of the chapter, we’re going to show you where to find it, test it, and run it on a full-scale human whole genome sample.</p>

<p>The good news is that it’s going to be pretty straightforward. We already mentioned previously that the GATK team <a contenteditable="false" data-primary="workspaces (Terra)" data-secondary="fully loaded GATK Best Practices workspaces in Terra" data-type="indexterm" id="idm45625614364760"/>makes its <a contenteditable="false" data-primary="Best Practices workflows (GATK)" data-secondary="fully loaded workspaces in Terra" data-type="indexterm" id="idm45625614363224"/>Best Practices workflows available in a <a href="https://oreil.ly/D0Ofp">GitHub repository</a>, but that’s not all; it also provides fully loaded Terra workspaces for all of them. These Best Practices workspaces contain data tables populated with appropriate example data samples (typically a small one and a full-scale one), and workflow configurations that are already wired up to run on the example data. All you need to do is clone the workspace. Then, you can follow the procedure that you learned in this chapter to run the workflows right out of the box. (We show you how to bring in data from other sources in <a data-type="xref" href="ch13.xhtml#assembling_your_own_workspace_in_terra">Chapter 13</a>.)</p>

<section data-type="sect2" data-pdf-bookmark="Finding and Cloning the GATK Best Practices Workspace for Germline Short Variant Discovery"><div class="sect2" id="finding_and_cloning_the_gatk_best_pract">
<h2>Finding and Cloning the GATK Best Practices Workspace for Germline Short Variant Discovery</h2>

<p>You already visited the <a href="https://oreil.ly/nUMy2">Terra Library showcase</a> earlier in this chapter to find the tutorial workspace we created for the book.<a contenteditable="false" data-primary="germline short variant discovery, GATK Best Practices" data-secondary="finding and cloning workspace for in Terra" data-type="indexterm" id="idm45625614356440"/><a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale" data-tertiary="finding and cloning workspace for germline short variant discovery" data-type="indexterm" id="ix_TerraGATKwksp"/><a contenteditable="false" data-primary="workspaces (Terra)" data-secondary="finding and cloning GATK Best Practices workspace for germline short variant discovery" data-type="indexterm" id="ix_wkspGATK"/> Let’s go back there, but this time you’re going to look for an actual Best Practices workspace published by the GATK team.<a contenteditable="false" data-primary="Whole Genome Analysis Pipeline workspace" data-type="indexterm" id="idm45625614351048"/> As of this writing, the featured germline short variants workspace is called <a href="https://oreil.ly/x4Pzc">Whole-Genome-Analysis-Pipeline</a>, as shown in <a data-type="xref" href="#summary_information_for_the_whole_genom">Figure 11-36</a>. This name might change in the future because the team has plans to adapt how they name and package these resources in light of the expanding scope covered by its tools. If you’re having trouble finding the right workspace, check the GATK website’s Best Practices section, which hosts a list of relevant resources that includes the Terra workspaces. Be sure to also check our book’s <a href="https://oreil.ly/genomics-blog">blog</a>, where we’ll provide updates over time.</p>

<figure class="no-frame"><div id="summary_information_for_the_whole_genom" class="figure"><img alt="Summary information for the Whole-Genome-Analysis-Pipeline workspace." src="Images/gitc_1136.png" width="1440" height="622"/>
<h6><span class="label">Figure 11-36. </span>Summary information for the <a href="https://oreil.ly/x4Pzc">Whole-Genome-Analysis-Pipeline workspace</a>.</h6>
</div></figure>

<p>When you’ve found the workspace, clone it as described earlier in this chapter. You’ll notice that the Dashboard provides a lot of information about the workflow, the example data and how to use these resources effectively. It even includes a summary of how long it takes and how much it costs to run the workflow on the various samples in the example data table. Speaking of which, let’s go see what’s in there.<a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale in Terra" data-startref="ix_TerraGATKwksp" data-tertiary="finding and cloning workspace for germline short variant discovery" data-type="indexterm" id="idm45625614342968"/><a contenteditable="false" data-primary="workspaces (Terra)" data-secondary="finding and cloning GATK Best Practices workspace for germline short variant discovery" data-startref="ix_wkspGATK" data-type="indexterm" id="idm45625614340952"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Examining the Preloaded Data"><div class="sect2" id="examining_the_preloaded_data">
<h2>Examining the Preloaded Data</h2>

<p>In your clone workspace, navigate <a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale in Terra" data-tertiary="examining preloaded data in workspace" data-type="indexterm" id="idm45625614337240"/>to the Data section. Again, this might change, but as of this writing, this workspace contains two main data tables as well as the Workspace Data table.<a contenteditable="false" data-primary="data tables (Terra)" data-secondary="in Whole Genome Analysis Pipeline workspace" data-type="indexterm" id="idm45625614335176"/> The latter lists the full-scale version of the genome reference files and other resources used in the whole genome pipeline. Note that these resources are all based on the hg38 build (more properly known as GRCh38) and would therefore not be compatible with the data in the tutorial workspace that we were using earlier.</p>

<p>The two main data tables are called <em>participant</em> and <em>sample</em>, as shown in <a data-type="xref" href="#a_list_of_tables_and_detailed_view_of_t">Figure 11-37</a>.</p>

<figure class="no-frame"><div id="a_list_of_tables_and_detailed_view_of_t" class="figure"><img alt="A list of tables and detailed view of the sample table." src="Images/gitc_1137.png" width="1440" height="268"/>
<h6><span class="label">Figure 11-37. </span>A list of tables and detailed view of the sample table.</h6>
</div></figure>

<p>The <em>sample</em> table should look familiar to you because it’s the same kind of table as the <em>book_sample</em> table that you encountered earlier in this chapter, with a few additional columns. As you can see in <a data-type="xref" href="#summary_information_for_the_whole_genom">Figure 11-36</a>, two samples are listed there: NA12878 and NAA12878_small. <a contenteditable="false" data-primary="NA12878 and NAA12878_small samples" data-type="indexterm" id="idm45625614326152"/>They both originate from the same study participant, dubbed NA12878. The former is a full-size whole genome sequencing dataset, whereas the latter is a downsampled version of that dataset. For each sample, we have a list of unmapped BAM files (which will be the main input to the workflow) as well as other files that the documentation explains are outputs produced by the workflow, which has already been run in this workspace.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45625614324280">
<h5>The NA12878 Test Samples</h5>

<p>As you might recall from earlier chapters, the NA12878 individual was the mother in the family trio whose data we’ve been using for testing purposes. That family’s samples, and NA12878 in particular, have been sequenced and analyzed many times by many groups as part of a wide variety of research and development efforts. We might not know their names, but we all owe them a debt of gratitude for the advances that their data made possible.</p>

<p>If you’re not <a contenteditable="false" data-primary="downsampling" data-type="indexterm" id="idm45625614322104"/>familiar with the term <em>downsampling</em>, it refers to a process of selectivly removing a proportion of the data (sequencing reads, in this case) in order for it to take less storage space and/or less time for processing. We sometimes refer to the downsampled data as the <em>plumbing sample</em>, because it is useful for testing if the pipeline runs to completion but contains too little data to test the scientific validity of the pipeline.</p>
</div></aside>

<p>The <em>participant</em> table, on the<a contenteditable="false" data-primary="participant table (Terra)" data-type="indexterm" id="idm45625614318472"/> other hand, is probably new to you. It lists the study participants, though in this case, that’s just a single person. If you looked carefully at the sample table, you might have noticed that one of its columns is <em>participant</em>, which is an identifier that points to an entry in the participant table (<em>participant_id</em> in that table). The purpose of the participant table is to provide a higher level of organization for your data, which is useful when you have multiple study participants, and each of them can have multiple samples associated with them, either corresponding to different data types, different assays, or both. With this setup, you can use the data table system to do things like run a workflow on all the samples that belong to a subset of participants, for example.<a contenteditable="false" data-primary="Mutect2 somatic analysis pipeline" data-type="indexterm" id="idm45625614315592"/></p>

<p>As another example, the <code>Mutect2</code> somatic analysis pipeline (described in detail in <a data-type="xref" href="ch07.xhtml#gatk_best_practices_for_somatic_variant">Chapter 7</a>) expects to see a tumor sample and a matched normal sample from each patient, which are formally described as pairs of samples. <a contenteditable="false" data-primary="tumor-normal pair analysis" data-type="indexterm" id="idm45625614312152"/>If you check out the corresponding GATK Best Practices workspace (<a href="https://oreil.ly/a8ksp">this one</a>, at the time of writing), you’ll see <a contenteditable="false" data-primary="Panel of Normals (PoN)" data-type="indexterm" id="idm45625614310104"/>it has four data tables organizing the data into participants, samples, pairs of samples, and sets <a contenteditable="false" data-primary="data models" data-type="indexterm" id="idm45625614308760"/>of samples (for the normals that are used in the PoN, described in <a data-type="xref" href="ch07.xhtml#gatk_best_practices_for_somatic_variant">Chapter 7</a>). The data tables in that workspace conform to a <em>data model</em> defined by the TCGA cancer<a contenteditable="false" data-primary="TCGA (The Cancer Genome Atlas)" data-type="indexterm" id="idm45625614305944"/> research program: The Cancer Genome Atlas.</p>

<p>More generally, you can use any number of tables to organize your data and describe the relationships between <em>data entities</em> like participants, samples, and others in a structured data model. In <a data-type="xref" href="ch13.xhtml#assembling_your_own_workspace_in_terra">Chapter 13</a>, we discuss options for building your data model in Terra and using it effectively to save yourself time and effort.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Selecting Data and Configuring the Full-Scale Workflow"><div class="sect2" id="selecting_data_and_configuring_the_full">
<h2>Selecting Data and Configuring the Full-Scale Workflow</h2>

<p>As we’ve<a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale" data-tertiary="selecting data and configuring full-scale workflow" data-type="indexterm" id="idm45625614300856"/> described previously, you can either head straight for the workflows page in the workspace or you can start the process from the Data page by selecting one or both samples in the <em>sample</em> table. (We recommend selecting both so you can experience the runtime difference of the plumbing test and the full-scale run for yourself.) If you choose to follow the same procedure as previously, click “Open with…” to choose the workflow option, and select the one workflow that is preconfigured in this workspace. Unless a lot has changed since the book came out, this should be the same, or practically the same, as the workflow that we examined in detail in <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a>. However, you’ll notice that on the workflow page, you can view only the main WDL script, not any of the additional WDL files that contain the subworkflows and task libraries. <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="files for workflows in Terra" data-type="indexterm" id="idm45625614296664"/>This is a limitation of the current interface that will be addressed in future work.</p>

<p>We didn’t look at the inputs to this workflow in much detail when we dissected it in <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a>, because at the time we were focused on understanding its internal plumbing. Now that we’re looking at them through the Terra interface, in the context of the workflow inputs configuration form, it’s pretty striking that it seems to have only four required inputs, which is fewer than the much simpler workflow we’ve been working with so far. However, this is mostly a distortion of reality; in fact, two of those four inputs represent a larger number of inputs that are bundled together using struct variables, which we encountered in <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a>. These two structs represent the two most typical categories of inputs that you will frequently encounter in genomics workflows. One is a bundle of reference data, grouping the genome reference sequence, associated index files, and known variant resources for validation. The other groups the files that hold the actual data that you’re looking to process.</p>

<p>Most of the optional inputs to this workflow are task-level runtime parameters and conditional checks, which are readily recognized by their type, Boolean. You might recall that in the first workflow we examined in <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a>, we found a lot of conditional statements that defined settings like default runtime resource allocation. The optional inputs we see here are set up so that you can override those default settings when you configure the workflow; for example, if you have reason to believe that the defaults won’t be appropriate for your use case. Yet if you don’t know the first thing about what the runtime resource allocations should be, you can just leave those fields blank and trust that the presets will be good enough.</p>

<p>It’s also worth <a contenteditable="false" data-primary="outputs configuration panel for workflows in Terra" data-type="indexterm" id="idm45625614289048"/>taking a quick peek at the Output tab, where you’ll be reminded that this workflow produces a ginormous number of outputs, which are mostly quality control-related metrics and reports. This is where we really appreciate being able to have the paths to the output files written to the data tables, which makes it a lot easier to find outputs than if you had to go rooting around in the Cromwell execution directories for each file. For the record, the outputs that you’re most likely to care about are the trio of <code>output_bam</code>, <code>output_cram</code>, and above all, <code>output_vcf</code>, which is the set of variant calls that you’ll want to use in downstream analysis.</p>

<p>That being said, all of this should mostly be prefilled and ready to go, but on the Output tab, click “Use defaults” to set up the mapping of outputs to the sample table.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Launching the Full-Scale Workflow and Monitoring Execution"><div class="sect2" id="launching_the_full_scale_workflow_and_m">
<h2>Launching the Full-Scale Workflow and Monitoring Execution</h2>

<p>Enough talk, let’s run this thing! As<a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale" data-tertiary="launching full-scale workflow and monitoring execution" data-type="indexterm" id="ix_TerraGATKlnchmon"/> previously, click Run Analysis and then Launch to submit the workflow for execution. You can follow the same steps as we described earlier to monitor the progress of your pipeline, but you should expect this to take quite a bit longer! As mentioned earlier, the Dashboard summary includes typical runtimes for the workflow running on both example datasets, so be sure to use that as a guide to gauge when to go check how it’s going. You can also browse the Job History of the original workspace (the one you cloned your copy from); it includes past executions, so you can look up the timing diagram there.</p>

<p>One new thing you might notice is that the List view of the workflow details page collapses subworkflows and displays their name in underlined font, as shown in <a data-type="xref" href="#the_list_view_of_the_task_calls_in_the">Figure 11-38</a>. This is similar to the representation of scattered tasks but lacks the little stack icon on the side.</p>

<figure class="width-40 no-frame"><div id="the_list_view_of_the_task_calls_in_the" class="figure"><img alt="The List View of the task calls in the master workflow." src="Images/gitc_1138.png" width="652" height="910"/>
<h6><span class="label">Figure 11-38. </span>The List View of the task calls in the master workflow.</h6>
</div></figure>

<p>Have a look at the timing diagram provided at this level: you essentially get a high-level summary of the component segments of the workflow, as shown in <a data-type="xref" href="#the_timing_diagram_for_the_master_workf">Figure 11-39</a>. If you hover over the various lines, you’ll see that the longest segment on the left corresponds to <em>UnmappedBamToAlignedBam</em>, the data processing subworkflow that takes in the raw unmapped data and outputs an analysis-ready BAM file. The next three lines consist of the main quality control subworkflow, <em>AggregatedBamQC</em>, and two metrics collection tasks that are not bundled into subworkflows. Next down is the <code>BamToGvcf</code> variant-calling subworkflow, which produces the final output of the per-ample pipeline, the GVCF file of variants. You’ll notice that those four segments all started at the same time, when the very first segment completed because they are independent of one another. This is parallelism in action! Finally, the last segment is the <em>BamToCram</em> workflow, which produces a CRAM file version of the processed sequencing data for archival purposes. The timing of that one might seem odd until you realize that it starts immediately after the <em>AggregatedBamQC</em> workflow finishes.</p>

<figure><div id="the_timing_diagram_for_the_master_workf" class="figure"><img alt="The timing diagram for the master workflow showing subworkflows (solid red bars) and individual tasks that are not bundled into subworkflows (multicolor bars)." src="Images/gitc_1139.png" width="1440" height="391"/>
<h6><span class="label">Figure 11-39. </span>The timing diagram for the master workflow showing subworkflows (solid red bars) and individual tasks that are not bundled into subworkflows (multicolor bars).</h6>
</div></figure>

<p>Now go back to the List View and click through one of the subworkflows; for example, the <code>BamToGvcf</code> variant calling subworkflow. You’ll see it open up on its own page as if it were a standalone workflow, with its own list of tasks, timing diagram, and so on, as shown in <a data-type="xref" href="#the_workflow_details_page_for_the_bamto">Figure 11-40</a>.</p>

<figure class="no-frame"><div id="the_workflow_details_page_for_the_bamto" class="figure"><img alt="The workflow details page for the BamToGvcf subworkflow." src="Images/gitc_1140.png" width="1440" height="824"/>
<h6><span class="label">Figure 11-40. </span>The workflow details page for the BamToGvcf subworkflow.</h6>
</div></figure>

<p>There is theoretically no limit to how deeply you can nest WDL subworkflows, as long as you don’t create loops. In practice, though, we have not yet seen workflows with more than three levels of nesting (including task libraries). In any case, you can navigate back up to the parent workflow level by clicking the upward-pointing arrow in the upper-right corner.</p>

<p>Finally, you can check that the outputs were produced as expected, both in the Job History view and in the <em>sample</em> <a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale" data-startref="x_TerraGATKlnchmon" data-tertiary="launching full-scale workflow and monitoring execution" data-type="indexterm" id="idm45625614263432"/>data table, as we’ve described earlier in the chapter.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Options for Downloading Output Data—or Not"><div class="sect2" id="options_for_downloading_output_dataem_d">
<h2>Options for Downloading Output Data—or Not</h2>

<p>Whether you’re browsing the outputs of<a contenteditable="false" data-primary="downloading workflow output data from Terra" data-type="indexterm" id="idm45625614259368"/> your workflow through the Job History page, or through <a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale" data-tertiary="options for downloading output data" data-type="indexterm" id="idm45625614258040"/>either the data tables or the Files browser on the Data page, you can download any file by simply clicking its name or path. This brings up a small window that includes a preview of the file (if it’s in a readable text format), its size, and an estimate of the cost of the download, which is due to egress fees. In <a data-type="xref" href="#file_download_windows_showing_aright_pa">Figure 11-41</a>, we have examples of such download windows for two kinds of files: the list of unmapped BAM files that served as input for the pipeline, which is a plain-text file and can therefore be previewed, and the GVCF that <a contenteditable="false" data-primary="GVCF data format" data-secondary="final output files from workflow run in Terra" data-type="indexterm" id="idm45625614254584"/>is the final data output of the pipeline, which is originally plain text, too, but here, was gzipped to require less storage space, and therefore cannot be previewed. That would also be the case for other compressed file formats like BAM and CRAM files, which also cannot be previewed.</p>

<figure class="no-frame"><div id="file_download_windows_showing_aright_pa" class="figure"><img alt="File download windows showing A) the list of unmapped BAM files, and B) the final GVCF output." src="Images/gitc_1141.png" width="1440" height="877"/>
<h6><span class="label">Figure 11-41. </span>File download windows showing A) the list of unmapped BAM files, and B) the final GVCF output.</h6>
</div></figure>

<p>The download window offers three ways to download the file of interest. You can follow the link to the GCS console, where<a contenteditable="false" data-primary="Google Cloud Storage (GCS)" data-secondary="using GCS console to download output files from Terra" data-type="indexterm" id="idm45625614249864"/> you can select multiple files and download them through your web browser. You can also simply click the blue Download button for that one file, which will also be downloaded by the web browser. Alternatively, you can copy the terminal download command, which includes the full path to the file’s location in GCS, to download the file with the command-line tool <code>gsutil</code>.</p>

<p>The direct download option is fine for individual files that you want to look at quickly, especially if they’re small. For example, the 1.9 KB text file in <a data-type="xref" href="#file_download_windows_showing_aright_pa">Figure 11-41</a> is predicted to cost less than a penny to retrieve. If you need to retrieve multiple small to medium files like the 185 MB GVCF in <a data-type="xref" href="#file_download_windows_showing_aright_pa">Figure 11-41</a> (just two cents? sounds reasonable), you’ll usually be better off using either the GCP console<a contenteditable="false" data-primary="GCP console" data-secondary="using to download output files from Terra" data-type="indexterm" id="idm45625614244392"/> or better yet, <code>gsutil</code>. But if you find yourself needing to retrieve large files (many gigabytes, many dollars), it might be worth pausing to rethink whether you really can’t do what you need to do without a local copy of the file.<a contenteditable="false" data-primary="gsutil" data-secondary="using to download output files from Terra" data-type="indexterm" id="idm45625614242152"/> For example, were you planning to look at the BAM and VCF files in IGV to check some variant calls by eye?<a contenteditable="false" data-primary="IGV (Integrated Genome Viewer)" data-secondary="connecting to GCS and viewing output files from Terra" data-type="indexterm" id="idm45625614240488"/> Remember, you can do that by connecting IGV to GCS. Or did you want to run another kind of analysis that you don’t have a workflow for, or that requires an interactive process? Ah, that’s fair…but maybe you could continue that work in the cloud rather than falling back to a local environment. Wouldn’t it be amazing if you could do <em>all</em> of your work in the cloud, from the raw data all the way to making the figures that are going to be in your paper?</p>

<p>That is not a pipe dream. It’s already possible today—but you’re going to need something better than just the VM and something different from the workflow system. You will need an integrated environment for interactive analysis on the cloud, which Terra provides as well.<a contenteditable="false" data-primary="Terra platform" data-secondary="running real GATK Best Practices pipeline at full scale" data-startref="ix_TerraGATK" data-type="indexterm" id="idm45625614237544"/><a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="running real Best Practices pipeline at full scale in Terra" data-startref="ix_GATKrunTer" data-type="indexterm" id="idm45625614235832"/></p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The filename produced by the workflow uses a plain <em>.vcf</em> extension instead of <em>.g.vcf</em>, which is optional but recommended for signifying that a file is, in fact, a GVCF rather than a regular VCF file. This highlights the fact that you can rarely rely on filenames and extensions to know for sure what a file contains and how it was produced. Data management frameworks like the workspace data model can mitigate such problems by helping us keep track of the relationships between pieces of data.</p>
</div>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrap-Up and Next Steps"><div class="sect1" id="wrap_up_and_next_steps-id00008">
<h1>Wrap-Up and Next Steps</h1>

<p>For the past four chapters, including this one, we’ve been living and breathing for workflows. We started out small in <a data-type="xref" href="ch08.xhtml#automating_analysis_execution_with_work">Chapter 8</a>, running canned WDL scripts on a single VM. Then, in <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a> we dissected real genomics workflows to learn what they did and how they were wired up. This led us to a better understanding of some of the requirements of such workflows, which are designed to take advantage of various cloud features including parallelism and burst capability.</p>

<p>But that made us realize that we couldn’t continue running workflows on a single VM, even if we beefed up its resource allocations, so we moved to dispatching jobs to PAPI for execution in <a data-type="xref" href="ch10.xhtml#running_single_workflows_at_scale_with">Chapter 10</a>. We experimented with two approaches for doing so: directly with Cromwell and through the WDL Runner wrapper, which showed us the power of PAPI but also showed us the limitations of launching a single workflow at a time.</p>

<p>Finally, we moved to Terra in this chapter to use its built-in, full-featured Cromwell server. We were able to take advantage of some of the Cromwell server’s coolest features, like the vaunted call caching mechanism and the timing diagram, without worrying for a second about server maintenance. Along the way, we also encountered unexpected benefits of using Terra, mainly thanks to the integration of data management with workflow execution. Having learned to launch a workflow on rows in a data table, we’re now able to process arbitrary amounts of data without breaking a sweat. And we know how to get the outputs to be added to the table automatically, so we don’t need to go digging for them.</p>

<p>While explaining all this, we might have implied that applying the GATK Best Practices to your own data should now “simply” be a matter of running the workflows as demonstrated. However, in the course of a real genomic study, you’ll typically need to perform a variety of peripheral tasks that aren’t so conveniently packaged into workflows. Whether for testing commands, evaluating the quality of results, or troubleshooting errors, you’ll need to be able to interact with the data in a more immediate way. That will be even more the case if your work responsibilities extend beyond what we defined very narrowly as genomics (i.e., variant discovery) to include developing and testing hypotheses to answer specific scientific or clinical questions.</p>

<p>In <a data-type="xref" href="ch12.xhtml#interactive_analysis_in_jupyter_noteboo">Chapter 12</a>, we use a popular environment for interactive analysis that also happens to do wonders for reproducible science, called Jupyter. We’ll still be working within the Terra platform, which hosts a scalable system for serving Jupyter in the cloud.<a contenteditable="false" data-primary="Terra platform" data-startref="ix_Terra" data-type="indexterm" id="idm45625614221544"/></p>
</div></section>
</div></section></div>



  </body></html>