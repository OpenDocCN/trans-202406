<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops" lang="en" xml:lang="en" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd">
  <head>
    <title>Unknown</title>
    <link rel="stylesheet" type="text/css" href="../stylesheet.css"/>
    <link rel="stylesheet" type="text/css" href="../page_styles.css"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  </head>
  <body class="calibre"><div id="sbo-rt-content" class="calibre1"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 15. Troubleshooting Pods and Containers" class="praise"><div class="dedication" id="troubleshooting_pods_containers">
<h1 class="calibre14"><span class="keep-together">Chapter 15. </span>Troubleshooting Pods and Containers</h1>


<p class="author1">When operating an application in a production Kubernetes cluster, failures are almost inevitable. You can’t completely leave this job up to the Kubernetes administrator—it’s your responsibility as an application developer to be able to troubleshoot issues for the Kubernetes objects you designed and deployed.</p>

<p class="author1">In this chapter, we’ll look at troubleshooting strategies that can help with identifying the root cause of an issue so that you can take action and correct the failure appropriately. The strategies discussed here start with the high-level perspective of a Kubernetes object and then drill into more detail as needed.</p>
<aside data-type="sidebar" epub:type="sidebar" class="calibre48"><div class="sidebar" id="id484">
<h1 class="calibre49">Coverage of Curriculum Objectives</h1>
<p class="author1">This chapter addresses the following curriculum objectives:</p>

<ul class="printings">
<li class="calibre13">
<p class="author1">Use provided tools to monitor Kubernetes applications</p>
</li>
<li class="calibre13">
<p class="author1">Utilize container logs</p>
</li>
<li class="calibre13">
<p class="author1">Debugging in Kubernetes</p>
</li>
</ul>
</div></aside>






<section data-type="sect1" data-pdf-bookmark="Troubleshooting Pods" class="praise"><div class="dedication" id="id312">
<h1 class="calibre17">Troubleshooting Pods</h1>

<p class="author1">In most cases, creating a Pod is no issue. You simply emit the <code class="calibre15">run</code>, <code class="calibre15">create</code>, or <code class="calibre15">apply</code> commands to instantiate the Pod. If the YAML manifest is formed properly, Kubernetes accepts your request, so the assumption is that everything works as expected. To verify the correct behavior, the first thing you’ll want to do is to check the Pod’s high-level runtime information. The operation could involve other Kubernetes objects like a Deployment responsible for rolling out multiple replicas of a Pod.</p>








<section data-type="sect2" data-pdf-bookmark="Retrieving High-Level Information" class="praise"><div class="dedication" id="id313">
<h2 class="calibre33">Retrieving High-Level Information</h2>

<p class="author1">To retrieve the information, run either the <code class="calibre15">kubectl get pods</code> command for just the Pods running in the namespace or the <code class="calibre15">kubectl get all</code> command to retrieve the most prominent object types in the namespace (which includes Deployments). You will want to look at the columns <code class="calibre15">READY</code>, <code class="calibre15">STATUS</code>, and <code class="calibre15">RESTARTS</code>. In the optimal case, the number of ready containers matches the number of containers you defined in the <code class="calibre15">spec</code>. For a single-container Pod, the <code class="calibre15">READY</code> column would say 1/1.</p>

<p class="author1">The status should say <code class="calibre15">Running</code> to indicate that the Pod entered the proper life cycle state. Be aware that it’s totally possible that a Pod renders a <code class="calibre15">Running</code> state, but the application isn’t actually working properly. If the number of restarts is greater than 0, then you might want to check the logic of the liveness probe (if defined) and identify the reason a restart was necessary.</p>

<p class="author1">The following Pod observes the status <code class="calibre15">ErrImagePull</code> and makes 0/1 containers available to incoming traffic. In short, this Pod has a problem:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl get pods</strong>
NAME              READY   STATUS         RESTARTS   AGE
misbehaving-pod   0/1     ErrImagePull   0          2s
</pre>

<p class="author1">After working with Kubernetes for a while, you’ll automatically recognize common error conditions. <a data-type="xref" href="#common_pod_error_statuses" class="calibre10">Table 15-1</a> lists some of those error statuses and explains how to fix them.</p>
<table id="common_pod_error_statuses" class="calibre58">
<caption class="calibre59"><span class="keep-together">Table 15-1. </span>Common Pod error statuses</caption>
<thead class="calibre61">
<tr class="calibre62">
<th class="calibre63">Status</th>
<th class="calibre63">Root cause</th>
<th class="calibre63">Potential fix</th>
</tr>
</thead>
<tbody class="calibre64">
<tr class="calibre62">
<td class="calibre65"><p class="author1"><code class="calibre60">ImagePullBackOff</code> or
<span class="keep-together"><code class="calibre60">ErrImagePull</code></span></p></td>
<td class="calibre65"><p class="author1">Image could not be pulled from registry.</p></td>
<td class="calibre65"><p class="author1">Check correct image name, check that image name exists in registry, verify network access from node to registry, ensure proper authentication.</p></td>
</tr>
<tr class="calibre66">
<td class="calibre65"><p class="author1"><code class="calibre60">CrashLoopBackOff</code></p></td>
<td class="calibre65"><p class="author1">Application or command run in container crashes.</p></td>
<td class="calibre65"><p class="author1">Check command executed in container, ensure that image can properly execute (e.g., by creating a container with Docker).</p></td>
</tr>
<tr class="calibre62">
<td class="calibre65"><p class="author1"><code class="calibre60">CreateContainerConfigError</code></p></td>
<td class="calibre65"><p class="author1">ConfigMap or Secret referenced by container cannot be found.</p></td>
<td class="calibre65"><p class="author1">Check correct name of the configuration object, verify the existence of the configuration object in the namespace.</p></td>
</tr>
</tbody>
</table>
</div></section>








<section data-type="sect2" class="praise" data-pdf-bookmark="Inspecting Events"><div class="dedication" id="id314">
<h2 class="calibre33">Inspecting Events</h2>

<p class="author1">You might not encounter any of those error statuses. But there’s still a chance of the Pod having a configuration issue. You can retrieve detailed information about the Pod using the <code class="calibre15">kubectl describe pod</code> command to inspect its events.</p>

<p class="author1">The following output belongs to a Pod that tries to mount a Secret that doesn’t exist. Instead of rendering a specific error message, the Pod gets stuck with the status 
<span class="keep-together"><code class="calibre15">ContainerCreating</code>:</span></p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl get pods</strong>
NAME         READY   STATUS              RESTARTS   AGE
secret-pod   0/1     ContainerCreating   0          4m57s
<strong class="calibre38">$ kubectl describe pod secret-pod</strong>
...
Events:
Type    Reason      Age                  From              Message
----    ------      ----                 ----              -------
Normal  Scheduled   &lt;unknown&gt;            default-scheduler Successfully \
                                                           assigned
                                                           default/secret-pod \
                                                           to minikube
Warning FailedMount 3m15s                kubelet, minikube Unable to attach or \
                                                           mount volumes: \
                                                           unmounted \
                                                           volumes=[mysecret], \
                                                           unattached volumes= \
                                                           [default-token-bf8rh \
                                                           mysecret]: timed out \
                                                           waiting for the \
                                                           condition
Warning FailedMount 68s (x10 over 5m18s) kubelet, minikube MountVolume.SetUp \
                                                           failed for volume \
                                                           "mysecret" : secret \
                                                           "mysecret" not found
Warning FailedMount 61s                  kubelet, minikube Unable to attach or \
                                                           mount volumes: \
                                                           unmounted volumes= \
                                                           [mysecret], \
                                                           unattached \
                                                           volumes=[mysecret \
                                                           default-token-bf8rh \
                                                           ]: timed out \
                                                           waiting for the \
                                                           condition
</pre>

<p class="author1">Another helpful command is <code class="calibre15">kubectl get events</code>. The output of the command lists the events across all Pods for a given namespace. You can use additional command-line options to further filter and sort events:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl get events</strong>
LAST SEEN   TYPE      REASON            OBJECT               MESSAGE
3m14s       Warning   BackOff           pod/custom-cmd       Back-off \
                                                             restarting \
                                                             failed container
2s          Warning   FailedNeedsStart  cronjob/google-ping  Cannot determine \
                                                             if job needs to \
                                                             be started: too \
                                                             many missed start \
                                                             time (&gt; 100). Set \
                                                             or decrease \
                                                             .spec. \
                                                             startingDeadline \
                                                             Seconds or check \
                                                             clock skew
</pre>

<p class="author1">Sometimes troubleshooting won’t be enough. You may have to dig into the application runtime behavior and configuration in the container.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Using Port Forwarding" class="praise"><div class="dedication" id="id315">
<h2 class="calibre33">Using Port Forwarding</h2>

<p class="author1">In production environments, you’ll operate an application in multiple Pods controlled by a ReplicaSet. It’s not unusual that one of those replicas experiences a runtime issue. Instead of troubleshooting the problematic Pod from a temporary Pod from within the cluster, you can also forward the traffic to a Pod through a tunneled HTTP connection. This is where the <a href="https://kubernetes.io/docs/reference/kubectl/generated/kubectl_port-forward/" class="calibre10"><code class="calibre15">port-forward</code> command</a> comes into play.</p>

<p class="author1">Let’s demonstrate the behavior. The following command creates a new Deployment running nginx in three replicas:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl create deployment nginx --image=nginx:1.24.0 --replicas=3 --port=80</strong>
deployment.apps/nginx created
</pre>

<p class="author1">The resulting Pod will have unique names derived from the name of the Deployment. Say the Pod <code class="calibre15">nginx-595dff4799-ph4js</code> has an issue you want to troubleshoot:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl get pods</strong>
NAME                     READY   STATUS    RESTARTS   AGE
nginx-595dff4799-pfgdg   1/1     Running   0          6m25s
nginx-595dff4799-ph4js   1/1     Running   0          6m25s
nginx-595dff4799-s76s8   1/1     Running   0          6m25s
</pre>

<p class="author1">The <code class="calibre15">port-forward</code> command forwards HTTP connections from a local port to a port exposed by a Pod. This exemplary command forwards port 2500 on your local machine to the container port 80 running in the Pod <code class="calibre15">nginx-595dff4799-ph4js</code>:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl port-forward nginx-595dff4799-ph4js 2500:80</strong>
Forwarding from 127.0.0.1:2500 -&gt; 80
Forwarding from [::1]:2500 -&gt; 80
</pre>

<p class="author1">The <code class="calibre15">port-forward</code> command does not return. You have to open another terminal to perform calls to the Pod via port forwarding. The following command simply checks if the Pod is accessible from your local machine using <code class="calibre15">curl</code>:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">curl -Is localhost:2500 | head -n 1</strong>
HTTP/1.1 200 OK
</pre>

<p class="author1">The HTTP response code 200 clearly shows that we can access the Pod from outside of the cluster. The <code class="calibre15">port-forward</code> command is not meant to run for a long time. Its primary purpose is for testing or troubleshooting a Pod without having to expose it with the help of a Service.</p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Troubleshooting Containers" class="praise"><div class="dedication" id="id316">
<h1 class="calibre17">Troubleshooting Containers</h1>

<p class="author1">You can interact with the container for a deep-dive into the application’s runtime environment. The next sections will discuss how to inspect logs, open an interactive shell to a container, and debug containers that do not provide a shell.</p>
<div data-type="note" epub:type="note" class="calibre26"><h6 class="calibre27">Note</h6>
<p class="author1">The commands described in the following sections apply to init and sidecar containers as well. Use the <code class="calibre15">-c</code> or <code class="calibre15">--container</code> command line flag to target a specific container if you are running more than a single one. See <a data-type="xref" href="ch08.xhtml#multi_container_pods" class="calibre10">Chapter 8</a> for more information on multi-container Pods.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Inspecting Logs" class="praise"><div class="dedication" id="id317">
<h2 class="calibre33">Inspecting Logs</h2>

<p class="author1">When troubleshooting a Pod, you can retrieve the next level of details by downloading and inspecting its logs. You may or may not find additional information that points to the root cause of a misbehaving Pod, but it’s definitely worth a look. The YAML manifest shown in <a data-type="xref" href="#pod_failing_shell" class="calibre10">Example 15-1</a> defines a Pod running a shell command.</p>
<div id="pod_failing_shell" data-type="example" class="calibre45">
<h5 class="calibre46"><span class="keep-together">Example 15-1. </span>A Pod running a failing shell command</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre47"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="calibre15">v1</code><code class="w"></code>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Pod</code><code class="w"></code>
<code class="nt">metadata</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">incorrect-cmd-pod</code><code class="w"></code>
<code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">test-container</code><code class="w"></code>
<code class="w">    </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="calibre15">busybox:1.36.1</code><code class="w"></code>
<code class="w">    </code><code class="nt">command</code><code class="p">:</code><code class="w"> </code><code class="calibre15">[</code><code class="s">"/bin/sh"</code><code class="calibre15">,</code><code class="w"> </code><code class="s">"-c"</code><code class="calibre15">,</code><code class="w"> </code><code class="s">"unknown"</code><code class="calibre15">]</code><code class="w"></code></pre></div>

<p class="author1">After creating the object, the Pod fails with the status <code class="calibre15">CrashLoopBackOff</code>. Running the <code class="calibre15">logs</code> command reveals that the command run in the container has an issue:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl create -f crash-loop-backoff.yaml</strong>
pod/incorrect-cmd-pod created
<strong class="calibre38">$ kubectl get pods incorrect-cmd-pod</strong>
NAME                READY   STATUS              RESTARTS   AGE
incorrect-cmd-pod   0/1     CrashLoopBackOff    5          3m20s
<strong class="calibre38">$ kubectl logs incorrect-cmd-pod</strong>
/bin/sh: unknown: not found
</pre>

<p class="author1">The <code class="calibre15">logs</code> command provides two helpful options. The option <code class="calibre15">-f</code> streams the logs, meaning you’ll see new log entries as they’re being produced in real time. The option <code class="calibre15">--previous</code> gets the logs from the previous instantiation of a container, which is helpful if the container has been restarted.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Opening an Interactive Shell" class="praise"><div class="dedication" id="id318">
<h2 class="calibre33">Opening an Interactive Shell</h2>

<p class="author1">If any of the previous commands don’t point you to the root cause of the failing Pod, it’s time to open an interactive shell to a container. As an application developer, you’ll know best what behavior to expect from the application at runtime. Inspect the running processes by using the Unix or Windows utility tools, depending on the image run in the 
<span class="keep-together">container.</span></p>

<p class="author1">Say you encounter a situation where a Pod seems to work properly on the surface, as shown in <a data-type="xref" href="#pod_current_date" class="calibre10">Example 15-2</a>.</p>
<div id="pod_current_date" data-type="example" class="calibre45">
<h5 class="calibre46"><span class="keep-together">Example 15-2. </span>A Pod periodically writing the current date to a file</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre47"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="calibre15">v1</code><code class="w"></code>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Pod</code><code class="w"></code>
<code class="nt">metadata</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">failing-pod</code><code class="w"></code>
<code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">args</code><code class="p">:</code><code class="w"></code>
<code class="w">    </code><code class="calibre15">-</code><code class="w"> </code><code class="calibre15">/bin/sh</code><code class="w"></code>
<code class="w">    </code><code class="calibre15">-</code><code class="w"> </code><code class="calibre15">-c</code><code class="w"></code>
<code class="w">    </code><code class="calibre15">-</code><code class="w"> </code><code class="calibre15">while true; do echo $(date) &gt;&gt; ~/tmp/curr-date.txt; sleep \</code><code class="w"></code>
<code class="w">      </code><code class="calibre15">5; done;</code><code class="w"></code>
<code class="w">    </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="calibre15">busybox:1.36.1</code><code class="w"></code>
<code class="w">    </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">failing-pod</code><code class="w"></code></pre></div>

<p class="author1">After creating the Pod, you check the status. It says <code class="calibre15">Running</code>; however, when making a request to the application, the endpoint reports an error. Next, you check the logs. The log output renders an error message that points to a nonexistent directory. Apparently, the directory that the application needs hasn’t been set up correctly:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl create -f failing-pod.yaml</strong>
pod/failing-pod created
<strong class="calibre38">$ kubectl get pods failing-pod</strong>
NAME          READY   STATUS    RESTARTS   AGE
failing-pod   1/1     Running   0          5s
<strong class="calibre38">$ kubectl logs failing-pod</strong>
/bin/sh: can't create /root/tmp/curr-date.txt: nonexistent directory
</pre>

<p class="author1">The <code class="calibre15">exec</code> command opens an interactive shell to further investigate the issue. In the following code, we’re using the Unix tools <code class="calibre15">mkdir</code>, <code class="calibre15">cd</code>, and <code class="calibre15">ls</code> inside of the running container to fix the problem. Obviously, the better mitigation strategy is to create the directory from the application or provide an instruction in the Dockerfile:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl exec failing-pod -it -- /bin/sh</strong>
# mkdir -p ~/tmp
# cd ~/tmp
# ls -l
total 4
-rw-r--r-- 1 root root 112 May 9 23:52 curr-date.txt
</pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Interacting with a Distroless Container" class="praise"><div class="dedication" id="id319">
<h2 class="calibre33">Interacting with a Distroless Container</h2>

<p class="author1">Some images run in containers are designed to be very minimal for security reasons. For example, the <a href="https://github.com/GoogleContainerTools/distroless" class="calibre10">Google distroless</a> images don’t have any Unix utility tools preinstalled. You can’t even open a shell to a container, as it doesn’t come with a shell.</p>
<div data-type="warning" epub:type="warning" class="calibre28"><h1 class="calibre68">Incorporating security best practices for container images</h1>
<p class="author1">Shipping container images with accessible shells and running with the <code class="calibre15">root</code> user is commonly discouraged as these aspects can be used as potential attack vectors. Check out the <a href="https://training.linuxfoundation.org/certification/certified-kubernetes-security-specialist/" class="calibre10">CKS certification</a> to learn more about security concerns in Kubernetes.</p>
</div>

<p class="author1">One of Google’s distroless images is <code class="calibre15">k8s.gcr.io/pause:3.1</code>, shown in <a data-type="xref" href="#pod_ephemeral_container" class="calibre10">Example 15-3</a>.</p>
<div id="pod_ephemeral_container" data-type="example" class="calibre45">
<h5 class="calibre46"><span class="keep-together">Example 15-3. </span>Running a distroless image</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre47"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="calibre15">v1</code><code class="w"></code>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Pod</code><code class="w"></code>
<code class="nt">metadata</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">minimal-pod</code><code class="w"></code>
<code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="calibre15">k8s.gcr.io/pause:3.1</code><code class="w"></code>
<code class="w">    </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">pause</code><code class="w"></code></pre></div>

<p class="author1">As you can see in the following <code class="calibre15">exec</code> command, the image doesn’t provide a shell:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl create -f minimal-pod.yaml</strong>
pod/minimal-pod created
<strong class="calibre38">$ kubectl get pods minimal-pod</strong>
NAME          READY   STATUS    RESTARTS   AGE
minimal-pod   1/1     Running   0          8s
<strong class="calibre38">$ kubectl exec minimal-pod -it -- /bin/sh</strong>
OCI runtime exec failed: exec failed: container_linux.go:349: starting \
container process caused "exec: \"/bin/sh\": stat /bin/sh: no such file \
or directory": unknown
command terminated with exit code 126
</pre>

<p class="author1">Kubernetes offers the concept of <a href="https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/" class="calibre10">ephemeral containers</a>. Those containers are meant to be disposable and have no resilience features like probes. You can deploy an ephemeral container for troubleshooting minimal containers that would usually not allow the use of the <code class="calibre15">exec</code> command.</p>

<p class="author1">Kubernetes 1.18 introduced a new <code class="calibre15">debug</code> command that can inject an ephemeral container to a running Pod for debugging purposes. The following command adds the ephemeral container running the image <code class="calibre15">busybox</code> to the Pod named <code class="calibre15">minimal-pod</code> and opens an interactive shell for it:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl alpha debug -it minimal-pod --image=busybox</strong>
Defaulting debug container name to debugger-jf98g.
If you don't see a command prompt, try pressing enter.
/ # pwd
/
/ # exit
Session ended, resume using 'kubectl alpha attach minimal-pod -c \
debugger-jf98g -i -t' command when the pod is running
</pre>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Inspecting Resource Metrics" class="praise"><div class="dedication" id="metrics_server">
<h1 class="calibre17">Inspecting Resource Metrics</h1>

<p class="author1">Deploying software to a Kubernetes cluster is only the start of operating an application long term. Developers need to understand their applications’ resource consumption patterns and behaviors, with the goal of providing a scalable and reliable service.</p>

<p class="author1">In the Kubernetes world, monitoring tools like <a href="https://prometheus.io/" class="calibre10">Prometheus</a> and <a href="https://www.datadoghq.com/" class="calibre10">Datadog</a> help with collecting, processing, and visualizing information over time. The exam does not expect you to be familiar with third-party monitoring, logging, tracing, and aggregation tools; however, it is helpful to have a basic understanding of the underlying Kubernetes infrastructure responsible for collecting usage metrics. The following are examples of typical metrics:</p>

<ul class="printings">
<li class="calibre13">
<p class="author1">Number of nodes in the cluster</p>
</li>
<li class="calibre13">
<p class="author1">Health status of nodes</p>
</li>
</ul>

<ul class="printings">
<li class="calibre13">
<p class="author1">Node performance metrics such as CPU, memory, disk space, network</p>
</li>
<li class="calibre13">
<p class="author1">Pod-level performance metrics such as CPU and memory consumption</p>
</li>
</ul>

<p class="author1">This responsibility falls to the <a href="https://github.com/kubernetes-sigs/metrics-server" class="calibre10">metrics server</a>, a cluster-wide aggregator of resource usage data. As shown in <a data-type="xref" href="#metrics-server" class="calibre10">Figure 15-1</a>, kubelets running on nodes collect metrics and send them to the metrics server.</p>

<figure class="calibre35"><div id="metrics-server" class="figure">
<img src="Images/ckd2_1501.png" alt="ckd2 1501" class="calibre97"/>
<h6 class="calibre32"><span class="keep-together">Figure 15-1. </span>Data collection for the metrics server</h6>
</div></figure>

<p class="author1">The metrics server stores data in memory and does not persist data over time. If you are looking for a solution that keeps historical data, then you need to look into commercial options. Refer to the documentation for more information on its <a href="https://github.com/kubernetes-sigs/metrics-server?tab=readme-ov-file#installation" class="calibre10">installation process</a>.</p>

<p class="author1">If you’re using Minikube as your practice environment, <a href="https://kubernetes.io/docs/tutorials/hello-minikube/#enable-addons" class="calibre10">enabling the metrics-server add-on</a> is straightforward using the following command:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ minikube addons enable metrics-server</strong>
The 'metrics-server' addon is enabled
</pre>

<p class="author1">You can now query for metrics of cluster nodes and Pods with the <code class="calibre15">top</code> command:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl top nodes</strong>
NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
minikube   283m         14%    1262Mi          32%
<strong class="calibre38">$ kubectl top pod frontend</strong>
NAME       CPU(cores)   MEMORY(bytes)
frontend   0m           2Mi
</pre>

<p class="author1">It takes a couple of minutes after the installation of the metrics server before it has gathered information about resource consumption. Rerun the <code class="calibre15">kubectl top</code> command if you receive an error message.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Summary" class="praise"><div class="dedication" id="id321">
<h1 class="calibre17">Summary</h1>

<p class="author1">We discussed strategies for approaching failed or misbehaving Pods. The main goal is to diagnose the root cause of a failure and then fix it by taking the right action. Troubleshooting Pods doesn’t have to be hard. With the right <code class="calibre15">kubectl</code> commands in your tool belt, you can rule out root causes one by one to get a clearer picture.</p>

<p class="author1">The Kubernetes ecosystem provides a lot of options for collecting and processing metrics of your cluster over time. Among those options are commercial monitoring tools like Prometheus and Datadog. Many of those tools use the metrics server as the source of truth for those metrics. We also briefly touched on the installation process and the <code class="calibre15">kubectl top</code> command for retrieving metrics from the command line.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Exam Essentials" class="praise"><div class="dedication" id="id322">
<h1 class="calibre17">Exam Essentials</h1>
<dl class="calibre18">
<dt class="calibre19">Know how to debug Pod objects</dt>
<dd class="calibre20">
<p class="calibre21">In this chapter, we mainly focused on troubleshooting problematic Pods and containers. Practice all relevant <code class="calibre15">kubectl</code> commands that can help with diagnosing issues. Refer to the <a href="https://kubernetes.io/docs/tasks/debug/debug-application/" class="calibre10">Kubernetes documentation</a> to learn more about debugging other Kubernetes resource types.</p>
</dd>
<dt class="calibre19">Learn how to retrieve and interpret resource metrics</dt>
<dd class="calibre20">
<p class="calibre21">Monitoring a Kubernetes cluster is an important aspect of successfully operating in a real-world environment. You should read up on commercial monitoring products and which data the metrics server can collect. You can assume that the exam environment provides you with an installation of the metrics server. Learn how to use the <code class="calibre15">kubectl top</code> command to render Pod and node resource metrics and how to interpret them.</p>
</dd>
</dl>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Sample Exercises" class="praise"><div class="dedication" id="id323">
<h1 class="calibre17">Sample Exercises</h1>

<p class="author1">Solutions to these exercises are available in <a href="app01_split_011.xhtml#appendix_a_troubleshooting_pods_containers" class="calibre10">Appendix A</a>.</p>
<ol class="calibre55">
<li class="calibre56">
<p class="author1">In this exercise, you will practice your troubleshooting skills by inspecting a misconfigured Pod. Navigate to the directory <em class="calibre3">app-a/ch15/troubleshooting</em> of the checked-out GitHub repository <a href="https://github.com/bmuschko/ckad-study-guide" class="calibre10"><em class="calibre3">bmuschko/ckad-study-guide</em></a>.</p>

<p class="author1">Create a new Pod from the YAML manifest in the file <em class="calibre3">pod.yaml</em>. Check the Pod’s status. Do you see any issue?</p>

<p class="author1">Render the logs of the running container and identify an issue. Shell into the container. Can you verify the issue based on the rendered log message?</p>

<p class="author1">Suggest solutions that can fix the root cause of the issue.</p>
</li>
<li class="calibre56">
<p class="author1">You will inspect the metrics collected by the metrics server. Navigate to the directory <em class="calibre3">app-a/ch15/stress-test</em> of the checked-out GitHub repository <a href="https://github.com/bmuschko/ckad-study-guide" class="calibre10"><em class="calibre3">bmuschko/ckad-study-guide</em></a>. The current directory contains the YAML manifests for three Pods, <em class="calibre3">stress-1-pod.yaml</em>, <em class="calibre3">stress-2-pod.yaml</em>, and <em class="calibre3">stress-3-pod.yaml</em>. Inspect those manifest files.</p>

<p class="author1">Create the namespace <code class="calibre15">stress-test</code> and the Pods inside of the namespace.</p>

<p class="author1">Use the data available through the metrics server to identify which of the Pods consumes the most memory.</p>

<p class="author1"><em class="calibre3">Prerequisite:</em> You will need to install the metrics server if you want to be able to inspect actual resource metrics. You can find <a href="https://github.com/kubernetes-sigs/metrics-server#installation" class="calibre10">installation instructions</a> on the project’s GitHub page.</p>
</li>

</ol>
</div></section>
</div></section></div></body>
</html>