<html><head></head><body><section data-pdf-bookmark="Chapter 8. Resilience" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch_resilience">&#13;
<h1><span class="label">Chapter 8. </span>Resilience</h1>&#13;
&#13;
&#13;
<p>This chapter focuses on <em>application resilience</em>, which <a data-primary="application resilience" data-see="resilience" data-type="indexterm" id="idm46291180592792"/>is the ability to survive situations that might otherwise lead to failure. Unlike other chapters that focused on services external to the Node.js process, this one mostly looks within the process.</p>&#13;
&#13;
<p>Applications should be <a data-primary="resilience" data-type="indexterm" id="idm46291180569176"/>resilient to certain types of failure. For example, there are many options available to a downstream service like <em>web-api</em> when it is unable to communicate with an upstream service like <em>recipe-api</em>. Perhaps it should retry the outgoing request, or maybe it should respond to the incoming request with an error. But in any case, crashing isn’t the best option. Similarly, if a connection to a stateful database is lost, the application should probably try to reconnect to it, while replying to incoming requests with an error. On the other hand, if a connection to a caching service is dropped, then the best action might be to reply to the client as usual, albeit in a slower, “degraded” manner.</p>&#13;
&#13;
<p>In many cases it is necessary for an application to crash. If a failure occurs that an engineer doesn’t anticipate—often global to the process and not associated with a single request—then the application can potentially enter a compromised state. In these situations it’s best to log the stack trace, leaving evidence behind for an engineer, and then exit. Due to the ephemeral nature of applications, it’s important that they remain stateless—doing so allows future instances to pick up where the last one left off.</p>&#13;
&#13;
<p>Speaking of crashing, there are a number of ways that an application can exit, intentionally or otherwise. It’s worth looking at these before diving into the ways the application can be kept alive and healthy.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Death of a Node.js Process" data-type="sect1"><div class="sect1" id="ch_resilience_sec_death">&#13;
<h1>The Death of a Node.js Process</h1>&#13;
&#13;
<p>There are many ways that a Node.js <a data-primary="process termination" data-type="indexterm" id="proc_term"/><a data-primary="resilience" data-secondary="process termination" data-type="indexterm" id="proc_term1"/>process can be terminated, and unfortunately, Node.js is sometimes helpless to prevent some of them. For example, a native module running compiled C++ code could cause a segfault, the process could receive the <em>SIGKILL</em> signal, or someone could trip over the server’s power cord. It’s important to build systems that are resilient to such problems. However, as for the Node.js process itself, it can’t do much about its own termination in such situations.</p>&#13;
&#13;
<p>The <code>process</code> global is an <code>EventEmitter</code> instance, and <a data-primary="exit event" data-type="indexterm" id="idm46291180558616"/><a data-primary="events" data-secondary="exit event" data-type="indexterm" id="idm46291180557880"/>when the process exits it will usually emit an <code>exit</code> event. This event can be listened for to perform final cleanup and logging work. Only synchronous work can be executed when this event is triggered. The event won’t always be called when a process terminates, like in a catastrophic event such as running out of memory.</p>&#13;
&#13;
<p>When it comes to intentionally terminating a process from within (or preventing termination), there are a few options available. <a data-type="xref" href="#table_process_exits">Table 8-1</a> contains a list of some of these situations.</p>&#13;
<table id="table_process_exits">&#13;
<caption><span class="label">Table 8-1. </span>Node.js termination from within</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Operation</th>&#13;
<th>Example</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Manual process exit</p></td>&#13;
<td><p><code>process.exit(1)</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Uncaught exception</p></td>&#13;
<td><p><code>throw new Error()</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Unhandled promise rejection<sup><a data-type="noteref" href="ch08.html#idm46291180529912" id="idm46291180529912-marker">a</a></sup></p></td>&#13;
<td><p><code>Promise.reject()</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Ignored error event</p></td>&#13;
<td><p><code>EventEmitter#emit('error')</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Unhandled signals</p></td>&#13;
<td><p><code>$ kill &lt;PROCESS_ID&gt;</code> without a signal handler</p></td>&#13;
</tr>&#13;
</tbody>&#13;
<tbody><tr class="footnotes"><td colspan="2"><p data-type="footnote" id="idm46291180529912"><sup><a href="ch08.html#idm46291180529912-marker">a</a></sup> As of Node.js v14.8, the <code>--unhandled-rejections=strict</code> flag must be provided for this to crash a process. Future versions of Node.js will crash by default.</p></td></tr></tbody></table>&#13;
&#13;
<p>Most of the entries in this list deal directly with failure scenarios, such as uncaught exceptions, unhandled rejections, and error events. Signals received from external processes are another interesting situation. However, only one of these has to do with cleanly and intentionally exiting the process.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Process Exit" data-type="sect2"><div class="sect2" id="idm46291180523304">&#13;
<h2>Process Exit</h2>&#13;
&#13;
<p>The <code>process.exit(code)</code> method <a data-primary="process.exit() function" data-type="indexterm" id="idm46291180521192"/><a data-primary="functions" data-secondary="process.exit()" data-type="indexterm" id="idm46291180520456"/>is the most basic mechanism for terminating a process and is useful in many scenarios where an error isn’t necessarily involved. For example, when building a CLI utility, the <code>process.exit()</code> may be relied on to terminate a process once it has completed its given task. It’s almost like an overpowered <code>return</code> statement.</p>&#13;
&#13;
<p>The <code>code</code> argument<sup><a data-type="noteref" href="ch08.html#idm46291180517368" id="idm46291180517368-marker">1</a></sup> is a numeric <em>exit status code</em> within the range of 0 and 255. By convention, a 0 means that the application terminated in a healthy manner, and any nonzero number means that an error occurred. There isn’t necessarily a standard for defining what the different nonzero exit values represent (as opposed to HTTP, which has well-defined numeric status codes). Instead, it’s usually up to the application to document what the different exit status codes mean. For example, if an application requires a set of environment variables that happen to be missing, it might exit with a 1, and if expects to find a configuration file that is missing, it might exit with a 2.</p>&#13;
&#13;
<p>No messages are printed to stdout or <em>stderr</em> by default when <code>process.exit()</code> is called. Instead, the process just ends. For that reason, you may want to emit a final message before the program ends so that someone running the application has an idea of what went wrong. As an example of this, run the following code:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>node -e <code class="s2">"process.exit(42)"</code> <code class="p">;</code> <code class="nb">echo</code> <code class="nv">$?</code></pre>&#13;
&#13;
<p>In this case, you should only see the number 42 printed. The number is printed for you by your shell, but the Node.js process doesn’t print anything. But what went wrong? A quick look at the logs won’t <a data-primary="process.abort() function" data-type="indexterm" id="idm46291180509944"/><a data-primary="functions" data-secondary="process.abort()" data-type="indexterm" id="idm46291180509448"/>provide any help.<sup><a data-type="noteref" href="ch08.html#idm46291180506840" id="idm46291180506840-marker">2</a></sup></p>&#13;
&#13;
<p>Here is an example of a more verbose approach that an application might employ if it needs to exit at startup when misconfigured:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kd">function</code> <code class="nx">checkConfig</code><code class="p">(</code><code class="nx">config</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="k">if</code> <code class="p">(</code><code class="o">!</code><code class="nx">config</code><code class="p">.</code><code class="nx">host</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="s2">"Configuration is missing 'host' parameter!"</code><code class="p">);</code>&#13;
    <code class="nx">process</code><code class="p">.</code><code class="nx">exit</code><code class="p">(</code><code class="mi">1</code><code class="p">);</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>In this case, the application prints a message to <em>stderr</em>, which makes the life of whoever is running the process easier. The process then exits with a status code of 1, which is useful for conveying to a machine that the process has failed. When <span class="keep-together"><code>process.exit()</code></span> is encountered, none of the code that follows it will run. It effectively terminates the current stack much like a <code>return</code> statement would (in fact, your IDE may highlight code following this line as dead-code).</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>The <code>process.exit()</code> method is very powerful. While it does have its purpose within Node.js application code, an npm package should almost never make use of it. Consumers of libraries expect to be able to handle errors in their own way.</p>&#13;
</div>&#13;
&#13;
<p>Status codes are used in a <a data-primary="status codes, HTTP" data-type="indexterm" id="idm46291180443496"/>lot of situations. For example, when unit tests run as part of continuous integration, a nonzero exit status informs the test runner (such as Travis CI) that the test suite has failed. Of course, it would be tedious to have to manually go through and add <code>process.exit(1)</code> calls all over a test suite. Thankfully, test suite runners handle that for you. In fact, any time an application throws an error that doesn’t get caught, it will default to producing an exit status of 1. The following <a data-primary="process termination" data-startref="proc_term" data-type="indexterm" id="idm46291180441768"/><a data-primary="resilience" data-secondary="process termination" data-startref="proc_term1" data-type="indexterm" id="idm46291180440792"/>example shows this happening:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>node -e <code class="s2">"throw new Error()"</code> <code class="p">;</code> <code class="nb">echo</code> <code class="nv">$?</code></pre>&#13;
&#13;
<p>In this case, you should see a stack trace printed, followed by the number 1 on a line of its own. Thrown errors warrant a bit more discussion.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exceptions, Rejections, and Emitted Errors" data-type="sect2"><div class="sect2" id="idm46291180522712">&#13;
<h2>Exceptions, Rejections, and Emitted Errors</h2>&#13;
&#13;
<p>Using <code>process.exit()</code> is nice for <a data-primary="applications" data-secondary="exceptions" data-type="indexterm" id="appexcep"/><a data-primary="applications" data-secondary="rejections" data-type="indexterm" id="appreject"/><a data-primary="applications" data-secondary="emitted errors" data-type="indexterm" id="appemit"/><a data-primary="exceptions" data-type="indexterm" id="excep"/><a data-primary="rejections" data-type="indexterm" id="reject"/><a data-primary="errors" data-type="indexterm" id="err"/>early startup errors, but sometimes you need something more contextual. For example, when a runtime error happens in the middle of an application’s lifetime, like during a request handler, something bad happening probably isn’t a foreseeable error like missing configuration. Instead, it’s likely due to some untested logic branch or an otherwise weird edge case. When this happens, the application owner needs to know where the problem happened. That is where the <code>Error</code> object comes in.</p>&#13;
&#13;
<p>Before discussing errors too much, it’s useful to define a few terms—especially since they’re often conflated:</p>&#13;
<dl>&#13;
<dt>Error</dt>&#13;
<dd>&#13;
<p><code>Error</code> is a global <a data-primary="Error object" data-type="indexterm" id="idm46291180398632"/><a data-primary="objects" data-secondary="Error" data-type="indexterm" id="idm46291180398008"/>object available in all JavaScript environments. When an <code>Error</code> is instantiated it has some metadata attached to it, such as the name of the error, a message, and a stack trace string. This metadata is provided as properties on the resulting object. Merely instantiating an <code>Error</code> isn’t that big of a deal (though there’s some performance impact when it comes to generating the stack trace) and doesn’t yet affect control flow—that happens later when it is thrown. It’s common to “subclass” an error by extending from it and creating more specific errors.</p>&#13;
</dd>&#13;
<dt>Throw</dt>&#13;
<dd>&#13;
<p>The <code>throw</code> keyword creates <a data-primary="throw keyword" data-type="indexterm" id="idm46291180393848"/>and throws an exception. When one of these is encountered, the current function will stop being executed. The exception is then “bubbled up” through the functions that called your function. When this happens, JavaScript looks for any try/catch statements that have wrapped any of the shallower function calls. If one is encountered, the <code>catch</code> branch is called. If none are encountered, the exception is then considered uncaught.</p>&#13;
</dd>&#13;
<dt>Exception</dt>&#13;
<dd>&#13;
<p>An <code>Exception</code> is something that has been thrown. Technically you can throw anything, even a string or <code>undefined</code>. That said it’s considered bad form to throw anything that isn’t an instance of, or extended from, the <code>Error</code> class. This also applies when it comes to rejecting promises, providing error arguments to callbacks, or emitting errors.</p>&#13;
</dd>&#13;
<dt>Rejection</dt>&#13;
<dd>&#13;
<p>A Rejection is what happens when a promise fails or when an exception is thrown within an <code>async</code> function. The concept is similar in nature to an exception, but it does need to be handled in slightly different ways, so it deserves a name of its own.</p>&#13;
</dd>&#13;
<dt>Error swallowing</dt>&#13;
<dd>&#13;
<p>Capturing an error and completely disregarding the outcome, including not logging the error to the console, is considered “swallowing an error.”</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>When an exception is thrown or a promise is rejected, it needs to be handled in some manner. When completely ignored it leads to an application crash—for example, an uncaught error will crash a Node.js process. Swallowing errors is universally a bad practice and will come back to bite you. However, checking if a specific anticipated error is thrown before swallowing it isn’t necessarily the end of the world.</p>&#13;
&#13;
<p>Consider the following example of a swallowed error:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">lib</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'some-library'</code><code class="p">);</code>&#13;
<code class="k">try</code> <code class="p">{</code>&#13;
  <code class="nx">lib</code><code class="p">.</code><code class="nx">start</code><code class="p">();</code>&#13;
<code class="p">}</code> <code class="k">catch</code><code class="p">(</code><code class="nx">e</code><code class="p">)</code> <code class="p">{}</code> <code class="c1">// Sometimes lib throws even though it works</code>&#13;
<code class="nx">lib</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="s1">'message'</code><code class="p">);</code></pre>&#13;
&#13;
<p>In this case, the <em>some-library</em> author has decided to throw an innocuous error, one that doesn’t actually affect the operation of the library. Perhaps it throws an error when the first database host it tries to connect to cannot be reached, even though the second host that it can connect to is reached. In this case, the catch branch is swallowing that connection fallback error. Unfortunately, it’s also throwing <a data-primary="lib.start() function" data-type="indexterm" id="idm46291180344696"/><a data-primary="functions" data-secondary="lib.start()" data-type="indexterm" id="idm46291180344024"/>any other error that the <code>lib.start()</code> method might be throwing.</p>&#13;
&#13;
<p>For example, you might find that when the <em>some-library</em> gets upgraded, it begins throwing another error, one that is a big deal. This usually leads to hours of debugging before finally finding the source of the underlying issue. For this reason, swallowing all errors is bad.</p>&#13;
&#13;
<p>To swallow only a specific error, you might instead change the code to look like this:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="k">catch</code><code class="p">(</code><code class="nx">e</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="k">if</code> <code class="p">(</code><code class="nx">e</code> <code class="k">instanceof</code> <code class="nx">lib</code><code class="p">.</code><code class="nx">Errors</code><code class="p">.</code><code class="nx">ConnectionFallback</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="c1">// swallow error</code>&#13;
  <code class="p">}</code> <code class="k">else</code> <code class="p">{</code>&#13;
    <code class="k">throw</code> <code class="nx">e</code><code class="p">;</code> <code class="c1">// re-throw</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>In this case, the exception is only swallowed if it is a specific error instance, otherwise it is rethrown again. This particular example assumes that a library author was thoughtful enough to export subclassed error instances. Unfortunately this often isn’t the case (not to mention <code>instanceof</code> checks can be tricky with a complex npm package hierarchy). Sometimes a library author might subclass errors but not export them. In those cases, you can check the <code>.name</code> field, for example by using <code>e.name === 'ConnectionFallback'</code>.</p>&#13;
&#13;
<p>Another convention—popularized by Node.js itself—for differentiating errors works by providing a <code>.code</code> property, <a data-primary=".code property" data-primary-sortas="code property" data-type="indexterm" id="idm46291180283816"/>which is a string named in a documented and consistent manner and that shouldn’t change between releases. An example of this is the <em>ERR_INVALID_URI</em> error code, <a data-primary="ERR_INVALID_URI error code" data-primary-sortas="ERR_INVALID_URI error code" data-type="indexterm" id="idm46291180282152"/>and even though the human-readable message of the string may change, the error code should not. This pattern unfortunately isn’t that popular yet amongst package authors either, though when a package surfaces a Node.js-produced error, the <code>.code</code> property should be present.</p>&#13;
&#13;
<p>The most common approach for targeting specific errors is to parse the actual <span class="keep-together"><code>.message</code></span> field. When doing this, your application will need to inspect text meant for human consumption—for example, using <code>e.message.startsWith('Had to fallback')</code>. This is unfortunately quite error prone! Error messages often have typos, and well-meaning contributors make PRs to fix them all the time. Such updates are usually released as a Semver patch release and may then break an application that inspects the error message string.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Unfortunately, there’s currently no perfect solution to the error-differentiation problem in the Node.js ecosystem. As a package author, always be intentional with the errors you provide and try to export error subclasses or provide a <code>.code</code> property. As a module consumer, offer pull requests for libraries that provide multiple errors in the same operation without a mechanism to programmatically differentiate them.</p>&#13;
</div>&#13;
&#13;
<p>When the error is thrown and <a data-primary="errors" data-secondary="uncaught" data-type="indexterm" id="idm46291180276072"/>remains uncaught, the stack trace for the error is printed to the console and the process exits with a status of 1. Here’s what an uncaught exception looks like:</p>&#13;
&#13;
<pre data-type="programlisting">/tmp/error.js:1&#13;
throw new Error('oh no');&#13;
^&#13;
Error: oh no&#13;
    at Object.&lt;anonymous&gt; (/tmp/foo.js:1:7)&#13;
    ... TRUNCATED ...&#13;
    at internal/main/run_main_module.js:17:47</pre>&#13;
&#13;
<p>This output has been truncated, but the stack trace suggests that the error was thrown at line 1, column 7 of a file located at <em>/tmp/error.js</em>.</p>&#13;
&#13;
<p>There is a way to globally intercept any uncaught exceptions and run a function. The global <code>process</code> object is <a data-primary="process object" data-type="indexterm" id="idm46291180271768"/><a data-primary="objects" data-secondary="process" data-type="indexterm" id="idm46291180271032"/><a data-primary="EventEmitter class" data-type="indexterm" id="idm46291180270088"/>an instance of the <code>EventEmitter</code> class. One of the many events it can emit is the <code>uncaughtException</code> event. If this event <a data-primary="uncaughtException event" data-type="indexterm" id="idm46291180268392"/><a data-primary="events" data-secondary="uncaughtException" data-type="indexterm" id="idm46291180267656"/>is listened for, the callback function will be invoked and the process itself will no longer automatically exit. This is useful for logging information about a failure before exiting a process, but by no means should you use it to swallow errors globally! Errors should always &#13;
<span class="keep-together">be dealt</span> with contextually by wrapping appropriate function calls in try/catch &#13;
<span class="keep-together">statements.</span></p>&#13;
&#13;
<p>The following is an example of how the handler might be used to log a final distress message:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">logger</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'./lib/logger.js'</code><code class="p">);</code>&#13;
<code class="nx">process</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'uncaughtException'</code><code class="p">,</code> <code class="p">(</code><code class="nx">error</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="nx">logger</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="s2">"An uncaught exception has occured"</code><code class="p">,</code> <code class="nx">error</code><code class="p">,</code> <code class="p">()</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
    <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="nx">error</code><code class="p">);</code>&#13;
    <code class="nx">process</code><code class="p">.</code><code class="nx">exit</code><code class="p">(</code><code class="mi">1</code><code class="p">);</code>&#13;
  <code class="p">});</code>&#13;
<code class="p">});</code></pre>&#13;
&#13;
<p>In this case, the <code>logger</code> module <a data-primary="logger module" data-type="indexterm" id="idm46291180193512"/><a data-primary="modules" data-secondary="logger" data-type="indexterm" id="idm46291180192872"/>represents a library that sends logs over the network. Here, the exception is caught; the log message is transmitted; and once it has been sent, the error is printed to the console and the process exits. Presumably, calling <code>process.exit()</code> <a data-primary="process.exit() function" data-type="indexterm" id="idm46291180191176"/><a data-primary="functions" data-secondary="process.exit()" data-type="indexterm" id="idm46291180190440"/><a data-primary="functions" data-secondary="logger.send()" data-type="indexterm" id="idm46291180189496"/><a data-primary="logger.send() function" data-type="indexterm" id="idm46291180188552"/>immediately after calling <code>logger.send()</code> might result in the process being killed before the message can be transmitted, which is why the callback needs to be awaited for. While this is one way to help ensure asynchronous messages are sent before terminating a process, it is unfortunate that the application may still be allowed to process other tasks, since whatever caused the first uncaught exception might be repeated.</p>&#13;
&#13;
<p>Promise rejections are <a data-primary="promise rejections" data-type="indexterm" id="idm46291180186456"/><a data-primary="rejections" data-secondary="promise rejections" data-type="indexterm" id="idm46291180185720"/><a data-primary="Promise.reject() function" data-type="indexterm" id="idm46291180184776"/><a data-primary="functions" data-secondary="Promise.reject()" data-type="indexterm" id="idm46291180184136"/>similar to exceptions. Promise rejections can happen in one of two ways. The first way is by calling <code>Promise.reject()</code> directly, or by otherwise throwing an error within a promise chain (like in a <code>.then()</code> function). The other way <a data-primary="asynchronous functions" data-secondary="throw statements" data-type="indexterm" id="idm46291180182152"/><a data-primary="functions" data-secondary="asynchronous" data-tertiary="throw statements" data-type="indexterm" id="idm46291180181176"/><a data-primary="throw statements, async function and" data-type="indexterm" id="idm46291180179960"/>to cause a promise rejection is by throwing while inside of an <code>async</code> function (within an <code>async</code> function, the JavaScript language changes the semantics of <code>throw</code> statements). The following two examples both result in equivalent promise rejections (albeit with slightly different stack traces):</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nb">Promise</code><code class="p">.</code><code class="nx">reject</code><code class="p">(</code><code class="k">new</code> <code class="nb">Error</code><code class="p">(</code><code class="s1">'oh no'</code><code class="p">));</code>&#13;
&#13;
<code class="p">(</code><code class="nx">async</code> <code class="p">()</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="k">throw</code> <code class="k">new</code> <code class="nb">Error</code><code class="p">(</code><code class="s1">'oh no'</code><code class="p">);</code>&#13;
<code class="p">})();</code></pre>&#13;
&#13;
<p>A slightly different error message <a data-primary="errors" data-secondary="promise rejections" data-type="indexterm" id="idm46291180167160"/><a data-primary="promise rejections" data-secondary="error messages" data-type="indexterm" id="idm46291180166424"/>is printed when a promise rejection happens. As of Node.js v14.8, a warning is displayed with it:</p>&#13;
&#13;
<pre data-type="programlisting">(node:52298) UnhandledPromiseRejectionWarning: Error: oh no&#13;
    at Object.&lt;anonymous&gt; (/tmp/reject.js:1:16)&#13;
    ... TRUNCATED ...&#13;
    at internal/main/run_main_module.js:17:47&#13;
(node:52298) UnhandledPromiseRejectionWarning: Unhandled promise&#13;
  rejection. This error originated either by throwing inside of an&#13;
  async function without a catch block, or by rejecting a promise&#13;
  which was not handled with .catch().</pre>&#13;
&#13;
<p>Unlike uncaught exceptions, unhandled promise rejections do not cause the process to crash in Node.js v14. In Node.js v15 and above, this will cause the process to exit. This behavior can be enabled in v14 by running the Node.js binary with the &#13;
<span class="keep-together"><code>--unhandled-rejections=strict</code></span> flag.</p>&#13;
&#13;
<p>Similar to uncaught exceptions, unhandled rejections <a data-primary="rejections" data-secondary="unhandled" data-type="indexterm" id="idm46291180113256"/>can also be listened for using the <code>process</code> event <a data-primary="process event" data-type="indexterm" id="idm46291180111768"/><a data-primary="events" data-secondary="process" data-type="indexterm" id="idm46291180111032"/>emitter. Here’s an example of how it’s done:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">process</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'unhandledRejection'</code><code class="p">,</code> <code class="p">(</code><code class="nx">reason</code><code class="p">,</code> <code class="nx">promise</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{});</code></pre>&#13;
&#13;
<p>Much like with the <code>uncaughtException</code> event, it’s important to not allow the process to continue running since it is likely in an invalid state. Consider running your Node.js processes with the flag enabled today to help future-proof your application. If you do encounter these uncaught rejection warnings while running an application in development, you should definitely track them down and fix them to prevent production bugs.</p>&#13;
&#13;
<p>Node.js and the npm package ecosystem are both going through a transitional phase. Node.js was built with the callback pattern in mind for asynchronous activities, having the first argument of the callback be an error. It’s now adapting the promise/async function pattern. Applications you build today will have to deal with both patterns.</p>&#13;
&#13;
<p>The <code>EventEmitter</code> class, <a data-primary="EventEmitter class" data-type="indexterm" id="idm46291180071384"/>available at <code>require('events').EventEmitter</code>, is extended by and used by many other classes, both those provided by core Node.js modules, as well as packages available on npm. Event emitters are so popular and follow a different-enough pattern than the other errors covered in this section that they’re worth their own consideration.</p>&#13;
&#13;
<p>Instances of <code>EventEmitter</code> that emit an <code>error</code> event without having a listener will cause <a data-primary="errors" data-secondary="EventEmitter class" data-type="indexterm" id="idm46291180068408"/>the process to terminate. When this happens, the base <code>EventEmitter</code> code either <a data-primary="events" data-secondary="argument" data-type="indexterm" id="idm46291180066856"/>throws the event argument or, if it’s missing, it will throw an <code>Error</code> with a code of <em>ERR_UNHANDLED_ERROR</em>.</p>&#13;
&#13;
<p>When an <code>EventEmitter</code> instance throws such an error, the following message will be displayed in the console before the process exits:</p>&#13;
&#13;
<pre data-type="programlisting">events.js:306&#13;
    throw err; // Unhandled 'error' event&#13;
    ^&#13;
Error [ERR_UNHANDLED_ERROR]: Unhandled error. (undefined)&#13;
    at EventEmitter.emit (events.js:304:17)&#13;
    at Object.&lt;anonymous&gt; (/tmp/foo.js:1:40)&#13;
    ... TRUNCATED ...&#13;
    at internal/main/run_main_module.js:17:47 {&#13;
  code: 'ERR_UNHANDLED_ERROR',&#13;
  context: undefined&#13;
}</pre>&#13;
&#13;
<p>The appropriate way to handle these errors is to listen for <code>error</code> events, similar to how you would catch errors in other situations.<sup><a data-type="noteref" href="ch08.html#idm46291180061896" id="idm46291180061896-marker">3</a></sup> Just like with thrown exceptions and promise rejections, the argument used when emitting an error, such as with &#13;
<span class="keep-together"><code>EventEmitter#emit('error', arg)</code></span>, should be an instance of the <code>Error</code> class. This is again so that the caller can get contextual information about the <a data-primary="applications" data-secondary="exceptions" data-startref="appexcep" data-type="indexterm" id="idm46291180058568"/><a data-primary="applications" data-secondary="rejections" data-startref="appreject" data-type="indexterm" id="idm46291180057352"/><a data-primary="applications" data-secondary="emitted errors" data-startref="appemit" data-type="indexterm" id="idm46291180056136"/><a data-primary="exceptions" data-startref="excep" data-type="indexterm" id="idm46291180054920"/><a data-primary="rejections" data-startref="reject" data-type="indexterm" id="idm46291180053976"/><a data-primary="errors" data-startref="err" data-type="indexterm" id="idm46291180053032"/>failure.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Signals" data-type="sect2"><div class="sect2" id="idm46291180419288">&#13;
<h2>Signals</h2>&#13;
&#13;
<p><em>Signals</em> are a mechanism provided <a data-primary="signals" data-type="indexterm" id="sign"/><a data-primary="SIGINT" data-type="indexterm" id="SIG"/><a data-primary="SIGKILL" data-type="indexterm" id="SIG2"/>by the operating system to allow programs to receive short “messages” from the kernel or from other programs. And by short, I mean really short. A signal is just a small number that is being sent, and there are only a few dozen of them available. While signals are represented as a number under the hood, they’re usually referred to by a string name. For example, <em>SIGINT</em> and <em>SIGKILL</em> are two of the more commonly encountered signals.</p>&#13;
&#13;
<p>Signals can be used for multiple reasons, though they are most commonly used to tell a process that it needs to terminate. Different platforms support different sets of signals, and the numeric values can even change between OS, which is why the string version of a signal is used. Run the <code><strong>kill -l</strong></code> command to get a <a data-primary="kill command" data-type="indexterm" id="idm46291180026424"/><a data-primary="commands" data-secondary="kill -l" data-type="indexterm" id="idm46291180025720"/>list of the signals recognized by your current machine.</p>&#13;
&#13;
<p><a data-type="xref" href="#table_signals">Table 8-2</a> contains a list of the more universal signals and what they’re used for.</p>&#13;
<table id="table_signals">&#13;
<caption><span class="label">Table 8-2. </span>Common signals</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Name</th>&#13;
<th>Number</th>&#13;
<th>Handleable</th>&#13;
<th>Node.js default</th>&#13;
<th>Signal purpose</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p><code>SIGHUP</code></p></td>&#13;
<td><p>1</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Terminate</p></td>&#13;
<td><p>Parent terminal has been closed</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>SIGINT</code></p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Terminate</p></td>&#13;
<td><p>Terminal trying to interrupt, à la Ctrl + C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>SIGQUIT</code></p></td>&#13;
<td><p>3</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Terminate</p></td>&#13;
<td><p>Terminal trying to quit, à la Ctrl + D</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>SIGKILL</code></p></td>&#13;
<td><p>9</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>Terminate</p></td>&#13;
<td><p>Process is being forcefully killed</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>SIGUSR1</code></p></td>&#13;
<td><p>10</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Start Debugger</p></td>&#13;
<td><p>User-defined signal 1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>SIGUSR2</code></p></td>&#13;
<td><p>12</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Terminate</p></td>&#13;
<td><p>User-defined signal 2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>SIGTERM</code></p></td>&#13;
<td><p>12</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Terminate</p></td>&#13;
<td><p>Represents a graceful termination</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>SIGSTOP</code></p></td>&#13;
<td><p>19</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>Terminate</p></td>&#13;
<td><p>Process is being forcefully stopped</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>When a program receives a signal, it usually gets a choice on how to handle it. The two signals <em>SIGKILL</em> and <em>SIGSTOP</em> cannot be handled at all, as conveyed by the <em>Handleable</em> column. Any program that receives either of those two signals will be terminated, regardless of what language it’s written in. Node.js also comes with some default actions for the remaining signals, as listed in the <em>Node.js default</em> column. Most of them cause the process to terminate, however the <em>SIGUSR1</em> signal tells Node.js to start the debugger.</p>&#13;
&#13;
<p>Node.js makes it straightforward to handle these signals when they’re received. Just like how you handle uncaught exceptions and unhandled rejections, the <code>process</code> emitter also emits events named after the signal being received. To prove this, create a new file named <em>/tmp/signals.js</em> and add the content in <a data-type="xref" href="#ex_signal_handlers">Example 8-1</a> to the file.</p>&#13;
<div data-type="example" id="ex_signal_handlers">&#13;
<h5><span class="label">Example 8-1. </span><em>/tmp/signals.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node</code>&#13;
<code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`Process ID: </code><code class="si">${</code><code class="nx">process</code><code class="p">.</code><code class="nx">pid</code><code class="si">}</code><code class="sb">`</code><code class="p">);</code>&#13;
<code class="nx">process</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'SIGHUP'</code><code class="p">,</code> <code class="p">()</code> <code class="o">=&gt;</code> <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Received: SIGHUP'</code><code class="p">));</code>&#13;
<code class="nx">process</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'SIGINT'</code><code class="p">,</code> <code class="p">()</code> <code class="o">=&gt;</code> <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Received: SIGINT'</code><code class="p">));</code>&#13;
<code class="nx">setTimeout</code><code class="p">(()</code> <code class="o">=&gt;</code> <code class="p">{},</code> <code class="mi">5</code> <code class="o">*</code> <code class="mi">60</code> <code class="o">*</code> <code class="mi">1000</code><code class="p">);</code> <code class="c1">// keep process alive</code></pre></div>&#13;
&#13;
<p>Execute the file in a terminal window. It prints a message with the process ID and then sits there for up to five minutes before terminating. Once you start the program, try to terminate the process by using the Ctrl + C keyboard shortcut. Try as you might, you won’t be able to terminate the process! When you use the Ctrl + C shortcut, your terminal sends the <em>SIGINT</em> signal to the process. The default action of exiting the process has now been replaced by your new signal handler, one that merely prints the name of the signal it has received. Take note of the process ID printed on your screen and switch to a new terminal window.</p>&#13;
&#13;
<p>In this new terminal window, you’re going to execute a command that will send a signal to your process. Run the following <a data-primary="signals" data-secondary="SIGHUP" data-type="indexterm" id="idm46291179924984"/><a data-primary="SIGHUP" data-type="indexterm" id="idm46291179924248"/>command to send the <em>SIGHUP</em> signal to your process:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code><code class="nb">kill</code> -s SIGHUP &lt;PROCESS_ID&gt;</pre>&#13;
&#13;
<p>The <code>kill</code> command <a data-primary="kill command" data-type="indexterm" id="idm46291179919704"/><a data-primary="commands" data-secondary="kill" data-type="indexterm" id="idm46291179919064"/>is a convenient utility that sends signals to processes. Since signals were originally used to kill processes, the name sort of stuck around and the <code>kill</code> command is what we use today.</p>&#13;
&#13;
<p>At it turns out, Node.js processes are also capable of sending signals to other processes. And, as an homage to the convention of referring to signals as <em>kill</em>, the method used to send signals is <a data-primary="process.kill() function" data-type="indexterm" id="idm46291179915544"/><a data-primary="functions" data-secondary="process.kill()" data-type="indexterm" id="idm46291179914840"/>available as <code>process.kill()</code>. Run the following command in your terminal to run a simple Node.js one-liner before exiting:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>node -e <code class="s2">"process.kill(&lt;PROCESS_ID&gt;, 'SIGHUP')"</code></pre>&#13;
&#13;
<p>Again, you should see the <em>SIGHUP</em> message printed in the console of the first application you’re running.</p>&#13;
&#13;
<p>Now that you’re done experimenting with signals, you’re ready to terminate the original process. Run the following command in your second terminal window:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code><code class="nb">kill</code> -9 &lt;PROCESS_ID&gt;</pre>&#13;
&#13;
<p>This command will send the <em>SIGKILL</em> signal to your process, terminating it immediately. The <code>-9</code> argument tells the <code>kill</code> command to use the numeric version of the signal. <em>SIGKILL</em> is universally the ninth signal, so this command should be fairly portable and will work pretty much everywhere. Recall that the <em>SIGKILL</em> command can’t have a signal handler installed for it. In fact, if you were to attempt to listen for that event on the <code>process</code> event emitter, the following error would be thrown:</p>&#13;
&#13;
<pre data-type="programlisting">Error: uv_signal_start EINVAL</pre>&#13;
&#13;
<p>As a practical application of signals, if an application receives a signal, it can begin shutting itself down in a graceful manner. This can include refusing to handle new connections, transmitting a shutdown metric, and closing database connections. When a Kubernetes pod is terminated, Kubernetes both stops sending requests to the pod and sends it the <em>SIGTERM</em> signal. Kubernetes also starts a 30 second timer. During this time, the application can then do whatever work is necessary to gracefully shutdown. Once the process is done, it should terminate itself so that the pod will go down. However, if the pod doesn’t terminate itself, Kubernetes will then send it the <em>SIGKILL</em> signal, forcefully closing the <a data-primary="signals" data-startref="sign" data-type="indexterm" id="idm46291179903960"/><a data-primary="signals" data-secondary="SIGKILL" data-type="indexterm" id="idm46291179902984"/><a data-primary="signals" data-secondary="SIGINT" data-type="indexterm" id="idm46291179819688"/><a data-primary="SIGINT" data-startref="SIG" data-type="indexterm" id="idm46291179818744"/><a data-primary="SIGKILL" data-startref="SIG2" data-type="indexterm" id="idm46291179817800"/>application.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Building Stateless Services" data-type="sect1"><div class="sect1" id="idm46291180564792">&#13;
<h1>Building Stateless Services</h1>&#13;
&#13;
<p>It’s important that state be <a data-primary="stateless services" data-secondary="building" data-type="indexterm" id="state_build"/>kept out of Node.js services due to the ephemeral nature of containers, and the fact that you and I write buggy code. If state isn’t kept outside of application code, then that state can be lost forever. This can lead to inconsistent data, poor user experience, and, in the wrong situations, even financial loss.</p>&#13;
&#13;
<p><em>Single Source of Truth</em> is a philosophy that <a data-primary="Single Source of Truth" data-type="indexterm" id="idm46291179846104"/>there is a single location that any particular piece of data must call home. If this data is ever kept in two separate locations, then those two sources may diverge (for example, if an update action succeeds in one place but then fails in another). If this data only exists within an application process and that process crashes, then the only copy of the data has just been lost.</p>&#13;
&#13;
<p>Keeping all state out of a process is impossible, but keeping the source of truth from the process is achievable. There is one caveat, though, and that is if a client tries to modify state by contacting a service and some sort of fault happens that leads to the loss of data. In that case, the service needs to respond to the client with an appropriate error. When this happens, the responsibility of that modified state is then shifted back to the client. This might result in an error being displayed to the user, prompting them to click the “Save” button again.</p>&#13;
&#13;
<p>It can be difficult to identify situations where the only source of truth is located inside of an application process, or situations where a process crash can lead to data inconsistency. Consider a situation where a Node.js process receives a request and needs &#13;
<span class="keep-together">to notify</span> two upstream services, <em>Data store #1</em> and <em>Data store #2</em>, that an account balance has been reduced. <a data-type="xref" href="#fig_hidden_state">Figure 8-1</a> is a digram of how the Node.js application might <span class="keep-together">do this.</span></p>&#13;
&#13;
<figure><div class="figure" id="fig_hidden_state">&#13;
<img alt="A service touches two data stores. It modifies data in one store but then crashes before modifying data in the second store. The two stores are no longer in sync. The service was technically stateful after all." src="assets/dsnj_0801.png"/>&#13;
<h6><span class="label">Figure 8-1. </span>Hidden state</h6>&#13;
</div></figure>&#13;
&#13;
<p>The equivalent application code for this situation might look like this:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">server</code><code class="p">.</code><code class="nx">patch</code><code class="p">(</code><code class="s1">'/v1/foo/:id'</code><code class="p">,</code> <code class="nx">async</code> <code class="p">(</code><code class="nx">req</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="kr">const</code> <code class="nx">id</code> <code class="o">=</code> <code class="nx">req</code><code class="p">.</code><code class="nx">params</code><code class="p">.</code><code class="nx">id</code><code class="p">;</code>&#13;
  <code class="kr">const</code> <code class="nx">body</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">req</code><code class="p">.</code><code class="nx">body</code><code class="p">();</code>&#13;
  <code class="nx">await</code> <code class="nx">fetch</code><code class="p">(</code><code class="sb">`http://ds1/foo/</code><code class="si">${</code><code class="nx">id</code><code class="si">}</code><code class="sb">`</code><code class="p">,</code> <code class="p">{</code> <code class="nx">method</code><code class="o">:</code> <code class="s1">'patch'</code><code class="p">,</code> <code class="nx">body</code> <code class="p">});</code>&#13;
  <code class="nx">doSomethingRisky</code><code class="p">();</code>&#13;
  <code class="nx">await</code> <code class="nx">fetch</code><code class="p">(</code><code class="sb">`http://ds2/foo/</code><code class="si">${</code><code class="nx">id</code><code class="si">}</code><code class="sb">`</code><code class="p">,</code> <code class="p">{</code> <code class="nx">method</code><code class="o">:</code> <code class="s1">'patch'</code><code class="p">,</code> <code class="nx">body</code> <code class="p">});</code>&#13;
  <code class="k">return</code> <code class="s1">'OK'</code><code class="p">;</code>&#13;
<code class="p">});</code></pre>&#13;
&#13;
<p>In the happy path, the application receives a request, notifies the first service, notifies the second service, and finally responds to the client that the operation was a success. In the sad path, the application notifies the first service and then crashes before notifying the second service. The client receives a failure response and knows that something bad happened. However, the system has been left in an inconsistent state.</p>&#13;
&#13;
<p>In this case, the Node.js application was, albeit temporarily, the only entity knowledgeable about the state of the system. Once the process crashed, the two backend services were left in an inconsistent state. Managing situations like these can be a very difficult task. I encourage you to read Martin Kleppmann’s <em>Designing Data-Intensive Applications</em> for more information <a data-primary="stateless services" data-secondary="building" data-startref="state_build" data-type="indexterm" id="idm46291179723448"/>about distributed transactions.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Avoiding Memory Leaks" data-type="sect2"><div class="sect2" id="idm46291179722120">&#13;
<h2>Avoiding Memory Leaks</h2>&#13;
&#13;
<p>Maintaining state within an <a data-primary="memory leaks" data-type="indexterm" id="memavoid"/>application process is not only risky for the data, but it can also be risky for the process. Imagine a service that declares a singleton Map instance for storing account information. Such an application might have code that looks like this:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">accounts</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">Map</code><code class="p">();</code>&#13;
&#13;
<code class="nx">module</code><code class="p">.</code><code class="nx">exports</code><code class="p">.</code><code class="nx">set</code> <code class="o">=</code> <code class="p">(</code><code class="nx">account_id</code><code class="p">,</code> <code class="nx">account</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="nx">accounts</code><code class="p">.</code><code class="nx">set</code><code class="p">(</code><code class="nx">account_id</code><code class="p">,</code> <code class="nx">account</code><code class="p">);</code>&#13;
<code class="p">};</code></pre>&#13;
&#13;
<p>Why might an application be built this way? Well, it’s extremely fast. Writing a data change to an in-memory data structure will always be orders of magnitude faster than writing to an external service. It’s also very easy to make mutable globals like this in Node.js.</p>&#13;
&#13;
<p>What sort of problems might arise with this example? The first is that of persistence. When an application restarts, how will the data be transferred to a new process? One way would be to listen for the <code>SIGTERM</code> signal and then to write the content to the filesystem. As you saw previously, filesystems aren’t easily persisted between container restarts, though it is possible. There are also other situations that cause a process to terminate, as you saw in <a data-type="xref" href="#ch_resilience_sec_death">“The Death of a Node.js Process”</a>. Even if the application sends a representation of the map to another service when it suspects termination, there’s no guarantee that the external service is still reachable.</p>&#13;
&#13;
<p>Another problem with this approach is that it’s a potential memory leak. The <code>accounts</code> Map has an unbounded size and may grow until the process consumes all of the free memory of the host! For example, there might be a bug where the <code>account_id</code> value changes slightly, leading to each <code>set()</code> call to insert a new record. Or an attacker might make many fake accounts to fill the value.</p>&#13;
&#13;
<p>Most potential memory leaks won’t be as easy to spot as this one. Here’s a vastly simplified example of a memory leak in the <code>cls-hooked</code> package,<sup><a data-type="noteref" href="ch08.html#idm46291179692920" id="idm46291179692920-marker">4</a></sup> a package that receives over 400,000 downloads every week:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">process</code><code class="p">.</code><code class="nx">namespaces</code> <code class="o">=</code> <code class="p">{};</code>&#13;
&#13;
<code class="kd">function</code> <code class="nx">createNamespace</code><code class="p">(</code><code class="nx">name</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="nx">process</code><code class="p">.</code><code class="nx">namespaces</code><code class="p">[</code><code class="nx">name</code><code class="p">]</code> <code class="o">=</code> <code class="nx">namespace</code><code class="p">;</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">function</code> <code class="nx">destroyNamespace</code><code class="p">(</code><code class="nx">name</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="nx">process</code><code class="p">.</code><code class="nx">namespaces</code><code class="p">[</code><code class="nx">name</code><code class="p">]</code> <code class="o">=</code> <code class="kc">null</code><code class="p">;</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>This package provides an implementation of continuation local storage, specifically to maintain a “session” object, identified by a “namespace,” between asynchronous callbacks. For example, a session can be created when an HTTP request is received, information about the user making the request can be added to the session object, and then, once an asynchronous database call finishes, the session can be looked &#13;
<span class="keep-together">up again.</span></p>&#13;
&#13;
<p>The global that maintains state in this case is <code>process.namespace</code>. The memory leak is that the namespace identifiers are never deleted from the global; instead they are set to <code>null</code>. Different applications use this package in different ways, but if an application creates a new namespace for each incoming HTTP request, it ends <a data-primary="memory leaks" data-startref="memavoid" data-type="indexterm" id="idm46291179587144"/>up resulting in a memory increase linear to the traffic rate.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Bounded In-Process Caches" data-type="sect2"><div class="sect2" id="idm46291179721528">&#13;
<h2>Bounded In-Process Caches</h2>&#13;
&#13;
<p>One type of state that is acceptable <a data-primary="caches" data-secondary="in-process" data-type="indexterm" id="cachein"/><a data-primary="in-process caches" data-type="indexterm" id="cachein2"/>to store within an application process is cached data. A cache represents a copy of data that is either expensive to calculate (CPU cost) or expensive to retrieve (network request time). In this situation a cache is intentionally <em>not</em> the source of truth. A cache stores data as key/value pairs where the key is a unique identifier for the cache’s resource and the value is the resource itself, serialized or otherwise. This type of data can be stored within a process because the source of truth is still safe after the process terminates.</p>&#13;
&#13;
<p>When dealing with a cache, an application first determines what data to look up. For example, this data might be an account with an identifier of 123. Once the identifier has been determined, the application will then consult with the cache. If the cache does contain the resource, such as <code>account:123</code>, then that resource is used and the application continues with the data. This situation is referred to <a data-primary="caches" data-secondary="hits" data-type="indexterm" id="idm46291179579784"/>as a <em>cache hit</em>. Looking up data from an in-process cache takes microseconds.</p>&#13;
&#13;
<p>However, if the resource doesn’t exist within the cache, then the application needs to perform the slower lookup of the data, potentially taking seconds of time. This is referred <a data-primary="caches" data-secondary="misses" data-type="indexterm" id="idm46291179577656"/>to as a <em>cache miss</em>. When this happens, the application performs whatever slow calculation or network request is needed. Once the result is obtained, the application then sets the value in the cache and continues with the newly required resource. When the resource is needed again, it consults the cache again.</p>&#13;
&#13;
<p>Caches should only be used in situations where performance requirements can’t be attained without them. Caches add an additional layer of complexity to an application. A cache also introduces the situation where the copy of the data in the cache may be outdated from the source of truth. For example, the <code>account:123</code> resource may have been modified to have a balance of 0, even though the cached version still contains a balance of 100.</p>&#13;
&#13;
<p>Knowing when to update or remove entries <a data-primary="caches" data-secondary="invalidation" data-type="indexterm" id="idm46291179574120"/>from a cache is a topic known as <em>cache invalidation</em>. There isn’t a perfect solution to this problem, only philosophical ones. It often becomes a business question of what sort of tolerance the product can have with regards to an outdated cache. Is it okay to display a slightly out-of-date account balance? Possibly yes. Is it okay to allow a player to spend more coins than they have in their account? Probably not.</p>&#13;
&#13;
<p>While cache invalidation philosophy is something specific to each organization, the requirement to avoid memory leaks is more universal. It’s safe to assume that a cache should never grow so much that it causes a process to crash.</p>&#13;
&#13;
<p>Applications run in environments where there is a finite amount of memory available. A host machine will always have a maximum amount of physical RAM that it has available. Containers and virtual machines then have a smaller piece of that memory available. When a Node.js process consumes too much memory, it will either fail to get access to more memory, or a supervising process like Docker may terminate the process once a threshold has been reached. Memory is measured in the number of bytes being consumed, not the number of records being cached, so it’s good to use a tool that limits in-process cache size based on some semblance of the byte requirements of the data.</p>&#13;
&#13;
<p>The <code>lru-cache</code> package is <a data-primary="lru-cache package" data-type="indexterm" id="idm46291179569384"/><a data-primary="packages" data-secondary="lru-cache" data-type="indexterm" id="idm46291179568648"/><a data-primary="caches" data-secondary="lru-cache package" data-type="indexterm" id="idm46291179567704"/>a popular tool for doing just that. It is a key/value store that can be configured to use the length of strings or buffers that are inserted into the cache to loosely approximate the memory requirements of those entries.<sup><a data-type="noteref" href="ch08.html#idm46291179566392" id="idm46291179566392-marker">5</a></sup> With this package, you can set values, get values, and perform your own lookup if a value is missing. The package even accepts an expiration time so that entries older than a certain amount of time will be removed. The LRU in the <a data-primary="LRU (Least Recently Used)" data-type="indexterm" id="idm46291179565352"/>name stands for <em>Least Recently Used</em>. This is a common cache practice for evicting keys that haven’t been accessed in a while—which hopefully means keys where cache misses don’t result in too high of a performance loss.</p>&#13;
&#13;
<p>Now that you’re familiar with some of the philosophies behind in-memory caches, you’re ready to work with one of your own. Create a new file named <em>caching/server.js</em> and add the content from <a data-type="xref" href="#ex_lru_cache">Example 8-2</a> to it. This file will serve as a mini-proxy to the GitHub API for looking up account details.</p>&#13;
<div data-type="example" id="ex_lru_cache">&#13;
<h5><span class="label">Example 8-2. </span><em>caching/server.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node&#13;
</code><code>&#13;
</code><code class="c1">// npm install fastify@3.2 lru-cache@6.0 node-fetch@2.6&#13;
</code><code class="kr">const</code><code> </code><code class="nx">fetch</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'node-fetch'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">server</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'fastify'</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">lru</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="p">(</code><code class="nx">require</code><code class="p">(</code><code class="s1">'lru-cache'</code><code class="p">)</code><code class="p">)</code><code class="p">(</code><code class="p">{</code><code> </code><a class="co" href="#callout_resilience_CO1-1" id="co_resilience_CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
  </code><code class="nx">max</code><code class="o">:</code><code> </code><code class="mi">4096</code><code class="p">,</code><code>&#13;
  </code><code class="nx">length</code><code class="o">:</code><code> </code><code class="p">(</code><code class="nx">payload</code><code class="p">,</code><code> </code><code class="nx">key</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">payload</code><code class="p">.</code><code class="nx">length</code><code> </code><code class="o">+</code><code> </code><code class="nx">key</code><code class="p">.</code><code class="nx">length</code><code class="p">,</code><code>&#13;
  </code><code class="nx">maxAge</code><code class="o">:</code><code> </code><code class="mi">10</code><code> </code><code class="o">*</code><code> </code><code class="mi">60</code><code> </code><code class="o">*</code><code> </code><code class="mi">1</code><code class="nx">_000</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">PORT</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code><code> </code><code class="o">||</code><code> </code><code class="mi">3000</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/account/:account'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="nx">req</code><code class="p">,</code><code> </code><code class="nx">reply</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="k">return</code><code> </code><code class="nx">getAccount</code><code class="p">(</code><code class="nx">req</code><code class="p">.</code><code class="nx">params</code><code class="p">.</code><code class="nx">account</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="nx">PORT</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`</code><code class="sb">http://localhost:</code><code class="si">${</code><code class="nx">PORT</code><code class="si">}</code><code class="sb">`</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">async</code><code> </code><code class="kd">function</code><code> </code><code class="nx">getAccount</code><code class="p">(</code><code class="nx">account</code><code class="p">)</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">cached</code><code> </code><code class="o">=</code><code> </code><code class="nx">lru</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="nx">account</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO1-2" id="co_resilience_CO1-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
  </code><code class="k">if</code><code> </code><code class="p">(</code><code class="nx">cached</code><code class="p">)</code><code> </code><code class="p">{</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'cache hit'</code><code class="p">)</code><code class="p">;</code><code> </code><code class="k">return</code><code> </code><code class="nx">JSON</code><code class="p">.</code><code class="nx">parse</code><code class="p">(</code><code class="nx">cached</code><code class="p">)</code><code class="p">;</code><code> </code><code class="p">}</code><code>&#13;
  </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'cache miss'</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">result</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">fetch</code><code class="p">(</code><code class="sb">`</code><code class="sb">https://api.github.com/users/</code><code class="si">${</code><code class="nx">account</code><code class="si">}</code><code class="sb">`</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">body</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">result</code><code class="p">.</code><code class="nx">text</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">lru</code><code class="p">.</code><code class="nx">set</code><code class="p">(</code><code class="nx">account</code><code class="p">,</code><code> </code><code class="nx">body</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO1-3" id="co_resilience_CO1-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
  </code><code class="k">return</code><code> </code><code class="nx">JSON</code><code class="p">.</code><code class="nx">parse</code><code class="p">(</code><code class="nx">body</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_resilience_CO1-1" id="callout_resilience_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The cache will store approximately 4kb of data for up to 10 minutes.</p></dd>&#13;
<dt><a class="co" href="#co_resilience_CO1-2" id="callout_resilience_CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The cache is always consulted before making a request.</p></dd>&#13;
<dt><a class="co" href="#co_resilience_CO1-3" id="callout_resilience_CO1-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>The cache is updated whenever data is retrieved.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Initialize the npm project, install the dependencies, and run the server in a terminal window. In another terminal window, run the following <code>curl</code> commands:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>node caching/server.js&#13;
<code class="nv">$ </code><code class="nb">time </code>curl http://localhost:3000/account/tlhunter&#13;
<code class="nv">$ </code><code class="nb">time </code>curl http://localhost:3000/account/nodejs&#13;
<code class="nv">$ </code><code class="nb">time </code>curl http://localhost:3000/account/tlhunter</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>At the time of this writing, each response from the GitHub API is about 1.2 KB. If things have changed much in the future, you may need to configure the server to have a larger LRU size. Try to set it to be large enough to hold at least two results. Also, be careful to not get rate-limited by the GitHub API. When that happens, you’ll get failed responses.</p>&#13;
</div>&#13;
&#13;
<p>When you run the first command, you <a data-primary="caches" data-secondary="misses" data-type="indexterm" id="idm46291179258920"/>should see a <em>cache miss</em> message displayed in the server terminal window. The command takes about 200ms to complete on my machine. This is because the <em>server.js</em> application is making an outgoing network request to the GitHub servers. When you make the second request, you should see the same thing happen, with another <em>cache miss</em> message and a request that likely takes 200ms to complete. However, when you run the third command, you should see something a little different, specifically a <em>cache hit</em> message, <a data-primary="caches" data-secondary="hits" data-type="indexterm" id="idm46291179463512"/>and the response should be much faster (in my case, 20ms).</p>&#13;
&#13;
<p>Next, substitute your username in one of those URLs and make another request. Then, use some other entries like <em>express</em> and <em>fastify</em>. Finally, circle back to the original <em>tlhunter</em> account again. This time, you should see that the request resulted in another <em>cache miss</em>. This is because <code>lru-cache</code> evicted the original <em>tlhunter</em> entry from the cache since newer entries replaced it and the cache had become full.</p>&#13;
&#13;
<p>There are a few shortcomings with this <a data-primary="GitHub" data-secondary="API errors" data-type="indexterm" id="idm46291179435240"/><a data-primary="errors" data-secondary="GitHub" data-type="indexterm" id="idm46291179434376"/>solution. One problem is surfaced when the GitHub API returns an error. When this happens, the error response will get inserted into the cache—ideally, no entry would be inserted when this happens. Another possible shortcoming (depending on how you look at it) is that the cache stores the JSON representation of the resource, not parsed object. This results in redundant <code>JSON.parse()</code> calls <a data-primary="JSON.parse() method" data-type="indexterm" id="idm46291179459128"/><a data-primary="methods" data-secondary="JSON.parse()" data-type="indexterm" id="idm46291179458392"/>being made each time the entry is retrieved from the cache. Storing the JSON string in the cache library does make it easier to calculate memory usage (string length). It also prevents accidental mutation of the cached objects.</p>&#13;
&#13;
<p>Another issue is that <a data-primary="in-process caches" data-secondary="username requests" data-type="indexterm" id="idm46291179456696"/>parallel incoming requests for the same username will result in simultaneous cache misses followed by parallel outgoing requests to GitHub. This might not be a big deal, but sometimes it’s nice to use a cache to reduce the number of outgoing requests to a third-party API. For example, if you send too many requests to GitHub, you’ll start to get rate limited. For this reason a more robust solution may be needed.</p>&#13;
&#13;
<p>There are two more issues with this cache that specifically deal with caching data inside of the process itself. The first is that if the process is restarted, then the cache is lost with it. In a high-throughput environment, a service restart will mean that upstream services will then receive a burst of traffic. For example, the <em>web-api</em> service <a data-primary="web-api service" data-type="indexterm" id="idm46291179411880"/><a data-primary="recipe-api-service" data-type="indexterm" id="idm46291179411144"/>you previously built could be caching results from the <em>recipe-api</em>. Once a <em>web-api</em> instance restarts, the <em>recipe-api</em> instances will receive increased traffic until the cache is replenished.</p>&#13;
&#13;
<p>Another shortcoming is that the cache is only used by a single service instance! If you had a fleet of 100 <em>web-api</em> instances, each would still need to send a request for the same <em>recipe-api</em> resource at least once every 10 minutes. Each service also contains redundant caches, wasting overall available memory. This issue can be seen by running a second instance of the server and making a request to that:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ PORT</code><code class="o">=</code><code class="m">4000</code> node server.js&#13;
<code class="nv">$ </code><code class="nb">time </code>curl http://localhost:4000/account/tlhunter</pre>&#13;
&#13;
<p>In this case, the request to the server instance listening on port 4000 will never make use of the other server instance’s cache. The easiest way to fix these two issues is to use <a data-primary="caches" data-secondary="in-process" data-startref="cachein" data-type="indexterm" id="idm46291179293176"/><a data-primary="in-process caches" data-startref="cachein2" data-type="indexterm" id="idm46291179298440"/>an external caching service.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="External Caching with Memcached" data-type="sect1"><div class="sect1" id="idm46291179849112">&#13;
<h1>External Caching with Memcached</h1>&#13;
&#13;
<p>There are many trade-offs when <a data-primary="caches" data-secondary="external caching" data-type="indexterm" id="cachex"/><a data-primary="Memcached" data-type="indexterm" id="memcach"/>it comes to performing a cache lookup. Speed, durability, expiration configurability, and how the cache is shared across services are all important concerns. Here’s a quick comparison of three different caching strategies:</p>&#13;
<dl>&#13;
<dt>In-memory cache</dt>&#13;
<dd>&#13;
<p>This is the approach examined <a data-primary="caches" data-secondary="in-memory" data-type="indexterm" id="idm46291179312632"/><a data-primary="in-memory cache" data-type="indexterm" id="idm46291179311656"/>in the previous section. It’s the fastest approach, but the cache is destroyed between crashes and deployments. Data structure changes between application versions don’t have side effects. Lookups that happen here will probably take less than one millisecond.</p>&#13;
</dd>&#13;
<dt>External cache</dt>&#13;
<dd>&#13;
<p>This is the approach covered in this section. It’s slower than an in-memory cache but should be faster than hitting the source of truth. It also prevents the cache from being wiped out between crashes and deployments. Data structures must be maintained, or cache keys renamed, between application versions. Lookups that happen here may take tens of milliseconds.</p>&#13;
</dd>&#13;
<dt>No cache</dt>&#13;
<dd>&#13;
<p>In this approach, an <a data-primary="caches" data-secondary="no cache" data-type="indexterm" id="idm46291179511448"/>application talks directly to the source of truth. It is usually the slowest and simplest to implement. There’s no risk of data integrity issues because there’s no cached values that can drift from the source of truth. Lookups that happen with this strategy could take any amount of time.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Much like with databases, if a heterogeneous collection of services are allowed to read and write to a cache service, bad things may happen. For example, if one team inside of an organization owns the <em>recipe-api</em> and another team owns the <em>web-api</em>, those teams may not communicate how the structure of cached data is going to change between releases. This can result in conflicting expectations and runtime errors. Just think: an API exposed over HTTP is just one API surface; if applications are sharing database tables or caches, there are now multiple API surfaces!</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Introducing Memcached" data-type="sect2"><div class="sect2" id="ch_resilience_sec_memcached_subsec_intro">&#13;
<h2>Introducing Memcached</h2>&#13;
&#13;
<p>One of the most established caching services available is <em>Memcached</em>. It’s a dependable, no-frills cache, one that can be distributed across multiple machines. When instantiating a Memcached instance, you specify the maximum amount of memory that the instance may consume, and Memcached automatically purges newly added entries following the same LRU approach covered in the previous section.</p>&#13;
&#13;
<p>Keys can be up to 250 bytes long, and values can be up to 1MB. Each individual key can have its own expiration time set.</p>&#13;
&#13;
<p>Memcached provides several commands as <a data-primary="Memcached" data-secondary="commands" data-type="indexterm" id="idm46291179340344"/><a data-primary="commands" data-secondary="Memcached" data-type="indexterm" id="idm46291179339368"/>part of its API. One of the most obvious commands is <code>set(key, val, expire)</code>, which will set a key to a value. It has a correlating <code>get(key1[, key2…])</code> command for retrieving data. There’s also <code>add(key, val, expire)</code>, which also sets data but it will only succeed if the key doesn’t already exist. Both <code>incr(key, amount)</code> and <code>decr(key, amount)</code> allow you to atomically modify numeric values, but only if they already exist. There’s even a <code>replace(key, val, expire)</code> command that will only set a value if it already exists. The <code>delete(key)</code> command allows you to delete a single key, and the <code>flush_all()</code> command removes all keys.</p>&#13;
&#13;
<p>There are two commands for performing string manipulations on the values stored in Memcached. The first is <code>append(key, val, expire)</code>, and the second is <span class="keep-together"><code>prepend(key, val, expire)</code></span>. These commands allow an application to append and prepend a string to an existing value.</p>&#13;
&#13;
<p>There are also two additional commands for making atomic changes where one client wants to ensure that another client hasn’t changed entries without it knowing. The first is <code>gets(key)</code>, which returns both the value of the data and a “CAS” (Compare and Set) id. This is an integer that changes with each manipulation to the key. This value can then be used with a correlating <code>cas(key, val, cas_id, expire)</code> command. That command will set a key to a new value but only if the existing value has the same CAS id.</p>&#13;
&#13;
<p>Various other commands exist for getting statistical information about the server, for retrieving the server settings, and for otherwise debugging the cache, though your applications probably won’t need to use them.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291179154296">&#13;
<h5>Alternatives to Memcached</h5>&#13;
<p>Redis is probably the most popular alternative to Memcached. Redis supports the same basic features as Memcached and also provides several powerful data structures with commands for operating on them atomically, which is very useful in a distributed environment. <a data-type="xref" href="ch09.html#ch_primitives_sec_redis">“Introduction to Redis”</a> covers Redis for non-caching situations.</p>&#13;
&#13;
<p>If you’re using AWS, you might choose to make use of <a class="orm:hideurl" href="https://aws.amazon.com/elasticache/">Amazon ElastiCache</a>, and if you use GCE, you might instead use <a class="orm:hideurl" href="https://cloud.google.com/memorystore/">Memorystore</a>, as opposed <a data-primary="caches" data-secondary="external caching" data-startref="cachex" data-type="indexterm" id="idm46291179199928"/><a data-primary="Memcached" data-startref="memcach" data-type="indexterm" id="idm46291179198648"/>to hosting your own instance.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running Memcached" data-type="sect2"><div class="sect2" id="idm46291179197320">&#13;
<h2>Running Memcached</h2>&#13;
&#13;
<p>Just like most of the servers you’ve <a data-primary="Memcached" data-secondary="running" data-type="indexterm" id="memrun"/>worked with, Memcached can be run within a Docker container for convenience.</p>&#13;
&#13;
<p>Like many other Docker images, Memcached also includes an Alpine variant to consume less resources. When instantiating the Memcached service, there are a few flags that can be passed in, including <code>-d</code> to daemonize (not required with Docker containers), <code>-m</code> to set the maximum amount of memory (very useful), and <code>-v</code> to enable logging (this flag can be repeated to increase verbosity).</p>&#13;
&#13;
<p>Run the following command in a terminal window to run Memcached:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>docker run <code class="se">\</code>&#13;
  --name distnode-memcached <code class="se">\</code>&#13;
  -p 11211:11211 <code class="se">\</code>&#13;
  -it --rm memcached:1.6-alpine <code class="se">\</code>&#13;
  memcached -m <code class="m">64</code> -vv</pre>&#13;
&#13;
<p>This Memcached instance is limited to 64MB of memory and will output a bunch of debugging information in your terminal. Port 11211 is the default Memcached port. Since the Docker command has the <code>-it</code> and <code>--rm</code> flags, you’ll be able to kill it with Ctrl + C when you’re done and the container will be removed from your system.</p>&#13;
&#13;
<p>When running multiple Memcached instances, the instances themselves aren’t aware of each other. Instead, clients connect directly to the different instances and use a client-side hashing algorithm to determine which server contains a particular key. Ideally, this means each client uses the same server for the same key names, but it is possible for different client libraries to decide on different servers to store particular keys, which can result in cache misses and data redundancy.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Caching Data with Memcached" data-type="sect2"><div class="sect2" id="idm46291179185352">&#13;
<h2>Caching Data with Memcached</h2>&#13;
&#13;
<p>Now that you have your <a data-primary="Memcached" data-secondary="caching" data-type="indexterm" id="mem"/>Memcached service running, you’re ready to interact with it from a Node.js application. For this example, copy and paste your existing <em>caching/server.js</em> file that you created in the previous section to <em>caching/server-ext.js</em>. Next, modify the file to resemble <a data-type="xref" href="#ex_memecached">Example 8-3</a>.</p>&#13;
<div data-type="example" id="ex_memecached">&#13;
<h5><span class="label">Example 8-3. </span><em>caching/server-ext.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node&#13;
</code><code>&#13;
</code><code class="c1">// npm install fastify@3.2 memjs@1.2 node-fetch@2.6&#13;
</code><code class="kr">const</code><code> </code><code class="nx">fetch</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'node-fetch'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">server</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'fastify'</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">memcache</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'memjs'</code><code class="p">)</code><code>&#13;
  </code><code class="p">.</code><code class="nx">Client</code><code class="p">.</code><code class="nx">create</code><code class="p">(</code><code class="s1">'localhost:11211'</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO2-1" id="co_resilience_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">PORT</code><code> </code><code class="o">=</code><code> </code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code><code> </code><code class="o">||</code><code> </code><code class="mi">3000</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/account/:account'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="nx">req</code><code class="p">,</code><code> </code><code class="nx">reply</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="k">return</code><code> </code><code class="nx">getAccount</code><code class="p">(</code><code class="nx">req</code><code class="p">.</code><code class="nx">params</code><code class="p">.</code><code class="nx">account</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="nx">PORT</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`</code><code class="sb">http://localhost:</code><code class="si">${</code><code class="nx">PORT</code><code class="si">}</code><code class="sb">`</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>&#13;
&#13;
</code><code class="nx">async</code><code> </code><code class="kd">function</code><code> </code><code class="nx">getAccount</code><code class="p">(</code><code class="nx">account</code><code class="p">)</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="p">{</code><code> </code><code class="nx">value</code><code class="o">:</code><code> </code><code class="nx">cached</code><code> </code><code class="p">}</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">memcache</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="nx">account</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO2-2" id="co_resilience_CO2-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
  </code><code class="k">if</code><code> </code><code class="p">(</code><code class="nx">cached</code><code class="p">)</code><code> </code><code class="p">{</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'cache hit'</code><code class="p">)</code><code class="p">;</code><code> </code><code class="k">return</code><code> </code><code class="nx">JSON</code><code class="p">.</code><code class="nx">parse</code><code class="p">(</code><code class="nx">cached</code><code class="p">)</code><code class="p">;</code><code> </code><code class="p">}</code><code>&#13;
  </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'cache miss'</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">result</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">fetch</code><code class="p">(</code><code class="sb">`</code><code class="sb">https://api.github.com/users/</code><code class="si">${</code><code class="nx">account</code><code class="si">}</code><code class="sb">`</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">body</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">result</code><code class="p">.</code><code class="nx">text</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">await</code><code> </code><code class="nx">memcache</code><code class="p">.</code><code class="nx">set</code><code class="p">(</code><code class="nx">account</code><code class="p">,</code><code> </code><code class="nx">body</code><code class="p">,</code><code> </code><code class="p">{</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO2-3" id="co_resilience_CO2-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
  </code><code class="k">return</code><code> </code><code class="nx">JSON</code><code class="p">.</code><code class="nx">parse</code><code class="p">(</code><code class="nx">body</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_resilience_CO2-1" id="callout_resilience_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Instantiate the Memcached connection.</p></dd>&#13;
<dt><a class="co" href="#co_resilience_CO2-2" id="callout_resilience_CO2-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The <code>.get()</code> call is now asynchronous.</p></dd>&#13;
<dt><a class="co" href="#co_resilience_CO2-3" id="callout_resilience_CO2-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>The <code>.set()</code> call is also asynchronous.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>A few code changes are needed <a data-primary="memjs package" data-type="indexterm" id="idm46291179017192"/><a data-primary="packages" data-secondary="memjs" data-type="indexterm" id="idm46291179016296"/>to migrate the service from an in-memory LRU cache to the <code>memjs</code> package. The <code>.get()</code> and <code>.set()</code> arguments for this example follow mostly the same signature as the previous LRU cache. The biggest change is that the calls are now asynchronous and their results must be awaited. The <code>.get()</code> method resolves an object with the cached value being a buffer on the <code>.value</code> property. The <code>JSON.parse()</code> method triggers the <code>.toString()</code> method on the buffer, so an additional data conversion isn’t needed. The <code>.set()</code> method requires a third, empty <em>options</em> object as an argument due to the way the <code>memjs</code> package performs callback to promise conversion.</p>&#13;
&#13;
<p>Now that you have your new service ready, execute two copies of the service in two separate terminals. In the first terminal, use the default port of 3000, and in the second terminal, override the port to be 4000, like so:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>node caching/server-ext.js&#13;
<code class="nv">$ PORT</code><code class="o">=</code><code class="m">4000</code> node caching/server-ext.js</pre>&#13;
&#13;
<p>Next, make a request to both of the services again. Hit the first service twice, and then hit the second service:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code><code class="nb">time </code>curl http://localhost:3000/account/tlhunter <code class="c"># miss</code>&#13;
<code class="nv">$ </code><code class="nb">time </code>curl http://localhost:3000/account/tlhunter <code class="c"># hit</code>&#13;
<code class="nv">$ </code><code class="nb">time </code>curl http://localhost:4000/account/tlhunter <code class="c"># hit</code></pre>&#13;
&#13;
<p>In this example, the first request results in a cache miss. The service makes the outbound request to GitHub and then fills the cache and returns. In my case, this takes about 300ms. Next, the second request to the first service will result in a cache hit. The operation takes about 30ms in my case, which is a little slower than when I had run the process with just an in-memory LRU cache. Finally, the third request to the &#13;
<span class="keep-together">second</span> service will also result in a cache hit, even though that service hasn’t made a request to GitHub. This is because both of the services use the same shared &#13;
<span class="keep-together">Memcached</span> cache entry.</p>&#13;
&#13;
<p>That’s it for Memcached! Feel free to clean up your running Node.js services and the Memcached server by switching to their <a data-primary="Memcached" data-secondary="caching" data-startref="mem" data-type="indexterm" id="idm46291178900984"/>terminal windows and pressing Ctrl + C.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data Structure Mutations" data-type="sect2"><div class="sect2" id="idm46291179184760">&#13;
<h2>Data Structure Mutations</h2>&#13;
&#13;
<p>Since cached resources may <a data-primary="data structure mutations" data-type="indexterm" id="datamut"/>change between releases, it’s sometimes necessary to prefix the name of a key with a version number to signify the version of the data structure being cached. For example, consider an application that stores the following object in a cache:</p>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">{</code>&#13;
  <code class="nt">"account"</code><code class="p">:</code> <code class="p">{</code>&#13;
    <code class="nt">"id"</code><code class="p">:</code> <code class="mi">7</code><code class="p">,</code>&#13;
    <code class="nt">"balance"</code><code class="p">:</code> <code class="mi">100</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Perhaps this representation of the cached entry is used by several different versions/releases of an application. Let’s refer to those as <em>r1..r5</em>. However, for the <em>r6</em> release of the application, an engineer decides to change the shape of the cached object to be more efficient and to deal with an anticipated migration of account IDs from numbers to strings.</p>&#13;
<div style="page-break-after: always;"/>&#13;
&#13;
<p>The engineer chooses to represent the cached entries like so:</p>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">{</code>&#13;
  <code class="nt">"id"</code><code class="p">:</code> <code class="s2">"7"</code><code class="p">,</code>&#13;
  <code class="nt">"balance"</code><code class="p">:</code> <code class="mi">100</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>In this case, the superfluous wrapper has been removed and the data type of the <code>id</code> attribute has been changed to a string. By changing the representation of the cached entries, something bad will likely happen!</p>&#13;
&#13;
<p>As an example, assume that the key names of these records in the cache follow the pattern <code>account-info-&lt;ACCOUNT_ID&gt;</code>. In the case of these two versions of the objects, the key would then be <code>account-info-7</code>.</p>&#13;
&#13;
<p>The code that reads from the cache in releases <em>r1..r5</em> of the application looks like this:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">async</code> <code class="kd">function</code> <code class="nx">reduceBalance</code><code class="p">(</code><code class="nx">account_id</code><code class="p">,</code> <code class="nx">item_cost</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="kr">const</code> <code class="nx">key</code> <code class="o">=</code> <code class="sb">`account-info-</code><code class="si">${</code><code class="nx">account_id</code><code class="si">}</code><code class="sb">`</code><code class="p">;</code>&#13;
  <code class="kr">const</code> <code class="nx">account</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">cache</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="nx">key</code><code class="p">);</code>&#13;
  <code class="kr">const</code> <code class="nx">new_balance</code> <code class="o">=</code> <code class="nx">account</code><code class="p">.</code><code class="nx">account</code><code class="p">.</code><code class="nx">balance</code> <code class="o">-</code> <code class="nx">item_cost</code><code class="p">;</code>&#13;
  <code class="k">return</code> <code class="nx">new_balance</code><code class="p">;</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>However, for release <em>r6</em> and onward of the application, the code will have been changed slightly to work with the new cached entry:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting">  <code class="kr">const</code> <code class="nx">new_balance</code> <code class="o">=</code> <code class="nx">account</code><code class="p">.</code><code class="nx">balance</code> <code class="o">-</code> <code class="nx">item_cost</code><code class="p">;</code></pre>&#13;
&#13;
<p>This means that when release <em>r6</em> of the application is deployed, it will read the cache and throw an error stating <code>account.balance</code> is undefined. This is because existing entries in the cache still have the wrapper object present. In this case, you might be tempted to clear the cache before deploying the new release. Unfortunately there’s still the risk of <em>r5</em> instances writing to the cache after it has been cleared and before <em>r6</em> instances have been deployed.</p>&#13;
&#13;
<p>The easiest way to survive this situation is to modify the names of the cache entries to contain a version number representing the object representation version. This version number need not resemble the release version of the application. In fact, it shouldn’t, because an application is likely to retain the same data structure for most objects across most releases. Instead, each resource type should get its own new version whenever its representation is changed.</p>&#13;
&#13;
<p>As an example of this, the key name could change from <code>account-info-&lt;ACCOUNT_ID&gt;</code> to <code>account-info-&lt;VERSION&gt;-&lt;ACCOUNT_ID&gt;</code>. In the case of the application release changing from <em>r5</em> to <em>r6</em>, the <code>account-info</code> object version may change from <em>v1</em> to <em>v2</em>. This would result in two separate cached entries, one named <code>account-info-v1-7</code> and one named <code>account-info-v2-7</code>. This is convenient because no matter how slow the deployment is, two separate application releases won’t have conflicting cache data. Unfortunately, it now means that all of the <code>account-info</code> objects in the cache need to be looked up again.</p>&#13;
&#13;
<p>Another solution, instead of changing key names and losing cached values, is to “migrate” the data from the old form to the new form. This allows different application releases to deal with different representations of cached objects. <a data-type="xref" href="#ch_resilience_sec_migrations">“Schema Migrations with Knex”</a> covers this concept of migrations in more detail, albeit from the perspective of a <a data-primary="data structure mutations" data-startref="datamut" data-type="indexterm" id="idm46291178559000"/>relational database.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Database Connection Resilience" data-type="sect1"><div class="sect1" id="ch_resilience_sec_db">&#13;
<h1>Database Connection Resilience</h1>&#13;
&#13;
<p>Node.js applications often <a data-primary="resilience" data-secondary="database connections" data-type="indexterm" id="res_data"/><a data-primary="database connections" data-secondary="resilience" data-type="indexterm" id="data_res"/>maintain a long-lived connection to one or more databases so that they may remain stateless. Database connections are usually made through a TCP network connection. Unfortunately, those connections will occasionally go down. Many different situations can cause connections to drop, such as database upgrades, network changes, or even temporary network outages.</p>&#13;
&#13;
<p>When a connection drops, your application might be dead in the water. Perhaps there are some actions that the service can still perform. For example, if there is an endpoint to retrieve a resource and the application is still able to connect to a caching service but not to the database, then it’s reasonable that requests for cached resources should succeed.</p>&#13;
&#13;
<p>However, when a connection isn’t available, and data must be written to or read from the database, your application is going to be in a tricky situation. At this point, it might make sense to simply fail the request, such as with a 503 Service Unavailable error if using HTTP.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running PostgreSQL" data-type="sect2"><div class="sect2" id="ch_resilience_sec_db_subsec_runpg">&#13;
<h2>Running PostgreSQL</h2>&#13;
&#13;
<p>In this section you’re going <a data-primary="database connections" data-secondary="PostgreSQL and" data-type="indexterm" id="post_SQL"/><a data-primary="resilience" data-secondary="database connections" data-tertiary="PostgreSQL and" data-type="indexterm" id="post_SQL2"/><a data-primary="PostgreSQL" data-secondary="database connection resilience" data-type="indexterm" id="post_SQL3"/>to use the <em>PostgreSQL</em> database. Most of the techniques covered herein are supported by other SQL and NoSQL databases alike. Postgres is a very powerful and popular database system that you’re likely to work with during your career, so it will make for a great guinea pig. Run the following command to get Postgres running via Docker:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>docker run <code class="se">\</code>&#13;
  --name distnode-postgres <code class="se">\</code>&#13;
  -it --rm <code class="se">\</code>&#13;
  -p 5432:5432 <code class="se">\</code>&#13;
  -e <code class="nv">POSTGRES_PASSWORD</code><code class="o">=</code>hunter2 <code class="se">\</code>&#13;
  -e <code class="nv">POSTGRES_USER</code><code class="o">=</code>user <code class="se">\</code>&#13;
  -e <code class="nv">POSTGRES_DB</code><code class="o">=</code>dbconn <code class="se">\</code>&#13;
  postgres:12.3</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Automatic Reconnection" data-type="sect2"><div class="sect2" id="idm46291178482904">&#13;
<h2>Automatic Reconnection</h2>&#13;
&#13;
<p>The first topic you’re going <a data-primary="database connections" data-secondary="automatic reconnection" data-type="indexterm" id="autoreconnect"/>to work with regarding database connection resilience is that of automatically reconnecting to the database. Unfortunately, connections will fail from time to time, and it’s convenient for the application to automatically reconnect when a failure does happen.</p>&#13;
&#13;
<p>Theoretically, if a database connection were to fail, then your application could terminate itself. Assuming you have infrastructure set up to detect such a termination, for example, a health check endpoint, then your Node.js process could be automatically restarted. That said, such infrastructure isn’t always available to an organization. Another thing to consider is that the overall application health isn’t necessarily any better by doing this. For example, if a process terminates and takes 10 seconds to fail a health check, then those are 10 seconds’ worth of failed requests. If an application loses connection to the database but is able to reconnect, that represents a potentially shorter period of downtime. For these reasons, developers often choose to implement reconnection logic.</p>&#13;
&#13;
<p>Not every database package provides the ability to reconnect to a database, but the principle is generally the same everywhere. In this section you will build out a reconnection module for the <code>pg</code> package <a data-primary="pg package" data-secondary="reconnection module" data-type="indexterm" id="idm46291178481304"/><a data-primary="packages" data-secondary="pg" data-type="indexterm" id="idm46291178480296"/>in a way that can be applied to other packages &#13;
<span class="keep-together">as well.</span></p>&#13;
&#13;
<p>First, you’re going to need to create an application file. This file will resemble a fairly typical web application, one that sends SQL queries as part of a request handler. But instead of requiring the database package directly, it instead requires the reconnection module. Create a new file named <em>dbconn/reconnect.js</em> and start it off with the content from <a data-type="xref" href="#ex_reconnection_server_1">Example 8-4</a>.</p>&#13;
<div data-type="example" id="ex_reconnection_server_1">&#13;
<h5><span class="label">Example 8-4. </span><em>dbconn/reconnect.js</em>, part one of two</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node&#13;
</code><code>&#13;
</code><code class="c1">// npm install fastify@3.2 pg@8.2&#13;
</code><code class="kr">const</code><code> </code><code class="nx">DatabaseReconnection</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'./db.js'</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO3-1" id="co_resilience_CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">db</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="nx">DatabaseReconnection</code><code class="p">(</code><code class="p">{</code><code>&#13;
  </code><code class="nx">host</code><code class="o">:</code><code> </code><code class="s1">'localhost'</code><code class="p">,</code><code> </code><code class="nx">port</code><code class="o">:</code><code> </code><code class="mi">5432</code><code class="p">,</code><code>&#13;
  </code><code class="nx">user</code><code class="o">:</code><code> </code><code class="s1">'user'</code><code class="p">,</code><code> </code><code class="nx">password</code><code class="o">:</code><code> </code><code class="s1">'hunter2'</code><code class="p">,</code><code>&#13;
  </code><code class="nx">database</code><code class="o">:</code><code> </code><code class="s1">'dbconn'</code><code class="p">,</code><code> </code><code class="nx">retry</code><code class="o">:</code><code> </code><code class="mi">1</code><code class="nx">_000</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">db</code><code class="p">.</code><code class="nx">connect</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO3-2" id="co_resilience_CO3-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code class="nx">db</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'error'</code><code class="p">,</code><code> </code><code class="p">(</code><code class="nx">err</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="s1">'db error'</code><code class="p">,</code><code> </code><code class="nx">err</code><code class="p">.</code><code class="nx">message</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">db</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'reconnect'</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'reconnecting...'</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO3-3" id="co_resilience_CO3-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code class="nx">db</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'connect'</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'connected.'</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">db</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'disconnect'</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'disconnected.'</code><code class="p">)</code><code class="p">)</code><code class="p">;</code></pre>&#13;
<div style="page-break-after: always;"/>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_resilience_CO3-1" id="callout_resilience_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This loads the <code>DatabaseReconnection</code> module <a data-primary="DatabaseReconnection module" data-type="indexterm" id="idm46291178297656"/><a data-primary="modules" data-secondary="DatabaseReconnection" data-type="indexterm" id="idm46291178297048"/>from the <em>db.js</em> file.</p></dd>&#13;
<dt><a class="co" href="#co_resilience_CO3-2" id="callout_resilience_CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>This call kicks off the database connection.</p></dd>&#13;
<dt><a class="co" href="#co_resilience_CO3-3" id="callout_resilience_CO3-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>These overly verbose event listeners are for educational purposes.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This file starts off like many applications you have likely written. The <code>DatabaseReconnection</code> class accepts the same configuration settings that are used by the <code>pg</code> package. In fact, it passes the connection settings along blindly. The <code>retry</code> value is specifically going to be used by the reconnection logic that you’ll soon write. In this case, it’s configured to retry the database connection every second until it &#13;
<span class="keep-together">succeeds.</span></p>&#13;
&#13;
<p>The big list of event listeners isn’t necessary for a production application, though the <em>error</em> event of <a data-primary="error event" data-type="indexterm" id="idm46291178257464"/><a data-primary="events" data-secondary="error event" data-type="indexterm" id="idm46291178256856"/>course needs to be handled, or else an error will be thrown. These are provided to later illustrate how the module goes through the reconnection flow.</p>&#13;
&#13;
<p>The file isn’t quite ready yet as you still need to add some request handlers. Add the content from <a data-type="xref" href="#ex_reconnection_server_2">Example 8-5</a> to the file.</p>&#13;
<div data-type="example" id="ex_reconnection_server_2">&#13;
<h5><span class="label">Example 8-5. </span><em>dbconn/reconnect.js</em>, part two of two</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code><code> </code><code class="nx">server</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'fastify'</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/foo/:foo_id'</code><code class="p">,</code><code> </code><code class="nx">async</code><code> </code><code class="p">(</code><code class="nx">req</code><code class="p">,</code><code> </code><code class="nx">reply</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="k">try</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="kd">var</code><code> </code><code class="nx">res</code><code> </code><code class="o">=</code><code> </code><code class="nx">await</code><code> </code><code class="nx">db</code><code class="p">.</code><code class="nx">query</code><code class="p">(</code><code> </code><a class="co" href="#callout_resilience_CO4-1" id="co_resilience_CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
      </code><code class="s1">'SELECT NOW() AS time, $1 AS echo'</code><code class="p">,</code><code> </code><code class="p">[</code><code class="nx">req</code><code class="p">.</code><code class="nx">params</code><code class="p">.</code><code class="nx">foo_id</code><code class="p">]</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code> </code><code class="k">catch</code><code> </code><code class="p">(</code><code class="nx">e</code><code class="p">)</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="nx">reply</code><code class="p">.</code><code class="nx">statusCode</code><code> </code><code class="o">=</code><code> </code><code class="mi">503</code><code class="p">;</code><code>&#13;
    </code><code class="k">return</code><code> </code><code class="nx">e</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code><code>&#13;
  </code><code class="k">return</code><code> </code><code class="nx">res</code><code class="p">.</code><code class="nx">rows</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/health'</code><code class="p">,</code><code> </code><code class="nx">async</code><code class="p">(</code><code class="nx">req</code><code class="p">,</code><code> </code><code class="nx">reply</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code> </code><a class="co" href="#callout_resilience_CO4-2" id="co_resilience_CO4-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
  </code><code class="k">if</code><code> </code><code class="p">(</code><code class="o">!</code><code class="nx">db</code><code class="p">.</code><code class="nx">connected</code><code class="p">)</code><code> </code><code class="p">{</code><code> </code><code class="k">throw</code><code> </code><code class="k">new</code><code> </code><code class="nb">Error</code><code class="p">(</code><code class="s1">'no db connection'</code><code class="p">)</code><code class="p">;</code><code> </code><code class="p">}</code><code>&#13;
  </code><code class="k">return</code><code> </code><code class="s1">'OK'</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">server</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="mi">3000</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`</code><code class="sb">http://localhost:3000</code><code class="sb">`</code><code class="p">)</code><code class="p">)</code><code class="p">;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_resilience_CO4-1" id="callout_resilience_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Basic parameterized query without a table</p></dd>&#13;
<dt><a class="co" href="#co_resilience_CO4-2" id="callout_resilience_CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>An example health endpoint</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Your web server now has two different HTTP endpoints registered in it. The first one, <code>GET /foo/:foo_id</code>, makes use of the database connection. In this case, it’s running an example query that doesn’t require a table, chosen so that you don’t have to create &#13;
<span class="keep-together">a schema.</span> All it does is show that the database connection is working. Within this &#13;
<span class="keep-together">handler,</span> if the query fails, the call to <code>db.query()</code> will reject, and the handler will return the error. However, if the database query succeeds, it’ll return an object with a <code>time</code> and <code>echo</code> property.</p>&#13;
&#13;
<p>The second request handler for <code>GET /health</code> is a health endpoint. In this case, the endpoint makes use of a property on the <code>DatabaseReconnection</code> class instance called <code>.connected</code>. This is a Boolean property declaring if the connection is working or not. In this case, the health endpoint will fail if the connection is down and will pass if the connection is up.</p>&#13;
&#13;
<p>With this, Kubernetes could be configured to hit the health endpoint, perhaps every few seconds, and also be configured to restart the service if the endpoint fails three times in a row. This would give the application enough time to reestablish a connection, allowing the instance to remain running. On the other hand, if the connection cannot be established in time, Kubernetes would then kill the instance.</p>&#13;
&#13;
<p>Once you’ve made these changes to the application file you’re now ready to work on the <code>DatabaseReconnection</code> class. Create a second file named <em>dbconn/db.js</em> and start it off by adding the content from <a data-type="xref" href="#ex_reconnection_library_1">Example 8-6</a> to it.</p>&#13;
<div data-type="example" id="ex_reconnection_library_1">&#13;
<h5><span class="label">Example 8-6. </span><em>dbconn/db.js</em>, part one of three</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="p">{</code> <code class="nx">Client</code> <code class="p">}</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'pg'</code><code class="p">);</code>&#13;
<code class="kr">const</code> <code class="p">{</code> <code class="nx">EventEmitter</code> <code class="p">}</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'events'</code><code class="p">);</code>&#13;
&#13;
<code class="kr">class</code> <code class="nx">DatabaseReconnection</code> <code class="kr">extends</code> <code class="nx">EventEmitter</code> <code class="p">{</code>&#13;
  <code class="err">#</code><code class="nx">client</code> <code class="o">=</code> <code class="kc">null</code><code class="p">;</code>       <code class="err">#</code><code class="nx">conn</code> <code class="o">=</code> <code class="kc">null</code><code class="p">;</code>&#13;
  <code class="err">#</code><code class="nx">kill</code> <code class="o">=</code> <code class="kc">false</code><code class="p">;</code>        <code class="nx">connected</code> <code class="o">=</code> <code class="kc">false</code><code class="p">;</code>&#13;
&#13;
  <code class="nx">constructor</code><code class="p">(</code><code class="nx">conn</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="kr">super</code><code class="p">();</code>&#13;
    <code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">conn</code> <code class="o">=</code> <code class="nx">conn</code><code class="p">;</code>&#13;
  <code class="p">}</code></pre></div>&#13;
&#13;
<p>The first part of this file isn’t too exciting. Since the module wraps the <code>pg</code> package, it needs to first require it. A <code>DatabaseReconnection</code> class instance is an instance of an <code>EventEmitter</code>, so the built-in <code>events</code> module is loaded and extended.</p>&#13;
&#13;
<p>The class depends on four properties. The first three are private properties. The first, <code>client</code>, is an instance of the <code>pg.Client</code> class. This is what handles the actual database connection and dispatches queries. The second property is <code>conn</code>. It contains the database connection object and needs to be stored because new connections will need to &#13;
<span class="keep-together">be created</span> with it. The third property, <code>kill</code>, is set when the application wants to &#13;
<span class="keep-together">disconnect</span> from the database server. It’s used so that an intentionally closing connection doesn’t attempt to reestablish another connection. The final public property, &#13;
<span class="keep-together"><code>connected</code></span>, tells the outside world if the database is connected or not. It won’t &#13;
<span class="keep-together">necessarily</span> be 100% accurate, because a downed connection might not immediately cause the value to change, but it’s useful for the health endpoint.</p>&#13;
&#13;
<p>The constructor method accepts the connection object, instantiates the event emitter, and then sets the private property. The exciting part won’t happen until the connection is actually kicked off.</p>&#13;
&#13;
<p>Once you’ve finished adding the first set of content to the file, you’re ready to move on. Now add the content from <a data-type="xref" href="#ex_reconnection_library_2">Example 8-7</a> to the file.</p>&#13;
<div data-type="example" id="ex_reconnection_library_2">&#13;
<h5><span class="label">Example 8-7. </span><em>dbconn/db.js</em>, part two of three</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code>  </code><code class="nx">connect</code><code class="p">(</code><code class="p">)</code><code> </code><code class="p">{</code><code>&#13;
    </code><code class="k">if</code><code> </code><code class="p">(</code><code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">client</code><code class="p">)</code><code> </code><code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">client</code><code class="p">.</code><code class="nx">end</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code> </code><a class="co" href="#callout_resilience_CO5-1" id="co_resilience_CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
    </code><code class="k">if</code><code> </code><code class="p">(</code><code class="k">this</code><code class="p">.</code><code class="nx">kill</code><code class="p">)</code><code> </code><code class="k">return</code><code class="p">;</code><code>&#13;
    </code><code class="kr">const</code><code> </code><code class="nx">client</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="nx">Client</code><code class="p">(</code><code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">conn</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="nx">client</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'error'</code><code class="p">,</code><code> </code><code class="p">(</code><code class="nx">err</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="k">this</code><code class="p">.</code><code class="nx">emit</code><code class="p">(</code><code class="s1">'error'</code><code class="p">,</code><code> </code><code class="nx">err</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="nx">client</code><code class="p">.</code><code class="nx">once</code><code class="p">(</code><code class="s1">'end'</code><code class="p">,</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code> </code><a class="co" href="#callout_resilience_CO5-2" id="co_resilience_CO5-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
      </code><code class="k">if</code><code> </code><code class="p">(</code><code class="k">this</code><code class="p">.</code><code class="nx">connected</code><code class="p">)</code><code> </code><code class="k">this</code><code class="p">.</code><code class="nx">emit</code><code class="p">(</code><code class="s1">'disconnect'</code><code class="p">)</code><code class="p">;</code><code>&#13;
      </code><code class="k">this</code><code class="p">.</code><code class="nx">connected</code><code> </code><code class="o">=</code><code> </code><code class="kc">false</code><code class="p">;</code><code>&#13;
      </code><code class="k">if</code><code> </code><code class="p">(</code><code class="k">this</code><code class="p">.</code><code class="nx">kill</code><code class="p">)</code><code> </code><code class="k">return</code><code class="p">;</code><code>&#13;
      </code><code class="nx">setTimeout</code><code class="p">(</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="k">this</code><code class="p">.</code><code class="nx">connect</code><code class="p">(</code><code class="p">)</code><code class="p">,</code><code> </code><code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">conn</code><code class="p">.</code><code class="nx">retry</code><code> </code><code class="o">||</code><code> </code><code class="mi">1</code><code class="nx">_000</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="nx">client</code><code class="p">.</code><code class="nx">connect</code><code class="p">(</code><code class="p">(</code><code class="nx">err</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
      </code><code class="k">this</code><code class="p">.</code><code class="nx">connected</code><code> </code><code class="o">=</code><code> </code><code class="o">!</code><code class="nx">err</code><code class="p">;</code><code>&#13;
      </code><code class="k">if</code><code> </code><code class="p">(</code><code class="o">!</code><code class="nx">err</code><code class="p">)</code><code> </code><code class="k">this</code><code class="p">.</code><code class="nx">emit</code><code class="p">(</code><code class="s1">'connect'</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
    </code><code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">client</code><code> </code><code class="o">=</code><code> </code><code class="nx">client</code><code class="p">;</code><code>&#13;
    </code><code class="k">this</code><code class="p">.</code><code class="nx">emit</code><code class="p">(</code><code class="s1">'reconnect'</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_resilience_CO5-1" id="callout_resilience_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Terminate any existing connections.</p></dd>&#13;
<dt><a class="co" href="#co_resilience_CO5-2" id="callout_resilience_CO5-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Attempt to reconnect when a connection ends.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This section of the file defines a single <code>connect()</code> method and is the most complex part of the <code>DatabaseReconnection</code> class. Many whitespace atrocities have been committed to squeeze the functionality into a small space; feel free to add newlines where appropriate.</p>&#13;
&#13;
<p>When the <code>connect()</code> method runs, it first checks to see if a client already exists. If so, it ends an existing connection. Next, it checks to see if the <code>kill</code> flag has been set. This flag is set later within the <code>disconnect()</code> method and is used to prevent the class from reconnecting after being manually disconnected. If the flag is set, then the method returns and no additional work is done.</p>&#13;
&#13;
<p>Next, a new database connection is instantiated and set to a variable named <code>client</code>. The <code>client.on('error')</code> call hoists any error calls from the database connection to the wrapping class so that the application can listen for them. The class also listens for <a data-primary="end event" data-type="indexterm" id="idm46291177771384"/><a data-primary="events" data-secondary="end" data-type="indexterm" id="idm46291177770680"/>the <code>end</code> event. That event is triggered any time the database connection closes, including when the connection is manually terminated, when there’s a network blip, or when the database dies. In this event <a data-primary="disconnect event" data-type="indexterm" id="idm46291177768984"/><a data-primary="events" data-secondary="disconnect" data-type="indexterm" id="idm46291177768280"/>handler, a <code>disconnect</code> event is emitted, the <code>connection</code> flag is set to false, and if the connection isn’t being manually killed, the <code>connect()</code> method is called again after the retry period has passed.</p>&#13;
&#13;
<p>After that, the database connection is attempted. The <code>connected</code> flag is set to true if the connection succeeds and false if it fails. It also emits a <code>connect</code> event <a data-primary="events" data-secondary="connect" data-type="indexterm" id="idm46291177628008"/><a data-primary="connect event" data-type="indexterm" id="idm46291177627000"/>upon success. The underlying <code>pg</code> package emits an <code>end</code> event if the connection fails to be made, which is why this event handler doesn’t call the <code>connect()</code> method.</p>&#13;
&#13;
<p>Finally, the <code>client</code> is assigned as a class attribute, and the <code>reconnect</code> event is emitted.</p>&#13;
&#13;
<p>Once you’ve saved those changes, you’re ready for the final part of the file. Add <a data-type="xref" href="#ex_reconnection_library_3">Example 8-8</a> to the end of the file.</p>&#13;
<div data-type="example" id="ex_reconnection_library_3">&#13;
<h5><span class="label">Example 8-8. </span><em>dbconn/db.js</em>, part three of three</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting">  <code class="nx">async</code> <code class="nx">query</code><code class="p">(</code><code class="nx">q</code><code class="p">,</code> <code class="nx">p</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="k">if</code> <code class="p">(</code><code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">kill</code> <code class="o">||</code> <code class="o">!</code><code class="k">this</code><code class="p">.</code><code class="nx">connected</code><code class="p">)</code> <code class="k">throw</code> <code class="k">new</code> <code class="nb">Error</code><code class="p">(</code><code class="s1">'disconnected'</code><code class="p">);</code>&#13;
    <code class="k">return</code> <code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">client</code><code class="p">.</code><code class="nx">query</code><code class="p">(</code><code class="nx">q</code><code class="p">,</code> <code class="nx">p</code><code class="p">);</code>&#13;
  <code class="p">}</code>&#13;
&#13;
  <code class="nx">disconnect</code><code class="p">()</code> <code class="p">{</code>&#13;
    <code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">kill</code> <code class="o">=</code> <code class="kc">true</code><code class="p">;</code>&#13;
    <code class="k">this</code><code class="p">.</code><code class="err">#</code><code class="nx">client</code><code class="p">.</code><code class="nx">end</code><code class="p">();</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">}</code>&#13;
<code class="nx">module</code><code class="p">.</code><code class="nx">exports</code> <code class="o">=</code> <code class="nx">DatabaseReconnection</code><code class="p">;</code></pre></div>&#13;
&#13;
<p>This part of the file exposes two more methods. The first one is the <code>query()</code> method, which for the most part passes the query along to the encapsulated <code>pg.Client</code> instance. However, if it knows the connection isn’t ready, or if it knows the connection is being killed, it will reject the call with an error. Note that this method doesn’t properly support the entire <code>pg.Client#query()</code> interface; be sure to spruce it up if you use it in a real project.</p>&#13;
&#13;
<p>The <code>disconnect()</code> method sets the <code>kill</code> flag on the class and also instructs the underlying <code>pg.Client</code> connection to terminate by calling its <code>.end()</code> method. That <code>kill</code> flag is needed to distinguish between the <code>end</code> event triggered by this manual disconnection versus an <code>end</code> event triggered by a connection failure.</p>&#13;
&#13;
<p>Finally the class is exported. Note that if you were to build such a reconnection library for other database packages, then it would make sense to expose any other methods the application needs to access.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>This database reconnection module isn’t necessarily ready for production. Depending on the package you use it to encapsulate, there may be other error conditions as well. As with any database connection library, it would be wise to experiment and reproduce many of the different failure cases.</p>&#13;
</div>&#13;
&#13;
<p>Once the file is complete, be sure to initialize a new npm project and to install the required dependencies. Then, execute the <em>reconnect.js</em> Node.js service. Once your &#13;
<span class="keep-together">service</span> is running, you may send it a request to confirm that it is connected to the &#13;
<span class="keep-together">database:</span></p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>curl http://localhost:3000/foo/hello&#13;
&gt; <code class="o">{</code><code class="s2">"time"</code>:<code class="s2">"2020-05-18T00:31:58.494Z"</code>,<code class="s2">"echo"</code>:<code class="s2">"hello"</code><code class="o">}</code>&#13;
<code class="nv">$ </code>curl http://localhost:3000/health&#13;
&gt; OK</pre>&#13;
&#13;
<p>In this case, you should get a successful response back from the server. The result I receive is printed on the second line. That timestamp was calculated by the Postgres service, not the Node.js application.</p>&#13;
&#13;
<p>Now that you’ve confirmed your Node.js service is able to speak to the database, it’s time to sever the connection. In this case, you’re going to take down the entire Postgres database. Switch to the terminal window running Postgres and kill it by pressing Ctrl + C.</p>&#13;
&#13;
<p>You should now see the following messages in the terminal running your Node.js &#13;
<span class="keep-together">service:</span></p>&#13;
&#13;
<pre data-type="programlisting">connected.&#13;
db error terminating connection due to administrator command&#13;
db error Connection terminated unexpectedly&#13;
disconnected.&#13;
reconnecting...&#13;
reconnecting...</pre>&#13;
&#13;
<p>The first connected message was displayed when the process first started. The two error messages and the disconnected message are displayed immediately after the Node.js service detected the disconnection. Finally, the reconnecting messages are displayed, once per second, as the service attempts to reconnect.</p>&#13;
&#13;
<p>At this point, your application is in a degraded state. But the service is still running. Make two new requests to the service, the first to the same endpoint and the second to the health endpoint:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl http://localhost:3000/foo/hello&#13;
&gt; {"statusCode":503,"error":"Service Unavailable",&#13;
&gt;   "message":"disconnected"}&#13;
$ curl http://localhost:3000/health&#13;
&gt; {"statusCode":error":"Internal Server Error",&#13;
&gt;   "message":"no db connection"}</pre>&#13;
&#13;
<p>In this case, both of the endpoints are failing. The first endpoint fails when it attempts to make a database query, and the second fails since the <code>connected</code> flag on the database connection is set to false. However, if the application supported other endpoints that didn’t rely on the database connection, they could still succeed.</p>&#13;
&#13;
<p>Finally, switch back to the terminal window where you killed the Postgres database and start it again. The container should start relatively quickly since the Docker images have already been downloaded to your machine. Once the Postgres database is back up, your Node.js service should establish a new connection. The logs that are displayed when I run the service looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">reconnecting...&#13;
reconnecting...&#13;
connected.</pre>&#13;
&#13;
<p>In this case, my Node.js service was able to reconnect to the Postgres database again. Run the <code>curl</code> commands a final <a data-primary="database connections" data-secondary="automatic reconnection" data-startref="autoreconnect" data-type="indexterm" id="idm46291177578312"/><a data-primary="automatic reconnection" data-startref="autoreconnect" data-type="indexterm" id="idm46291177577032"/>time and you should get passing responses again.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Connection Pooling" data-type="sect2"><div class="sect2" id="idm46291178500360">&#13;
<h2>Connection Pooling</h2>&#13;
&#13;
<p>Another way to increase the <a data-primary="database connections" data-secondary="connection pooling" data-type="indexterm" id="connpool"/><a data-primary="connection pooling" data-type="indexterm" id="connpool1"/>resilience of your application’s database connection is to use more than one connection, or as it’s better known, use a pool of connections. With regards to resilience, if a single one of the connections were to fail, then another connection would remain open.</p>&#13;
&#13;
<p>When configured to use connection pools, an application will typically try to maintain a certain number of connections. When a connection goes down, the application attempts to create a new connection to compensate. When the application chooses to run a database query, it will then pick one of the available connections in the pool to pass the query through.</p>&#13;
&#13;
<p>Most database packages seem to support some form of connection pooling by default. The popular <code>pg</code> package <a data-primary="pg package" data-secondary="connection pooling" data-type="indexterm" id="idm46291177566392"/>used in these examples is no exception. The <code>pg.Pool</code> class is available and can mostly be swapped out with <code>pg.Client</code>, though it does have a few different configuration options and exposes some new properties.</p>&#13;
&#13;
<p>Create a new file named <em>dbconn/pool.js</em> and add the content in <a data-type="xref" href="#ex_pooling_server">Example 8-9</a> to it.</p>&#13;
<div data-type="example" id="ex_pooling_server">&#13;
<h5><span class="label">Example 8-9. </span><em>dbconn/pool.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node</code>&#13;
&#13;
<code class="c1">// npm install fastify@3.2 pg@8.2</code>&#13;
<code class="kr">const</code> <code class="p">{</code> <code class="nx">Pool</code> <code class="p">}</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'pg'</code><code class="p">);</code>&#13;
<code class="kr">const</code> <code class="nx">db</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">Pool</code><code class="p">({</code>&#13;
  <code class="nx">host</code><code class="o">:</code> <code class="s1">'localhost'</code><code class="p">,</code> <code class="nx">port</code><code class="o">:</code> <code class="mi">5432</code><code class="p">,</code>&#13;
  <code class="nx">user</code><code class="o">:</code> <code class="s1">'user'</code><code class="p">,</code> <code class="nx">password</code><code class="o">:</code> <code class="s1">'hunter2'</code><code class="p">,</code>&#13;
  <code class="nx">database</code><code class="o">:</code> <code class="s1">'dbconn'</code><code class="p">,</code> <code class="nx">max</code><code class="o">:</code> <code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">MAX_CONN</code> <code class="o">||</code> <code class="mi">10</code>&#13;
<code class="p">});</code>&#13;
<code class="nx">db</code><code class="p">.</code><code class="nx">connect</code><code class="p">();</code>&#13;
&#13;
<code class="kr">const</code> <code class="nx">server</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'fastify'</code><code class="p">)();</code>&#13;
<code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/'</code><code class="p">,</code> <code class="nx">async</code> <code class="p">()</code> <code class="o">=&gt;</code> <code class="p">(</code>&#13;
  <code class="nx">await</code> <code class="nx">db</code><code class="p">.</code><code class="nx">query</code><code class="p">(</code><code class="s2">"SELECT NOW() AS time, 'world' AS hello"</code><code class="p">)).</code><code class="nx">rows</code><code class="p">[</code><code class="mi">0</code><code class="p">]);</code>&#13;
<code class="nx">server</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="mi">3000</code><code class="p">,</code> <code class="p">()</code> <code class="o">=&gt;</code> <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`http://localhost:3000`</code><code class="p">));</code></pre></div>&#13;
&#13;
<p>The connection establishment is mostly the same, but in this case, a property named <code>max</code> has been added. This property represents the maximum number of connections that the process should have to the Postgres database. In this case, it’s pulling the value from the <code>MAX_CONN</code> environment variable or falling back to 10 if it’s missing. Internally, the <code>pg.Pool</code> class also defaults to a connection pool size of 10.</p>&#13;
&#13;
<p>How many connections should <a data-primary="database connections" data-secondary="number of connections" data-type="indexterm" id="idm46291177422600"/>your application use? The best way to determine that is to run some real-world benchmarks in a production setting, generating traffic at a certain request rate and seeing how many connections it takes to maintain your desired throughput. Perhaps you’ll find that the default 10 works for you. At any rate, you should try to use the lowest number of database connections that will work to reach your performance needs. Keeping this number low is important for a few &#13;
<span class="keep-together">reasons.</span></p>&#13;
&#13;
<p>One reason to minimize database connections is that there is a finite number of connections that a database will accept. In fact, the default number of connections that a Postgres database will accept is 100. This number can be configured per database server. Managed Postgres installations like AWS RDS have different connection limitations based on tier.</p>&#13;
&#13;
<p>If you go over the number of available connections, then the Postgres database server will refuse subsequent connections. This is something that you can simulate locally. The Postgres server that you’re running in Docker should be configured to have a maximum of 100 connections. Run the following commands in two separate terminal windows. The first will run the <em>dbconn/pool.js</em> service using up to 100 connections, and the second will hit the service with so many requests that it’ll be forced to use the entire connection pool:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ MAX_CONN</code><code class="o">=</code><code class="m">100</code> node ./dbconn/pool.js&#13;
<code class="nv">$ </code>autocannon -c <code class="m">200</code> http://localhost:3000/</pre>&#13;
&#13;
<p>Keep an eye on the terminal window where you’re running Postgres. While the tests run, you shouldn’t see anything bad happening.</p>&#13;
&#13;
<p>Kill the Node.js service once the <a data-primary="Autocannon" data-type="indexterm" id="idm46291177416296"/>Autocannon test is complete. Next, run the <em>dbconn/pool.js</em> service a second time, but this time using a pool size greater than what the server is configured to handle, and run the same Autocannon benchmark again:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ MAX_CONN</code><code class="o">=</code><code class="m">101</code> node ./dbconn/pool.js&#13;
<code class="nv">$ </code>autocannon -c <code class="m">200</code> http://localhost:3000/</pre>&#13;
&#13;
<p>This time, you should see the Postgres server complain with “FATAL: sorry, too many clients already” errors. Once the Autocannon test is complete, you should even see that the throughput is slightly lower.</p>&#13;
&#13;
<p>If you would like to know how many connections a particular Postgres database is configured to handle (for example, when using a managed instance) run the following query:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">SELECT</code> <code class="o">*</code> <code class="k">FROM</code> <code class="n">pg_settings</code> <code class="k">WHERE</code> <code class="n">name</code> <code class="o">=</code> <code class="s1">'max_connections'</code><code class="p">;</code></pre>&#13;
&#13;
<p>The maximum number of connections can be increased, but there is at least a small amount of overhead required for the server to handle the connections. If not, the default would be infinity. When choosing a connection count, you’ll probably need to make sure the number of connections used per process multiplied by the number of processes running at once is less than half of the number of connections the Postgres server can handle. This half part is important because if you deploy a new set of processes to replace the old processes, then there’s a small amount of time where both the new and old instances need to run with overlap.</p>&#13;
&#13;
<p>So, if your server has a maximum of 100 connections available and you’re running 6 service instances, then the maximum number of connections each process can make is 8:</p>&#13;
&#13;
<pre data-type="programlisting">100 / 2 = 50 ; 50 / 6 = 8.3</pre>&#13;
&#13;
<p>One tactic I’ve seen at companies is that they’ll scale up beyond this maximum number of processes (like scaling up to 10 processes consuming a total of 80 connections). But when it’s time to do a deployment, they’ll scale back down the safe number of instances (6 in this case) during off periods, do a deployment, and then scale back up. While I can’t necessarily recommend this approach, I’d be lying if I said I wasn’t guilty of it myself.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>One thing to be careful of, especially with Node.js projects, is requiring a database singleton module. In my experience, it’s pretty common to have a file require a database package, make the connection, and export the database instance. It’s also very easy for a spiderweb of <code>require()</code> statements to require such a module. This can result in sidecar processes making unnecessary connections with no visibility that such a connection was made.</p>&#13;
</div>&#13;
&#13;
<p>Connection pooling isn’t just about resilience; it’s also about performance. The Postgres database, for example, isn’t able to handle multiple queries sent through the same connection at the same time. Instead, each query needs to finish before the following query can be sent, serially.</p>&#13;
&#13;
<p>This serial processing of queries can be seen in <a data-type="xref" href="#ex_database_serial">Example 8-10</a>.</p>&#13;
<div data-type="example" id="ex_database_serial">&#13;
<h5><span class="label">Example 8-10. </span><em>dbconn/serial.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="c-Hashbang">#!/usr/bin/env node&#13;
</code><code class="c1">// npm install pg@8.2&#13;
</code><code class="kr">const</code><code> </code><code class="p">{</code><code> </code><code class="nx">Client</code><code> </code><code class="p">}</code><code> </code><code class="o">=</code><code> </code><code class="nx">require</code><code class="p">(</code><code class="s1">'pg'</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="kr">const</code><code> </code><code class="nx">db</code><code> </code><code class="o">=</code><code> </code><code class="k">new</code><code> </code><code class="nx">Client</code><code class="p">(</code><code class="p">{</code><code>&#13;
  </code><code class="nx">host</code><code class="o">:</code><code> </code><code class="s1">'localhost'</code><code class="p">,</code><code> </code><code class="nx">port</code><code class="o">:</code><code> </code><code class="mi">5432</code><code class="p">,</code><code>&#13;
  </code><code class="nx">user</code><code class="o">:</code><code> </code><code class="s1">'user'</code><code class="p">,</code><code> </code><code class="nx">password</code><code class="o">:</code><code> </code><code class="s1">'hunter2'</code><code class="p">,</code><code>&#13;
  </code><code class="nx">database</code><code class="o">:</code><code> </code><code class="s1">'dbconn'</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="nx">db</code><code class="p">.</code><code class="nx">connect</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">(</code><code class="nx">async</code><code> </code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">=&gt;</code><code> </code><code class="p">{</code><code>&#13;
  </code><code class="kr">const</code><code> </code><code class="nx">start</code><code> </code><code class="o">=</code><code> </code><code class="nb">Date</code><code class="p">.</code><code class="nx">now</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">await</code><code> </code><code class="nb">Promise</code><code class="p">.</code><code class="nx">all</code><code class="p">(</code><code class="p">[</code><code> </code><a class="co" href="#callout_resilience_CO6-1" id="co_resilience_CO6-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
    </code><code class="nx">db</code><code class="p">.</code><code class="nx">query</code><code class="p">(</code><code class="s2">"SELECT pg_sleep(2);"</code><code class="p">)</code><code class="p">,</code><code>&#13;
    </code><code class="nx">db</code><code class="p">.</code><code class="nx">query</code><code class="p">(</code><code class="s2">"SELECT pg_sleep(2);"</code><code class="p">)</code><code class="p">,</code><code>&#13;
  </code><code class="p">]</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`</code><code class="sb">took </code><code class="si">${</code><code class="p">(</code><code class="nb">Date</code><code class="p">.</code><code class="nx">now</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">-</code><code> </code><code class="nx">start</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="mi">1000</code><code class="si">}</code><code class="sb"> seconds</code><code class="sb">`</code><code class="p">)</code><code class="p">;</code><code>&#13;
  </code><code class="nx">db</code><code class="p">.</code><code class="nx">end</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code class="p">}</code><code class="p">)</code><code class="p">(</code><code class="p">)</code><code class="p">;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_resilience_CO6-1" id="callout_resilience_CO6-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Two slow queries are sent at the same time.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This application makes a single connection to the Postgres database and then sends two requests at the same time. Each of the requests is making use of the <code>pg_sleep()</code> function, which, in this case, will cause the connection to pause for two seconds, simulating a slow query. When I run this application locally, I get the message “took 4.013 seconds” as a response.</p>&#13;
&#13;
<p>Modify the <a data-type="xref" href="#ex_database_serial">Example 8-10</a> code by replacing the two occurrences of <code>Client</code> with <code>Pool</code> and run the application again. This results in a pool with a maximum size of 10. The <code>pg</code> package uses two of those connections to run the two queries. On my machine, the <a data-primary="resilience" data-secondary="database connections" data-startref="res_data" data-type="indexterm" id="idm46291177399896"/><a data-primary="database connections" data-secondary="resilience" data-startref="data_res" data-type="indexterm" id="idm46291177370248"/><a data-primary="database connections" data-secondary="PostgreSQL and" data-startref="post_SQL" data-type="indexterm" id="idm46291177369032"/><a data-primary="resilience" data-secondary="database connections" data-startref="post_SQL2" data-tertiary="PostgreSQL and" data-type="indexterm" id="idm46291177298952"/><a data-primary="PostgreSQL" data-secondary="database connection resilience" data-startref="post_SQL3" data-type="indexterm" id="idm46291177297464"/><a data-primary="database connections" data-secondary="connection pooling" data-startref="connpool" data-type="indexterm" id="idm46291177296280"/><a data-primary="connection pooling" data-startref="connpool1" data-type="indexterm" id="idm46291177146344"/>program now prints the message “took 2.015 seconds.”</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Schema Migrations with Knex" data-type="sect1"><div class="sect1" id="ch_resilience_sec_migrations">&#13;
<h1>Schema Migrations with Knex</h1>&#13;
&#13;
<p>Knex is a popular SQL query <a data-primary="resilience" data-secondary="schema migration" data-tertiary="Knex" data-type="indexterm" id="migknex"/><a data-primary="schema migration" data-secondary="Knex and" data-type="indexterm" id="idm46291177142312"/><a data-primary="Knex" data-type="indexterm" id="idm46291177141368"/>builder package. It’s relied upon by many higher-level ORM (Object-Relational Mapping) packages. If you’ve worked on a few Node.js projects that interact with an SQL database, then chances are good that you have come into contact with Knex at some point.</p>&#13;
&#13;
<p>While Knex is usually heralded for its ability to generate SQL queries (reducing the need to dangerously concatenate SQL strings together), the functionality covered in this section is that of its lesser-known <a class="orm:hideurl" href="https://knexjs.org/#Migrations">schema migration</a> features.</p>&#13;
&#13;
<p>A <em>schema migration</em> is a change that is made to a database schema in a way that is incremental, reversible, and can be represented using code that can be checked into version control. Since application data storage requirements change all the time, such schema migrations need to be incremental. Each new feature may be represented by one or more migrations. Since application changes occasionally need to be rolled back, these schema migrations must be reversible as well. Finally, since a repository should be the source of truth for representing an application, it’s incredibly convenient to check in schema migrations.</p>&#13;
&#13;
<p>Each schema migration ultimately executes SQL <a data-primary="schema migration" data-secondary="SQL queries" data-type="indexterm" id="idm46291177132632"/>queries to alter the state of the database. Often a later migration will build upon a change made in an earlier migration. For this reason, the order in which database migrations are applied matters greatly. The most basic approach to building out database migrations could be to maintain a list of numbered SQL files and to execute them one after another, with paired SQL files for reversing the changes:</p>&#13;
&#13;
<pre data-type="programlisting">000001.sql  000001-reverse.sql&#13;
000002.sql  000002-reverse.sql&#13;
000003.sql  000003-reverse.sql</pre>&#13;
&#13;
<p>One problem with this approach is that the filenames aren’t all that descriptive. Which file accidentally turned all users into administrators? Another problem is a race condition between two people making code changes. When two engineers create a file named <em>000004.sql</em> in two separate pull requests, the second branch to be merged needs to modify the commit to rename the file to <em>000005.sql</em>.</p>&#13;
&#13;
<p>A common migration approach, the <a data-primary="schema migration" data-secondary="timestamp" data-type="indexterm" id="idm46291177128248"/><a data-primary="Knex" data-secondary="timestamp" data-type="indexterm" id="idm46291177127272"/>same employed by Knex, is to instead use a timestamp and a feature name as the name of the file. This maintains order, solves the issue with name collisions, gives the file a descriptive name, and even lets the developer know when the schema migration was first conceived. Wrapping the queries in a non-SQL file allows for combining the migration and reverse migration. These migration filenames end up looking like this:</p>&#13;
&#13;
<pre data-type="programlisting">20200523133741_create_users.js&#13;
20200524122328_create_groups.js&#13;
20200525092142_make_admins.js</pre>&#13;
&#13;
<p>An entire list of migrations doesn’t need to be applied every time a new version of the application is checked out. Instead, only migrations that are newer than the last migration that was run need to be applied. Knex, and most other schema migration tools, tracks which migrations are run in a special database table. The only thing that makes the table special is that the application itself will probably never touch it. Such a table can be as simple as a single row with a “last schema filename run” column or as complex as containing meta information about each time migrations are run. The important part is that it maintains some sort of reference to the last-run migration. The default name of this table in Knex is <code>knex_migrations</code>.</p>&#13;
&#13;
<p>When doing development as part of a team for an application that uses database migrations, the workflow often requires that you frequently pull source code from the central repository. If any changes are committed to a schema migration directory, you’ll then need to apply some schema modifications. If you don’t do that, then the newer application code may be incompatible with your older database schema, resulting in runtime errors. Once you apply the migrations locally, you’re then free to make modifications of your own.</p>&#13;
&#13;
<p>Now that you’re familiar with the theory behind schema migrations, you’re ready to write some of your own.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Configuring Knex" data-type="sect2"><div class="sect2" id="idm46291177121752">&#13;
<h2>Configuring Knex</h2>&#13;
&#13;
<p>First, create a new <a data-primary="schema migration" data-secondary="Knex and" data-tertiary="configuring Knex" data-type="indexterm" id="configKnex"/><a data-primary="Knex" data-secondary="configuring" data-type="indexterm" id="configKnex1"/><a data-primary="knexfile.js file" data-type="indexterm" id="idm46291177031416"/>directory named <em>migrations/</em> to represent a new application that will use migrations and initialize a new npm project. Next, install the <code>knex</code> package <a data-primary="knex package" data-type="indexterm" id="idm46291177029784"/><a data-primary="packages" data-secondary="knex" data-type="indexterm" id="idm46291177029176"/>in this directory. For ease of running the migration scripts, you also need <code>knex</code> installed as a global package—this isn’t required for a regular application where you might wrap the locally installed Knex with <em>package.json</em> scripts, but it will make things more convenient for now.<sup><a data-type="noteref" href="ch08.html#idm46291177027288" id="idm46291177027288-marker">6</a></sup> Finally, initialize a Knex project, which creates a configuration file for you. This can all be done by running the following commands:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>mkdir migrations <code class="o">&amp;&amp;</code> <code class="nb">cd </code>migrations&#13;
<code class="nv">$ </code>npm init -y&#13;
<code class="nv">$ </code>npm install knex@0.21 pg@8.2&#13;
<code class="nv">$ </code>npm install -g knex@0.21&#13;
<code class="nv">$ </code>knex init</pre>&#13;
&#13;
<p>Knex created a file for you named <em>knexfile.js</em>, which is used by the <code>knex</code> CLI utility to connect to your database. The file contains configuration and could be represented with a declarative format like YAML, but it’s common to pull in environment <a data-primary="Knex" data-secondary="environment variables" data-type="indexterm" id="idm46291177023624"/><a data-primary="environment variables" data-secondary="Knex and" data-type="indexterm" id="idm46291177022680"/>variables, which is why JavaScript is the default format. Open the file with a text editor to view its content. The file currently exports a single object with keys representing &#13;
<span class="keep-together">environment</span> names and values representing configuration. By defaul, the <em>development</em> environment uses <em>SQLite</em>, while the <em>staging</em> and <em>production</em> databases are set to &#13;
<span class="keep-together">Postgres.</span></p>&#13;
&#13;
<p>By having different environments defined within <em>knexfile.js</em>, you’re able to apply migrations to database servers across those different environments. For this project, you’re only going to use a single <em>development</em> configuration. Modify your <em>migrations/knexfile.js</em> file to resemble <a data-type="xref" href="#ex_migration_knexfile">Example 8-11</a>.</p>&#13;
<div data-type="example" id="ex_migration_knexfile">&#13;
<h5><span class="label">Example 8-11. </span><em>migrations/knexfile.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">module</code><code class="p">.</code><code class="nx">exports</code> <code class="o">=</code> <code class="p">{</code>&#13;
  <code class="nx">development</code><code class="o">:</code> <code class="p">{</code>&#13;
    <code class="nx">client</code><code class="o">:</code> <code class="s1">'pg'</code><code class="p">,</code>&#13;
    <code class="nx">connection</code><code class="o">:</code> <code class="p">{</code>&#13;
      <code class="nx">host</code><code class="o">:</code> <code class="s1">'localhost'</code><code class="p">,</code> <code class="nx">port</code><code class="o">:</code> <code class="mi">5432</code><code class="p">,</code>&#13;
      <code class="nx">user</code><code class="o">:</code> <code class="s1">'user'</code><code class="p">,</code> <code class="nx">password</code><code class="o">:</code> <code class="s1">'hunter2'</code><code class="p">,</code>&#13;
      <code class="nx">database</code><code class="o">:</code> <code class="s1">'dbconn'</code>&#13;
    <code class="p">}</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">};</code></pre></div>&#13;
&#13;
<p>Once that’s done, you’re ready to test the database connections. Run the following command:</p>&#13;
&#13;
<pre data-type="programlisting">$ knex migrate:currentVersion&#13;
&gt; Using environment: development&#13;
&gt; Current Version: none</pre>&#13;
&#13;
<p>The command displays <a data-primary="schema migration" data-secondary="NOD_ENV environment variable" data-type="indexterm" id="idm46291176945432"/><a data-primary="NODE_ENV environment variable" data-type="indexterm" id="idm46291176944584"/>the environment being used. (It defaults to <em>development</em> but can be overwritten using the <code>NODE_ENV</code> environment variable.) It also displays the migration version, which in this case is <code>none</code>. If you get an error, you may need to either modify the connection <a data-primary="schema migration" data-secondary="Knex and" data-startref="configKnex" data-tertiary="configuring Knex" data-type="indexterm" id="idm46291176942600"/><a data-primary="Knex" data-secondary="configuring" data-startref="configKnex1" data-type="indexterm" id="idm46291176941080"/>file or go back and run the Docker command to start Postgres, defined in <a data-type="xref" href="#ch_resilience_sec_db_subsec_runpg">“Running PostgreSQL”</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Creating a Schema Migration" data-type="sect2"><div class="sect2" id="idm46291176938968">&#13;
<h2>Creating a Schema Migration</h2>&#13;
&#13;
<p>Now that <a data-primary="schema migration" data-secondary="Knex and" data-tertiary="creating" data-type="indexterm" id="scheme_create"/><a data-primary="Knex" data-secondary="schema migration" data-tertiary="creating" data-type="indexterm" id="scheme_create1"/>you’re able to connect to the database, it’s time to create your first schema migration. In this case, the migration is going to create a <em>users</em> table in the database. Run the following commands to create the migration and then to view a list of &#13;
<span class="keep-together">migrations:</span></p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>knex migrate:make create_users&#13;
<code class="nv">$ </code>ls migrations</pre>&#13;
&#13;
<p>The <code>knex migrate:make</code> command has created <a data-primary="Knex" data-secondary="migrations/ directory" data-type="indexterm" id="idm46291176930504"/>a new <em>migrations/</em> directory, which is what Knex uses for keeping track of the schema migration files. It also generated a schema migration file for you. In my case, the name of the migration file &#13;
<span class="keep-together">is <em>20200525141008_create_users.js</em>.</span> Yours will have a more recent date as part of the &#13;
<span class="keep-together">filename.</span></p>&#13;
&#13;
<p>Next, modify your schema migration file to contain the content displayed in <a data-type="xref" href="#ex_migration_sql_migrate_up">Example 8-12</a>.</p>&#13;
<div data-type="example" id="ex_migration_sql_migrate_up">&#13;
<h5><span class="label">Example 8-12. </span><em>migrations/migrations/20200525141008_create_users.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">module</code><code class="p">.</code><code class="nx">exports</code><code class="p">.</code><code class="nx">up</code> <code class="o">=</code> <code class="nx">async</code> <code class="p">(</code><code class="nx">knex</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="nx">await</code> <code class="nx">knex</code><code class="p">.</code><code class="nx">schema</code><code class="p">.</code><code class="nx">createTable</code><code class="p">(</code><code class="s1">'users'</code><code class="p">,</code> <code class="p">(</code><code class="nx">table</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
    <code class="nx">table</code><code class="p">.</code><code class="nx">increments</code><code class="p">(</code><code class="s1">'id'</code><code class="p">).</code><code class="nx">unsigned</code><code class="p">().</code><code class="nx">primary</code><code class="p">();</code>&#13;
    <code class="nx">table</code><code class="p">.</code><code class="nx">string</code><code class="p">(</code><code class="s1">'username'</code><code class="p">,</code> <code class="mi">24</code><code class="p">).</code><code class="nx">unique</code><code class="p">().</code><code class="nx">notNullable</code><code class="p">();</code>&#13;
  <code class="p">});</code>&#13;
&#13;
  <code class="nx">await</code> <code class="nx">knex</code><code class="p">(</code><code class="s1">'users'</code><code class="p">)</code>&#13;
    <code class="p">.</code><code class="nx">insert</code><code class="p">([</code>&#13;
      <code class="p">{</code><code class="nx">username</code><code class="o">:</code> <code class="s1">'tlhunter'</code><code class="p">},</code>&#13;
      <code class="p">{</code><code class="nx">username</code><code class="o">:</code> <code class="s1">'steve'</code><code class="p">},</code>&#13;
      <code class="p">{</code><code class="nx">username</code><code class="o">:</code> <code class="s1">'bob'</code><code class="p">},</code>&#13;
    <code class="p">]);</code>&#13;
<code class="p">};</code>&#13;
&#13;
<code class="nx">module</code><code class="p">.</code><code class="nx">exports</code><code class="p">.</code><code class="nx">down</code> <code class="o">=</code> <code class="p">(</code><code class="nx">knex</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="nx">knex</code><code class="p">.</code><code class="nx">schema</code><code class="p">.</code><code class="nx">dropTable</code><code class="p">(</code><code class="s1">'users'</code><code class="p">);</code></pre></div>&#13;
&#13;
<p>By default, schema migrations <a data-primary="up() function" data-type="indexterm" id="idm46291176917816"/><a data-primary="functions" data-secondary="up()" data-type="indexterm" id="idm46291176917320"/><a data-primary="down() Knex function" data-type="indexterm" id="idm46291176783128"/><a data-primary="functions" data-secondary="down()" data-type="indexterm" id="idm46291176782456"/><a data-primary="schema migration" data-secondary="Knex and" data-tertiary="up() function" data-type="indexterm" id="idm46291176781512"/><a data-primary="schema migration" data-secondary="Knex and" data-tertiary="down() function" data-type="indexterm" id="idm46291176780296"/><a data-primary="Knex" data-secondary="up() function" data-type="indexterm" id="idm46291176779080"/><a data-primary="Knex" data-secondary="down() function" data-type="indexterm" id="idm46291176778136"/>export two functions, one named <code>up()</code> and one named <code>down()</code>. In this case, you’re still exporting the two functions, albeit with slightly more modern JavaScript syntax. The <code>up()</code> method is called when a schema is being applied, and the <code>down()</code> method is called when it’s being “reversed” or “rolled back.”</p>&#13;
&#13;
<p>The two methods make use of the <a data-primary="Knex" data-secondary="query builder" data-type="indexterm" id="idm46291176774760"/><a data-primary="schema migration" data-secondary="Knex and" data-tertiary="query builder" data-type="indexterm" id="idm46291176773784"/>Knex query builder interface for creating and dropping tables. The table being created is named <em>users</em> and has two columns, <em>id</em> and <em>username</em>. The query builder syntax used by Knex pretty cleanly maps to the underlying SQL query that is sent to the database. The <code>up()</code> method also inserts three users into the table.</p>&#13;
&#13;
<p>The <code>down()</code> method performs the opposite operation. Technically, since the <code>up()</code> method performed two operations (creating a table and then adding users), the <code>down()</code> method should mirror those operations (deleting the users and destroying a table). But since dropping a table implicitly destroys the entries in it, the <code>down()</code> method only needs to drop the <em>users</em> table.</p>&#13;
&#13;
<p>Next, run the following command to get a list of the migrations that Knex is currently aware of:</p>&#13;
&#13;
<pre data-type="programlisting">$ knex migrate:list&#13;
&gt; No Completed Migration files Found.&#13;
&gt; Found 1 Pending Migration file/files.&#13;
&gt; 20200525141008_create_users.js</pre>&#13;
&#13;
<p>In this case, a single migration exists and <a data-primary="schema migration" data-secondary="Knex and" data-startref="scheme_create" data-tertiary="creating" data-type="indexterm" id="idm46291176765880"/><a data-primary="Knex" data-secondary="schema migration" data-startref="scheme_create1" data-tertiary="creating" data-type="indexterm" id="idm46291176764360"/>has not yet been applied.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Applying a Migration" data-type="sect2"><div class="sect2" id="idm46291176938344">&#13;
<h2>Applying a Migration</h2>&#13;
&#13;
<p>Now that your migration is ready, it’s time to <a data-primary="schema migration" data-secondary="Knex and" data-tertiary="applying" data-type="indexterm" id="scheme_apply"/><a data-primary="Knex" data-secondary="schema migration" data-tertiary="applying" data-type="indexterm" id="scheme_apply1"/>run it. Run the following command to apply the migration:</p>&#13;
&#13;
<pre data-type="programlisting">$ knex migrate:up&#13;
&gt; Batch 1 ran the following migrations:&#13;
&gt; 20200525141008_create_users.js</pre>&#13;
&#13;
<p>The <code>knex migrate:up</code> applies the next migration in line based on the order of migration filenames. In this case, there was only a single migration to be made.</p>&#13;
&#13;
<p>Now that your migration has been executed, you should take a look at the database schema to confirm that it worked. Execute the following command to run the <code>psql</code> command <a data-primary="psql command" data-type="indexterm" id="idm46291176754744"/><a data-primary="commands" data-secondary="psql" data-type="indexterm" id="idm46291176754008"/>inside of the Postgres Docker container:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>docker <code class="nb">exec</code> <code class="se">\</code>&#13;
  -it distnode-postgres <code class="se">\</code>&#13;
  psql -U user -W dbconn</pre>&#13;
&#13;
<p>When prompted, enter the password <strong><code>hunter2</code></strong> and press enter. Once that’s done, you’re now using an interactive Postgres terminal client. Commands entered in this client will take place in the <em>dbconn</em> database. For now, it would be useful to get a list of the tables stored in the database. Within the prompt, type <strong><code>\dt</code></strong> to do just that. When I run that command on my machine, I get the following results:</p>&#13;
&#13;
<pre data-type="programlisting"> Schema |         Name         | Type  | Owner&#13;
--------+----------------------+-------+-------&#13;
 public | knex_migrations      | table | user&#13;
 public | knex_migrations_lock | table | user&#13;
 public | users                | table | user</pre>&#13;
&#13;
<p>The <code>users</code> entry refers to the users table that was created when you ran the database migration. Next, to see the entries inside this table, type the command <strong><code>SELECT * FROM users;</code></strong> and press enter again. You should see results like these:</p>&#13;
&#13;
<pre data-type="programlisting"> id | username&#13;
----+----------&#13;
  1 | tlhunter&#13;
  2 | steve&#13;
  3 | bob</pre>&#13;
&#13;
<p>In this case, the three users that were created as part of the migration script are &#13;
<span class="keep-together">displayed.</span></p>&#13;
&#13;
<p>The Knex query builder has converted the query that you represented by chaining JavaScript object methods into an equivalent SQL query. In this case, the table that is generated inside of the database could have been created by using the following SQL query:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">CREATE</code> <code class="k">TABLE</code> <code class="n">users</code> <code class="p">(</code>&#13;
  <code class="n">id</code> <code class="nb">serial</code> <code class="k">NOT</code> <code class="k">NULL</code><code class="p">,</code>&#13;
  <code class="n">username</code> <code class="nb">varchar</code><code class="p">(</code><code class="mi">24</code><code class="p">)</code> <code class="k">NOT</code> <code class="k">NULL</code><code class="p">,</code>&#13;
  <code class="k">CONSTRAINT</code> <code class="n">users_pkey</code> <code class="k">PRIMARY</code> <code class="k">KEY</code> <code class="p">(</code><code class="n">id</code><code class="p">),</code>&#13;
  <code class="k">CONSTRAINT</code> <code class="n">users_username_unique</code> <code class="k">UNIQUE</code> <code class="p">(</code><code class="n">username</code><code class="p">));</code></pre>&#13;
&#13;
<p>While you’re still running the Postgres client, it’s worth taking a look at the migrations table that Knex also created. Run another query, <strong><code>SELECT * FROM knex_migrations;</code></strong>, and press enter. On my machine, I get the following results back:</p>&#13;
&#13;
<pre data-type="programlisting"> id |              name              | batch |      migration_time&#13;
----+--------------------------------+-------+---------------------------&#13;
  2 | 20200525141008_create_users.js |     1 | 2020-05-25 22:17:19.15+00</pre>&#13;
&#13;
<p>In this case, the <em>20200525141008_create_users.js</em> migration is the only migration that has been executed. Some additional meta information about the query is also stored. Since migration information is stored in a database, any developer would be able to run additional migrations for a remote database host, such as a production database, without the need to keep track of which migrations had been run previously.</p>&#13;
&#13;
<p>The other table, <code>knex_migrations_lock</code>, isn’t as interesting. It’s used to create a lock so that multiple people don’t attempt to run migrations simultaneously, which could result in a corrupted database.</p>&#13;
&#13;
<p>The only thing more exciting than one migration is two migrations, so go ahead and create another one. This second migration builds on the changes made in the first migration. Again, run a command to create a new migration file:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>knex migrate:make create_groups</pre>&#13;
&#13;
<p>Next, modify the migration file that was created. Make the file resemble the code in <a data-type="xref" href="#ex_migration_sql_migrate_up2">Example 8-13</a>.</p>&#13;
<div data-type="example" id="ex_migration_sql_migrate_up2">&#13;
<h5><span class="label">Example 8-13. </span><em>migrations/migrations/20200525172807_create_groups.js</em></h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">module</code><code class="p">.</code><code class="nx">exports</code><code class="p">.</code><code class="nx">up</code> <code class="o">=</code> <code class="nx">async</code> <code class="p">(</code><code class="nx">knex</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="nx">await</code> <code class="nx">knex</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code><code class="sb">`CREATE TABLE groups (</code>&#13;
<code class="sb">    id SERIAL PRIMARY KEY,</code>&#13;
<code class="sb">    name VARCHAR(24) UNIQUE NOT NULL)`</code><code class="p">);</code>&#13;
  <code class="nx">await</code> <code class="nx">knex</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code><code class="sb">`INSERT INTO groups (id, name) VALUES</code>&#13;
<code class="sb">    (1, 'Basic'), (2, 'Mods'), (3, 'Admins')`</code><code class="p">);</code>&#13;
  <code class="nx">await</code> <code class="nx">knex</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code><code class="sb">`ALTER TABLE users ADD COLUMN</code>&#13;
<code class="sb">    group_id INTEGER NOT NULL REFERENCES groups (id) DEFAULT 1`</code><code class="p">);</code>&#13;
<code class="p">};</code>&#13;
&#13;
<code class="nx">module</code><code class="p">.</code><code class="nx">exports</code><code class="p">.</code><code class="nx">down</code> <code class="o">=</code> <code class="nx">async</code> <code class="p">(</code><code class="nx">knex</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="nx">await</code> <code class="nx">knex</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code><code class="sb">`ALTER TABLE users DROP COLUMN group_id`</code><code class="p">);</code>&#13;
  <code class="nx">await</code> <code class="nx">knex</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code><code class="sb">`DROP TABLE groups`</code><code class="p">);</code>&#13;
<code class="p">};</code></pre></div>&#13;
&#13;
<p>This time, raw queries are being executed instead of using the query builder. Both approaches are fine when representing schema migrations. In fact, some queries may be difficult to represent using the query builder and may be better served by using raw query strings.</p>&#13;
&#13;
<p>This query creates an additional table named <code>groups</code> and also alters the <code>users</code> table to have a <code>group_id</code> column that references the <code>groups</code> table. In this case, the second migration absolutely depends on the first migration.</p>&#13;
&#13;
<p>Now that your second migration is ready, go ahead and apply it. This time, you’re going to use a slightly different command:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>knex migrate:latest</pre>&#13;
&#13;
<p>This command tells Knex to run every migration, starting with the migration following the current representation of the database, until the final migration. In this case, only a single migration is run, specifically the <em>create_groups</em> migration. In general, you’re likely to run this version of the <code>migrate</code> command <a data-primary="migrate command" data-type="indexterm" id="idm46291176503672"/><a data-primary="commands" data-secondary="migrate" data-type="indexterm" id="idm46291176503144"/>the most frequently, such as whenever <a data-primary="schema migration" data-secondary="Knex and" data-startref="scheme_apply" data-tertiary="applying" data-type="indexterm" id="idm46291176502072"/><a data-primary="Knex" data-secondary="schema migration" data-startref="scheme_apply1" data-tertiary="applying" data-type="indexterm" id="idm46291176499784"/>you pull from the master branch of a repository.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Rolling Back a Migration" data-type="sect2"><div class="sect2" id="idm46291176761784">&#13;
<h2>Rolling Back a Migration</h2>&#13;
&#13;
<p>Sometimes an erroneous schema <a data-primary="schema migration" data-secondary="Knex and" data-tertiary="rollbacks" data-type="indexterm" id="schema_roll"/><a data-primary="Knex" data-secondary="rollbacks" data-type="indexterm" id="knex_roll"/><a data-primary="rollbacks" data-secondary="schema migration" data-type="indexterm" id="roll_schema"/>change will make its way into a migration file. Perhaps such a schema change is destructive and leads to data loss. Or perhaps a schema change adds support for a new feature that ends up getting dropped. In any case, such a migration change will need to be reversed. When this happens, you can run the following command to undo the last migration:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>knex migrate:down</pre>&#13;
&#13;
<p>In my case, when I run this locally, I get the following output:</p>&#13;
&#13;
<pre data-type="programlisting">Batch 2 rolled back the following migrations:&#13;
20200525172807_create_groups.js</pre>&#13;
&#13;
<p>Once this command has been run, the second migration will be rolled back, but the first migration will still be present. In this case, the SQL statements in the <code>down()</code> method of the <em>create_groups</em> migration have been executed. Feel free to run the <strong><code>knex migrate:list</code></strong> command at this point if you don’t believe me.</p>&#13;
&#13;
<p>There’s no way that Knex can enforce that a down migration will completely undo the changes made by an up migration. That is ultimately up to the engineer to do. Unfortunately some operations just don’t have a correlating undo. As an example of this, imagine the following up and down migrations:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="c1">-- WARNING: DESTRUCTIVE MIGRATION!</code>&#13;
<code class="c1">-- MIGRATE UP</code>&#13;
<code class="k">ALTER</code> <code class="k">TABLE</code> <code class="n">users</code> <code class="k">DROP</code> <code class="k">COLUMN</code> <code class="n">username</code><code class="p">;</code>&#13;
<code class="c1">-- MIGRATE DOWN</code>&#13;
<code class="k">ALTER</code> <code class="k">TABLE</code> <code class="n">users</code> <code class="k">ADD</code> <code class="k">COLUMN</code> <code class="n">username</code> <code class="nb">VARCHAR</code><code class="p">(</code><code class="mi">24</code><code class="p">)</code> <code class="k">UNIQUE</code> <code class="k">NOT</code> <code class="k">NULL</code><code class="p">;</code></pre>&#13;
&#13;
<p>In this case, the up migration drops the <em>username</em> column, and the down migration adds the <em>username</em> column back. But the data that existed in the column has now been destroyed, and no amount of reverse migrations is going to get it back, either. What’s more, assuming there’s at least one user in the table, the down migration will fail because the unique constraint won’t be met—every username will be set to a null value!</p>&#13;
&#13;
<p>One way these issues are sometimes discovered is after a code commit has been merged. For example, maybe a bad migration was merged and then run against the staging environment. At this point, all of the user accounts in the staging database have been corrupted and might need to be repaired. Some organizations copy &#13;
<span class="keep-together">production</span> data into staging as part of a nightly task while anonymizing user data. In this case, the data will eventually be repaired in staging. Such safeguards aren’t always present for production.</p>&#13;
&#13;
<p>In these situations, the migration should never be run in production. The way Knex works is that it runs each migration serially until the most recent is run. One way to fix these situations is to run the appropriate migrate down commands anywhere the database has been affected (in this case, the staging environment and the developer’s local environment). Next, delete the erroneous migration file entirely. This can probably be done in a single revert commit.</p>&#13;
&#13;
<p>Later, when a future migration is run against the production database, the destructive migration won’t be present at all, <a data-primary="schema migration" data-secondary="Knex and" data-startref="schema_roll" data-tertiary="rollbacks" data-type="indexterm" id="idm46291176398392"/><a data-primary="Knex" data-secondary="rollbacks" data-startref="knex_roll" data-type="indexterm" id="idm46291176396872"/><a data-primary="rollbacks" data-secondary="schema migration" data-startref="roll_schema" data-type="indexterm" id="idm46291176395656"/>and the data loss should be avoided.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Live Migrations" data-type="sect2"><div class="sect2" id="idm46291176498040">&#13;
<h2>Live Migrations</h2>&#13;
&#13;
<p>It’s nearly impossible to <a data-primary="schema migration" data-secondary="Knex and" data-tertiary="live migrations" data-type="indexterm" id="livemigrate"/><a data-primary="Knex" data-secondary="live migration" data-type="indexterm" id="livemigrate2"/><a data-primary="live migration" data-type="indexterm" id="livemigrate3"/>time a database migration to happen at the exact moment that application code changes are deployed. The timing difference between these two operations is further complicated by migrations that take a long time to complete, like when a database table contains many rows that need to be backfilled, as well as due to the need to run multiple service instances, particularly when old and new versions overlap during deployment.</p>&#13;
&#13;
<p>This difference in timing can lead to an application deployment that is momentarily broken. <a data-type="xref" href="#fig_migration_broken">Figure 8-2</a> shows how such a situation can occur.</p>&#13;
&#13;
<figure><div class="figure" id="fig_migration_broken">&#13;
<img alt="First, the database and application are compatible. Next, a database migration makes them incompatible. Finally, a deployment makes them compatible again." src="assets/dsnj_0802.png"/>&#13;
<h6><span class="label">Figure 8-2. </span>Broken migration timeline</h6>&#13;
</div></figure>&#13;
&#13;
<p>In this case, the application is running just fine at 15:00. At 15:01, a migration is applied, and the application code has become incompatible with the database schema. The application is currently broken. Next, a code deployment happens at 15:02. Once that happens, the application and schema are now compatible again.</p>&#13;
&#13;
<p>One way to mitigate this incompatibility is to put an application in “maintenance mode.” In this mode, requests from users are blocked before they can reach the application. One way to do this is to configure a reverse proxy to serve a static maintenance page, deploy application code and apply database migrations, and then disable the maintenance page. If your application is only used during certain times of the day and by users in a limited geographical region, then performing such a migration during off-hours might be acceptable. But if you receive traffic during all hours, then such an approach is going to result in a poor user experience.</p>&#13;
&#13;
<p>A <em>live migration</em> is a migration that happens in a way that doesn’t cause the application to go offline. Simple operations, such as adding a new optional database column, can take place using a single commit. This commit can contain the migration to add the column and the code change to read and write to the column, provided the migration is run first. More complex migrations, however, take multiple commits, each with different combinations of code changes and migration changes, in order to prevent a breaking change from happening.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Live migration scenario" data-type="sect3"><div class="sect3" id="idm46291176381528">&#13;
<h3>Live migration scenario</h3>&#13;
&#13;
<p>As an example of this, pretend that you have the following database table being used by your application:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">CREATE</code> <code class="k">TABLE</code> <code class="n">people</code> <code class="p">(</code>&#13;
  <code class="n">id</code> <code class="nb">SERIAL</code><code class="p">,</code>&#13;
  <code class="n">fname</code> <code class="nb">VARCHAR</code><code class="p">(</code><code class="mi">20</code><code class="p">)</code> <code class="k">NOT</code> <code class="k">NULL</code><code class="p">,</code>&#13;
  <code class="n">lname</code> <code class="nb">VARCHAR</code><code class="p">(</code><code class="mi">20</code><code class="p">)</code> <code class="k">NOT</code> <code class="k">NULL</code><code class="p">);</code></pre>&#13;
&#13;
<p>And the corresponding application code to interact with this table looks like this:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">async</code> <code class="kd">function</code> <code class="nx">getUser</code><code class="p">(</code><code class="nx">id</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="kr">const</code> <code class="nx">result</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">db</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code>&#13;
    <code class="s1">'SELECT fname, lname FROM people WHERE id = $1'</code><code class="p">,</code> <code class="p">[</code><code class="nx">id</code><code class="p">]);</code>&#13;
  <code class="kr">const</code> <code class="nx">person</code> <code class="o">=</code> <code class="nx">result</code><code class="p">.</code><code class="nx">rows</code><code class="p">[</code><code class="mi">0</code><code class="p">];</code>&#13;
  <code class="k">return</code> <code class="p">{</code> <code class="nx">id</code><code class="p">,</code> <code class="nx">fname</code><code class="o">:</code> <code class="nx">person</code><code class="p">.</code><code class="nx">fname</code><code class="p">,</code> <code class="nx">lname</code><code class="o">:</code> <code class="nx">person</code><code class="p">.</code><code class="nx">lname</code> <code class="p">};</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="nx">async</code> <code class="kd">function</code> <code class="nx">setUser</code><code class="p">(</code><code class="nx">id</code><code class="p">,</code> <code class="nx">fname</code><code class="p">,</code> <code class="nx">lname</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="nx">await</code> <code class="nx">db</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code>&#13;
  <code class="s1">'UPDATE people SET fname = $1, lname = $2 WHERE id = $3'</code><code class="p">,</code>&#13;
    <code class="p">[</code><code class="nx">fname</code><code class="p">,</code> <code class="nx">lname</code><code class="p">,</code> <code class="nx">id</code><code class="p">]);</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>However, one day your company realizes that there are users with names that don’t match the first name and last name pattern and that it’s really just better for everyone involved to keep track of a single name entry.<sup><a data-type="noteref" href="ch08.html#idm46291176335720" id="idm46291176335720-marker">7</a></sup> In this situation, you’d like to replace the existing <code>fname</code> and <code>lname</code> columns with a <code>name</code> column. You’d also like to copy the existing name columns for use with the new name column, all without causing the application to go down.</p>&#13;
&#13;
<p>This is the perfect scenario for a multistage live migration. In this case, the transition from the old schema to the new <a data-primary="Knex" data-secondary="live migration" data-startref="livemigrate2" data-type="indexterm" id="idm46291176211880"/><a data-primary="live migration" data-startref="livemigrate3" data-type="indexterm" id="idm46291176210632"/>schema can be represented using three commits.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Commit A: Beginning the transition" data-type="sect3"><div class="sect3" id="idm46291176209432">&#13;
<h3>Commit A: Beginning the transition</h3>&#13;
&#13;
<p>For this first step, you’re going to <a data-primary="Knex" data-secondary="live migration" data-tertiary="Commit A" data-type="indexterm" id="commitA"/><a data-primary="live migration" data-secondary="Commit A" data-type="indexterm" id="commitA1"/>add the new <code>name</code> column and configure the application to write to the new column but read from either the old <code>fname</code> and <code>lname</code> columns <em>or</em> the new <code>name</code> column, whichever has data.</p>&#13;
&#13;
<p>A few migration queries need to be run for this to work. For one thing, the new <code>name</code> column needs to be added. Even though it will eventually need the same <code>NOT NULL</code> constraint used by the existing name columns, you can’t add that constraint just yet. This is because the columns will start off having no data, and the unmet constraint would cause the <code>ALTER</code> query to fail.</p>&#13;
&#13;
<p>Another change that needs to be made is that the previous <code>NOT NULL</code> constraint on the name columns needs to be dropped. This is because newly added rows won’t contain data in the old columns.</p>&#13;
&#13;
<p>Here’s what the migration <code>up()</code> queries look like:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">ALTER</code> <code class="k">TABLE</code> <code class="n">people</code> <code class="k">ADD</code> <code class="k">COLUMN</code> <code class="n">name</code> <code class="nb">VARCHAR</code><code class="p">(</code><code class="mi">41</code><code class="p">)</code> <code class="k">NULL</code><code class="p">;</code>&#13;
<code class="k">ALTER</code> <code class="k">TABLE</code> <code class="n">people</code> <code class="k">ALTER</code> <code class="k">COLUMN</code> <code class="n">fname</code> <code class="k">DROP</code> <code class="k">NOT</code> <code class="k">NULL</code><code class="p">;</code>&#13;
<code class="k">ALTER</code> <code class="k">TABLE</code> <code class="n">people</code> <code class="k">ALTER</code> <code class="k">COLUMN</code> <code class="n">lname</code> <code class="k">DROP</code> <code class="k">NOT</code> <code class="k">NULL</code><code class="p">;</code></pre>&#13;
&#13;
<p>The code should then read from the new column, if present, or fall back to data stored in the old column, as well as write to the new <code>name</code> column. In this case, a <code>name</code> column with a null value means that the row has not yet transitioned to the new format. As part of this first commit, you’ll also need to refactor the application to use a single <code>name</code> property instead of the separate <code>fname</code> and <code>lname</code> properties.</p>&#13;
&#13;
<p>The code changes look like this:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">async</code> <code class="kd">function</code> <code class="nx">getUser</code><code class="p">(</code><code class="nx">id</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="kr">const</code> <code class="nx">result</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">db</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code>&#13;
    <code class="s1">'SELECT * FROM people WHERE id = $1'</code><code class="p">,</code> <code class="p">[</code><code class="nx">id</code><code class="p">]);</code>&#13;
  <code class="kr">const</code> <code class="nx">person</code> <code class="o">=</code> <code class="nx">result</code><code class="p">.</code><code class="nx">rows</code><code class="p">[</code><code class="mi">0</code><code class="p">];</code>&#13;
  <code class="kr">const</code> <code class="nx">name</code> <code class="o">=</code> <code class="nx">person</code><code class="p">.</code><code class="nx">name</code> <code class="o">||</code> <code class="sb">`</code><code class="si">${</code><code class="nx">person</code><code class="p">.</code><code class="nx">fname</code><code class="si">}</code><code class="sb"> </code><code class="si">${</code><code class="nx">person</code><code class="p">.</code><code class="nx">lname</code><code class="si">}</code><code class="sb">`</code><code class="p">;</code>&#13;
  <code class="k">return</code> <code class="p">{</code> <code class="nx">id</code><code class="p">,</code> <code class="nx">name</code> <code class="p">};</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="nx">async</code> <code class="kd">function</code> <code class="nx">setUser</code><code class="p">(</code><code class="nx">id</code><code class="p">,</code> <code class="nx">name</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="nx">await</code> <code class="nx">db</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code>&#13;
  <code class="s1">'UPDATE people SET name = $1 WHERE id = $2'</code><code class="p">,</code>&#13;
    <code class="p">[</code><code class="nx">name</code><code class="p">,</code> <code class="nx">id</code><code class="p">]);</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>At this point, you can combine the migration and the code change into a single version control commit. You will, however, need to apply the migration before the code changes are deployed. This is because the application code now expects the <code>name</code> &#13;
<span class="keep-together">column</span> to be present, as seen in the <code>setUser()</code> function.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Commit B: Backfill" data-type="sect3"><div class="sect3" id="idm46291176208840">&#13;
<h3>Commit B: Backfill</h3>&#13;
&#13;
<p>Now it’s time to <em>backfill</em> the <code>name</code> column in <a data-primary="Knex" data-secondary="live migration" data-tertiary="Commit B" data-type="indexterm" id="commitB"/><a data-primary="live migration" data-secondary="Commit B" data-type="indexterm" id="commitB1"/>the database. A backfill is when data that is missing is retroactively provided. In this case, the <code>name</code> column needs to be set to a combination of the <code>fname</code> and <code>lname</code> fields.</p>&#13;
&#13;
<p>Such an operation can be represented using a single SQL query. In this example, the <code>up()</code> schema migration might run the following SQL command:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">UPDATE</code> <code class="n">people</code> <code class="k">SET</code> <code class="n">name</code> <code class="o">=</code> <code class="n">CONCAT</code><code class="p">(</code><code class="n">fname</code><code class="p">,</code> <code class="s1">' '</code><code class="p">,</code> <code class="n">lname</code><code class="p">)</code> <code class="k">WHERE</code> <code class="n">name</code> <code class="k">IS</code> <code class="k">NULL</code><code class="p">;</code></pre>&#13;
&#13;
<p>If your database has a lot of data, then this query will take a long time and will result in many rows being locked. When this happens, certain interactions with the database will need to wait for the migration to finish. This effectively introduces downtime to your application, the very thing you were trying to avoid with a live migration!</p>&#13;
&#13;
<p>To get around this, you may need to break the query up and run it against smaller sets of data in the database. For example, you could modify the query to affect chunks of 1,000 rows at a time by adding an additional clause to it:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">WHERE</code> <code class="n">name</code> <code class="k">IS</code> <code class="k">NULL</code> <code class="k">AND</code> <code class="n">id</code> <code class="o">&gt;=</code> <code class="mi">103000</code> <code class="k">AND</code> <code class="n">id</code> <code class="o">&lt;</code> <code class="mi">104000</code></pre>&#13;
&#13;
<p>In this example, the migration is on the 103rd iteration of a loop.</p>&#13;
&#13;
<p>Other backfill operations may require additional work. For example, if you have a column that contains a user’s GitHub numeric ID and you want to add a column that contains their GitHub username, then you would need a complex application to loop through every record in the database, make a GitHub API request, and then write the data back. Such a backfill could take days to run.</p>&#13;
&#13;
<p>No application code changes are needed to accompany this commit, so your application shouldn’t require a deployment.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Commit C: Finishing the transition" data-type="sect3"><div class="sect3" id="idm46291176032136">&#13;
<h3>Commit C: Finishing the transition</h3>&#13;
&#13;
<p>Finally, you’re ready to add the <a data-primary="Knex" data-secondary="live migration" data-tertiary="Commit C" data-type="indexterm" id="commitC"/><a data-primary="live migration" data-secondary="Commit C" data-type="indexterm" id="commitC1"/>constraints to the new column and to drop the old columns. The application code can also be modified to only look at the new column and to disregard the previous names.</p>&#13;
&#13;
<p>The <code>up()</code> migration to complete this process will involve the following queries:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">ALTER</code> <code class="k">TABLE</code> <code class="n">people</code> <code class="k">ALTER</code> <code class="k">COLUMN</code> <code class="n">name</code> <code class="k">SET</code> <code class="k">NOT</code> <code class="k">NULL</code><code class="p">;</code>&#13;
<code class="k">ALTER</code> <code class="k">TABLE</code> <code class="n">people</code> <code class="k">DROP</code> <code class="k">COLUMN</code> <code class="n">fname</code><code class="p">;</code>&#13;
<code class="k">ALTER</code> <code class="k">TABLE</code> <code class="n">people</code> <code class="k">DROP</code> <code class="k">COLUMN</code> <code class="n">lname</code><code class="p">;</code></pre>&#13;
&#13;
<p>Within this same commit, you can also finish the transition of the <code>getUser()</code> method to no longer contain the fallback for the now-missing <code>fname</code> and <code>lname</code> columns:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">async</code> <code class="kd">function</code> <code class="nx">getUser</code><code class="p">(</code><code class="nx">id</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="kr">const</code> <code class="nx">result</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">db</code><code class="p">.</code><code class="nx">raw</code><code class="p">(</code>&#13;
    <code class="s1">'SELECT name FROM people WHERE id = $1'</code><code class="p">,</code> <code class="p">[</code><code class="nx">id</code><code class="p">]);</code>&#13;
  <code class="k">return</code> <code class="p">{</code> <code class="nx">id</code><code class="p">,</code> <code class="nx">name</code><code class="o">:</code> <code class="nx">result</code><code class="p">.</code><code class="nx">rows</code><code class="p">[</code><code class="mi">0</code><code class="p">].</code><code class="nx">name</code> <code class="p">};</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>The <code>setUser()</code> method in this case doesn’t need any changes since it’s already writing to the new column. The migration can run either before or after the deployment in this case.</p>&#13;
&#13;
<p>The timeline for this multistage live migration now resembles <a data-type="xref" href="#fig_migration_fixed">Figure 8-3</a>. While it’s certainly more complex than before, it does lead to a situation where the application is always compatible with the database.</p>&#13;
&#13;
<figure><div class="figure" id="fig_migration_fixed">&#13;
<img alt="The application is now always compatible with the database." src="assets/dsnj_0803.png"/>&#13;
<h6><span class="label">Figure 8-3. </span>Working migration timeline</h6>&#13;
</div></figure>&#13;
&#13;
<p>In this case, the application is running just fine at 15:00. At 15:01 the first migration is run. The application is still compatible with the schema since there’s just a new column being added that the application is ignoring. Next, around 15:02, deployment A happens. The application is still compatible with the schema, and it’s now writing to the new column and reading from all columns. At 15:03 migration B happens and data gets backfilled. The code is still compatible and encounters rows that either have a <code>name</code> column with data or an empty <code>name</code> column. Around 15:04 another deployment happens where the code is only reading from the new <code>name</code> column. Finally, around 15:05, the final schema migration happens.</p>&#13;
&#13;
<p>This is just an example of one form of live migration. As you perform other mutations to your database, you’ll need to change the steps and the queries involved. One rule of thumb is to always test migrations locally or in a staging environment before performing them in production. Test suites often aren’t designed with schema mutations in mind, and it can <a data-primary="resilience" data-secondary="schema migration" data-startref="migknex" data-tertiary="Knex" data-type="indexterm" id="idm46291175791544"/><a data-primary="schema migration" data-secondary="Knex and" data-startref="livemigrate" data-tertiary="live migrations" data-type="indexterm" id="idm46291175790024"/>be difficult to spot migration failures.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Idempotency and Messaging Resilience" data-type="sect1"><div class="sect1" id="ch_resilience_sec_messaging">&#13;
<h1>Idempotency and Messaging Resilience</h1>&#13;
&#13;
<p>Clients need to know the outcome <a data-primary="resilience" data-secondary="idempotency" data-type="indexterm" id="idemp"/><a data-primary="resilience" data-secondary="messaging resilience" data-type="indexterm" id="mess_res"/><a data-primary="messaging" data-secondary="resilience" data-type="indexterm" id="mes_res"/>of a write operation carried out by a server; there’s a reason why they requested the write to happen, after all. For example, if a web server that a user is interacting with sends a message to an account server to make a purchase, then the web server will need to provide the result of the operation to the user agent. If the purchase fails, then the user may want to try again, or they may want to purchase something else. If it succeeds, then the user will expect to have less money in their account. But what does the web server do if it doesn’t know the result of the account server’s write operation?</p>&#13;
&#13;
<p>Distributed applications communicate by sending messages to one another over a network. Not only are applications unreliable—a Node.js server may throw while processing a request—but the very network over which they communicate is also unreliable. Generally there are two types of errors that need to be dealt with in these scenarios. The first has to do with the lower-level protocol being used, such as an inability to communicate with a remote host via TCP. The second has to deal with whatever higher-level protocol is being used, like a 500 error via HTTP.</p>&#13;
&#13;
<p>High-level errors are usually easier to deal with. When an operation fails, the server provides information to the client about that failure over HTTP. The client can then use this information to make an informed decision. For example, a 404 response means that the resource being acted upon does not exist. Depending on the work being performed by the client, this might not be a big deal, like if a client is polling to see if a resource has been created yet, or it might be a huge deal, like if someone is checking to see if they’re still employed.</p>&#13;
&#13;
<p>Low-level errors require more work. These errors usually involve a communication breakdown, and it’s not always possible to know if the server received the message or not. If it did receive the message, it’s not possible to tell if the server processed the message or not. <a data-type="xref" href="#fig_protocol_errors">Figure 8-4</a> shows how these different scenarios play out.</p>&#13;
&#13;
<figure><div class="figure" id="fig_protocol_errors">&#13;
<img alt="A high-level protocol error happens when a client and server communicate. A low level protocol happens when the request or response is lost. It's impossible to tell if a server received the message in these situations." src="assets/dsnj_0804.png"/>&#13;
<h6><span class="label">Figure 8-4. </span>Protocol errors</h6>&#13;
</div></figure>&#13;
&#13;
<p>In the first example, a high-level error has occurred. In this case, the request/response lifecycle successfully completed and the high-level HTTP protocol error was communicated to the client. In the second example, the server did receive and process the request (like making a database change), but the client didn’t receive a response. In the third example, the server neither received nor processed the request. In this case, the client can’t necessarily distinguish between the second and third scenarios.</p>&#13;
&#13;
<p>There is a finite number of <a class="orm:hideurl" href="https://nodejs.org/api/errors.html">errors</a> that are surfaced to application code from the underlying Node.js network APIs. These errors are applicable regardless of which higher-level protocol is used, such as HTTP or gRPC. <a data-type="xref" href="#table_network_errors">Table 8-3</a> contains a list of these errors and what they mean. These error codes are provided as an <code>Error#code</code> property and are exposed via error callbacks, event emitter error events, and promise rejections.</p>&#13;
<table id="table_network_errors">&#13;
<caption><span class="label">Table 8-3. </span>Node.js network errors</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Error</th>&#13;
<th>Context</th>&#13;
<th>Ambiguous</th>&#13;
<th>Meaning</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p><code>EACCES</code></p></td>&#13;
<td><p>Server</p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p>Cannot listen on port due to permissions</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>EADDRINUSE</code></p></td>&#13;
<td><p>Server</p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p>Cannot listen on port since another process has it</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>ECONNREFUSED</code></p></td>&#13;
<td><p>Client</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>Client unable to connect to server</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>ENOTFOUND</code></p></td>&#13;
<td><p>Client</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>DNS lookup for the server failed</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>ECONNRESET</code></p></td>&#13;
<td><p>Client</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Server closed connection with client</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>EPIPE</code></p></td>&#13;
<td><p>Client</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Connection to server has closed</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>ETIMEDOUT</code></p></td>&#13;
<td><p>Client</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Server didn’t respond in time</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The first two errors, <code>EACCESS</code> and <code>EADDRINUSE</code>, usually happen early in the lifetime of a process when a server attempts to listen. <code>EACCESS</code> means that the user running the process doesn’t have permission to listen on a port and is often the case when a non-root user listens to a low port, meaning 1024 and below. <code>EADDRINUSE</code> happens when another process is already listening on the specified port and interface.</p>&#13;
&#13;
<p>The other errors are applicable to the client and message resiliency. <code>ECONNREFUSED</code> and <code>ENOTFOUND</code> happen early in the network connection process. They can precede every individual message, like an HTTP request made without a keep alive connection. Or they can happen early on during a long-lived connection like gRPC. Notably, these errors happen before a message is sent to the server, so when they’re surfaced, there isn’t ambiguity about whether or not the server received and processed the &#13;
<span class="keep-together">message.</span></p>&#13;
&#13;
<p>The final three errors can happen during the middle of a network conversation and come with message delivery ambiguity. They can happen before or after the server receives and processes a message, leading to the third situation in <a data-type="xref" href="#fig_protocol_errors">Figure 8-4</a>. With these errors, it’s not possible to tell if a message was received.</p>&#13;
&#13;
<p>Depending on the situation, and the properties of the message being sent, the client may attempt subsequent deliveries of the message.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="HTTP Retry Logic" data-type="sect2"><div class="sect2" id="idm46291175718536">&#13;
<h2>HTTP Retry Logic</h2>&#13;
&#13;
<p><a data-type="xref" href="ch02.html#ch_protocols_sec_http">“Request and Response with HTTP”</a> already covers <a data-primary="HTTP (Hypertext Transfer Protocol)" data-secondary="retry logic" data-type="indexterm" id="idm46291175716168"/>some details about HTTP, but in this section, further consideration is given to resiliency of messages, in particular the conditions in which a request can be repeated. <a data-type="xref" href="#fig_http_retry_flowchart">Figure 8-5</a> contains a flowchart that you can follow when designing your own retry logic.</p>&#13;
&#13;
<figure><div class="figure" id="fig_http_retry_flowchart">&#13;
<img alt="A flowchart of HTTP retry logic" src="assets/dsnj_0805.png"/>&#13;
<h6><span class="label">Figure 8-5. </span>HTTP retry flowchart</h6>&#13;
</div></figure>&#13;
&#13;
<p>First, the low-level errors from <a data-type="xref" href="#table_network_errors">Table 8-3</a> still apply. If an HTTP request results in a network error of <code>ECONNREFUSED</code> or <code>ENOTFOUND</code>, then the client is free to attempt the request again. However, the network errors <code>ECONNRESET</code>, <code>EPIPE</code>, and <code>ETIMEDOUT</code>, as well as HTTP errors in the 5XX range, require some further consideration. If the request is considered idempotent, then it may be retried; otherwise, the request should be considered a failure at that point. If an HTTP 4XX error is received, then the message should also fail. And if no HTTP error is received, then the request was successfully sent and the process is complete.</p>&#13;
&#13;
<p><a data-type="xref" href="#table_idempotency">Table 8-4</a> contains a list of the popular HTTP methods often supported by HTTP APIs, as well as details about the methods such as if they’re idempotent or potentially destructive.</p>&#13;
<table id="table_idempotency">&#13;
<caption><span class="label">Table 8-4. </span>HTTP method matrix</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Method</th>&#13;
<th>Idempotent</th>&#13;
<th>Destructive</th>&#13;
<th>Safe</th>&#13;
<th>4XX</th>&#13;
<th>5XX</th>&#13;
<th>Ambiguous</th>&#13;
<th>Purpose</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p><code>GET</code></p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>No Retry</p></td>&#13;
<td><p>Retry</p></td>&#13;
<td><p>Retry</p></td>&#13;
<td><p>Retrieve resource(s)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>POST</code></p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>No Retry</p></td>&#13;
<td><p>No Retry</p></td>&#13;
<td><p>No Retry</p></td>&#13;
<td><p>Create resource</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>PUT</code></p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>No Retry</p></td>&#13;
<td><p>Retry</p></td>&#13;
<td><p>Retry</p></td>&#13;
<td><p>Create or modify resource</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>PATCH</code></p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>No Retry</p></td>&#13;
<td><p>Retry</p></td>&#13;
<td><p>Retry</p></td>&#13;
<td><p>Modify resource</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>DELETE</code></p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>Yes</p></td>&#13;
<td><p>No</p></td>&#13;
<td><p>No Retry</p></td>&#13;
<td><p>Retry</p></td>&#13;
<td><p>Retry</p></td>&#13;
<td><p>Remove resource</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>This table is based on many assumptions and requires that an HTTP API adheres to HTTP standards, like those defined in <a class="orm:hideurl" href="https://tools.ietf.org/html/rfc7231">RFC7231</a>. For example, a <code>GET</code> request shouldn’t modify any data (perhaps a write to a secondary system is made for tracking rate limits or analytics, but otherwise, the primary data store should not be affected). If the HTTP standards are violated by an API, then it’s no longer possible to make any assumptions about retry safety.</p>&#13;
&#13;
<p>A request can be repeated multiple times without side effect if it is idempotent. For example, if a client requests <code>DELETE /recipes/42</code>, then the record will be deleted. If this is repeated, then the record isn’t any more or less deleted. Even though the first request might succeed with a 200 status and future requests might fail with a 404 status, the request itself is still idempotent. This is based on the assumption that a URL represents a specific resource, and that other resources can’t reuse a URL.</p>&#13;
&#13;
<p>A message is destructive if it can lead to loss of data. For example, a <code>PUT</code> and a <code>PATCH</code> request may overwrite data that was recently set by another client’s request, and a <code>DELETE</code> will definitely destroy data. In these situations, a server may choose to implement the <code>ETag</code> and <code>If-Match</code> <a class="orm:hideurl" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag">HTTP headers</a> to provide additional semantics to avoid data clobbering. This is similar to the Memcached CAS concept mentioned in <a data-type="xref" href="#ch_resilience_sec_memcached_subsec_intro">“Introducing Memcached”</a>.</p>&#13;
&#13;
<p>A message is safe if it doesn’t modify resources. In this list, only the <code>GET</code> method is safe.</p>&#13;
&#13;
<p>Any message that results in a 4XX HTTP error should not be retried. In this situation, the client has made some sort of mistake with the request (such as providing data of the wrong type). Re-attempting the same request should always result in &#13;
<span class="keep-together">failure.</span></p>&#13;
&#13;
<p>To further complicate things, depending on which specific 5XX error is encountered, the client may technically be able to assume that the server did receive the message but did not attempt to process it. For example, a 503 Service Unavailable error might mean that the server received the message but did not have a connection to a database. Perhaps you can get away with such assumptions when dealing with an internal service. However, when dealing with 5XX errors generally, especially ones from external services, it is safest to assume that the state of the server is unknown.</p>&#13;
&#13;
<p>A mechanism that a server may choose to implement that makes every request idempotent is an <em>idempotency key</em>. An idempotency key <a data-primary="idempotency key" data-type="indexterm" id="idm46291175661144"/><a data-primary="keys" data-secondary="idempotency" data-type="indexterm" id="idm46291175660536"/>is metadata that is provided by the client when making a request to a server. In the case of the <a class="orm:hideurl" href="https://stripe.com/docs/api/idempotent_requests">Stripe API</a>, clients may send a <code>Idempotency-Key</code> header, and with the <a class="orm:hideurl" href="https://developer.paypal.com/docs/platforms/develop/idempotency/">PayPal API</a>, clients can provide a <code>PayPal-Request-Id</code> header. When the server receives a request with this key, it first checks a cache for the presence of the key. If the entry is present in the cache, then the server immediately replies with the cached entry. If the entry is missing in the cache, the server carries out the request as usual and then writes the response to the cache and replies to the request. Entries in the cache can then be cleared out after a set amount of time (Stripe clears after 24 hours) since repeat requests after a long time are rare (retries should realistically happen over the course of minutes). Consider supporting idempotency keys in your API if the side effect of duplicated requests can be costly.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Circuit Breaker Pattern" data-type="sect2"><div class="sect2" id="idm46291175717912">&#13;
<h2>Circuit Breaker Pattern</h2>&#13;
&#13;
<p>Sometimes, a message or <a data-primary="circuit breaker pattern" data-type="indexterm" id="idm46291175654600"/><a data-primary="messaging" data-secondary="circuit breaker pattern" data-type="indexterm" id="idm46291175653896"/>two gets lost over the network. Other times, a service is just down. Try as it might, a client won’t be able to contact a fallen server. In these situations, it’s often better for a client to give up for a while. By giving up, the client is able to fail incoming requests quicker (if appropriate), less wasted requests will flood the network, and an overwhelmed server may be free to successfully respond to other incoming requests. This approach of not making outbound requests when a server is perceived to be down is called the <em>circuit breaker</em> pattern.</p>&#13;
&#13;
<p>Clients have many options to choose from for determining when a client is down. For example, they may choose to define a threshold before flipping the circuit breaker, such as if ten 500 errors are encountered within 60 seconds. Other approaches might involve checking the response time of a service, considering one to be down if it takes longer than 200 milliseconds to reply.</p>&#13;
&#13;
<p>Things get more tricky when it comes to differentiating services from one another. For example, when you worked with Kubernetes, you created a Service object that abstracted the individual service instances away from you. In that situation it’s impossible to differentiate a faulty service instance from a healthy service instance. Luckily, Kubernetes may handle the health checks and can clean up a service automatically. With other technologies, such as Consul by HashiCorp, it’s possible to build a system where applications maintain an in-memory list of host and port combinations representing service instances. In that situation it’s possible to apply a circuit breaker on an individual-instance basis.</p>&#13;
&#13;
<p>When it comes to communicating with outside services, such as the GitHub API, you’ll probably never know which underlying service instance is responding to a request; you just know that “the GitHub API is down.” In these situations, you may need to circuit-break the entire third-party API. This can be done by keeping a failure counter in a fast, in-memory database like Redis. When the number of 500 errors or <code>ECONNREFUSED</code> errors reaches a threshold, your services will then give up making requests and will instead fail immediately.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exponential Backoff" data-type="sect2"><div class="sect2" id="idm46291175648280">&#13;
<h2>Exponential Backoff</h2>&#13;
&#13;
<p>The naive approach for <a data-primary="exponential backoff" data-type="indexterm" id="expo_back"/>having a client retry a request to an external service is to simply have it make the request again as soon as the failure happens. Then, if that retry fails, make another one immediately. This approach may not help requests succeed and may also exacerbate the problem.</p>&#13;
&#13;
<p><a data-type="xref" href="#fig_no_exponential_backoff">Figure 8-6</a> contains an example of a client using immediate retries. In this diagram, service instance A crashes. All the while, a client is making requests to the service. Once the client starts receiving failures, it begins sending requests much more rapidly. When this happens the client ends up working harder than it should, and the network is flooded with wasteful requests. Even once the new service instance B does start, it still needs to go through a startup phase where it may continue to fail any requests that it receives. When this happens the service may work harder than it needs to in order to respond to requests.</p>&#13;
&#13;
<figure><div class="figure" id="fig_no_exponential_backoff">&#13;
<img alt="Without exponential backoff, a client will barrage a server with requests" src="assets/dsnj_0806.png"/>&#13;
<h6><span class="label">Figure 8-6. </span>Without exponential backoff</h6>&#13;
</div></figure>&#13;
&#13;
<p>When you worked with Kubernetes, you might have noticed that a common theme within the cluster is that it takes time for applications to reach a desired state. For one reason, it takes time for an application to start and for it to establish connections to external services such as databases. Another reason is that it takes time for Kubernetes to notice that a health check is failing and to restart a service. Because such deployments and restarts take time, request re-attempts should also take time.</p>&#13;
&#13;
<p>Often, when there’s a problem communicating with a service, it might just be a temporary blip. For example, a single network message might be dropped within the span of 1ms. Other times, the service might be down for a longer amount of time. For example, it might have lost a connection to the database and will need to re-establish a new connection, taking a second or two. Still, in other situations, the amount of time it takes for the server to come back is even longer, like when a health check fails and an instance is rebooted, taking up to a minute. Finally, sometimes a service can be down for hours, like when a DNS misconfiguration is deployed and an engineer needs to manually roll back.</p>&#13;
&#13;
<p>Because of this wide range of time that a service might be down, and the cost incurred by making failed requests, a different approach needs to be taken for retrying requests. Currently, the industry standard is called an <em>exponential backoff</em>. With this approach, the client starts by making retry attempts quickly but then slows down over time. For example, a service might choose to make request retries using the following schedule:</p>&#13;
&#13;
<pre data-type="programlisting">100ms  | 250ms | 500ms | 1000ms | 2500ms | 5000ms | 5000ms | ...</pre>&#13;
&#13;
<p>In this case, the first retry happens in 100 milliseconds, the second at 250 milliseconds, and so on, until it reaches 5 seconds, at which point it continues to retry at a rate of once every 5 seconds. Of course, this approach isn’t exactly exponential. It is, however, easy to reason about, being rounded to values familiar to humans. Once the application gets to the point where it’s making requests every 5 seconds, it’s very unlikely to overwhelm any service.</p>&#13;
&#13;
<p>This approach can be used with the <code>ioredis</code> package <a data-primary="ioredis module" data-secondary="retry logic" data-type="indexterm" id="idm46291175635432"/>that you previously worked with. The <code>ioredis</code> package has retry support built into the package. Here’s an example of how to adapt this connection retry schedule:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">Redis</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'ioredis'</code><code class="p">);</code>&#13;
<code class="kr">const</code> <code class="nx">DEFAULT</code> <code class="o">=</code> <code class="mi">5000</code><code class="p">;</code>&#13;
<code class="kr">const</code> <code class="nx">SCHEDULE</code> <code class="o">=</code> <code class="p">[</code><code class="mi">100</code><code class="p">,</code> <code class="mi">250</code><code class="p">,</code> <code class="mi">500</code><code class="p">,</code> <code class="mi">1000</code><code class="p">,</code> <code class="mi">2500</code><code class="p">];</code>&#13;
<code class="kr">const</code> <code class="nx">redis</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">Redis</code><code class="p">({</code>&#13;
  <code class="nx">retryStrategy</code><code class="o">:</code> <code class="p">(</code><code class="nx">times</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
    <code class="k">return</code> <code class="nx">SCHEDULE</code><code class="p">[</code><code class="nx">times</code><code class="p">]</code> <code class="o">||</code> <code class="nx">DEFAULT</code><code class="p">;</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">});</code></pre>&#13;
&#13;
<p>In this case, the <code>retrySchedule()</code> method <a data-primary="retrySchedule() function" data-type="indexterm" id="idm46291175578088"/><a data-primary="functions" data-secondary="retrySchedule()" data-type="indexterm" id="idm46291175577496"/>accepts an argument, which is the current reattempt number. The method then returns a value, which is the amount of time to wait before reconnecting in milliseconds. The function itself tries to grab a value from the retry schedule, falling back to a default value if missing in the schedule.</p>&#13;
&#13;
<p>Depending on the operation, it may make sense to choose a different retry schedule. For example, for a service that depends on a database connection to function, this schedule might be fine. Once the application reaches the five second mark, it will continue to try to reconnect to the database forever. However, for other requests, like an HTTP request to an upstream service made as part of an incoming request from a downstream service, it wouldn’t be helpful to keep the incoming request open for too long. In that case, it might make sense to have a finite schedule containing three retries. When performance is more important, it also makes sense that the retries fire much quicker. For example, an HTTP retry schedule might look more like this:</p>&#13;
&#13;
<pre data-type="programlisting">10ms | 20ms | 40ms | quit</pre>&#13;
&#13;
<p>While exponential backoff seems like a great solution to the retry problem, it can cause some other problems when used with internal services. For example, say that there is a fleet of 10 clients communicating with a single server. Each of the clients sends the server a steady stream of requests. Then, the service dies for several seconds before being started again. When this happens, each of the clients will probably notice that the service is down at the same time. They’ll then start re-attempting requests to the server with the exponential backoff schedule. But this means that each of the clients is now making requests at the same time. When the server finally does come back up, it will receive a barrage of requests all at the same time! This may cause the server to receive waves of traffic, where the server is doing no work for some periods of time and overwhelmed at other periods of time. This is a phenomenon known as the <em>thundering herd</em>. <a data-type="xref" href="#fig_thundering_herd">Figure 8-7</a> shows an example of this happening.</p>&#13;
&#13;
<figure><div class="figure" id="fig_thundering_herd">&#13;
<img alt="Multiple clients will send waves of requests to a service when it comes back up" src="assets/dsnj_0807.png"/>&#13;
<h6><span class="label">Figure 8-7. </span>Thundering herd</h6>&#13;
</div></figure>&#13;
&#13;
<p>To overcome this issue, you may <a data-primary="jitter" data-type="indexterm" id="idm46291175569272"/>want to introduce <em>jitter</em> to your applications. Jitter is random variance, such as an increase or decrease of request timing of ±10%. When this happens, some clients end up quicker and some end up slower. This helps spread out the message retries over time and may eventually reach a request rate that is evenly distributed across all clients.</p>&#13;
&#13;
<p>Random jitter can be introduced to the previous example like so:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">redis</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">Redis</code><code class="p">({</code>&#13;
  <code class="nx">retryStrategy</code><code class="o">:</code> <code class="p">(</code><code class="nx">times</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
    <code class="kd">let</code> <code class="nx">time</code> <code class="o">=</code> <code class="nx">SCHEDULE</code><code class="p">[</code><code class="nx">times</code><code class="p">]</code> <code class="o">||</code> <code class="nx">DEFAULT</code><code class="p">;</code>&#13;
    <code class="k">return</code> <code class="nb">Math</code><code class="p">.</code><code class="nx">random</code><code class="p">()</code> <code class="o">*</code> <code class="p">(</code><code class="nx">time</code> <code class="o">*</code> <code class="mf">0.2</code><code class="p">)</code> <code class="o">+</code> <code class="nx">time</code> <code class="o">*</code> <code class="mf">0.9</code><code class="p">;</code> <code class="c1">// ±10%</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">});</code></pre>&#13;
&#13;
<p>The concept of jitter is useful in other situations as well. For example, an application may need to buffer stats in memory and flush it to a database every minute. This can be pulled off by making a <code>setInterval(fn, 60_000)</code> call once when the application starts. However, the same thundering herd problem exists. Applications are often deployed in a fleet all at once. This can mean that when deploying 10 applications, 10 flushes will happen at the same time every minute, periodically overwhelming the database.</p>&#13;
&#13;
<p>Instead, jitter can be calculated randomly on a per-process basis when the process starts, where the jitter value is a number between zero and the interval of time. For example, when calculating an interval for an operation happening every minute, you might write code that looks like this:</p>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">PERIOD</code> <code class="o">=</code> <code class="mi">60</code><code class="nx">_000</code><code class="p">;</code>&#13;
<code class="kr">const</code> <code class="nx">OFFSET</code> <code class="o">=</code> <code class="nb">Math</code><code class="p">.</code><code class="nx">random</code><code class="p">()</code> <code class="o">*</code> <code class="nx">PERIOD</code><code class="p">;</code>&#13;
<code class="nx">setTimeout</code><code class="p">(()</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="nx">setInterval</code><code class="p">(()</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
    <code class="nx">syncStats</code><code class="p">();</code>&#13;
  <code class="p">},</code> <code class="nx">PERIOD</code><code class="p">);</code>&#13;
<code class="p">},</code> <code class="nx">OFFSET</code><code class="p">);</code></pre>&#13;
&#13;
<p>With this approach, instance A might get an offset of 17 seconds, instance B an offset of 42 seconds, and instance C an offset of 11 seconds. This would then result in a request schedule like <a data-primary="exponential backoff" data-startref="expo_back" data-type="indexterm" id="idm46291175482456"/>the following:</p>&#13;
&#13;
<pre data-type="programlisting">071 077 102 131 137 162 191 197 222</pre>&#13;
&#13;
<p>But without jitter, the request timeline would instead look like this:</p>&#13;
&#13;
<pre data-type="programlisting">060 060 060 120 120 120 180 180 180</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Resilience Testing" data-type="sect1"><div class="sect1" id="idm46291175788152">&#13;
<h1>Resilience Testing</h1>&#13;
&#13;
<p>As an engineer it’s far too easy <a data-primary="resilience" data-secondary="testing" data-type="indexterm" id="idm46291175411224"/><a data-primary="testing" data-secondary="resilience" data-type="indexterm" id="idm46291175410248"/>to treat error scenarios as a second-class citizen. Engineers may only test the happy paths of an application, both when it comes to interacting with a new feature via a UI as well as writing unit tests. When only the successful uses of a feature are tested, an application is left wide open for failure when it’s no longer run on a developer’s laptop and is shipped to production. Failure in a distributed environment can be further compounded because an error in one application can lead to errors in other applications—usually without the original stack trace to debug with.</p>&#13;
&#13;
<p>One philosophy for enforcing that such errors are dealt with is called <em>chaos engineering</em>. This is an <a data-primary="chaos engineering" data-type="indexterm" id="idm46291175407784"/>approach where failures are introduced randomly into an environment. By turning what are usually rare failures into an everyday occurrence, engineers are forced to deal with them sooner rather than later, lest they face the wrath of the midnight pager. This approach to testing failures is something that you may consider using within your organization, though it requires a very disciplined collection of developers to achieve.</p>&#13;
&#13;
<p>The first thing you’ll need to consider when introducing chaos into an organization is in which environments the chaos should be enabled. While introducing chaos to production may be the ultimate test of a system’s ability to be resilient to failure, starting with the staging environment is going to be much easier to get management buy-in.</p>&#13;
&#13;
<p>Another thing that needs to be considered is what types of chaos should be introduced into a system. When it comes to planning, it’s important to consider realistic failure situations within a real-world application. Here are some examples of the types of chaos that can be introduced into a Node.js application based on some of the common failure boundaries I’ve encountered within the applications I’ve worked on.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Random Crashes" data-type="sect2"><div class="sect2" id="idm46291175404744">&#13;
<h2>Random Crashes</h2>&#13;
&#13;
<p>One of the themes that has <a data-primary="resilience" data-secondary="random crashes" data-type="indexterm" id="idm46291175403176"/><a data-primary="random crashes" data-type="indexterm" id="idm46291175402200"/>been repeated throughout this book is that process instances will die. Because of this it’s important to keep state outside of the application instance. It’s also important that when a client gets a failure when communicating with a server, the client attempts to retry the request when appropriate.</p>&#13;
&#13;
<p><a data-type="xref" href="#ex_chaos_crash">Example 8-14</a> is an example of how you might introduce random crashes into an application.</p>&#13;
<div data-type="example" id="ex_chaos_crash">&#13;
<h5><span class="label">Example 8-14. </span>Random crash chaos</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="k">if</code> <code class="p">(</code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">NODE_ENV</code> <code class="o">===</code> <code class="s1">'staging'</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="kr">const</code> <code class="nx">LIFESPAN</code> <code class="o">=</code> <code class="nb">Math</code><code class="p">.</code><code class="nx">random</code><code class="p">()</code> <code class="o">*</code> <code class="mi">100</code><code class="nx">_000_000</code><code class="p">;</code> <code class="c1">// 0 - 30 hours</code>&#13;
  <code class="nx">setTimeout</code><code class="p">(()</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
    <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="s1">'chaos exit'</code><code class="p">);</code>&#13;
    <code class="nx">process</code><code class="p">.</code><code class="nx">exit</code><code class="p">(</code><code class="mi">99</code><code class="p">);</code>&#13;
  <code class="p">},</code> <code class="nx">LIFESPAN</code><code class="p">);</code>&#13;
<code class="p">}</code></pre></div>&#13;
&#13;
<p>The first thing this example does is check what environment it’s running in. In this case, the chaos is only introduced if run within the staging environment. Next, a lifespan for the process is calculated. In this case, the number is calculated to be some time between 0 and 30 hours of time. Next, a function is scheduled to fire once that amount of time has been met. Once the timer fires, the application will exit. In this example, the exit status is set to 99, and a message is also printed to <em>stderr</em>. This is helpful for debugging the reason for a crash; without it, an engineer might waste a bunch of time trying to fix an application that crashed intentionally.</p>&#13;
&#13;
<p>Assuming your application is being run in an environment where some sort of supervisor is keeping an eye on it (such as Kubernetes), the process should be restarted once it crashes. Once it crashes, there will be a period of time when requests made to the service will fail. It’s now up to the client in those situations to implement retry logic. Consider tweaking the amount of time between crashes depending on your environment; maybe it should crash every two minutes on a development laptop, every few hours in staging, and once a week in production.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Event Loop Pauses" data-type="sect2"><div class="sect2" id="idm46291178609096">&#13;
<h2>Event Loop Pauses</h2>&#13;
&#13;
<p>When the event loop in your <a data-primary="event loops" data-secondary="pauses" data-type="indexterm" id="idm46291175316936"/><a data-primary="resilience" data-secondary="event loop pauses" data-type="indexterm" id="idm46291175315960"/>JavaScript-based Node.js application pauses, the entire application comes to a standstill. During this time it is unable to process requests. Interesting race conditions with asynchronous timers can also sometimes appear when this happens. Assuming the process is incapable of responding to requests for long enough, it might even fail a health check and be considered for recycling.</p>&#13;
&#13;
<p><a data-type="xref" href="#ex_chaos_pause">Example 8-15</a> demonstrates how to introduce random pauses to your application.</p>&#13;
<div data-type="example" id="ex_chaos_pause">&#13;
<h5><span class="label">Example 8-15. </span>Random event loop pauses</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">TIMER</code> <code class="o">=</code> <code class="mi">100</code><code class="nx">_000</code><code class="p">;</code>&#13;
<code class="kd">function</code> <code class="nx">slow</code><code class="p">()</code> <code class="p">{</code>&#13;
  <code class="nx">fibonacci</code><code class="p">(</code><code class="mi">1</code><code class="nx">_000_000n</code><code class="p">);</code>&#13;
  <code class="nx">setTimeout</code><code class="p">(</code><code class="nx">slow</code><code class="p">,</code> <code class="nb">Math</code><code class="p">.</code><code class="nx">random</code><code class="p">()</code> <code class="o">*</code> <code class="nx">TIMER</code><code class="p">);</code>&#13;
<code class="p">}</code>&#13;
<code class="nx">setTimeout</code><code class="p">(</code><code class="nx">slow</code><code class="p">,</code> <code class="nb">Math</code><code class="p">.</code><code class="nx">random</code><code class="p">()</code> <code class="o">*</code> <code class="nx">TIMER</code><code class="p">);</code></pre></div>&#13;
&#13;
<p>In this case, the application runs a timer randomly between 0 and 100 seconds, randomly rescheduling to be run again until the process dies. When the timer fires, it performs a Fibonacci calculation for a million iterations. The Fibonacci calculation will take some amount of time depending on the version of the V8 engine being used and the speed of the CPU that the application is running on. Consider finding a number, or a random range of numbers, that will cause your application to freeze for multiple seconds.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Random Failed Async Operations" data-type="sect2"><div class="sect2" id="idm46291175306936">&#13;
<h2>Random Failed Async Operations</h2>&#13;
&#13;
<p>One of the most common failure scenarios is <a data-primary="asynchronous operations, failed" data-type="indexterm" id="asyncfail"/>when asynchronous operations are made. Errors are fairly common when an HTTP request is made, a file is read, or a database is accessed. Unlike the previous two examples, which run globally, this example requires some slight modifications to application code. In this case, a new function is added at the boundary where the application communicates with the underlying library.</p>&#13;
&#13;
<p><a data-type="xref" href="#ex_chaos_async">Example 8-16</a> shows how to introduce random failures to asynchronous calls in your application.</p>&#13;
<div data-type="example" id="ex_chaos_async">&#13;
<h5><span class="label">Example 8-16. </span>Random async failures</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="kr">const</code> <code class="nx">THRESHOLD</code> <code class="o">=</code> <code class="mi">10</code><code class="nx">_000</code><code class="p">;</code>&#13;
<code class="nx">async</code> <code class="kd">function</code> <code class="nx">chaosQuery</code><code class="p">(</code><code class="nx">query</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="k">if</code> <code class="p">(</code><code class="nx">math</code><code class="p">.</code><code class="nx">random</code><code class="p">()</code> <code class="o">*</code> <code class="nx">THRESHOLD</code> <code class="o">&lt;=</code> <code class="mi">1</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="k">throw</code> <code class="k">new</code> <code class="nb">Error</code><code class="p">(</code><code class="s1">'chaos query'</code><code class="p">);</code>&#13;
  <code class="p">}</code>&#13;
  <code class="k">return</code> <code class="nx">db</code><code class="p">.</code><code class="nx">query</code><code class="p">(</code><code class="nx">query</code><code class="p">);</code>&#13;
<code class="p">}</code>&#13;
<code class="kr">const</code> <code class="nx">result</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">chaosQuery</code><code class="p">(</code><code class="s1">'SELECT foo FROM bar LIMIT 1'</code><code class="p">);</code>&#13;
<code class="k">return</code> <code class="nx">result</code><code class="p">.</code><code class="nx">rows</code><code class="p">[</code><code class="mi">0</code><code class="p">];</code></pre></div>&#13;
&#13;
<p>This particular example provides a new method, <code>chaosQuery()</code>, which can be used as a replacement for an existing package that exposes a <code>db.query()</code> method. In this example, approximately 1 out of every 10,000 database queries will result in an error. This simple asynchronous method wrapper can be applied in other situations as well, like <a data-primary="resilience" data-secondary="idempotency" data-startref="idemp" data-type="indexterm" id="idm46291175160712"/><a data-primary="resilience" data-secondary="messaging resilience" data-startref="mess_res" data-type="indexterm" id="idm46291175159816"/><a data-primary="messaging" data-secondary="resilience" data-startref="mes_res" data-type="indexterm" id="idm46291175158600"/><a data-primary="asynchronous operations, failed" data-startref="asyncfail" data-type="indexterm" id="idm46291175157384"/>when making HTTP calls with the <code>node-fetch</code> package.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291175155960">&#13;
<h5>Alternatives to Manual Chaos</h5>&#13;
<p>Netflix created an open source tool named <a class="orm:hideurl" href="https://netflix.github.io/chaosmonkey/">Chaos Monkey</a> that introduces different forms of chaos into an organization’s infrastructure. Most notably, Chaos Monkey is able to randomly kill service instances, which requires that other service instances be able to handle the termination. Unlike the JavaScript code introduced in this section, Chaos Monkey works with services written in any language and doesn’t require code changes.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm46291180517368"><sup><a href="ch08.html#idm46291180517368-marker">1</a></sup> An exit status can also be set by assigning a code to <code>process.exitStatus</code> and then calling <code>process.exit()</code> without an argument.</p><p data-type="footnote" id="idm46291180506840"><sup><a href="ch08.html#idm46291180506840-marker">2</a></sup> There’s also a <code>process.abort()</code> method available. Calling it immediately terminates the process, prints some memory locations, and writes a core dump file to disk if the OS is configured to do so.</p><p data-type="footnote" id="idm46291180061896"><sup><a href="ch08.html#idm46291180061896-marker">3</a></sup> The deprecated internal <code>domain</code> module provides a way to capture <code>error</code> events from many <code>EventEmitter</code> instances.</p><p data-type="footnote" id="idm46291179692920"><sup><a href="ch08.html#idm46291179692920-marker">4</a></sup> I reported this issue to the package author two years ago. Fingers crossed!</p><p data-type="footnote" id="idm46291179566392"><sup><a href="ch08.html#idm46291179566392-marker">5</a></sup> Languages like Rust and C++ allow for extremely accurate memory calculations; with JavaScript, we can only work with approximations.</p><p data-type="footnote" id="idm46291177027288"><sup><a href="ch08.html#idm46291177027288-marker">6</a></sup> You can also avoid globally installing <code>knex</code> by prefixing each of the commands with <code>npx</code>, such as <code>npx knex init</code>.</p><p data-type="footnote" id="idm46291176335720"><sup><a href="ch08.html#idm46291176335720-marker">7</a></sup> Some systems think that my first name is “Thomas Hunter” and my last name is “II.”</p></div></div></section></body></html>