<html><head></head><body><section data-pdf-bookmark="Chapter 7. Worldwide Application Distribution and Staging" data-type="chapter" epub:type="chapter"><div class="chapter" id="worldwide_application_distribution_and_staging">&#13;
<h1><span class="label">Chapter 7. </span>Worldwide Application <span class="keep-together">Distribution and Staging</span></h1>&#13;
&#13;
&#13;
<p>To this point in the book,&#13;
we have seen a number of different practices&#13;
for building, developing, and deploying applications, but a&#13;
whole different set of concerns arises when deploying and managing&#13;
an application with a global footprint.</p>&#13;
&#13;
<p>There<a data-primary="global distribution" data-secondary="reasons for" data-type="indexterm" id="id664"/><a data-primary="distribution, global" data-see="global distribution" data-type="indexterm" id="id665"/><a data-primary="worldwide distribution" data-see="global distribution" data-type="indexterm" id="id666"/> are many different reasons why an application might need to scale to&#13;
a global deployment. The first and most obvious one is simply scale.&#13;
It might be that your application is so successful or mission critical&#13;
that it simply needs to be deployed around the world to provide&#13;
the capacity necessary for its users. Examples of such applications include&#13;
a worldwide API gateway for a public cloud provider, a large-scale IoT&#13;
product with a worldwide footprint, a highly successful social network,&#13;
and more.</p>&#13;
&#13;
<p>Although relatively few of us will build out systems that&#13;
require worldwide scale, many more applications require a worldwide&#13;
footprint for latency. Even with containers and Kubernetes there is no&#13;
getting around the speed of light. To minimize latency between clients and&#13;
our applications, it is sometimes necessary to distribute our applications&#13;
around the world to minimize the physical distance between the application&#13;
and its users.</p>&#13;
&#13;
<p>Finally, an even more common reason for global distribution is locality.&#13;
Either for reasons of bandwidth (e.g., a remote sensing platform) or data&#13;
privacy (e.g., geographic restrictions), it is sometimes necessary to deploy&#13;
an application in specific locations for the application to be possible&#13;
or successful. As more and more countries and regions implement data privacy&#13;
and sovereignty laws and regulations, it is becoming a common business&#13;
necessity to deploy your application in specific locations to serve users&#13;
who reside in that location.</p>&#13;
&#13;
<p>In all these cases, your application is no longer simply present in a&#13;
small handful of production clusters. Instead it is distributed across&#13;
tens to hundreds of different geographic locations. The management&#13;
of these locations, as well as the demands of rolling out a globally&#13;
reliable service, is a significant challenge. This chapter covers&#13;
approaches and practices for doing this successfully.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Distributing Your Image" data-type="sect1"><div class="sect1" id="id48">&#13;
<h1>Distributing Your Image</h1>&#13;
&#13;
<p>Before <a data-primary="global distribution" data-secondary="image distribution stage" data-type="indexterm" id="global-distro-image"/><a data-primary="image management" data-secondary="global distribution" data-type="indexterm" id="image-mgmt-global-distro"/>you can even consider running your application around the world,&#13;
you need to have that image available to clusters located around the globe.&#13;
The first thing to consider is whether your image registry has <a data-primary="geo-replication" data-type="indexterm" id="id667"/>automatic&#13;
geo-replication. Many image registries supplied by cloud providers will&#13;
automatically distribute your image around the world and resolve a&#13;
request for that image to the storage location nearest to the cluster&#13;
from which you are pulling the image. Many clouds enable you to decide&#13;
where you want to replicate the image; for example, you might know&#13;
of locations where you are not going to be present. An example of such a&#13;
registry is the <a href="https://oreil.ly/4jWNh">Microsoft Azure container registry</a>, but others&#13;
provide similar services. If you use a cloud-provided registry that&#13;
supports geo-replication, distributing your image around the world&#13;
is simple. You push the image into the registry, select the regions for&#13;
geo-distribution, and the registry takes care of the rest.</p>&#13;
&#13;
<p>If you are not using a cloud registry, or your provider does not support&#13;
automatic geo-distribution of images, you will need to solve that&#13;
problem yourself. One option is to use a registry situated in a&#13;
specific location. There are several concerns about such an approach.&#13;
Image pull latency often dictates the speed with which you can launch a&#13;
container in a cluster. This in turn can determine how quickly you can&#13;
respond to a machine failure, given that generally in the case of a machine&#13;
failure, you will need to pull the container image down to a new machine.</p>&#13;
&#13;
<p>Another concern about a single registry is that it can be a single point&#13;
of failure. If the registry is located in a single region or a single&#13;
datacenter, it’s possible that the registry could go offline due to a&#13;
large-scale incident in that datacenter. If your registry goes offline,&#13;
your CI/CD pipeline will stop working, and you’ll be unable to deploy new&#13;
code. This obviously has a significant impact on both developer&#13;
productivity and application operations. Additionally, a single registry&#13;
can be much more expensive because you will be using significant&#13;
bandwidth each time you launch a new container, and even though container&#13;
images are generally fairly small, the bandwidth can add up. Despite&#13;
these negatives, a single registry solution can be the appropriate answer for&#13;
small-scale applications running in only a few global regions. It&#13;
certainly is simpler to set up than full-scale image replication.</p>&#13;
&#13;
<p>If you cannot use cloud-provided geo-replication and you need to&#13;
replicate your image, you are on your own to craft a solution for image&#13;
replication. To implement such a service, you have two options. The first&#13;
is to use geographic names for each image registry (e.g., <code>us.my-registry.io</code>, <code>eu.my-registry.io</code>, etc.). The advantage of&#13;
this approach is that it is simple to set up and manage. Each registry&#13;
is entirely independent, and you can simply push to all registries at&#13;
the end of your CI/CD pipeline. The downside is that&#13;
each cluster will require a slightly different configuration to pull the&#13;
image from the nearest geographic location. However, given that you&#13;
likely will have geographic differences in your application&#13;
configurations anyway, this downside is relatively easy to manage and&#13;
likely already present in your <span class="keep-together">environment.</span></p>&#13;
&#13;
<p>The second option is to use a networking configuration to connect&#13;
your image pulls to a specific repository. In this approach you still push your image&#13;
to multiple registries, but instead of giving them each a unique name, you give&#13;
them all a single DNS endpoint (e.g., <code>my-registry.io</code>). You can <a data-primary="GeoDNS" data-type="indexterm" id="id668"/>use geography-aware DNS (GeoDNS),&#13;
which will respond to DNS requests from different geographic regions with different IP addresses,&#13;
or if you have the right networking infrastructure, you can use <a data-primary="multicast IP addresses" data-type="indexterm" id="id669"/>multicast IP addresses.&#13;
In multicast, all your registries share the same IP address, but it is&#13;
advertised to the internet in multiple physical locations, and shortest-path&#13;
network routing is relied on to take traffic to the server that provides the nearest&#13;
image registry. Both of these network configurations are tricky to implement correctly. The best&#13;
answer is definitely to use a cloud-based registry, even if you are pulling to on-premises&#13;
servers. If you really want to run your own registry (and take on the operational burden that&#13;
implies), we strongly suggest you use the regional server approach discussed in the previous&#13;
paragraph unless you have prior network experience with replicated services. The next&#13;
section describes how you can parameterize your deployment to, for example, use different&#13;
registries in <a data-primary="global distribution" data-secondary="image distribution stage" data-startref="global-distro-image" data-type="indexterm" id="id670"/><a data-primary="image management" data-secondary="global distribution" data-startref="image-mgmt-global-distro" data-type="indexterm" id="id671"/>different regions.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Parameterizing Your Deployment" data-type="sect1"><div class="sect1" id="id207">&#13;
<h1>Parameterizing Your Deployment</h1>&#13;
&#13;
<p>When you<a data-primary="global distribution" data-secondary="parameterizing deployments" data-type="indexterm" id="global-distro-parameter"/><a data-primary="deployments" data-secondary="parameterizing" data-type="indexterm" id="deploy-parameter-global"/><a data-primary="parameterization" data-secondary="for global distributions" data-secondary-sortas="global distributions" data-type="indexterm" id="parameter-global"/> have replicated your image everywhere, you need to parameterize&#13;
your deployments for different global locations. Whenever you are&#13;
deploying to a variety of different regions, there are bound to be&#13;
differences in the configuration of your application in those&#13;
regions. For example, if you don’t have a geo-replicated registry, you&#13;
might need to tweak the image name for different regions. However, even if you have a geo-replicated image, it’s likely that different geographic&#13;
locations will present different load on your application, and thus the&#13;
size (e.g., the number of replicas) as well as other configuration can be&#13;
different between regions. Managing this complexity in a manner that&#13;
doesn’t incur undue toil is key to successfully managing a worldwide&#13;
application.</p>&#13;
&#13;
<p>The first thing to consider is how to organize your different&#13;
configurations on disk. A common way to achieve this is by using a&#13;
different directory for each global region. Given these directories, it&#13;
might be tempting to simply copy the same configurations into each&#13;
directory, but doing this is guaranteed to lead to drift and changes&#13;
between configurations in which some regions are modified and other regions&#13;
are forgotten. Instead, use a template-based approach so that most of the configuration is retained in a single template that is shared by all regions, and then parameters are applied to that template to produce the region-specific templates. <a href="https://helm.sh">Helm</a> is a commonly used tool for this sort of templating <a data-primary="global distribution" data-secondary="parameterizing deployments" data-startref="global-distro-parameter" data-type="indexterm" id="id672"/><a data-primary="deployments" data-secondary="parameterizing" data-startref="deploy-parameter-global" data-type="indexterm" id="id673"/><a data-primary="parameterization" data-secondary="for global distributions" data-secondary-sortas="global distributions" data-startref="parameter-global" data-type="indexterm" id="id674"/>(for details, see <a data-type="xref" href="ch01.html#setting_up_a_basic_service">Chapter 1</a>).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Load-Balancing Traffic Around the World" data-type="sect1"><div class="sect1" id="id49">&#13;
<h1>Load-Balancing Traffic Around the World</h1>&#13;
&#13;
<p>Now that <a data-primary="global distribution" data-secondary="load balancing" data-type="indexterm" id="id675"/><a data-primary="load balancing" data-type="indexterm" id="id676"/>your application is running around the world, the next step is&#13;
to determine how to direct traffic to the application. In general, you&#13;
want to take advantage of geographic proximity to ensure low-latency&#13;
access to your service. But you also want to failover across geographic&#13;
regions in case of an outage or any other source of service failure.&#13;
Correctly setting up the balancing of traffic to your various regional&#13;
deployments is key to establishing both a performant and&#13;
reliable system.</p>&#13;
&#13;
<p>Let’s begin with the assumption that you have a single hostname that you want to use for your service, for example, <em>myapp.myco.com</em>. One initial decision that you need to make is whether you want to use the Domain Name System (DNS) protocol to implement load balancing across your regional endpoints. If you use DNS for load balancing, the IP address that is returned when a user makes a DNS query to <em>myapp.myco.com</em> is based on both the location of the user accessing your service as well as the current availability of your service. The other alternative is multicast IP addresses, where the same IP address is advertised from multiple locations on the internet. When a user looks up <em>myapp.myco.com</em>, the DNS always returns this fixed IP address, but the actual routing of packets varies depending on where the connection is in the network.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Reliably Rolling Out Software Around the World" data-type="sect1"><div class="sect1" id="id50">&#13;
<h1>Reliably Rolling Out Software Around the World</h1>&#13;
&#13;
<p>After you <a data-primary="global distribution" data-secondary="rollouts" data-type="indexterm" id="global-distro-rollout"/><a data-primary="rollouts" data-secondary="global" data-type="indexterm" id="rollout-global"/>have templatized your application so that you have proper configurations for each region, the next important problem is how to deploy these configurations around the world. It might be tempting to simultaneously deploy your application worldwide so that you can efficiently and quickly iterate your application, but this, although Agile, is an approach that can easily leave you with a global outage. Any errors that you accidentally roll out to the world are immediately present for&#13;
all users in all regions. Instead, for most production applications, a more carefully staged approach to rolling out your software around the world is more appropriate. When combined with things like global load balancing, these approaches can maintain high availability even in the face of major application failures.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Overall, when approaching the problem of a global rollout, the goal is to roll out software as quickly as possible, while simultaneously detecting issues quickly—ideally before they affect many users.</p>&#13;
</div>&#13;
&#13;
<p>Let’s assume that by the time you are performing a global rollout, your application has already passed basic functional and load testing. Before a particular image (or images) is certified for a global rollout, it should have gone through enough testing that you believe the application is operating correctly. It is important to note that this <em>does not</em> mean that your application <em>is</em> operating correctly. Though testing catches many problems, in the real world, application problems are often first noticed when they are rolled out to production traffic. This is because the true nature of production traffic is often difficult to simulate with perfect fidelity. For example, you might test with only English-language inputs, whereas in the real world, you see input from a variety of languages. Or your set of test inputs may not be comprehensive for the real-world data your application ingests. Of course, any time that you do see a failure in production that wasn’t caught by testing, it is a strong indicator that you need to extend and expand your testing. Nonetheless, it is still true that many problems are caught during a production rollout.</p>&#13;
&#13;
<p>With this in mind, each region that you roll out to is an opportunity to discover a new problem. And because the region is a production region, it is also a potential outage to which you will need to react. These factors combine to set the stage for how you should approach regional rollouts.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Throughout this discussion we talk about rolling out software to a geographic region, but this sort of progressive rollout is only one form of progressive exposure control. An alternative way to roll out a feature is to use<a data-primary="feature flags" data-type="indexterm" id="id677"/> feature flags to do progressive exposure. With feature flags, a new feature is first rolled out via a release that follows a geographic rollout as described next; however, the feature is flagged “off” by default. Once the release is in all regions, the flag is gradually turned on by (for example) activating the feature for 10% of all users, followed by 20%, and so on until the feature is fully rolled out. There are numerous configuration systems for doing flag-based experiments and progressive rollouts. And combining flags with geographic releases is a very stable way to release new features while being able to quickly respond <a data-primary="global distribution" data-secondary="rollouts" data-startref="global-distro-rollout" data-type="indexterm" id="id678"/><a data-primary="rollouts" data-secondary="global" data-startref="rollout-global" data-type="indexterm" id="id679"/>to failures.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pre-Rollout Validation" data-type="sect2"><div class="sect2" id="id51">&#13;
<h2>Pre-Rollout Validation</h2>&#13;
&#13;
<p>Before you <a data-primary="global distribution" data-secondary="rollouts" data-tertiary="pre-rollout validation" data-type="indexterm" id="global-distro-rollout-valid"/><a data-primary="rollouts" data-secondary="global" data-tertiary="pre-rollout validation" data-type="indexterm" id="rollout-global-valid"/><a data-primary="testing" data-secondary="pre-rollout validation" data-type="indexterm" id="test-rollout-valid"/>even consider rolling out a particular version of your software around the world, it’s critically important to validate that software in some sort of synthetic testing environment. If you have your CD pipeline set up correctly, all code prior to a particular release build will have undergone some form of unit testing, and possibly limited integration testing. However, even with this testing in place, it’s important to consider two other sorts of tests for a release before it begins its journey through the release pipeline. The first is<a data-primary="integration testing" data-type="indexterm" id="integrate-test"/> complete integration testing. This means that you assemble the entirety of your stack into a full-scale deployment of your application but without any real-world traffic. This complete stack generally will include either a copy of your production data or simulated data on the same size and scale as your true production data. If in the real world, the data in your application is 500 GB, it’s critical that in preproduction testing your dataset is roughly the same size (and possibly even literally the same dataset).</p>&#13;
&#13;
<p>Generally speaking, setting up a complete integration testing environment is a significant challenge. Often, production data is present only in production, and generating a synthetic dataset of the same size and scale is quite difficult. Because of this complexity, setting up a realistic integration testing dataset is a great example of a task that it pays to do early on in the development of an application. If you set up a synthetic copy of your dataset early, when the dataset itself is quite small, your integration test data grows gradually at the same pace as your production data. This is generally significantly more manageable than if you attempt to duplicate your production data when you are already at scale.</p>&#13;
&#13;
<p>Sadly, many people don’t realize that they need a&#13;
copy of their data until they are already at a large scale and the task&#13;
is difficult. In such cases it might be possible to deploy a&#13;
read/write-deflecting layer in front of your production data store.&#13;
Obviously, you don’t want your integration tests writing to production&#13;
data, but it is often possible to set up a proxy in front of your&#13;
production data store that reads from production but stores writes in a&#13;
side table that is also consulted on subsequent reads.</p>&#13;
&#13;
<p>Of course, it is also extremely important that if you use your production&#13;
data for testing and development you are very careful with the security&#13;
of that data. Numerous data leaks have been associated with developers&#13;
accidentally placing their production user data in insecure locations.</p>&#13;
&#13;
<p>Regardless of how you manage to set up your integration testing&#13;
environment, the goal is the same: to validate that your application&#13;
behaves as expected when given a series of test inputs and interactions.&#13;
There are a variety of ways to define and execute these tests—from the&#13;
most manual, a worksheet of tests and human effort (not recommended because&#13;
it is fairly error prone), through tests that simulate browsers and user&#13;
interactions, like clicks and so forth. In the middle are tests that&#13;
probe RESTful APIs but don’t necessarily test the web UI built on top&#13;
of those APIs. Regardless of how you define your integration tests, the&#13;
goal should be the same: an automated test suite that validates the&#13;
correct behavior of your application in response to a complete set of&#13;
real-world inputs. For simple applications it may be possible to perform&#13;
this validation in premerge testing, but for most large-scale&#13;
real-world applications, a complete integration environment is required.</p>&#13;
&#13;
<p>Integration testing will <a data-primary="integration testing" data-startref="integrate-test" data-type="indexterm" id="id680"/><a data-primary="load testing" data-type="indexterm" id="load-test"/>validate the correct operation of your&#13;
application, but you should also load-test the application. It is one thing&#13;
to demonstrate that the application behaves correctly; it is quite&#13;
another to demonstrate that it stands up to real-world load. In any&#13;
reasonably high-scale system, a significant regression in &#13;
<span class="keep-together">performance—for</span> example, a 20% increase in request latency—has a significant impact&#13;
on the UX of the application and, in addition to&#13;
frustrating users, can cause an application to completely fail. Thus, it&#13;
is critical to ensure that such performance regressions do not happen in&#13;
production.</p>&#13;
&#13;
<p>Like integration testing, identifying the correct way to load-test an&#13;
application can be a complex proposition; after all, it requires that&#13;
you generate a load similar to production traffic but in a synthetic and&#13;
reproducible way. One of the easiest ways to do this is to simply&#13;
replay the logs of traffic from a real-world production system. Doing&#13;
this can be a great way to perform a load test whose characteristics&#13;
match what your application will experience when deployed. However, using&#13;
replay isn’t always foolproof. For example, if your logs are old, and&#13;
your application or dataset has changed, it’s possible that the&#13;
performance on old, replayed logs will be different than the performance&#13;
on fresh traffic. Additionally, if you have real-world dependencies that&#13;
you haven’t mocked, it’s possible that the old traffic will be invalid when&#13;
sent over to the dependencies (e.g., the data might no longer exist).</p>&#13;
&#13;
<p>As with production data it is critical to safeguard the security of any&#13;
recorded real-world requests. Just like the production databases,&#13;
production requests often contain private information or secure&#13;
credentials (or both!), and it is critical that the security of any&#13;
recordings be treated the same as the actual user requests.</p>&#13;
&#13;
<p>Because of the challenges associated with saving, securing, and managing&#13;
this test data, many systems, even critical systems, are&#13;
developed for a long time without a load test. Like modeling your&#13;
production data, this is a clear example of something that is easier to maintain if you start earlier. If you build a load test&#13;
when your application has only a handful of dependencies, and improve&#13;
and iterate the load test as you adapt your application, you will have a&#13;
far easier time than if you attempt to retrofit load testing onto an&#13;
existing large-scale application.</p>&#13;
&#13;
<p>Assuming that you have crafted a load test, the next question is the&#13;
metrics<a data-primary="metrics" data-secondary="in load testing" data-secondary-sortas="load testing" data-type="indexterm" id="metrics-load-test"/> to watch when load-testing your application. The obvious ones&#13;
are requests per second and request latency because those are clearly the&#13;
user-facing metrics.</p>&#13;
&#13;
<p>When measuring latency, it’s important to realize&#13;
that this is actually a distribution, and you need to measure both the&#13;
mean latency as well as the outlier percentiles (like the 90th and 99th&#13;
percentiles) since they represent the “worst” UX of your&#13;
application. Problems with very long latencies can be hidden if you just&#13;
look at the averages, but if 10% of your users are having a bad&#13;
time, it can have a significant impact on the success of your product.</p>&#13;
&#13;
<p>In addition, it’s worth looking at the resource usage (CPU, memory,&#13;
network, disk) of the application under load test. Though these metrics&#13;
do not directly contribute to the UX, large changes in&#13;
resource usage for your application should be identified and understood&#13;
in preproduction testing. If your application is suddenly consuming&#13;
twice as much memory, it’s something you will want to investigate, even&#13;
if you pass your load test, because eventually such significant resource&#13;
growth will affect the quality and availability of your application.&#13;
Depending on the circumstances, you might continue bringing a release to&#13;
production, but at the same time, you need to understand why the&#13;
resource footprint of your application <a data-primary="global distribution" data-secondary="rollouts" data-startref="global-distro-rollout-valid" data-tertiary="pre-rollout validation" data-type="indexterm" id="id681"/><a data-primary="rollouts" data-secondary="global" data-startref="rollout-global-valid" data-tertiary="pre-rollout validation" data-type="indexterm" id="id682"/><a data-primary="testing" data-secondary="pre-rollout validation" data-startref="test-rollout-valid" data-type="indexterm" id="id683"/><a data-primary="load testing" data-startref="load-test" data-type="indexterm" id="id684"/><a data-primary="metrics" data-secondary="in load testing" data-secondary-sortas="load testing" data-startref="metrics-load-test" data-type="indexterm" id="id685"/>is changing.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Canary Region" data-type="sect2"><div class="sect2" id="id52">&#13;
<h2>Canary Region</h2>&#13;
&#13;
<p>When <a data-primary="global distribution" data-secondary="rollouts" data-tertiary="canary regions" data-type="indexterm" id="global-distro-rollout-canary"/><a data-primary="rollouts" data-secondary="global" data-tertiary="canary regions" data-type="indexterm" id="rollout-global-canary"/><a data-primary="canary regions" data-type="indexterm" id="canary-region"/>your application appears to be operating&#13;
correctly, the first step should be a <em>canary region</em>. A canary region is&#13;
a deployment that receives real-world traffic from people and teams who&#13;
want to validate your release. These can be internal teams that depend&#13;
on your service, or they might be external customers who are using your&#13;
service. Canaries exist to give a team some early warning about changes&#13;
that you are about to roll out that might break them. No matter how good&#13;
your integration and load testing, it’s always possible that a bug will&#13;
slip through that isn’t covered by your tests but is critical to some&#13;
user or customer. In such cases, it is much better to catch these issues&#13;
in a space where everyone using or deploying against the service&#13;
understands that there is a higher probability of failure. This is the canary region.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Canary is<a data-primary="self-testing" data-type="indexterm" id="id686"/> also a great place for your team or company to <em>dogfood</em> or&#13;
self-test the early release before it goes further in production. A great&#13;
best practice is to set up an HTTP redirector so that requests from&#13;
within your company are redirected to an instance of your product that&#13;
is running in canary. That way every person on your team becomes an&#13;
end-to-end tester before the release proceeds to external users.</p>&#13;
</div>&#13;
&#13;
<p>Canaries must be treated as a production region in&#13;
terms of monitoring, scale, features, and so on. However, because it is the&#13;
first stop on the release process, it is also the location most likely&#13;
to see a broken release. This is OK; in fact it is precisely the point.&#13;
Your customers will knowingly use a canary for lower-risk use cases (e.g., development or internal users) so that they can get an early&#13;
indication of any breaking changes that you might be rolling out as part&#13;
of a release.</p>&#13;
&#13;
<p>Because the goal of a canary is to get early feedback on a&#13;
release, it is a good idea to leave the release in the canary region for&#13;
a few days. This enables a broad collection of customers to access it before you move on to additional regions. This&#13;
length of time is needed because sometimes a bug is probabilistic (e.g., affects 1% of&#13;
requests), or it manifests only in an edge case that takes some time&#13;
to present itself. It might not even be severe enough to trigger automated&#13;
alerts, but there might be a problem in business logic that is&#13;
visible only via customer interactions.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Identifying Region Types" data-type="sect2"><div class="sect2" id="id273">&#13;
<h2>Identifying Region Types</h2>&#13;
&#13;
<p>When you<a data-primary="global distribution" data-secondary="rollouts" data-tertiary="region types" data-type="indexterm" id="id687"/><a data-primary="rollouts" data-secondary="global" data-tertiary="region types" data-type="indexterm" id="id688"/> begin thinking about rolling out your software across the world,&#13;
it’s important to think about the different characteristics of your&#13;
different regions. After you begin rolling out software to production&#13;
regions, you need to run it through integration testing as well as initial&#13;
canary testing. This means that any subsequent issues you find will be issues that&#13;
did not manifest in either of these settings. Think about your different&#13;
regions. Do some get more traffic than others? Are some accessed in a&#13;
different way? An example of a difference might be that in the&#13;
developing world, traffic is more likely to come from mobile web&#13;
browsers. Thus, a region that is geographically close to more developing&#13;
countries might have significantly more mobile traffic than your test or&#13;
canary regions.</p>&#13;
&#13;
<p>Another example might be input language. Regions in&#13;
non-English-speaking areas of the world might send more Unicode characters&#13;
that could manifest bugs in string or character handling. If you are&#13;
building an API-driven service, some APIs might be more popular in some&#13;
regions versus others. All these things are examples of <span class="keep-together">differences</span> that&#13;
might be present in your application and might be different than your canary&#13;
traffic. Each of these differences is a possible source of a production&#13;
incident. Build a table of different characteristics that you think are&#13;
important. Identifying these characteristics will help you plan your&#13;
global rollout.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Constructing a Global Rollout" data-type="sect2"><div class="sect2" id="id53">&#13;
<h2>Constructing a Global Rollout</h2>&#13;
&#13;
<p>Having <a data-primary="global distribution" data-secondary="rollouts" data-tertiary="planning" data-type="indexterm" id="global-distro-rollout-plan"/><a data-primary="rollouts" data-secondary="global" data-tertiary="planning" data-type="indexterm" id="rollout-global-plan"/><a data-primary="planning global distribution rollouts" data-type="indexterm" id="plan-global-rollout"/>identified the characteristics of your regions, you want&#13;
to identify a plan for rolling out to all regions. Obviously, you&#13;
want to minimize the impact of a production outage, so a great first&#13;
region to start with is a region that looks mostly like your canary and&#13;
has light user traffic. Such a region is very unlikely to have problems,&#13;
but if they do occur, the impact is also smaller because the region&#13;
receives less traffic.</p>&#13;
&#13;
<p>With a successful rollout to the first production region,&#13;
you need to decide how long to wait before moving on to the next region.&#13;
The reason for waiting is not to artificially delay your release; rather, it’s to wait long enough for a fire to send up smoke. This time-to-smoke period is a measure of how long it generally takes between a rollout&#13;
completing and your monitoring seeing some sign of a problem. Clearly if&#13;
a rollout contains a problem, the minute the rollout completes, the&#13;
problem is present in your infrastructure. But even though it is&#13;
present, it can take some time to manifest. For example, a memory leak&#13;
might take an hour or more before the impact of the leaked memory is&#13;
clearly discernible in monitoring or is affecting users. The time-to-smoke is the probability distribution that indicates how long you&#13;
should wait to have a strong probability that your release is&#13;
operating correctly. Generally speaking, a decent rule of thumb is&#13;
doubling the average time it took for a problem to manifest in the past.</p>&#13;
&#13;
<p>If, over the past six months, each outage took an average of an hour to&#13;
show up, waiting two hours between regional rollouts gives you a&#13;
decent probability that your release is successful. If you want to&#13;
derive richer (and more meaningful) statistics based on the history of&#13;
your application, you can estimate this time-to-smoke even more&#13;
closely.</p>&#13;
&#13;
<p>Having successfully rolled out to a canary-like, low-traffic&#13;
region, it’s time to roll out to a canary-like, high-traffic region.&#13;
This is a region where the input data looks like that in your canary,&#13;
but it receives a large volume of traffic. Because you successfully&#13;
rolled out to a similar-looking region with lower traffic, at this point&#13;
the only thing you are testing is your application’s ability to scale.&#13;
If you safely perform this rollout, you can have strong confidence&#13;
in the quality of your release.</p>&#13;
&#13;
<p>After you have rolled out to a high-traffic region receiving canary-like&#13;
data, you should follow the same pattern for other potential&#13;
differences in traffic. For example, you might roll out to a low-traffic&#13;
region in Asia or Europe next. At this point, it might be tempting to&#13;
accelerate your rollout, but it is critically important to roll&#13;
out only to a single region that represents any significant change in either&#13;
input or load to your release. After you are confident that you have&#13;
tested all the potential <span class="keep-together">variability</span> in the production input to your&#13;
application, then you can start parallelizing the release to speed it up&#13;
with strong confidence that it is operating correctly and your rollout&#13;
can complete<a data-primary="global distribution" data-secondary="rollouts" data-startref="global-distro-rollout-plan" data-tertiary="planning" data-type="indexterm" id="id689"/><a data-primary="rollouts" data-secondary="global" data-startref="rollout-global-plan" data-tertiary="planning" data-type="indexterm" id="id690"/><a data-primary="planning global distribution rollouts" data-startref="plan-global-rollout" data-type="indexterm" id="id691"/> successfully.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="When Something Goes Wrong" data-type="sect1"><div class="sect1" id="id54">&#13;
<h1>When Something Goes Wrong</h1>&#13;
&#13;
<p>So far,<a data-primary="global distribution" data-secondary="troubleshooting" data-type="indexterm" id="global-distro-rollout-troubleshoot"/><a data-primary="troubleshooting global distributions" data-type="indexterm" id="troubleshoot-global-rollout"/> we have seen the pieces that go into setting up a worldwide&#13;
rollout for your software system, and we have seen the ways that you can&#13;
structure this rollout to minimize the chances that something goes&#13;
wrong. But what do you do when something actually does go wrong? All&#13;
emergency responders know that in the heat and panic of a crisis,&#13;
your brain is significantly stressed and it is much more difficult to&#13;
remember even the simplest processes. Add to this pressure the&#13;
knowledge that when an outage happens, everyone in the company from the&#13;
CEO down is going to be feverishly waiting for the “all clear” signal,&#13;
and you can see how easy it is to make a mistake.&#13;
Additionally, in such circumstances, a simple mistake, like forgetting a&#13;
particular step in a recovery process, or rolling out a “fixed” build that actually has more problems,&#13;
can make a bad situation an order of magnitude worse.</p>&#13;
&#13;
<p>For all these reasons, it is critical that you are&#13;
capable of responding quickly, calmly, and correctly when a problem&#13;
happens with a rollout. To ensure that everything necessary is done, and&#13;
done in the correct order, it pays to have a clear checklist of tasks&#13;
organized in the order in which they are to be executed as well as the&#13;
expected output for each step. Write down every step, no matter how&#13;
obvious it might seem. In the heat of the moment, even the most obvious&#13;
and easy steps can be the ones that are forgotten and accidentally skipped.</p>&#13;
&#13;
<p>The way that first responders ensure a correct response in a&#13;
high-stress situation is to practice that response without the stress of&#13;
the emergency. The same practice applies to all the activities that you might take in response to a problem with your rollout. You begin by identifying all the steps needed to respond to an issue and perform a&#13;
rollback. Ideally, the first response is to “stop the bleeding,” to move&#13;
user traffic away from the impacted region(s) and into a region where&#13;
the rollout hasn’t happened and your system is operating correctly. This&#13;
is the first thing you should practice. Can you successfully direct&#13;
traffic away from a region? How long does it take?</p>&#13;
&#13;
<p>The first time you attempt to move traffic using a DNS-based traffic load balancer, you will realize just how long and in how many ways our computers cache DNS entries. It can take nearly a day to fully drain traffic away from a region using a DNS-based traffic shaper. Regardless of how your first attempt to drain traffic goes, take notes. What worked well? What went poorly? Given this data, set a goal for how long a traffic drain should take in terms of time to drain a percentage of traffic, for example, being able to drain 99% of traffic in less than 10 minutes. Keep practicing until you can achieve that goal. You might need to make architectural changes to make this possible. You might need to add automation so that humans aren’t cutting and pasting commands. Regardless of necessary changes, practice will ensure that you are more capable when responding to an incident and that you will learn where your system design needs to be improved.</p>&#13;
&#13;
<p>The same sort of practice applies to every action that you might take on&#13;
your system. Practice a full-scale data recovery. Practice a global&#13;
rollback of your system to a previous version. Set goals for the length&#13;
of time it should take. Note any places where you made mistakes, and&#13;
add validation and automation to eliminate the possibility of mistakes.&#13;
Achieving your incident reaction goals in practice gives you&#13;
confidence that you will be able to respond correctly in a real&#13;
incident. But just like every emergency responder continues to train and&#13;
learn, you too need to set up a regular cadence of practice to ensure&#13;
that everyone on a team stays well versed in the proper responses and&#13;
(perhaps more important) that your responses stay up to date as<a data-primary="global distribution" data-secondary="troubleshooting" data-startref="global-distro-rollout-troubleshoot" data-type="indexterm" id="id692"/><a data-primary="troubleshooting global distributions" data-startref="troubleshoot-global-rollout" data-type="indexterm" id="id693"/> your&#13;
system changes.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Worldwide Rollout Best Practices" data-type="sect1"><div class="sect1" id="id208">&#13;
<h1>Worldwide Rollout Best Practices</h1>&#13;
&#13;
<p>Rolling out <a data-primary="global distribution" data-secondary="best practices" data-type="indexterm" id="id694"/><a data-primary="best practices" data-secondary="global distribution" data-type="indexterm" id="id695"/>your software around the world, especially if you have never done it before, can be a significant challenge. Here are some best practices based on our years of production experience for how to manage the global deployment of mission critical software:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Distribute each image around the world. A successful rollout depends on the release bits (binaries, images, etc.) being nearby to where they will be used. This also ensures reliability of the rollout in the presence of networking slowdowns or irregularities. Geographic distribution should be&#13;
a part of your automated release pipeline for guaranteed consistency.</p>&#13;
</li>&#13;
<li>&#13;
<p>Shift as much of your testing as possible to the left by having as much extensive integration and replay testing of your application as possible. You want to start a rollout only with a release that you strongly believe to be correct.</p>&#13;
</li>&#13;
<li>&#13;
<p>Begin a release in a canary region, which is a preproduction environment&#13;
in which other teams or large customers can validate <em>their</em> use of your service before you begin a larger-scale rollout.</p>&#13;
</li>&#13;
<li>&#13;
<p>Identify different characteristics of the regions where you are rolling out. Each difference can be one that causes a failure and a full or partial outage. Try to roll out to low-risk regions first.</p>&#13;
</li>&#13;
<li>&#13;
<p>Document and practice your response to any problem or process (e.g., a rollback) that you might encounter. Trying to remember what to do in the&#13;
heat of the moment is a recipe for forgetting something and making a&#13;
bad problem worse.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id355">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>It might seem unlikely today, but most of us will end up running a&#13;
worldwide scale system sometime during our careers. This chapter&#13;
described how you can gradually build and iterate your system to be a&#13;
truly global design. It also discussed how you can set up your rollout&#13;
to ensure minimal downtime of the system while it is being updated.&#13;
Finally, we covered setting up and practicing the processes and procedures&#13;
necessary to react when (note that we didn’t say “if”) something goes&#13;
wrong.</p>&#13;
</div></section>&#13;
</div></section></body></html>