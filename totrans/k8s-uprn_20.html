<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 20. Policy and Governance &#10;for Kubernetes Clusters" data-type="chapter" epub:type="chapter"><div class="chapter" id="policy_and_governance_for_kubernetes_clusters">
<h1><span class="label">Chapter 20. </span>Policy and Governance 
<span class="keep-together">for Kubernetes Clusters</span></h1>
<p>Throughout this book we have introduced many different Kubernetes resource types, each with a specific purpose.<a data-primary="clusters" data-secondary="policy and governance for" data-type="indexterm" id="ix_clspolgov"/><a data-primary="policy and governance" data-type="indexterm" id="ix_polgov"/> It doesn’t take long before the resources on a Kubernetes cluster go from several, for a single microservice application, to hundreds and thousands, for a complete distributed application. In the context of a production cluster it isn’t hard to imagine the challenges associated with managing thousands of resources.</p>
<p>In this chapter, we introduce the concepts of policy and governance. <em>Policy</em> is a set of constraints and conditions for how Kubernetes resources can be configured. <em>Governance</em> provides the ability to verify and enforce organizational policies for all resources deployed to a Kubernetes cluster, such as ensuring all resources use current best practices, comply with security policy, or adhere to company conventions.<a data-primary="governance" data-seealso="policy and governance" data-type="indexterm" id="idm45664068530416"/> Whatever your case may be, your tooling needs to be flexible and scalable so that all resources defined on a cluster comply with your organization’s defined policies.</p>
<section data-pdf-bookmark="Why Policy and Governance Matter" data-type="sect1"><div class="sect1" id="idm45664068528992">
<h1>Why Policy and Governance Matter</h1>
<p>There are many different types of policies in Kubernetes. <a data-primary="policy and governance" data-secondary="importance of" data-type="indexterm" id="idm45664068527552"/>For example, NetworkPolicy allows you to specify what network services and endpoints a Pod can connect to. PodSecurityPolicy enables fine-grained control over the security elements of a Pod. Both can be used to configure network or container runtimes.</p>
<p>However, you might want to enforce a policy before Kubernetes resources are even created. This is the problem that policy and governance solve. At this point, you might be thinking, “Isn’t this what role-based access control does?” However, as you’ll see in this chapter, RBAC isn’t granular enough to restrict specific fields within resources from being set.</p>
<p>Here are some common examples of policies that cluster administrators often 
<span class="keep-together">configure</span>:</p>
<ul>
<li>
<p>All containers <em>must</em> only come from a specific container registry.</p>
</li>
<li>
<p>All Pods <em>must</em> be labeled with the department name and contact information.</p>
</li>
<li>
<p>All Pods <em>must</em> have both CPU and memory resource limits set.</p>
</li>
<li>
<p>All Ingress hostnames <em>must</em> be unique across a cluster.</p>
</li>
<li>
<p>A certain service <em>must</em> not be made available on the internet.</p>
</li>
<li>
<p>Containers <em>must</em> not listen on privileged ports.</p>
</li>
</ul>
<p>Cluster administrators may also want to audit existing resources on a cluster, perform dry-run policy evaluations, or even mutate a resource based on a set of conditions—for example, applying labels to a Pod if they aren’t present.</p>
<p>It’s very important for cluster administrators to be able to define policy and perform compliance audits without interfering with the developers’ ability to deploy applications to Kubernetes. If developers are creating noncompliant resources, you need a system to make sure they get the feedback and remediation they need to bring their work into compliance.</p>
<p>Let’s take a look at how to achieve policy and governance by leveraging core extensibility components of Kubernetes.</p>
</div></section>
<section data-pdf-bookmark="Admission Flow" data-type="sect1"><div class="sect1" id="idm45664068514272">
<h1>Admission Flow</h1>
<p>To understand how policy and governance ensures resources are compliant before they are created in your<a data-primary="APIs" data-secondary="Kubernetes API server request flow" data-type="indexterm" id="idm45664068512832"/><a data-primary="policy and governance" data-secondary="admission flow" data-type="indexterm" id="idm45664068511888"/><a data-primary="admission flow" data-type="indexterm" id="idm45664068510944"/> Kubernetes cluster, you must first understand the request flow through the Kubernetes API server. <a data-type="xref" href="#fig1701">Figure 20-1</a> depicts the flow of an API request through the API server. Here, we’ll focus on mutating admission, validating admission, and webhooks.<a data-primary="webhooks" data-type="indexterm" id="idm45664068509232"/></p>
<figure><div class="figure" id="fig1701">
<img alt="kur3 2001" height="514" src="assets/kur3_2001.png" width="1431"/>
<h6><span class="label">Figure 20-1. </span>API request flow through the Kubernetes API server</h6>
</div></figure>
<p>Admission controllers operate inline as an API request flows through the Kubernetes API server and are used to either mutate or validate the API request resource before it’s saved to storage.<a data-primary="admission controllers" data-type="indexterm" id="idm45664068506144"/> Mutating admission controllers allow the resource to be modified; validating admission controllers do not. There are many different types of admission controllers; this chapter focuses on admission webhooks, which are dynamically configurable. They allow a cluster administrator to configure an endpoint to which the API server can send requests for evaluation by creating either a MutatingWebhookConfiguration or a ValidatingWebhookConfiguration resource. The admission webhook will respond with an “admit” or “deny” directive to let the API server know whether to save the resource to storage.</p>
</div></section>
<section data-pdf-bookmark="Policy and Governance with Gatekeeper" data-type="sect1"><div class="sect1" id="idm45664068505056">
<h1>Policy and Governance with Gatekeeper</h1>
<p>Let’s dive into how to configure policies and ensure that Kubernetes resources are compliant.<a data-primary="policy and governance" data-secondary="using Gatekeeper" data-type="indexterm" id="ix_polgovGate"/><a data-primary="Gatekeeper" data-type="indexterm" id="ix_Gate"/> The Kubernetes project doesn’t provide any controllers that enable policy and governance, but there are open source solutions. Here, we will focus on an open source ecosystem project called <a href="https://oreil.ly/u0deR">Gatekeeper</a>.</p>
<p>Gatekeeper is a Kubernetes-native policy controller that evaluates resources based on defined policy and determines whether to allow a Kubernetes resource to be created or modified. These evaluations happen server-side as the API request flows through the Kubernetes API server, which means each cluster has a single point of processing. Processing the policy evaluations server-side means that you can install Gatekeeper on existing Kubernetes clusters without changing developer tooling, workflows, or continuous delivery pipelines.</p>
<p>Gatekeeper uses <em>custom resource definitions</em> (CRDs) to define a new set of Kubernetes resources specific to configuring it, which allows cluster administrators to use familiar tools like <code>kubectl</code> to operate Gatekeeper.<a data-primary="custom resource definitions (CRDs)" data-secondary="use by Gatekeeper" data-type="indexterm" id="idm45664068498128"/> In addition, it provides real-time, meaningful feedback to the user on why a resource was denied and how to remediate the problem. These Gatekeeper-specific custom resources can be stored in source control and managed using GitOps workflows.</p>
<p>Gatekeeper also performs <em>resource mutation</em> (resource modification based on defined conditions) and auditing.<a data-primary="resource mutation" data-type="indexterm" id="idm45664068496128"/> It is highly configurable and offers fine-grained control over what resources to evaluate and in which namespaces.</p>
<section data-pdf-bookmark="What Is Open Policy Agent?" data-type="sect2"><div class="sect2" id="idm45664068495040">
<h2>What Is Open Policy Agent?</h2>
<p>At the core of Gatekeeper is <a href="https://oreil.ly/nbR5d">Open Policy Agent</a>, a cloud native open source policy engine that is extensible and allows policy to be portable across different applications.<a data-primary="Open Policy Agent" data-type="indexterm" id="idm45664068492992"/><a data-primary="Gatekeeper" data-secondary="Open Policy Agent" data-type="indexterm" id="idm45664068492288"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="Open Policy Agent" data-type="indexterm" id="idm45664068491344"/> Open Policy Agent (OPA) is responsible for performing all policy evaluations and returning either an admit or deny. This gives Gatekeeper access to an ecosystem of policy tooling, such as, <a href="https://oreil.ly/ElWYE">Conftest</a>, which enables you to write policy tests and implement them in continuous integration pipelines before deployment.</p>
<p>Open Policy Agent exclusively uses a native query language called <a href="https://oreil.ly/Ar55f">Rego</a> for all policies.<a data-primary="Rego query language" data-type="indexterm" id="idm45664068488032"/> One of the core tenets of Gatekeeper is to abstract the inner workings of Rego from the cluster administrator and present a structured API in the form of a Kubernetes CRD to create and apply policy. This lets you share parameterized policies across organizations and the community. The Gatekeeper project maintains a policy library solely for this purpose (discussed later in this chapter).</p>
</div></section>
<section data-pdf-bookmark="Installing Gatekeeper" data-type="sect2"><div class="sect2" id="idm45664068486912">
<h2>Installing Gatekeeper</h2>
<p>Before you start configuring policies, you’ll need to install Gatekeeper. Gatekeeper components run as Pods in the <code>gatekeeper-system</code> namespace and configure a webhook admission controller.<a data-primary="Gatekeeper" data-secondary="installing" data-type="indexterm" id="idm45664068484736"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="installing Gatekeeper" data-type="indexterm" id="idm45664068483680"/></p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Do not install Gatekeeper on a Kubernetes cluster without first understanding how to safely create and disable policy. You should also review the installation YAML before installing Gatekeeper to ensure that you are comfortable with the resources it creates.</p>
</div>
<p>You can install Gatekeeper <a data-primary="Helm tool" data-secondary="installing Gatekeeper with" data-type="indexterm" id="idm45664068480896"/>using the Helm package manager:</p>
<pre data-type="programlisting">
$ <strong>helm repo add gatekeeper https://open-policy-agent.github.io/gatekeeper/charts</strong>
$ <strong>helm install gatekeeper/gatekeeper --name-template=gatekeeper \
  --namespace gatekeeper-system --create-</strong>
</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Gatekeeper installation requires cluster-admin permissions and is version specific. Please refer to the official documentation for the latest release of <a href="https://oreil.ly/GvLHc">Gatekeeper</a>.</p>
</div>
<p>Once the installation is complete, confirm that Gatekeeper is up and running:</p>
<pre data-type="programlisting">$ <strong>kubectl get pods -n gatekeeper-system</strong>
NAME                                             READY   STATUS    RESTARTS  AGE
gatekeeper-audit-54c9759898-ljwp8                1/1     Running   0         1m
gatekeeper-controller-manager-6bcc7f8fb5-4nbkt   1/1     Running   0         1m
gatekeeper-controller-manager-6bcc7f8fb5-d85rn   1/1     Running   0         1m
gatekeeper-controller-manager-6bcc7f8fb5-f8m8j   1/1     Running   0         1m
</pre>
<p>You can also review how the <a data-primary="webhooks" data-secondary="ValidatingWebhookConfiguration" data-type="indexterm" id="idm45664068474096"/><a data-primary="ValidatingWebhookConfiguration" data-type="indexterm" id="idm45664068473056"/>webhook is configured using this command:</p>
<pre data-type="programlisting">$ <strong>kubectl get validatingwebhookconfiguration -o yaml</strong>
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    gatekeeper.sh/system: "yes"
  name: gatekeeper-validating-webhook-configuration
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: gatekeeper-webhook-service
      namespace: gatekeeper-system
      path: /v1/admit
  failurePolicy: Ignore
  matchPolicy: Exact
  name: validation.gatekeeper.sh
  namespaceSelector:
    matchExpressions:
    - key: admission.gatekeeper.sh/ignore
      operator: DoesNotExist
  rules:
  - apiGroups:
    - '*'
    apiVersions:
    - '*'
    operations:
    - CREATE
    - UPDATE
    resources:
    - '*'
  sideEffects: None
  timeoutSeconds: 3
	...</pre>
<p>Under the <code>rules</code> section of the output above, we see that all resources are being sent to the webhook admission controller, running as a service named <code>gatekeeper-webhook-service</code> in the <code>gatekeeper-system</code> namespace. Only resources from namespaces that aren’t labeled <code>admission.gatekeeper.sh/ignore</code> will be considered for policy evaluation. Finally, the <code>failurePolicy</code> is set to <code>Ignore</code>, which means that this is a <em>fail open configuration</em>: if the Gatekeeper service doesn’t respond within the configured timeout of three seconds, the request will be admitted. <a data-primary="fail open configuration" data-type="indexterm" id="idm45664068466784"/><a data-primary="configurations" data-secondary="fail open configuration" data-type="indexterm" id="idm45664068466080"/></p>
</div></section>
<section data-pdf-bookmark="Configuring Policies" data-type="sect2"><div class="sect2" id="idm45664068486320">
<h2>Configuring Policies</h2>
<p>Now that you have Gatekeeper installed, you can start configuring policies.<a data-primary="Gatekeeper" data-secondary="configuring policies" data-type="indexterm" id="ix_Gatecfgpol"/> We will first go through a canonical example and demonstrate how the cluster administrator creates policies.<a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="configuring policies" data-type="indexterm" id="ix_polgovGatecfgpol"/> Then we’ll look at the developer experience when creating compliant and noncompliant resources. We will then expand on each step to gain a deeper understanding, and walk you through the process of creating a sample policy stating that container images can only come from one specific registry. This example is based on the <a href="https://oreil.ly/ikfZk">Gatekeeper policy library</a>.</p>
<p>First, you’ll need to configure the policy we need to create a custom resource called a <em>constraint template</em>. <a data-primary="constraint templates" data-type="indexterm" id="idm45664068458848"/>This is usually done by a cluster administrator. The constraint template in <a data-type="xref" href="#example1701">Example 20-1</a> requires you to provide a list of container repositories as parameters that Kubernetes resources are allowed to use.</p>
<div data-type="example" id="example1701">
<h5><span class="label">Example 20-1. </span>allowedrepos-constraint-template.yaml</h5>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">templates.gatekeeper.sh/v1beta1</code><code class="w"/>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">ConstraintTemplate</code><code class="w"/>
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">k8sallowedrepos</code><code class="w"/>
<code class="w">  </code><code class="nt">annotations</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">description</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Requires container images to begin with a repo string from a</code><code class="w"/>
<code class="w">      </code><code class="l-Scalar-Plain">specified list.</code><code class="w"/>
<code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">crd</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="nt">names</code><code class="p">:</code><code class="w"/>
<code class="w">        </code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">K8sAllowedRepos</code><code class="w"/>
<code class="w">      </code><code class="nt">validation</code><code class="p">:</code><code class="w"/>
<code class="w">        </code><code class="c1"># Schema for the `parameters` field</code><code class="w"/>
<code class="w">        </code><code class="nt">openAPIV3Schema</code><code class="p">:</code><code class="w"/>
<code class="w">          </code><code class="nt">properties</code><code class="p">:</code><code class="w"/>
<code class="w">            </code><code class="nt">repos</code><code class="p">:</code><code class="w"/>
<code class="w">              </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">array</code><code class="w"/>
<code class="w">              </code><code class="nt">items</code><code class="p">:</code><code class="w"/>
<code class="w">                </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">string</code><code class="w"/>
<code class="w">  </code><code class="nt">targets</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">target</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">admission.k8s.gatekeeper.sh</code><code class="w"/>
<code class="w">      </code><code class="nt">rego</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">|</code><code class="w"/>
<code class="w">        </code><code class="no">package k8sallowedrepos</code><code class="w"/>

<code class="w">        </code><code class="no">violation[{"msg": msg}] {</code><code class="w"/>
<code class="w">          </code><code class="no">container := input.review.object.spec.containers[_]</code><code class="w"/>
<code class="w">          </code><code class="no">satisfied := [good | repo = input.parameters.repos[_] ; good = starts...</code><code class="w"/>
<code class="w">          </code><code class="no">not any(satisfied)</code><code class="w"/>
<code class="w">          </code><code class="no">msg := sprintf("container &lt;%v&gt; has an invalid image repo &lt;%v&gt;, allowed...</code><code class="w"/>
<code class="w">        </code><code class="no">}</code><code class="w"/>

<code class="w">        </code><code class="no">violation[{"msg": msg}] {</code><code class="w"/>
<code class="w">          </code><code class="no">container := input.review.object.spec.initContainers[_]</code><code class="w"/>
<code class="w">          </code><code class="no">satisfied := [good | repo = input.parameters.repos[_] ; good = starts...</code><code class="w"/>
<code class="w">          </code><code class="no">not any(satisfied)</code><code class="w"/>
<code class="w">          </code><code class="no">msg := sprintf("container &lt;%v&gt; has an invalid image repo &lt;%v&gt;, allowed...)</code><code class="w"/>
<code class="w">        </code><code class="no">}</code><code class="w"/></pre></div>
<p>Create the constraint template using the following command:</p>
<pre data-type="programlisting">$ <strong>kubectl apply -f allowedrepos-constraint-template.yaml</strong>
constrainttemplate.templates.gatekeeper.sh/k8sallowedrepos created</pre>
<p>Now you can create a constraint resource to put the policy into effect (again, playing the role of the cluster administrator). The constraint in <a data-type="xref" href="#example1702">Example 20-2</a> allows all containers with the prefix of <code>gcr.io/kuar-demo/</code> in the <code>default</code> namespace. The <code>enforcementAction</code> is set to “deny”: any noncompliant resources will be denied.</p>
<div data-type="example" id="example1702">
<h5><span class="label">Example 20-2. </span>allowedrepos-constraint.yaml</h5>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">constraints.gatekeeper.sh/v1beta1</code><code class="w"/>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">K8sAllowedRepos</code><code class="w"/>
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">repo-is-kuar-demo</code><code class="w"/>
<code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">enforcementAction</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">deny</code><code class="w"/>
<code class="w">  </code><code class="nt">match</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">kinds</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">apiGroups</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">""</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">        </code><code class="nt">kinds</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"Pod"</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">    </code><code class="nt">namespaces</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="s">"default"</code><code class="w"/>
<code class="w">  </code><code class="nt">parameters</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">repos</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="s">"gcr.io/kuar-demo/"</code><code class="w"/></pre></div>
<pre data-type="programlisting">$ <strong>kubectl create -f allowedrepos-constraint.yaml</strong>
k8sallowedrepos.constraints.gatekeeper.sh/repo-is-kuar-demo created</pre>
<p>The next step is to create some Pods to test that the policy is indeed working.<a data-primary="Pods" data-secondary="creating to test policy" data-type="indexterm" id="idm45664068280832"/> <a data-type="xref" href="#example1703">Example 20-3</a> creates a Pod using a container image, <code>gcr.io/kuar-demo/kuard-amd64:blue</code>, that complies with the constraint we defined in the previous step. Workload resource creation is typically performed by the developer responsible for operating the service or a continuous delivery pipeline.</p>
<div data-type="example" id="example1703">
<h5><span class="label">Example 20-3. </span>compliant-pod.yaml</h5>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Pod</code><code class="w"/>
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">kuard</code><code class="w"/>
<code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">gcr.io/kuar-demo/kuard-amd64:blue</code><code class="w"/>
<code class="w">      </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">kuard</code><code class="w"/>
<code class="w">      </code><code class="nt">ports</code><code class="p">:</code><code class="w"/>
<code class="w">        </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">containerPort</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">8080</code><code class="w"/>
<code class="w">          </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">http</code><code class="w"/>
<code class="w">          </code><code class="nt">protocol</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">TCP</code><code class="w"/></pre></div>
<pre data-type="programlisting">$ <strong>kubectl apply -f compliant-pod.yaml</strong>
pod/kuard created</pre>
<p>What happens if we create a noncompliant Pod? <a data-type="xref" href="#example1704">Example 20-4</a> creates a Pod using a container image, <code>nginx</code>, that is <em>not</em> compliant with the constraint we defined in the previous step. Workload resource creation would typically be performed by the developer or continuous delivery pipeline responsible for operating the service. Note the output in <a data-type="xref" href="#example1704">Example 20-4</a>.</p>
<div data-type="example" id="example1704">
<h5><span class="label">Example 20-4. </span>noncompliant-pod.yaml</h5>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Pod</code><code class="w"/>
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">nginx-noncompliant</code><code class="w"/>
<code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">containers</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">nginx</code><code class="w"/>
<code class="w">      </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">nginx</code><code class="w"/></pre></div>
<pre data-type="programlisting">$ <strong>kubectl apply -f noncompliant-pod.yaml</strong>
Error from server ([repo-is-kuar-demo] container &lt;nginx&gt; has an invalid image
repo &lt;nginx&gt;, allowed repos are ["gcr.io/kuar-demo/"]): error when creating
"noncompliant-pod.yaml": admission webhook "validation.gatekeeper.sh" denied
the request: [repo-is-kuar-demo] container &lt;nginx&gt; has an invalid image
repo &lt;nginx&gt;, allowed repos are ["gcr.io/kuar-demo/"]</pre>
<p><a data-type="xref" href="#example1704">Example 20-4</a> shows that an error is returned to the user with details on why the resource was not created and how to remediate the issue. Cluster administrators can configure the error message in the constraint template.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If your constraint’s scope is Pods and you create a resource that generates Pods, such as ReplicaSets, Gatekeeper will return an error. However, it won’t be returned to you, the user, but to the controller trying to create the Pod. To see these error messages, look in the event log for the relevant resource.<a data-primary="Gatekeeper" data-secondary="configuring policies" data-startref="ix_Gatecfgpol" data-type="indexterm" id="idm45664068021280"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-startref="ix_polgovGatecfgpol" data-tertiary="configuring policies" data-type="indexterm" id="idm45664068020032"/></p>
</div>
</div></section>
<section data-pdf-bookmark="Understanding Constraint Templates" data-type="sect2"><div class="sect2" id="idm45664068018160">
<h2>Understanding Constraint Templates</h2>
<p>Now that we have walked through a canoncial example, take a closer look at the constraint template in <a data-type="xref" href="#example1701">Example 20-1</a>, which takes a list of container repositories that are allowed in Kubernetes resources.<a data-primary="constraint templates" data-secondary="understanding" data-type="indexterm" id="idm45664068015840"/><a data-primary="Gatekeeper" data-secondary="understanding constraint templates" data-type="indexterm" id="idm45664068014896"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="understanding constraint templates" data-type="indexterm" id="idm45664068013984"/></p>
<p>This constraint template has an <code>apiVersion</code> and <code>kind</code> that are part of the custom resources used only by Gatekeeper. Under the <code>spec</code> section, you’ll see the name <code>K8sAllowedRepos</code>: remember that name, because you’ll use it as the constraint kind when creating constraints. You’ll also see a schema that defines an array of strings for the cluster administrator to configure. This is done by providing a list of allowed container registries. It also contains the raw Rego policy definition (under the <code>target</code> section). This policy evaluates containers and initContainers to ensure that the container repository name starts with the values provided by the constraint. The <code>msg</code> section defines the message that is sent back to the user if the policy is violated.</p>
</div></section>
<section data-pdf-bookmark="Creating Constraints" data-type="sect2"><div class="sect2" id="idm45664067961696">
<h2>Creating Constraints</h2>
<p>To instantiate a policy, you must create a constraint that provides the template’s required parameters.<a data-primary="constraints" data-secondary="creating" data-type="indexterm" id="idm45664067960192"/><a data-primary="Gatekeeper" data-secondary="creating constraints" data-type="indexterm" id="idm45664067959344"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="creating constraints" data-type="indexterm" id="idm45664067958432"/> There may be many constraints that match the kind of a specific constraint template. Let’s take a closer look at the constraint we used in <a data-type="xref" href="#example1702">Example 20-2</a>, which allows only container images that originate from <em>gcr.io/kuar-demo/</em>.</p>
<p>You may notice that the constraint is of the <code>kind</code> “K8sAllowedRepos,” which was defined as part of the constraint template. It also defines an <code>enforcementAction</code> of “deny,” meaning that noncompliant resources will be denied. <code>enforcementAction</code> also accepts “dryrun” and “warn”: “dryrun” uses the audit feature to test policies and verify their impact; “warn” sends a warning back to the user with the associated message, but allows them to create or update. The <code>match</code> portion defines the scope of this constraint, all Pods in the default namespace. Finally, the <code>parameters</code> section is required to satisfy the constraint template (an array of strings). The following demonstrates the user experience when the <code>enforcementAction</code> is set to “warn”:</p>
<pre data-type="programlisting">$ <strong>kubectl apply -f noncompliant-pod.yaml</strong>
Warning: [repo-is-kuar-demo] container &lt;nginx&gt; has an invalid image repo...
pod/nginx-noncompliant created</pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Constraints are only enforced on resource CREATE and UPDATE events. If you already have workloads running on a cluster, Gatekeeper will not  reevaluate them until a CREATE or UPDATE event takes place.</p>
<p>Here is a real-world example to demonstrate: say you create a policy that only allows containers from a specific registry. All workloads that are already running on the cluster will continue to do so. If you scale the workload Deployment from 1 to 2, the ReplicaSet will attempt to create another Pod. If that Pod doesn’t have a container from an allowed repository, then it will be denied. It’s important to set the <code>enforcementAction</code> to “dryrun” and audit to confirm that any policy violations are known before setting the <code>enforcementAction</code> to “deny.”</p>
</div>
</div></section>
<section class="pagebreak-before less_space" data-pdf-bookmark="Audit" data-type="sect2"><div class="sect2" id="idm45664067948592">
<h2>Audit</h2>
<p>Being able to enforce policy on new resources is only one piece of the policy and governance story.<a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="auditing" data-type="indexterm" id="idm45664067946240"/><a data-primary="auditing" data-type="indexterm" id="idm45664067944992"/><a data-primary="Gatekeeper" data-secondary="auditing" data-type="indexterm" id="idm45664067944320"/> Policies often change over time, and you can also use Gatekeeper to confirm that everything currently deployed is still compliant. Additionally, you may already have a cluster full of services and wish to install Gatekeeper to bring these resources into compliance. Gatekeeper’s audit capabilities allow cluster administrators to get a list of current, noncompliant resources on a cluster.</p>
<p>To demonstrate how auditing works, let’s look at an example. We’re going to update the <code>repo-is-kuar-demo</code> constraint to have an <code>enforcementAction</code> action of “dryrun” (as shown in <a data-type="xref" href="#example1707">Example 20-5</a>). This will allow users to create noncompliant resources. We will then determine which resources are noncompliant using audit.<a data-primary="constraints" data-secondary="updating" data-type="indexterm" id="idm45664067941056"/></p>
<div data-type="example" id="example1707">
<h5><span class="label">Example 20-5. </span>allowedrepos-constraint-dryrun.yaml</h5>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">constraints.gatekeeper.sh/v1beta1</code><code class="w"/>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">K8sAllowedRepos</code><code class="w"/>
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">repo-is-kuar-demo</code><code class="w"/>
<code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">enforcementAction</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">dryrun</code><code class="w"/>
<code class="w">  </code><code class="nt">match</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">kinds</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">apiGroups</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">""</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">        </code><code class="nt">kinds</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"Pod"</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">    </code><code class="nt">namespaces</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="s">"default"</code><code class="w"/>
<code class="w">  </code><code class="nt">parameters</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">repos</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="s">"gcr.io/kuar-demo/"</code><code class="w"/></pre></div>
<p>Update the constraint by running the following command:</p>
<pre data-type="programlisting">$ <strong>kubectl apply -f allowedrepos-constraint-dryrun.yaml</strong>
k8sallowedrepos.constraints.gatekeeper.sh/repo-is-kuar-demo configured</pre>
<p>Create a noncompliant Pod using the following command:</p>
<pre data-type="programlisting">$ <strong>kubectl apply -f noncompliant-pod.yaml</strong>
pod/nginx-noncompliant created</pre>
<p>To audit the list of noncompliant resources for a given constraint, run a <code>kubectl get constraint</code> on that <a data-primary="constraints" data-secondary="auditing list of non-compliant resources for" data-type="indexterm" id="idm45664067894256"/>constraint and specify that you want the output in YAML format as follows:</p>
<pre data-type="programlisting">$ <strong>kubectl get constraint repo-is-kuar-demo -o yaml</strong>
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sAllowedRepos
...
spec:
  enforcementAction: dryrun
  match:
    kinds:
    - apiGroups:
      - ""
      kinds:
      - Pod
    namespaces:
    - default
  parameters:
    repos:
    - gcr.io/kuar-demo/
status:
  auditTimestamp: "2021-07-14T20:05:38Z"
	...
  totalViolations: 1
  violations:
  - enforcementAction: dryrun
    kind: Pod
    message: container &lt;nginx&gt; has an invalid image repo &lt;nginx&gt;, allowed repos
      are ["gcr.io/kuar-demo/"]
    name: nginx-noncompliant
    namespace: default</pre>
<p>Under the <code>status</code> section, you can see the <code>auditTimestamp</code>, which is the last time the audit was run. <code>totalViolations</code> lists the number of resources that violate this constraint. The <code>violations</code> section lists the violations. We can see that the nginx-noncompliant Pod is in violation and the message with the details why.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Using a constraint <code>enforcementAction</code> of “dryrun” along with audit is a powerful way to confirm that your policy is having the desired impact. It also creates a workflow to bring resources into compliance.<a data-primary="constraints" data-secondary="enforcementAction of dryrun" data-type="indexterm" id="idm45664067888192"/></p>
</div>
</div></section>
<section data-pdf-bookmark="Mutation" data-type="sect2"><div class="sect2" id="idm45664067947968">
<h2>Mutation</h2>
<p>So far we have covered how you can use constraints to validate if a resource is compliant. <a data-primary="Gatekeeper" data-secondary="mutation features" data-type="indexterm" id="idm45664067885312"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="mutation" data-type="indexterm" id="idm45664067815552"/><a data-primary="resource mutation" data-type="indexterm" id="idm45664067814400"/><a data-primary="mutation" data-type="indexterm" id="idm45664067813728"/>What about modifying resources to make them compliant? This is handled via the mutation feature in Gatekeeper. Earlier in this chapter, we discussed two different type of admission webhooks, mutating and validating.<a data-primary="webhooks" data-secondary="mutating and validating admission webhooks" data-type="indexterm" id="idm45664067812928"/> By default, Gatekeeper is only deployed as a validating admission webhook, but it can be configured to operate as a mutating admission webhook.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Mutation features in Gatekeeper are in beta state and may change. We share them to demonstrate Gatekeeper’s upcoming capabilities. The installation steps in this chapter do not cover enabling mutation. Please refer to the Gatekeeper project for more information on <a href="https://oreil.ly/DQKhl">enabling mutation</a>.</p>
</div>
<p>Let’s walk through an example to demonstrate the power of mutation. In this example, we will set the <code>imagePullPolicy</code> to “Always” on all Pods. We will assume that Gatekeeper is configured correctly to support mutation. <a data-type="xref" href="#example1708">Example 20-6</a> defines a mutation assignment that matches all Pods except those in the “system” namespace, and assigns a value of “Always” to <code>imagePullPolicy</code>.</p>
<div data-type="example" id="example1708">
<h5><span class="label">Example 20-6. </span>imagepullpolicyalways-mutation.yaml</h5>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">mutations.gatekeeper.sh/v1alpha1</code><code class="w"/>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Assign</code><code class="w"/>
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo-image-pull-policy</code><code class="w"/>
<code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">applyTo</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">groups</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">""</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">    </code><code class="nt">kinds</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"Pod"</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">    </code><code class="nt">versions</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"v1"</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">  </code><code class="nt">match</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">scope</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Namespaced</code><code class="w"/>
<code class="w">    </code><code class="nt">kinds</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">apiGroups</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"*"</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">      </code><code class="nt">kinds</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"Pod"</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">    </code><code class="nt">excludedNamespaces</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">[</code><code class="s">"system"</code><code class="p-Indicator">]</code><code class="w"/>
<code class="w">  </code><code class="nt">location</code><code class="p">:</code><code class="w"> </code><code class="s">"spec.containers[name:*].imagePullPolicy"</code><code class="w"/>
<code class="w">  </code><code class="nt">parameters</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">assign</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="nt">value</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Always</code><code class="w"/></pre></div>
<p>Create the mutation assignment:</p>
<pre data-type="programlisting">$ <strong>kubectl apply -f imagepullpolicyalways-mutation.yaml</strong>
assign.mutations.gatekeeper.sh/demo-image-pull-policy created</pre>
<p>Now create a Pod. This Pod doesn’t have <code>imagePullPolicy</code> explicitly set, so by default this field is set to “IfNotPresent.” However, we expect Gatekeeper to mutate this field to “Always”:</p>
<pre data-type="programlisting">$ <strong>kubectl apply -f compliant-pod.yaml</strong>
pod/kuard created</pre>
<p>Validate that the <code>imagePullPolicy</code> has been successfully mutated to “Always” by running the following:</p>
<pre data-type="programlisting">$ <strong>kubectl get pods kuard -o=jsonpath="{.spec.containers[0].imagePullPolicy}"
</strong>
Always</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Mutating admission happens before validating admission, so create constraints that validate the mutations you expect to apply to the specific resource.</p>
</div>
<p>Delete the Pod using the following command:</p>
<pre data-type="programlisting">$ <strong>kubectl delete -f compliant-pod.yaml</strong>
pod/kuard deleted</pre>
<p>Delete the mutation assignment using the following command:</p>
<pre data-type="programlisting">$ <strong>kubectl delete -f imagepullpolicyalways-mutation.yaml</strong>
assign.mutations.gatekeeper.sh/demo-image-pull-policy deleted</pre>
<p>Unlike validation, mutation provides a way to remediate noncompliant resources automatically on behalf of the cluster administrator.</p>
</div></section>
<section data-pdf-bookmark="Data Replication" data-type="sect2"><div class="sect2" id="idm45664067886528">
<h2>Data Replication</h2>
<p>When writing constraints you may want to compare the value of one field to the value of a field in another resource.<a data-primary="data replication" data-type="indexterm" id="idm45664067743376"/><a data-primary="Gatekeeper" data-secondary="data replication" data-type="indexterm" id="idm45664067742672"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="data replication" data-type="indexterm" id="idm45664067741728"/> A specific example of when you might need to do this is making sure that ingress hostnames are unique across a cluster. By default, Gatekeeper can only evaluate fields within the current resource: if comparisons across resources are required to fulfill a policy, it must be configured. Gatekeeper can be configured to cache specific resources into Open Policy Agent to allow comparisons across resources.<a data-primary="Open Policy Agent" data-type="indexterm" id="idm45664067740384"/> The resource in <a data-type="xref" href="#example1709">Example 20-7</a> configures Gatekeeper to cache Namespace and Pod resources.</p>
<div data-type="example" id="example1709">
<h5><span class="label">Example 20-7. </span>config-sync.yaml</h5>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">config.gatekeeper.sh/v1alpha1</code><code class="w"/>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Config</code><code class="w"/>
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">config</code><code class="w"/>
<code class="w">  </code><code class="nt">namespace</code><code class="p">:</code><code class="w"> </code><code class="s">"gatekeeper-system"</code><code class="w"/>
<code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">sync</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">syncOnly</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">group</code><code class="p">:</code><code class="w"> </code><code class="s">""</code><code class="w"/>
<code class="w">        </code><code class="nt">version</code><code class="p">:</code><code class="w"> </code><code class="s">"v1"</code><code class="w"/>
<code class="w">        </code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="s">"Namespace"</code><code class="w"/>
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">group</code><code class="p">:</code><code class="w"> </code><code class="s">""</code><code class="w"/>
<code class="w">        </code><code class="nt">version</code><code class="p">:</code><code class="w"> </code><code class="s">"v1"</code><code class="w"/>
<code class="w">        </code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="s">"Pod"</code><code class="w"/></pre></div>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You should only cache the specific resources needed to perform a policy evaluation. Having hundreds or thousands of resources cached in OPA will require more memory and may also have security implications.</p>
</div>
<p>The constraint template in <a data-type="xref" href="#example1710">Example 20-8</a> demonstrates how to compare something in the Rego section (in this case, unique ingress hostnames).<a data-primary="constraint templates" data-secondary="unique ingress host" data-type="indexterm" id="idm45664067547712"/> Specifically, “data.inventory” refers to the cache resources, as opposed to “input,” which is the resource sent for evaluation from the Kubernetes API server as part of the admission flow. This example is based on the <a href="https://oreil.ly/gGrts">Gatekeeper policy library</a>.</p>
<div data-type="example" id="example1710">
<h5><span class="label">Example 20-8. </span>uniqueingresshost-constraint-template.yaml</h5>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">templates.gatekeeper.sh/v1beta1</code><code class="w"/>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">ConstraintTemplate</code><code class="w"/>
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">k8suniqueingresshost</code><code class="w"/>
<code class="w">  </code><code class="nt">annotations</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">description</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Requires all Ingress hosts to be unique.</code><code class="w"/>
<code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">crd</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">spec</code><code class="p">:</code><code class="w"/>
<code class="w">      </code><code class="nt">names</code><code class="p">:</code><code class="w"/>
<code class="w">        </code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">K8sUniqueIngressHost</code><code class="w"/>
<code class="w">  </code><code class="nt">targets</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">target</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">admission.k8s.gatekeeper.sh</code><code class="w"/>
<code class="w">      </code><code class="nt">rego</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">|</code><code class="w"/>
<code class="w">        </code><code class="no">package k8suniqueingresshost</code><code class="w"/>

<code class="w">        </code><code class="no">identical(obj, review) {</code><code class="w"/>
<code class="w">          </code><code class="no">obj.metadata.namespace == review.object.metadata.namespace</code><code class="w"/>
<code class="w">          </code><code class="no">obj.metadata.name == review.object.metadata.name</code><code class="w"/>
<code class="w">        </code><code class="no">}</code><code class="w"/>

<code class="w">        </code><code class="no">violation[{"msg": msg}] {</code><code class="w"/>
<code class="w">          </code><code class="no">input.review.kind.kind == "Ingress"</code><code class="w"/>
<code class="w">          </code><code class="no">re_match("^(extensions|networking.k8s.io)$", input.review.kind.group)</code><code class="w"/>
<code class="w">          </code><code class="no">host := input.review.object.spec.rules[_].host</code><code class="w"/>
<code class="w">          </code><code class="no">other := data.inventory.namespace[ns][otherapiversion]["Ingress"][name]</code><code class="w"/>
<code class="w">          </code><code class="no">re_match("^(extensions|networking.k8s.io)/.+$", otherapiversion)</code><code class="w"/>
<code class="w">          </code><code class="no">other.spec.rules[_].host == host</code><code class="w"/>
<code class="w">          </code><code class="no">not identical(other, input.review)</code><code class="w"/>
<code class="w">          </code><code class="no">msg := sprintf("ingress host conflicts with an existing ingress &lt;%v&gt;"...</code><code class="w"/>
<code class="w">        </code><code class="no">}</code><code class="w"/></pre></div>
<p>Data replication is a powerful tool that allows you to make comparisons across Kubernetes resources. We recommend only configuring it if you have policies that require it to function. If you use it, scope it only to the relevant resources.</p>
</div></section>
<section data-pdf-bookmark="Metrics" data-type="sect2"><div class="sect2" id="idm45664067469552">
<h2>Metrics</h2>
<p>Gatekeeper emits metrics in Prometheus format to enable continuous resource compliance monitoring.<a data-primary="Gatekeeper" data-secondary="metrics" data-type="indexterm" id="idm45664067403680"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="metrics" data-type="indexterm" id="idm45664067402704"/><a data-primary="metrics from Gatekeeper" data-type="indexterm" id="idm45664067401488"/> You can view simple metrics regarding Gatekeeper’s overall health, such as the numbers of constraints, constraint templates, and requests being set to Gatekeeper.</p>
<p>In addition, details on policy compliance and governance are also available:</p>
<ul>
<li>
<p>The total number of audit violations</p>
</li>
<li>
<p>Number of constraints by <code>enforcementAction</code></p>
</li>
<li>
<p>Audit duration</p>
</li>
</ul>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Completely automating the policy and governance process is the ideal goal, so we strongly recommended that you monitor Gatekeeper from an external monitoring system and set alerts based on resource compliance.</p>
</div>
</div></section>
<section data-pdf-bookmark="Policy Library" data-type="sect2"><div class="sect2" id="idm45664067395552">
<h2>Policy Library</h2>
<p>One of the core tenets of the Gatekeeper project is to create reusable policy libraries that can be shared between organizations.<a data-primary="Gatekeeper" data-secondary="policy library" data-type="indexterm" id="idm45664067394000"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-tertiary="policy library" data-type="indexterm" id="idm45664067393024"/> Being able to share policies reduces boilerplate policy work and allows cluster administrators to focus on applying policy rather than writing it. The Gatekeeper project has a great <a href="https://oreil.ly/uBY2h">policy library</a>. It contains a general library with the most common policies as well as a <em>pod-security-policy</em> library that models the capabilities of the PodSecurityPolicy API as Gatekeeper policy.<a data-primary="PodSecurityPolicy" data-type="indexterm" id="idm45664067390304"/> The great thing about this library is that it is always expanding and is open source, so feel free to contribute any policies that you write.<a data-primary="Gatekeeper" data-startref="ix_Gate" data-type="indexterm" id="idm45664067389472"/><a data-primary="policy and governance" data-secondary="using Gatekeeper" data-startref="ix_polgovGate" data-type="indexterm" id="idm45664067388528"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45664068504464">
<h1>Summary</h1>
<p>In this chapter, you’ve learned about policy and governance and why they are important as more and more resources are deployed to Kubernetes. We covered the Gatekeeper project, a Kubernetes-native policy controller built on Open Policy Agent, and showed you to use it to meet your policy and governance requirements. From writing policies to auditing, you are now equipped with the know-how to meet your compliance needs.<a data-primary="policy and governance" data-startref="ix_polgov" data-type="indexterm" id="idm45664067348720"/><a data-primary="clusters" data-secondary="policy and governance for" data-startref="ix_clspolgov" data-type="indexterm" id="idm45664067347872"/></p>
</div></section>
</div></section></div></body></html>