<html><head></head><body><section data-pdf-bookmark="Chapter 15. Building Higher-Level Application Patterns on Top of Kubernetes" data-type="chapter" epub:type="chapter"><div class="chapter" id="building_higher_level_application_patterns_on_kubernetes">&#13;
<h1><span class="label">Chapter 15. </span>Building Higher-Level Application <span class="keep-together">Patterns on Top of Kubernetes</span></h1>&#13;
&#13;
&#13;
<p>It’s no secret that Kubernetes is a complex system. Although it simplifies the deployment and&#13;
operations of distributed applications, it does little to make the&#13;
development of such systems easy. In fact, when adding new concepts and&#13;
artifacts for the developer to interact with, it adds a layer of complexity in the service of simplified operations.&#13;
Consequently, in many environments, it makes sense to develop higher-level abstractions to provide more developer-friendly primitives on top&#13;
of Kubernetes. Additionally, in many large companies, it makes sense to&#13;
standardize the way in which applications are configured and deployed so&#13;
that everyone adheres to the same operational best practices. This can&#13;
also be achieved by developing higher-level abstractions so that&#13;
developers automatically adhere to these principles. However, developing&#13;
these abstractions can hide important details from the&#13;
developer and might introduce a walled garden. This limits or complicates the&#13;
development of certain applications or the integration of existing&#13;
solutions. Throughout the development of the cloud, the tension between the&#13;
flexibility of infrastructure and the power of the platform has been a&#13;
constant. Designing the appropriate higher-level abstractions enables us to&#13;
walk an ideal path through this divide.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Approaches to Developing Higher-Level Abstractions" data-type="sect1"><div class="sect1" id="id233">&#13;
<h1>Approaches to Developing Higher-Level Abstractions</h1>&#13;
&#13;
<p>When <a data-primary="higher-level abstractions" data-secondary="development approaches" data-type="indexterm" id="high-level-abstraction-dev-approach"/>considering how to develop a higher-level primitive on top of&#13;
Kubernetes, there are two basic approaches. The first is to wrap Kubernetes as an implementation detail. With this approach, developers&#13;
who consume your platform should be largely unaware that they are&#13;
running on top of Kubernetes; instead, they should think of&#13;
themselves as consumers of the platform you supply, and thus&#13;
Kubernetes is an implementation detail.</p>&#13;
&#13;
<p>The second option is to use the extensibility capabilities built into&#13;
Kubernetes itself. The Kubernetes Server API is quite flexible, and you&#13;
can dynamically add arbitrary new resources to the Kubernetes API. With this approach, your new higher-level resources coexist&#13;
alongside the built-in Kubernetes objects, and the users use the built-in&#13;
tooling for interacting with all the Kubernetes resources, both built-in ones&#13;
and extensions. This extension model results in an environment in which&#13;
Kubernetes is still front and center for your developers but with&#13;
additions that reduce complexity and make it easier to use.</p>&#13;
&#13;
<p>How do you choose the approach that is appropriate? It depends on the goals for the abstraction layer that you are&#13;
building. If you are constructing a fully isolated, integrated environment in which you have strong confidence that users will not need to “break glass” and escape, and where ease of use is an important characteristic, the first option is a great choice. A good example&#13;
of this would be building a machine learning pipeline. The domain is relatively well understood. The data scientists who are your&#13;
users are likely not familiar with Kubernetes. Enabling these data scientists to rapidly get their work done and focus on their domains&#13;
rather than distributed systems is the primary goal. As a result, building a complete abstraction on top of Kubernetes makes the most sense.</p>&#13;
&#13;
<p>On the other hand, when building a higher-level developer abstraction—for example, an easy way to deploy Java applications—it is a far&#13;
better choice to extend Kubernetes rather than wrap it, for two reasons. First, the domain of application development is&#13;
extraordinarily broad. It will be difficult for you to anticipate all&#13;
the requirements and use cases for your developers, especially as the&#13;
applications and business iterate and change over time. The other reason&#13;
is to ensure that you can continue to take advantage of the Kubernetes&#13;
ecosystem of tools. There are countless cloud native tools for&#13;
monitoring, continuous delivery, and more. Extending rather than&#13;
replacing the Kubernetes API ensures that you can continue to use these&#13;
tools and new ones as they are developed. Additionally, when you choose&#13;
to extend rather than obfuscate the Kubernetes API, it is relatively&#13;
straightforward to find people with industry experience in Kubernetes.&#13;
Experience building applications in a bespoke application platform that&#13;
exists only in your environment is <a data-primary="higher-level abstractions" data-secondary="development approaches" data-startref="high-level-abstraction-dev-approach" data-type="indexterm" id="id979"/>definitionally rare.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Extending Kubernetes" data-type="sect1"><div class="sect1" id="id371">&#13;
<h1>Extending Kubernetes</h1>&#13;
&#13;
<p>Because every layer that you might build over Kubernetes is unique, it is&#13;
beyond the scope of this book to describe how you might build such a&#13;
layer to extend Kubernetes. But the tools and techniques for extending Kubernetes are generic&#13;
to any construction you might do on top of Kubernetes, so we’ll&#13;
spend time covering them.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Extending Kubernetes Clusters" data-type="sect2"><div class="sect2" id="id130">&#13;
<h2>Extending Kubernetes Clusters</h2>&#13;
&#13;
<p>A<a data-primary="higher-level abstractions" data-secondary="extending Kubernetes" data-tertiary="clusters" data-type="indexterm" id="high-level-abstraction-extend-cluster"/><a data-primary="extending" data-secondary="clusters" data-type="indexterm" id="extend-cluster"/><a data-primary="clusters" data-secondary="extending" data-type="indexterm" id="cluster-extend"/> complete how-to for extending a Kubernetes cluster is a large topic&#13;
and more completely covered in other books like <a class="orm:hideurl" href="https://oreil.ly/6kUUX"><em>Managing Kubernetes</em></a> and <a class="orm:hideurl" href="https://oreil.ly/fdRA3"><em>Kubernetes: Up and Running</em></a> (O’Reilly). Rather than going over the same material&#13;
here, this section focuses on providing an understanding of how to use&#13;
Kubernetes extensibility.</p>&#13;
&#13;
<p>Extending the Kubernetes cluster involves&#13;
understanding the touch points for resources in Kubernetes. There are&#13;
three related technical solutions. The <a data-primary="sidecar proxies" data-type="indexterm" id="id980"/>first is the <em>sidecar</em>. Sidecar&#13;
containers (shown in <a data-type="xref" href="#fig-sidecar-design">Figure 15-1</a>) have been popularized in the context of service meshes. These containers run alongside a main application container to&#13;
provide additional capabilities that are decoupled from the main&#13;
application and often maintained by a separate team. For example, in&#13;
service meshes, a sidecar might provide transparent mutual Transport Layer Security (mTLS)&#13;
authentication to a containerized application. You can use sidecars to add capabilities to your user-defined applications.</p>&#13;
&#13;
<figure><div class="figure" id="fig-sidecar-design">&#13;
<img alt="images/figure-16-1.png" src="assets/kbp2_1501.png"/>&#13;
<h6><span class="label">Figure 15-1. </span>The sidecar design</h6>&#13;
</div></figure>&#13;
&#13;
<p>Within the industry the sidecar approach has become increasingly popular, and many projects use it to deliver services alongside the developer’s containers. A great example is the <a href="https://dapr.io">Dapr</a> (Distributed Application Runtime) project. Dapr<a data-primary="Dapr (Distributed Application Runtime)" data-type="indexterm" id="id981"/> is an open source project within the CNCF that implements a sidecar for applications that delivers many capabilities like encryption, key/value store, pub/sub queues, and much more with a very simple, consistent API. Sidecars like Dapr can be used as modular building blocks for a platform that you are developing on top of Kubernetes.</p>&#13;
&#13;
<p>Of course, the entire goal of this effort was to make a developer’s life easier, but if we require that they learn about and know how to use sidecars, we’ve actually made the problem worse. Fortunately, additional tools for extending Kubernetes simplify things. In particular, <a data-primary="admission controllers" data-type="indexterm" id="admission-control"/>Kubernetes features <em>admission controllers</em>. Admission controllers are interceptors that read Kubernetes API requests prior to them being stored (or “admitted”) into the cluster’s backing store. You can use these admission controllers to validate or modify API objects. In the context of sidecars, you can use them to automatically add sidecars to all pods created in the cluster so that developers do not need to know about the sidecars to reap their benefits. <a data-type="xref" href="#figure-admission-control">Figure 15-2</a> illustrates how admission controllers interact with the Kubernetes API.</p>&#13;
&#13;
<figure><div class="figure" id="figure-admission-control">&#13;
<img alt="images/figure-16-2.png" src="assets/kbp2_1502.png"/>&#13;
<h6><span class="label">Figure 15-2. </span>Admission controllers</h6>&#13;
</div></figure>&#13;
&#13;
<p>The utility of admission controllers isn’t limited to adding sidecars.&#13;
You can also use them to validate objects submitted by developers to&#13;
Kubernetes. For example, you could implement<a data-primary="linters" data-type="indexterm" id="id982"/> a <em>linter</em> (a tool that analyzes code) for Kubernetes&#13;
that ensures developers submit pods and other resources that follow best&#13;
practices for using Kubernetes. A common mistake for&#13;
developers is to not reserve resources for their application. For those circumstances, an&#13;
admission controller–based linter could intercept such requests and&#13;
reject them. Of course, you should also leave an escape hatch (for&#13;
example, a special <span class="keep-together">annotation)</span> so that advanced users can opt out of the&#13;
lint rule, as appropriate. We discuss the importance of escape hatches&#13;
later on in this <a data-primary="admission controllers" data-startref="admission-control" data-type="indexterm" id="id983"/>chapter.</p>&#13;
&#13;
<p>So far, we’ve only covered ways to augment existing applications and to&#13;
ensure that developers follow best practices—we haven’t really&#13;
covered how to add higher-level abstractions. This is where custom&#13;
resource definitions (CRDs) <a data-primary="CRDs (custom resource definitions)" data-secondary="dynamically adding resources" data-type="indexterm" id="id984"/>come into play. CRDs are a way&#13;
to dynamically add new resources to an existing Kubernetes cluster. For&#13;
example, using CRDs, you could add a new ReplicatedService&#13;
resource to a Kubernetes cluster. When a developer creates an instance&#13;
of a ReplicatedService, it turns around to Kubernetes and creates&#13;
corresponding Deployment and Service resources. Thus, the ReplicatedService is a convenient developer abstraction for a common pattern.&#13;
CRDs are generally implemented by a control loop that is&#13;
deployed into the cluster itself to manage these new <a data-primary="higher-level abstractions" data-secondary="extending Kubernetes" data-startref="high-level-abstraction-extend-cluster" data-tertiary="clusters" data-type="indexterm" id="id985"/><a data-primary="extending" data-secondary="clusters" data-startref="extend-cluster" data-type="indexterm" id="id986"/><a data-primary="clusters" data-secondary="extending" data-startref="cluster-extend" data-type="indexterm" id="id987"/>resource types.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Extending the Kubernetes User Experience" data-type="sect2"><div class="sect2" id="id131">&#13;
<h2>Extending the Kubernetes User Experience</h2>&#13;
&#13;
<p>Adding<a data-primary="higher-level abstractions" data-secondary="extending Kubernetes" data-tertiary="user experience" data-type="indexterm" id="high-level-abstraction-extend-userexp"/><a data-primary="extending" data-secondary="user experience" data-type="indexterm" id="extend-userexp"/><a data-primary="user experience, extending" data-type="indexterm" id="userexp-extend"/> new resources to your cluster is a great way to provide new&#13;
capabilities, but to truly take advantage of them, it’s often useful to&#13;
extend the Kubernetes user experience (UX) as well. By default, the&#13;
Kubernetes tooling is unaware of custom resources and other extensions&#13;
and thus treats them in a very generic and not particularly&#13;
user-friendly manner. Extending the Kubernetes command line can provide&#13;
an enhanced user experience.</p>&#13;
&#13;
<p>Generally, the tool used for accessing Kubernetes is the <code>kubectl</code>&#13;
command-line tool. Fortunately, it too has been built for extensibility.&#13;
<code>kubectl</code> plug-ins are binaries that have a name like <code>kubectl-foo</code>, where&#13;
<code>foo</code> is the name of the plug-in. When you invoke <code>kubectl foo ...</code>&#13;
on the command line, the invocation is in turn routed to an&#13;
invocation of the plug-in binary. Using <code>kubectl</code> plug-ins, you can define&#13;
new experiences that deeply understand the new resources that you have&#13;
added to your cluster. You are free to implement whatever kind of&#13;
experiences are suitable while at the same time taking advantage of the&#13;
familiarity of the <code>kubectl</code> tooling. This is especially valuable because&#13;
it means that you don’t need to teach developers about a new tool set. Likewise, you can gradually introduce Kubernetes-native concepts as the developers&#13;
advance their Kubernetes knowledge.</p>&#13;
&#13;
<p>If you are looking to build graphical interfaces for your Kubernetes-based platform, several tools can help. In particular the open source <a href="https://oreil.ly/2-4fB">Headlamp project</a> is<a data-primary="Headlamp project" data-type="indexterm" id="id988"/> a library that enables easy construction of web-based, mobile, or desktop applications for interacting with Kubernetes infrastructure. Using a tool like Headlamp enables you to rapidly create a custom developer experience that perfectly fits your platform and<a data-primary="higher-level abstractions" data-secondary="extending Kubernetes" data-startref="high-level-abstraction-extend-userexp" data-tertiary="user experience" data-type="indexterm" id="id989"/><a data-primary="extending" data-secondary="user experience" data-startref="extend-userexp" data-type="indexterm" id="id990"/><a data-primary="user experience, extending" data-startref="userexp-extend" data-type="indexterm" id="id991"/> its needs.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Making Containerized Development Easier" data-type="sect2"><div class="sect2" id="id132">&#13;
<h2>Making Containerized Development Easier</h2>&#13;
&#13;
<p>Before <a data-primary="higher-level abstractions" data-secondary="extending Kubernetes" data-tertiary="containerized development" data-type="indexterm" id="id992"/><a data-primary="containerized development" data-type="indexterm" id="id993"/>they can even deploy an application to Kubernetes, a developer must&#13;
first containerize that application. Though building containers is second nature for those familiar with the&#13;
cloud native ecosystem, for many it&#13;
is a daunting task that prevents even getting started with modern&#13;
application development.</p>&#13;
&#13;
<p>Fortunately, several open source tools can help jump start your&#13;
development. Tools like <a href="https://draft.sh">Draft</a> and <a href="https://oreil.ly/H4DzY">Skaffold</a> will automatically generate a Dockerfile for a particular language or development environment.</p>&#13;
&#13;
<p>If developers are familiar with the buildpack idea from cloud foundry or other&#13;
platforms, there are also tools like <a href="https://paketo.io">Paketo</a> that provide&#13;
easy-to-use and vetted container images for building applications in popular&#13;
languages as well as command-line tools to get started easily.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Developing a “Push-to-Deploy” Experience" data-type="sect2"><div class="sect2" id="id133">&#13;
<h2>Developing a “Push-to-Deploy” Experience</h2>&#13;
&#13;
<p>One of <a data-primary="higher-level abstractions" data-secondary="extending Kubernetes" data-tertiary="&quot;push to deploy&quot; experience" data-tertiary-sortas="push to deploy" data-type="indexterm" id="id994"/><a data-primary="&quot;push to deploy&quot; experience" data-primary-sortas="push to deploy experience" data-type="indexterm" id="id995"/>the most popular features of many PaaS products is “push to deploy,”&#13;
meaning that a single push of code to a Git repository results in the&#13;
application deploying to a cloud environment. Though this has&#13;
previously been the domain of large-scale managed PaaS solutions, it&#13;
is now very easy to build a similar experience using CI/CD solutions like&#13;
GitHub Actions, Azure DevOps, or other continuous-build tooling.</p>&#13;
&#13;
<p>With a properly designed pipeline, once a developer pushes code into&#13;
their Git repository, it is automatically tested, built, packaged&#13;
into a container image, and pushed to a container registry.</p>&#13;
&#13;
<p>Once the new version of the container image is present in the&#13;
container registry, it is a simple step to use another Git commit&#13;
combined with GitOps to push that image out to a running application.</p>&#13;
&#13;
<p>Combining GitHub actions and GitOps can enable your developers to&#13;
achieve fast deployment while also staying true to the cloud native&#13;
ecosystem and ideas like Infrastructure as Code (IaC).</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Design Considerations When Building Platforms" data-type="sect1"><div class="sect1" id="id234">&#13;
<h1>Design Considerations When Building Platforms</h1>&#13;
&#13;
<p>Countless platforms<a data-primary="higher-level abstractions" data-secondary="designing" data-type="indexterm" id="high-level-abstraction-design"/><a data-primary="designing" data-secondary="higher-level abstractions" data-type="indexterm" id="design-high-level-abstraction"/><a data-primary="platforms" data-see="higher-level abstractions" data-type="indexterm" id="id996"/> have been built to enable developer productivity.&#13;
Given the opportunity to observe all the places where these platforms&#13;
have succeeded and failed, you can develop a common set of patterns and&#13;
considerations to learn from the experience of others. Following&#13;
these design guidelines can help to ensure that the platform you build is successful instead of a “legacy” dead end from which you must eventually&#13;
move away.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Support Exporting to a Container Image" data-type="sect2"><div class="sect2" id="id235">&#13;
<h2>Support Exporting to a Container Image</h2>&#13;
&#13;
<p>When you are building<a data-primary="image management" data-secondary="exporting to container images" data-type="indexterm" id="id997"/><a data-primary="exporting" data-secondary="to container images" data-secondary-sortas="container images" data-type="indexterm" id="id998"/><a data-primary="containers" data-secondary="exporting to" data-type="indexterm" id="id999"/> a platform, many designs provide simplicity by enabling&#13;
the user to simply supply code (e.g., a function in Function as a&#13;
Service [FaaS]) or a native package (e.g., a JAR file in Java) instead of a&#13;
complete container image. This approach has a great deal of appeal&#13;
because it lets the user stay within the confines of their&#13;
well-understood tools and development experience. The platform handles&#13;
the containerization of the application for them.</p>&#13;
&#13;
<p>The problem with this approach, however, comes when the developer&#13;
encounters the limitations of the programming environment that you&#13;
have given them. Perhaps it’s because they need a specific version&#13;
of a language runtime to work around a bug. Or it might be that they need&#13;
to package additional resources or executables that aren’t part of&#13;
the way you have structured the automatic containerization of the&#13;
application.</p>&#13;
&#13;
<p>No matter the reason, hitting this wall is an ugly moment&#13;
for the developer, because it is a moment when they suddenly must learn a great deal more about how to package their application, when all&#13;
they really wanted to do was to extend it slightly to fix a bug or&#13;
deliver a new feature.</p>&#13;
&#13;
<p>However, it doesn’t need to be this way. If you support the exporting of&#13;
your platform’s programming environment into a generic container, the&#13;
developer using your platform doesn’t need to start from scratch and&#13;
learn everything there is to know about containers. Instead, they have a&#13;
complete working container image that represents their current&#13;
application (i.e., the container image containing their function and the&#13;
node runtime). Given this starting point, they can then make the small&#13;
tweaks necessary to adapt the container image to their needs. This sort&#13;
of gradual degradation and incremental learning dramatically smooths the path from higher-level platform down into lower-level&#13;
infrastructure. It also increases the general utility of the platform&#13;
because using it doesn’t introduce steep cliffs for <span class="keep-together">developers.</span></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Support Existing Mechanisms for Service and Service Discovery" data-type="sect2"><div class="sect2" id="id134">&#13;
<h2>Support Existing Mechanisms for Service and Service Discovery</h2>&#13;
&#13;
<p>Another <a data-primary="services" data-secondary="exposing" data-type="indexterm" id="id1000"/><a data-primary="exposing services" data-type="indexterm" id="id1001"/><a data-primary="service discovery" data-type="indexterm" id="id1002"/>common story of platforms is that they evolve and interconnect&#13;
with other systems. Many developers might be very happy and productive in&#13;
your platform, but any real-world application will span both the&#13;
platform that you build and lower-level Kubernetes applications as well&#13;
as <em>other</em> platforms. Connections to legacy databases or open source&#13;
applications built for Kubernetes will always be a part of a&#13;
sufficiently large application.</p>&#13;
&#13;
<p>Because of this need for interconnectivity, it’s critically important&#13;
that the core Kubernetes primitives for services and service discovery&#13;
are used and exposed by any platform that you construct. Don’t reinvent&#13;
the wheel in the interest of improved platform experience, because in&#13;
doing so you will be creating a walled garden incapable of interacting&#13;
with the broader world.</p>&#13;
&#13;
<p>If you expose the applications defined in your platform as Kubernetes&#13;
Services, any application anywhere within your cluster will be able&#13;
to consume your applications regardless of whether they are running in&#13;
your higher-level platform. Likewise, if you use the Kubernetes&#13;
DNS servers for service discovery, you will be able to connect from your&#13;
higher-level application platform to other applications running in the&#13;
cluster, even if they are not defined in your higher-level platform. It&#13;
might be tempting to build something better or easier to use, but&#13;
interconnectivity across different platforms is the common design&#13;
pattern for any application of sufficient age and complexity. You will&#13;
always regret the decision to build a<a data-primary="higher-level abstractions" data-secondary="designing" data-startref="high-level-abstraction-design" data-type="indexterm" id="id1003"/><a data-primary="designing" data-secondary="higher-level abstractions" data-startref="design-high-level-abstraction" data-type="indexterm" id="id1004"/> walled garden.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Building Application Platforms Best Practices" data-type="sect1"><div class="sect1" id="id236">&#13;
<h1>Building Application Platforms Best Practices</h1>&#13;
&#13;
<p>Although <a data-primary="higher-level abstractions" data-secondary="best practices" data-type="indexterm" id="id1005"/><a data-primary="best practices" data-secondary="higher-level abstractions" data-type="indexterm" id="id1006"/>Kubernetes provides powerful tools for operating software, it does considerably less to enable developers to build applications. It is often necessary to build platforms on top of Kubernetes to make developers more productive and/or Kubernetes easier. When building such platforms, you’ll benefit from keeping the following best practices in mind:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Use admission controllers to limit and modify API calls to the cluster. An&#13;
admission controller can validate (and reject invalid) Kubernetes resources.&#13;
A mutating admission controller can automatically modify API resources to&#13;
add new sidecars or other changes that users might not even need to know about.</p>&#13;
</li>&#13;
<li>&#13;
<p>Use <code>kubectl</code> plug-ins to extend the Kubernetes user experience by adding&#13;
new tools to the existing command-line tool. In rare occasions, a&#13;
purpose-built tool might be more appropriate.</p>&#13;
</li>&#13;
<li>&#13;
<p>When building platforms on top of Kubernetes, think carefully about the platform’s users and how their needs will evolve. Making things simple and easy&#13;
to use is clearly a good goal, but if this also leads to users that are trapped&#13;
and unable to be successful without rewriting everything outside of your&#13;
platform, it will ultimately be a frustrating (and unsuccessful) experience.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id372">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Kubernetes is a fantastic tool for simplifying the deployment and operation of software; unfortunately, it is not always the most&#13;
developer-friendly or productive environment. Because of this, a&#13;
common task is to build a higher-level platform on top of Kubernetes to make it more approachable and usable&#13;
by the average developer. This chapter described several approaches for&#13;
designing such a higher-level system and provided a summary of the core&#13;
extensibility infrastructure available in Kubernetes. It&#13;
concluded with lessons and design principles drawn from our observation of other&#13;
platforms that have been built on top of Kubernetes, with the hope that&#13;
they can guide the design of your platform.</p>&#13;
</div></section>&#13;
</div></section></body></html>