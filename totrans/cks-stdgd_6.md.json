["```\n$ docker pull alpine:3.17.0\n...\n$ docker image ls alpine\nREPOSITORY   TAG       IMAGE ID       CREATED       SIZE\nalpine       3.17.0    49176f190c7e   3 weeks ago   7.05MB\n```", "```\n$ docker run -it alpine:3.17.0 /bin/sh\n/ # exit\n```", "```\n$ docker pull gcr.io/distroless/static-debian11\n...\n$ docker image ls gcr.io/distroless/static-debian11:latest\nREPOSITORY                          TAG       IMAGE ID       CREATED      \\\n  SIZE\ngcr.io/distroless/static-debian11   latest    901590160d4d   53 years ago \\\n  2.34MB\n```", "```\n$ docker run -it gcr.io/distroless/static-debian11:latest /bin/sh\ndocker: Error response from daemon: failed to create shim task: OCI runtime \\\ncreate failed: runc create failed: unable to start container process: exec: \\\n\"/bin/sh\": stat /bin/sh: no such file or directory: unknown.\n```", "```\nFROM golang:1.19.4-alpine ![1](assets/1.png)\nWORKDIR /app\n\nCOPY go.mod .\nCOPY go.sum .\nRUN go mod download\n\nCOPY . .\nRUN CGO_ENABLED=0 go test -v ![2](assets/2.png)\nRUN go build -o /go-sample-app . ![3](assets/3.png)\nCMD [\"/go-sample-app\"]\n```", "```\n$ docker build . -t go-sample-app:0.0.1\n...\n```", "```\n$ docker images\nREPOSITORY      TAG     IMAGE ID       CREATED          SIZE\ngo-sample-app   0.0.1   88175f3ab0d3   44 seconds ago   358MB\n```", "```\nFROM golang:1.19.4-alpine AS build ![1](assets/1.png)\nRUN apk add --no-cache git\nWORKDIR /tmp/go-sample-app\nCOPY go.mod .\nCOPY go.sum .\nRUN go mod download\nCOPY . .\n\nRUN CGO_ENABLED=0 go test -v ![2](assets/2.png)\nRUN go build -o ./out/go-sample-app . ![3](assets/3.png)\n\nFROM alpine:3.17.0 ![4](assets/4.png)\nRUN apk add ca-certificates\nCOPY --from=build /tmp/go-sample-app/out/go-sample-app /app/go-sample-app ![5](assets/5.png)\nCMD [\"/app/go-sample-app\"]\n```", "```\n$ docker build . -t go-sample-app:0.0.1\n...\n$ docker images\nREPOSITORY      TAG     IMAGE ID       CREATED          SIZE\ngo-sample-app   0.0.1   88175f3ab0d3   44 seconds ago   12MB\n```", "```\nFROM ubuntu:22.10\nRUN apt-get update -y\nRUN apt-get upgrade -y\nRUN apt-get install -y curl\n```", "```\nFROM ubuntu:22.10\nRUN apt-get update -y && apt-get upgrade -y && apt-get install -y curl\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: alpine-valid\nspec:\n  containers:\n  - name: alpine\n    image: alpine@sha256:c0d488a800e4127c334ad20d61d7bc21b40 \\\n           97540327217dfab52262adc02380c\n    command: [\"/bin/sh\"]\n    args: [\"-c\", \"while true; do echo hello; sleep 10; done\"]\n```", "```\n$ kubectl apply -f pod-valid-image-digest.yaml\npod/alpine-valid created\n$ kubectl get pod alpine-valid\nNAME           READY   STATUS    RESTARTS   AGE\nalpine-valid   1/1     Running   0          6s\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: alpine-invalid\nspec:\n  containers:\n  - name: alpine\n    image: alpine@sha256:d006a643bccb6e9adbabaae668533c7f2e5 \\\n           111572fffb5c61cb7fcba7ef4150b\n    command: [\"/bin/sh\"]\n    args: [\"-c\", \"while true; do echo hello; sleep 10; done\"]\n```", "```\n$ kubectl get pods\nNAME             READY   STATUS         RESTARTS   AGE\nalpine-invalid   0/1     ErrImagePull   0          29s\n$ kubectl describe pod alpine-invalid\n...\nEvents:\n  Type     Reason     Age   From               Message\n  ----     ------     ----  ----               -------\n  Normal   Scheduled  13s   default-scheduler  Successfully assigned default \\\n  /alpine-invalid to minikube\n  Normal   Pulling    13s   kubelet            Pulling image \"alpine@sha256: \\\n  d006a643bccb6e9adbabaae668533c7f2e5111572fffb5c61cb7fcba7ef4150b\"\n  Warning  Failed     11s   kubelet            Failed to pull image \\\n  \"alpine@sha256:d006a643bccb6e9adbabaae668533c7f2e5111572fffb5c61cb7fcba7ef4 \\\n  150b\": rpc error: code = Unknown desc = Error response from daemon: manifest \\\n  for alpine@sha256:d006a643bccb6e9adbabaae668533c7f2e5111572fffb5c61cb7fcba7e \\\n  f4150b not found: manifest unknown: manifest unknown\n  Warning  Failed     11s   kubelet            Error: ErrImagePull\n  Normal   BackOff    11s   kubelet            Back-off pulling image \\\n  \"alpine@sha256:d006a643bccb6e9adbabaae668533c7f2e5111572fffb5c61cb7fcba7ef415 \\\n  0b\"\n  Warning  Failed     11s   kubelet            Error: ImagePullBackOff\n```", "```\napiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8sallowedrepos\n  annotations:\n    metadata.gatekeeper.sh/title: \"Allowed Repositories\"\n    metadata.gatekeeper.sh/version: 1.0.0\n    description: >-\n      Requires container images to begin with a string from the specified list.\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sAllowedRepos\n      validation:\n        openAPIV3Schema:\n          type: object\n          properties:\n            repos:\n              description: The list of prefixes a container image is allowed to have.\n              type: array\n              items:\n                type: string\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8sallowedrepos\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.containers[_]\n          satisfied := [good | repo = input.parameters.repos[_] ; \\\n          good = startswith(container.image, repo)]\n          not any(satisfied)\n          msg := sprintf(\"container <%v> has an invalid image repo <%v>, allowed \\\n          repos are %v\", [container.name, container.image, input.parameters.repos])\n        }\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.initContainers[_]\n          satisfied := [good | repo = input.parameters.repos[_] ; \\\n          good = startswith(container.image, repo)]\n          not any(satisfied)\n          msg := sprintf(\"initContainer <%v> has an invalid image repo <%v>, \\\n          allowed repos are %v\", [container.name, container.image, \\\n          input.parameters.repos])\n        }\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.ephemeralContainers[_]\n          satisfied := [good | repo = input.parameters.repos[_] ; \\\n          good = startswith(container.image, repo)]\n          not any(satisfied)\n          msg := sprintf(\"ephemeralContainer <%v> has an invalid image repo <%v>, \\\n          allowed repos are %v\", [container.name, container.image, \\\n          input.parameters.repos])\n        }\n```", "```\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sAllowedRepos\nmetadata:\n  name: repo-is-gcr\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n  parameters:\n    repos:\n      - \"gcr.io/\"\n```", "```\n$ kubectl apply -f allowed-repos-constraint-template.yaml\nconstrainttemplate.templates.gatekeeper.sh/k8sallowedrepos created\n$ kubectl apply -f gcr-allowed-repos-constraint.yaml\nk8sallowedrepos.constraints.gatekeeper.sh/repo-is-gcr created\n```", "```\n$ kubectl run nginx --image=nginx:1.23.3\nError from server (Forbidden): admission webhook \"validation.gatekeeper.sh\" \\\ndenied the request: [repo-is-gcr] container <nginx> has an invalid image \\\nrepo <nginx:1.23.3>, allowed repos are [\"gcr.io/\"]\n```", "```\n$ kubectl run busybox --image=gcr.io/google-containers/busybox:1.27.2\npod/busybox created\n$ kubectl get pods\nNAME      READY   STATUS      RESTARTS     AGE\nbusybox   0/1     Completed   1 (2s ago)   3s\n```", "```\n$ curl -X POST -H \"Content-Type: application/json\" -k -d \\'{\"apiVersion\": \\\n\"imagepolicy.k8s.io/v1alpha1\", \"kind\": \"ImageReview\", \"spec\": \\\n{\"containers\": [{\"image\": \"nginx:1.19.0\"}]}}' https://localhost:8080/validate\n{\"apiVersion\": \"imagepolicy.k8s.io/v1alpha1\", \"kind\": \"ImageReview\", \\\n\"status\": {\"allowed\": false, \"reason\": \"Denied request: [container 1 \\\nhas an invalid image repo nginx:1.19.0, allowed repos are [gcr.io/]]\"}}\n\n```", "```\n$ curl -X POST -H \"Content-Type: application/json\"  -k -d '{\"apiVersion\": \\\n\"imagepolicy.k8s.io/v1alpha1\", \"kind\": \"ImageReview\", \"spec\": {\"containers\": \\\n[{\"image\": \"gcr.io/nginx:1.19.0\"}]}}' https://localhost:8080/validate\n{\"apiVersion\": \"imagepolicy.k8s.io/v1alpha1\", \"kind\": \"ImageReview\", \\\n\"status\": {\"allowed\": true, \"reason\": \"\"}}\n\n```", "```\napiVersion: apiserver.config.k8s.io/v1\nkind: AdmissionConfiguration\nplugins:\n  - name: ImagePolicyWebhook ![1](assets/1.png)\n    configuration:\n      imagePolicy:\n        kubeConfigFile: /etc/kubernetes/admission-control/ \\\n                        imagepolicywebhook.kubeconfig ![2](assets/2.png)\n        allowTTL: 50\n        denyTTL: 50\n        retryBackoff: 500\n        defaultAllow: false ![3](assets/3.png)\n```", "```\napiVersion: v1\nkind: Config\npreferences: {}\nclusters:\n  - name: image-validation-webhook\n    cluster:\n      certificate-authority: /etc/kubernetes/admission-control/ca.crt\n      server: https://image-validation-webhook:8080/validate ![1](assets/1.png)\ncontexts:\n- context:\n    cluster: image-validation-webhook\n    user: api-server-client\n  name: image-validation-webhook\ncurrent-context: image-validation-webhook\nusers:\n  - name: api-server-client\n    user:\n      client-certificate: /etc/kubernetes/admission-control/api-server-client.crt\n      client-key: /etc/kubernetes/admission-control/api-server-client.key\n```", "```\n...\nspec:\n  containers:\n  - command:\n    - kube-apiserver\n    - --enable-admission-plugins=NodeRestriction,ImagePolicyWebhook\n    - --admission-control-config-file=/etc/kubernetes/admission-control/ \\\n      image-policy-webhook-admission-configuration.yaml\n    ...\n    volumeMounts:\n    ...\n    - name: admission-control\n      mountPath: /etc/kubernetes/admission-control\n      readonly: true\n  volumes:\n  ...\n  - name: admission-control\n    hostPath:\n      path: /etc/kubernetes/admission-control\n      type: DirectoryOrCreate\n...\n```", "```\n$ kubectl get pods -n kube-system\nNAME                           READY   STATUS    RESTARTS   AGE\n...\nkube-apiserver-control-plane   1/1     Running   0          69s\n```", "```\nFROM golang\nCOPY main.go .\nRUN go build main.go\nCMD [\"./main\"]\n```", "```\n$ hadolint Dockerfile\nDockerfile:1 DL3006 warning: Always tag the version of an image explicitly\nDockerfile:2 DL3045 warning: `COPY` to a relative destination without \\\n`WORKDIR` set.\n```", "```\nFROM golang:1.19.4-alpine\nWORKDIR /app\nCOPY main.go .\nRUN go build main.go\nCMD [\"./main\"]\n```", "```\n$ hadolint Dockerfile\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: kubesec-demo\nspec:\n  containers:\n  - name: kubesec-demo\n    image: gcr.io/google-samples/node-hello:1.0\n    securityContext:\n      readOnlyRootFilesystem: true\n```", "```\n$ docker run -i kubesec/kubesec:512c5e0 scan /dev/stdin \\\n  < pod-initial-kubesec-test.yaml\n[\n  {\n    \"object\": \"Pod/kubesec-demo.default\",\n    \"valid\": true,\n    \"message\": \"Passed with a score of 1 points\",\n    \"score\": 1,\n    \"scoring\": {\n      \"advise\": [\n        {\n          \"selector\": \".spec .serviceAccountName\",\n          \"reason\": \"Service accounts restrict Kubernetes API access and \\\n                     should be configured with least privilege\"\n        },\n        {\n          \"selector\": \".metadata .annotations .\\\"container.apparmor.security. \\\n                       beta.kubernetes.io/nginx\\\"\",\n          \"reason\": \"Well defined AppArmor policies may provide greater \\\n                     protection from unknown threats. WARNING: NOT PRODUCTION \\\n                     READY\"\n        },\n        {\n          \"selector\": \"containers[] .resources .requests .cpu\",\n          \"reason\": \"Enforcing CPU requests aids a fair balancing of \\\n                     resources across the cluster\"\n        },\n        {\n          \"selector\": \".metadata .annotations .\\\"container.seccomp.security. \\\n                       alpha.kubernetes.io/pod\\\"\",\n          \"reason\": \"Seccomp profiles set minimum privilege and secure against \\\n                     unknown threats\"\n        },\n        {\n          \"selector\": \"containers[] .resources .limits .memory\",\n          \"reason\": \"Enforcing memory limits prevents DOS via resource \\\n                     exhaustion\"\n        },\n        {\n          \"selector\": \"containers[] .resources .limits .cpu\",\n          \"reason\": \"Enforcing CPU limits prevents DOS via resource exhaustion\"\n        },\n        {\n          \"selector\": \"containers[] .securityContext .runAsNonRoot == true\",\n          \"reason\": \"Force the running image to run as a non-root user to \\\n                     ensure least privilege\"\n        },\n        {\n          \"selector\": \"containers[] .resources .requests .memory\",\n          \"reason\": \"Enforcing memory requests aids a fair balancing of \\\n                     resources across the cluster\"\n        },\n        {\n          \"selector\": \"containers[] .securityContext .capabilities .drop\",\n          \"reason\": \"Reducing kernel capabilities available to a container \\\n                     limits its attack surface\"\n        },\n        {\n          \"selector\": \"containers[] .securityContext .runAsUser -gt 10000\",\n          \"reason\": \"Run as a high-UID user to avoid conflicts with the \\\n                     host's user table\"\n        },\n        {\n          \"selector\": \"containers[] .securityContext .capabilities .drop | \\\n                       index(\\\"ALL\\\")\",\n          \"reason\": \"Drop all capabilities and add only those required to \\\n                     reduce syscall attack surface\"\n        }\n      ]\n    }\n  }\n]\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: kubesec-demo\nspec:\n  containers:\n  - name: kubesec-demo\n    image: gcr.io/google-samples/node-hello:1.0\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n    securityContext:\n      readOnlyRootFilesystem: true\n      runAsNonRoot: true\n      runAsUser: 20000\n      capabilities:\n        drop: [\"ALL\"]\n```", "```\n$ docker run -i kubesec/kubesec:512c5e0 scan /dev/stdin \\\n  < pod-improved-kubesec-test.yaml\n[\n  {\n    \"object\": \"Pod/kubesec-demo.default\",\n    \"valid\": true,\n    \"message\": \"Passed with a score of 9 points\",\n    \"score\": 9,\n    \"scoring\": {\n      \"advise\": [\n        {\n          \"selector\": \".metadata .annotations .\\\"container.seccomp.security. \\\n                       alpha.kubernetes.io/pod\\\"\",\n          \"reason\": \"Seccomp profiles set minimum privilege and secure against \\\n                     unknown threats\"\n        },\n        {\n          \"selector\": \".spec .serviceAccountName\",\n          \"reason\": \"Service accounts restrict Kubernetes API access and should \\\n                     be configured with least privilege\"\n        },\n        {\n          \"selector\": \".metadata .annotations .\\\"container.apparmor.security. \\\n                       beta.kubernetes.io/nginx\\\"\",\n          \"reason\": \"Well defined AppArmor policies may provide greater \\\n                     protection from unknown threats. WARNING: NOT PRODUCTION \\\n                     READY\"\n        }\n      ]\n    }\n  }\n]\n```", "```\n$ trivy -v\nVersion: 0.36.1\nVulnerability DB:\n  Version: 2\n  UpdatedAt: 2022-12-13 12:07:14.884952254 +0000 UTC\n  NextUpdate: 2022-12-13 18:07:14.884951854 +0000 UTC\n  DownloadedAt: 2022-12-13 17:09:28.866739 +0000 UTC\n```", "```\n    FROM node:latest\n    ENV NODE_ENV development\n    WORKDIR /app\n    COPY package.json .\n    RUN npm install\n    COPY . .\n    EXPOSE 3001\n    CMD [\"node\", \"app.js\"]\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: hello-world\n    spec:\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: linux\n        image: hello-world:linux\n    ```"]