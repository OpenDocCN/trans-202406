- en: Chapter 24\. Network Segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is a great platform for running distributed applications that communicate
    with one another over the network. By default, the network space within Kubernetes
    is flat, which means that every Pod can connect to every other Pod in the cluster.
    In this chapter, we will explore how to structure this network space for improved
    security and a lightweight multitenancy model.
  prefs: []
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Namespaces are a crucial part of Kubernetes, allowing you to group your workloads
    together. However, they only provide a grouping concept, imposing isolation constraints
    on the containers associated with specific namespaces. In Kubernetes, every Pod
    can talk to every other Pod, regardless of their namespace. This default behavior
    has security implications, particularly when multiple independent applications
    operated by different teams run in the same cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Restricting network access to and from Pods is essential for enhancing the security
    of your application because not everyone may be allowed to access your application
    via an ingress. Outgoing egress network traffic for Pods should also be limited
    to what is necessary to minimize the blast radius of a security breach.
  prefs: []
  type: TYPE_NORMAL
- en: Network segmentation plays a vital role in multitenancy setups where multiple
    parties share the same cluster. For example, the following sidebar addresses some
    of the challenges of multitenancy on Kubernetes, such as creating network boundaries
    for applications.
  prefs: []
  type: TYPE_NORMAL
- en: In the past, shaping the network topology was primarily the responsibility of
    administrators who managed firewalls and iptable rules. The challenge with this
    model is that administrators need to understand the networking requirements of
    the applications. In addition, the network graph can get very complex in a microservices
    world with many dependencies, requiring deep domain knowledge about the application.
    In this sense, the developer must communicate and sync information about dependencies
    with administrators. A DevOps setup can help, but the definition of network topologies
    is still far away from the application itself and can change dynamically over
    time.
  prefs: []
  type: TYPE_NORMAL
- en: So, what does defining and establishing a network segmentation look like in
    a Kubernetes world?
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The good news is that Kubernetes shifts left these networking tasks so that
    developers using Kubernetes fully define their applications’ networking topology.
    You have already seen this process model described briefly in [Chapter 23](ch23.html#ProcessContainment),
    when we discussed the *Process Containment* pattern.
  prefs: []
  type: TYPE_NORMAL
- en: The essence of this *Network Segmentation* pattern is how we, as developers,
    can define the network segmentation for our applications by creating “application
    firewalls.”
  prefs: []
  type: TYPE_NORMAL
- en: There are two ways to implement this feature that are complementary and can
    be applied together. The first is through the use of core Kubernetes features
    that operate on the L3/L4 networking layers.^([1](ch24.html#idm45902087907696))
    By defining resources of the type NetworkPolicy, developers can create ingress
    and egress firewall rules for workload Pods.
  prefs: []
  type: TYPE_NORMAL
- en: The other method involves the use of a service mesh and targets the L7 protocol
    layer, specifically HTTP-based communication. This allows for filtering based
    on HTTP verbs and other L7 protocol parameters. We will explore Istio’s AuthenticationPolicy
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: To start, let’s focus on how to use NetworkPolicies to define the network boundaries
    for your application.
  prefs: []
  type: TYPE_NORMAL
- en: Network Policies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NetworkPolicy is a Kubernetes resource type that allows users to define rules
    for inbound and outbound network connections for Pods. These rules act like a
    custom firewall and determine which Pods can be accessed and which destinations
    they can connect to. The user-defined rules are picked up by the Container Network
    Interface (CNI) add-on used by Kubernetes for its internal networking. However,
    not all CNI plugins support NetworkPolicies; for example, the popular Flannel
    CNI plugin does not support it, but many others, like Calico, do. All hosted Kubernetes
    cloud offerings support NetworkPolicy (either directly or by configuring an add-on)
    as well as other distributions like Minikube.
  prefs: []
  type: TYPE_NORMAL
- en: The NetworkPolicy definition consists of a selector for Pods and lists of inbound
    (ingress) or outbound (egress) rules.
  prefs: []
  type: TYPE_NORMAL
- en: The *Pod selector* is used to match the Pods to which the NetworkPolicy should
    be applied. This selection is done by using labels, which are metadata attached
    to Pods. The labels allow for a flexible and dynamic grouping of Pods, meaning
    that the same NetworkPolicy can be applied to multiple Pods that share the same
    labels and are running in the same namespace as the NetworkPolicy. Pod selectors
    are described in detail in [“Labels”](ch01.html#intro-labels).
  prefs: []
  type: TYPE_NORMAL
- en: The list of *ingress* and *egress* rules defines which inbound and outbound
    connections are allowed for the Pods matched by the Pod selector. These rules
    specify which sources and destinations are allowed to connect to and from the
    Pods. For example, a rule could allow connections from a specific IP address or
    range of addresses, or it could block connections to a specific destination.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with the simple example in [Example 24-1](#ex-network-segmentation-simple)
    that allows access to all database Pods only from backend Pods and nothing else.
  prefs: []
  type: TYPE_NORMAL
- en: Example 24-1\. Simple NetworkPolicy allowing ingress traffic
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_network_segmentation_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Selector matching all Pods with the label `id: database` and `app: chili-shop`.
    All those Pods are affected by this NetworkPolicy.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_network_segmentation_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: List of sources that are allowed for incoming traffic.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_network_segmentation_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Pod selector that will allow all Pods of the type `backend` to access the selected
    database Pods.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 24-1](#img-network-segmentation-ingress) shows how the backend Pods
    can access the database Pods but frontend Pods can’t.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stages that need to be passed by a request to the Kubernetes API server](assets/kup2_2401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 24-1\. NetworkPolicy for ingress traffic
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: NetworkPolicy objects are namespace-scoped and match only Pods from within the
    NetworkPolicy’s namespace. Unfortunately, there is no way to define cluster-wide
    defaults for all namespaces. However, some CNI plugins like Calico support customer
    extensions for defining cluster-wide behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Network segment definition with labels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [Example 24-1](#ex-network-segmentation-simple), we can see how label selectors
    are used to dynamically define groups of Pods. This is a powerful concept in Kubernetes
    that allows users to easily create distinct networking segments.
  prefs: []
  type: TYPE_NORMAL
- en: Developers are typically the best ones to know which Pods belong to a specific
    application and how they communicate with one another. By carefully labeling the
    Pods, users can directly translate the dependency graphs of distributed applications
    into NetworkPolicies. These policies can then be used to define the network boundaries
    for an application, with well-defined entry and exit points.
  prefs: []
  type: TYPE_NORMAL
- en: To create network segmentation using labels, it’s common to label all Pods in
    the application with a unique `app` label. The `app` label can be used in the
    selector of the NetworkPolicy to ensure that all Pods belonging to the application
    are covered by the policy. For example, in [Example 24-1](#ex-network-segmentation-simple),
    the network segment is defined using an `app` label with the value `chili-shop`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two common ways to consistently label workloads:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using workload-unique labels, you can directly model the dependency graph between
    application components such as other microservices or a database. These workloads
    can consist of multiple Pods, for example, when deployed in high availability.
    This technique is used to model the permission graph in [Example 24-1](#ex-network-segmentation-simple),
    where we use a label `type` to identify the application component. Only one type
    of workload (e.g., Deployment or StatefulSet) is expected to carry the label `type:
    database`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a more loosely coupled approach, you can define specific `role` or `permissions`
    labels that need to be attached to every workload that plays a certain role. [Example 24-2](#ex-network-segmentation-simple-role)
    shows an example of this setup. This approach is more flexible and allows for
    new workloads to be added without updating the NetworkPolicy. However, the more
    straightforward approach of directly connecting workloads is often easier to understand
    by simply looking at the NetworkPolicy without having to look up all workloads
    that apply to a role.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example 24-2\. Role-based network segment definition
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_network_segmentation_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Add all roles that enable this backend Pod to access the requested services.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_network_segmentation_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Selector matching the database Pods—i.e., Pods with the label `id: database`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_network_segmentation_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Every Pod that is a database client (`role-database-client: ''true''`) is allowed
    to send traffic to the backend Pod.'
  prefs: []
  type: TYPE_NORMAL
- en: Deny-all as default policy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Examples [24-1](#ex-network-segmentation-simple) and [24-2](#ex-network-segmentation-simple-role),
    we have seen how to individually configure the allowed incoming connections for
    a selected set of Pods. This setup works fine as long as you don’t forget to configure
    one Pod, since the default mode, when NetworkPolicy is not configured in the namespace,
    does not restrict incoming and outgoing traffic (allow-all). Also, for Pods that
    we might create in the future, it is problematic that it might be necessary to
    remember to add the respective NetworkPolicy.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it is highly recommended to start with a deny-all policy, as shown
    in [Example 24-3](#ex-network-segmentation-deny-all).
  prefs: []
  type: TYPE_NORMAL
- en: Example 24-3\. Deny-all policy for incoming traffic
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_network_segmentation_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: An empty selector matches every Pod.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_network_segmentation_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: An empty list of ingress rules implies that all incoming traffic gets dropped.
  prefs: []
  type: TYPE_NORMAL
- en: The list of allowed ingresses is set to an empty list (`[]`), which implies
    there is no ingress rule that allows incoming traffic. Note that an empty list
    `[]` is different from a list with a single empty element `[ {} ]`, which achieves
    the exact opposite since the single empty rule matches everything.
  prefs: []
  type: TYPE_NORMAL
- en: Ingress
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Example 24-1](#ex-network-segmentation-simple) covers the primary use case
    of a policy that covers ingress traffic. We have already explained the `podSelector`
    field and given an example of an `ingress` list that matches Pods that are allowed
    to send traffic to the Pod under configuration. The selected Pod can receive traffic
    if any of the configured ingress rules in the list are matched.'
  prefs: []
  type: TYPE_NORMAL
- en: Besides selecting Pods, you have additional options to configure the ingress
    rules. We already saw the `from` field for an ingress rule that can contain a
    `podSelector` for selecting all Pods that pass this rule. In addition, a `namespaceSelector`
    can be given to choose the namespaces in which the `podSelector` should be applied
    to identify the Pods that can send traffic.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 24-1](#table-network-segmentation-ingress-rules) shows the effect of
    the various combinations of `podSelector` and `name​sp⁠aceSelector`. Combining
    both fields allows for very flexible setups.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 24-1\. Combinations of setting `podSelector` and `namespaceSelector`
    `({}: empty`, `{...}: non-empty`, `---: unset`)'
  prefs: []
  type: TYPE_NORMAL
- en: '| podSelector | namespaceSelector | Behavior |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| {} | {} | Every Pod in every namespace |'
  prefs: []
  type: TYPE_TB
- en: '| {} | { …​ } | Every Pod in the matched namespaces |'
  prefs: []
  type: TYPE_TB
- en: '| { …​ } | { } | Every matching Pod in all namespaces |'
  prefs: []
  type: TYPE_TB
- en: '| { …​ } | { …​ } | Every matching Pod in the matching namespaces |'
  prefs: []
  type: TYPE_TB
- en: '| --- | { …​ } / {} | Every Pod in the matching namespace/all namespaces |'
  prefs: []
  type: TYPE_TB
- en: '| { …​ } / {} | --- | Matching Pods/every Pod in the NetworkPolicy’s namespace
    |'
  prefs: []
  type: TYPE_TB
- en: As an alternative for selecting Pods from the cluster, a range of IP addresses
    can be specified with a field `ipBlock`. We show IP ranges in [Example 24-5](#ex-network-segmentation-egress-ipblock).
  prefs: []
  type: TYPE_NORMAL
- en: Another option is to restrict the traffic to specific ports to the selected
    Pod. We can specify this list with a `ports` field that contains all allowed ports.
  prefs: []
  type: TYPE_NORMAL
- en: Egress
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Not only can incoming traffic be regulated, but so can any request that a Pod
    sends in the outgoing direction. Egress rules are configured precisely with the
    same options as ingress rules. And as with ingress rules, starting with a very
    restrictive policy is recommended. However, denying all outgoing traffic is not
    practical. Every Pod needs interaction with Pods from the system namespace for
    DNS lookups. Also, if we use ingress rules to restrict incoming traffic, we would
    have to add mirrored egress rules for the source Pods. So let’s be pragmatic and
    allow all egress within the cluster, forbid everything outside the cluster, and
    let ingress rules define the network boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 24-4](#ex-network-segmentation-internal-egress) shows the definition
    of such a rule.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 24-4\. Allow all internal egress traffic
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_network_segmentation_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Add only `Egress` as policy type; otherwise, Kubernetes assumes that you want
    to specify ingress and egress.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_network_segmentation_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Apply NetworkPolicy to all Pods in the NetworkPolicy’s namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_network_segmentation_CO4-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Allow egress to every Pod in every other namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 24-2](#img-network-segmentation-egress) illustrates the effect of this
    NetworkPolicy and how it prevents Pods from connecting to external services.'
  prefs: []
  type: TYPE_NORMAL
- en: '![NetworkPolicy that allows only internal egress traffic](assets/kup2_2402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 24-2\. NetworkPolicy that allows only internal egress traffic
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The `policyTypes` field in a NetworkPolicy determines the type of traffic the
    policy affects. It is a list that can contain the elements `Egress` and/or `Ingress`,
    and it specifies which rules are included in the policy. If the field is omitted,
    the default value is determined based on the presence of the `ingress` and `egress`
    rule sections:'
  prefs: []
  type: TYPE_NORMAL
- en: If an `ingress` section is present, the default value of `policyTypes` is `[Ingress]`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If an `egress` section is provided, the default value of `policyTypes` is `[Ingress,
    Egress]` regardless of whether ingress rules are provided.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This default behavior implies that to define an egress-only policy, you must
    explicitly set `policyTypes` to `[Egress]`, as in [Example 24-4](#ex-network-segmentation-internal-egress).
    Failing to do so would imply an empty `ingress` rules set, effectively forbidding
    all incoming traffic.
  prefs: []
  type: TYPE_NORMAL
- en: With this restriction for cluster-internal egress traffic in place, we can selectively
    activate access to external IP addresses for certain Pods that might require cluster-external
    network access. In [Example 24-5](#ex-network-segmentation-egress-ipblock), such
    an IP range block for allowing external egress access is defined.
  prefs: []
  type: TYPE_NORMAL
- en: Example 24-5\. NetworkPolicy that allows access to all IP addresses, with some
    exceptions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_network_segmentation_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Allow access to all IP addresses…​
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_network_segmentation_CO5-2)'
  prefs: []
  type: TYPE_NORMAL
- en: …​except IP addresses that belong to these subnets.
  prefs: []
  type: TYPE_NORMAL
- en: Some care must be taken if you decide to choose more strict egress rules and
    also want to restrict the cluster’s internal egress traffic. First, it is essential
    to always allow access to the DNS server in the kube-system namespace. This configuration
    is best done by allowing access to port 53 for UDP and TCP to all ports in the
    system namespace.
  prefs: []
  type: TYPE_NORMAL
- en: For operators and controllers, the Kubernetes API server needs to be accessible.
    Unfortunately, no unique label would select the API server in the kube-system
    namespace, so the filtering should happen on the API server’s IP address. The
    IP address can best be fetched from the `kubernetes` endpoints in the default
    namespace with `kubectl get endpoints -n default kubernetes`.
  prefs: []
  type: TYPE_NORMAL
- en: Tooling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Setting up the network topology with NetworkPolicies gets complex quickly since
    it involves creating many NetworkPolicy resources. It is best to start with some
    simple use cases that you can adapt to your specific needs. [Kubernetes Network
    Policy Recipes](https://oreil.ly/NvQFm) is a good starting point.
  prefs: []
  type: TYPE_NORMAL
- en: Commonly, NetworkPolicies are defined along with the application’s architecture.
    However, sometimes you must retrofit the policy schemas to an existing solution.
    In this case, policy advisor tools can be beneficial. They work by recording the
    network activity when playing through typical use cases. A comprehensive integration
    test suite with good test coverage pays off to catch all corner cases involving
    network connections. As of 2023, several tools can help you audit network traffic
    to create network policies.
  prefs: []
  type: TYPE_NORMAL
- en: '[Inspektor Gadget](https://oreil.ly/nlVOx) is a great tool suite for debugging
    and inspecting Kubernetes resources. It is entirely based on eBPF programs that
    enable kernel-level observability and provides a bridge from kernel features to
    high-level Kubernetes resources. One of Inspektor Gadget’s features is to monitor
    network activity and record all UDP and TCP traffic for generating Kubernetes
    network policies. This technique works well but depends on the quality and depth
    of covered use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: Another great eBPF-based platform is [Cilium](https://cilium.io), which has
    a dedicated audit mode that tracks all network traffic and matches it against
    a given network policy. By starting with a deny-all policy and audit mode enabled,
    Cilium will record all policy violations but will not block the traffic otherwise.
    The audit report helps create the proper NetworkPolicy to fit the traffic patterns
    exercised.
  prefs: []
  type: TYPE_NORMAL
- en: These are only two examples of the rich and growing landscape of tools for policy
    recommendation, simulations, and auditing.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have seen how we can model the network boundaries for our application
    on the TCP/UDP and IP levels, let’s move up some levels in the OSI stack.
  prefs: []
  type: TYPE_NORMAL
- en: Authentication Policies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Until now, we looked at how we can control the network traffic between Pods
    on the TCP/IP level. However, it is sometimes beneficial to base the network restrictions
    on filtering on higher-level protocol parameters. This advanced network control
    requires knowledge of higher-level protocols like HTTP and the ability to inspect
    incoming and outgoing traffic. Kubernetes does not support this out of the box.
    Luckily, a whole family of add-ons extends Kubernetes to provide this functionality:
    service meshes.'
  prefs: []
  type: TYPE_NORMAL
- en: We chose Istio as our example service mesh, but you will find similar functionalities
    in other service meshes. We won’t go into much detail about service meshes or
    Istio. Instead, we’ll focus on a particular custom resource of Istio that helps
    us shape the networking segments on the HTTP protocol level.
  prefs: []
  type: TYPE_NORMAL
- en: Istio has a rich feature set for enabling authentication, transport security
    via mTLS, identity management with CERT rotations, and authorization.
  prefs: []
  type: TYPE_NORMAL
- en: As with other Kubernetes extensions, Istio leverages the Kubernetes API machinery
    by introducing its own CustomResourceDefinitions (CRDs) that are explained in
    detail in [Chapter 28, “Operator”](ch28.html#Operator). Authorization in Istio
    is configured with the AuthorizationPolicy resource. While AuthorizationPolicy
    is only one component in Istio’s security model, it can be used alone and allows
    for partitioning the network space based on HTTP.
  prefs: []
  type: TYPE_NORMAL
- en: The schema of AuthorizationPolicy is very similar to NetworkPolicy but is more
    flexible and includes HTTP-specific filters. NetworkPolicy and AuthorizationPolicy
    should be used together. This can lead to a tricky debugging setup when two configurations
    must be checked and verified in parallel. Traffic will pass through to a Pod only
    if the two user-defined firewalls spanned by NetworkPolicy and AuthorizationPolicy
    definition will allow it.
  prefs: []
  type: TYPE_NORMAL
- en: 'An AuthorizationPolicy is a namespaced resource and contains a set of rules
    that control whether or not traffic is allowed or denied to a particular set of
    Pods in a Kubernetes cluster. The policy consists of the following three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Selector
  prefs: []
  type: TYPE_NORMAL
- en: Specifies which Pods the policy applies to. If no selector is specified, the
    policy applies to all Pods in the same namespace as the policy. If the policy
    is created in Istio’s root namespace (`istio-system`), it applies to all matching
    Pods in all namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: Action
  prefs: []
  type: TYPE_NORMAL
- en: Defines what should be done with the traffic that matches the rules. The possible
    actions are `ALLOW`, `DENY`, `AUDIT` (for logging only), and `CUSTOM` (for user-defined
    actions).
  prefs: []
  type: TYPE_NORMAL
- en: List of rules
  prefs: []
  type: TYPE_NORMAL
- en: 'These are evaluated for incoming traffic. All of the rules must be satisfied
    for the action to be taken. Each rule has three components: a `from` field that
    specifies the source of the request, a `to` field that specifies the HTTP operation
    that the request must match, and an optional `when` field for additional conditions
    (e.g., the identity associated with the request must match a particular value).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 24-6](#ex-network-segmentation-authorization-policy) shows a typical
    example that allows the monitoring operator access to application endpoints for
    collecting metric data.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 24-6\. Authorization for a Prometheus setup
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_network_segmentation_CO6-1)'
  prefs: []
  type: TYPE_NORMAL
- en: When created in the namespace `istio-system`, the policy applies to all matching
    Pods in all namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_network_segmentation_CO6-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The policy is applied to all Pods with a `has-metrics` label set to `true`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_network_segmentation_CO6-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The action should allow the request to pass if the rules match.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_network_segmentation_CO6-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Every request coming from a Pod from the `prometheus` namespace…​
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_network_segmentation_CO6-5)'
  prefs: []
  type: TYPE_NORMAL
- en: …​can perform a GET request on the `/metrics` endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Example 24-6](#ex-network-segmentation-authorization-policy), every Pod
    that carries the label `has-metrics: "true"` allows traffic to its `/metrics`
    endpoint from each Pod of the `prometheus` namespace.'
  prefs: []
  type: TYPE_NORMAL
- en: This policy has an effect only if, by default, all requests are denied. As for
    NetworkPolicy, the best starting point is to define a deny-all policy, as shown
    in [Example 24-7](#ex-network-segmentation-istio-deny-all), and then selectively
    build up the network topology by allowing dedicated routes.
  prefs: []
  type: TYPE_NORMAL
- en: Example 24-7\. Deny-all policy as the default
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_network_segmentation_CO7-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The policy applies to all namespaces since it is created in `istio-system`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_network_segmentation_CO7-2)'
  prefs: []
  type: TYPE_NORMAL
- en: An empty selector always matches.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_network_segmentation_CO7-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Deny access for all Pods that match the selector.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_network_segmentation_CO7-4)'
  prefs: []
  type: TYPE_NORMAL
- en: An empty rule that will always match.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Istio follows NetworkPolicy’s semantics that an empty rule list [] never matches.
    In contrast, a list with a single empty rule [{}] always matches.
  prefs: []
  type: TYPE_NORMAL
- en: With the help of the proper labeling schema, AuthorizationPolicy helps define
    the application’s network segments that are independent and isolated from one
    another. All that we said in [“Network segment definition with labels”](#network-segmentation-labeling)
    also applies here.
  prefs: []
  type: TYPE_NORMAL
- en: However, AuthorizationPolicy can also be used for application-level authorization
    when we add an identity check to the rules. One crucial difference to the authorization
    that we describe in [Chapter 26, “Access Control”](ch26.html#AccessControl), is
    that AuthorizationPolicy is about *application authorization*, while the Kubernetes
    RBAC model is about securing the access to the Kubernetes API server. Access control
    is primarily helpful for operators monitoring their custom resources.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the early days of computing, network topologies were defined by physical
    wiring and devices like switches. This approach is secure but not very flexible.
    With the advent of virtualization, these devices were replaced by software-backed
    constructs to provide network security. *Software-defined networking* (SDN) is
    a type of computer networking architecture that allows network administrators
    to manage network services through abstraction of lower-level functionality. This
    abstraction is typically achieved by separating the control plane, which makes
    decisions about how data should be transmitted, from the data plane, which actually
    sends the data. Even with the use of SDN, administrators are still needed to set
    up and rearrange networking boundaries to effectively manage the network.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has the ability to overlay its flat cluster-internal network with
    network segments defined by users through the Kubernetes API. This is the next
    step in the evolution of network user interfaces. It shifts the responsibility
    to developers who understand the security requirements of their applications.
    This shift-left approach is beneficial in a world of microservices with many distributed
    dependencies and a complex network of connections. NetworkPolicies for L3/L4 network
    segmentation and AuthenticationPolicies for more granular control of network boundaries
    are essential for implementing this *Network Segmentation* pattern.
  prefs: []
  type: TYPE_NORMAL
- en: With the advent of eBPF-based platforms on top of Kubernetes, there is additional
    support for finding suitable network models. Cilium is an example of a platform
    that combines L3/L4 and L7 firewalling into a single API, making it easier to
    implement the pattern described in this chapter in future versions of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: More Information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Network Segmentation Example](https://oreil.ly/gwU-y)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Network Policies](https://oreil.ly/P5r0X)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Kubernetes Network Model](https://oreil.ly/qR0O9)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kubernetes Network Policy Recipes](https://oreil.ly/NhrWK)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using Network Policies](https://oreil.ly/BzlSd)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why You Should Test Your Kubernetes Network Policies](https://oreil.ly/r-dn7)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using the eBPF Superpowers to Generate Kubernetes Security Policies](https://oreil.ly/_5cWc)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using Advise Network-Policy](https://oreil.ly/5VbP4) with Inspektor Gadget'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[You and Your Security Profiles; Generating Security Policies with the Help
    of eBPF](https://oreil.ly/-jKvO)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[kube-iptables-tailer](https://oreil.ly/r-4pI)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Creating Policies from Verdicts](https://oreil.ly/9lqlu)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Istio: Authorization Policy](https://oreil.ly/69M7s)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Istio: Authentication Policies](https://oreil.ly/bLq35)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SIG Multitenancy Working Group](https://oreil.ly/X00FG)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ^([1](ch24.html#idm45902087907696-marker)) Level 3 and Level 4 of the OSI Network
    stack are mostly about IP and TCP/UDP, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch24.html#idm45902087228288-marker)) eBPF was originally an acronym for
    “extended Berkeley Packet Filter” but is nowadays used as an independent term
    on its own.
  prefs: []
  type: TYPE_NORMAL
