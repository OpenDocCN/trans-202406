["```\n`kubectl describe pod -n kube-system -l component=kube-apiserver`\nName:         kube-apiserver-docker-for-desktop Namespace:    kube-system ... Containers:\n kube-apiserver: ... Command: kube-apiserver ... --authorization-mode=Node,RBAC\n```", "```\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: secret-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n```", "```\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: daisy-edit\n  namespace: demo\nsubjects:\n- kind: User\n  name: daisy\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: edit\n  apiGroup: rbac.authorization.k8s.io\n```", "```\n`kubectl` `describe` `clusterrole/edit`\nName:         edit\nLabels:       kubernetes.io/bootstrapping=rbac-defaults\nAnnotations:  rbac.authorization.kubernetes.io/autoupdate=true\nPolicyRule:\n  Resources   ... Verbs\n  ---------   ... -----\n  bindings    ... [get list watch]\n  configmaps  ... [create delete deletecollection get list patch update watch]\n  endpoints   ... [create delete deletecollection get list patch update watch]\n  ...\n```", "```\nError from server (Forbidden): nodes.metrics.k8s.io is forbidden: User\n\"demo\" cannot list nodes.metrics.k8s.io at the cluster scope.\n```", "```\n`kubectl logs -n kube-system -l component=kube-apiserver | grep \"RBAC DENY\"`\nRBAC DENY: user \"demo\" cannot \"list\" resource \"nodes\" cluster-wide\n```", "```\n[source, console, subs=\"quotes\"]\n*kubectl auth can-i list secrets*\nyes\n*kubectl auth can-i create deployments --as test-user*\nno\n```", "```\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sDisallowedTags\nmetadata:\n  name: container-image-must-not-have-latest-tag\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n    namespaces:\n      - \"my-namespace\"\n  parameters:\n    tags: [\"latest\"]\n```", "```\n`kubectl apply -f job.yaml`\njob.batch/kube-bench created \n`kubectl logs job/kube-bench`\n... == Summary total == 63 checks PASS 13 checks FAIL 46 checks WARN 0 checks INFO ...\n```", "```\n`trivy image [YOUR_CONTAINER_IMAGE_NAME]`\n```", "```\n`trivy config [YOUR_CODE_DIR]`\n```", "```\n`docker scan golang:1.17-alpine`\n\nTesting golang:1.17-alpine... \nPackage manager:   apk Project name:      docker-image|golang Docker image:      golang:1.17-alpine Platform:          linux/amd64 Base image:        golang:1.17.1-alpine3.14 \nâœ“ Tested 15 dependencies for known vulnerabilities, no vulnerable paths found.\n```", "```\n`docker scan golang:1.14-alpine`\n... Tested 15 dependencies for known vulnerabilities, found 10 vulnerabilities. \nBase Image          Vulnerabilities  Severity golang:1.14-alpine  10               2 critical, 5 high, 2 medium, 1 low \nRecommendations for base image upgrade: \nMinor upgrades Base Image            Vulnerabilities  Severity golang:1.17.0-alpine  0                0 critical, 0 high, 0 medium, 0 low\n```", "```\napiVersion: velero.io/v1\nkind: BackupStorageLocation\nmetadata:\n  name: default\n  namespace: velero\nspec:\n  provider: aws\n  objectStorage:\n    bucket: demo-backup\n  config:\n    region: us-east-1\n```", "```\napiVersion: velero.io/v1\nkind: VolumeSnapshotLocation\nmetadata:\n  name: aws-default\n  namespace: velero\nspec:\n  provider: aws\n  config:\n    region: us-east-1\n```", "```\n`velero backup create demo-backup --include-namespaces demo`\n```", "```\n`velero backup download demo-backup`\nBackup demo-backup has been successfully downloaded to $PWD/demo-backup-data.tar.gz\n```", "```\n`velero schedule create demo-schedule --schedule=\"0 1 * * *\" --include-namespaces` `demo`\nSchedule \"demo-schedule\" created successfully.\n```", "```\n`kubectl get componentstatuses`\nNAME                 STATUS    MESSAGE              ERROR controller-manager   Healthy   ok scheduler            Healthy   ok etcd-0               Healthy   {\"health\": \"true\"}\n```", "```\n`kubectl get nodes`\nNAME             STATUS   ROLES                  AGE   VERSION docker-desktop   Ready    control-plane,master   24d   v1.21.4\n```", "```\n`kubectl get nodes`\nNAME                                         STATUS   ROLES   AGE  VERSION gke-k8s-cluster-1-n1-standard-2-pool--8l6n   Ready    <none>  9d   v1.20.2-gke.1 gke-k8s-cluster-1-n1-standard-2-pool--dwtv   Ready    <none>  19d  v1.20.2-gke.1 gke-k8s-cluster-1-n1-standard-2-pool--67ch   Ready    <none>  20d  v1.20.2-gke.1 ...\n```", "```\n`kubectl describe nodes/gke-k8s-cluster-1-n1-standard-2-pool--8l6n`\n```", "```\n`kubectl get pods --all-namespaces`\nNAMESPACE     NAME                          READY  STATUS           RESTARTS  AGE cert-manager  cert-manager-cert-manager-55  1/1    Running          1         10d pa-test       permissions-auditor-15281892  0/1    CrashLoopBackOff 1720      6d metrics-api   metrics-api-779758f445        3/3    Running          5         20d ...\n```", "```\n`kubectl top nodes`\nNAME                           CPU(cores)   CPU%      MEMORY(bytes)   MEMORY% gke-k8s-cluster-1-n1-...8l6n   151m         7%        2783Mi          49% gke-k8s-cluster-1-n1-...dwtv   155m         8%        3449Mi          61% gke-k8s-cluster-1-n1-...67ch   580m         30%       3172Mi          56% ...\n```", "```\n`kubectl top pods -n kube-system`\nNAME                                    CPU(cores)   MEMORY(bytes) event-exporter-v0.1.9-85bb4fd64d-2zjng  0m           27Mi fluentd-gcp-scaler-7c5db745fc-h7ntr     10m          27Mi fluentd-gcp-v3.0.0-5m627                11m          171Mi ...\n```"]