- en: Chapter 1\. Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 1 章\. 引言
- en: Programming Kubernetes can mean different things to different people. In this
    chapter, we’ll first establish the scope and focus of this book. Also, we will
    share the set of assumptions about the environment we’re operating in and what
    you’ll need to bring to the table, ideally, to benefit most from this book. We
    will define what exactly we mean by programming Kubernetes, what Kubernetes-native
    apps are, and, by having a look at a concrete example, what their characteristics
    are. We will discuss the basics of controllers and operators, and how the event-driven
    Kubernetes control plane functions in principle. Ready? Let’s get to it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不同的人，编程 Kubernetes 可能意味着不同的事情。在本章中，我们首先会确定本书的范围和重点。此外，我们将分享对我们操作环境的一组假设，以及您最好带来的东西，以便从本书中获益最大化。我们将定义编程
    Kubernetes 的确切含义，Kubernetes 本地应用程序是什么，以及通过具体示例来了解它们的特征。我们将讨论控制器和操作员的基础知识，以及事件驱动的
    Kubernetes 控制平面的工作原理。准备好了吗？让我们开始吧。
- en: What Does Programming Kubernetes Mean?
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程 Kubernetes 意味着什么？
- en: We assume you have access to a running Kubernetes cluster such as Amazon EKS,
    Microsoft AKS, Google GKE, or one of the OpenShift offerings.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您可以访问运行中的 Kubernetes 集群，如 Amazon EKS、Microsoft AKS、Google GKE 或 OpenShift
    的某个提供方。
- en: Tip
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'You will spend a fair amount of time developing *locally* on your laptop or
    desktop environment; that is, the Kubernetes cluster against which you’re developing
    is local, rather than in the cloud or in your datacenter. When developing locally,
    you have a number of options available. Depending on your operating system and
    other preferences you might choose one (or maybe even more) of the following solutions
    for running Kubernetes locally: [kind](https://kind.sigs.k8s.io), [k3d](http://bit.ly/2Ja1LaH),
    or [Docker Desktop](https://dockr.ly/2PTJVLL).^([1](ch01.html#idm46336877072840))'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您将会在本地开发相当一段时间，即您开发的 Kubernetes 集群是本地的，而不是在云端或数据中心。在本地开发时，您有多种选择。根据您的操作系统和其他偏好，您可以选择以下一种（或多种）解决方案来本地运行
    Kubernetes：[kind](https://kind.sigs.k8s.io)、[k3d](http://bit.ly/2Ja1LaH) 或 [Docker
    Desktop](https://dockr.ly/2PTJVLL).^([1](ch01.html#idm46336877072840))
- en: 'We also assume that you are a Go programmer—that is, you have experience or
    at least basic familiarity with the Go programming language. Now is a good time,
    if any of those assumptions do not apply to you, to train up: for Go, we recommend
    [*The Go Programming Language*](https://www.gopl.io) by Alan A. A. Donovan and
    Brian W. Kernighan (Addison-Wesley) and [*Concurrency in Go*](http://bit.ly/2tdCt5j)
    by Katherine Cox-Buday (O’Reilly). For Kubernetes, check out one or more of the
    following books:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还假设您是一位 Go 程序员，即您具有使用 Go 编程语言的经验或至少基本了解。如果您不符合以上任何假设，现在是一个很好的时机来进行培训：对于 Go
    语言，我们推荐 [*The Go Programming Language*](https://www.gopl.io) 由 Alan A. A. Donovan
    和 Brian W. Kernighan 撰写（Addison-Wesley），以及 [*Concurrency in Go*](http://bit.ly/2tdCt5j)
    由 Katherine Cox-Buday 撰写（O’Reilly）。对于 Kubernetes，可以查阅以下一本或多本书籍：
- en: '[*Kubernetes in Action*](http://bit.ly/2Tb8Ydo) by Marko Lukša (Manning)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Kubernetes 实战*](http://bit.ly/2Tb8Ydo) 由 Marko Lukša 撰写（Manning）'
- en: '[*Kubernetes: Up and Running*, 2nd Edition](https://oreil.ly/2SaANU4) by Kelsey
    Hightower et al. (O’Reilly)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Kubernetes: Up and Running*，第 2 版](https://oreil.ly/2SaANU4) 由 Kelsey Hightower
    等人撰写（O’Reilly）'
- en: '[*Cloud Native DevOps with Kubernetes*](https://oreil.ly/2BaE1iq) by John Arundel
    and Justin Domingus (O’Reilly)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*使用 Kubernetes 进行云原生 DevOps*](https://oreil.ly/2BaE1iq) 由 John Arundel 和 Justin
    Domingus 撰写（O’Reilly）'
- en: '[*Managing Kubernetes*](https://oreil.ly/2wtHcAm) by Brendan Burns and Craig
    Tracey (O’Reilly)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*管理 Kubernetes*](https://oreil.ly/2wtHcAm) 由 Brendan Burns 和 Craig Tracey
    撰写（O’Reilly）'
- en: '[*Kubernetes Cookbook*](http://bit.ly/2FTgJzk) by Sébastien Goasguen and Michael
    Hausenblas (O’Reilly)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Kubernetes Cookbook*](http://bit.ly/2FTgJzk) 由 Sébastien Goasguen 和 Michael
    Hausenblas 撰写（O’Reilly）'
- en: Note
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Why do we focus on programming Kubernetes in Go? Well, an analogy might be
    useful here: Unix was written in the C programming language, and if you wanted
    to write applications or tooling for Unix you would default to C. Also, in order
    to extend and customize Unix—even if you were to use a language other than C—you
    would need to at least be able to read C.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们专注于使用 Go 编程 Kubernetes？好吧，这里可能有一个类比会有帮助：Unix 是用 C 编程语言编写的，如果您想为 Unix 编写应用程序或工具，您将默认使用
    C。此外，即使您想使用其他语言来扩展和定制 Unix，您至少也需要能够阅读 C 语言。
- en: Now, Kubernetes and many related cloud-native technologies, from container runtimes
    to monitoring such as Prometheus, are written in Go. We believe that the majority
    of native applications will be Go-based and hence we focus on it in this book.
    Should you prefer other languages, keep an eye on the [kubernetes-client](http://bit.ly/2xfSrfT)
    GitHub organization. It may, going forward, contain a client in your favorite
    programming language.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Kubernetes 和许多相关的云原生技术，从容器运行时到监控如 Prometheus，都是用 Go 编写的。我们相信大多数原生应用将会基于 Go，因此在本书中我们重点关注它。如果你更喜欢其他语言，请关注
    [kubernetes-client](http://bit.ly/2xfSrfT) GitHub 组织。将来可能会包含你喜欢的编程语言的客户端。
- en: 'By “programming Kubernetes” in the context of this book, we mean the following:
    you are about to develop a Kubernetes-native application that directly interacts
    with the API server, querying the state of resources and/or updating their state.
    We do not mean running off-the-shelf apps, such as WordPress or Rocket Chat or
    your favorite enterprise CRM system, oftentimes called *commercially available
    off-the-shelf* (COTS) apps. Besides, in [Chapter 7](ch07.html#ch_shipping), we
    do not really focus too much on operational issues, but mainly look at the development
    and testing phase. So, in a nutshell, this book is about developing genuinely
    cloud-native applications. [Figure 1-1](#apps-on-kube) might help you soak that
    in better.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的上下文中，“编程 Kubernetes”指的是以下内容：你将要开发一个直接与 API 服务器交互的 Kubernetes 原生应用，查询资源的状态和/或更新它们的状态。我们不是指运行诸如
    WordPress 或 Rocket Chat 或你最喜欢的企业 CRM 系统等现成的应用，通常称为 *商业可用现成的* (COTS) 应用。此外，在[第
    7 章](ch07.html#ch_shipping)中，我们并不真正关注操作问题，而主要关注开发和测试阶段。总之，本书关注的是开发真正的云原生应用。[图
    1-1](#apps-on-kube) 可能会帮助你更好地理解。
- en: '![Different types of apps running on Kubernetes](assets/prku_0101.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![在 Kubernetes 上运行的不同类型的应用](assets/prku_0101.png)'
- en: Figure 1-1\. Different types of apps running on Kubernetes
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-1\. 在 Kubernetes 上运行的不同类型的应用
- en: 'As you can see, there are different styles at your disposal:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，这里有不同的风格可供选择：
- en: Take a COTS such as Rocket Chat and run it on Kubernetes. The app itself is
    not aware it runs on Kubernetes and usually doesn’t have to be. Kubernetes controls
    the app’s lifecycle—find node to run, pull image, launch container(s), carry out
    health checks, mount volumes, and so on—and that is that.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将类似 Rocket Chat 的 COTS 应用运行在 Kubernetes 上。这种应用本身并不知道它运行在 Kubernetes 上，通常也不需要知道。Kubernetes
    控制应用的生命周期 — 找到运行节点、拉取镜像、启动容器、执行健康检查、挂载卷等等 — 就是这样。
- en: Take a bespoke app, something you wrote from scratch, with or without having
    had Kubernetes as the runtime environment in mind, and run it on Kubernetes. The
    same modus operandi as in the case of a COTS applies.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拿一个定制的应用，比如你从头开始编写的东西，无论是否考虑将 Kubernetes 作为运行时环境，并在 Kubernetes 上运行它。与 COTS 的情况相同的操作方式适用。
- en: The case we focus on in this book is a cloud-native or Kubernetes-native application
    that is fully aware it is running on Kubernetes and leverages Kubernetes APIs
    and resources to some extent.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本书关注的案例是一个云原生或 Kubernetes 原生应用，它完全意识到自己正在 Kubernetes 上运行，并在一定程度上利用 Kubernetes
    的 API 和资源。
- en: 'The price you pay developing against the Kubernetes API pays off: on the one
    hand you gain portability, as your app will now run in any environment (from an
    on-premises deployment to any public cloud provider), and on the other hand you
    benefit from the clean, declarative mechanism Kubernetes provides.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你开发针对 Kubernetes API 的付出将会得到回报：一方面，你获得了可移植性，因为你的应用现在可以在任何环境中运行（从本地部署到任何公共云提供商），另一方面，你受益于
    Kubernetes 提供的干净、声明式的机制。
- en: Let’s move on to a concrete example now.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们转向一个具体的例子。
- en: A Motivational Example
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个激励性的例子
- en: To demonstrate the power of a Kubernetes-native app, let’s assume you want to
    implement `at`—that is, [schedule the execution of a command](http://bit.ly/2L4VqzU)
    at a given time.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要展示一个 Kubernetes 原生应用的强大，假设你想实现 `at` — 也就是在给定时间[安排命令的执行](http://bit.ly/2L4VqzU)。
- en: 'We call this [`cnat`](http://bit.ly/2RpHhON) or cloud-native `at`, and it works
    as follows. Let’s say you want to execute the command `echo "Kubernetes native
    rocks!"` at 2 a.m. on July 3, 2019\. Here’s what you would do with `cnat`:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称这个为 [`cnat`](http://bit.ly/2RpHhON) 或云原生 `at`，它的工作原理如下。假设你想在 2019 年 7 月 3
    日凌晨 2 点执行命令 `echo "Kubernetes native rocks!"`。你可以用 `cnat` 来做到：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Behind the scenes, the following components are involved:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，涉及以下组件：
- en: A custom resource called `cnat.programming-kubernetes.info/cnrex`, representing
    the schedule.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为`cnat.programming-kubernetes.info/cnrex`的自定义资源，代表调度。
- en: A controller to execute the scheduled command at the correct time.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个控制器，在正确的时间执行计划的命令。
- en: In addition, a `kubectl` plug-in for the CLI UX would be useful, allowing simple
    handling via commands like `kubectl` `at` `"02:00 Jul 3"` `echo` `"Kubernetes
    native rocks!"` We won’t write this in this book, but you can refer to [the Kubernetes
    documentation for instructions](http://bit.ly/2J1dPuN).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`kubectl` 的 CLI UX 插件将非常有用，允许通过命令如`kubectl at "02:00 Jul 3" echo "Kubernetes
    native rocks!"`进行简单处理。本书不会涉及此内容，但您可以参考[《Kubernetes 文档》的说明](http://bit.ly/2J1dPuN)。
- en: Throughout the book, we will use this example to discuss aspects of Kubernetes,
    its inner workings, and how to extend it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们将使用此示例来讨论 Kubernetes 的各个方面，其内部工作原理以及如何进行扩展。
- en: 'For the more advanced examples in Chapters [8](ch08.html#ch_custom-api-servers)
    and [9](ch09.html#ch_advanced-topics), we will simulate a pizza restaurant with
    pizza and topping objects in the cluster. See [“Example: A Pizza Restaurant”](ch08.html#aggregation-example)
    for details.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第8章和第9章的更高级示例，我们将在集群中模拟一个比萨餐厅，其中包含比萨和配料对象。详细信息请参见[“示例：比萨餐厅”](ch08.html#aggregation-example)。
- en: Extension Patterns
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展模式
- en: 'Kubernetes is a powerful and inherently extensible system. In general, there
    are multiple ways to customize and/or extend Kubernetes: using [configuration
    files and flags](http://bit.ly/2KteqbA) for control plane components like the
    `kubelet` or the Kubernetes API server, and through a number of defined extension
    points:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个功能强大且本质上可扩展的系统。通常，有多种方式可以自定义和/或扩展 Kubernetes：使用[配置文件和标志](http://bit.ly/2KteqbA)控制平面组件如`kubelet`或
    Kubernetes API 服务器，并通过多个定义的扩展点：
- en: So-called [cloud providers](http://bit.ly/2FpHInw), which were traditionally
    in-tree as part of the controller manager. As of 1.11, Kubernetes makes out-of-tree
    development possible by providing a [custom `cloud-controller-manager` process
    to integrate with a cloud](http://bit.ly/2WWlcxk). Cloud providers allow the use
    of cloud provider–specific tools like load balancers or Virtual Machines (VMs).
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所谓的[云提供商](http://bit.ly/2FpHInw)，传统上作为控制器管理器的一部分。从1.11版本开始，Kubernetes 通过提供一个[自定义
    `cloud-controller-manager` 进程来支持云](http://bit.ly/2WWlcxk)，使得离线开发成为可能。云提供商允许使用特定于云提供商的工具，如负载均衡器或虚拟机（VM）。
- en: Binary `kubelet` plug-ins for [network](http://bit.ly/2L1tPzm), [devices](http://bit.ly/2XthLgM)
    (such as GPUs), [storage](http://bit.ly/2x7Unaa), and [container runtimes](http://bit.ly/2Zzh1Eq).
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二进制 `kubelet` 插件用于[网络](http://bit.ly/2L1tPzm)、[设备](http://bit.ly/2XthLgM)（如
    GPU）、[存储](http://bit.ly/2x7Unaa) 和[容器运行时](http://bit.ly/2Zzh1Eq)。
- en: Binary `kubectl` [plug-ins](http://bit.ly/2FmH7mu).
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二进制 `kubectl` 的[插件](http://bit.ly/2FmH7mu)。
- en: Access extensions in the API server, such as the [dynamic admission control
    with webhooks](http://bit.ly/2DwR2Y3) (see [Chapter 9](ch09.html#ch_advanced-topics)).
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 API 服务器中访问扩展，例如使用[webhook进行动态准入控制](http://bit.ly/2DwR2Y3)（参见[第9章](ch09.html#ch_advanced-topics)）。
- en: Custom resources (see [Chapter 4](ch04.html#ch_crds)) and custom controllers;
    see the following section.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义资源（参见[第4章](ch04.html#ch_crds)）和自定义控制器；请参阅下一节。
- en: Custom API servers (see [Chapter 8](ch08.html#ch_custom-api-servers)).
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义 API 服务器（参见[第8章](ch08.html#ch_custom-api-servers)）。
- en: Scheduler extensions, such as using a [webhook](http://bit.ly/2xcg4FL) to implement
    your own scheduling decisions.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度程序扩展，例如使用[webhook](http://bit.ly/2xcg4FL)来实现您自己的调度决策。
- en: '[Authentication](http://bit.ly/2Oh6DPS) with webhooks.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用webhook进行[身份验证](http://bit.ly/2Oh6DPS)。
- en: In the context of this book we focus on custom resources, controllers, webhooks,
    and custom API servers, along with the Kubernetes [extension patterns](http://bit.ly/2L2SJ1C).
    If you’re interested in other extension points, such as storage or network plug-ins,
    check out the [official documentation](http://bit.ly/2Y0L1J9).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的背景下，我们专注于自定义资源、控制器、webhook 和自定义 API 服务器，以及 Kubernetes 的[扩展模式](http://bit.ly/2L2SJ1C)。如果您对其他扩展点感兴趣，如存储或网络插件，请查阅[官方文档](http://bit.ly/2Y0L1J9)。
- en: Now that you have a basic understanding of the Kubernetes extension patterns
    and the scope of this book, let’s move on to the heart of the Kubernetes control
    plane and see how we can extend it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经对 Kubernetes 扩展模式和本书的范围有了基本了解，让我们进入 Kubernetes 控制平面的核心部分，看看我们如何进行扩展。
- en: Controllers and Operators
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制器和操作员
- en: In this section you’ll learn about controllers and operators in Kubernetes and
    how they work.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将了解 Kubernetes 中控制器和运算符的工作原理。
- en: Per the [Kubernetes glossary](http://bit.ly/2IWGlxz), a *controller* implements
    a control loop, watching the shared state of the cluster through the API server
    and making changes in an attempt to move the current state toward the desired
    state.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 [Kubernetes 术语表](http://bit.ly/2IWGlxz)，*控制器* 实现了一个控制循环，通过 API 服务器监视集群的共享状态，并进行更改，试图将当前状态向期望状态移动。
- en: 'Before we dive into the controller’s inner workings, let’s define our terminology:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究控制器的内部工作之前，让我们先定义术语：
- en: Controllers can act on core resources such as deployments or services, which
    are typically part of the [Kubernetes controller manager](http://bit.ly/2WUAEVy)
    in the control plane, or can watch and manipulate user-defined custom resources.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器可以对核心资源（例如部署或服务）进行操作，这些资源通常是控制平面中的 [Kubernetes 控制器管理器](http://bit.ly/2WUAEVy)
    的一部分，或者可以监视和操作用户定义的自定义资源。
- en: Operators are controllers that encode some operational knowledge, such as application
    lifecycle management, along with the custom resources defined in [Chapter 4](ch04.html#ch_crds).
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运算符是编码了一些操作知识的控制器，例如应用程序生命周期管理，以及在 [第四章](ch04.html#ch_crds) 中定义的自定义资源。
- en: Naturally, given that the latter concept is based on the former, we’ll look
    at controllers first and then discuss the more specialized case of an operator.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，考虑到后者的概念基于前者，我们将首先讨论控制器，然后再讨论运算符的更专业案例。
- en: The Control Loop
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制循环
- en: 'In general, the control loop looks as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，控制循环如下所示：
- en: Read the state of resources, preferably event-driven (using watches, as discussed
    in [Chapter 3](ch03.html#ch_client-go)). See [“Events”](#controller-events) and
    [“Edge- Versus Level-Driven Triggers”](#edge-vs-level) for details.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首选事件驱动地读取资源状态（使用监视，如 [第三章](ch03.html#ch_client-go) 中讨论的），详见 [“事件”](#controller-events)
    和 [“边缘驱动触发器与级别驱动触发器”](#edge-vs-level)。
- en: Change the state of objects in the cluster or the cluster-external world. For
    example, launch a pod, create a network endpoint, or query a cloud API. See [“Changing
    Cluster Objects or the External World”](#controller-change-world) for details.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改集群对象或集群外部世界的对象状态。例如，启动一个 pod，创建一个网络端点或查询云 API。详见 [“更改集群对象或外部世界”](#controller-change-world)。
- en: Update status of the resource in step 1 via the API server in `etcd`. See [“Optimistic
    Concurrency”](#optimistic-concurrency) for details.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 API 服务器在 `etcd` 中更新资源状态的步骤 1。详见 [“乐观并发性”](#optimistic-concurrency)。
- en: Repeat cycle; return to step 1.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复循环；返回到步骤 1。
- en: No matter how complex or simple your controller is, these three steps—read resource
    state ˃ change the world ˃ update resource status—remain the same. Let’s dig a
    bit deeper into how these steps are actually implemented in a Kubernetes controller.
    The control loop is depicted in [Figure 1-2](#controller-loop-overview), which
    shows the typical moving parts, with the main loop of the controller in the middle.
    This main loop is continuously running inside of the controller process. This
    process is usually running inside a pod in the cluster.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您的控制器有多复杂或简单，这三个步骤——读取资源状态 ˃ 改变世界 ˃ 更新资源状态——始终保持不变。让我们深入了解 Kubernetes 控制器中这些步骤的实际实现。控制循环显示在
    [图 1-2](#controller-loop-overview) 中，显示了典型的运行部件，控制器的主循环位于中间。这个主循环在控制器进程内持续运行。该进程通常在集群中的一个
    pod 内运行。
- en: '![Kubernetes control loop](assets/prku_0102.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![Kubernetes 控制循环](assets/prku_0102.png)'
- en: Figure 1-2\. Kubernetes control loop
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-2\. Kubernetes 控制循环概述
- en: 'From an architectural point of view, a controller typically uses the following
    data structures (as discussed in detail in [Chapter 3](ch03.html#ch_client-go)):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从架构角度来看，控制器通常使用以下数据结构（在 [第三章](ch03.html#ch_client-go) 中详细讨论）：
- en: Informers
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 信息员
- en: Informers watch the desired state of resources in a scalable and sustainable
    fashion. They also implement a resync mechanism (see [“Informers and Caching”](ch03.html#informers)
    for details) that enforces periodic reconciliation, and is often used to make
    sure that the cluster state and the assumed state cached in memory do not drift
    (e.g., due bugs or network issues).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 信息员以可扩展和可持续的方式监视资源的期望状态。它们还实现了重新同步机制（详见[“信息员和缓存”](ch03.html#informers)），强制周期性协调，并经常用于确保集群状态和内存中缓存的假定状态不会偏离（例如由于错误或网络问题）。
- en: Work queues
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 工作队列
- en: Essentially, a work queue is a component that can be used by the event handler
    to handle queuing of state changes and help to implement retries. In `client-go`
    this functionality is available via the [*workqueue* package](http://bit.ly/2x7zyeK)
    (see [“Work Queue”](ch03.html#workqueue)). Resources can be requeued in case of
    errors when updating the world or writing the status (steps 2 and 3 in the loop),
    or just because we have to reconsider the resource after some time for other reasons.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，工作队列是一个组件，事件处理器可以使用它来处理状态变化的排队，并帮助实现重试。在`client-go`中，通过[*workqueue* package](http://bit.ly/2x7zyeK)（参见[“Work
    Queue”](ch03.html#workqueue)）提供此功能。在更新世界或写入状态时（循环中的步骤2和3），或仅因为我们必须因其他原因重新考虑资源时，资源可以重新排队。
- en: For a more formal discussion of Kubernetes as a declarative engine and state
    transitions, read [“The Mechanics of Kubernetes”](http://bit.ly/2IV2lcb) by Andrew
    Chen and Dominik Tornow.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 想要更正式地讨论 Kubernetes 作为声明式引擎和状态转换的话题，请阅读[“Kubernetes 的机制”](http://bit.ly/2IV2lcb)
    by Andrew Chen and Dominik Tornow。
- en: Let’s now take a closer look at the control loop, starting with Kubernetes event-driven
    architecture.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们更详细地了解控制循环，从 Kubernetes 事件驱动架构开始。
- en: Events
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件
- en: 'The Kubernetes control plane heavily employs events and the principle of loosely
    coupled components. Other distributed systems use remote procedure calls (RPCs)
    to trigger behavior. Kubernetes does not. Kubernetes controllers watch changes
    to Kubernetes objects in the API server: adds, updates, and removes. When such
    an event happens, the controller executes its business logic.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 控制平面大量使用事件和松耦合组件的原则。其他分布式系统使用远程过程调用（RPC）来触发行为，但 Kubernetes 不是这样。Kubernetes
    控制器监视 API 服务器中 Kubernetes 对象的更改：添加、更新和删除。当发生这样的事件时，控制器执行其业务逻辑。
- en: 'For example, in order to launch a pod via a deployment, a number of controllers
    and other control plane components work together:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，为了通过部署启动一个 pod，多个控制器和其他控制平面组件需要协同工作：
- en: The deployment controller (inside of `kube-controller-manager`) notices (through
    a deployment informer) that the user creates a deployment. It creates a replica
    set in its business logic.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署控制器（位于`kube-controller-manager`内部）通过部署通知器（deployment informer）注意到用户创建了一个部署。它根据自身的业务逻辑创建一个副本集。
- en: The replica set controller (again inside of `kube-controller-manager`) notices
    (through a replica set informer) the new replica set and subsequently runs its
    business logic, which creates a pod object.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 副本集控制器（同样位于`kube-controller-manager`内部）通过副本集通知器注意到新的副本集，随后运行其业务逻辑，创建一个 pod 对象。
- en: The scheduler (inside the `kube-scheduler` binary)—which is also a controller—notices
    the pod (through a pod informer) with an empty `spec.nodeName` field. Its business
    logic puts the pod in its scheduling queue.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调度器（位于`kube-scheduler`二进制文件内）——也是一个控制器——通过 pod 通知器注意到一个`spec.nodeName`字段为空的
    pod。其业务逻辑将该 pod 放入调度队列。
- en: Meanwhile the `kubelet`—another controller—notices the new pod (through its
    pod informer). But the new pod’s `spec.nodeName` field is empty and therefore
    does not match the `kubelet`’s node name. It ignores the pod and goes back to
    sleep (until the next event).
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与此同时，另一个控制器`kubelet`通过其 pod 通知器注意到了新的 pod。但新 pod 的`spec.nodeName`字段为空，因此与`kubelet`的节点名称不匹配。它会忽略该
    pod 并继续休眠（直到下一个事件）。
- en: The scheduler takes the pod out of the work queue and schedules it to a node
    that has enough free resources by updating the `spec.nodeName` field in the pod
    and writing it to the API server.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调度器从工作队列中取出 pod，并根据具有足够空闲资源的节点更新 pod 的`spec.nodeName`字段，并将其写入 API 服务器。
- en: The `kubelet` wakes up again due to the pod update event. It again compares
    the `spec.nodeName` with its own node name. The names match, and so the `kubelet`
    starts the containers of the pod and reports back that the containers have been
    started by writing this information into the pod status, back to the API server.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubelet`再次因 pod 更新事件而唤醒。它再次比较`spec.nodeName`与自身节点名称。名称匹配，因此`kubelet`启动 pod
    的容器，并通过将此信息写入 pod 状态回写到 API 服务器来报告容器已启动。'
- en: The replica set controller notices the changed pod but has nothing to do.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 副本集控制器注意到更改的 pod，但没有任何操作。
- en: Eventually the pod terminates. The `kubelet` will notice this, get the pod object
    from the API server and set the “terminated” condition in the pod’s status, and
    write it back to the API server.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，pod 终止。`kubelet`将注意到这一点，从 API 服务器获取 pod 对象，并在 pod 的状态中设置“terminated”条件，然后将其写回
    API 服务器。
- en: The replica set controller notices the terminated pod and decides that this
    pod must be replaced. It deletes the terminated pod on the API server and creates
    a new one.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制集控制器注意到已终止的 pod，并决定必须替换此 pod。它在 API 服务器上删除已终止的 pod 并创建一个新的 pod。
- en: And so on.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等等。
- en: As you can see, a number of independent control loops communicate purely through
    object changes on the API server and events these changes trigger through informers.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，许多独立的控制循环纯粹通过 API 服务器上的对象更改及这些更改触发的事件进行通信。
- en: These events are sent from the API server to the informers inside the controllers
    via watches (see [“Watches”](ch03.html#client-go-watches))—that is, streaming
    connections of watch events. All of this is mostly invisible to the user. Not
    even the API server audit mechanism makes these events visible; only the object
    updates are visible. Controllers often use log output, though, when they react
    on events.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这些事件通过监视器（参见 [“监视器”](ch03.html#client-go-watches)）从 API 服务器发送到控制器内的通知器，即监视事件的流连接。所有这些对用户而言大部分是不可见的。甚至
    API 服务器审计机制也不会使这些事件可见；只有对象更新可见。但是，当控制器对事件作出反应时，通常会使用日志输出。
- en: If you want to learn more about events, read Michael Gasch’s blog post [“Events,
    the DNA of Kubernetes”](http://bit.ly/2MZwbl6), where he provides more background
    and examples.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多关于事件的信息，请阅读迈克尔·加斯希的博客文章 [“Kubernetes 的 DNA：事件”](http://bit.ly/2MZwbl6)，在这里他提供了更多背景和示例。
- en: Edge- Versus Level-Driven Triggers
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘驱动与级别驱动触发器
- en: Let’s step back a bit and look more abstractly at how we can structure business
    logic implemented in controllers, and why Kubernetes has chosen to use events
    (i.e., state changes) to drive its logic.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微退后一步，更抽象地看待我们如何在控制器中实现业务逻辑的结构，以及为什么 Kubernetes 选择使用事件（即状态更改）来驱动其逻辑。
- en: 'There are two principled options to detect state change (the event itself):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个原则选项可以检测状态变化（事件本身）：
- en: Edge-driven triggers
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘驱动触发器
- en: At the point in time the state change occurs, a handler is triggered—for example,
    from no pod to pod running.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在状态变化发生时刻，会触发一个处理程序，例如从无 pod 到 pod 运行。
- en: Level-driven triggers
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 级别驱动触发器
- en: The state is checked at regular intervals and if certain conditions are met
    (for example, pod running), then a handler is triggered.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 定期检查状态，并且如果满足某些条件（例如 pod 运行），则触发处理程序。
- en: The latter is a form of polling. It does not scale well with the number of objects,
    and the latency of controllers noticing changes depends on the interval of polling
    and how fast the API server can answer. With many asynchronous controllers involved,
    as described in [“Events”](#controller-events), the result is a system that takes
    a long time to implement the users’ desire.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 后者是轮询的一种形式。随着对象数量的增加，它的扩展性不佳，控制器注意到更改的延迟取决于轮询间隔和 API 服务器的响应速度。涉及许多异步控制器时，正如在
    [“事件”](#controller-events) 中描述的那样，结果是系统需要很长时间来实现用户的需求。
- en: The former option is much more efficient with many objects. The latency mostly
    depends on the number of worker threads in the controller’s processing events.
    Hence, Kubernetes is based on events (i.e., edge-driven triggers).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 前者选项在处理许多对象时效率更高。延迟主要取决于控制器处理事件的工作线程数。因此，Kubernetes 基于事件（即边缘驱动触发器）。
- en: In the Kubernetes control plane, a number of components change objects on the
    API server, with each change leading to an event (i.e., an edge). We call these
    components *event sources* or *event producers*. On the other hand, in the context
    of controllers, we’re interested in consuming events—that is, when and how to
    react to an event (via an informer).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 控制平面中，许多组件更改 API 服务器上的对象，每次更改都会导致一个事件（即边缘）。我们称这些组件为*事件源*或*事件生产者*。另一方面，在控制器的上下文中，我们对消费事件感兴趣——也就是何时以及如何对事件（通过通知器）做出反应。
- en: In a distributed system there are many actors running in parallel, and events
    come in asynchronously in any order. When we have a buggy controller logic, some
    slightly wrong state machine, or an external service failure, it is easy to lose
    events in the sense that we don’t process them completely. Hence, we have to take
    a deeper look at how to cope with errors.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式系统中，有许多并行运行的参与者，并且事件以任意顺序异步到来。当我们有一个有缺陷的控制器逻辑、略微错误的状态机或外部服务故障时，很容易丢失事件，意味着我们不能完全处理它们。因此，我们必须更深入地研究如何处理错误。
- en: 'In [Figure 1-3](#edge-vs-level-overview) you can see different strategies at
    work:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图1-3](#edge-vs-level-overview) 中，您可以看到不同的工作策略：
- en: An example of an edge-driven-only logic, where potentially the second state
    change is missed.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 边缘驱动逻辑的示例，可能会错过第二次状态变化。
- en: An example of an edge-triggered logic, which always gets the latest state (i.e.,
    level) when processing an event. In other words, the logic is edge-triggered but
    level-driven.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 边缘触发逻辑的示例，在处理事件时总是获取最新状态（即级别）。换句话说，逻辑是边缘触发的，但是级别驱动。
- en: An example of an edge-triggered, level-driven logic with additional resync.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 边缘触发、级别驱动逻辑的示例，附加重新同步。
- en: '![Trigger options (edge vs. level)](assets/prku_0103.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![触发选项（边缘 vs. 级别）](assets/prku_0103.png)'
- en: Figure 1-3\. Trigger options (edge-driven versus level-driven)
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-3\. 触发选项（边缘驱动 vs. 级别驱动）
- en: Strategy 1 does not cope well with missed events, whether because broken networking
    makes it lose events, or because the controller itself has bugs or some external
    cloud API was down. Imagine that the replica set controller would replace pods
    only when they terminate. Missing events would mean that the replica set would
    always run with fewer pods because it never reconciles the whole state.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 策略 1 在处理丢失的事件时表现不佳，无论是因为网络故障导致丢失事件，还是因为控制器本身存在 bug 或某些外部云 API 失效。想象一下，复制集控制器仅在
    pod 终止时才会替换 pods。丢失的事件意味着复制集将始终以更少的 pods 运行，因为它从不调和整个状态。
- en: Strategy 2 recovers from those issues when another event is received because
    it implements its logic based on the latest state in the cluster. In the case
    of the replica set controller, it will always compare the specified replica count
    with the running pods in the cluster. When it loses events, it will replace all
    missing pods the next time a pod update is received.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 策略 2 在接收到另一个事件时从这些问题中恢复，因为它基于集群中的最新状态实现其逻辑。例如，在 replica set 控制器的情况下，它将始终将指定的复制数量与集群中运行的
    pods 进行比较。当丢失事件时，它将在接收到下一个 pod 更新时替换所有丢失的 pods。
- en: Strategy 3 adds continuous resync (e.g., every five minutes). If no pod events
    come in, it will at least reconcile every five minutes, even if the application
    runs very stably and does not lead to many pod events.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 策略 3 增加了持续重新同步（例如，每五分钟一次）。如果没有 pod 事件发生，它至少每五分钟进行一次调和，即使应用程序运行非常稳定，也不会导致多个 pod
    事件。
- en: Given the challenges of pure edge-driven triggers, the Kubernetes controllers
    typically implement the third strategy.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于纯边缘驱动触发器的挑战，Kubernetes 控制器通常实现第三种策略。
- en: If you want to learn more about the origins of the triggers and the motivations
    for level triggering with reconciliation in Kubernetes, read James Bowes’s article,
    [“Level Triggering and Reconciliation in Kubernetes”](http://bit.ly/2FmLLAW).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解触发器的起源以及在 Kubernetes 中使用调和级触发的动机，请阅读 James Bowes 的文章，《[Kubernetes 中的级触发和调和](http://bit.ly/2FmLLAW)》。
- en: This concludes the discussion of the different, abstract ways to detect external
    changes and to react on them. The next step in the control loop of [Figure 1-2](#controller-loop-overview)
    is to change the cluster objects or to change the external world following the
    spec. We’ll look at it now.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了对检测外部变化和对其作出反应的不同抽象方式的讨论。控制循环中 [图 1-2](#controller-loop-overview) 的下一步是更改集群对象或按照规范更改外部世界。我们现在来看一下。
- en: Changing Cluster Objects or the External World
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更改集群对象或外部世界
- en: In this phase, the controller changes the state of the objects it is supervising.
    For example, the `ReplicaSet` controller in the [controller manager](http://bit.ly/2WUAEVy)
    is supervising pods. On each event (edge-triggered), it will observe the current
    state of its pods and compare that with the desired state (level-driven).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在此阶段，控制器更改其监督的对象的状态。例如，在 [控制器管理器](http://bit.ly/2WUAEVy) 中的 ReplicaSet 控制器正在监督
    pods。在每个事件（边缘触发）中，它将观察其 pods 的当前状态，并将其与期望的状态（级别驱动）进行比较。
- en: 'Since the act of changing the resource state is domain- or task-specific, we
    can provide little guidance. Instead, we’ll keep looking at the `ReplicaSet` controller
    we introduced earlier. `ReplicaSet`s are used in deployments, and the bottom line
    of the respective controller is: maintain a user-defined number of identical pod
    replicas. That is, if there are fewer pods than the user specified—for example,
    because a pod died or the replica value has been increased—the controller will
    launch new pods. If, however, there are too many pods, it will select some for
    termination. The entire business logic of the controller is available via [the
    *replica_set.go* package](http://bit.ly/2L4eKxa), and the following excerpt of
    the Go code deals with the state change (edited for clarity):'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于改变资源状态的行为是特定于领域或任务的，我们无法提供太多指导。相反，我们将继续关注我们之前介绍的`ReplicaSet`控制器。`ReplicaSet`在部署中使用，其相应控制器的底线是：维护指定数量的相同Pod副本。也就是说，如果Pod少于用户指定的数量——例如因为某个Pod已经死亡或者复制值已增加——控制器将启动新的Pod。然而，如果Pod过多，它将选择一些Pod进行终止。控制器的整个业务逻辑可通过[*replica_set.go*包](http://bit.ly/2L4eKxa)获得，以下Go代码节选处理了状态变化（已编辑以增强清晰度）：
- en: '[PRE1]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can see that the controller computes the difference between specification
    and current state in the line `diff` `:= len(filteredPods) - int(*(rs.Spec.Replicas))`
    and then implements two cases depending on that:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，控制器在这一行中计算规范和当前状态之间的差异 `diff` `:= len(filteredPods) - int(*(rs.Spec.Replicas))`，然后根据这两种情况实现了两种情况：
- en: '`diff` `<` `0`: Too few replicas; more pods must be created.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diff` `<` `0`: 复本过少；必须创建更多的Pod。'
- en: '`diff` `>` `0`: Too many replicas; pods must be deleted.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diff` `>` `0`: 复本过多；必须删除Pod。'
- en: It also implements a strategy to choose pods where it is least harmful to delete
    them in `getPodsToDelete`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 它还实现了一种策略，选择在`getPodsToDelete`中删除它们最不具有破坏性的Pod。
- en: 'Changing the resource state does not, however, necessarily mean that the resources
    themselves have to be part of the Kubernetes cluster. In other words, a controller
    can change the state of resources that are located outside of Kubernetes, such
    as a cloud storage service. For example, the [AWS Service Operator](http://bit.ly/2ItJcif)
    allows you to manage AWS resources. Among other things, it allows you to manage
    S3 buckets—that is, the S3 controller is supervising a resource (the S3 bucket)
    that exists outside of Kubernetes, and the state changes reflect concrete phases
    in its lifecycle: an S3 bucket is created and at some point deleted.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，改变资源状态并不一定意味着这些资源必须是Kubernetes集群的一部分。换句话说，控制器可以改变位于Kubernetes之外的资源状态，比如云存储服务。例如，[AWS服务操作器](http://bit.ly/2ItJcif)允许你管理AWS资源。除了其他功能外，它允许你管理S3存储桶——也就是说，S3控制器正在监督一个存在于Kubernetes之外的资源（S3存储桶），并且状态变化反映了其生命周期中的具体阶段：一个S3存储桶被创建，最终删除。
- en: This should convince you that with a custom controller you can manage not only
    core resources, like pods, and custom resources, like our `cnat` example, but
    even compute or store resources that exist outside of Kubernetes. This makes controllers
    very flexible and powerful integration mechanisms, providing a unified way to
    use resources across platforms and environments.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该能够让你相信，通过自定义控制器，你不仅可以管理核心资源（如Pods）和自定义资源（如我们的`cnat`示例），甚至可以管理存在于Kubernetes之外的计算或存储资源。这使得控制器成为非常灵活和强大的集成机制，提供了一种统一的方式来跨平台和环境使用资源。
- en: Optimistic Concurrency
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 乐观并发
- en: In [“The Control Loop”](#controller-loop), we discussed in step 3 that a controller—after
    updating cluster objects and/or the external world according to the spec—writes
    the results into the status of the resource that triggered the controller run
    in step 1.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“控制循环”](#controller-loop)中，我们在第3步讨论了一个控制器——在根据规范更新集群对象和/或外部世界之后——将结果写入在第1步触发控制器运行的资源的状态中。
- en: This and actually any other write (also in step 2) can go wrong. In a distributed
    system, this controller is probably only one of many that update resources. Concurrent
    writes can fail because of write conflicts.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这以及实际上任何其他写入（也在第2步中）都可能出错。在分布式系统中，这个控制器可能只是更新资源的众多控制器之一。由于写入冲突，并发写入可能会失败。
- en: To better understand what’s happening, let’s step back a bit and have a look
    at [Figure 1-4](#scheduling-archs).^([2](ch01.html#idm46336867946120))
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解正在发生的情况，让我们退后一步，看看[图1-4](#scheduling-archs)。
- en: '![Scheduling architectures in distributed systems](assets/prku_0104.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![分布式系统中的调度架构](assets/prku_0104.png)'
- en: Figure 1-4\. Scheduling architectures in distributed systems
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. 分布式系统中的调度架构
- en: 'The source defines Omega’s parallel scheduler architecture as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 该源代码将Omega的并行调度器架构定义如下：
- en: Our solution is a new parallel scheduler architecture built around shared state,
    using lock-free optimistic concurrency control, to achieve both implementation
    extensibility and performance scalability. This architecture is being used in
    Omega, Google’s next-generation cluster management system.
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们的解决方案是围绕共享状态构建的新并行调度器架构，使用无锁乐观并发控制，以实现实施的可扩展性和性能的可伸缩性。这种架构正在被用于Omega，Google的下一代集群管理系统。
- en: 'While Kubernetes inherited a lot of traits and lessons learned from [Borg](http://bit.ly/2XNSv5p),
    this specific, transactional control plane feature comes from Omega: in order
    to carry out concurrent operations without locks, the Kubernetes API server uses
    optimistic concurrency.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Kubernetes从[Borg](http://bit.ly/2XNSv5p)继承了许多特性和经验教训，但这种特定的事务控制平面特性来自于Omega：为了在没有锁的情况下执行并发操作，Kubernetes
    API服务器使用乐观并发。
- en: This means, in a nutshell, that if and when the API server detects concurrent
    write attempts, it rejects the latter of the two write operations. It is then
    up to the client (controller, scheduler, `kubectl`, etc.) to handle a conflict
    and potentially retry the write operation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这意味着如果API服务器检测到并发的写入尝试，它将拒绝后面两次写入操作中的后者。然后由客户端（控制器、调度器、`kubectl`等）来处理冲突，并可能重试写入操作。
- en: 'The following demonstrates the idea of optimistic concurrency in Kubernetes:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 以下演示了在Kubernetes中乐观并发的思想：
- en: '[PRE2]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The code shows a retry loop that gets the latest object `foo` in each iteration,
    then tries to update the world and `foo`’s status to match `foo`’s spec. The changes
    done before the `Update` call are optimistic.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 代码展示了一个重试循环，在每次迭代中获取最新的对象`foo`，然后尝试将世界和`foo`的状态更新为匹配`foo`的规范。在`Update`调用之前进行的更改是乐观的。
- en: The returned object `foo` from the `client.Get` call contains a *resource version*
    (part of the embedded `ObjectMeta` struct—see [“ObjectMeta”](ch03.html#ObjectMeta)
    for details), which will tell `etcd` on the write operation behind the `client.Update`
    call that another actor in the cluster wrote the `foo` object in the meantime.
    If that’s the case, our retry loop will get a *resource version conflict error*.
    This means that the optimistic concurrency logic failed. In other words, the `client.Update`
    call is also optimistic.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 从`client.Get`调用返回的对象`foo`包含一个*资源版本*（嵌入`ObjectMeta`结构体中—请参阅[“ObjectMeta”](ch03.html#ObjectMeta)了解详细信息），这将告诉`etcd`在`client.Update`调用后的写操作时，集群中的另一个参与者写入了`foo`对象。如果是这种情况，我们的重试循环将会遇到*资源版本冲突错误*。这意味着乐观并发逻辑失败了。换句话说，`client.Update`调用也是乐观的。
- en: Note
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The resource version is actually the `etcd` key/value version. The resource
    version of each object is a string in Kubernetes that contains an integer. This
    integer comes directly from `etcd`. `etcd` maintains a counter that increases
    each time the value of a key (which holds the object’s serialization) is modified.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 资源版本实际上是`etcd`的键/值版本。每个对象的资源版本在Kubernetes中是一个包含整数的字符串。这个整数直接来自于`etcd`。`etcd`维护一个计数器，每当修改保存对象序列化的键的值时，该计数器都会增加。
- en: Throughout the API machinery code the resource version is (more or less consequently)
    handled like an arbitrary string, but with some ordering on it. The fact that
    integers are stored is just an implementation detail of the current `etcd` storage
    backend.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个API机制代码中，资源版本（更或多或少地）像是一个任意字符串进行处理，但其中有些排序规则。整数存储的事实仅仅是当前`etcd`存储后端的实现细节。
- en: 'Let’s look at a concrete example. Imagine your client is not the only actor
    in the cluster that modifies a pod. There is another actor, namely the `kubelet`,
    that constantly modifies some fields because a container is constantly crashing.
    Now your controller reads the pod object’s latest state like so:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个具体的例子。想象一下，您的客户端不是唯一一个修改pod的集群中的参与者。还有另一个参与者，即`kubelet`，因为容器不断崩溃，它会不断修改某些字段。现在，您的控制器像这样读取pod对象的最新状态：
- en: '[PRE3]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now assume the controller needs several seconds with its updates to the world.
    Seven seconds later, it tries to update the pod it read—for example, it sets an
    annotation. Meanwhile, the `kubelet` has noticed yet another container restart
    and updated the pod’s status to reflect that; that is, `resourceVersion` has increased
    to 58.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设控制器需要几秒钟来更新其对世界的更新。七秒钟后，它尝试更新它读取的pod——例如，设置一个注释。与此同时，`kubelet`注意到另一个容器重新启动并更新了pod的状态以反映这一情况；即`resourceVersion`已增加到58。
- en: 'The object your controller sends in the update request has `resourceVersion:
    57`. The API server tries to set the `etcd` key for the pod with that value. `etcd`
    notices that the resource versions do not match and reports back that 57 conflicts
    with 58\. The update fails.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '您的控制器发送的更新请求中的对象具有`resourceVersion: 57`。API服务器尝试使用该值设置该pod的`etcd`键。`etcd`注意到资源版本不匹配，并报告说57与58冲突。更新失败。'
- en: The bottom line of this example is that for your controller, you are responsible
    for implementing a retry strategy and for adapting if an optimistic operation
    failed. You never know who else might be manipulating state, whether other custom
    controllers or core controllers such as the deployment controller.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子的要点是，对于您的控制器，您需要负责实施重试策略，并适应如果乐观操作失败的情况。您永远不知道谁还在操作状态，无论是其他自定义控制器还是诸如部署控制器之类的核心控制器。
- en: 'The essence of this is: *conflict errors are totally normal in controllers.
    Always expect them and handle them gracefully*.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这的精髓是：*在控制器中冲突错误是完全正常的。始终预期它们并优雅地处理它们*。
- en: It’s important to point out that optimistic concurrency is a perfect fit for
    level-based logic, because by using level-based logic you can just rerun the control
    loop (see [“Edge- Versus Level-Driven Triggers”](#edge-vs-level)). Another run
    of that loop will automatically undo optimistic changes from the previous failed
    optimistic attempt, and it will try to update the world to the latest state.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 乐观并发控制在基于级别逻辑上非常合适，因为通过使用级别逻辑，您可以简单地重新运行控制循环（参见[“边缘驱动触发器与级别驱动触发器”](#edge-vs-level)）。该循环的另一次运行将自动撤销先前失败的乐观尝试所做的更改，并尝试将世界更新到最新状态。
- en: 'Let’s move on to a specific case of custom controllers (along with custom resources):
    the operator.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论定制控制器（以及定制资源）的具体案例：操作器。
- en: Operators
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作器
- en: 'Operators as a concept in Kubernetes were introduced by CoreOS in 2016\. In
    his seminal blog post, [“Introducing Operators: Putting Operational Knowledge
    into Software”](http://bit.ly/2ZC4Rui), CoreOS CTO Brandon Philips defined operators
    as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes中的操作器的概念由CoreOS在2016年引入。在他的重要博文中，[“介绍操作器：将操作知识编入软件”](http://bit.ly/2ZC4Rui)，CoreOS的CTO
    Brandon Philips这样定义操作器：
- en: A Site Reliability Engineer (SRE) is a person [who] operates an application
    by writing software. They are an engineer, a developer, who knows how to develop
    software specifically for a particular application domain. The resulting piece
    of software has an application’s operational domain knowledge programmed into
    it.
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 网站可靠性工程师（SRE）是一个通过编写软件来操作应用程序的人。他们是一位工程师、开发人员，了解如何专门为特定应用程序领域开发软件。结果产生的软件将应用程序的操作领域知识编程其中。
- en: ''
  id: totrans-146
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[…]'
  id: totrans-147
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[…]'
- en: ''
  id: totrans-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We call this new class of software Operators. An Operator is an application-specific
    controller that extends the Kubernetes API to create, configure, and manage instances
    of complex stateful applications on behalf of a Kubernetes user. It builds upon
    the basic Kubernetes resource and controller concepts but includes domain or application-specific
    knowledge to automate common tasks.
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们称这种新型软件类为操作器。操作器是一种特定于应用程序的控制器，通过扩展Kubernetes API代表Kubernetes用户创建、配置和管理复杂状态应用程序的实例。它基于基本的Kubernetes资源和控制器概念，但包括领域或应用程序特定的知识，以自动化常见任务。
- en: 'In the context of this book, we will use operators as Philips describes them
    and, more formally, require that the following three conditions hold (see also
    [Figure 1-5](#operator-conceptual)):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的背景下，我们将使用Philips所描述的操作器，并更正式地要求满足以下三个条件（另见[图1-5](#operator-conceptual)）：
- en: There’s some domain-specific operational knowledge you’d like to automate.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一些特定领域的操作知识您想要自动化。
- en: The best practices for this operational knowledge are known and can be made
    explicit—for example, in the case of a Cassandra operator, when and how to re-balance
    nodes, or in the case of an operator for a service mesh, how to create a route.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于这些运营知识的最佳实践已被公认，并可以明确说明，例如在Cassandra操作员的情况下，何时以及如何重新平衡节点，或者在服务网格的操作员的情况下，如何创建路由。
- en: 'The artifacts shipped in the context of the operator are:'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作员在运算符的上下文中运送的工件有：
- en: A set of *custom resource definitions* (CRDs) capturing the domain-specific
    schema and custom resources following the CRDs that, on the instance level, represent
    the domain of interest.
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组*自定义资源定义*（CRD），捕获特定领域的模式和遵循这些CRD的自定义资源，在实例级别上代表感兴趣的领域。
- en: A custom controller, supervising the custom resources, potentially along with
    core resources. For example, the custom controller might spin up a pod.
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义控制器负责管理自定义资源，可能还包括核心资源。例如，自定义控制器可以启动一个 pod。
- en: '![The concept of an operator](assets/prku_0105.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![操作员的概念](assets/prku_0105.png)'
- en: Figure 1-5\. The concept of an operator
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5\. 操作员的概念
- en: Operators have [come a long way](http://bit.ly/2x5TSNw) from the conceptual
    work and prototyping in 2016 to the launch of [OperatorHub.io](https://operatorhub.io)
    by Red Hat (which acquired CoreOS in 2018 and continued to build out the idea)
    in early 2019\. See [Figure 1-6](#operatorhub) for a screenshot of the hub in
    mid-2019 sporting some 17 operators, ready to be used.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 操作员已经从2016年的概念工作和原型设计发展到了2019年初由红帽（2018年收购CoreOS并继续推动这一理念）推出的[OperatorHub.io](https://operatorhub.io)。请见[图 1-6](#operatorhub)，显示了2019年中期的这个中心截图，展示了大约17个可以使用的操作员。
- en: '![OperatorHub.io screen shot](assets/prku_0106.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![OperatorHub.io 的截图](assets/prku_0106.png)'
- en: Figure 1-6\. OperatorHub.io screenshot
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6\. OperatorHub.io 截图
- en: Summary
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this first chapter we defined the scope of our book and what we expect from
    you. We explained what we mean by programming Kubernetes and defined Kubernetes-native
    apps in the context of this book. As preparation for later examples, we also provided
    a high-level introduction to controllers and operators.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第一章中，我们定义了书籍的范围及对您的期望。我们解释了在本书背景下什么是编程 Kubernetes，并在为后续示例做准备时，还提供了对控制器和操作员的高级介绍。
- en: So, now that you know what to expect from the book and how you can benefit from
    it, let’s jump into the deep end. In the next chapter, we’ll take a closer look
    at the Kubernetes API, the API server’s inner workings, and how you can interact
    with the API using command-line tools such as `curl`.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了本书的预期和您可以从中获益的方式，让我们深入研究。在下一章中，我们将更详细地了解 Kubernetes API，API 服务器的内部工作原理，以及如何使用诸如`curl`等命令行工具与
    API 进行交互。
- en: ^([1](ch01.html#idm46336877072840-marker)) For more on this topic, see Megan
    O’Keefe’s [“A Kubernetes Developer Workflow for MacOS”](http://bit.ly/2WXfzu1),
    *Medium*, January 24, 2019; and Alex Ellis’s blog post, [“Be KinD to yourself”](http://bit.ly/2XkK9C1),
    December 14, 2018.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.html#idm46336877072840-marker)) 欲了解更多相关主题，请参阅Megan O’Keefe的[“A Kubernetes
    Developer Workflow for MacOS”](http://bit.ly/2WXfzu1)，*Medium*，2019年1月24日；以及Alex
    Ellis的博客文章，[“Be KinD to yourself”](http://bit.ly/2XkK9C1)，2018年12月14日。
- en: '^([2](ch01.html#idm46336867946120-marker)) Source: [“Omega: Flexible, Scalable
    Schedulers for Large Compute Clusters”](http://bit.ly/2PjYZ59), by Malte Schwarzkopf
    et al., Google AI, 2013.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '^([2](ch01.html#idm46336867946120-marker)) 来源：由Malte Schwarzkopf等人在2013年Google
    AI发表的文章[“Omega: Flexible, Scalable Schedulers for Large Compute Clusters”](http://bit.ly/2PjYZ59)。'
