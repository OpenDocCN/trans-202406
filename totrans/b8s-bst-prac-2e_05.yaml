- en: Chapter 5\. Continuous Integration, Testing, and Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we look at the key concepts of how to integrate a continuous
    integration/continuous deployment (CI/CD) pipeline to deliver your applications
    to Kubernetes. Building a well-integrated pipeline will enable you to deliver
    applications to production with confidence, so here we look at the methods, tools,
    and processes to enable CI/CD in your environment. The goal of CI/CD is to have
    a fully automated process, from a developer checking in code to rolling out the
    new code to production. You want to avoid manually rolling out updates to your
    apps deployed to Kubernetes because it can be very error prone. Manually managing
    application updates in Kubernetes leads to configuration drift and fragile deployment
    updates, and overall agility delivering an application is lost.
  prefs: []
  type: TYPE_NORMAL
- en: 'We cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Version control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container builds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container image tagging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing in production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chaos testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We also go through an example CI/CD pipeline, which consists of the following
    tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Pushing code changes to the Git repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a build of the application code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running test against the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a container image on a successful test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pushing the container image to a container registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the application to Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a test against a deployed application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing rolling upgrades on Deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Version Control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every CI/CD pipeline starts with version control, which maintains a running
    history of application and configuration code changes. Git has become the industry
    standard as a source-control management platform, and every Git repository will
    contain a *main branch*. A main branch contains your production code. You will
    have other branches for feature and development work that eventually will be merged
    to your main branch. There are many ways to set up a branching strategy, and the
    setup will be very dependent on the organization structure and separation of duties.
    We find that including both application code and configuration code, such as a
    Kubernetes manifest or Helm charts, helps promote good DevOps principles of communication
    and collaboration. Having both application developers and operation engineers
    collaborate in a single repository builds confidence in a team to deliver an application
    to production.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CI is the process of integrating code changes continuously into a version-control
    repository. Instead of committing large changes less often, you commit smaller
    changes more often. Each time a code change is committed to the repository, a
    build is kicked off. This allows you to have a quicker feedback loop into what
    might have broken the application if problems indeed arise. Many solutions provide
    CI, with Jenkins being one of the more popular tools. At this point you might
    be asking, “Why do I need to know about how the application is built; isn’t that
    the application developer’s role?” Traditionally, this might have been the case,
    but as companies move toward embracing a DevOps culture, the operations team comes
    closer to the application code and software development workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of running tests in the pipeline is to quickly provide a feedback loop
    for code changes that break the build. The language that you’re using will determine
    the testing framework you use. For example, Go applications can use `go test`
    for running a suite of unit tests against your code base. Having an extensive
    test suite helps to avoid delivering bad code into your production environment.
    You’ll want to ensure that if tests fail in the pipeline, the build fails after
    the test suite runs. You don’t want to build the container image and push it to
    a registry if you have failing tests against your code base.
  prefs: []
  type: TYPE_NORMAL
- en: Again, you might be asking, “Isn’t creating tests a developer’s job?” As you
    begin automating the delivery of infrastructure and applications to production,
    you need to think about running automated tests against all of the pieces of the
    code base. For example, in [Chapter 2](ch02.html#developer_workflows), we talked
    about using Helm to package applications for Kubernetes. Helm includes a tool
    called `helm lint`, which runs a series of tests against a chart to examine any
    potential issues with the chart provided. Many different tests need to be run
    in an end-to-end pipeline. Some are the developer’s responsibility, like unit
    testing for the application, but others, like smoke testing, will be a joint effort.
    Testing the code base and its delivery to production is a team effort and needs
    to be implemented end to end.
  prefs: []
  type: TYPE_NORMAL
- en: Container Builds
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When building your images, you should optimize the size of the image. Having
    a smaller image decreases the time it takes to pull and deploy the image, and
    also increases the security of the image. There are multiple ways of optimizing
    the image size, but some do have trade-offs. The following strategies will help
    you build the smallest image possible for your application:'
  prefs: []
  type: TYPE_NORMAL
- en: Multistage builds
  prefs: []
  type: TYPE_NORMAL
- en: These allow you to remove the dependencies not needed for your applications
    to run. For example, with Golang, we don’t need all the build tools used to build
    the static binary, so multistage builds allow you to run a build step in a single
    Dockerfile with the final image containing only the static binary that’s needed
    to run the application.
  prefs: []
  type: TYPE_NORMAL
- en: Distroless base images
  prefs: []
  type: TYPE_NORMAL
- en: These remove all the unneeded binaries and shells from the image. This reduces
    the size of the image and increases the security. The trade-off with distroless
    images is you don’t have a shell, so you can’t attach a debugger to the image.
    You might think this is great, but it can be a pain to debug an application. Distroless
    images contain no package manager, shell, or other typical OS packages, so you
    might not have access to the debugging tools you are accustomed to with a typical
    OS.
  prefs: []
  type: TYPE_NORMAL
- en: Optimized base images
  prefs: []
  type: TYPE_NORMAL
- en: These are images that focus on removing the cruft out of the OS layer and provide
    a slimmed-down image. For example, Alpine provides a base image that starts at
    just 10 MB, and it allows you to attach a local debugger for local development.
    Other distros also typically offer an optimized base image, such as Debian’s Slim
    image. This might be a good option for you because its optimized images give you
    the capabilities you expect for development while also optimizing for image size
    and lower security exposure.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing your images is extremely important and often overlooked by users.
    You might have obstacles due to company standards for OSes that are approved for
    use in the enterprise, but push back on these so that you can maximize the value
    of containers.
  prefs: []
  type: TYPE_NORMAL
- en: We have found that companies starting out with Kubernetes tend to be successful
    with initially using their current OS but then choose a more optimized image,
    like Debian Slim. After you mature in operationalizing and developing against
    a container environment, you’ll be comfortable with distroless images.
  prefs: []
  type: TYPE_NORMAL
- en: Container Image Tagging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another step in the CI pipeline is to build a container image so that you have
    an image artifact to deploy to an environment. It’s important to have an image-tagging
    strategy so that you can easily identify the versioned images you have deployed
    to your environments. We can’t preach enough about one of the most important things:
    do not use “latest” as an image tag. Using that as an image tag is not a *version*
    and will lead to not having the ability to identify what code change belongs to
    the rolled-out image. Every image that is built in the CI pipeline should have
    a unique tag.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple strategies we’ve found to be effective when tagging images
    in the CI pipeline. The following strategies allow you to easily identify the
    code changes and the build with which they are associated:'
  prefs: []
  type: TYPE_NORMAL
- en: BuildID
  prefs: []
  type: TYPE_NORMAL
- en: When a CI build kicks off, it has a buildID associated with it. Using this part
    of the tag allows you to reference which build assembled the image.
  prefs: []
  type: TYPE_NORMAL
- en: Build System-buildID
  prefs: []
  type: TYPE_NORMAL
- en: This tag is the same as BuildID but adds the Build System for users who have
    multiple build systems.
  prefs: []
  type: TYPE_NORMAL
- en: Git hash
  prefs: []
  type: TYPE_NORMAL
- en: On new code commits, a Git hash is generated, and using the hash for the tag
    allows you to easily reference which commit generated the image.
  prefs: []
  type: TYPE_NORMAL
- en: githash-buildID
  prefs: []
  type: TYPE_NORMAL
- en: This allows you to reference both the code commit and the buildID that generated
    the image. The only caution here is that the tag can be kind of long.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CD is the process by which changes that have passed successfully through the
    CI pipeline are deployed to production without human intervention. Containers
    provide a great advantage for deploying changes into production. Container images
    become an immutable object that can be promoted through dev and staging and into
    production. For example, a major issue we’ve always had has been maintaining consistent
    environments. Almost everyone has experienced a Deployment that works fine in
    staging, but when it gets promoted to production, it breaks. This is due to having
    *configuration drift*, with libraries and versioning of components differing in
    each environment. Kubernetes gives us a declarative way to describe our Deployment
    objects that can be versioned and deployed consistently.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to keep in mind is that you need a solid CI pipeline set up before
    focusing on CD. If you don’t have a robust set of tests to catch issues early
    in the pipeline, you’ll end up rolling bad code to all your environments.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment Strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we learned the principles of CD, let’s look at the different rollout
    strategies you can use. Kubernetes provides multiple strategies to roll out new
    versions of your application. And even though it has a built-in mechanism to provide
    rolling updates, you can also utilize more advanced strategies. Here, we examine
    the following strategies to deliver updates to your application:'
  prefs: []
  type: TYPE_NORMAL
- en: Rolling updates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blue/green deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canary deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Rolling updates* are built into Kubernetes and allow you to trigger an update
    to the currently running application without downtime. For example, if you took
    your frontend app that is currently running frontend:v1 and updated the Deployment
    to frontend:v2, Kubernetes would update the replicas in a rolling fashion to frontend:v2\.
    [Figure 5-1](#rolling_update) depicts a rolling update.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A Kubernetes rolling update](assets/kbp2_0501.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-1\. A Kubernetes rolling update
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'A Deployment object also lets you configure the maximum amount of replicas
    to be updated and the maximum unavailable pods during the rollout. The following
    manifest is an example of how you specify the rolling update strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You need to be cautious with rolling updates because using this strategy can
    cause dropped connections. To deal with this issue, you can utilize *readiness
    probes* and *preStop* life-cycle hooks. The readiness probe ensures that the new
    version deployed is ready to accept traffic, whereas the preStop hook can ensure
    that connections are drained on the current deployed application. The life-cycle
    hook is called before the container exits and is synchronous, so it must complete
    before the final termination signal is given. The following example implements
    a readiness probe and life-cycle hook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The preStop life-cycle hook in this example will gracefully exit NGINX, whereas
    a SIGTERM conducts a nongraceful, quick exit.
  prefs: []
  type: TYPE_NORMAL
- en: Another concern with rolling updates is that you now have two versions of the
    application running at the same time during the rollover. Your database schema
    needs to support both versions of the application. You can also use a feature
    flag strategy in which your schema indicates the new columns created by the new
    app version. After the rolling update has completed, the old columns can be removed.
  prefs: []
  type: TYPE_NORMAL
- en: We have also defined a readiness and liveness probe in our Deployment manifest.
    A readiness probe will ensure that your application is ready to serve traffic
    before putting it behind the service as an endpoint. The liveness probe ensures
    that your application is healthy and running, and it restarts the pod if it fails
    its liveness probe. Kubernetes can automatically restart a failed pod only if
    the pod exits on error. For example, the liveness probe can check its endpoint
    and restart it if we had a deadlock from which the pod did not exit.
  prefs: []
  type: TYPE_NORMAL
- en: '*Blue/green deployments* allow you to release your application predictably.
    With blue/green deployments, you control when the traffic is shifted over to the
    new environment, so it gives you a lot of control over the rollout of a new version
    of your application. With blue/green deployments, you are required to have the
    capacity to deploy both the existing and new environment at the same time. These
    types of deployments have a lot of advantages, such as easily switching back to
    your previous version of the application. There are some things that you need
    to consider with this deployment strategy, however:'
  prefs: []
  type: TYPE_NORMAL
- en: Database migrations can become difficult with this deployment option because
    you need to consider in-flight transactions and schema update compatibility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is the risk of accidental deletion of both environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need extra capacity for both environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are coordination issues for hybrid deployments in which legacy apps can’t
    handle the deployment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 5-2](#blue_green_deployment) depicts a blue/green deployment.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A blue/green deployment](assets/kbp2_0502.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-2\. A blue/green deployment
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '*Canary deployments* are very similar to blue/green deployments, but they give
    you much more control over shifting traffic to the new release. Most modern Ingress
    implementations will give you the ability to release a percentage of traffic to
    a new release, but you can also implement a service mesh technology, like Istio,
    Linkerd, or HashiCorp Consul, which gives you a number of features that help implement
    this deployment strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: Canary deployments allow you to test new features for only a subset of users.
    For example, you might roll out a new version of an application and want to test
    the deployment for only 10% of your user base. This allows you to reduce the risk
    of a bad deployment or broken features to a much smaller subset of users. If there
    are no errors with the deployment or new features, you can begin shifting a greater
    percentage of traffic to the new version of the application. There are also more
    advanced techniques that you can use with canary deployments in which you release
    to only a specific region of users or only target users with a specific profile.
    These types of releases are often referred to as A/B or dark releases because
    users are unaware they are testing new feature deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'With canary deployments, you have some of the same considerations that you
    have with blue/green deployments, but there are some additional considerations
    as well. You must have:'
  prefs: []
  type: TYPE_NORMAL
- en: The ability to shift traffic to a percentage of users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A firm knowledge of steady state to compare against a new release
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics to understand whether the new release is in a “good” or “bad” state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 5-3](#canary_development) provides an example of a canary deployment.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A canary deployment](assets/kbp2_0503.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-3\. A canary deployment
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Canary releases also suffer from having multiple versions of the application
    running at the same time. Your database schema needs to support both versions
    of the application. When using these strategies, you’ll need to focus on how to
    handle dependent services and having multiple versions running. This includes
    having strong API contracts and ensuring that your data services support the multiple
    versions you have deployed at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Testing in Production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing in production helps you to build confidence in the resiliency, scalability,
    and UX of your application. This comes with the caveat that *testing in production*
    doesn’t come without challenges and risk, but it’s worth the effort to ensure
    reliability in your systems. There are important aspects you need to address up
    front when embarking on the implementation. You need to ensure that you have an
    in-depth observability strategy in place, in which you have the ability to identify
    the effects of testing in production. Without being able to observe metrics that
    affect the end users’ experience of your applications, you won’t have a clear
    indication of what to focus on when trying to improve the resiliency of your system.
    You also need a high degree of automation in place to be able to automatically
    recover from failures that you inject into your systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll need to implement many tools to reduce risk and effectively test your
    systems when they’re in production. We have discussed some tools in this chapter,
    but there are some new ones, like distributed tracing, instrumentation, chaos
    engineering, and traffic shadowing. To recap, here are the tools we have already
    mentioned:'
  prefs: []
  type: TYPE_NORMAL
- en: Canary deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blue/green deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traffic shifting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature flags
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chaos engineering was developed by Netflix. It is the practice of deploying
    experiments into live production systems to discover weaknesses within those systems.
    Chaos engineering allows you to learn about the behavior of your system by observing
    it during a controlled experiment. Following are the steps that you want to implement
    before doing a “game-day” experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: Build a hypothesis and learn about your steady state.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Have a varying degree of real-world events that can affect the system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a control group and experiment to compare to steady state.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform experiments to test the hypothesis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It’s extremely important that when you’re running experiments, you minimize
    the “blast radius” to ensure that the issues that might arise are minimal. You’ll
    also want to ensure that when you’re building experiments, you focus on automating
    them, given that running experiments can be labor intensive.
  prefs: []
  type: TYPE_NORMAL
- en: 'By this point, you might be asking, “Why wouldn’t I just test in staging?”
    We find there are some inherent problems when testing in staging, such as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Nonidentical deployment of resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration drift from production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traffic and user behavior tend to be generated synthetically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of requests generated don’t mimic a real workload.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of monitoring implemented in staging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data services deployed contain differing data and load than in production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can’t stress this enough: ensure that you have solid confidence in the monitoring
    you have in place for production, because this practice tends to fail users who
    don’t have adequate observability of their production systems. Also, starting
    with smaller experiments to first learn about your experiments and their effects
    will help build confidence.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up a Pipeline and Performing a Chaos Experiment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step in the process is to fork a GitHub repository so that you can
    have your own repository to use throughout the chapter. You will need to use the
    GitHub interface to fork the [sample application repository](https://oreil.ly/TtJfd).
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up CI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you have learned about CI, you will set up a build of the code that
    we cloned previously.
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we use the hosted *drone.io*. You’ll need to [sign up for
    a free account](https://cloud.drone.io). Log in with your GitHub credentials (this
    registers your repositories in Drone and allows you to synchronize the repositories).
    After you’re logged in to Drone, select Activate on your forked repository. The
    first thing that you need to do is add some secrets to your settings so that you
    can push the app to your Docker Hub registry and also deploy the app to your Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Under your repository in Drone, click Settings and add the following secrets
    (see [Figure 5-4](#fig0504)):'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker_username`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker_password`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubernetes_server`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubernetes_cert`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubernetes_token`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Drone secrets configuration](assets/kbp2_0504.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-4\. Drone secrets configuration
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The Docker username and password will be whatever you used to register on Docker
    Hub. The following steps show how to create a Kubernetes service account and certificate
    and retrieve the token.
  prefs: []
  type: TYPE_NORMAL
- en: For the Kubernetes server, you will need a publicly available Kubernetes API
    endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You will need cluster-admin privileges on your Kubernetes cluster to perform
    the steps in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can retrieve your API endpoint by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see something like the following: Kubernetes master is running at
    https://kbp.centralus.azmk8s.io:443\. You’ll store this in the `kubernetes_server`
    secret.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s create a service account that Drone will use to connect to the cluster.
    Use the following command to create the `serviceaccount`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, use the following command to create a `clusterrolebinding` for the `service​ac⁠count`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now retrieve your `serviceaccount` token:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You’ll want to store the output of the token in the `kubernetes_token` secret.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will also need the user certificate to authenticate to the cluster, so
    use the following command and paste the `ca.crt` for the `kubernetes_cert` secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now, build your app in a Drone pipeline and then push it to Docker Hub.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is the *build step*, which will build your Node.js frontend.
    Drone utilizes container images to run its steps, which gives you a lot of flexibility
    in what you can do with it. For the build step, use a Node.js image from Docker
    Hub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'When the build completes, you’ll want to test it, so we include a *test step*,
    which will run `npm` against the newly built app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have successfully built and tested your app, you will move on to
    a *publish step* to create a container image of the app and push it to Docker
    Hub.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *.drone.yml* file, make the following code change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: After the Docker build step finishes, it will push the image to your Docker
    registry.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up CD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the deployment step in your pipeline, you will push your application to
    your Kubernetes cluster. You will use the deployment manifest that is under the
    frontend app folder in your repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After the pipeline finishes its deployment, you will see the pods running in
    your cluster. Run the following command to confirm that the pods are running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also add a test step that will retrieve the status of the deployment
    by adding the following step in your Drone pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Performing a Rolling Upgrade
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s demonstrate a rolling upgrade by changing a line in the frontend code.
    In the *server.js* file, change the following line and then commit the change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: You will see the deployment rolling out and rolling updates happening to the
    existing pods. After the rolling update finishes, you’ll have the new version
    of the application deployed.
  prefs: []
  type: TYPE_NORMAL
- en: A Simple Chaos Experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A variety of tools in the Kubernetes ecosystem can help with performing chaos
    experiments in your environment. They range from sophisticated hosted Chaos as
    a Service solutions to basic chaos experiment tools that kill pods in your environment.
    Following are some of the successful tools:'
  prefs: []
  type: TYPE_NORMAL
- en: Gremlin
  prefs: []
  type: TYPE_NORMAL
- en: Hosted chaos service that provides advanced features for running chaos experiments
  prefs: []
  type: TYPE_NORMAL
- en: PowerfulSeal
  prefs: []
  type: TYPE_NORMAL
- en: Open source project that provides advanced chaos scenarios
  prefs: []
  type: TYPE_NORMAL
- en: Chaos Toolkit
  prefs: []
  type: TYPE_NORMAL
- en: Open source project with a mission to provide a free, open, and community-driven
    toolkit and API to all the various forms of chaos engineering tools
  prefs: []
  type: TYPE_NORMAL
- en: KubeMonkey
  prefs: []
  type: TYPE_NORMAL
- en: Open source tool that provides basic resiliency testing for pods in your cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s set up a quick chaos experiment to test the resiliency of your application
    by automatically terminating pods. For this experiment, we’ll use Chaos Toolkit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Best Practices for CI/CD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Your CI/CD pipeline won’t be perfect on day one, but consider some of the following
    best practices to iteratively improve on the pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: With CI, focus on automation and providing quick builds. Optimizing the build
    speed will provide developers quick feedback if their changes have broken the
    build.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on providing reliable tests in your pipeline. This will give developers
    rapid feedback on issues with their code. The faster the feedback loop to developers,
    the more productive they’ll become in their workflow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When deciding on CI/CD tools, ensure that the tools allow you to define the
    pipeline as code. This will allow you to version-control the pipeline with your
    application code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that you optimize your images so that you can reduce the size of the
    image and also reduce the attack surface when running the image in production.
    Multistage Docker builds allow you to remove packages not needed for the application
    to run. For example, you might need Maven to build the application, but you don’t
    need it for the actual running image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid using “latest” as an image tag, and utilize a *tag* that can be referenced
    back to the buildID or Git commit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are new to CD, utilize Kubernetes rolling updates to start. They are
    easy to use and will get you comfortable with deployment. As you become more comfortable
    and confident with CD, look at utilizing blue/green and canary deployment strategies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With CD, ensure that you test how client connections and database schema upgrades
    are handled in your application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing in production will help you build reliability into your application
    and ensure that you have good monitoring in place. With testing in production,
    also start at a small scale and limit the blast radius of the experiment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the stages of building a CI/CD pipeline for your
    applications, which let you reliably deliver software with confidence. CI/CD pipelines
    help reduce risk and increase throughput of delivering applications to Kubernetes.
    We also discussed the different deployment strategies that can be utilized for
    delivering applications.
  prefs: []
  type: TYPE_NORMAL
