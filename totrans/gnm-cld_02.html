<html><head></head><body><div id="sbo-rt-content"><section class="pagenumrestart" data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 1. Introduction"><div class="chapter" id="introduction">
<h1><span class="label">Chapter 1. </span>Introduction</h1>

<p>We live in a time of great opportunity: technological advances are making it possible to generate incredibly detailed and comprehensive data about everything, from the sequence of our entire genomes to the patterns of gene expression of individual cells. Not only can we generate this type of data, we can generate a <em>lot of it</em>.</p>

<p>Over the past 10 years, we’ve seen a stunning growth<a contenteditable="false" data-primary="data (sequencing), growth in amount of" data-type="indexterm" id="idm45625635888920"/> in the amount of sequencing data produced worldwide, enabled by a huge reduction in cost of short read sequencing, a technology that we explore in <a data-type="xref" href="ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new">Chapter 2</a> (<a data-type="xref" href="#aright_parenthesis_projected_growth_of">Figure 1-1</a>). Recently developed and up-and-coming technologies like long-read sequencing<a contenteditable="false" data-primary="long-read sequencing" data-type="indexterm" id="idm45625635885528"/> and<a contenteditable="false" data-primary="single-cell transcriptomics" data-type="indexterm" id="idm45625635884328"/> single-cell transcriptomics promise a future filled with similar transformative drops in costs and greater access to ’omics experimental designs than ever before.</p>

<figure><div id="aright_parenthesis_projected_growth_of" class="figure"><img alt="A) Projected growth of datasets; B) growth in data production at the Broad Institute." src="Images/gitc_0101.png" width="1440" height="1451"/>
<h6><span class="label">Figure 1-1. </span>Recorded growth of sequencing datasets up to 2015 and projected growth for the next decade (top); growth in data production at the Broad Institute (bottom).<sup><a data-type="noteref" id="idm45625635881160-marker" href="ch01.xhtml#idm45625635881160">1</a></sup></h6>
</div></figure>

<section class="pagebreak-before" data-type="sect1" data-pdf-bookmark="The Promises and Challenges of Big Data in Biology and Life Sciences"><div class="sect1" id="the_promises_and_challenges_of_big_data">
<h1 class="less_space">The Promises and Challenges of Big Data in Biology and Life Sciences</h1>

<p>Anyone, from individual labs to large-scale institutions, will soon be able to generate enormous amounts of data. As of this writing, projects that are considered large include whole genome sequences for hundreds of thousands of genomes. Over the next decade, we can expect to see projects sequencing millions of genomes and transcriptomes, complemented (and complicated) by a wide variety of new data types such as advanced cell imaging and proteomics. The promise is that the copious amounts of data and variety of new data types will allow researchers to get closer to answering some of the most difficult—if vexingly simple to ask—questions in biology. For example, how many cell types exist in the human body? What genetic variants cause disease? How do cancers arise, and can we predict them earlier? Because research is by its nature a team sport, we’ll want to broadly share much of the data on the horizon, we’ll want to share our algorithms to analyze this data, and we’ll want to share the findings with the wider world.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Infrastructure Challenges"><div class="sect1" id="infrastructure_challenges">
<h1>Infrastructure Challenges</h1>

<p>The dual opportunities of falling costs and expanded experimental designs available to researchers come with their own set of challenges. <a contenteditable="false" data-primary="infrastructure challenges" data-type="indexterm" id="ix_infch"/>It’s not easy being on the bleeding edge, and each new technology comes with its own complications. How do you accurately read single bases correctly as they whip on by through a nanopore? How do you image live cells in 3D without frying them? How do you compare one lab’s single-cell expression data with another lab’s while correcting for differences from batch effects? These are just a few examples in a very long list of technical challenges we face when developing or optimizing a new experimental design.</p>

<p>But the difficulty doesn’t stop with the data generation; if anything, that’s only the beginning. When the experiments are done and you have the data in hand, you have a whole new world of complexity to reckon with. Indeed, one of the most challenging aspects of ’omics research is determining how to deal with the data after it’s generated. When your imaging study produces a terabyte of data per experiment, where do you store the images to make them accessible? When your whole genome sequencing study produces a complex mixture of clinical and phenotypic data along with the sequence data, how do you organize this data to make it findable, both within your own group and to the wider research community when you publish it? When you need to update your methodology to use the latest version of the analysis software on more than 100,000 samples, how will you scale up your analysis? How can you ensure that your analytical techniques will work properly in different environments, across different platforms and organizations? And how can you make sure your methods can be reproduced by life scientists who have little to no formal training in <span class="keep-together">computing?</span></p>

<p>In this book, we show you how to use the <em>public cloud</em>—computational services made available on demand over the internet—to address some of these fundamental infrastructure challenges. But first, let’s talk about why we think the cloud is a particularly appealing solution and identify some of the limitations that might apply.</p>

<p>This is not meant to be an exhaustive inventory of all available options; much like the landscape of experimental designs is highly varied, there are many ways to use the cloud in research.<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-type="indexterm" id="idm45625635868056"/> Instead, this book focuses on taking advantage of widely used tools and methods that include the Best Practice genomics workflows provided by the <a href="https://oreil.ly/6J8y5">Genome Analysis Toolkit</a> (GATK) (<a data-type="xref" href="#gatk_provides_a_series_of_best_practice">Figure 1-2</a>), implemented using the <a href="https://openwdl.org">Workflow Description Language</a> (WDL), which can be run on any of the platform types commonly used in research computing.<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-type="indexterm" id="idm45625635864104"/><a contenteditable="false" data-primary="Google Cloud Platform (GCP)" data-type="indexterm" id="idm45625635862968"/> We show you how to use them in <a href="https://cloud.google.com">Google Cloud Platform (GCP)</a>, first through GCP’s own services, and then in the <a href="https://terra.bio">Terra</a> platform operated on top of GCP by the Broad Institute and Verily.<a contenteditable="false" data-primary="Terra platform" data-type="indexterm" id="idm45625635860248"/></p>

<figure><div id="gatk_provides_a_series_of_best_practice" class="figure"><img alt="GATK provides a series of best-practice workflows to process sequence data for a variety of experimental designs." src="Images/gitc_0102.png" width="1440" height="217"/>
<h6><span class="label">Figure 1-2. </span>GATK provides a series of Best Practices to process sequence data for a variety of experimental designs.</h6>
</div></figure>

<p>By starting with this end-to-end stack, you will acquire fundamental skills that will allow you to take advantage of the many other options out there for workflow languages, analytical tools, platforms, and the cloud.<a contenteditable="false" data-primary="GATK" data-see="Genome Analysis Toolkit" data-type="indexterm" id="idm45625635856568"/><a contenteditable="false" data-primary="infrastructure challenges" data-startref="ix_infch" data-type="indexterm" id="idm45625635855192"/></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Toward a Cloud-Based Ecosystem for Data Sharing and Analysis"><div class="sect1" id="toward_a_cloud_based_ecosystem_for_data">
<h1>Toward a Cloud-Based Ecosystem for Data Sharing <span class="keep-together">and Analysis</span></h1>

<p>From <a data-type="xref" href="#aright_parenthesis_projected_growth_of">Figure 1-1</a>, you can see that data has already been growing faster than the venerable <em>Moore’s law</em> can keep up, and as we discussed earlier, new experimental designs that generate massive amounts of data are popping up like mushrooms in the night.<a contenteditable="false" data-primary="cloud computing" data-secondary="toward an ecosystem for data sharing and analysis" data-type="indexterm" id="ix_cldeco"/> This deluge of data is in many ways the prime mover that is motivating the push to migrate scientific computing to the cloud. However, it’s important to understand that in its current form, the public cloud is mainly a collection of low-level infrastructure components, and for most purposes, it’s what we build on top of these components that will truly help researchers manage their work and answer the scientific questions they are investigating. This is all part of a larger shift that takes advantage of <span class="keep-together">cloud-hosted</span> data, compute, and portable algorithm implementations, along with platforms that make them easier to work with, standards for getting platforms to communicate with one another, and a set of conceptual principles that make science open to <span class="keep-together">everyone.</span></p>

<section data-type="sect2" data-pdf-bookmark="Cloud-Hosted Data and Compute"><div class="sect2" id="cloud_hosted_data_and_compute">
<h2>Cloud-Hosted Data and Compute</h2>

<p>The first giant challenge of this dawning big data era of biology lies in how we make these large datasets available to the research community. The traditional approach, depicted in <a data-type="xref" href="#inverting_the_model_for_data_sharingdot">Figure 1-3</a>, involves centralized repositories from which interested researchers must download copies of the data to analyze on their institution’s local computational installations. However, this approach of “bringing the data to the <span class="keep-together">people</span>" is already quite wasteful (everyone pays to store copies of the same data) and cannot possibly scale in the face of the massive growth (both in dataset numbers and size) that we are expecting, which is measured in <em>petabytes</em> (PB; 1,000 terabytes).</p>

<p>In the next<a contenteditable="false" data-type="indexterm" data-primary="National Institutes of Health (NIH)" data-secondary="genomic data hosted by" id="idm45625635413880"/> five years, for example, we estimate that the US National Institutes of Health (NIH) and other organizations will be hosting in excess of 50 PB of genomic data that needs to be accessible to the research community. There is simply going to be too much data for any single researcher to spend time downloading and too much for every research institution to host locally for their researchers. Likewise, the computational requirements for analyzing genomic, imaging, and other experimental designs is really significant. Not everyone has a compute cluster ready to go with thousands of CPUs at the ready.</p>

<p>The solution that has become obvious in recent years is to flip the script and “bring the people to the data.” Instead of depositing data into storage-only silos, we host it in widely accessible repositories that are directly connected to compute resources; thus, anyone with access can run analyses on the data where it resides, without transferring any of it, as depicted in <a data-type="xref" href="#inverting_the_model_for_data_sharingdot">Figure 1-3</a>. Even though these requirements (wide access and compute colocated with storage) could be fulfilled through a variety of technological solutions, the most readily available is a public cloud infrastructure. We go into the details of what that entails in <a data-type="xref" href="ch03.xhtml#computing_technology_basics_for_life_sc">Chapter 3</a> as part of the technology primer; for now, simply imagine that a cloud is like any institution’s high-performance computing (HPC) installation except that it is generally a whole lot larger, a lot more flexible with respect to configuration options, and anyone can rent time on the equipment.</p>

<p>Popular choices for the cloud include <a href="https://aws.amazon.com">Amazon Web Services (AWS)</a>, GCP, and <a href="https://azure.microsoft.com">Microsoft Azure</a>. Each provides the basics of compute and storage but also more advanced services; for example, the Pipelines API on GCP, which we use when running analysis at scale in <a data-type="xref" href="ch10.xhtml#running_single_workflows_at_scale_with">Chapter 10</a>.</p>

<figure><div id="inverting_the_model_for_data_sharingdot" class="figure"><img alt="Inverting the model for data sharing." src="Images/gitc_0103.png" width="1440" height="685"/>
<h6><span class="label">Figure 1-3. </span>Inverting the model for data sharing.</h6>
</div></figure>

<p>Unlike the traditional HPC clusters for which you tend to script your analysis in a way that’s very much dependent on the environment, the model presented in <a data-type="xref" href="#inverting_the_model_for_data_sharingdot">Figure 1-3</a> really encourages thinking about the portability of analysis approaches. With multiple clouds vying for market share, each storing and providing access to multiple datasets, researchers are going to want to apply their algorithms to the data wherever it resides. Highly portable workflow languages that can run in different systems on different clouds have, therefore, become popular over the past several years, including WDL (which we use in this book and explore more in <a data-type="xref" href="ch08.xhtml#automating_analysis_execution_with_work">Chapter 8</a>), <a href="https://www.commonwl.org">Common Workflow Language</a> (CWL), and <a href="https://www.nextflow.io">Nextflow</a>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Platforms for Research in the Life Sciences"><div class="sect2" id="platforms">
<h2>Platforms for Research in the Life Sciences</h2>

<p>The downside of the move to the cloud is that it adds a whole new layer of complexity (or possibly several) to the already nontrivial world of research computing. Although some researchers might already have sufficient training or personal affinity to figure out how to use cloud services effectively in their work, they are undoubtedly the minority. The much larger majority of the biomedical research community is generally not equipped adequately to deal with the “bare” services provided by public cloud vendors, so there is a clear and urgent need for the development of platforms and interfaces tailored to the needs of researchers that abstract away the operational details and allow those researchers to focus on the science.</p>

<p>Several popular platforms present easy-to-use web interfaces focused on providing researchers a point-and-click means of utilizing cloud storage and compute. For example, Terra (which we explore in <a data-type="xref" href="ch11.xhtml#running_many_workflows_conveniently_in">Chapter 11</a> and continue to use through the book), <a href="https://www.sevenbridges.com">Seven Bridges</a>, <a href="https://www.dnanexus.com">DNAnexus</a>, and <a href="https://dnastack.com">DNAstack</a> all provide these sophisticated platforms to researchers over the web.</p> 

<p>These and similar platforms can have different user interfaces and focus on different functionality, but at their core they provide a workspace environment to users. This is a place where researchers can bring together their data, metadata, and analytical workflows, sharing with their collaborators along the way. The workspace metaphor then allows researchers to run analysis—for example, on Terra this could be a batch workflow in WDL or Jupyter Notebook for interactive analysis—without ever having to dive into the underlying cloud details. We look at this in action in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch11.xhtml#running_many_workflows_conveniently_in">11</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch12.xhtml#interactive_analysis_in_jupyter_noteboo">12</a>, and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch13.xhtml#assembling_your_own_workspace_in_terra">13</a>. The takeaway is that these platforms allow researchers to take advantage of the cloud’s power and scale without having to deal with the underlying complexity.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="funding_agencies_such_as_the_national_c">
<h5>Federal Cloud Initiatives Supporting Biomedical Research in the US</h5>

<p>Funding agencies such as the National Cancer Institute (NCI) in the United States<a contenteditable="false" data-primary="National Cancer Institutes (NCI)" data-type="indexterm" id="idm45625635384888"/> have been leading the way of supporting the migration of biomedical research to public cloud infrastructure. One of the earliest examples of this shift to the cloud is the Cancer Genomics Cloud (CGC) pilot program funded by the NCI. <a contenteditable="false" data-primary="Cancer Genomics Cloud (CGC)" data-type="indexterm" id="idm45625635383384"/>That program supported the development of cloud infrastructure to host data from <a contenteditable="false" data-primary="The Cancer Genome Atlas (TCGA)" data-primary-sortas="Cancer Genome Atlas" data-type="indexterm" id="idm45625635382136"/>The Cancer Genome Atlas (TCGA), with appropriate security and access controls as well as colocated analysis tools.</p>

<p>The<a contenteditable="false" data-primary="Seven Bridges" data-type="indexterm" id="idm45625635379976"/> NCI granted awards to three applicants rather than a single winner: the commercial company<a contenteditable="false" data-primary="Institute for Systems Biology (ISB)" data-type="indexterm" id="idm45625635378600"/> Seven Bridges; the Institute for Systems Biology (ISB), a nonprofit research organization located in Seattle, WA; and the Broad Institute of MIT and Harvard, also a nonprofit research organization, located in Cambridge, MA.<a contenteditable="false" data-primary="Broad Institute of MIT and Harvard" data-type="indexterm" id="idm45625635377112"/> Seven Bridges offers the ability to run on either GCP or AWS, whereas the ISB and Broad Institute built their analysis platforms on top of Google Cloud. You can read more about the program and its evolution on the <a href="https://oreil.ly/CrfE1">NCI blog</a>.</p>

<p>The NCI Cloud Pilots program has played a seminal role in enabling infrastructure development groups to get the ball rolling. For all three awardee groups and their collaborators, it has been a long road of identifying requirements, building out prototypes, and experimenting with technologies and interfaces involved in threading that finest of needles: empowering researchers with minimal computational background to get the most from massive computational resources, securely and efficiently. Yet today all three original pilot projects are operating stable services that are supporting thousands of users on a monthly basis, in many cases enabling important research that would not have been readily possible otherwise.</p>

<p>In this book, you will have the opportunity to use the Terra Community Workbench, a subset of the Terra platform developed by the Broad Institute and Verily based on our experiences with FireCloud (the Broad Institute’s cloud pilot project). The Terra Community Workbench provides access to powerful data management and analysis capabilities for biomedical researchers. We use the name <em>Terra</em> throughout this book to refer to both the Community Workbench and the underlying capabilities of the Terra Platform that also support applications like the <em>All of Us</em> Researcher Workbench and Single Cell Portal.</p>

<p>Moving forward, the NIH, which is the largest biomedical research agency in the world, has committed to expanding the range of data and services available through public cloud infrastructure. <a contenteditable="false" data-primary="National Institutes of Health (NIH)" data-secondary="expansion in public cloud offerings" data-type="indexterm" id="idm45625635564312"/>In fact, the NIH is currently supporting multiple programs on the theme of hosting federally funded datasets and tools on the cloud. Likewise, other countries and funders have embraced using clouds for researchers as well, such as efforts like <a href="https://elixir-europe.org">ELIXIR</a> in Europe.</p>
</div></aside>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Standardization and Reuse of Infrastructure"><div class="sect2" id="standardization_and_reuse_of_infrastruc">
<h2>Standardization and Reuse of Infrastructure</h2>

<p>So it sounds like multiple clouds are available to researchers, multiple groups have built platforms on top of these clouds, and they all solve similar problems of colocating data and compute in places that researchers can easily access. The other side of this coin is that we need these distinct data repositories and platforms to be interoperable across organizations. Indeed, one of the big hopes of moving data and analysis to the cloud is that it will break down the traditional silos that have in the past made it difficult to collaborate and apply analyses across multiple datasets. Imagine being able to pull in petabytes of data into a single cross-cutting analysis without ever having to worry about where the files reside, how to transfer them, and how to store them. Now here’s some good news: that dream of a mechanism for federated data analysis is already a reality and is continuing to rapidly improve!</p>

<p>Key to<a contenteditable="false" data-primary="Global Alliance for Genomics and Health (GA4GH)" data-secondary="standards developed by" data-type="indexterm" id="idm45625635558472"/> this vision of using data regardless of platform and cloud are standards. Organizations such as the <a href="https://www.ga4gh.org">Global Alliance for Genomics and Health</a> (GA4GH) have pioneered harmonizing the way platforms communicate with one another. These standards range from file formats like CRAMs, BAMs, and VCFs (which you will see used throughout this book), to application programming interfaces (APIs) that connect storage, compute, discovery, and user identity between platforms. It might seem boring or dry to talk about APIs and file formats, but the reality is that we want the cloud platforms to support common APIs to allow researchers to break down the barriers between cloud platforms and use data regardless of location.<a contenteditable="false" data-type="indexterm" data-primary="GA4GH" data-see="Global Alliance for Genomics and Health" id="idm45625635555448"/></p>

<p>Software architecture, vision sharing, and component reuse, in addition to standards, are other key drivers for interoperability. For the past few years, five US organizations involved in <span class="keep-together">developing</span> cloud infrastructure with the support of NIH agencies and<a contenteditable="false" data-primary="Data Biosphere" data-type="indexterm" id="idm45625635552552"/> programs have been collaborating to develop interoperable infrastructure components under the shared vision of a <a href="https://www.databiosphere.org">Data Biosphere</a>. Technology leaders at the five partner organizations—Vanderbilt University in Nashville, TN; the University of California, Santa Cruz (UCSC); the University of Chicago; the Broad Institute; and Verily, an Alphabet company—articulated this shared vision of an open ecosystem in a <a href="https://oreil.ly/hsG1B">blog post on Medium</a>, published in October 2017. <a contenteditable="false" data-primary="Broad Institute of MIT and Harvard" data-type="indexterm" id="idm45625635549464"/><a contenteditable="false" data-primary="University of Chicago" data-type="indexterm" id="idm45625635548296"/><a contenteditable="false" data-primary="University of California, Santa Cruz (UCSC)" data-type="indexterm" id="idm45625635547192"/><a contenteditable="false" data-primary="Verily" data-type="indexterm" id="idm45625635546056"/>The Data Biosphere emphasizes four key pillars: it should be community driven, standards based, modular, and open source. Beyond the manifesto, which we do encourage you to read in full, the partners have integrated these principles into the components and services that each has been building and operating.</p>

<p>Taken together, community-based standards development in GA4GH and system architecture vision and software component sharing in Data Biosphere have moved us collectively forward. <a contenteditable="false" data-primary="Terra platform" data-secondary="federated data analysis across multiple datasets" data-type="indexterm" id="idm45625635544024"/>The result of these collaborative efforts is that today, you can log on to the Broad Institute’s Terra platform, quickly import data from multiple repositories hosted by the University of Chicago, the Broad Institute, and others into a private workspace on Terra, import a workflow from the <a href="https://dockstore.org">Dockstore</a> methods<a contenteditable="false" data-primary="Dockstore methods repository" data-type="indexterm" id="idm45625635541496"/> repository, and execute your analysis securely on Google Cloud with a few clicks, as illustrated in <a data-type="xref" href="#data_biosphere_principles_in_action_fed">Figure 1-4</a>.</p>

<figure><div id="data_biosphere_principles_in_action_fed" class="figure"><img alt="Data Biosphere principles in action: federated data analysis across multiple datasets in Terra using a workflow imported from Dockstore and executed in GCP." src="Images/gitc_0104.png" width="1154" height="794"/>
<h6><span class="label">Figure 1-4. </span>Data Biosphere principles in action: federated data analysis across multiple datasets in Terra using a workflow imported from Dockstore and executed in GCP.</h6>
</div></figure>

<p>To be clear, the full vision of a Data Biosphere ecosystem is far from realized. There are still major hurdles to overcome; some are, boringly, purely technical, but others are rooted in the practices and incentives that drive individuals, communities, and organizations. <a contenteditable="false" data-primary="metadata, need for greater standardization in" data-type="indexterm" id="idm45625635536024"/>For example, there is an outstanding need for greater standardization in the way data properties are formally described in metadata, which affects searchability across datasets as well as the feasibility of federated data analysis. To put this in concrete terms, it’s much more difficult to apply a joint analysis to samples coming from different datasets if the equivalent data files are identified differently in the metadata—you begin to need to provide a “translation” of how the pieces of data match up to one another across datasets (<code>input_bam</code> in one, <code>bam</code> in another, <code>aligned_reads</code> in a third). To solve this, we need to have the relevant research <span class="keep-together">communities</span> come together to hash out common standards. Technology can then be used to enforce the chosen conventions, but someone (or ideally several someones) needs to step up and formulate those in the first place.</p>

<p>As another example of a human-driven rather than technology-driven stumbling block, biomedical research would clearly benefit from having mechanisms in place to run <a contenteditable="false" data-primary="federated data analysis" data-type="indexterm" id="idm45625635531432"/>federated analyses seamlessly across infrastructure platforms; for example, cloud to cloud (Google Cloud and AWS), cloud to on-premises (Google Cloud and your institution’s local HPC cluster), and any multiplatform combination you can imagine on that theme.<a contenteditable="false" data-primary="cloud computing" data-secondary="cloud to cloud federated analyses" data-type="indexterm" id="idm45625635529928"/><a contenteditable="false" data-primary="cloud computing" data-secondary="cloud to on-premises analyses" data-type="indexterm" id="idm45625635528536"/> There is some technical complexity there, in particular around identity management and secure authentication, but one important obstacle is that this concept does not always align with the business model of commercial cloud vendors and software providers. More generally, many organizations need to be involved in developing and operating such an ecosystem, which brings a slew of complications ranging from the legal domain (data-use agreements, authority to operate, and privacy laws in various nations) to the technical (interoperability of infrastructure, data <span class="keep-together">harmonization</span>).</p>

<p>Nevertheless, significant progress has been made over the past several years, and we’re getting closer to the vision of the Data Biosphere. Many groups and organizations are actively cooperating on building interoperable cloud infrastructure components despite being in direct competition for various grant programs, which suggests that this vision has a vibrant future. The shared goal to build platforms that can exchange data and compute with one another—allowing researchers to find, mix, and match data across systems and compute in the environment of their choosing—is becoming a reality. Terra as a platform is at the forefront of this trend and is an integral part to providing access to a wide range of research datasets from projects at <a href="https://www.cancer.gov">the NCI</a>, <a href="https://www.genome.gov">National Human Genome Research Institute (NHGRI)</a>, <a href="https://www.nhlbi.nih.gov">National Heart, Lung, and Blood Institute (NHLBI)</a>, the <a href="https://www.humancellatlas.org">Human Cell Atlas</a>, and <a href="https://www.projectbaseline.com">Project Baseline by Verily</a>, to name just a few. This is possible<a contenteditable="false" data-primary="Terra platform" data-secondary="connecting to datasets already accessible in the cloud" data-type="indexterm" id="idm45625635520696"/> because these projects are adopting GA4GH APIs and common architectural principles of the Data Biosphere, making them compatible with Terra and other platforms that embrace these standards and design <span class="keep-together">philosophies</span>.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Being FAIR"><div class="sect1" id="being_fair">
<h1>Being FAIR</h1>

<p>So far, we’ve covered a lot of ground<a contenteditable="false" data-primary="cloud computing" data-secondary="toward an ecosystem for data sharing and analysis" data-startref="ix_cldeco" data-type="indexterm" id="idm45625635516568"/> in this chapter, starting with the phenomenal growth of data in the life sciences and how that’s stressing the older model of data download and pushing researchers toward a better model that uses the cloud for <span class="keep-together">storage</span> and compute.<a contenteditable="false" data-primary="FAIR (findable, accessible, interoperable, and reusable) research" data-type="indexterm" id="idm45625635513848"/> We also took a look at what the community is doing to <span class="keep-together">standardize</span> the way data and compute is made accessible on the cloud, and how the philosophy of the Data Biosphere is shaping the way platforms work together to make themselves accessible to researchers.</p>

<p>The benefits of this model are clear for platform builders who don’t want to reinvent the wheel and are motivated to reuse APIs, components, and architectural design wherever possible. But, from a researcher’s perspective, how do these standards from GA4GH and architecture from Data Biosphere translate to improvements in their research?</p>

<p>Taken together, these standards and architectural principles as applied in platforms like Terra enable researchers to make their research more FAIR: findable, accessible, interoperable, and reusable.<sup><a data-type="noteref" id="idm45625635510248-marker" href="ch01.xhtml#idm45625635510248">2</a></sup> We dive into this in more detail in <a data-type="xref" href="ch14.xhtml#making_a_fully_reproducible_paper">Chapter 14</a>. But for now, it’s useful to think that the work described up to this point by platform builders is all in an effort to make their systems, tools, and data more FAIR for researchers. Likewise, by embracing the cloud, writing portable workflows in languages like WDL, running analysis in Terra, and sharing workflows on Dockstore, researchers can make their own work more FAIR. This allows other researchers to find and access analytical techniques, interoperate, run the analysis in different places, and ultimately reuse tools as a stepping-stone to novel discovery. Throughout the book, we come back to the FAIR principles from the perspective of both platform builders and researchers.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrap-Up and Next Steps"><div class="sect1" id="wrap_up_and_next_steps-id00001">
<h1>Wrap-Up and Next Steps</h1>

<p>Now that we’ve given you a background on some of the central motivations for why genomics as a discipline is moving to the cloud, let’s recapitulate how this book aims to help you get started in this brave new world, as outlined in the <a data-type="xref" href="preface01.xhtml#preface">Preface</a>. We designed it as a journey that takes you through a progression of technical topics, with an end goal of addressing the aforementioned infrastructure challenges, ultimately showing you how to get your work done on the cloud and make it FAIR to boot.</p> 

<p>Remember, there are many different ways to approach these challenges, using different solutions, and we’re focusing on just one particular approach. Yet, we hope the following chapters will give you robust foundations to build on in your own work:</p>

<dl>
	<dt><a data-type="xref" href="ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new">Chapter 2</a> and <a data-type="xref" href="ch03.xhtml#computing_technology_basics_for_life_sc">Chapter 3</a></dt>
	<dd>We explore the fundamentals of biology and cloud computing.</dd>
	<dt><a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a> through <a data-type="xref" href="ch07.xhtml#gatk_best_practices_for_somatic_variant">Chapter 7</a></dt>
	<dd>We dive into the GATK toolkit and the current Best Practices pipelines for germline and somatic variant discovery.</dd>
	<dt><a data-type="xref" href="ch08.xhtml#automating_analysis_execution_with_work">Chapter 8</a> and <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a></dt>
	<dd>We describe how to automate your analysis and make it portable with workflows written in WDL.</dd>
	<dt><a data-type="xref" href="ch10.xhtml#running_single_workflows_at_scale_with">Chapter 10</a> and <a data-type="xref" href="ch11.xhtml#running_many_workflows_conveniently_in">Chapter 11</a></dt>
	<dd>We begin scaling up analysis first in Google Cloud, then in Terra.</dd>
	<dt><a data-type="xref" href="ch12.xhtml#interactive_analysis_in_jupyter_noteboo">Chapter 12</a></dt>
	<dd>We complement workflow-based analysis with interactive analysis using Jupyter in Terra.</dd>
	<dt><a data-type="xref" href="ch13.xhtml#assembling_your_own_workspace_in_terra">Chapter 13</a> and <a data-type="xref" href="ch14.xhtml#making_a_fully_reproducible_paper">Chapter 14</a></dt>
	<dd>We show you how to make your own workspaces in Terra and bring together everything you learned, to show you how to make a fully FAIR paper.</dd>
</dl>

<p>By the end of the book, we want you to have a good understanding of the current best practices for genomics data analysis, feel comfortable using WDL to express your analytical processes, be able to use Terra for both workflow-based and interactive analysis at scale, and share your work with your collaborators.</p> 

<p>Let’s get started!</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="idm45625635881160"><sup><a href="ch01.xhtml#idm45625635881160-marker">1</a></sup> Stephens ZD, et al. “Big Data: Astronomical or Genomical?” PLoS Biol 13(7): e1002195 (2015). <em>https://doi.org/10.1371/journal.pbio.1002195</em>.</p><p data-type="footnote" id="idm45625635510248"><sup><a href="ch01.xhtml#idm45625635510248-marker">2</a></sup>  <a href="https://oreil.ly/JyTlX">The FAIR Guiding Principles for scientific data management and stewardship</a> by Mark D. Wilkinson et al. is the original publication of this set of principles.</p></div></div></section></div>



  </body></html>