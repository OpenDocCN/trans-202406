["```\napiVersion: v1\nkind: Namespace\nmetadata:\n  labels:\n    app: orion\n  name: g04\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    tier: backend\n  name: backend\n  namespace: g04\nspec:\n  containers:\n  - image: bmuschko/nodejs-hello-world:1.0.0\n    name: hello\n    ports:\n    - containerPort: 3000\n  restartPolicy: Never\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    tier: frontend\n  name: frontend\n  namespace: g04\nspec:\n  containers:\n  - image: alpine\n    name: frontend\n    args:\n    - /bin/sh\n    - -c\n    - while true; do sleep 5; done;\n  restartPolicy: Never\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    tier: outside\n  name: other\nspec:\n  containers:\n  - image: alpine\n    name: other\n    args:\n    - /bin/sh\n    - -c\n    - while true; do sleep 5; done;\n  restartPolicy: Never\n```", "```\n$ kubectl apply -f setup.yaml\nnamespace/g04 created\npod/backend created\npod/frontend created\npod/other created\n```", "```\n$ kubectl get pods -n g04 -o wide\nNAME       READY   STATUS    RESTARTS   AGE   IP           NODE     \\\n  NOMINATED NODE   READINESS GATES\nbackend    1/1     Running   0          15s   10.0.0.43    minikube \\\n  <none>           <none>\nfrontend   1/1     Running   0          15s   10.0.0.193   minikube \\\n  <none>           <none>\n```", "```\n$ kubectl get pods\nNAME    READY   STATUS    RESTARTS   AGE\nother   1/1     Running   0          4h45m\n```", "```\n$ kubectl exec frontend -it -n g04 -- /bin/sh\n/ # wget --spider --timeout=1 10.0.0.43:3000\nConnecting to 10.0.0.43:3000 (10.0.0.43:3000)\nremote file exists\n/ # exit\n```", "```\n$ kubectl exec other -it -- /bin/sh\n/ # wget --spider --timeout=1 10.0.0.43:3000\nConnecting to 10.0.0.43:3000 (10.0.0.43:3000)\nremote file exists\n/ # exit\n```", "```\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-ingress\n  namespace: g04\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n```", "```\n$ kubectl apply -f deny-all-ingress-network-policy.yaml\nnetworkpolicy.networking.k8s.io/default-deny-ingress created\n```", "```\n$ kubectl exec frontend -it -n g04 -- /bin/sh\n/ # wget --spider --timeout=1 10.0.0.43:3000\nConnecting to 10.0.0.43:3000 (10.0.0.43:3000)\nwget: download timed out\n/ # exit\n```", "```\n$ kubectl exec other -it -- /bin/sh\n/ # wget --spider --timeout=1 10.0.0.43:3000\nConnecting to 10.0.0.43:3000 (10.0.0.43:3000)\nwget: download timed out\n```", "```\n$ kubectl get ns g04 --show-labels\nNAME   STATUS   AGE   LABELS\ng04    Active   12m   app=orion,kubernetes.io/metadata.name=g04\n$ kubectl get pods -n g04 --show-labels\nNAME       READY   STATUS    RESTARTS   AGE     LABELS\nbackend    1/1     Running   0          9m46s   tier=backend\nfrontend   1/1     Running   0          9m46s   tier=frontend\n```", "```\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: backend-ingress\n  namespace: g04\nspec:\n  podSelector:\n    matchLabels:\n      tier: backend\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          app: orion\n      podSelector:\n        matchLabels:\n          tier: frontend\n    ports:\n    - protocol: TCP\n      port: 3000\n```", "```\n$ kubectl apply -f backend-ingress-network-policy.yaml\nnetworkpolicy.networking.k8s.io/backend-ingress created\n```", "```\n$ kubectl exec frontend -it -n g04 -- /bin/sh\n/ # wget --spider --timeout=1 10.0.0.43:3000\nConnecting to 10.0.0.43:3000 (10.0.0.43:3000)\nremote file exists\n/ # exit\n```", "```\n$ kubectl exec other -it -- /bin/sh\n/ # wget --spider --timeout=1 10.0.0.43:3000\nConnecting to 10.0.0.43:3000 (10.0.0.43:3000)\nwget: download timed out\n```", "```\n$ kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/\\\nmain/job-master.yaml\njob.batch/kube-bench-master created\n```", "```\n$ kubectl get pods\nNAME                      READY   STATUS      RESTARTS   AGE\nkube-bench-master-8f6qh   0/1     Completed   0          45s\n```", "```\n$ kubectl logs kube-bench-master-8f6qh\n```", "```\n[INFO] 1 Control Plane Security Configuration ![1](assets/1.png)\n[INFO] 1.1 Control Plane Node Configuration Files\n[PASS] 1.1.1 Ensure that the API server pod specification file permissions are \\\nset to 644 or more restrictive (Automated) ![2](assets/2.png)\n...\n[INFO] 1.2 API Server\n[WARN] 1.2.1 Ensure that the --anonymous-auth argument is set to false \\\n(Manual) ![3](assets/3.png)\n...\n[FAIL] 1.2.6 Ensure that the --kubelet-certificate-authority argument is set \\\nas appropriate (Automated) ![4](assets/4.png)\n\n== Remediations master ==\n...\n1.2.1 Edit the API server pod specification file /etc/kubernetes/manifests/ \\\nkube-apiserver.yaml on the control plane node and set the below parameter.\n--anonymous-auth=false\n...\n1.2.6 Follow the Kubernetes documentation and setup the TLS connection between ![5](assets/5.png)\nthe apiserver and kubelets. Then, edit the API server pod specification file ![5](assets/5.png)\n/etc/kubernetes/manifests/kube-apiserver.yaml on the control plane node and \\ ![5](assets/5.png)\nset the --kubelet-certificate-authority parameter to the path to the cert \\ ![5](assets/5.png)\nfile for the certificate authority. ![5](assets/5.png)\n--kubelet-certificate-authority=<ca-string> ![5](assets/5.png)\n\n...\n== Summary total == ![6](assets/6.png)\n42 checks PASS\n9 checks FAIL\n11 checks WARN\n0 checks INFO\n```", "```\n[INFO] 1.2 API Server\n...\n[WARN] 1.2.12 Ensure that the admission control plugin AlwaysPullImages is \\\nset (Manual)\n\n== Remediations master ==\n...\n1.2.12 Edit the API server pod specification file /etc/kubernetes/manifests/ \\\nkube-apiserver.yaml\non the control plane node and set the --enable-admission-plugins parameter \\\nto include AlwaysPullImages.\n--enable-admission-plugins=...,AlwaysPullImages,...\n```", "```\n$ sudo vim /etc/kubernetes/manifests/kube-apiserver.yaml\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: \\\n    192.168.56.10:6443\n  creationTimestamp: null\n  labels:\n    component: kube-apiserver\n    tier: control-plane\n  name: kube-apiserver\n  namespace: kube-system\nspec:\n  containers:\n  - command:\n    - kube-apiserver\n    - --advertise-address=192.168.56.10\n    - --allow-privileged=true\n    - --authorization-mode=Node,RBAC\n    - --client-ca-file=/etc/kubernetes/pki/ca.crt\n    - --enable-admission-plugins=NodeRestriction,AlwaysPullImages\n...\n```", "```\n$ kubectl get pods -n kube-system\nNAME                           READY   STATUS    RESTARTS   AGE\n...\nkube-apiserver-control-plane   1/1     Running   0          71m\n...\n```", "```\n$ kubectl delete job kube-bench-master\njob.batch \"kube-bench-master\" deleted\n```", "```\n$ kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/\\\nmain/job-master.yaml\njob.batch/kube-bench-master created\n$ kubectl get pods\nNAME                      READY   STATUS      RESTARTS   AGE\nkube-bench-master-5gjdn   0/1     Completed   0          10s\n$ kubectl logs kube-bench-master-5gjdn | grep 1.2.12\n[PASS] 1.2.12 Ensure that the admission control plugin AlwaysPullImages is \\\nset (Manual)\n```", "```\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: t75\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  namespace: t75\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: accounting-service\n  namespace: t75\nspec:\n  selector:\n    app: nginx\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n```", "```\n$ kubectl apply -f setup.yaml\nnamespace/t75 created\ndeployment.apps/nginx-deployment created\nservice/accounting-service created\n```", "```\n$ kubectl get all -n t75\nNAME                                    READY   STATUS    RESTARTS   AGE\npod/nginx-deployment-6595874d85-5rdrh   1/1     Running   0          108s\npod/nginx-deployment-6595874d85-jmhvh   1/1     Running   0          108s\npod/nginx-deployment-6595874d85-vtwxp   1/1     Running   0          108s\n\nNAME                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S) \\\n  AGE\nservice/accounting-service   ClusterIP   10.97.101.228   <none>        80/TCP \\\n  108s\n\nNAME                               READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/nginx-deployment   3/3     3            3           108s\n```", "```\n$ kubectl run tmp --image=busybox --restart=Never -it --rm \\\n  -- wget 10.97.101.228:80\nConnecting to 10.97.101.228:80 (10.97.101.228:80)\nsaving to 'index.xhtml'\nindex.xhtml           100% |************|   612  0:00:00 ETA\n'index.xhtml' saved\npod \"tmp\" deleted**********\n```", "```\n$ openssl req -nodes -new -x509 -keyout accounting.key -out accounting.crt \\\n  -subj \"/CN=accounting.tls\"\nGenerating a 2048 bit RSA private key\n...........................+\n..........................+\nwriting new private key to 'accounting.key'\n-----\n$ ls\naccounting.crt accounting.key\n```", "```\n$ kubectl create secret tls accounting-secret --cert=accounting.crt \\\n  --key=accounting.key -n t75\nsecret/accounting-secret created\n```", "```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: accounting-secret\n  namespace: t75\ntype: kubernetes.io/tls\ndata:\n  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk...\n  tls.key: LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tCk...\n```", "```\n$ base64 accounting.crt\nLS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNyakNDQ...\n```", "```\n$ kubectl create ingress accounting-ingress \\\n  --rule=\"accounting.internal.acme.com/*=accounting-service:80, \\\n  tls=accounting-secret\" -n t75\ningress.networking.k8s.io/accounting-ingress created\n```", "```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: accounting-ingress\n  namespace: t75\nspec:\n  tls:\n  - hosts:\n    - accounting.internal.acme.com\n    secretName: accounting-secret\n  rules:\n  - host: accounting.internal.acme.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: accounting-service\n            port:\n              number: 80\n```", "```\n$ kubectl get ingress -n t75\nNAME                 CLASS   HOSTS                          ADDRESS       \\\n  PORTS     AGE\naccounting-ingress   nginx   accounting.internal.acme.com   192.168.64.91 \\\n  80, 443   55s\n```", "```\n$ kubectl describe ingress accounting-ingress -n t75\nName:             accounting-ingress\nLabels:           <none>\nNamespace:        t75\nAddress:          192.168.64.91\nIngress Class:    nginx\nDefault backend:  <default>\nTLS:\n  accounting-secret terminates accounting.internal.acme.com\nRules:\n  Host                          Path  Backends\n  ----                          ----  --------\n  accounting.internal.acme.com\n                                /   accounting-service:80 \\\n                                (172.17.0.5:80,172.17.0.6:80,172.17.0.7:80)\nAnnotations:                    <none>\nEvents:\n  Type    Reason  Age               From                      Message\n  ----    ------  ----              ----                      -------\n  Normal  Sync    1s (x2 over 31s)  nginx-ingress-controller  Scheduled for sync\n```", "```\n$ kubectl get nodes -o wide\nNAME       STATUS   ROLES           AGE     VERSION   INTERNAL-IP   \\\n  EXTERNAL-IP   OS-IMAGE               KERNEL-VERSION   CONTAINER-RUNTIME\nminikube   Ready    control-plane   3d19h   v1.24.1   192.168.64.91 \\\n  <none>        Buildroot 2021.02.12   5.10.57          docker://20.10.16\n```", "```\n$ sudo vim /etc/hosts\n...\n192.168.64.91   accounting.internal.acme.com\n```", "```\n$ wget -O- https://accounting.internal.acme.com --no-check-certificate\n--2022-07-28 15:32:43--  https://accounting.internal.acme.com/\nResolving accounting.internal.acme.com (accounting.internal.acme.com)... \\\n192.168.64.91\nConnecting to accounting.internal.acme.com (accounting.internal.acme.com) \\\n|192.168.64.91|:443... connected.\nWARNING: cannot verify accounting.internal.acme.com's certificate, issued \\\nby ‘CN=Kubernetes Ingress Controller Fake Certificate,O=Acme Co’:\n  Self-signed certificate encountered.\nWARNING: no certificate subject alternative name matches\n\trequested host name ‘accounting.internal.acme.com’.\nHTTP request sent, awaiting response... 200 OK\n```", "```\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-egress-metadata-server\n  namespace: a12\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - ipBlock:\n        cidr: 0.0.0.0/0\n        except:\n        - 169.254.169.254/32\n```", "```\n$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/\\\nv2.6.0/aio/deploy/recommended.yaml\n```", "```\n$ kubectl get deployments,pods,services -n kubernetes-dashboard\nNAME                                        READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/dashboard-metrics-scraper   1/1     1            1           11m\ndeployment.apps/kubernetes-dashboard        1/1     1            1           11m\n\nNAME                                             READY   STATUS    RESTARTS   AGE\npod/dashboard-metrics-scraper-78dbd9dbf5-f8z4x   1/1     Running   0          11m\npod/kubernetes-dashboard-5fd5574d9f-ns7nl        1/1     Running   0          11m\n\nNAME                                TYPE        CLUSTER-IP       EXTERNAL-IP \\\n  PORT(S)    AGE\nservice/dashboard-metrics-scraper   ClusterIP   10.98.6.37       <none>      \\\n  8000/TCP   11m\nservice/kubernetes-dashboard        ClusterIP   10.102.234.158   <none>      \\\n  80/TCP     11m\n```", "```\n$ kubectl proxy\nStarting to serve on 127.0.0.1:8001\n```", "```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kubernetes-dashboard\n```", "```\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kubernetes-dashboard\n```", "```\n$ kubectl create -f admin-user-serviceaccount.yaml\nserviceaccount/admin-user created\n$ kubectl create -f admin-user-clusterrolebinding.yaml\nclusterrolebinding.rbac.authorization.k8s.io/admin-user created\n```", "```\n$ kubectl create token admin-user -n kubernetes-dashboard\neyJhbGciOiJSUzI1NiIsImtpZCI6...\n```", "```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: developer-user\n  namespace: kubernetes-dashboard\n```", "```\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  annotations:\n    rbac.authorization.kubernetes.io/autoupdate: \"true\"\n  name: cluster-developer\nrules:\n- apiGroups:\n  - '*'\n  resources:\n  - '*'\n  verbs:\n  - get\n  - list\n  - watch\n- nonResourceURLs:\n  - '*'\n  verbs:\n  - get\n  - list\n  - watch\n```", "```\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: developer-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-developer\nsubjects:\n- kind: ServiceAccount\n  name: developer-user\n  namespace: kubernetes-dashboard\n```", "```\n$ kubectl create -f restricted-user-serviceaccount.yaml\nserviceaccount/restricted-user created\n$ kubectl create -f restricted-user-clusterrole.yaml\nclusterrole.rbac.authorization.k8s.io/cluster-developer created\n$ kubectl create -f restricted-user-clusterrolebinding.yaml\nclusterrolebinding.rbac.authorization.k8s.io/developer-user created\n```", "```\n$ kubectl create token developer-user -n kubernetes-dashboard\neyJhbGciOiJSUzI1NiIsImtpZCI6...\n```", "```\n$ curl -LO \"https://dl.k8s.io/v1.26.1/bin/linux/amd64/kubeadm\"\n$ curl -LO \"https://dl.k8s.io/v1.26.1/bin/linux/amd64/kubeadm.sha256\"\n```", "```\n$ echo \"$(cat kubeadm.sha256)  kubeadm\" | shasum -a 256 --check\nkubeadm: OK\n```"]