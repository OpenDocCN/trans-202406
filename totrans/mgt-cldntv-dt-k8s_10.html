<html><head></head><body><section data-pdf-bookmark="Chapter 9. Data Analytics on Kubernetes" data-type="chapter" epub:type="chapter"><div class="chapter" id="data_analytics_on_kubernetes">&#13;
<h1><span class="label">Chapter 9. </span>Data Analytics on Kubernetes</h1>&#13;
<blockquote data-type="epigraph" epub:type="epigraph">&#13;
<p>Progress in technology is when we have the ability to be more lazy.</p>&#13;
<p data-type="attribution">Dr. Laurian Chirica</p>&#13;
</blockquote>&#13;
<p><a contenteditable="false" data-primary="data analytics" data-secondary="on Kubernetes" data-type="indexterm" id="da_kub"/><a contenteditable="false" data-primary="Kubernetes" data-secondary="data analytics on" data-type="indexterm" id="kub_da"/><a contenteditable="false" data-primary="Chirica, Laurian" data-type="indexterm" id="idm46183195729200"/><a contenteditable="false" data-primary="data analytics" data-secondary="about" data-type="indexterm" id="idm46183195936160"/><a contenteditable="false" data-primary="Google" data-type="indexterm" id="idm46183195934784"/>In the early 2000s, Google captivated the internet with a declared public goal: “to organize the world’s information and make it universally accessible and useful.” This was an ambitious goal and accomplishing it would, to paraphrase, take “computer sciencing” the bits out of it. Given the increasing rate of data creation, Google needed to invent (and reinvent) ways of managing data volumes no one had ever considered. An entirely new community, culture, and industry were born around analyzing data called <em>analytics</em>, tackling what was eventually labeled “big data.” Today, analytics is a full-fledged member of almost every application stack and not just relegated to a Google problem. Now it’s everyone’s problem; instead of an art form restricted to a small club of experts, we all need to know how to make analytics work. Organizations need reliable and fast ways to deploy applications with analytics so that they can do more with less.</p>&#13;
<p>The laziness Dr. Chirica was talking about in a tongue-in-cheek way in the quote that opens this chapter describes an ideal future. Instead of having a hundred-person team working night and day to analyze a petabyte of data, what if you could reduce that to one person and a few minutes? The cloud native way of running data infrastructure is a path we should all work toward to achieve that kind of glorious laziness.</p>&#13;
<p>We’ve already looked at several aspects of moving stateful workloads onto Kubernetes, including storage, databases, and streaming. In this chapter, it’s time to look at analytics to complete the picture. As a bit of a preview, <a data-type="xref" href="#the_cloud_native_virtual_datacenter">Figure 9-1</a> shows how data analytics fits as the final part of our roadmap of managing the complete data stack using Kubernetes.</p>&#13;
<figure><div class="figure" id="the_cloud_native_virtual_datacenter">&#13;
<img alt="The cloud native virtual datacenter" src="assets/mcdk_0901.png"/>&#13;
<h6><span class="label">Figure 9-1. </span>The cloud native virtual datacenter</h6>&#13;
</div></figure>&#13;
<p>In this architecture, there are no more external network requirements bridging to resources in or out of the Kubernetes cluster, just a single, virtual datacenter that serves our bespoke needs for cloud native applications. The large blocks represent the macro components of data infrastructure we discussed in <a data-type="xref" href="ch01.html#introduction_to_cloud_native_data_infra">Chapter 1</a>, with the addition of user application code, deployed in microservices.</p>&#13;
<section data-pdf-bookmark="Introduction to Analytics" data-type="sect1"><div class="sect1" id="introduction_to_analytics">&#13;
<h1>Introduction to Analytics</h1>&#13;
<p>Analytic workloads and the accompanying infrastructure operations are much different from other workloads. Analytics isn’t just another containerized system to orchestrate. The typical stateful applications like databases we examined in previous chapters have many similar characteristics but tend to stay static or predictably slow-growing once deployed.</p> &#13;
&#13;
<p>However, one aspect of analytic workloads strikes fear in many administrators: volume. While persistent data stores like databases can consume gigabytes to terabytes of storage, analytic volumes can easily soar into petabytes, creating an entirely new class of problems to solve. They don’t call it “big data” for nothing.</p>&#13;
<p class="pagebreak-before">The <em>Oxford English Dictionary</em> defines analytics as “the systematic computational analysis of data or statistics.” <a href="https://oreil.ly/Hc1Pp">Wikipedia</a> adds, “It is used for the discovery, interpretation, and communication of meaningful patterns in data.” Combine those definitions with large volumes of data and what sort of outcome should we expect for cloud native applications? Let’s break down the different types of analytics workflows and methodologies:</p>&#13;
<dl>&#13;
<dt>Batch analytics</dt>&#13;
<dd><a contenteditable="false" data-primary="batch analytics" data-type="indexterm" id="idm46183196195248"/><a contenteditable="false" data-primary="analytics" data-secondary="batch" data-type="indexterm" id="idm46183195827584"/>In computer science, a <em>batch</em> is a series of instructions applied to data with little or no user interaction. The idea of running batch Jobs is as old as general-purpose computing. In distributed systems such as Apache Hadoop or Apache Spark, each individual Job consists of a program that can operate on smaller bits of data in parallel and in stages or pipelines. The smaller results are combined into a single, final result at the end of a Job. An example of this is MapReduce, discussed later in this chapter. In most cases, statistical analysis such as count, average, and percentile measurement is done. Batch analytics is the focus of this chapter.</dd>&#13;
<dt>Stream analytics</dt>&#13;
<dd><a contenteditable="false" data-primary="stream analytics" data-type="indexterm" id="idm46183195652144"/>As discussed in <a data-type="xref" href="ch08.html#streaming_data_on_kubernetes">Chapter 8</a>, stream analytics is about what is <em>happening,</em> whereas batch analytics is about what <em>happened</em>. Many of the same APIs and developer methodologies are used in both stream analytics and batch analytics. This can be confusing and lead people to believe that they are the same thing when, in fact, they have very different use cases and implementations. A good example is fraud detection. The time frames for detecting and stopping fraud can be measured in milliseconds to seconds, which fits the stream analytics use case. Batch analytics would be used to find fraud patterns over larger time periods.</dd>&#13;
<dt>Artificial intelligence/machine learning (AI/ML)</dt>&#13;
<dd><a contenteditable="false" data-primary="AI/ML (artificial intelligence/machine learning)" data-secondary="about" data-type="indexterm" id="idm46183195824256"/>While AI and ML can be considered a subset of batch analytics, they are such specialized fields that they deserve a special callout. AI and ML are often mentioned together; however, they have two different output goals. AI attempts to emulate human cognition in decision making. ML uses algorithms to derive meaning from pools of data, sometimes in ways that aren’t readily obvious. Both approaches require the application of computing resources across volumes of data. This topic is discussed in greater detail in <a data-type="xref" href="ch10.html#machine_learning_and_other_emerging_use">Chapter 10</a>.</dd>&#13;
</dl>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Deploying Analytic Workloads in Kubernetes" data-type="sect1"><div class="sect1" id="deploying_analytic_workloads_in_kuberne">&#13;
<h1>Deploying Analytic Workloads in Kubernetes</h1>&#13;
<p><a contenteditable="false" data-primary="data analytics" data-secondary="deploying analytic workloads" data-type="indexterm" id="da_work"/>The original focus of Kubernetes was on scaling and orchestrating stateless applications. As you’re learning in this book, Kubernetes is evolving to support stateful applications. The promise of operational efficiency by moving more and more workloads into virtual datacenters has been highly motivating. The world of analytics can take advantage of the progress made in reducing the operational burden for stateless and stateful workloads. However, Kubernetes has some unique challenges in managing analytic workloads; many are still a work in progress. What features of Kubernetes are required to complete the data picture and put analytic workloads on par with other parts of the stack like microservices and databases? Here are a few of the key considerations we’ll examine in this chapter:</p>&#13;
<dl>&#13;
<dt>Orderly execution</dt>&#13;
<dd><a contenteditable="false" data-primary="execution, analytic workloads and" data-type="indexterm" id="idm46183196147520"/>An essential aspect of analytic workloads is the order of operations required to analyze large volumes of data. This involves far more than just making sure Pods are started with the proper storage and networking resources. It also includes a mapping of the application with the orderly execution run in each Pod. The Kubernetes component primarily responsible for this task is <code>kube-scheduler</code> (see <a data-type="xref" href="ch05.html#automating_database_management_on_kuber">Chapter 5</a>), but the controllers for Jobs and CronJobs are involved as well. This is a particular area of attention for the Kubernetes communities focusing on analytics, which we will further cover in the chapter.</dd>&#13;
<dt>Storage management</dt>&#13;
<dd><a contenteditable="false" data-primary="data storage" data-secondary="managing analytic workloads and" data-type="indexterm" id="idm46183195925248"/>Analytic workloads use ephemeral and persistent storage in different Jobs that process data. The real trouble occurs when it comes to identifying and selecting the right storage per Job. Many analytic workloads require ephemeral storage for short periods and more-efficient (cheaper) persistent storage for long terms. As you learned in <a data-type="xref" href="ch02.html#managing_data_storage_on_kubernetes">Chapter 2</a>, Kubernetes storage has greatly increased maturity. Analytics projects that run on Kubernetes need to take advantage of the work already done with stateful workloads and continue to partner with the Kubernetes community for future enhancements in areas like StorageClasses and different access patterns.</dd>&#13;
<dt>Efficient use of resources</dt>&#13;
<dd><a contenteditable="false" data-primary="resources" data-secondary="efficient use of" data-type="indexterm" id="idm46183195705200"/>There is an old saying that “everything counts in large amounts,” and nothing makes that more evident than analytics. A Job may require 1,000 Pods for 10 minutes, but what if it needs 10,000? That’s a challenging problem for the Kubernetes control plane. Another Job might require terabytes of swap disk space that is needed only for the duration of a Job. In a cloud native world, Jobs should be able to quickly allocate the resources they need and release the resources when finished. Making these operations as efficient as possible saves time and, more importantly, money. The fast and bursty nature of analytics has created some challenges for the Kubernetes API server and scheduler to keep up with all the Jobs that need to be run. Several of those challenges are already being addressed, as discussed later in the chapter, and some are still a work in progress.</dd>&#13;
</dl>&#13;
<p>Those are the challenges, but none of them are showstoppers that will get in the way of our dream of a complete cloud native stack deployed as a single virtual datacenter in Kubernetes.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="analytics_on_kubernetes_is_the_next_fro">&#13;
<h5>Analytics on Kubernetes Is the Next Frontier</h5>&#13;
<p><em>With Holden Karau, Open Source Engineer, Apache Spark PMC</em></p>&#13;
<p><a contenteditable="false" data-primary="Karau, Holden" data-type="indexterm" id="idm46183195716640"/>Running analytic workloads has been the boss-level challenge for infrastructure engineers from day one. There is the challenge of massive volumes of needed resources, which in many cases are the most significant part of your infrastructure. Then, coordination is required to use all those resources efficiently, and this is where frameworks like Spark come into play. Projects like YARN from Hadoop and then Mesos were developed to help with the container management game. Today, infrastructure engineers everywhere are very happy with migrating the best aspects of those systems to Kubernetes.</p>&#13;
<p>Let’s consider a few examples. Running multiple Spark tenants in Kubernetes provides better isolation between your workloads, which is really important if you don’t trust each workload to the same degree. Historically, the support for Python dependencies inside Spark Jobs has been poor, but deploying on Kubernetes makes it possible to use leading-edge Python libraries for ML and GPU usage. SREs can spend more time optimizing resources rather than chasing down obscure errors typical with large, distributed systems.</p>&#13;
<p>Ultimately, we are still in the early days of learning how to run our analytic workloads in Kubernetes most effectively. The difficulty curve starts getting much steeper as data volumes increase. Once you start going over the tens or hundreds of terabytes, you will find yourself on the leading edge of Spark operations in Kubernetes. This is probably not a big surprise, because that tends to be how infrastructure engineering works. The upper-limit scale problems with Kubernetes are rooted in the early use cases it was designed for. The dynamic and elastic nature of Kubernetes works well for the use cases for which it was first designed, but it gets overwhelmed at the levels required to run Spark applications. This is not impossible to solve, and the Spark and Kubernetes communities are working to improve a few critical areas.</p>&#13;
<p>Kubernetes SREs love the idea of elastic workloads, but in Spark, that’s been much more painful than it needs to be. Regular execution of a Spark Job can cause a rapid increase in Pods while the Job is processing, and then those resources are released when the Job is complete. Scaling up is, unfortunately, much easier than scaling down. Spark can now make use of externalized resource allocation that opens the possibility for better solutions. Open source projects such as Volcano and Apache YuniKorn are already working on resource allocation solutions inside Kubernetes, which the execution allocator and shuffle service can leverage to align more closely to the way Kubernetes works. Taken together, these efforts provide a significant path forward for more efficient resource usage in a dynamic Spark environment.</p>&#13;
<p>Resource-intensive applications like Spark can benefit from having more insight from the underlying systems to balance Jobs as they are run. Today, Kubernetes and Spark do not share as much information as they need for the best outcomes, and you should adjust your expectations accordingly. A specific example is the way Kubernetes approaches storage quota enforcement, which can work against Spark in some cases. Ephemeral storage is a key part of Spark execution, but Kubernetes provides no system-level APIs that Spark could use to check the utilization against the storage quota, which can cause Job failures. Previous applications that have been deployed on Kubernetes haven’t needed this level of insight. Spark creates a compelling case for significant changes to expose additional system-level APIs in Kubernetes, which will make it possible to build much more reliable analytic workloads.</p>&#13;
<p>If you are interested in solving these problems, these solutions will happen in open source projects. You can get involved today and help us move forward by participating in the larger <a href="https://spark.apache.org/community.html">community</a>. Apache Spark has room for improvement and so does Kubernetes, but the future direction is clear. Kubernetes is where cloud native analytics will happen, and Spark will continue to evolve. There will be a lot of interesting work in this area for the next several years at least, and it’s a pretty exciting community to be a part of.</p>&#13;
</div></aside>&#13;
<p><a contenteditable="false" data-primary="" data-startref="da_work" data-type="indexterm" id="idm46183195534992"/>Engineers can be their own worst enemies. Often when we go to solve one problem, it creates a few more that need to be solved. We can count this as progress, however, when it comes to managing data. Every step up we take, despite the challenges, allows for new solutions that were never available before. It’s a staggering thought—today, a small number of people can perform analytics tasks that massive teams would not have been able to accomplish just a few years ago. See the quote about laziness at the beginning of the chapter. There is still work to be done, and next we will look at the tools available for analyzing data in Kubernetes.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Introduction to Apache Spark" data-type="sect1"><div class="sect1" id="introduction_to_apache_spark">&#13;
<h1>Introduction to Apache Spark</h1>&#13;
<p><a contenteditable="false" data-primary="data analytics" data-secondary="Apache Spark" data-type="indexterm" id="da_as"/><a contenteditable="false" data-primary="Apache Spark" data-secondary="about" data-type="indexterm" id="idm46183195585344"/><a contenteditable="false" data-primary="HDFS (Hadoop Distributed File System)" data-type="indexterm" id="idm46183195568768"/><a contenteditable="false" data-primary="RDD (Resilient Distributed Dataset)" data-type="indexterm" id="idm46183195570336"/><a contenteditable="false" data-primary="DAG (Directed Acyclic Graph)" data-type="indexterm" id="idm46183195565504"/><a contenteditable="false" data-primary="MapReduce paper" data-type="indexterm" id="idm46183195547088"/>Google changed the world of data analytics with the MapReduce algorithm simply by describing it to the world in an academic paper. Not long after the <a href="https://oreil.ly/mryO0">MapReduce paper</a> got engineers talking, an open source implementation was created: the now-famous Apache Hadoop. A massive ecosystem was built up around Hadoop with tooling and complementary projects such as Hadoop Distributed File System (HDFS).</p> &#13;
&#13;
<p>Growing pains from this fast-moving project opened the door for the next generation of tools that built on the lessons learned with Hadoop. One project that grew in popularity as an alternative to Hadoop was <a href="https://oreil.ly/BlT4i">Apache Spark</a>. Spark addressed reliability and processing efficiency problems by introducing the Resilient Distributed Dataset (RDD) API and Directed Acyclic Graph (DAG).</p>&#13;
<p>The RDD was a significant improvement over the forced linear processing patterns of MapReduce, which involved a lot of reading from disk, processing, and then writing back to disk only to be redone over and over. This put the burden on developers to reason through how data was processed. RDDs shifted the responsibility away from developers as an API that created a unified view of all data while abstracting the actual processing details. Those details were created in a workflow to perform each task expressed in a DAG. The DAG is nothing more than an optimized path that describes data and operations to be completed in an orderly fashion until the final result is produced. RDDs were eventually replaced with the Dataset and DataFrame APIs, further enhancing developer productivity over large volumes of data.</p>&#13;
<p>Spark’s operational complexity is greatly reduced compared to Hadoop, which notoriously tipped the scale with the infrastructure required even for basic Jobs. Spark is an excellent example of one of the benefits of being a next-generation implementation with great hindsight. Much effort was put into simplifying Spark’s architecture, leveraging distributed systems concepts. The result is the three familiar components you should be familiar with in a Spark cluster, shown in <a data-type="xref" href="#components_of_a_spark_cluster">Figure 9-2</a>.</p>&#13;
<figure class="width-90"><div class="figure" id="components_of_a_spark_cluster">&#13;
<img alt="Components of a Spark cluster" src="assets/mcdk_0902.png"/>&#13;
<h6><span class="label">Figure 9-2. </span>Components of a Spark cluster</h6>&#13;
</div></figure>&#13;
<p class="pagebreak-before">Let’s review the responsibilities of each of these components:</p>&#13;
<dl>&#13;
<dt>Cluster Manager</dt>&#13;
<dd><a contenteditable="false" data-primary="Cluster Manager (Apache Spark)" data-type="indexterm" id="idm46183196029744"/>The Cluster Manager is the central hub for activity in the Spark cluster where new Jobs are submitted for processing. The Cluster Manager also acquires the resources needed to complete the task submitted. Different versions of the Cluster Manager are primarily based on how resources are managed (standalone, YARN, Mesos, and Kubernetes). The Cluster Manager is critical for deploying your Spark application using Kubernetes.</dd>&#13;
<dt>Worker Node</dt>&#13;
<dd><a contenteditable="false" data-primary="Worker Nodes" data-type="indexterm" id="idm46183195593888"/>When Spark Jobs run, they are broken into manageable pieces by the Cluster Manager and handed to the Worker Nodes to perform the processing. They serve as the local manager for hardware resources as a single point of contact. Worker Nodes invoke and manage Spark Executors.</dd>&#13;
<dt>Spark Executor</dt>&#13;
<dd><a contenteditable="false" data-primary="Spark Executor" data-type="indexterm" id="idm46183195580256"/>Each application sent to a Worker Node will get its own Spark Executor. Each Executor is a standalone JVM process that operates independently and communicates back with the Worker Node. The tasks for the application are broken into threads that consume the compute resources allocated.</dd>&#13;
</dl>&#13;
<p>These are the traditional components of Spark as designed early in the project. We’ll see that the need to deploy a cloud native version of Spark forced some architectural evolution. The fundamentals are the same, but the execution framework has adapted to take advantage of what Kubernetes provides and eliminate duplication in orchestration overhead. In the next section, we’ll look at those changes and how to work with Spark in Kubernetes.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Deploying Apache Spark in Kubernetes" data-type="sect1"><div class="sect1" id="deploying_apache_spark_in_kubernetes">&#13;
<h1>Deploying Apache Spark in Kubernetes</h1>&#13;
<p><a contenteditable="false" data-primary="Apache Spark" data-secondary="deploying in Kubernetes" data-type="indexterm" id="as_dep"/><a contenteditable="false" data-primary="data analytics" data-secondary="deploying Apache Spark" data-type="indexterm" id="da_dep"/><a contenteditable="false" data-primary="spark-submit command" data-type="indexterm" id="idm46183195694800"/>As of Apache Spark version 2.3, Kubernetes is one of the supported modes in the Cluster Manager. It would be easy to understate what that has meant for Spark as a cloud native analytics tool. Starting with Spark 3.1, Kubernetes mode is considered production-ready, continually adding steady improvements. When the Spark project looked at what it takes to run a clustered analytics system inside a cluster orchestration platform, a lot of overlaps became obvious. Kubernetes already had the mechanisms in place for the lifecycle management of containers and the dynamic provisioning and deprovisioning of compute elements, so Spark lets Kubernetes take care of this work. The redundant parts were removed, and Spark is closer to the way Kubernetes works as a result. The <code>spark-submit</code> command-line tool was extended to interface with Kubernetes clusters using the Kubernetes API, maintaining a familiar toolchain for developers and data engineers. These unique aspects of a Spark deployment in Kubernetes are shown in <a data-type="xref" href="#spark_on_kubernetes">Figure 9-3</a>.</p>&#13;
<figure><div class="figure" id="spark_on_kubernetes">&#13;
<img alt="Spark on Kubernetes" src="assets/mcdk_0903.png"/>&#13;
<h6><span class="label">Figure 9-3. </span>Spark on Kubernetes</h6>&#13;
</div></figure>&#13;
<p>Let’s highlight a few of the differences:</p>&#13;
<dl>&#13;
<dt>Spark Driver</dt>&#13;
<dd><a contenteditable="false" data-primary="Spark Driver" data-type="indexterm" id="idm46183195632448"/>The dedicated Cluster Manager of a standalone Spark cluster is replaced with native Kubernetes cluster management and the Spark Driver for Spark-specific management. The Spark Driver Pod is created when the Kubernetes API server receives a Job from the <code>spark-submit</code> tool. It invokes the Spark Executor Pods to satisfy the Job requirements. It is also responsible for cleaning up Executor Pods after the Job, making it a crucial part of elastic workloads.</dd>&#13;
<dt>Spark Executor</dt>&#13;
<dd><a contenteditable="false" data-primary="Spark Executor" data-type="indexterm" id="idm46183195523952"/>Like a standalone Spark cluster, Executors are where the work gets done and where the most compute resources are consumed. Invoked from the Spark Driver, they take Job instructions passed by <code>spark-submit</code> with details such as CPU and memory limits, storage information, and security credentials. The containers used in Executor Pods are pre-created by the user.</dd>&#13;
<dt>Custom Executor container</dt>&#13;
<dd><a contenteditable="false" data-primary="Custom Executor container" data-type="indexterm" id="idm46183196073568"/>Before a Job is sent for processing using <code>spark-submit</code>, users must build a custom container image tailored to meet the application requirements. The Spark distribution download contains a Dockerfile that can be customized and used in conjunction with the <em>docker-image-tool.sh</em> script to build and upload the container required when submitting a Spark Job in Kubernetes. The custom container has everything it needs to work within a Kubernetes environment, like a Spark Executor based on the Spark distribution version required.</dd>&#13;
</dl>&#13;
<p>The workflow for preparing and running Spark Jobs when using Kubernetes and defaults can be relatively simple, requiring only a couple of steps. This is especially true if you are already familiar with and running Spark in production. You will need a running Kubernetes cluster and a download of Spark in a local filepath along with your Spark application source code.</p>&#13;
<section data-pdf-bookmark="Build Your Custom Container" data-type="sect2"><div class="sect2" id="build_your_custom_container">&#13;
<h2>Build Your Custom Container</h2>&#13;
<p><a contenteditable="false" data-primary="Custom Executor container" data-type="indexterm" id="idm46183195655536"/>An executor container encapsulates your application and the runtime needed to act as an executor Pod. The build script takes an argument for the source code repository and a tag assignment for the output image when pushed to your Docker registry:</p>&#13;
<pre data-type="programlisting"><strong>./bin/docker-image-tool.sh -r &lt;repo&gt; -t &lt;tag&gt; build</strong></pre>&#13;
<p>The output will be a Docker image with a JAR file containing your application code. You will then need to push this image to your Docker registry:</p>&#13;
<pre data-type="programlisting"><strong>./bin/docker-image-tool.sh -r &lt;repo&gt; -t &lt;tag&gt; push</strong></pre>&#13;
<div data-type="warning" epub:type="warning">&#13;
<h1>Docker Image Tags</h1>&#13;
<p><a contenteditable="false" data-primary="Docker Image tags" data-type="indexterm" id="idm46183195478112"/>Be mindful that your tag name is labeled and versioned correctly. Reusing the same tag name in production could have unintended consequences, as some of us have learned from experience.</p>&#13;
</div>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Submit and Run Your Application" data-type="sect2"><div class="sect2" id="submit_and_run_your_application">&#13;
<h2>Submit and Run Your Application</h2>&#13;
<p><a contenteditable="false" data-primary="applications" data-secondary="running" data-type="indexterm" id="idm46183195474672"/><a contenteditable="false" data-primary="applications" data-secondary="submitting" data-type="indexterm" id="idm46183195473456"/>Once the Docker image is pushed to the repo, use <code><strong>spark-submit</strong></code> to start the process of running the Spark application inside Kubernetes. This is the same <code>spark-submit</code> used for other modes, so many of the same arguments are used. This corresponds to (1) in <a data-type="xref" href="#spark_on_kubernetes">Figure 9-3</a>:</p>&#13;
<pre data-type="programlisting"><strong>./bin/spark-submit \</strong>&#13;
    <strong>--master k8s://https://&lt;k8s-apiserver-host&gt;:&lt;k8s-apiserver-port&gt; \</strong>&#13;
    <strong>--deploy-mode cluster \</strong>&#13;
    <strong>--name &lt;application-name&gt; \</strong>&#13;
    <strong>--class &lt;fully-qualified-class-name&gt; \</strong>&#13;
    <strong>--conf spark.executor.instances=&lt;instance-number&gt; \</strong>&#13;
    <strong>--conf spark.kubernetes.container.image=&lt;spark-image&gt; \</strong>&#13;
    <strong>local:///path/to/application.jar</strong></pre>&#13;
<p class="pagebreak-before">Quite a few things are happening here, but the <em>most important</em> is in the <code>--master</code> parameter. To indicate this is for Kubernetes, the URL in the argument must start with <code>k8s://</code> and point to the API server in the default Kubernetes cluster specified in your local <em>.kubeconfig</em> file. The <code><em>&lt;spark-image&gt;</em></code> is the Docker image you created in (1), and the application path refers to your application stored inside the image.</p>&#13;
<p>Next is (2), where <code>spark-submit</code> interacts with the Kubernetes cluster to schedule the Spark Driver Pod (3) and (4). The Spark Driver parses the Job parameters and works with the Kubernetes scheduler to set up Spark Executor Pods (5), (6), and (7) to run the application code contained in the customer container image. The application will run to completion, and eventually the Pod used will be terminated and resources returned to the Kubernetes cluster in a process called <em>garbage collection</em>.</p>&#13;
<p>This is just an overview of how Spark natively works with Kubernetes. Please refer to the <a href="https://oreil.ly/upJeL">official documentation</a> to go into much greater detail. There are many ways to customize the arguments and parameters to best fit your specific needs.</p>&#13;
<div data-type="note" epub:type="note">&#13;
<h1>Security Considerations when Running Spark in Kubernetes</h1>&#13;
<p><a contenteditable="false" data-primary="Apache Spark" data-secondary="security considerations" data-type="indexterm" id="idm46183195463712"/><a contenteditable="false" data-primary="UID (unprivileged unique identifier)" data-type="indexterm" id="idm46183195616336"/>Security is not enabled by default when using Spark in Kubernetes. The first line of defense is authentication. Production Spark applications should use the built-in authentication in Spark to ensure that the users and processes accessing your application are the ones you intended.</p>&#13;
<p>When creating a container for your application, the Spark documentation highly recommends changing the <code>USER</code> directive to an unprivileged unique identifier (UID) and group identifier (GID) to mitigate against privilege escalation attacks. This can also be accomplished with a SecurityContext inside the Pod template file provided as a parameter to <code>spark-submit</code>.</p>&#13;
<p>Storage access should also be restricted with the Spark Driver and Spark Executor. Specifically, you should limit the paths that can be accessed by the running application to eliminate any accidental access in the event of a vulnerability. These can be set inside a PodSecurityAdmission, which the Spark documentation <a href="https://oreil.ly/xQcom">recommends</a>.</p>&#13;
</div>&#13;
<p><a contenteditable="false" data-primary="" data-startref="da_as" data-type="indexterm" id="idm46183195480224"/><a contenteditable="false" data-primary="" data-startref="as_dep" data-type="indexterm" id="idm46183195748608"/><a contenteditable="false" data-primary="" data-startref="da_dep" data-type="indexterm" id="idm46183195777888"/>For optimal security of your Spark applications, use the security primitives Kubernetes provides and customize the defaults for your environment. The best security is the one you don’t have to think about. If you are an SRE, this is one of the best things you can do for your developers and data engineers. Default secure!</p>&#13;
</div></section>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Kubernetes Operator for Apache Spark" data-type="sect1"><div class="sect1" id="kubernetes_operator_for_apache_spark">&#13;
<h1>Kubernetes Operator for Apache Spark</h1>&#13;
<p><a contenteditable="false" data-primary="Apache Spark" data-secondary="Kubernetes Operator for" data-type="indexterm" id="as_ko"/><a contenteditable="false" data-primary="data analytics" data-secondary="Kubernetes Operator for Apache Spark" data-type="indexterm" id="da_ko"/><a contenteditable="false" data-primary="Kubernetes Operator, for Apache Spark" data-type="indexterm" id="ko_as"/>If Spark can run in Kubernetes via <code>spark-submit</code>, why do we need an operator? As you learned in previous chapters, Kubernetes operators give you more flexibility in managing applications and a more cloud native experience overall. Using <code>spark-submit</code> to run your Spark applications requires your production systems to be set up with a local installation of Spark, including all dependencies. The Spark on Kubernetes Operator allows SREs and developers to manage park applications declaratively using Kubernetes tools such as Helm and <code>kubectl</code>. It also allows better observability on running Jobs and exporting metrics to external systems like Prometheus. Finally, using the operator provides an experience much closer to running other applications in Kubernetes.</p>&#13;
<p>The first step is to install the operator into your Kubernetes cluster using Helm:</p>&#13;
<pre data-type="programlisting"><strong>helm repo add spark-operator \</strong>&#13;
<strong>  https://googlecloudplatform.github.io/spark-on-k8s-operator</strong>&#13;
&#13;
<strong>helm install my-release spark-operator/spark-operator \</strong>&#13;
<strong>  --namespace spark-operator --create-namespace</strong></pre>&#13;
<p>Once completed, you will have a SparkApplication controller running and looking for SparkApplication objects. This is the first big departure from <code>spark-submit</code>. Instead of a long list of command-line arguments, you use the SparkApplication CRD to define the Spark Job in a YAML file. Let’s look at a config file from the <a href="https://oreil.ly/quNfG">Spark on Kubernetes Operator documentation</a>:</p>&#13;
<pre data-type="programlisting">apiVersion: "sparkoperator.k8s.io/v1beta2"&#13;
kind: SparkApplication&#13;
metadata:&#13;
  name: spark-pi&#13;
  namespace: default&#13;
spec:&#13;
  type: Scala&#13;
  mode: cluster&#13;
  image: "gcr.io/spark-operator/spark:v3.1.1"&#13;
  imagePullPolicy: Always&#13;
  mainClass: org.apache.spark.examples.SparkPi&#13;
  mainApplicationFile: &#13;
    "local:///opt/spark/examples/jars/spark-examples_2.12-3.1.1.jar"&#13;
  sparkVersion: "3.1.1"&#13;
  restartPolicy:&#13;
    type: Never&#13;
  volumes:&#13;
    - name: "test-volume"&#13;
      hostPath:&#13;
        path: "/tmp"&#13;
        type: Directory&#13;
  driver:&#13;
    cores: 1&#13;
    coreLimit: "1200m"&#13;
    memory: "512m"&#13;
    labels:&#13;
      version: 3.1.1&#13;
    serviceAccount: spark&#13;
    volumeMounts:&#13;
      - name: "test-volume"&#13;
        mountPath: "/tmp"&#13;
  executor:&#13;
    cores: 1&#13;
    instances: 1&#13;
    memory: "512m"&#13;
    labels:&#13;
      version: 3.1.1&#13;
    volumeMounts:&#13;
      - name: "test-volume"&#13;
        mountPath: "/tmp"</pre>&#13;
<p>The <code>spec:</code> section is similar to the parameters you passed in <code>spark-submit</code> with details about your application. The most important is the location of the container image. This example uses a default Spark container with the <code>spark-examples</code> JAR file preinstalled. You will need to use <em>docker-image-tool.sh</em> to build the image for your application as described in <a data-type="xref" href="#build_your_custom_container">“Build Your Custom Container”</a>, and modify the <code>mainClass</code> and <code>mainApplicationFile</code> as appropriate for your application.</p>&#13;
<p>Two other notable fields under <code>spec</code> are <code>driver</code> and <code>executor</code>. These provide the specifications for the Spark Driver Pods and Spark Executor Pods that the Spark Operator will deploy. For <code>driver</code>, only one core is required, but CPU and memory allocations need to be enough to maintain the number of executors you require. The number is set in the <code>executor</code> section under <code>instances</code>.</p>&#13;
<div data-type="warning" epub:type="warning">&#13;
<h1>Minding Your Resources</h1>&#13;
<p>For resource management, the requests you make under <code>driver</code> and <code>spec</code> need to be carefully considered for resource management. The number of instances plus their allocated CPU and memory could use up resources quickly. Jobs can hang indefinitely while waiting for resources to free up, which may never happen.</p>&#13;
</div>&#13;
<p>Now that your configuration YAML is ready, it’s time to put it into action. For a walk-through, refer to <a data-type="xref" href="#spark_on_kubernetes_operator">Figure 9-4</a>.</p>&#13;
<figure><div class="figure" id="spark_on_kubernetes_operator">&#13;
<img alt="Spark on Kubernetes Operator" src="assets/mcdk_0904.png"/>&#13;
<h6><span class="label">Figure 9-4. </span>Spark on Kubernetes Operator</h6>&#13;
</div></figure>&#13;
<p>First, use <code>kubectl apply -f <em>&lt;filename&gt;</em></code> (1) to apply the SparkApplication into your running Kubernetes cluster (2). The Spark Operator listens for new applications (3), and when a new config object is applied, the submission runner controller begins the tasks of building out the required Pods. From here the actions taken in the Kubernetes cluster are the same as if you used <code>spark-submit</code>, with all of the parameters being supplied in this case via the SparkApplication YAML. The submission runner starts the Spark Driver Pod (4) which in turn directs the Spark Executor Pods (5), which runs the application code to completion. The Pod monitor included in the Spark Operator exports Spark metrics to observability tools such as Prometheus.</p>&#13;
<p><a contenteditable="false" data-primary="" data-startref="as_ko" data-type="indexterm" id="idm46183195586176"/><a contenteditable="false" data-primary="" data-startref="da_ko" data-type="indexterm" id="idm46183195581200"/><a contenteditable="false" data-primary="" data-startref="ko_as" data-type="indexterm" id="idm46183195703888"/>The Spark Operator fills in the gaps between the way <code>spark-submit</code> works and the way SREs and developers typically deploy applications into Kubernetes. This was a long answer to the question posed at the beginning of this section. We need an operator to make using Spark more cloud native and thus more manageable in the long run. The cloud native way of doing things includes taking a declarative approach to managing resources and making those resources observable.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Alternative Schedulers for Kubernetes" data-type="sect1"><div class="sect1" id="alternative_schedulers_for_kubernetes">&#13;
<h1>Alternative Schedulers for Kubernetes</h1>&#13;
<p><a contenteditable="false" data-primary="alternative schedulers" data-type="indexterm" id="alt_ab"/><a contenteditable="false" data-primary="data analytics" data-secondary="alternative schedulers for Kubernetes" data-type="indexterm" id="da_alt"/>As you learned in <a data-type="xref" href="ch05.html#automating_database_management_on_kuber">Chapter 5</a>, the Kubernetes scheduler has a basic but essential job: take requests for resources and assign the compute, network, and storage to satisfy the requirements. Let’s look at the default approach for this action, as shown in <a data-type="xref" href="#typical_kubernetes_scheduling">Figure 9-5</a>.</p>&#13;
<figure><div class="figure" id="typical_kubernetes_scheduling">&#13;
<img alt="Typical Kubernetes scheduling" src="assets/mcdk_0905.png"/>&#13;
<h6><span class="label">Figure 9-5. </span>Typical Kubernetes scheduling</h6>&#13;
</div></figure>&#13;
<p>A typical scheduling effort begins when you create a <em>deployment.yaml</em> file describing the resources required (1), including which Pod resources are needed and how many. When the YAML file is submitted (2) to the Kubernetes cluster API server using <code>kubectl apply</code>, the Pod resources are created with the supplied parameters and are ready for assignment to a node. Nodes have the needed pool of resources, and it’s the job of <code>kube-scheduler</code> to be the matchmaker between nodes and Pods. The scheduler performs state matching whenever a new Pod resource is created (3), and checks whether the Pod has an assigned node. If not, the scheduler makes the calculations needed to find an available node. It examines the requirements for the Pod, scores the available nodes using an internal set of rules, and selects a node to run the Pod (4). This is where the real work of container orchestration in Kubernetes gets done.</p>&#13;
<p><a contenteditable="false" data-primary="Karau, Holden" data-type="indexterm" id="idm46183195502640"/><a contenteditable="false" data-primary="“Analytics on Kubernetes Is the Next Frontier” (Karau)" data-primary-sortas="analytics" data-type="indexterm" id="idm46183196136960"/>However, we have a problem with analytic workloads: the default Kubernetes scheduler was not designed for batch workloads. The design is just too basic to work the way that’s needed for analytics. As mentioned in <a data-type="xref" href="#analytics_on_kubernetes_is_the_next_fro">“Analytics on Kubernetes Is the Next Frontier”</a>, Kubernetes was built for the needs of stateless workloads. These are long-running processes that may expand or contract over time but tend to remain relatively static. Analytic applications such as Spark are different, requiring the scheduling of potentially thousands of short-lived jobs.</p>&#13;
<p>Thankfully, the developers of Kubernetes anticipated expanded requirements for future scheduling needs and made it possible for users to specify their scheduler in a configuration, bypassing the default scheduling approach.</p>&#13;
<p>The strong desire to manage the entire application stack with a common control plane has been an innovation driver. As demonstrated in <a data-type="xref" href="#deploying_apache_spark_in_kubernetes">“Deploying Apache Spark in Kubernetes”</a>, Spark has been moving closer to Kubernetes. In this section, we’ll look at how some teams have been bringing Kubernetes closer to Spark by building more appropriate schedulers. Two open source projects are leading the way in this effort: Volcano and Apache YuniKorn. These schedulers share similar guiding principles that make them more appropriate for batch workloads by providing the following alternative features:</p>&#13;
<dl>&#13;
<dt>Multitenant resource management</dt>&#13;
<dd><p><a contenteditable="false" data-primary="multitenancy" data-type="indexterm" id="idm46183195664464"/>The default Kubernetes scheduler allocates Pods as requested until no more available resources match Pod requirements. Both YuniKorn and Volcano provide a wide variety of resourcing modes to match your application needs better, especially in multitenant environments. Fairness in resource management prevents one analytic Job from starving out other Jobs for required resources. As these Jobs are scheduled, the entire resource pool is considered to balance utilization based on priority and throughput.</p>&#13;
<p><em>Gang scheduling</em> adds another layer of intelligence. If a submitted Job needs a certain amount of resources, it doesn’t make sense to start the Job if every Pod can’t be started. The default scheduler will start Pods until the cluster runs out of resources, potentially stranding Jobs as they wait for more Pods to come online. Gang scheduling implements an all-or-nothing approach, as Jobs will start only when all resources needed are available for the complete Job.</p></dd>&#13;
<dt>Job queue management</dt>&#13;
<dd><a contenteditable="false" data-primary="job queue management" data-type="indexterm" id="idm46183198604640"/>Smarter queue management can also lead to better resource management. If one Job needs few resources and can be run while larger Jobs are being run, the scheduler can fit the Job in and therefore increase the Kubernetes cluster’s overall throughput. In some cases, users need control over what Jobs have priority and which can preempt or pause other running Jobs as they are submitted. Queues can be reordered or reprioritized after Jobs are submitted. Observability tooling provides queue insights that help determine total cluster health and resource usage.</dd>&#13;
</dl>&#13;
<p>If you are considering a production deployment of analytic workloads, you should avoid using the default scheduler, <code>kube-scheduler</code>. It wasn’t designed for your needs in this case. Starting with a better scheduler lets you future-proof your Kubernetes experience. Let’s examine some highlights of each scheduler.</p>&#13;
<section data-pdf-bookmark="Apache YuniKorn" data-type="sect2"><div class="sect2" id="apache_yunikorn">&#13;
<h2>Apache YuniKorn</h2>&#13;
<p><a contenteditable="false" data-primary="Apache YuniKorn" data-type="indexterm" id="idm46183195441728"/><a contenteditable="false" data-primary="data analytics" data-secondary="Apache YuniKorn" data-type="indexterm" id="idm46183195589296"/><a contenteditable="false" data-primary="Cloudera" data-type="indexterm" id="idm46183195587888"/>The <em>YuniKorn project</em> was built by engineers from Cloudera out of the operational frustration of working with analytic workloads in Spark. In the spirit of using open source to solve problems as a community, YuniKorn was donated to the Apache Software Foundation and accepted as an incubating project in 2020. The name comes directly from the two systems it supports, YARN and Kubernetes. (Y unified K. YuniKorn. Get it?) It addresses the specific resource management and user control needs of analytic workloads from a Spark cluster administration point of view. YuniKorn also added support for TensorFlow and Flink jobs with the same level of resource control. No doubt, this support was born of the same operation frustrations found in Spark.</p>&#13;
<p>YuniKorn is <a href="https://yunikorn.apache.org/docs">installed</a> in Kubernetes using Helm. The goal of YuniKorn is to transform your Kubernetes cluster into a place that is friendly to the resource requirements of batch Jobs. A key part of that transformation is replacing the default <code>kube-scheduler</code>. To demonstrate how, let’s use <a data-type="xref" href="#yunikorn_architecture">Figure 9-6</a> to walk through the components.</p>&#13;
&#13;
<p>YuniKorn is meant to be a drop-in scheduler replacement with minimal changes to your existing Spark workflow, so we will start there. When new resource requests (1) are sent to the Kubernetes API server via <code>spark-submit</code> (2), the default <code>kube-scheduler</code> (3) is typically used to match Pods and nodes. When YuniKorn is deployed in your cluster, an <code>admissions-controller</code> Pod is created.  The function of the <code>admissions-controller</code> is to listen for new resource requests (4) and make a small change, adding <code>schedulerName: yunikorn</code> to the resource request. If you need more fine-grained control, you can disable the <code>admissions-controller</code> and enable YuniKorn on a per Job basis by manually adding the following line to the SparkApplication YAML:</p>&#13;
<pre data-type="programlisting">spec:&#13;
schedulerName: yunikorn</pre>&#13;
&#13;
<figure><div class="figure" id="yunikorn_architecture">&#13;
<img alt="YuniKorn architecture" src="assets/mcdk_0906.png"/>&#13;
<h6><span class="label">Figure 9-6. </span>YuniKorn architecture</h6>&#13;
</div></figure>&#13;
&#13;
<p>All scheduling needs will now be handled by the YuniKorn Scheduler (5). YuniKorn is built to run with multiple orchestration engines and provides an API translation layer called <em>Kubernetes shim</em> to manage communication between Kubernetes and the YuniKorn core (6). yunikorn-core extends the basic filter and score algorithm available in the default <code>kube-scheduler</code> by adding options appropriate for batch workloads such as Spark. These options range from simple resource-based queues to more advanced hierarchical queue management that allows for queues and resource pools to map to organizational structures. Hierarchical pooling can be helpful for those with a massive analytics footprint across many parts of a large enterprise and is critical for multitenant environments when running in a single Kubernetes cluster.</p>&#13;
<p>YuniKorn core is <a href="https://oreil.ly/2Tp19">configured</a> using the <em>queues.yaml</em> file, which contains all the details of how YuniKorn will schedule Pods to nodes, including the following:</p>&#13;
<dl>&#13;
<dt>Partitions</dt>&#13;
<dd><a contenteditable="false" data-primary="partitions (YuniKorn)" data-type="indexterm" id="idm46183195679344"/>One or more named <a href="https://oreil.ly/kxtHf">configuration sections</a> for different application requirements.</dd>&#13;
<dt>Queues</dt>&#13;
<dd><a contenteditable="false" data-primary="queues" data-type="indexterm" id="idm46183195393984"/>Fine-grained <a href="https://oreil.ly/M5W1A">control</a> over resources in a hierarchical arrangement to provide resource guarantees in a multitenant environment.</dd>&#13;
</dl>&#13;
&#13;
<dl class="pagebreak-before">&#13;
<dt>Node sort policy</dt>&#13;
<dd><a contenteditable="false" data-primary="node sort policy (YuniKorn)" data-type="indexterm" id="idm46183195368496"/>How Nodes are selected by available resources. Choices are <a href="https://oreil.ly/RUI7q">FairnessPolicy</a> and <a href="https://oreil.ly/sED2J">BinPackingPolicy</a>.</dd>&#13;
<dt>Placement Rules</dt>&#13;
<dd><a contenteditable="false" data-primary="placement rules (YuniKorn)" data-type="indexterm" id="idm46183195364112"/>Description and <a href="https://oreil.ly/sHvMP">filters</a> for Pod placement based on user or group membership.</dd>&#13;
<dt>Limits</dt>&#13;
<dd><a contenteditable="false" data-primary="limits (YuniKorn)" data-type="indexterm" id="idm46183195361744"/><a href="https://oreil.ly/ytYU9">Definitions</a> for fine-grained resource limits on partitions or queues.</dd>&#13;
</dl>&#13;
<p>New Jobs are processed by YuniKorn core by matching details and assigning the right queue.  At this point, the scheduler can make a decision to assign Pods to nodes, which are then brought online (7).</p>&#13;
<p>YuniKorn also ships with an observability web-based tool called <em>scheduler UI</em> that provides insights into Job and queue status. It can be used to monitor scheduler health and provide better insights to troubleshoot any Job issues.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Volcano" data-type="sect2"><div class="sect2" id="volcano">&#13;
<h2>Volcano</h2>&#13;
<p><a contenteditable="false" data-primary="HPC (high performance computing)" data-type="indexterm" id="idm46183195356432"/><a contenteditable="false" data-primary="data analytics" data-secondary="Volcano" data-type="indexterm" id="da_vol"/><a contenteditable="false" data-primary="Volcano" data-type="indexterm" id="vol_ab"/><em>Volcano</em> was developed as a general-purpose scheduler for running high performance computing (HPC) workloads in Kubernetes. Volcano supports a variety of workloads, including Spark, Flink, PyTorch, TensorFlow, and specialized systems such as KubeGene for genome sequencing. Engineers built Volcano at Huawei, Tencent, and Baidu, to name a few of the long list of contributors. Donated to the CNCF, it was accepted as a Sandbox project in 2020.</p>&#13;
<p>Volcano is installed using Helm and creates CRDs for Jobs and queues, making the configuration a core part of your Kubernetes cluster as compared with YuniKorn, which is more of a bypass. This is a reflection of the general-purpose nature of Volcano. When installed, the Volcano scheduler is available for any process needing advanced scheduling and queuing. Let’s use <a data-type="xref" href="#volcano_architecture">Figure 9-7</a> to walk through how it works.</p>&#13;
&#13;
<p>To use Volcano with your batch Jobs, you will need to explicitly add the scheduler configuration to your Job YAML file (1). If you are using Volcano for Spark, it is <a href="https://volcano.sh/en/docs/spark_on_volcano">recommended</a> by the Volcano project to use the Spark Operator for Kubernetes and add one field to your SparkApplication YAML:</p>&#13;
<pre data-type="programlisting">spec:&#13;
batchScheduler: "volcano"</pre>&#13;
&#13;
<figure><div class="figure" id="volcano_architecture">&#13;
<img alt="Volcano architecture" src="assets/mcdk_0907.png"/>&#13;
<h6><span class="label">Figure 9-7. </span>Volcano architecture</h6>&#13;
</div></figure>&#13;
&#13;
<p>You can then use <code>kubectl apply</code> as you normally would to submit your Job (2). Without specifying the Volcano scheduler, Kubernetes will match Pods and nodes with the default <code>kube-scheduler</code> (3).</p>&#13;
<p>A Helm installation of Volcano will install the CRDs for Job, queue, and PodGroup and create a new Pod called Volcano Admission. Volcano Admission (4) attaches to the API server and validates Volcano-specific CRD entries and Jobs asking for the Volcano scheduler:</p>&#13;
<dl>&#13;
<dt>Job</dt>&#13;
<dd><a contenteditable="false" data-primary="jobs (Volcano)" data-type="indexterm" id="idm46183195484032"/>A Volcano-specific Job with extended <a href="https://oreil.ly/CknE0">configuration</a> for HPC.</dd>&#13;
<dt>Queue</dt>&#13;
<dd><a contenteditable="false" data-primary="queues" data-type="indexterm" id="idm46183195340192"/>A collection of PodGroups to be managed as a first in, first out (FIFO) resource group. <a href="https://oreil.ly/MW2xq">Configuration</a> dictates the behavior of the queue for different situations.</dd>&#13;
<dt>PodGroup</dt>&#13;
<dd><a contenteditable="false" data-primary="PodGroup (Volcano)" data-type="indexterm" id="idm46183195338960"/>A collection of Pods related to their purpose. Examples would be groups for Spark and TensorFlow with different <a href="https://oreil.ly/LzeBj">properties</a> for each.</dd>&#13;
</dl>&#13;
<p>When selected as the scheduler for a Job (5), the Volcano scheduler will take the CRDs and start to work (6). Incoming Jobs marked to use Volcano as the scheduler are matched with a PodGroup and queue. Based on this assignment, a final node placement is made for each Pod (7).</p>&#13;
<p>The cluster-specific configuration for the Volcano scheduler core is stored in a ConfigMap named <code>volcano-scheduler-configmap</code>. This config file contains two main sections: <code>actions</code> and <code>plugins</code>. <a href="https://oreil.ly/frTKk">Actions</a> are an ordered list of each step in the node selection for each Job: enqueue, allocate, preempt, reclaim, and backfill. Each step is optional and can be reordered to match the type of work that needs to be performed.</p>&#13;
<p>Plug-ins are the algorithms used to match Pods with nodes. Each has a different use case and purpose and can be combined as an ensemble:</p>&#13;
<dl>&#13;
<dt>Gang</dt>&#13;
<dd><a contenteditable="false" data-primary="Gang plug-in" data-type="indexterm" id="idm46183195328944"/>This plug-in looks for higher-priority tasks in the queue and performs preemption and eviction if needed to free up resources for them.</dd>&#13;
<dt>BinPack</dt>&#13;
<dd><a contenteditable="false" data-primary="BinPack plug-in" data-type="indexterm" id="idm46183195724816"/><a contenteditable="false" data-primary="plug-ins" data-type="indexterm" id="idm46183195326608"/>This is a classic algorithm for finding the best fit for using every resource available by mixing different-size resource requests in the most efficient manner.</dd>&#13;
<dt>Conformance</dt>&#13;
<dd><a contenteditable="false" data-primary="Conformance plug-in" data-type="indexterm" id="idm46183195482688"/>This ignores any task in the Namespace <code>kube-system</code> for eviction decisions.</dd>&#13;
<dt>Dominant Resource Fairness (DRF)</dt>&#13;
<dd><a contenteditable="false" data-primary="DRF (Dominant Resource Fairness) plug-in" data-type="indexterm" id="idm46183195321792"/>This is an algorithm to address issues of fairness across multiple resource types to ensure that all Jobs have equal throughput.</dd>&#13;
<dt>Proportion</dt>&#13;
<dd><a contenteditable="false" data-primary="Proportion plug-in" data-type="indexterm" id="idm46183195327600"/>This is a multitenant algorithm to allocate dedicated portions of cluster allocation for running Jobs.</dd>&#13;
<dt>Task-topology</dt>&#13;
<dd><a contenteditable="false" data-primary="Task-topology plug-in" data-type="indexterm" id="idm46183195318128"/>This algorithm uses affinity to put network-intensive Jobs physically closer together for more efficient network use.</dd>&#13;
<dt>NodeOrder</dt>&#13;
<dd><a contenteditable="false" data-primary="NodeOrder plug-in" data-type="indexterm" id="idm46183195314304"/>This plug-in takes multiple user-defined dimensions to score every available node before selection.</dd>&#13;
<dt>Predicate</dt>&#13;
<dd><a contenteditable="false" data-primary="Predicate plug-in" data-type="indexterm" id="idm46183195315488"/>This looks for certain predicates in nodes for selection (but currently supports only the GPU sharing predicate).</dd>&#13;
<dt>Priority</dt>&#13;
<dd><a contenteditable="false" data-primary="Priority plug-in" data-type="indexterm" id="idm46183195310080"/>This plug-in chooses task priority based on the user-supplied configuration in  <code>priorityClassName</code>, <code>createTime</code>, and <code>id</code>.</dd>&#13;
</dl>&#13;
&#13;
<dl class="pagebreak-before">&#13;
<dt>Service level agreement (SLA)</dt>&#13;
<dd><a contenteditable="false" data-primary="SLA (service level agreement) plug-in" data-type="indexterm" id="idm46183195307136"/>This uses the parameter <code>JobWaitingTime</code> to allow individual Jobs the control over priority based on when they are needed.</dd>&#13;
<dt>Time-division multiplexing (TDM)</dt>&#13;
<dd><a contenteditable="false" data-primary="TDM (time-division multiplexing) plug-in" data-type="indexterm" id="idm46183195305648"/>When nodes are used for both Kubernetes and YARN, TDM will schedule Pods that share resources in this arrangement.</dd>&#13;
<dt>NUMA-aware</dt>&#13;
<dd><a contenteditable="false" data-primary="NUMA-aware plug-in" data-type="indexterm" id="idm46183195301952"/>This provides scheduling for Pods with an awareness of CPU resource topology.</dd>&#13;
</dl>&#13;
<p><a contenteditable="false" data-primary="vcctl tool" data-type="indexterm" id="idm46183195300000"/>Outside of the Kubernetes installation, Volcano also ships with a command-line tool called <code>vcctl</code>. Managing Volcano can be done solely through the use of <code>kubectl</code>. However, <code>vcctl</code> presents an interface for operators more familiar with Job control systems.</p>&#13;
<p><a contenteditable="false" data-primary="" data-startref="alt_ab" data-type="indexterm" id="idm46183195296240"/><a contenteditable="false" data-primary="" data-startref="da_alt" data-type="indexterm" id="idm46183195295248"/><a contenteditable="false" data-primary="" data-startref="da_vol" data-type="indexterm" id="idm46183195294320"/><a contenteditable="false" data-primary="" data-startref="vol_ab" data-type="indexterm" id="idm46183195293056"/>As you can see from the list of features offered by YuniKorn and Volcano, having choices is a beautiful thing. Regardless of which project you choose, you’ll have a better experience running analytic workloads in Kubernetes with one of these alternate schedulers.</p>&#13;
</div></section>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Analytic Engines for Kubernetes" data-type="sect1"><div class="sect1" id="analytic_engines_for_kubernetes">&#13;
<h1>Analytic Engines for Kubernetes</h1>&#13;
<p><a contenteditable="false" data-primary="analytic engines" data-type="indexterm" id="ae_ab"/><a contenteditable="false" data-primary="data analytics" data-secondary="analytic engines" data-type="indexterm" id="da_ae"/><a contenteditable="false" data-primary="Kubernetes" data-secondary="analytic engines for" data-type="indexterm" id="kub_ae"/><a contenteditable="false" data-primary="MPP (massively Parallel processing)" data-type="indexterm" id="idm46183195291552"/>Spark is a powerful tool that solves many use cases in analytics. However, having just a single choice can be restrictive once that tool no longer works the way you do. Google developed MapReduce in 2004 to fill a need for data transformation, such as taking a pool of data and creating a count of the things in it, and this is still a relevant problem today given the volumes of data we create. Even before MapReduce, massively parallel processing (MPP) was a popular approach for data analysis. These “supercomputers” consisted of rows and rows of individual computers presented as a single processing grid for researchers in fields such as physics and meteorology to run massive calculations that would take far too long on a single computer.</p>&#13;
<p><a contenteditable="false" data-primary="TensorFlow" data-type="indexterm" id="idm46183195290288"/>A similar computing need arises when tackling the ML and AI tasks in analytics: many processes need to analyze a large volume of data. Libraries such as TensorFlow require analytic tools beyond data transformation. With Kubernetes, data scientists and engineers can now create virtual datacenters quickly with commodity compute, network, and storage to rival some of the supercomputers of the past. This combination of technologies brings a completely new and exciting future for developers: building ML-based and AI-based applications based on a self-service usage model without having to wait for time on a very expensive supercomputer (yes, this was a thing).</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="the_evolution_of_analytics_for_develope">&#13;
<h5>The Evolution of Analytics for Developers in a Cloud Native World</h5>&#13;
<p><em>With Dean Wampler, Product Engineering Director for Accelerated Discovery, <span class="keep-together">IBM Research</span></em></p>&#13;
<p><a contenteditable="false" data-primary="data analytics" data-secondary="evolution of" data-type="indexterm" id="idm46183195817712"/><a contenteditable="false" data-primary="developers" data-type="indexterm" id="idm46183195296912"/><a contenteditable="false" data-primary="Wampler, Dean" data-type="indexterm" id="idm46183197049152"/>There has been speculation that streaming and batch analytics will somehow converge into a single, universal approach for every project or product. I believe with Kubernetes that vision becomes less ideal as developers determine what they need to be successful, and it’s all about choosing the best tool for the job. In fact, more choices will likely become available for analyzing data that fit different use cases inside and outside of Kubernetes. Developers and data engineers will need a variety of tools to overcome limitations and trade-offs.</p>&#13;
<p>Let’s suppose you have bought into the idea that you could do everything with streams. What does that actually mean in practice and where are the limitations? Suppose I wanted to know exactly how many of each SKU I sold in every store, segmented into hourly buckets. The challenge with that calculation is some uncertainty in knowing when all the data is delivered for each hour bucket. You can’t start the Job exactly on the hour because data might still be in flight. In the worst case, some data may be significantly delayed because of network partitions or other outages. Now it’s up to the developers to build in the sophistication for provisional results, which might be calculated as quickly as possible, and then integrate corrections when late data arrives. With more diversity in data tooling, they can better solve the problem. For this example, maybe they would use Apache Flink for dashboards with some percentage of accuracy about what’s happening immediately. Data that is captured later would be used in an overnight Apache Spark Job to do the final accounting and produce the canonical results per hourly bucket. You could argue this is a much more reasonable level of sophistication based on using the simplest, correct tool for each Job, composable using Kubernetes.</p>&#13;
<p>At larger data scales, organizations still like using Spark for big analytics tasks. However, in a growing trend, data scientists and data engineers are starting to recognize it’s reasonable to have data in a database, rather than a data lake, as a matter of choosing the right tool for the job. Some teams will use something like Cassandra because they don’t want the complexity of keeping track of HDFS and Apache Parquet files, and they want the benefits of indexing and queries. They accept a performance hit from scanning tables versus a file. These are teams experienced in making trade-off decisions for convenience or reliability, and sometimes even for less performance. Kubernetes can encourage a more extensive choice of alternatives by reducing the up-front costs of trying new things. It’s still early days for cloud native analytics, but the leaders in this space make it work by being more agile with underlying data infrastructure.</p>&#13;
<p><a contenteditable="false" data-primary="JVM (Java Virtual Machine)" data-type="indexterm" id="idm46183195278624"/>A new generation of analytic tools is expanding the choices that can be made. With all its dominance, Spark is still very dependent on the Java Virtual Machine (JVM), and that feature is becoming a trade-off consideration. Some data engineering shops don’t want to deal with the JVM anymore: they just want to run Python, sometimes with C-based library kernels for high performance. This has created an opportunity for projects like Ray and Dask to cater directly to teams that want to use Python first. Developers gravitate to tools that help them go faster with fewer trade-offs. However, while the JVM might be a liability in some cases, Spark has enormous mindshare and years of continuous improvement. Keeping with the theme of choice, it’s easy to see how Kubernetes can help create a place where Spark and Ray could be used in the same application. Cloud native analytics could eliminate the zero-sum game of all-in-one tools.</p>&#13;
<p>The analytics convergence that people have talked about will likely happen at the interface level, giving developers a single interface with access to the appropriate tooling underneath—the right mix of services for a cloud native world. Batch offline analytics with data warehouses augmented with online databases. Streaming analytics that provide real-time updates to the same data used for the batch Jobs. All are provided as services deployed in Kubernetes. The most important factor is the easy access it provides. Citizen data scientists can use Microsoft Excel to explore data. Visualization tools can connect to any underlying service with low or no code. Python is increasingly the language of choice for data engineers and scientists building pipelines. Support for SQL across streaming and batch analytics has remained universally popular, leveraging a data language that has been the standard for decades. Kubernetes will have to support this by enabling the fine-grained concurrency within a single process that some data processing systems require while leveraging Pod boundaries for big chunks of resources. It’s a balance of trade-offs. The winner will be the developers and data scientists who no longer have to worry about making bad tool choices, allowing them to spend more time writing code that creates value.</p>&#13;
</div></aside>&#13;
<p>Access via the right APIs and ability via the right infrastructure built on Kubernetes is a powerful combination that the data science and Python community has been working to make a reality. Two new projects are already making a mark: Dask and Ray. As pointed out by Dean, Python is the preferred language for data science. Both Ray and Dask provide a native Python interface for massively parallel processing both inside and outside of Kubernetes.</p>&#13;
<section data-pdf-bookmark="Dask" data-type="sect2"><div class="sect2" id="dask">&#13;
<h2>Dask</h2>&#13;
<p><a href="https://www.dask.org">Dask</a> is a Python-based clustering tool for large-scale processing that abstracts away the complicated setup steps. It can be used for anything that you can express in a Python program but has found a real home in data science with the countless libraries available. scikit-learn, NumPy, TensorFlow, and Pandas are all mature data science libraries that can be used on a laptop and then scaled to a massive cluster of computers thanks to Dask.<a contenteditable="false" data-primary="Dask" data-type="indexterm" id="idm46183195840960"/><a contenteditable="false" data-primary="data analytics" data-secondary="Dask" data-type="indexterm" id="idm46183195457792"/></p>&#13;
<p>Dask integrates nicely with Kubernetes to provide the easy user experience that operators and developers have come to expect with Python. The Dask storage primitives Array, DataFrame, and Bag map to many cloud native storage choices. For example, you could map a DataFrame to a file stored in a PersistentVolume or an object bucket such as S3. Your storage scale is limited only by the underlying resources and your budget. As the Python code is working with your data, Dask manages the chunking across multiple workers seamlessly.</p>&#13;
<p>Deployment options include the manual Helm install we are now familiar with from <a data-type="xref" href="ch04.html#automating_database_deployment_on_kuber">Chapter 4</a>, as you can see in this example:</p>&#13;
<pre data-type="programlisting"><strong>helm repo add dask https://helm.dask.org/</strong>&#13;
<strong>helm repo update</strong>&#13;
<strong>helm install my-dask dask/dask</strong></pre>&#13;
<p>Or as an alternative, you can install a Dask cluster in Kubernetes with a Jupyter Notebook instance for working inside the cluster:</p>&#13;
<pre data-type="programlisting"><strong>helm install my-dask dask/daskhub</strong></pre>&#13;
<p>Once your Dask cluster is running inside Kubernetes, you can connect as a client and run your Python code across the compute nodes using the <code>HelmCluster</code> object. Connect using the name you gave your cluster given at the time of installation:</p>&#13;
<pre data-type="programlisting">from dask_kubernetes import HelmCluster&#13;
from dask.distributed import Client&#13;
&#13;
# Connect to the name of the helm installation&#13;
cluster = HelmCluster(release_name="my-dask")&#13;
&#13;
# specify the number of workers(pods) explicitly&#13;
cluster.scale(10)&#13;
&#13;
# or dynamically scale based on current workload&#13;
cluster.adapt(minimum=1, maximum=100)&#13;
&#13;
# Your Python code here</pre>&#13;
<p>If that wasn’t easy enough, you can completely skip the Helm installation and just let Dask do that part for you. The <code>KubeCluster</code> object takes an argument specifying the Pod configuration either using a <code>make_pod_spec</code> method or specifying a YAML configuration file. It will connect to the default Kubernetes cluster accessible via <code>kubectl</code> and invoke the cluster creation inside your Kubernetes cluster as a part of the running Python program:</p>&#13;
<pre data-type="programlisting">from dask.distributed import Client&#13;
from dask_kubernetes import KubeCluster, make_pod_spec&#13;
&#13;
pod_spec = make_pod_spec(image='daskdev/dask:latest',&#13;
                         memory_limit='4G', memory_request='4G',&#13;
                         cpu_limit=1, cpu_request=1)&#13;
&#13;
cluster = KubeCluster(pod_spec)&#13;
&#13;
# specify the number of workers(pods) explicitly&#13;
cluster.scale(10)&#13;
&#13;
# or dynamically scale based on current workload&#13;
cluster.adapt(minimum=1, maximum=100)&#13;
&#13;
# Connect Dask to the cluster&#13;
client = Client(cluster)&#13;
&#13;
# Your Python code here</pre>&#13;
<p>Developer access to Kubernetes clusters for parallel computing couldn’t get much easier, and this is the appeal new tools like Dask can provide.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Ray" data-type="sect2"><div class="sect2" id="ray">&#13;
<h2>Ray</h2>&#13;
<p><a contenteditable="false" data-primary="Ray" data-type="indexterm" id="idm46183195745312"/><a contenteditable="false" data-primary="data analytics" data-secondary="Ray" data-type="indexterm" id="idm46183195239296"/>In a significant difference from the arbitrary Python code in Dask, <em>Ray</em> takes a different approach to Python clustering by operating as a parallel task manager that includes a distributed computing framework with a large <a href="https://oreil.ly/XY5rC">ecosystem of integrations</a>. For the end user, Ray provides low-level C++ libraries to run distributed code purpose-built for compute-intensive workloads typical in data science. The base is Ray Core, which does all the work of distributing workloads using the concept of a task. When developers write Python code using Ray, each task is expressed as a remote function, as shown in this example from the <a href="https://oreil.ly/gCmBs">Ray documentation</a>:</p>&#13;
<pre data-type="programlisting"># By adding the `@ray.remote` decorator, a regular Python function&#13;
# becomes a Ray remote function.&#13;
@ray.remote&#13;
def my_function():&#13;
    return 1</pre>&#13;
<p>In this basic example, you can see the difference in the approach Ray takes for distributing work. Developers have to be explicit in what work is distributed with Ray Core handling the compute management with the Cluster Manager.</p>&#13;
<p>A Ray deployment in Kubernetes is designed to leverage compute and network resource management within dynamic workloads. The Ray Operator includes a custom controller and CRD to deploy everything needed to attach code to a Ray cluster. A Helm chart is provided for easy installation. However, since the chart is unavailable in a public repository, you must first download the entire Ray distribution to your local filesystem. An extensive configuration YAML file can be modified, but to get a simple Ray cluster working, the defaults are fine, as you can see in this example from the <a href="https://oreil.ly/XjXJo">documentation</a>:</p>&#13;
<pre data-type="programlisting"><strong>cd ray/deploy/charts</strong>&#13;
<strong>helm -n ray install example-cluster --create-namespace ./ray</strong></pre>&#13;
<p>This results in the creation of two types of Pods being installed. The head node handles the communication and orchestration of running tasks in the cluster, and the Worker Node handles where tasks execute their code. With a Ray cluster running inside a Kubernetes cluster, there are two ways to run a Ray Job: interactively with the Ray client or as a Job submitted via <code>kubectl</code>.</p>&#13;
<p>The Ray client is embedded into a Python program file and initializes the connection to the Ray cluster. This requires the head service IP to be exposed through either Ingress or local port forwarding. Along with the remote function code, an initializer will establish the connection to the externalized Ray cluster host IP and port:</p>&#13;
<pre data-type="programlisting">import ray&#13;
&#13;
ray.init("ray://&lt;host&gt;:&lt;port&gt;")&#13;
&#13;
@ray.remote&#13;
def my_function():&#13;
    return 1</pre>&#13;
<p>Another option is to run your code inside the Kubernetes cluster and attach it to an internal service and port. You use <code>kubectl</code> to submit the Job to run and pass a Job description YAML file that outlines the Python program to use and Pod resource information. Here is an example Job file from the <a href="https://oreil.ly/gCmBs">Ray documentation</a>:</p>&#13;
<pre data-type="programlisting">apiVersion: batch/v1&#13;
kind: Job&#13;
metadata:&#13;
  name: ray-test-job&#13;
spec:&#13;
  template:&#13;
    spec:&#13;
      restartPolicy: Never&#13;
      containers:&#13;
        - name: ray&#13;
          image: rayproject/ray:latest&#13;
          imagePullPolicy: Always&#13;
          command: [ "/bin/bash", "-c", "--" ]&#13;
          args:&#13;
            - "wget &lt;URL&gt;/job_example.py &amp;&amp;&#13;
              python job_example.py"&#13;
          resources:&#13;
            requests:&#13;
              cpu: 100m&#13;
              memory: 512Mi</pre>&#13;
<p>This file can then be submitted to the cluster using <code>kubectl</code>:</p>&#13;
<pre data-type="programlisting"><strong>kubectl -n ray create -f job-example.yaml</strong></pre>&#13;
<p class="pagebreak-before">Inside the Python file submitted, we can use the DNS name of the Ray service head and let Kubernetes ensure that the network path is routed:</p>&#13;
<pre data-type="programlisting">ray.init("ray://example-cluster-ray-head:10001")</pre>&#13;
<p><a contenteditable="false" data-primary="" data-startref="ae_ab" data-type="indexterm" id="idm46183195233296"/><a contenteditable="false" data-primary="" data-startref="da_ae" data-type="indexterm" id="idm46183195216448"/><a contenteditable="false" data-primary="" data-startref="kub_ae" data-type="indexterm" id="idm46183195215232"/><a contenteditable="false" data-primary="" data-startref="da_kub" data-type="indexterm" id="idm46183195214016"/><a contenteditable="false" data-primary="" data-startref="kub_da" data-type="indexterm" id="idm46183195212800"/>For both external and internal modes of running Ray programs, the head node utilizes the Kubernetes scheduler to manage the Worker Node Pod lifecycle to complete the submitted Job. Ray provides a simple programming API for developers to utilize large-scale cluster computing without learning Kubernetes administration. SREs can create and manage Kubernetes clusters that can be easily used by data scientists using their preferred Python programming language.</p>&#13;
</div></section>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="summary-id000008">&#13;
<h1>Summary</h1>&#13;
<p>This wraps up the tour of data components in your cloud native application stack. Adding analytics completes the total data picture by enabling you to find insights in larger volumes of data that can complement other parts of your application.</p>&#13;
<p>Analytics is at the frontier of cloud native data innovation, and for this reason big data isn’t something you should assume fits into Kubernetes in the same way as other data infrastructure. Two primary differences are the volumes of data involved and the bursty nature of the workloads. Further improvements are needed to make Apache Spark run more effectively on Kubernetes, especially in the areas of Job management and storage APIs However, the knowledge is available to help you deploy with confidence today. Projects such as Apache YuniKorn and Volcano are already leading the way in open source to give Kubernetes a better foundation for analytic workloads. Emerging analytic engines such as Dask and Ray may be a better choice for your use case, and they can be used in combination with other tools.</p>&#13;
<p>While analytic workloads may not have been in your original plans for deployment in Kubernetes, they can’t be skipped if your goal is to build the complete picture of a virtual datacenter, purpose-designed to run your application.</p>&#13;
</div></section>&#13;
</div></section></body></html>