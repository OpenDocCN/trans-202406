<html><head></head><body><section class="preface" data-pdf-bookmark="Chapter 1. Service Mesh 101" data-type="chapter" epub:type="chapter"><div class="preface" id="LUAR_service_mesh_101">
<h1 class="calibre7"><span class="calibre">Chapter 1. </span>Service Mesh 101</h1>


<p class="author1">Linkerd is the first service mesh—in fact,<a data-primary="service meshes" data-secondary="Linkerd as first" data-type="indexterm" id="id337" class="calibre4"/><a data-primary="Linkerd" data-secondary="as first service mesh" data-secondary-sortas="first service mesh" data-type="indexterm" id="id338" class="calibre4"/><a data-primary="Buoyant, Inc." data-secondary="Linkerd as first service mesh" data-type="indexterm" id="id339" class="calibre4"/><a data-primary="Linkerd" data-secondary="about" data-type="indexterm" id="id340" class="calibre4"/><a data-primary="monolithic applications" data-secondary="microservices architecture versus" data-type="indexterm" id="id341" class="calibre4"/><a data-primary="microservices architecture" data-secondary="monolithic applications versus" data-type="indexterm" id="id342" class="calibre4"/> it’s the project that coined
the term “service mesh.” It was created in 2015 by Buoyant, Inc., as we’ll
discuss more in <a data-type="xref" href="ch02.html#LUAR_intro_to_linkerd" class="calibre4">Chapter 2</a>, and for all that time it’s been
focused on making it easier to produce and operate truly excellent
cloud native software.</p>

<p class="author1">But what, exactly, is a service mesh? We can start with the definition from
the <a href="https://oreil.ly/dgNqN" class="calibre4">CNCF Glossary</a>:<a data-primary="service meshes" data-secondary="about" data-tertiary="definition" data-type="indexterm" id="id343" class="calibre4"/><a data-primary="microservices architecture" data-secondary="service mesh definition" data-type="indexterm" id="id344" class="calibre4"/><a data-primary="service meshes" data-secondary="about" data-type="indexterm" id="id345" class="calibre4"/><a data-primary="communication" data-secondary="unreliable as microservice norm" data-type="indexterm" id="id346" class="calibre4"/><a data-primary="reliability" data-secondary="service mesh functionality" data-type="indexterm" id="id347" class="calibre4"/><a data-primary="security" data-secondary="service mesh functionality" data-type="indexterm" id="id348" class="calibre4"/><a data-primary="service meshes" data-secondary="basic mesh functionality" data-tertiary="security" data-type="indexterm" id="id349" class="calibre4"/><a data-primary="service meshes" data-secondary="basic mesh functionality" data-tertiary="reliability" data-type="indexterm" id="id350" class="calibre4"/><a data-primary="microservices architecture" data-secondary="reliability" data-type="indexterm" id="id351" class="calibre4"/><a data-primary="service meshes" data-secondary="basic mesh functionality" data-tertiary="observability" data-type="indexterm" id="id352" class="calibre4"/><a data-primary="observability" data-secondary="service mesh functionality" data-type="indexterm" id="id353" class="calibre4"/><a data-primary="microservices architecture" data-secondary="security" data-type="indexterm" id="id354" class="calibre4"/><a data-primary="microservices architecture" data-secondary="observability" data-type="indexterm" id="id355" class="calibre4"/></p>
<blockquote class="pcalibre1 calibre21 pcalibre2">
<p class="calibre22">In a microservices world, apps are broken down into multiple smaller
services that communicate over a network. Just like your wifi network,
computer networks are intrinsically unreliable, hackable, and often slow.
Service meshes address this new set of challenges by managing traffic (i.e.,
communication) between services and adding reliability, observability, and
security features uniformly across all services.</p></blockquote>

<p class="author1">The cloud native world is all about computing at a huge range of scales, from tiny clusters running on your laptop for development up through the kind of massive infrastructure that Google and Amazon wrangle. This works best when applications use the microservices architecture, but the microservices architecture is inherently more fragile than a monolithic architecture.</p>

<p class="author1">Fundamentally, service meshes are about hiding that fragility from the
application developer—and, indeed, from the application itself. They do
this by taking several features that are critical when creating robust
applications and moving them from the application into the infrastructure.
This allows application developers to focus on what makes their applications
unique, rather than having to spend all their time worrying about how to
provide the critical functions that should be the same across all
applications.</p>

<p class="author1">In this chapter, we’ll take a high-level look at what service meshes do, how
they work, and why they’re important. In the process, we’ll provide the
background you need for our more detailed discussions about Linkerd in the
rest of the book.</p>






<section data-pdf-bookmark="Basic Mesh Functionality" data-type="sect1" class="preface"><div class="preface" id="id1">
<h1 class="calibre8">Basic Mesh Functionality</h1>

<p class="author1">The critical functions provided by<a data-primary="service meshes" data-secondary="basic mesh functionality" data-type="indexterm" id="id356" class="calibre4"/> services meshes fall into three broad categories: <em class="hyperlink">security</em>, <em class="hyperlink">reliability</em>, and <em class="hyperlink">observability</em>. As we examine these three categories, we’ll be comparing the way they play out in a typical monolith and in a microservices application.</p>

<p class="author1">Of course, “monolith” can mean<a data-primary="monolithic applications" data-type="indexterm" id="id357" class="calibre4"/> several different things. <a data-type="xref" href="#monolith-diagram" class="calibre4">Figure 1-1</a> shows a diagram of the “typical” monolithic application that we’ll be considering.</p>

<figure class="calibre23"><div class="figure" id="monolith-diagram">
<img alt="luar 0101" src="assets/luar_0101.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-1. </span>A monolithic application</h6>
</div></figure>

<p class="author1">The monolith is a single process within the operating system, which means that
it gets to take advantage of all the protection mechanisms offered by the
operating system; other processes can’t see anything inside the monolith, and
they <em class="hyperlink">definitely</em> can’t modify anything inside it. <a data-primary="communication" data-secondary="monolith function calls" data-type="indexterm" id="id358" class="calibre4"/>Communications between
different parts of the monolith are typically function calls within the
monolith’s single memory space, so again there’s no opportunity for any other
process to see or alter these communications. It’s true that one area of the
monolith can alter the memory in use by other parts—in fact, this is a huge
source of bugs!—but these are generally just errors, rather than attacks.</p>
<div data-type="note" epub:type="note" class="calibre16"><h1 class="calibre26">Multiple Processes Versus Multiple Machines</h1>
<p class="author1">“But wait!” we hear you cry. “Any operating system worthy of the name can provide protections that do span more than one process! What about memory-mapped files or System V shared memory segments? What about the loopback interface and Unix domain sockets (to stretch the point a bit)?”</p>

<p class="author1">You’re right: these mechanisms can allow multiple processes to cooperate and
share information while still being protected by the operating system.
However, they must be explicitly coded into the application, and they only
function on a <em class="hyperlink">single machine</em>. <a data-primary="Kubernetes" data-secondary="multiple processes versus multiple machines" data-type="indexterm" id="id359" class="calibre4"/>Part of the power of cloud native
orchestration systems like Kubernetes is that they’re allowed to schedule Pods
on any machine in your cluster, and you won’t know which machine ahead of
time. This is tremendously flexible, but it also means that mechanisms that
assume everything is on a single machine simply won’t work in the
cloud native world.</p>
</div>

<p class="author1">In contrast, <a data-type="xref" href="#microservices-diagram" class="calibre4">Figure 1-2</a> shows the corresponding microservices
application.</p>

<figure class="calibre23"><div class="figure" id="microservices-diagram">
<img alt="luar 0102" src="assets/luar_0102.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-2. </span>A microservices application</h6>
</div></figure>

<p class="author1">With microservices, things are different. Each microservice is a separate
process, and microservices communicate only over the network—but the
protection mechanisms provided by the operating system function only <em class="hyperlink">inside</em>
a process. These mechanisms aren’t enough in a world where any information shared
between microservices has to travel over the network.</p>

<p class="author1">This reliance on communications over<a data-primary="communication" data-secondary="unreliable as microservice norm" data-type="indexterm" id="id360" class="calibre4"/> the unreliable, insecure network raises a
<em class="hyperlink">lot</em> of concerns when developing microservices applications.</p>








<section data-pdf-bookmark="Security" data-type="sect2" class="preface"><div class="preface" id="security_ch01_LUAR_service_mesh_101_1712598114301">
<h2 class="calibre27">Security</h2>

<p class="author1">Let’s start with the fact that the<a data-primary="service meshes" data-secondary="basic mesh functionality" data-tertiary="security" data-type="indexterm" id="id361" class="calibre4"/><a data-primary="security" data-secondary="service mesh functionality" data-type="indexterm" id="id362" class="calibre4"/><a data-primary="communication" data-secondary="unreliable as microservice norm" data-tertiary="security issues" data-type="indexterm" id="id363" class="calibre4"/><a data-primary="microservices architecture" data-secondary="security" data-type="indexterm" id="id364" class="calibre4"/> network is inherently insecure. This gives
rise to a number of possible issues, some of which are shown in
<a data-type="xref" href="#insecure-communications" class="calibre4">Figure 1-3</a>.</p>

<figure class="calibre23"><div class="figure" id="insecure-communications">
<img alt="luar 0103" src="assets/luar_0103.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-3. </span>Communication is a risky business</h6>
</div></figure>

<p class="author1">Some of the most significant security issues are <em class="hyperlink">eavesdropping</em>, <em class="hyperlink">tampering</em>,
<em class="hyperlink">identity theft</em>, and <em class="hyperlink">overreach</em>:</p>
<dl class="calibre10">
<dt class="calibre11">Eavesdropping</dt>
<dd class="calibre12">
<p class="calibre13">Evildoers may be able to intercept<a data-primary="security" data-secondary="eavesdropping" data-type="indexterm" id="id365" class="calibre4"/><a data-primary="eavesdropping as security issue" data-type="indexterm" id="id366" class="calibre4"/> communications between two microservices, reading communications not intended for them. Depending on what exactly an evildoer learns, this could be a minor annoyance or a major disaster.</p>

<p class="calibre13">The typical protection against<a data-primary="encryption" data-secondary="eavesdropping as security issue" data-type="indexterm" id="id367" class="calibre4"/> eavesdropping is <em class="hyperlink">encryption</em>, which scrambles the data so that only the intended recipient can understand it.</p>
</dd>
<dt class="calibre11">Tampering</dt>
<dd class="calibre12">
<p class="calibre13">An evildoer might also be able to<a data-primary="tampering as security issue" data-type="indexterm" id="id368" class="calibre4"/><a data-primary="security" data-secondary="tampering" data-type="indexterm" id="id369" class="calibre4"/> modify the data in transit over the network. At its simplest, the tampering attack would simply corrupt the data in transit; at its most subtle, it would modify the data to be advantageous to the attacker.</p>

<p class="calibre13">It’s <em class="hyperlink">extremely</em> important to understand<a data-primary="encryption" data-secondary="tampering not protected against" data-type="indexterm" id="id370" class="calibre4"/><a data-primary="integrity checks against tampering" data-type="indexterm" id="id371" class="calibre4"/> that encryption alone will <em class="hyperlink">not</em> protect against tampering! The proper protection is to use <em class="hyperlink">integrity checks</em> like checksums; all well-designed cryptosystems include integrity checks as part of their protocols.</p>
</dd>
<dt class="calibre11">Identity theft</dt>
<dd class="calibre12">
<p class="calibre13">When you hand off credit card details<a data-primary="security" data-secondary="identity theft" data-type="indexterm" id="id372" class="calibre4"/><a data-primary="identity theft as security issue" data-type="indexterm" id="id373" class="calibre4"/> to your payment microservice, how do you know for certain that you’re really talking to your payment microservice? If an evildoer can successfully pretend to be one of your microservices, that opens the door to all manner of troublesome possibilities.</p>

<p class="calibre13">Strong <em class="hyperlink">authentication</em> is critical to<a data-primary="authentication" data-secondary="identity theft as security issue" data-type="indexterm" id="id374" class="calibre4"/> protect against this type of attack. It’s the only way to be sure that the microservice you’re talking to is really the one you think 
<span class="calibre">it is.</span></p>
</dd>
<dt class="calibre11">Overreach</dt>
<dd class="calibre12">
<p class="calibre13">On the flip side of identity theft, an evildoer<a data-primary="security" data-secondary="microservice overreach" data-type="indexterm" id="id375" class="calibre4"/><a data-primary="microservices architecture" data-secondary="microservice overreach as security issue" data-type="indexterm" id="id376" class="calibre4"/> may be able to take advantage
of a place where a microservice is allowed to do things that it simply
shouldn’t be allowed to do. Imagine, for example, an evildoer finding that the
payment microservice is perfectly happy to accept requests from the
microservice that should merely be listing things for sale.</p>

<p class="calibre13">Careful attention to <em class="hyperlink">authorization</em> is the<a data-primary="authorization" data-secondary="microservice overreach as security issue" data-type="indexterm" id="id377" class="calibre4"/><a data-primary="principle of least privilege" data-type="indexterm" id="id378" class="calibre4"/><a data-primary="authorization" data-secondary="principle of least privilege" data-type="indexterm" id="id379" class="calibre4"/> key here. In a perfect world, every microservice will be able to do exactly what it needs, and no more (the <em class="hyperlink">principle of least privilege</em>).</p>
</dd>
</dl>
</div></section>








<section data-pdf-bookmark="Reliability" data-type="sect2" class="preface"><div class="preface" id="id3">
<h2 class="calibre27">Reliability</h2>

<p class="author1">Reliability in the monolith world typically<a data-primary="service meshes" data-secondary="basic mesh functionality" data-tertiary="reliability" data-type="indexterm" id="id380" class="calibre4"/><a data-primary="reliability" data-secondary="service mesh functionality" data-type="indexterm" id="id381" class="calibre4"/><a data-primary="monolithic applications" data-secondary="reliability" data-type="indexterm" id="id382" class="calibre4"/><a data-primary="microservices architecture" data-secondary="reliability" data-type="indexterm" id="id383" class="calibre4"/><a data-primary="communication" data-secondary="unreliable as microservice norm" data-type="indexterm" id="id384" class="calibre4"/><a data-primary="reliability" data-secondary="monoliths" data-type="indexterm" id="id385" class="calibre4"/> refers to how well the monolith functions: when the different parts of the monolith communicate with function calls, you don’t typically have to worry about a call getting lost or about one of your functions suddenly becoming unresponsive! But, as shown in <a data-type="xref" href="#unreliable-communications" class="calibre4">Figure 1-4</a>, unreliable communications are actually <em class="hyperlink">the norm</em> with microservices.</p>

<figure class="calibre23"><div class="figure" id="unreliable-communications">
<img alt="luar 0104" src="assets/luar_0104.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-4. </span>Unreliable communications are the norm</h6>
</div></figure>

<p class="author1">There are quite a few ways microservices can be unreliable, including:<a data-primary="communication" data-secondary="unreliable as microservice norm" data-tertiary="reliability issues" data-type="indexterm" id="id386" class="calibre4"/><a data-primary="reliability" data-secondary="service mesh functionality" data-tertiary="reliability issues" data-type="indexterm" id="id387" class="calibre4"/></p>
<dl class="calibre10">
<dt class="calibre11">Request failure</dt>
<dd class="calibre12">
<p class="calibre13">Sometimes requests made over the network fail.<a data-primary="request failure" data-secondary="reliability issue" data-type="indexterm" id="id388" class="calibre4"/> There may be any number of possible reasons, ranging from a crashed microservice to a network overload or partition. Either the application or the infrastructure needs to do something to deal with the request that failed.</p>

<p class="calibre13">In the simplest case, the mesh can<a data-primary="request failure" data-secondary="retries" data-type="indexterm" id="id389" class="calibre4"/><a data-primary="retries" data-secondary="request failure" data-type="indexterm" id="id390" class="calibre4"/><a data-primary="failure of requests" data-see="request failure" data-type="indexterm" id="id391" class="calibre4"/> simply manage <em class="hyperlink">retries</em> for the application: if the call fails because the called service dies or times out, just resend the request. This won’t always work, of course: not all requests are safe to retry, and not every failure is transient. But in many cases, simple retry logic can be used to great effect.</p>
</dd>
<dt class="calibre11">Service failure</dt>
<dd class="calibre12">
<p class="calibre13">A special case of request failures<a data-primary="services" data-secondary="reliability issues" data-tertiary="service failures" data-type="indexterm" id="id392" class="calibre4"/> comes up when it isn’t just a single instance of a microservice that crashes, but <em class="hyperlink">all</em> instances. Maybe a bad version was deployed, or maybe an entire cluster crashed. <a data-primary="failing over in service failure" data-type="indexterm" id="id393" class="calibre4"/>In these cases the mesh can help by <em class="hyperlink">failing over</em> to a backup cluster or to a known-good implementation of the service.</p>

<p class="calibre13">Again, this can’t always happen without application help (failover of stateful services can be quite complex, for example). But microservices are often designed to manage without state, in which case mesh failover can be a huge help.</p>
</dd>
<dt class="calibre11">Service overload</dt>
<dd class="calibre12">
<p class="calibre13">Another special case: sometimes<a data-primary="services" data-secondary="reliability issues" data-tertiary="service overloads" data-type="indexterm" id="id394" class="calibre4"/><a data-primary="circuit breaking" data-secondary="service overload avoided" data-type="indexterm" id="id395" class="calibre4"/> the failure happens because too many requests are piling onto the same service. In these cases, <em class="hyperlink">circuit breaking</em> can help avoid a cascade failure: if the mesh fails some requests quickly, before dependent services get involved and cause further trouble, it can help limit the damage. This is a bit of a drastic technique, but this type of enforced load shedding can dramatically increase the overall reliability of the application as a whole.</p>
</dd>
</dl>
</div></section>








<section data-pdf-bookmark="Observability" data-type="sect2" class="preface"><div class="preface" id="id4">
<h2 class="calibre27">Observability</h2>

<p class="author1">It’s difficult to see what’s going on<a data-primary="service meshes" data-secondary="basic mesh functionality" data-tertiary="observability" data-type="indexterm" id="ch01-obs" class="calibre4"/><a data-primary="observability" data-secondary="service mesh functionality" data-type="indexterm" id="ch01-obs2" class="calibre4"/><a data-primary="microservices architecture" data-secondary="observability" data-type="indexterm" id="ch01-obs3" class="calibre4"/> in any computing application: even a
slow machine, these days, operates on time scales a billion times faster than
the one we humans live by! <a data-primary="observability" data-secondary="monoliths" data-type="indexterm" id="id396" class="calibre4"/><a data-primary="monolithic applications" data-secondary="observability" data-type="indexterm" id="id397" class="calibre4"/>Within a monolith, observability is often handled
by internal logging or dashboards that collect global metrics
from many different areas of the monolith. This is much less feasible with a
microservices architecture, as we see in <a data-type="xref" href="#lack-of-observability" class="calibre4">Figure 1-5</a>—and even
if it were feasible, it wouldn’t tell the whole story.</p>

<figure class="calibre23"><div class="figure" id="lack-of-observability">
<img alt="luar 0105" src="assets/luar_0105.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-5. </span>It’s hard to work in the dark</h6>
</div></figure>

<p class="author1">In the microservices world, “observability” tends to focus more on the <em class="hyperlink">call graph</em> and the <em class="hyperlink">golden metrics</em>:<a data-primary="call graph" data-type="indexterm" id="id398" class="calibre4"/></p>
<dl class="calibre10">
<dt class="calibre11">The call graph</dt>
<dd class="calibre12">
<p class="calibre13">When looking at a microservices application, the first critical thing is
usually knowing which services are getting called by which other services.
This is the <em class="hyperlink">call graph</em>, shown in <a data-type="xref" href="#call-graph" class="calibre4">Figure 1-6</a>, and a critical thing that a
service mesh can do is to provide metrics about how much traffic is going over
each edge of the graph, how much is succeeding, how much is failing, etc.</p>

<figure class="calibre23"><div class="figure" id="call-graph">
<img alt="luar 0106" src="assets/luar_0106.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-6. </span>The call graph of an application</h6>
</div></figure>

<p class="calibre13">The call graph is a critical starting point because problems that the user sees from outside the cluster may actually be caused by problems with a single service buried deep in the graph. It’s very important to have visibility into the whole graph to be able to solve problems.</p>

<p class="calibre13">It’s also worth noting that, in specific situations, particular paths through
the graph will be relevant, as shown in <a data-type="xref" href="#call-graph-paths" class="calibre4">Figure 1-7</a>. For example,
different requests from the user may use different paths in the graph,
exercising different aspects of the workloads.</p>

<figure class="calibre23"><div class="figure" id="call-graph-paths">
<img alt="luar 0107" src="assets/luar_0107.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-7. </span>Different paths through the call graph</h6>
</div></figure>
</dd>
<dt class="calibre11">The golden metrics</dt>
<dd class="calibre12">
<p class="calibre13">There are a great many metrics that<a data-primary="golden metrics" data-type="indexterm" id="id399" class="calibre4"/><a data-primary="metrics" data-secondary="golden metrics" data-type="indexterm" id="id400" class="calibre4"/> we could collect for every microservice.
Over time, three of them have repeatedly proven especially useful in a wide
variety of situations, so much so that we now refer to them as the “golden
metrics” (as shown in <a data-type="xref" href="#golden-metrics" class="calibre4">Figure 1-8</a>):<a data-primary="latency" data-type="indexterm" id="id401" class="calibre4"/><a data-primary="traffic" data-type="indexterm" id="id402" class="calibre4"/><a data-primary="success rate of requests" data-type="indexterm" id="id403" class="calibre4"/><a data-primary="error rate of requests" data-type="indexterm" id="id404" class="calibre4"/></p>
<dl class="calibre10">
<dt class="calibre11">Latency</dt>
<dd class="calibre12">
<p class="calibre13">How long are requests taking to complete? This is typically reported as an amount of time for a certain percentage of requests to complete. For example, P95 latency indicates the time in which 95% of requests complete, so you can interpret “5 ms P95” to mean that 95% of requests complete in 5 ms or less.</p>
</dd>
<dt class="calibre11">Traffic</dt>
<dd class="calibre12">
<p class="calibre13">How many requests is a given service handling? This is typically reported as requests per second, or RPS.</p>
</dd>
<dt class="calibre11">Success rate</dt>
<dd class="calibre12">
<p class="calibre13">How many requests are succeeding? (This can also be
reported as its inverse, the <em class="hyperlink">error rate</em>.) This is typically reported as a percentage of total requests, with “success rate” often abbreviated as SR.</p>

<figure class="calibre23"><div class="figure" id="golden-metrics">
<img alt="luar 0108" src="assets/luar_0108.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-8. </span>The three golden metrics</h6>
</div></figure>
</dd>
</dl>
</dd>
</dl>
<div data-type="note" epub:type="note" class="calibre16"><h1 class="calibre26">The Original “Golden Signals”</h1>
<p class="author1">These were originally described<a data-primary="golden metrics" data-secondary="as golden signals originally" data-type="indexterm" id="id405" class="calibre4"/><a data-primary="metrics" data-secondary="golden metrics" data-tertiary="as golden signals originally" data-type="indexterm" id="id406" class="calibre4"/><a data-primary="“Monitoring Distributed Systems” (Google)" data-primary-sortas="Monitoring Distributed Systems (Google)" data-type="indexterm" id="id407" class="calibre4"/><a data-primary="Google post on monitoring distributed systems" data-type="indexterm" id="id408" class="calibre4"/> in Google’s <a href="https://oreil.ly/TGgBm" class="calibre4">“Monitoring Distributed Systems” post</a> as the four “golden signals”: latency, request rate, error rate, and saturation.
We prefer “golden metrics” because metrics are things you can directly
measure; you derive <em class="hyperlink">signals</em> (like “saturation”) from <em class="hyperlink">metrics</em>.</p>
</div>

<p class="author1">We’ll discuss these in much greater detail in <a data-type="xref" href="ch10.html#LUAR_observability" class="calibre4">Chapter 10</a>, but it’s worth noting at this point that these metrics have proven so useful that many meshes devote considerable effort to recording them—and that the service mesh is an ideal place to track them.<a data-startref="ch01-obs" data-type="indexterm" id="id409" class="calibre4"/><a data-startref="ch01-obs2" data-type="indexterm" id="id410" class="calibre4"/><a data-startref="ch01-obs3" data-type="indexterm" id="id411" class="calibre4"/></p>
</div></section>
</div></section>






<section data-pdf-bookmark="How Do Meshes Actually Work?" data-type="sect1" class="preface"><div class="preface" id="id5">
<h1 class="calibre8">How Do Meshes Actually Work?</h1>

<p class="author1">Finally, let’s take a quick look at how service meshes actually function.<a data-primary="meshes" data-see="service meshes" data-type="indexterm" id="id412" class="calibre4"/><a data-primary="service meshes" data-secondary="how they work" data-type="indexterm" id="id413" class="calibre4"/><a data-primary="communication" data-secondary="how service meshes work" data-type="indexterm" id="id414" class="calibre4"/><a data-primary="Linkerd" data-secondary="how Linkerd works" data-seealso="service meshes" data-type="indexterm" id="id415" class="calibre4"/></p>

<p class="author1">At a high level, all meshes are fundamentally doing the same job: they insert
themselves into the operating system’s network stack, take over the low-level
networking that the application is using, and mediate everything the
application does on the network. This is the only practical way to allow the
mesh to provide all the functionality it’s designed to provide without
requiring changes to the application itself.</p>

<p class="author1">Most meshes—including Linkerd—use<a data-primary="service meshes" data-secondary="how they work" data-seealso="sidecar model" data-tertiary="sidecar model" data-type="indexterm" id="id416" class="calibre4"/><a data-primary="sidecar model" data-type="indexterm" id="id417" class="calibre4"/><a data-primary="Linkerd" data-secondary="architecture" data-tertiary="sidecar model of service meshes" data-type="indexterm" id="id418" class="calibre4"/><a data-primary="architecture of Linkerd" data-secondary="sidecar model of service meshes" data-type="indexterm" id="id419" class="calibre4"/> the <em class="hyperlink">sidecar</em> model of injecting a proxy
container next to every application container (see <a data-type="xref" href="#sidecar-model" class="calibre4">Figure 1-9</a>).<sup class="calibre28"><a data-type="noteref" href="ch01.html#id420" id="id420-marker" class="calibre29">1</a></sup> Once running, the proxy
reconfigures the host’s network routing rules so that all traffic into and out
of the application container goes through the proxy. This allows the proxy to
control everything necessary for the functionality of the mesh.</p>

<figure class="calibre23"><div class="figure" id="sidecar-model">
<img alt="luar 0109" src="assets/luar_0109.png" class="calibre24"/>
<h6 class="calibre25"><span class="calibre">Figure 1-9. </span>Linkerd and the sidecar model</h6>
</div></figure>

<p class="author1">There are other models, but the sidecar model has tremendous advantages in terms of operational simplicity and security:</p>

<ul class="printings">
<li class="calibre6">
<p class="author1">From the perspective of basically everything else in the system, the
sidecar acts like it <em class="hyperlink">is</em> part of the application. In particular, this means
that all the things that the operating system does to guarantee the safety of
the application just work for the sidecar, too. This is a very, very
important characteristic: limiting the sidecar to exactly one security context
sharply limits the attack surface of the sidecar and makes it much easier to
reason about whether the things the sidecar is doing are safe.</p>
</li>
<li class="calibre6">
<p class="author1">In much the same way, managing the sidecar is exactly the same as managing any other application or service. For example, <code class="calibre9">kubectl rollout restart</code> will just work to restart an application Pod <em class="hyperlink">and its sidecar</em> as a unit.</p>
</li>
</ul>

<p class="author1">There are disadvantages too, of course. <a data-primary="Pods" data-secondary="sidecars needed by application Pods" data-type="indexterm" id="id421" class="calibre4"/>The biggest is that <em class="hyperlink">every</em> application Pod needs a sidecar container—even if your application has thousands of Pods. <a data-primary="latency" data-secondary="as sidecar issue" data-secondary-sortas="sidecar issue" data-type="indexterm" id="id422" class="calibre4"/>Another common concern is around latency: the sidecar, by definition, requires some time to process network traffic. Again, we’ll talk more about this later, but it’s worth noting up front that Linkerd goes to a lot of trouble to minimize the sidecar’s impact, and in practice Linkerd is very fast and very lightweight.</p>
</div></section>






<section class="preface" data-pdf-bookmark="So Why Do We Need This?" data-type="sect1"><div class="preface" id="id118">
<h1 class="calibre8">So Why Do We Need This?</h1>

<p class="author1">Put bluntly, <em class="hyperlink">the functionality provided by the mesh is not optional</em>. <a data-primary="service meshes" data-secondary="importance of" data-type="indexterm" id="id423" class="calibre4"/>You’re never going to hear the engineering team say “oh, we don’t need security” or “oh, reliability isn’t important” (though you might have to convince people of the need for observability—hopefully this book will help!).</p>

<p class="author1">In other words, the choice isn’t between having these three features or not:
it’s between having them provided by the mesh or needing to provide them in
the application.</p>

<p class="author1">Providing them in the application is costly. Your developers could write them by
hand, but this means a lot of fiddly application code replicated in every
microservice, which is very easy to get wrong (especially since the temptation
will always be to have senior developers focus on the crown jewels of logic
specific to your business, rather than the dreary, less visible, but equally
critical work of getting retries right). You may also run into incompatibilities
between parts of the application, especially as the application grows.</p>

<p class="author1">Alternatively, you could find libraries that implement the functionality for
you, which definitely saves development time. On the other hand, you still end up
with each and every one of your developers needing to learn how to use those
libraries, you’re limited to languages and runtimes for which you can find the
libraries, and incompatibilities are still a serious issue (suppose one
microservice upgrades the library before another one does).</p>

<p class="author1">Over time, it’s become pretty clear to us that pushing all this functionality
into the mesh, where the application developers don’t even necessarily need to
know that it exists, is the smart way to provide it—and we
think that Linkerd is the best of the meshes out there. If we haven’t
convinced you, too, by the end of the book, please reach out and let us know
where we fell short!</p>
</div></section>






<section data-pdf-bookmark="Summary" data-type="sect1" class="preface"><div class="preface" id="id311">
<h1 class="calibre8">Summary</h1>

<p class="author1">In summary, service meshes are platform-level infrastructure that provide
security, reliability, and observability uniformly across an entire
application, without requiring changes to the application itself. Linkerd was the first
service mesh, and we think it’s still the one with the best balance of power,
speed, and operational simplicity.</p>
</div></section>
<div data-type="footnotes" class="calibre30"><p data-type="footnote" id="id420" class="calibre31"><sup class="calibre32"><a href="ch01.html#id420-marker" class="calibre29">1</a></sup> The name comes from the analogy of bolting a sidecar onto a motorcycle.</p></div></div></section></body></html>