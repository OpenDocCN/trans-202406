<html><head></head><body><section data-pdf-bookmark="Chapter 4. Working with Docker Images" data-type="chapter" epub:type="chapter"><div class="chapter" id="docker_images">&#13;
<h1><span class="label">Chapter 4. </span>Working with Docker Images</h1>&#13;
&#13;
&#13;
<p>Every Linux container is based on an image.<a data-primary="OCI images" data-secondary="about" data-type="indexterm" id="idm46803155709744"/><a data-primary="Linux containers" data-secondary="Docker image runtime instance" data-type="indexterm" id="idm46803155708832"/><a data-primary="OCI images" data-secondary="about" data-tertiary="Linux container templates" data-type="indexterm" id="idm46803155707872"/> Images are the underlying definition of what gets reconstituted into a running container, much like a virtual disk becomes a VM when you start it up. Docker or <a href="https://opencontainers.org">Open Container Initiative (OCI)</a> images provide the basis for everything that you will ever deploy and run with Docker. To launch a container, you must either download a public image or create your own. <a data-primary="Linux containers" data-secondary="filesystem layers" data-type="indexterm" id="idm46803155705840"/><a data-primary="filesystem layers of Linux containers" data-type="indexterm" id="idm46803155704896"/><a data-primary="OCI images" data-secondary="filesystem layers" data-type="indexterm" id="idm46803155704160"/>You can think of the image as a single asset that primarily represents the filesystem for the container. However, in reality, every image consists of one or more linked filesystem layers that generally have a direct one-to-one mapping to each build step used to create that image.</p>&#13;
&#13;
<p>Because images are built up from individual layers,<a data-primary="Linux containers" data-secondary="filesystem layers" data-tertiary="storage backend for" data-type="indexterm" id="idm46803155702640"/><a data-primary="filesystem layers of Linux containers" data-secondary="storage backend for" data-type="indexterm" id="idm46803155701392"/><a data-primary="storage backends for filesystem layers" data-type="indexterm" id="idm46803155700432"/><a data-primary="OCI images" data-secondary="filesystem layers" data-tertiary="storage backend for" data-type="indexterm" id="idm46803155699744"/><a data-primary="Linux" data-secondary="kernel" data-tertiary="OCI image layers and" data-type="indexterm" id="idm46803155698528"/> they put special demands on the Linux kernel, which must provide the drivers that Docker needs to run the storage backend. For image management, Docker relies heavily on this storage backend, which communicates with the underlying Linux filesystem to build and manage the multiple layers that combine into a single usable image. The primary storage backends that are supported include the following:<a data-primary="overlay2" data-type="indexterm" id="idm46803155697184"/><a data-primary="Btrfs" data-type="indexterm" id="idm46803155696512"/><a data-primary="Device Mapper" data-type="indexterm" id="idm46803155695840"/></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="https://oreil.ly/r4JHY">Overlay2</a><sup><a data-type="noteref" href="ch04.html#idm46803155693712" id="idm46803155693712-marker">1</a></sup></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://btrfs.wiki.kernel.org/index.php/Main_Page">B-Tree File System (Btrfs)</a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://www.sourceware.org/dm">Device Mapper</a></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Each storage backend provides<a data-primary="copy-on-write (CoW) system" data-type="indexterm" id="idm46803155688304"/> a fast copy-on-write (CoW) system for image management. We discuss the specifics of various backends in <a data-type="xref" href="ch11.html#advanced_topics">Chapter 11</a>. For now, we’ll use the default backend and explore how images work, since they make up the basis for almost everything else that you will do with Docker, including the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Building images</p>&#13;
</li>&#13;
<li>&#13;
<p>Uploading (pushing) images to an image registry</p>&#13;
</li>&#13;
<li>&#13;
<p>Downloading (pulling) images from an image registry</p>&#13;
</li>&#13;
<li>&#13;
<p>Creating and running containers from an image</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Anatomy of a Dockerfile" data-type="sect1"><div class="sect1" id="idm46803155682320">&#13;
<h1>Anatomy of a Dockerfile</h1>&#13;
&#13;
<p>To create a custom Docker image<a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="anatomy of" data-type="indexterm" id="ch04-dockfile"/><a data-primary="OCI images" data-secondary="Dockerfile for customization" data-type="indexterm" id="ch04-dockfile2"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="about" data-tertiary="Docker image customization" data-type="indexterm" id="idm46803155677536"/> with the default tools, you will need to become familiar with the <em>Dockerfile</em>. This file describes all the steps that are required to create an image and is usually contained within the root directory of the source code repository for your application.</p>&#13;
&#13;
<p>A typical <em>Dockerfile</em> might look something like the one shown here, which creates a container for a Node.js-based application:</p>&#13;
&#13;
<pre data-code-language="dockerfile" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">node:18.13.0</code><code class="w"/>&#13;
&#13;
<code class="k">ARG</code><code class="w"> </code><code class="nv">email</code><code class="o">=</code><code class="s2">"anna@example.com"</code><code class="w"/>&#13;
<code class="k">LABEL</code><code class="w"> </code><code class="s2">"maintainer"</code><code class="o">=</code><code class="nv">$email</code><code class="w"/>&#13;
<code class="k">LABEL</code><code class="w"> </code><code class="s2">"rating"</code><code class="o">=</code><code class="s2">"Five Stars"</code><code class="w"> </code><code class="s2">"class"</code><code class="o">=</code><code class="s2">"First Class"</code><code class="w"/>&#13;
&#13;
<code class="k">USER</code><code class="w"> </code><code class="s">root</code><code class="w"/>&#13;
&#13;
<code class="k">ENV</code><code class="w"> </code>AP<code class="w"> </code>/data/app<code class="w"/>&#13;
<code class="k">ENV</code><code class="w"> </code>SCPATH<code class="w"> </code>/etc/supervisor/conf.d<code class="w"/>&#13;
&#13;
<code class="k">RUN</code><code class="w"> </code>apt-get<code class="w"> </code>-y<code class="w"> </code>update<code class="w"/>&#13;
&#13;
<code class="c"># The daemons</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>apt-get<code class="w"> </code>-y<code class="w"> </code>install<code class="w"> </code>supervisor<code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>mkdir<code class="w"> </code>-p<code class="w"> </code>/var/log/supervisor<code class="w"/>&#13;
&#13;
<code class="c"># Supervisor Configuration</code><code class="w"/>&#13;
<code class="k">COPY</code><code class="w"> </code>./supervisord/conf.d/*<code class="w"> </code><code class="nv">$SCPATH</code>/<code class="w"/>&#13;
&#13;
<code class="c"># Application Code</code><code class="w"/>&#13;
<code class="k">COPY</code><code class="w"> </code>*.js*<code class="w"> </code><code class="nv">$AP</code>/<code class="w"/>&#13;
&#13;
<code class="k">WORKDIR</code><code class="w"> </code><code class="s">$AP</code><code class="w"/>&#13;
&#13;
<code class="k">RUN</code><code class="w"> </code>npm<code class="w"> </code>install<code class="w"/>&#13;
&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"supervisord"</code><code class="p">,</code><code class="w"> </code><code class="s2">"-n"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>Dissecting this <em>Dockerfile</em> will provide some<a data-primary="supervisord" data-secondary="Dockerfile anatomy" data-type="indexterm" id="idm46803155670656"/> initial exposure to a number of the possible instructions for controlling how an image is assembled. Each line in a <em>Dockerfile</em> creates a new image layer that is stored by Docker. This layer contains all of the changes that are a result of that command being issued. This means that when you build new images, Docker will only need to build layers that deviate from previous builds: you can reuse all the layers that haven’t changed.</p>&#13;
&#13;
<p>Although you could build a Node<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Node images" data-type="indexterm" id="idm46803155572464"/><a data-primary="Node.js Docker images" data-type="indexterm" id="idm46803155571216"/><a data-primary="Node instance via Dockerfile" data-type="indexterm" id="idm46803155570544"/> instance from a plain, base Linux image, you can also explore <a href="https://registry.hub.docker.com">Docker Hub</a> for official images for Node. The Node.js community maintains a series of <a href="https://registry.hub.docker.com/_/node">Docker images</a> and tags that allow you to quickly determine what versions are available. If you want to lock the image to a specific point release of Node, you could point it at something like <code>node:18.13.0</code>. The following base image will provide you with an Ubuntu Linux image running Node 11.11.x:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/node:18.13.0</code><code class="w"/></pre>&#13;
&#13;
<p>The <code>ARG</code> parameter provides a way for you to set variables and their default values, which are only available during the image build process:</p>&#13;
&#13;
<pre data-code-language="dockerfile" data-type="programlisting"><code class="k">ARG</code><code class="w"> </code><code class="nv">email</code><code class="o">=</code><code class="s2">"anna@example.com"</code><code class="w"/></pre>&#13;
&#13;
<p>Applying labels to images and containers<a data-primary="Linux containers" data-secondary="configuring" data-tertiary="labels" data-type="indexterm" id="idm46803155526048"/><a data-primary="metadata of Linux containers" data-secondary="labels" data-type="indexterm" id="idm46803155524960"/><a data-primary="Linux containers" data-secondary="metadata" data-tertiary="labels" data-type="indexterm" id="idm46803155524112"/><a data-primary="labels" data-type="indexterm" id="idm46803155522896"/> allows you to add metadata via key/value pairs that can later be used to search for and identify Docker images and containers. You can see the labels applied to any image using the <code>docker image inspect</code> command. For the maintainer label, we are leveraging the value of the <code>email</code> build argument that was defined in the previous line of the <em>Dockerfile</em>. This means that this label can be changed anytime we build this image:</p>&#13;
&#13;
<pre data-code-language="dockerfile" data-type="programlisting"><code class="k">LABEL</code><code class="w"> </code><code class="s2">"maintainer"</code><code class="o">=</code><code class="nv">$email</code><code class="w"/>&#13;
<code class="k">LABEL</code><code class="w"> </code><code class="s2">"rating"</code><code class="o">=</code><code class="s2">"Five Stars"</code><code class="w"> </code><code class="s2">"class"</code><code class="o">=</code><code class="s2">"First Class"</code><code class="w"/></pre>&#13;
&#13;
<p>By default, Docker runs all <a data-primary="processes" data-secondary="run as root within container" data-type="indexterm" id="idm46803155456640"/><a data-primary="root running container processes" data-type="indexterm" id="idm46803155455792"/>processes as <code>root</code> within the container, but you can use the <code>USER</code> instruction to change this:</p>&#13;
&#13;
<pre data-code-language="dockerfile" data-type="programlisting"><code class="k">USER</code><code class="w"> </code><code class="s">root</code><code class="w"/></pre>&#13;
<div data-type="caution"><h6>Caution</h6>&#13;
<p>Even though containers provide<a data-primary="security" data-secondary="unprivileged user context in production" data-type="indexterm" id="idm46803155435248"/><a data-primary="production" data-secondary="unprivileged user context" data-type="indexterm" id="idm46803155434400"/><a data-primary="Linux containers" data-secondary="unprivileged user or group context" data-type="indexterm" id="idm46803155451264"/><a data-primary="unprivileged user or group context" data-type="indexterm" id="idm46803155450416"/><a data-primary="privileged containers" data-secondary="unprivileged user or group context" data-type="indexterm" id="idm46803155449776"/> some isolation from the underlying operating system, they still run on the host kernel. Due to potential security risks, production containers should almost always be run in the context of an unprivileged user.</p>&#13;
</div>&#13;
&#13;
<p>Unlike the <code>ARG</code> instruction, the <code>ENV</code> instruction allows you to set shell variables that can be used by your running application for configuration, in addition to being available during the build process. The <code>ENV</code> and <code>ARG</code> instructions can be used to simplify the <em>Dockerfile</em> and help keep it DRYer (Don’t Repeat Yourself):</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">ENV</code><code class="w"> </code>AP<code class="w"> </code>/data/app<code class="w"/>&#13;
<code class="k">ENV</code><code class="w"> </code>SCPATH<code class="w"> </code>/etc/supervisor/conf.d<code class="w"/></pre>&#13;
&#13;
<p>In the following code, you’ll use a collection of <code>RUN</code> instructions to start and create the required file structure that you need, and install some required software &#13;
<span class="keep-together">dependencies:</span></p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">RUN</code><code class="w"> </code>apt-get<code class="w"> </code>-y<code class="w"> </code>update<code class="w"/>&#13;
&#13;
<code class="c"># The daemons</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>apt-get<code class="w"> </code>-y<code class="w"> </code>install<code class="w"> </code>supervisor<code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>mkdir<code class="w"> </code>-p<code class="w"> </code>/var/log/supervisor<code class="w"/></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>While we’re demonstrating it here for simplicity, it is not recommended that you run commands like <code>apt-get -y update</code> or <code>dnf <span class="keep-together">-y</span> update</code> in your application’s <em>Dockerfile</em>. This is because it requires crawling the repository index each time you run a build, which means that your build is not guaranteed to be repeatable since package versions might change between builds. Instead, consider basing your application image on another image that already has these updates applied to it and where the versions are in a known state. It will be faster and more repeatable.</p>&#13;
</div>&#13;
&#13;
<p>The <code>COPY</code> instruction is used to copy files from the local filesystem into your image. Most often this will include your application code and any required support files. Because <code>COPY</code> copies the files into the image, you no longer need access to the local filesystem to access them once the image is built.&#13;
You’ll also start to use the build variables you defined in the previous section to save you a bit of work and help protect you from typos:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="c"># Supervisor Configuration</code><code class="w"/>&#13;
<code class="k">COPY</code><code class="w"> </code>./supervisord/conf.d/*<code class="w"> </code><code class="nv">$SCPATH</code>/<code class="w"/>&#13;
&#13;
<code class="c"># Application Code</code><code class="w"/>&#13;
<code class="k">COPY</code><code class="w"> </code>*.js*<code class="w"> </code><code class="nv">$AP</code>/<code class="w"/></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Remember that every instruction<a data-primary="supervisord" data-secondary="Dockerfile anatomy" data-type="indexterm" id="idm46803155311696"/> creates a new Docker image layer, so it often makes sense to combine a few logically grouped commands onto a single line. It is even possible to use the <code>COPY</code> instruction in combination with the <code>RUN</code> instruction to copy a complex script to your image and then execute that script with only two commands in the <em>Dockerfile</em>.</p>&#13;
</div>&#13;
&#13;
<p>With the <code>WORKDIR</code> instruction, you change the working directory in the image for &#13;
<span class="keep-together">the remaining</span> build instructions and the default process that launches with any resulting containers:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">WORKDIR</code><code class="w"> </code><code class="s">$AP</code><code class="w"/>&#13;
&#13;
<code class="k">RUN</code><code class="w"> </code>npm<code class="w"> </code>install<code class="w"/></pre>&#13;
<div data-type="caution"><h6>Caution</h6>&#13;
<p>The order of commands in a <em>Dockerfile</em> can have a very significant impact on ongoing build times. You should try to order commands so that things that change between every single build are closer to the bottom. This means that adding your code and similar steps should be held off until the end. When you rebuild an image, every single layer after the first introduced change will need to be rebuilt.</p>&#13;
</div>&#13;
&#13;
<p>And finally, you end with the <code>CMD</code> instruction, which defines the command that launches the process that you want to run within the container:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"supervisord"</code><code class="p">,</code><code class="w"> </code><code class="s2">"-n"</code><code class="p">]</code><code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Though not a hard-and-fast rule,<a data-primary="processes" data-secondary="single process within a container" data-type="indexterm" id="idm46803155247376"/><a data-primary="supervisord" data-secondary="Dockerfile anatomy" data-type="indexterm" id="idm46803155246496"/> it is generally considered a best practice to try to run only a single process within a container. The core idea is that a container should provide a single function so that it remains easy to horizontally scale individual functions within your architecture. In the example, you are using &#13;
<span class="keep-together"><code>supervisord</code></span> as a process manager to help improve the resiliency of the node application within the container and ensure that it stays running. This can also be useful for troubleshooting your application during development so that you can restart your service without restarting the whole container.</p>&#13;
&#13;
<p>You could also achieve a similar<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--init" data-tertiary-sortas="init" data-type="indexterm" id="idm46803155244000"/> effect by using the <code>--init</code> command-line argument to <code>docker container run</code>, which we discuss in <a data-type="xref" href="ch07.html#controlling_processes">“Controlling Processes”</a>.<a data-startref="ch04-dockfile" data-type="indexterm" id="idm46803155240384"/><a data-startref="ch04-dockfile2" data-type="indexterm" id="idm46803155239680"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Building an Image" data-type="sect1"><div class="sect1" id="idm46803155681376">&#13;
<h1>Building an Image</h1>&#13;
&#13;
<p>To build your first image, go ahead<a data-primary="OCI images" data-secondary="building an image" data-type="indexterm" id="ch04-bldimg"/><a data-primary="building a Docker image" data-type="indexterm" id="ch04-bldimg2"/><a data-primary="Git" data-secondary="cloning a Git repository" data-tertiary="building first image" data-type="indexterm" id="idm46803155215792"/><a data-primary="cloning a Git repository" data-secondary="building first image" data-type="indexterm" id="idm46803155214704"/><a data-primary="OCI images" data-secondary="building an image" data-tertiary="cloning a Git repository" data-type="indexterm" id="idm46803155213856"/><a data-primary="repositories for Docker images" data-secondary="cloning a Git repository" data-type="indexterm" id="idm46803155212688"/> and clone a Git repo that contains an example application called <em>docker-node-hello</em>, as shown here:<sup><a data-type="noteref" href="ch04.html#idm46803155211200" id="idm46803155211200-marker">2</a></sup></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>git<code class="w"> </code>clone<code class="w"> </code>https://github.com/spkane/docker-node-hello.git<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--config<code class="w"> </code>core.autocrlf<code class="o">=</code>input<code class="w"/>&#13;
<code class="go">Cloning into 'docker-node-hello'…</code>&#13;
<code class="go">remote: Counting objects: 41, done.</code>&#13;
<code class="go">remote: Total 41 (delta 0), reused 0 (delta 0), pack-reused 41</code>&#13;
<code class="go">Unpacking objects: 100% (41/41), done.</code>&#13;
&#13;
<code class="gp">$ </code><code class="nb">cd</code><code class="w"> </code>docker-node-hello<code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Git is frequently installed on Linux<a data-primary="resources online" data-secondary="Git installer" data-type="indexterm" id="idm46803155206256"/><a data-primary="Git" data-secondary="installer link" data-type="indexterm" id="idm46803155205344"/> and macOS systems, but if you do not already have Git available, you can download a simple installer from <a href="https://git-scm.com/downloads"><em>git-scm.com</em></a>.</p>&#13;
&#13;
<p>The <code>--config core.autocrlf=input</code> option we use helps ensure that the line endings are not accidentally altered from the Linux standard that is expected.</p>&#13;
</div>&#13;
&#13;
<p>This will download a working <em>Dockerfile</em> and related source code files into a directory called <em>docker-node-hello</em>. If you look at the contents while ignoring the Git repo directory, you should see the following:<a data-primary="tree command" data-type="indexterm" id="idm46803155191424"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>tree<code class="w"> </code>-a<code class="w"> </code>-I<code class="w"> </code>.git<code class="w"/>&#13;
<code class="go">.</code>&#13;
<code class="go">├── .dockerignore</code>&#13;
<code class="go">├── .gitignore</code>&#13;
<code class="go">├── Dockerfile</code>&#13;
<code class="go">├── index.js</code>&#13;
<code class="go">├── package.json</code>&#13;
<code class="go">└── supervisord</code>&#13;
<code class="go">    └── conf.d</code>&#13;
<code class="go">        ├── node.conf</code>&#13;
<code class="go">        └── supervisord.conf</code></pre>&#13;
&#13;
<p>Let’s review the most relevant files in the repo.</p>&#13;
&#13;
<p>The <em>Dockerfile</em> should be the same as the one you just reviewed.</p>&#13;
&#13;
<p>The <em>.dockerignore</em> file allows<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary=".dockerignore file" data-tertiary-sortas="dockerignore file" data-type="indexterm" id="idm46803155109904"/><a data-primary=".dockerignore file" data-type="indexterm" id="idm46803155144160"/> you to define files and directories that you do not want to upload to the Docker host when you are building the image. In this instance, the <em>.dockerignore</em> file contains the following line:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">.git</pre>&#13;
&#13;
<p>This instructs <code>docker image build</code> to exclude the <em>.git</em> directory, which contains the whole source code repository, from the build. The rest of the files reflect the current state of your source code on the checked-out branch. You don’t need the contents of the <em>.git</em> directory to build the Docker image, and since it can grow quite large over time, you don’t want to waste time copying it every time you do a build. <em>package.json</em> defines the Node.js application and lists any dependencies that it relies on. <em>index.js</em> is the main source code for the application.</p>&#13;
&#13;
<p>The <em>supervisord</em> directory contains<a data-primary="supervisord" data-secondary="building a Docker image" data-type="indexterm" id="idm46803168575168"/> the configuration files for <code>supervisord</code> that you will use to start and monitor the application.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Using <a href="http://supervisord.org"><code>supervisord</code></a> in this example to monitor the application is overkill, but it is intended to provide a bit of insight into some of the techniques you can use in a container to provide more control over your application and its running state.</p>&#13;
</div>&#13;
&#13;
<p>As we discussed in <a data-type="xref" href="ch03.html#installing_docker">Chapter 3</a>, you will need to have your Docker server running and your client properly set up to communicate with it before you can build a Docker image. Assuming that this is all working, you should be able to initiate a new build by running the upcoming command, which will build and tag an image based on the files in the current directory.</p>&#13;
&#13;
<p>Each step identified in the following output maps directly to a line in the <em>Dockerfile</em>, and each step creates a new image layer based on the previous step.  The first build that you run will take a few minutes because you have to download the base node image. Subsequent builds should be much faster unless a new version of our base image tag has been released.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The output that follows is from the new BuildKit included<a data-primary="BuildKit" data-secondary="enabling" data-type="indexterm" id="idm46803155136592"/> in Docker. If you see significantly different output, then you are likely still using the older image building code.</p>&#13;
&#13;
<p>You can enable BuildKit in your environment<a data-primary="environment variables" data-secondary="DOCKER_BUILDKIT" data-type="indexterm" id="idm46803155100640"/> by setting the <code>DOCKER_BUILDKIT</code> environment variable to <code>1</code>.</p>&#13;
&#13;
<p>You can find more details on the <a href="https://docs.docker.com/build/buildkit">Docker website</a>.</p>&#13;
</div>&#13;
&#13;
<p>At the end of the <code>build</code> command, you<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="period at end" data-type="indexterm" id="idm46803155096352"/> will notice a period. This refers to the build context,  which tells Docker what files it should upload to the server so that it can build our image. In many cases, you will simply see a <code>.</code> at the end of a <code>build</code> command, since a single period represents the current directory. This build context is what the <em>.dockerignore</em> file is filtering so that we don’t upload more than we need.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Docker assumes that the <em>Dockerfile</em> is in the current directory, but if it is not, you can point directly to it using the <code>-f</code> argument.</p>&#13;
</div>&#13;
&#13;
<p>Let’s run the build:<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-type="indexterm" id="idm46803155074768"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>example/docker-node-hello:latest<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 37B</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 34B</code>&#13;
<code class="go"> =&gt; [internal] load metadata for docker.io/library/node:18.13.0</code>&#13;
<code class="go"> =&gt; CACHED [1/8] FROM docker.io/library/node:18.13.0@19a9713dbaf3a3899ad…</code>&#13;
<code class="go"> =&gt; [internal] load build context</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 233B</code>&#13;
<code class="go"> =&gt; [2/8] RUN apt-get -y update</code>&#13;
<code class="go"> =&gt; [3/8] RUN apt-get -y install supervisor</code>&#13;
<code class="go"> =&gt; [4/8] RUN mkdir -p /var/log/supervisor</code>&#13;
<code class="go"> =&gt; [5/8] COPY ./supervisord/conf.d/* /etc/supervisor/conf.d/</code>&#13;
<code class="go"> =&gt; [6/8] COPY *.js* /data/app/</code>&#13;
<code class="go"> =&gt; [7/8] WORKDIR /data/app</code>&#13;
<code class="go"> =&gt; [8/8] RUN npm install</code>&#13;
<code class="go"> =&gt; exporting to image</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:991844271ca5b984939ab49d81b24d4d53137f04a1bd…</code>&#13;
<code class="go"> =&gt; =&gt; naming to docker.io/example/docker-node-hello:latest</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>To improve the speed of builds,<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="local cache" data-type="indexterm" id="idm46803155034176"/> Docker will use a local cache when it thinks it is safe. This can sometimes lead to unexpected issues because it doesn’t always notice that something changed in a lower layer. In the preceding output, you will notice lines like <code>⇒ [2/8] RUN apt-get -y update</code>. If instead you see <code>⇒ CACHED [2/8] RUN apt-get -y update</code>, you know that Docker decided to use the cache. You can disable the cache for a build by using the <code>--no-cache</code> argument to the <code>docker image build</code> command.</p>&#13;
</div>&#13;
&#13;
<p>If you are building your Docker images on a system that is used for other simultaneous processes, you can limit the resources available to your builds by using many of the same cgroup methods that we will discuss in <a data-type="xref" href="ch05.html#docker_containers">Chapter 5</a>. <a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="documentation" data-type="indexterm" id="idm46803155029296"/><a data-primary="documentation" data-secondary="Docker" data-tertiary="docker image build command" data-type="indexterm" id="idm46803155027776"/><a data-primary="resources online" data-secondary="Docker documentation" data-tertiary="docker image build" data-type="indexterm" id="idm46803155026592"/>You can find detailed documentation on the <code>docker image build</code> arguments in the <a href="https://docs.docker.com/engine/reference/commandline/image_build">official documentation</a>.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Using <code>docker image build</code> is functionally the same as using <code>docker build</code>.<a data-primary="docker build" data-primary-sortas="docker-z" data-see="docker image build" data-type="indexterm" id="idm46803155043856"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="list" data-see="docker container ls" data-type="indexterm" id="idm46803155042576"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ps" data-see="docker container ls" data-type="indexterm" id="idm46803155041088"/><a data-primary="docker kill" data-primary-sortas="docker-z" data-see="docker container kill" data-type="indexterm" id="idm46803155039600"/><a data-primary="docker images" data-primary-sortas="docker-z" data-see="docker image ls" data-type="indexterm" id="idm46803155038384"/><a data-primary="docker ps" data-primary-sortas="docker-z" data-see="docker container ls" data-type="indexterm" id="idm46803155037168"/><a data-primary="docker stop" data-primary-sortas="docker-z" data-see="docker container stop" data-type="indexterm" id="idm46803155035952"/><a data-primary="docker pause" data-primary-sortas="docker-z" data-see="docker container pause" data-type="indexterm" id="idm46803154988480"/><a data-primary="docker rm" data-primary-sortas="docker-z" data-see="docker container rm" data-type="indexterm" id="idm46803154987392"/><a data-primary="docker rmi" data-primary-sortas="docker-z" data-see="docker image rm" data-type="indexterm" id="idm46803154986272"/><a data-primary="docker run" data-primary-sortas="docker-z" data-see="docker container run" data-type="indexterm" id="idm46803154985056"/><a data-primary="docker start" data-primary-sortas="docker-z" data-see="docker container start" data-type="indexterm" id="idm46803154983840"/><a data-primary="docker unpause" data-primary-sortas="docker-z" data-see="docker container unpause" data-type="indexterm" id="idm46803154982624"/><a data-primary="docker-buildx" data-see="docker buildx" data-type="indexterm" id="idm46803154981392"/><a data-primary="docker-ce" data-see="Docker Community Edition" data-type="indexterm" id="idm46803154980448"/><a data-primary="docker-compose" data-see="docker compose" data-type="indexterm" id="idm46803154979488"/></p>&#13;
</div>&#13;
&#13;
<p>If you have any issues getting a build to work correctly, you may want to skip ahead and read the sections <a data-type="xref" href="#multi_stage">“Multistage builds”</a> and <a data-type="xref" href="#broken_builds">“Troubleshooting Broken Builds”</a> in this chapter.<a data-startref="ch04-bldimg" data-type="indexterm" id="idm46803154976560"/><a data-startref="ch04-bldimg2" data-type="indexterm" id="idm46803154975856"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running Your Image" data-type="sect1"><div class="sect1" id="idm46803155238096">&#13;
<h1>Running Your Image</h1>&#13;
&#13;
<p>Once you have successfully built the image, you can run it on your Docker host with the following command:<a data-primary="OCI images" data-secondary="running the image" data-type="indexterm" id="idm46803154973968"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="running a Docker image" data-type="indexterm" id="idm46803154972992"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-p/--publish to map ports" data-tertiary-sortas="p" data-type="indexterm" id="idm46803154971504"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code>-p<code class="w"> </code><code class="m">8080</code>:8080<code class="w"> </code>example/docker-node-hello:latest<code class="w"/></pre>&#13;
&#13;
<p>This command tells Docker to create a running container in the background from the image with the <code>example/docker-node-hello:latest</code> tag, and then map port 8080 in the container to port 8080 on the Docker host. If everything goes as expected, the new Node.js application should be running in a container on the host. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="checking for running container" data-type="indexterm" id="idm46803154964448"/>You can verify this by running <code>docker container ls</code>. To see the running application in action, you will need to open up a web browser and point it at port 8080 on the Docker host. <a data-primary="IP addresses" data-secondary="Docker host IP address determination" data-type="indexterm" id="idm46803154949120"/><a data-primary="docker context" data-primary-sortas="docker-z" data-secondary="list" data-type="indexterm" id="idm46803154948176"/>You can usually determine the Docker host IP address by examining the entry from <code>docker context list</code> that is marked with an asterisk or <a data-primary="environment variables" data-secondary="DOCKER_HOST" data-type="indexterm" id="idm46803154946448"/>checking the value of the <code>DOCKER_HOST</code> environment variable if it happens to be set. If the <code>DOCKER ENDPOINT</code> is set to a Unix socket, then the IP address is most likely <code>127.0.0.1</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>context<code class="w"> </code>list<code class="w"/>&#13;
<code class="go">NAME      TYPE … DOCKER ENDPOINT             …</code>&#13;
<code class="go">default * moby … unix:///var/run/docker.sock …</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>Get the IP address and enter something like <em><a class="bare" href="http://127.0.0.1:8080/"><em class="hyperlink">http://127.0.0.1:8080/</em></a></em> (or your remote Docker address if it’s different than that) into your web browser address bar, or use a command-line tool like <code>curl</code>. You should see the following text:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">Hello World. Wish you were here.</pre>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Build Arguments" data-type="sect2"><div class="sect2" id="idm46803154935552">&#13;
<h2>Build Arguments</h2>&#13;
&#13;
<p>If you inspect the image<a data-primary="OCI images" data-secondary="building an image" data-tertiary="build arguments" data-type="indexterm" id="idm46803154912528"/><a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="build arguments" data-type="indexterm" id="idm46803154911776"/><a data-primary="docker inspect" data-primary-sortas="docker-z" data-type="indexterm" id="idm46803154910352"/> that we built, you will be able to see that the maintainer label was set to <code>anna@example.com</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>inspect<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>example/docker-node-hello:latest<code class="w"> </code><code class="p">|</code><code class="w"> </code>grep<code class="w"> </code>maintainer<code class="w"/>&#13;
<code class="go">            "maintainer": "anna@example.com",</code></pre>&#13;
&#13;
<p>If we wanted to change the <code>maintainer</code> label, we could simply rerun the build and provide a new value for the <code>email</code> <code>ARG</code> via the <code>--build-arg</code> command-line argument, like so:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>--build-arg<code class="w"> </code><code class="nv">email</code><code class="o">=</code>me@example.com<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>-t<code class="w"> </code>example/docker-node-hello:latest<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; =&gt; naming to docker.io/example/docker-node-hello:latest</code></pre>&#13;
&#13;
<p>After the build has finished, we can check the results by reinspecting the new image:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>inspect<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>example/docker-node-hello:latest<code class="w"> </code><code class="p">|</code><code class="w"> </code>grep<code class="w"> </code>maintainer<code class="w"/>&#13;
<code class="go">            "maintainer": "me@example.com",</code></pre>&#13;
&#13;
<p>The <code>ARG</code> and <code>ENV</code> instructions can help make <em>Dockerfile</em>s very flexible while also avoiding a lot of repeated values that can be hard to keep up to date.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Environment Variables as Configuration" data-type="sect2"><div class="sect2" id="idm46803154792544">&#13;
<h2>Environment Variables as Configuration</h2>&#13;
&#13;
<p>If you read the <em>index.js</em> file, you will notice<a data-primary="environment variables" data-secondary="configuration via" data-tertiary="building Docker images" data-type="indexterm" id="ch04-env"/><a data-primary="OCI images" data-secondary="building an image" data-tertiary="environment variables as configuration" data-type="indexterm" id="ch04-env2"/><a data-primary="configuration" data-secondary="environment variables" data-tertiary="building Docker images" data-type="indexterm" id="ch04-env3"/> that part of the file refers to the variable <code>$WHO</code>, which the application uses to determine who the application is going to say Hello to:</p>&#13;
&#13;
<pre data-code-language="js" data-type="programlisting"><code class="kd">var</code> <code class="nx">DEFAULT_WHO</code> <code class="o">=</code> <code class="s2">"World"</code><code class="p">;</code>&#13;
<code class="kd">var</code> <code class="nx">WHO</code> <code class="o">=</code> <code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">WHO</code> <code class="o">||</code> <code class="nx">DEFAULT_WHO</code><code class="p">;</code>&#13;
&#13;
<code class="nx">app</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/'</code><code class="p">,</code> <code class="kd">function</code> <code class="p">(</code><code class="nx">req</code><code class="p">,</code> <code class="nx">res</code><code class="p">)</code> <code class="p">{</code>&#13;
  <code class="nx">res</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="s1">'Hello '</code> <code class="o">+</code> <code class="nx">WHO</code> <code class="o">+</code> <code class="s1">'. Wish you were here.\n'</code><code class="p">);</code>&#13;
<code class="p">});</code></pre>&#13;
&#13;
<p>Let’s quickly cover how you can configure this application by passing in environment variables when you start it. First, you need to stop the existing container using two commands. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="container ID retrieved" data-type="indexterm" id="idm46803154704768"/>The first command will provide you with the container ID, which you will need to use in the second command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">CONTAINER ID  IMAGE                             STATUS       …</code>&#13;
<code class="go">b7145e06083f  example/centos-node-hello:latest  Up 4 minutes …</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>You can format the output<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="formatting the output" data-type="indexterm" id="idm46803154637136"/><a data-primary="Go language" data-secondary="template for output formatting" data-type="indexterm" id="idm46803154713296"/> of <code>docker container ls</code> by using a <a href="https://developer.hashicorp.com/nomad/tutorials/templates/go-template-syntax">Go template</a> so that you see only the information that you care about. In the preceding example, you might decide to run something like <code>docker container ls --format "table &#13;
<span class="keep-together">{{.ID}}\t{{.Image}}\t{{.Status}}"</span></code> to limit the output to the three fields you care about. Additionally, running <code>docker container ls --quiet</code> with no format options will limit the output to only the container ID.</p>&#13;
</div>&#13;
&#13;
<p>And then, using the container ID from the previous output, you can stop the running container by typing the following:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="stop" data-tertiary="stop running container" data-type="indexterm" id="idm46803154632064"/><a data-primary="Linux containers" data-secondary="stopping a container" data-type="indexterm" id="idm46803154630576"/><a data-primary="OCI images" data-secondary="running the image" data-tertiary="stopping the container" data-type="indexterm" id="idm46803154629632"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>stop<code class="w"> </code>b7145e06083f<code class="w"/>&#13;
<code class="go">b7145e06083f</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Using <code>docker container ls</code> is functionally<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="equivalent commands" data-type="indexterm" id="idm46803154602240"/> equivalent to using <code>docker container list</code>, <code>docker container ps</code>, or <code>docker ps</code>.</p>&#13;
&#13;
<p>Using <code>docker container stop</code> is also functionally equivalent to using <code>docker stop</code>.</p>&#13;
</div>&#13;
&#13;
<p>You can then restart the container<a data-primary="Linux containers" data-secondary="restarting a container" data-type="indexterm" id="idm46803154595648"/><a data-primary="OCI images" data-secondary="running the image" data-tertiary="restarting the container" data-type="indexterm" id="idm46803154594784"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-p/--publish to map ports" data-tertiary-sortas="p" data-type="indexterm" id="idm46803154593600"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-e/--env to set environment variable" data-tertiary-sortas="e" data-type="indexterm" id="idm46803154591872"/> after adding a single instance of the <code>--env</code> argument to the previous <code>docker container run</code> command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--publish<code class="w"> </code><code class="nv">mode</code><code class="o">=</code>ingress,published<code class="o">=</code><code class="m">8080</code>,target<code class="o">=</code><code class="m">8080</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--env<code class="w"> </code><code class="nv">WHO</code><code class="o">=</code><code class="s2">"Sean and Karl"</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>example/docker-node-hello:latest<code class="w"/></pre>&#13;
&#13;
<p>If you reload your web browser, you should see that the text on the web page now reads as follows:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">Hello Sean and Karl. Wish you were here.</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>You could shorten the preceding <code>docker</code> command to the following if you wanted:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code>-p<code class="w"> </code><code class="m">8080</code>:8080<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>-e<code class="w"> </code><code class="nv">WHO</code><code class="o">=</code><code class="s2">"Sean and Karl"</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>example/docker-node-hello:latest<code class="w"/></pre>&#13;
</div>&#13;
&#13;
<p>You can go ahead and stop this container now, by using <code>docker container stop</code> and passing in the correct container ID.<a data-startref="ch04-env" data-type="indexterm" id="idm46803154471616"/><a data-startref="ch04-env2" data-type="indexterm" id="idm46803154471008"/><a data-startref="ch04-env3" data-type="indexterm" id="idm46803154466720"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Custom Base Images" data-type="sect1"><div class="sect1" id="idm46803154791952">&#13;
<h1>Custom Base Images</h1>&#13;
&#13;
<p>Base images are the lowest-level images<a data-primary="OCI images" data-secondary="custom base images" data-type="indexterm" id="idm46803154464624"/> that other Docker images will build upon. Most often, these are based on minimal installs of Linux distributions like Ubuntu, Fedora, or Alpine Linux, but they can also be much smaller, containing a single statically compiled binary. For most people, using the official base images for their favorite distribution or tool is a great option.</p>&#13;
&#13;
<p>However, there are times when it is preferable to build your own base images rather than use an image created by someone else. One reason to do this is to maintain a consistent OS image across all your deployment methods for hardware, VMs, and containers. Another is to get the image size down substantially. There is no need to ship around an entire Ubuntu distribution, for example, if your application is a statically built C or Go application. You might find that you only need the tools you regularly use for debugging, and some other shell commands and binaries. Making the effort to build such an image could pay off in better deployment times and easier application distribution.</p>&#13;
&#13;
<p>A common middle ground between these<a data-primary="OCI images" data-secondary="custom base images" data-tertiary="Alpine Linux for small distribution size" data-type="indexterm" id="idm46803154462720"/><a data-primary="Alpine Linux" data-secondary="small distribution size" data-type="indexterm" id="idm46803154461120"/><a data-primary="Linux" data-secondary="Alpine Linux for small distribution size" data-type="indexterm" id="idm46803154460176"/> two approaches is to build images using Alpine Linux, which is designed to be very small and is popular as a basis for Docker images. <a data-primary="musl standard library" data-type="indexterm" id="idm46803154459136"/><a data-primary="GNU C Library (glibc)" data-type="indexterm" id="idm46803154458464"/><a data-primary="glibc (GNU C Library)" data-type="indexterm" id="idm46803154457792"/>To keep the distribution size very small, Alpine Linux is based on the modern, lightweight <a href="https://musl.libc.org">musl standard library</a>, instead of the more traditional <a href="https://www.gnu.org/software/libc">GNU C Library (glibc)</a>. In general, this is not a big issue, since many packages support <em>musl</em>, but it is something to be aware of. It has the largest impact on Java-based applications and DNS resolution. It’s widely used in production, however, because of its diminutive image size. Alpine Linux is highly optimized for space, which is the reason that it ships with <em>/bin/sh</em> instead of <em>/bin/bash</em>, by default. However, you can also install <em>glibc and bash</em> in Alpine Linux if you need it, and this is often done in the case of JVM containers.</p>&#13;
&#13;
<p>In the official Docker documentation,<a data-primary="OCI images" data-secondary="custom base images" data-tertiary="documentation on various Linux distributions" data-type="indexterm" id="idm46803154453744"/><a data-primary="documentation" data-secondary="Docker" data-tertiary="building base images on various Linux distributions" data-type="indexterm" id="idm46803154452464"/><a data-primary="resources online" data-secondary="Docker documentation" data-tertiary="building base images on various Linux distributions" data-type="indexterm" id="idm46803154451216"/> there is some good information about how you can build base images on the various <a href="https://dockr.ly/2N1FZcU">Linux distributions</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Storing Images" data-type="sect1"><div class="sect1" id="idm46803154449088">&#13;
<h1>Storing Images</h1>&#13;
&#13;
<p>Now that you have created a Docker image<a data-primary="OCI images" data-secondary="storing images" data-tertiary="about" data-type="indexterm" id="idm46803154429824"/><a data-primary="storing Docker images" data-secondary="about" data-type="indexterm" id="idm46803154428848"/> that you’re happy with, you’ll want to store it somewhere so that it can be easily accessed by any Docker host that you want to deploy it to. This is also the normal hand-off point between building images and storing them somewhere for future deployment. You don’t normally build the images on a production server and then run them. This process was described when we talked about handoff between teams for application deployment. Ordinarily, deployment is the process of pulling an image from a repository and running it on one or more Linux servers. There are a few ways you can go about storing your images into a central repository for easy retrieval.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Public Registries" data-type="sect2"><div class="sect2" id="idm46803154427648">&#13;
<h2>Public Registries</h2>&#13;
&#13;
<p>Docker provides an <a href="https://registry.hub.docker.com">image registry</a> for public<a data-primary="OCI images" data-secondary="storing images" data-tertiary="public registries" data-type="indexterm" id="idm46803154425488"/><a data-primary="public registries for storing Docker images" data-seealso="Docker Hub; storing Docker images" data-type="indexterm" id="idm46803154424208"/><a data-primary="storing Docker images" data-secondary="public registries" data-type="indexterm" id="idm46803154423200"/><a data-primary="image registries" data-secondary="public registries" data-seealso="Docker Hub; GitHub" data-type="indexterm" id="idm46803154422256"/> images that the community wants to share. These include official images for Linux distributions, ready-to-go WordPress containers, and much more.</p>&#13;
&#13;
<p>If you have images that can be published on the internet, the best place<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-type="indexterm" id="idm46803154420304"/><a data-primary="OCI images" data-secondary="storing images" data-tertiary="Docker Hub" data-type="indexterm" id="idm46803154419088"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-type="indexterm" id="idm46803154417872"/> for them is a public registry, like <a href="https://hub.docker.com">Docker Hub</a>. However, there are other options. When the core Docker tools were first gaining popularity, Docker Hub did not exist. <a data-primary="Quay.io image public registry" data-type="indexterm" id="idm46803154416144"/>To fill this obvious void in the community, <a href="https://quay.io">Quay.io</a> was created. Since then, Quay.io has gone through a few acquisitions and is now owned by Red Hat. Cloud vendors like Google and SaaS companies like GitHub also have their own registry offerings. Here we’ll talk about just the two of them.</p>&#13;
&#13;
<p>Both Docker Hub and Quay.io provide centralized Docker image registries that can be accessed from anywhere on the internet, and provide a method to store private images in addition to public ones. Both have nice user interfaces and the ability to separate team access permissions and manage users. Both also offer reasonable commercial options for private SaaS hosting of your images, much in the same way that <a data-primary="private registries" data-secondary="GitHub selling" data-type="indexterm" id="idm46803154414432"/><a data-primary="private registries" data-secondary="storing images" data-see="storing Docker images" data-type="indexterm" id="idm46803154413424"/>GitHub sells private registries on its systems. This is probably the right first step if you’re getting serious about Docker but are not yet shipping enough code to need an internally hosted solution.</p>&#13;
&#13;
<p>For companies that use Docker heavily, one of the biggest downsides to these registries is that they are not local to the network on which the application is being deployed. This means that every layer of every deployment might need to be dragged across the internet to deploy an application. Internet latencies have a very real impact on software deployments, and outages that affect these registries could have a very detrimental impact on a company’s ability to deploy smoothly and on schedule. This is mitigated by good image design, where you make thin layers that are easy to move around the internet.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Private Registries" data-type="sect2"><div class="sect2" id="idm46803154411568">&#13;
<h2>Private Registries</h2>&#13;
&#13;
<p>The other option that many companies<a data-primary="OCI images" data-secondary="storing images" data-tertiary="private registries" data-type="indexterm" id="idm46803154410240"/><a data-primary="storing Docker images" data-secondary="private registries" data-type="indexterm" id="idm46803154408992"/><a data-primary="private registries" data-type="indexterm" id="idm46803154408048"/><a data-primary="image registries" data-secondary="private registries" data-type="indexterm" id="idm46803154407376"/> consider is to host some type of Docker image registry internally, which can interact with the Docker client to support pushing, pulling, and searching images. <a data-primary="Distribution project for private registry" data-type="indexterm" id="idm46803154406304"/>The open source <a href="https://github.com/distribution/distribution">Distribution</a> project provides the basic functionality that most other registries build upon.</p>&#13;
&#13;
<p>Other strong contenders in the private<a data-primary="Harbor private image registry" data-type="indexterm" id="idm46803154404272"/><a data-primary="Red Hat" data-secondary="Quay private image registry" data-type="indexterm" id="idm46803154403600"/><a data-primary="Quay (Red Hat) private image registry" data-type="indexterm" id="idm46803154402640"/> registry space include <a href="https://goharbor.io">Harbor</a> and <a href="https://www.redhat.com/en/technologies/cloud-computing/quay">Red Hat Quay</a>. In addition to the basic Docker registry functionality, these products have solid GUI interfaces and many additional features, like image verification.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Authenticating to a Registry" data-type="sect2"><div class="sect2" id="idm46803154400224">&#13;
<h2>Authenticating to a Registry</h2>&#13;
&#13;
<p>Communicating with a registry<a data-primary="OCI images" data-secondary="storing images" data-tertiary="Docker Hub" data-type="indexterm" id="ch04-dhstor"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-type="indexterm" id="ch04-dhstor2"/><a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-type="indexterm" id="ch04-dhstor3"/> that stores container images is a part of daily life with Docker. For many registries, this means you’ll need to authenticate to gain access to images. But Docker also tries to make it easy to automate things so it can store your login information and use it on your behalf when you request things like pulling down a private image. By default, Docker assumes the registry will be Docker Hub, the public repository hosted by Docker, Inc.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Although a bit more advanced,<a data-primary="OCI images" data-secondary="storing images" data-tertiary="custom registry mirror" data-type="indexterm" id="idm46803154392736"/><a data-primary="storing Docker images" data-secondary="custom registry mirror" data-type="indexterm" id="idm46803154391488"/><a data-primary="OCI images" data-secondary="storing images" data-tertiary="pull-through image cache" data-type="indexterm" id="idm46803154390544"/><a data-primary="storing Docker images" data-secondary="pull-through image cache" data-type="indexterm" id="idm46803154389264"/><a data-primary="pull-through image cache" data-type="indexterm" id="idm46803154388304"/><a data-primary="image registries" data-secondary="custom registry mirror" data-type="indexterm" id="idm46803154387616"/><a data-primary="image registries" data-secondary="pull-through image cache" data-type="indexterm" id="idm46803154386672"/> it is worth noting that you can also configure the Docker daemon to use a <a href="https://oreil.ly/16Kns">custom registry mirror</a><sup><a data-type="noteref" href="ch04.html#idm46803154385056" id="idm46803154385056-marker">3</a></sup> or a <a href="https://oreil.ly/2Am1f">pull-through image cache</a>.<sup><a data-type="noteref" href="ch04.html#idm46803154382192" id="idm46803154382192-marker">4</a></sup></p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Creating a Docker Hub account" data-type="sect3"><div class="sect3" id="idm46803154380048">&#13;
<h3>Creating a Docker Hub account</h3>&#13;
&#13;
<p>For these examples, you will create<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-tertiary="creating account" data-type="indexterm" id="idm46803154378624"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-tertiary="creating account" data-type="indexterm" id="idm46803154377040"/> an account on Docker Hub. You don’t need an account to download publicly shared images, but you will need to be logged in to avoid rate limits and upload any containers that you build.</p>&#13;
&#13;
<p>To create your account, use a web browser of your choice to navigate to <a href="https://hub.docker.com">Docker Hub</a>.</p>&#13;
&#13;
<p>From there, you can log in via an existing account or create a new login based on your email address. When you create your account, Docker Hub sends a verification email to the address that you provided during sign-up. You should immediately log in to your email account and click the verification link inside the email to finish the validation process.</p>&#13;
&#13;
<p>At this point, you have created a public registry to which you can upload new images. The <a href="https://hub.docker.com/settings/default-privacy">Account Settings</a> option under your profile picture has a <code>Default Privacy</code> section that allows you to change your registry default visibility to <code>private</code> if that is what you need.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>For much better security, you should create and log in to Docker Hub with a <a href="https://docs.docker.com/go/access-tokens">limited-privilege personal access token</a>.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Logging in to a registry" data-type="sect3"><div class="sect3" id="idm46803154369808">&#13;
<h3>Logging in to a registry</h3>&#13;
&#13;
<p>Now let’s log in to the Docker Hub registry using our account:<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-tertiary="logging in" data-type="indexterm" id="idm46803154368176"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-tertiary="logging in" data-type="indexterm" id="idm46803154366592"/><a data-primary="docker login" data-primary-sortas="docker-z" data-type="indexterm" id="idm46803154365376"/><a data-primary="logging in to Docker Hub" data-type="indexterm" id="idm46803154364432"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>login<code class="w"/>&#13;
<code class="go">Login with your Docker ID to push and pull images from Docker Hub. If you</code>&#13;
<code class="go">don't have a Docker ID, head over to https://hub.docker.com to create one.</code>&#13;
<code class="go">Username: &lt;hub_username&gt;</code>&#13;
<code class="go">Password: &lt;hub_password/token&gt;</code>&#13;
<code class="go">Login Succeeded</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The command <code>docker login</code> is functionally the same command as <code>docker login docker.io</code>.</p>&#13;
</div>&#13;
&#13;
<p>When you get <code>Login Succeeded</code> back from the server, you know you’re ready to pull images from the registry. But what happened behind the scenes? It turns out that Docker has written a dotfile for you in your home directory to cache this information. The permissions are set to 0600 as a security precaution against other users reading your credentials. You can inspect the file with something like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>ls<code class="w"> </code>-la<code class="w"> </code><code class="si">${</code><code class="nv">HOME</code><code class="si">}</code>/.docker/config.json<code class="w"/>&#13;
<code class="go">-rw-------@ 1 …  158 Dec 24 10:37 /Users/someuser/.docker/config.json</code>&#13;
&#13;
<code class="gp">$ </code>cat<code class="w"> </code><code class="si">${</code><code class="nv">HOME</code><code class="si">}</code>/.docker/config.json<code class="w"/></pre>&#13;
&#13;
<p>On Linux you will see something like this:</p>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">{</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">"auths"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">"https://index.docker.io/v1/"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">"auth"</code><code class="p">:</code><code class="s2">"cmVsaEXamPL3hElRmFCOUE="</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">"email"</code><code class="p">:</code><code class="s2">"someuser@example.com"</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">}</code><code class="w"/>&#13;
<code class="w">  </code><code class="p">}</code><code class="w"/>&#13;
<code class="p">}</code><code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Docker is constantly evolving and has added support for many OS native secret management systems like the macOS Keychain or Windows Credential Manager. So, your <em>config.json</em> file might look significantly different than the example. There is also a set of <a href="https://github.com/docker/docker-credential-helpers">credentials managers</a> for different platforms that can make your life easier here.</p>&#13;
</div>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>The <code>auth</code> value in the Docker client config file is only base64 encoded. It is <em>not</em> encrypted. This is typically only a significant issue on multiuser Linux systems, because there isn’t a default system-wide credential manager that just works, and other privileged users on the system can likely read your Docker client config file and access those secrets. It is possible to configure <code>gpg</code> pr <code>pass</code> to encrypt these files on Linux.</p>&#13;
</div>&#13;
&#13;
<p>Here you can see that the <em>${HOME}/.docker/config.json</em> file contains <code>docker.io</code> credentials for the user <code>someuser@example.com</code> in JSON. This configuration file supports storing credentials for multiple registries. In this case, you just have one entry, for Docker Hub, but you could have more if you needed it. From now on, when the registry needs authentication, Docker will look in <em>${HOME}/.docker/config.json</em> to see if you have credentials stored for this hostname. If so, it will supply them. You will notice that one value is completely lacking here: a timestamp. These credentials are cached forever or until you tell Docker to remove them, whichever comes first.</p>&#13;
&#13;
<p>As with logging in, you can also log out of a registry if you no longer want to cache the credentials:<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-tertiary="logging out" data-type="indexterm" id="idm46803154258192"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-tertiary="logging out" data-type="indexterm" id="idm46803154256704"/><a data-primary="docker logout" data-primary-sortas="docker-z" data-type="indexterm" id="idm46803154255488"/><a data-primary="logging in to Docker Hub" data-secondary="logging out" data-type="indexterm" id="idm46803154254544"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code><code class="nb">logout</code><code class="w"/>&#13;
<code class="go">Removing login credentials for https://index.docker.io/v1/</code>&#13;
<code class="gp">$ </code>cat<code class="w"> </code><code class="si">${</code><code class="nv">HOME</code><code class="si">}</code>/.docker/config.json<code class="w"/></pre>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">{</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">"auths"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">  </code><code class="p">}</code><code class="w"/>&#13;
<code class="p">}</code><code class="w"/></pre>&#13;
&#13;
<p>Here you have removed the cached credentials and they are no longer stored by Docker. Some versions of Docker may even remove this file if it is empty. <a data-primary="docker login" data-primary-sortas="docker-z" data-secondary="registry hostname supplied" data-type="indexterm" id="idm46803154191152"/>If you were trying to log in to something other than the Docker Hub registry, you could supply the hostname on the command line:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>login<code class="w"> </code>someregistry.example.com<code class="w"/></pre>&#13;
&#13;
<p>This would then add another auth entry into your <em>${HOME}/.docker/config.json</em> file.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pushing images into a repository" data-type="sect3"><div class="sect3" id="idm46803154369216">&#13;
<h3>Pushing images into a repository</h3>&#13;
&#13;
<p>The first step required to push your image<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-tertiary="pushing images" data-type="indexterm" id="idm46803154132128"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-tertiary="pushing images" data-type="indexterm" id="idm46803154183200"/><a data-primary="pushing images onto Docker Hub" data-type="indexterm" id="idm46803154181984"/> is to ensure that you are logged in to the Docker repository you intend to use. For this example, we will focus on Docker Hub, so ensure that you are logged in to Docker Hub with your preferred credentials:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>login<code class="w"/>&#13;
<code class="go">Login with your Docker ID to push and pull images from Docker Hub. If you</code>&#13;
<code class="go">don't have a Docker ID, head over to https://hub.docker.com to create one.</code>&#13;
<code class="go">Username: &lt;hub_username&gt;</code>&#13;
<code class="go">Password: &lt;hub_password/token&gt;</code>&#13;
<code class="go">Login Succeeded</code>&#13;
&#13;
<code class="go">Logging in with your password grants your terminal complete access to</code>&#13;
<code class="go">your account.</code></pre>&#13;
&#13;
<p>Once you are logged in, you can upload an image. Earlier, you used the command <code>docker image build -t example/docker-node-hello:latest .</code> to build the <code>docker-node-hello</code> image.</p>&#13;
&#13;
<p>In reality, the Docker client, and for compatibility reasons, many other container tools, actually interpret <code>example/docker-node-hello:latest</code> as <code>&#13;
<span class="keep-together">docker.io/example/docker-node-hello:latest</span></code>. Here, <code>docker.io</code> signifies the image registry hostname, and <code>example/docker-node-hello</code> is the repository inside the registry that contains the images in question.</p>&#13;
&#13;
<p>When you are building an image locally,<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="uploading image to registry" data-type="indexterm" id="idm46803154103680"/> the registry and repository name can be anything that you want. However, when you are going to upload your image to a real registry, you need that to match the login.</p>&#13;
&#13;
<p>You can easily edit the tags<a data-primary="image tags" data-secondary="editing for Docker Hub username" data-type="indexterm" id="idm46803154101680"/><a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-tertiary="editing image tags with username" data-type="indexterm" id="idm46803154100736"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-tertiary="editing image tags with username" data-type="indexterm" id="idm46803154099312"/><a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="tag" data-tertiary="editing username" data-type="indexterm" id="idm46803154098128"/> on the image that you already created by running the following command and replacing <code>${&lt;myuser&gt;}</code> with your Docker Hub username:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>tag<code class="w"> </code>example/docker-node-hello:latest<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>docker.io/<code class="si">${</code><code class="p">&lt;myuser&gt;</code><code class="si">}</code>/docker-node-hello:latest<code class="w"/></pre>&#13;
&#13;
<p>If you need to rebuild the image with the new naming convention or simply want to give it a try, you can accomplish this by running the following command in the <em>docker-node-hello</em> working directory that was generated when you performed the Git checkout earlier in the chapter.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For the following examples, you will need to replace <code>${&lt;myuser&gt;}</code> in all the examples with the user that you created in Docker Hub. If you are using a different registry, you will also need to replace <code>docker.io</code> with the hostname of the registry you are using.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>docker.io/<code class="si">${</code><code class="p">&lt;myuser&gt;</code><code class="si">}</code>/docker-node-hello:latest<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>On the first build, this will take a little time. If you rebuild the image, you may find that it is very fast. This is because most, if not all, of the layers already exist on your Docker server from the previous build. <a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="verifying image on server" data-type="indexterm" id="idm46803154027328"/>We can quickly verify that our image is indeed on the server by running <code>docker image ls &#13;
<span class="keep-together">${&lt;myuser&gt;}/docker-node-hello</span></code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>ls<code class="w"> </code><code class="si">${</code><code class="p">&lt;myuser&gt;</code><code class="si">}</code>/docker-node-hello<code class="w"/>&#13;
<code class="go">REPOSITORY                 TAG      IMAGE ID       CREATED             SIZE</code>&#13;
<code class="go">myuser/docker-node-hello   latest   f683df27f02d   About an hour ago   649MB</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>It is possible to format the output<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="formatting output" data-type="indexterm" id="idm46803154019344"/> of <code>docker image ls</code> to make it more concise by using the <code>--format</code> argument, like this: <code>docker image ls --format="table {{.ID}}\t{{.Repository}}"</code>.</p>&#13;
</div>&#13;
&#13;
<p>At this point you can upload the image to the Docker repository by using the <code>docker image push</code> command:<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="push to upload image to repository" data-type="indexterm" id="idm46803153976288"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>push<code class="w"> </code><code class="si">${</code><code class="p">&lt;myuser&gt;</code><code class="si">}</code>/docker-node-hello:latest<code class="w"/>&#13;
<code class="go">Using default tag: latest</code>&#13;
<code class="go">The push refers to repository [docker.io/myuser/docker-node-hello]</code>&#13;
<code class="go">5f3ee7afc69c: Pushed</code>&#13;
<code class="go">…</code>&#13;
<code class="go">5bb0785f2eee: Mounted from library/node</code>&#13;
<code class="go">latest: digest: sha256:f5ceb032aec36fcacab71e468eaf0ba8a832cfc8244fbc784d0…</code></pre>&#13;
&#13;
<p>If this image was uploaded to a public repository, <a data-primary="OCI images" data-secondary="storing images" data-tertiary="pulling from repository" data-type="indexterm" id="idm46803153932864"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-tertiary="pulling from repository" data-type="indexterm" id="idm46803153957616"/><a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-tertiary="pulling images" data-type="indexterm" id="idm46803153956400"/><a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="pull" data-tertiary="downloading image from repository" data-type="indexterm" id="idm46803153954944"/><a data-primary="pulling images" data-type="indexterm" id="idm46803153946816"/>anyone in the world can now easily download it by running the <code>docker image pull</code> command.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>If you uploaded the image to a private repository, then users must log in with credentials that have access to those repositories using the <code>docker login</code> command before they will be able to pull the image down to their local system.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>pull<code class="w"> </code><code class="si">${</code><code class="p">&lt;myuser&gt;</code><code class="si">}</code>/docker-node-hello:latest<code class="w"/>&#13;
<code class="go">Using default tag: latest</code>&#13;
<code class="go">latest: Pulling from myuser/docker-node-hello</code>&#13;
<code class="go">Digest: sha256:f5ceb032aec36fcacab71e468eaf0ba8a832cfc8244fbc784d040872be041cd5</code>&#13;
<code class="go">Status: Image is up to date for myuser/docker-node-hello:latest</code>&#13;
<code class="go">docker.io/myuser/docker-node-hello:latest</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exploring images in Docker Hub" data-type="sect3"><div class="sect3" id="idm46803153898464">&#13;
<h3>Exploring images in Docker Hub</h3>&#13;
&#13;
<p>In addition to simply using<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-tertiary="exploring images" data-type="indexterm" id="idm46803153941296"/><a data-primary="OCI images" data-secondary="storing images" data-tertiary="exploring images in Docker Hub" data-type="indexterm" id="idm46803153939840"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-tertiary="exploring images in" data-type="indexterm" id="idm46803153938656"/><a data-primary="docker search" data-primary-sortas="docker-z" data-type="indexterm" id="idm46803153937440"/> the <a href="https://hub.docker.com">Docker Hub website</a> to explore what images are available, you can also use the <code>docker search</code> command to find images that might be useful.</p>&#13;
&#13;
<p>Running <code>docker search node</code> will return a list of images that contain the word <code>node</code> in either the image name or the description:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>search<code class="w"> </code>node<code class="w"/>&#13;
<code class="go">NAME                     DESCRIPTION                 STARS OFFICIAL AUTOMATED</code>&#13;
<code class="go">node                     Node.js is a JavaScript-ba… 12267 [OK]</code>&#13;
<code class="go">mongo-express            Web-based MongoDB admin in… 1274  [OK]</code>&#13;
<code class="go">nodered/node-red         Low-code programming for e… 544</code>&#13;
<code class="go">nodered/node-red-docker  Deprecated - older Node-RE… 356            [OK]</code>&#13;
<code class="go">circleci/node            Node.js is a JavaScript-ba… 130</code>&#13;
<code class="go">kindest/node             sigs.k8s.io/kind node imag… 78</code>&#13;
<code class="go">bitnami/node             Bitnami Node.js Docker Ima… 69             [OK]</code>&#13;
<code class="go">cimg/node                The CircleCI Node.js Docke… 14</code>&#13;
<code class="go">opendronemap/nodeodm     Automated build for NodeOD… 10             [OK]</code>&#13;
<code class="go">bitnami/node-exporter    Bitnami Node Exporter Dock… 9              [OK]</code>&#13;
<code class="go">appdynamics/nodejs-agent Agent for monitoring Node.… 5</code>&#13;
<code class="go">wallarm/node             Wallarm: end-to-end API se… 5              [OK]</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>The <code>OFFICIAL</code> header tells you<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="Docker image public registry" data-tertiary="official curated images" data-type="indexterm" id="idm46803153880736"/><a data-primary="OCI images" data-secondary="storing images" data-tertiary="official curated images" data-type="indexterm" id="idm46803153879312"/><a data-primary="storing Docker images" data-secondary="Docker Hub" data-tertiary="official curated images" data-type="indexterm" id="idm46803153848688"/> that the image is one of the <a href="https://docs.docker.com/docker-hub/official_images">official curated images</a> on Docker Hub. This typically means that the image is maintained by the company or official development community that oversees that application. <code>AUTOMATED</code> denotes that the image is automatically built and uploaded by a CI/CD process triggered via commits to the underlying source code repository. Official images are always automated.<a data-startref="ch04-dhstor" data-type="indexterm" id="idm46803153846304"/><a data-startref="ch04-dhstor2" data-type="indexterm" id="idm46803153845600"/><a data-startref="ch04-dhstor3" data-type="indexterm" id="idm46803153844928"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running a Private Registry" data-type="sect2"><div class="sect2" id="private_registry">&#13;
<h2>Running a Private Registry</h2>&#13;
&#13;
<p>In keeping with the spirit of the<a data-primary="OCI images" data-secondary="storing images" data-tertiary="running a private registry" data-type="indexterm" id="ch04-runpriv"/><a data-primary="storing Docker images" data-secondary="private registries" data-tertiary="running a private registry" data-type="indexterm" id="ch04-runpriv2"/><a data-primary="private registries" data-secondary="running a private registry" data-type="indexterm" id="ch04-runpriv3"/><a data-primary="Docker Registry" data-primary-sortas="docker-a" data-type="indexterm" id="ch04-runpriv4"/><a data-primary="image registries" data-secondary="private registries" data-tertiary="running a private registry" data-type="indexterm" id="ch04-runpriv5"/> open source community, Docker encourages the community to share Docker images via Docker Hub by default. There are times, however, when this is not a viable option due to commercial, legal, image retention, or reliability concerns.</p>&#13;
&#13;
<p>In these cases, it makes sense to host an internal private registry. Setting up a basic registry is not difficult, but for production use, you should take the time to familiarize yourself with all the available configuration options for <a href="https://docs.docker.com/registry">the open source Docker Registry (Distribution)</a>.</p>&#13;
&#13;
<p>For this example, we are going to create a very simple secure registry using SSL and HTTP basic auth.</p>&#13;
&#13;
<p>First, let’s create a few directories and files on our Docker server. If you are using a VM or cloud instance to run your Docker server, then you will need to SSH to that server for the next few commands. If you are using Docker Desktop or Community Edition, then you should be able to run these on your local system.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Windows users may need to download<a data-primary="Windows running Docker" data-secondary="htppaswd tool" data-type="indexterm" id="idm46803153803616"/> additional tools, like <code>htppaswd</code>, or alter the non-Docker commands to accomplish the same tasks on your local system.</p>&#13;
</div>&#13;
&#13;
<p>First let’s clone a Git repository<a data-primary="cloning a Git repository" data-secondary="private registry" data-type="indexterm" id="idm46803153801744"/><a data-primary="Git" data-secondary="cloning a Git repository" data-tertiary="private registry" data-type="indexterm" id="idm46803153800816"/><a data-primary="private registries" data-secondary="running a private registry" data-tertiary="cloning a Git repository" data-type="indexterm" id="idm46803153799584"/> that contains the basic files required to set up a simple, authenticated Docker registry:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>git<code class="w"> </code>clone<code class="w"> </code>https://github.com/spkane/basic-registry<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--config<code class="w"> </code>core.autocrlf<code class="o">=</code>input<code class="w"/>&#13;
<code class="go">Cloning into 'basic-registry'…</code>&#13;
<code class="go">remote: Counting objects: 10, done.</code>&#13;
<code class="go">remote: Compressing objects: 100% (8/8), done.</code>&#13;
<code class="go">remote: Total 10 (delta 0), reused 10 (delta 0), pack-reused 0</code>&#13;
<code class="go">Unpacking objects: 100% (10/10), done.</code></pre>&#13;
&#13;
<p>Once you have the files locally, you can change directories and examine the files that you just downloaded:<a data-primary="config.yaml for private registry" data-type="indexterm" id="idm46803153791344"/><a data-primary="configuration" data-secondary="config.yaml for private registry" data-type="indexterm" id="idm46803153783440"/><a data-primary="private registries" data-secondary="running a private registry" data-tertiary="config.yaml for configuration" data-type="indexterm" id="idm46803153782704"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">cd</code><code class="w"> </code>basic-registry<code class="w"/>&#13;
<code class="gp">$ </code>ls<code class="w"/>&#13;
<code class="go">Dockerfile          config.yaml.sample  registry.crt.sample</code>&#13;
<code class="go">README.md           htpasswd.sample     registry.key.sample</code></pre>&#13;
&#13;
<p>The <em>Dockerfile</em> simply takes the upstream registry image from Docker Hub and copies some local configuration and support files into a new image.</p>&#13;
&#13;
<p>For testing, you can use some of the included sample files, but <em>do not</em> use these in production.</p>&#13;
&#13;
<p>If your Docker server is available via <code>localhost</code> (127.0.0.1), then you can use these files unmodified by simply copying each of them like this:<a data-primary="IP addresses" data-secondary="running a private registry" data-type="indexterm" id="idm46803153740496"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>cp<code class="w"> </code>config.yaml.sample<code class="w"> </code>config.yaml<code class="w"/>&#13;
<code class="gp">$ </code>cp<code class="w"> </code>registry.key.sample<code class="w"> </code>registry.key<code class="w"/>&#13;
<code class="gp">$ </code>cp<code class="w"> </code>registry.crt.sample<code class="w"> </code>registry.crt<code class="w"/>&#13;
<code class="gp">$ </code>cp<code class="w"> </code>htpasswd.sample<code class="w"> </code>htpasswd<code class="w"/></pre>&#13;
&#13;
<p>If, however, your Docker server is on a remote IP address, then you will need to do a little additional work.</p>&#13;
&#13;
<p>First, copy <em>config.yaml.sample</em> to <em>config.yaml</em>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>cp<code class="w"> </code>config.yaml.sample<code class="w"> </code>config.yaml<code class="w"/></pre>&#13;
&#13;
<p class="pagebreak-before">Then edit <em>config.yaml</em> and replace <code>127.0.0.1</code> with the IP address of your Docker server so that:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">http</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">host</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">https://127.0.0.1:5000</code><code class="w"/></pre>&#13;
&#13;
<p>becomes something like this:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">http</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">host</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">https://172.17.42.10:5000</code><code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>It is easy to create a registry using a fully qualified domain name (FQDN), like <code>my-registry.example.com</code>, but for this example, working with IP addresses is easier because no DNS is required.</p>&#13;
</div>&#13;
&#13;
<p>Next, you need to create an SSL keypair for your registry’s IP address.<a data-primary="SSL keypair for private registry" data-type="indexterm" id="idm46803153608192"/><a data-primary="openssl command" data-type="indexterm" id="idm46803153607520"/></p>&#13;
&#13;
<p>One way to do this is with the following OpenSSL command. Note that you will need to set the IP address in this portion of the command, <code>/CN=172.17.42.10</code>, to match your Docker server’s IP address:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>openssl<code class="w"> </code>req<code class="w"> </code>-x509<code class="w"> </code>-nodes<code class="w"> </code>-sha256<code class="w"> </code>-newkey<code class="w"> </code>rsa:4096<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>-keyout<code class="w"> </code>registry.key<code class="w"> </code>-out<code class="w"> </code>registry.crt<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>-days<code class="w"> </code><code class="m">14</code><code class="w"> </code>-subj<code class="w"> </code><code class="s1">'{/CN=172.17.42.10}'</code><code class="w"/></pre>&#13;
&#13;
<p>Finally, you can either use the example <code>htpasswd</code> file by copying it:<a data-primary="htpasswd file for private registry" data-type="indexterm" id="idm46803153559936"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>cp<code class="w"> </code>htpasswd.sample<code class="w"> </code>htpasswd<code class="w"/></pre>&#13;
&#13;
<p>or you can create your own<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="authentication username and password" data-type="indexterm" id="idm46803153543008"/> username and password pair for authentication by using a command like the following, replacing <code>${&lt;username&gt;}</code> and <code>${&lt;password&gt;}</code> with your preferred values:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>--entrypoint<code class="w"> </code>htpasswd<code class="w"> </code>g<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>-Bbn<code class="w"> </code><code class="si">${</code><code class="p">&lt;username&gt;</code><code class="si">}</code><code class="w"> </code><code class="si">${</code><code class="p">&lt;password&gt;</code><code class="si">}</code><code class="w"> </code>&gt;<code class="w"> </code>htpasswd<code class="w"/></pre>&#13;
&#13;
<p>If you look at the directory listing again, it should now look like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>ls<code class="w"/>&#13;
<code class="go">Dockerfile          config.yaml.sample  registry.crt        registry.key.sample</code>&#13;
<code class="go">README.md           htpasswd            registry.crt.sample</code>&#13;
<code class="go">config.yaml         htpasswd.sample     registry.key</code></pre>&#13;
&#13;
<p>If any of these files are missing, review the previous steps to ensure that you did not miss one, before moving on.</p>&#13;
&#13;
<p>If everything looks correct, then you should be ready to build and run the registry:<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="running a private registry" data-type="indexterm" id="idm46803153455808"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="running a private registry" data-type="indexterm" id="idm46803153479664"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="logs" data-tertiary="running a private registry" data-type="indexterm" id="idm46803153478336"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--rm to remove container on exit" data-tertiary-sortas="rm0" data-type="indexterm" id="idm46803153425888"/><a data-primary="logging" data-secondary="running a private registry" data-type="indexterm" id="idm46803153424160"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>my-registry<code class="w"> </code>.<code class="w"/>&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code>-p<code class="w"> </code><code class="m">5000</code>:5000<code class="w"> </code>--name<code class="w"> </code>registry<code class="w"> </code>my-registry<code class="w"/>&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>logs<code class="w"> </code>registry<code class="w"/></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>If you see errors like<a data-primary="Linux containers" data-secondary="configuring" data-tertiary="container name unique" data-type="indexterm" id="idm46803153399616"/> “docker: Error response from daemon: Conflict. The container name “/registry” is already in use,” then you need to either change the preceding container name or remove the existing container with that name. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="rm" data-tertiary="removing a container" data-type="indexterm" id="idm46803153398304"/><a data-primary="Linux containers" data-secondary="removing a container" data-type="indexterm" id="idm46803153396816"/><a data-primary="removing a container" data-type="indexterm" id="idm46803153395872"/>You can remove the container by running <code>docker container rm registry</code>.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Testing the private registry" data-type="sect3"><div class="sect3" id="idm46803153394432">&#13;
<h3>Testing the private registry</h3>&#13;
&#13;
<p>Now that the registry is running,<a data-primary="private registries" data-secondary="running a private registry" data-tertiary="testing the private registry" data-type="indexterm" id="idm46803153392736"/><a data-primary="testing" data-secondary="testing your private registry" data-type="indexterm" id="idm46803153391552"/><a data-primary="IP addresses" data-secondary="running a private registry" data-tertiary="testing the private registry" data-type="indexterm" id="idm46803153390640"/> you can test it. The very first thing that you need to do is authenticate against it. You will need to make sure that the IP address in the <code>docker login</code> matches the IP address of your Docker server that is running the registry.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p><code>myuser</code> is the default username, and <code>myuser-pw!</code> is the default password.&#13;
If you generated your own <code>htpasswd</code>, then these will be whatever you choose.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>login<code class="w"> </code><code class="m">127</code>.0.0.1:5000<code class="w"/>&#13;
<code class="go">Username: &lt;registry_username&gt;</code>&#13;
<code class="go">Password: &lt;registry_password&gt;</code>&#13;
<code class="go">Login Succeeded</code></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>This registry container has an<a data-primary="SSL keypair for private registry" data-type="indexterm" id="idm46803153350800"/><a data-primary="secrets" data-secondary="private registry" data-type="indexterm" id="idm46803153350192"/> embedded SSL key and is not using any external storage, which means that it contains a secret, and when you delete the running container, all your images will also be deleted. This is by design.</p>&#13;
&#13;
<p>In production, you will want to have<a data-primary="secrets" data-secondary="private registry" data-tertiary="production" data-type="indexterm" id="idm46803153348736"/><a data-primary="production" data-secondary="secrets" data-type="indexterm" id="idm46803153347488"/> your containers pull secrets from a secrets management system and use some type of redundant external storage, like an object store. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="--mount" data-secondary-sortas="mount" data-type="indexterm" id="idm46803153346416"/>If you want to keep your development registry images between containers, you could add something like <code>--mount type=bind,source=/tmp/registry-data,target=/var/lib/registry</code> to your <code>docker container run</code> command to store the registry data on the Docker server.</p>&#13;
</div>&#13;
&#13;
<p>Now, let’s see if you can push the image you just built into your local private registry.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>In all of these commands, ensure that you use the correct IP address for your registry.</p>&#13;
</div>&#13;
&#13;
<pre class="pagebreak-before" data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>tag<code class="w"> </code>my-registry<code class="w"> </code><code class="m">127</code>.0.0.1:5000/my-registry<code class="w"/>&#13;
<code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>push<code class="w"> </code><code class="m">127</code>.0.0.1:5000/my-registry<code class="w"/>&#13;
<code class="go">Using default tag: latest</code>&#13;
<code class="go">The push refers to repository [127.0.0.1:5000/my-registry]</code>&#13;
<code class="go">f09a0346302c: Pushed</code>&#13;
<code class="go">…</code>&#13;
<code class="go">4fc242d58285: Pushed</code>&#13;
<code class="go">latest: digest: sha256:c374b0a721a12c41d5b298930d11e658fbd37f22dc2a0fac7d6a2…</code></pre>&#13;
&#13;
<p>You can then try to pull the same image from your repository:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>pull<code class="w"> </code><code class="m">127</code>.0.0.1:5000/my-registry<code class="w"/>&#13;
<code class="go">Using default tag: latest</code>&#13;
<code class="go">latest: Pulling from my-registry</code>&#13;
<code class="go">Digest: sha256:c374b0a721a12c41d5b298930d11e658fbd37f22dc2a0fac7d6a2ecdc0ba5490</code>&#13;
<code class="go">Status: Image is up to date for 127.0.0.1:5000/my-registry:latest</code>&#13;
<code class="go">127.0.0.1:5000/my-registry:latest</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>It’s worth keeping in mind that<a data-primary="Docker Hub" data-primary-sortas="docker-a" data-secondary="API endpoint information" data-type="indexterm" id="idm46803153257792"/><a data-primary="Docker" data-primary-sortas="docker-a" data-secondary="API endpoint information" data-type="indexterm" id="idm46803153256640"/><a data-primary="APIs" data-secondary="API endpoint information" data-type="indexterm" id="idm46803153255456"/><a data-primary="documentation" data-secondary="API endpoint information" data-type="indexterm" id="idm46803153254544"/><a data-primary="resources online" data-secondary="API endpoint information" data-type="indexterm" id="idm46803153253632"/> both Docker Hub and Docker Distribution expose an API endpoint that you can query for useful information. You can find out more information about the API via the <a href="https://github.com/distribution/distribution/blob/main/docs/spec/api.md">official documentation</a>.</p>&#13;
</div>&#13;
&#13;
<p>If you have not encountered any errors, then you have a working registry for development and can build on this foundation to create a production registry. At this point, you may want to stop the registry for the time being. You can easily accomplish this by running the following:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>stop<code class="w"> </code>registry<code class="w"/></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>As you become comfortable with Docker Distribution, you may also want to consider exploring the Cloud Native Computing Foundation (CNCF) open source project, called <a href="https://goharbor.io">Harbor</a>, which extends the Docker Distribution with a lot of security and reliability-focused features.<a data-startref="ch04-runpriv" data-type="indexterm" id="idm46803155956416"/><a data-startref="ch04-runpriv2" data-type="indexterm" id="idm46803153230608"/><a data-startref="ch04-runpriv3" data-type="indexterm" id="idm46803153229936"/><a data-startref="ch04-runpriv4" data-type="indexterm" id="idm46803153229264"/><a data-startref="ch04-runpriv5" data-type="indexterm" id="idm46803153228592"/></p>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Optimizing Images" data-type="sect1"><div class="sect1" id="idm46803153843344">&#13;
<h1>Optimizing Images</h1>&#13;
&#13;
<p>After you have spent a little bit of time working<a data-primary="OCI images" data-secondary="optimizing" data-tertiary="about" data-type="indexterm" id="idm46803153226608"/> with Docker, you will quickly notice that keeping your image sizes small and your build times fast can be very beneficial in decreasing the time required to build and deploy new versions of your software into production. In this section, we will talk a bit about some of the considerations you should always keep in mind when designing your images and a few techniques that can help you achieve these goals.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Keeping Images Small" data-type="sect2"><div class="sect2" id="small_images">&#13;
<h2>Keeping Images Small</h2>&#13;
&#13;
<p>In most modern businesses, downloading<a data-primary="OCI images" data-secondary="optimizing" data-tertiary="keeping images small" data-type="indexterm" id="ch04-small"/> a single 1 GB file from a remote location on the internet is not something that people often worry about. It is so easy to find software on the internet that people will often rely on simply re-downloading it if they need it again, instead of keeping a local copy for the future. This may often be acceptable when you truly need a single copy of this software on a single server, but it can quickly become a scaling problem when you need the same software on 100+ nodes and you deploy new releases multiple times a day. Downloading these large files can quickly cause network congestion and slower deployment cycles that have a real impact on the production environment.</p>&#13;
&#13;
<p>For convenience, a large number <a data-primary="Linux containers" data-secondary="inspecting a container" data-tertiary="minimal container example" data-type="indexterm" id="idm46803153190752"/>of Linux containers inherit from a base image that contains a minimal Linux distribution. Although this is an easy starting place, it isn’t required. Containers only need to contain the files that are required to run the application on the host kernel, and nothing else. The best way to explain this is to explore a very minimal container.</p>&#13;
&#13;
<p>Go is a compiled programming language<a data-primary="Go language" data-secondary="minimal container example" data-type="indexterm" id="idm46803153189024"/> that can easily generate statically compiled binary files. For this example, we are going to use a very small web application written in Go that can be found on <a href="https://github.com/spkane/scratch-helloworld">GitHub</a>.</p>&#13;
&#13;
<p>Let’s go ahead and try out the application so that you can see what it does. Run the following command, and then open up a web browser and point it to your Docker host on port 8080 (e.g., <em>http://127.0.0.1:8080</em> for Docker Desktop and Community Edition):</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code>-p<code class="w"> </code><code class="m">8080</code>:8080<code class="w"> </code>spkane/scratch-helloworld<code class="w"/></pre>&#13;
&#13;
<p>If all goes well, you should see the following message in your web browser: “Hello World from Go in minimal Linux container.” Now let’s take a look at what files this container comprises. It would be fair to assume that at a minimum it will include a working Linux environment and all the files required to compile Go programs, but you will soon see that this is not the case.</p>&#13;
&#13;
<p>While the container is still running,<a data-primary="Linux containers" data-secondary="container ID retrieved" data-type="indexterm" id="idm46803153165920"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="container ID retrieved" data-type="indexterm" id="idm46803153165072"/> execute the following command to determine what the container ID is. The following command returns the information for the last container that you created:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"> </code>-l<code class="w"/>&#13;
<code class="go">CONTAINER ID IMAGE                     COMMAND       CREATED           …</code>&#13;
<code class="go">ddc3f61f311b spkane/scratch-helloworld "/helloworld" 4 minutes ago     …</code></pre>&#13;
&#13;
<p>You can then use the container ID that you obtained from running the previous command to export the files in the container into a tarball, which can be easily examined:<a data-primary="Linux containers" data-secondary="exporting contained files into tarball" data-type="indexterm" id="idm46803153160928"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="export contained files to tarball" data-type="indexterm" id="idm46803153160080"/><a data-primary="exporting container files to a tarball" data-type="indexterm" id="idm46803153158960"/><a data-primary="filesystem layers of Linux containers" data-secondary="exporting to a tarball" data-type="indexterm" id="idm46803153158320"/><a data-primary="OCI images" data-secondary="filesystem layers" data-tertiary="exporting files to a tarball" data-type="indexterm" id="idm46803153157408"/><a data-primary="Linux containers" data-secondary="filesystem layers" data-tertiary="exporting to a tarball" data-type="indexterm" id="idm46803153135024"/><a data-primary="OCI images" data-secondary="exporting files to a tarball" data-type="indexterm" id="idm46803153133808"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code><code class="nb">export</code><code class="w"> </code>ddc3f61f311b<code class="w"> </code>-o<code class="w"> </code>web-app.tar<code class="w"/></pre>&#13;
&#13;
<p>Using the <code>tar</code> command, you can now examine the contents of your container at the time of the export:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>tar<code class="w"> </code>-tvf<code class="w"> </code>web-app.tar<code class="w"/>&#13;
<code class="go">-rwxr-xr-x  0 0      0           0 Jan  7 15:54 .dockerenv</code>&#13;
<code class="go">drwxr-xr-x  0 0      0           0 Jan  7 15:54 dev/</code>&#13;
<code class="go">-rwxr-xr-x  0 0      0           0 Jan  7 15:54 dev/console</code>&#13;
<code class="go">drwxr-xr-x  0 0      0           0 Jan  7 15:54 dev/pts/</code>&#13;
<code class="go">drwxr-xr-x  0 0      0           0 Jan  7 15:54 dev/shm/</code>&#13;
<code class="go">drwxr-xr-x  0 0      0           0 Jan  7 15:54 etc/</code>&#13;
<code class="go">-rwxr-xr-x  0 0      0           0 Jan  7 15:54 etc/hostname</code>&#13;
<code class="go">-rwxr-xr-x  0 0      0           0 Jan  7 15:54 etc/hosts</code>&#13;
<code class="go">lrwxrwxrwx  0 0      0           0 Jan  7 15:54 etc/mtab -&gt; /proc/mounts</code>&#13;
<code class="go">-rwxr-xr-x  0 0      0           0 Jan  7 15:54 etc/resolv.conf</code>&#13;
<code class="go">-rwxr-xr-x  0 0      0     3604416 Jul  2  2014 helloworld</code>&#13;
<code class="go">drwxr-xr-x  0 0      0           0 Jan  7 15:54 proc/</code>&#13;
<code class="go">drwxr-xr-x  0 0      0           0 Jan  7 15:54 sys/</code></pre>&#13;
&#13;
<p>The first thing you might notice here is that there are almost no files in this container, and almost all of them are zero bytes in length. All of the files that have a zero length are required to exist in every Linux container and are automatically <a href="https://unix.stackexchange.com/questions/198590/what-is-a-bind-mount">bind-mounted</a> from the host into the container when it is first created. All of these files, except for <em>.dockerenv</em>, are critical files that the kernel needs to do its job properly. The only file in this container that has any actual size and is related to our application is the statically compiled <code>helloworld</code> binary.</p>&#13;
&#13;
<p>The takeaway from this exercise is that your containers are only required to contain exactly what they need to run on the underlying kernel. Everything else is unnecessary. Because it is often useful for troubleshooting to have access to a working shell in your container, people will often compromise and build their images from<a data-primary="Alpine Linux" data-secondary="small distribution size" data-type="indexterm" id="idm46803153052400"/><a data-primary="Linux" data-secondary="Alpine Linux for small distribution size" data-type="indexterm" id="idm46803153051424"/> a very lightweight Linux distribution like Alpine Linux.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>If you find yourself exploring image<a data-primary="dive tool for exploring image contents" data-type="indexterm" id="idm46803153049408"/><a data-primary="OCI images" data-secondary="exploring contents via dive tool" data-type="indexterm" id="idm46803153048736"/> files a lot, you might want to take a look at the tool <a href="https://github.com/wagoodman/dive">dive</a>, which provides a nice CLI interface for understanding what an image contains.</p>&#13;
</div>&#13;
&#13;
<p>To dive into this a little deeper, let’s look at that same container again so that we can dig into the underlying filesystem and compare it with the popular <code>alpine</code> base image.</p>&#13;
&#13;
<p>Although we could easily poke<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-ti for interactive terminal" data-tertiary-sortas="ti" data-type="indexterm" id="idm46803153045664"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-it for interactive terminal" data-tertiary-sortas="it" data-type="indexterm" id="idm46803153026032"/> around in the <code>alpine</code> image by simply running <code>docker container run -ti alpine:latest /bin/sh</code>, we cannot do this with the <code>spkane/scratch-helloworld</code> image, because it does not contain a shell or SSH. This means that we can’t use <code>ssh</code>, <code>nsenter</code>, or <code>docker container exec</code> to examine it, though there is an advanced trick discussed in <a data-type="xref" href="ch11.html#shellless">“Debugging Shell-less Containers”</a>. Earlier, we took advantage of the <code>docker container export</code> command to create a <em>.tar</em> file that contained a copy of all the files in the container, <a data-primary="Linux containers" data-secondary="filesystem layers" data-tertiary="examining in server image files" data-type="indexterm" id="ch04-file"/><a data-primary="filesystem layers of Linux containers" data-secondary="examining in server image files" data-type="indexterm" id="ch04-file2"/><a data-primary="OCI images" data-secondary="filesystem layers" data-tertiary="server image files examined" data-type="indexterm" id="ch04-file3"/>but this time around we are going to examine the container’s filesystem by connecting directly to the Docker server and then looking into the container’s filesystem itself. To do this, we need to find out where the image files reside on the server’s disk.</p>&#13;
&#13;
<p>To determine where on the server<a data-primary="Docker server" data-primary-sortas="docker-a" data-secondary="image file location" data-type="indexterm" id="idm46803153015264"/><a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="inspect to locate server image files" data-type="indexterm" id="idm46803153014080"/> our files are actually being stored, run <code>docker image inspect</code> on the <code>alpine:latest</code> image:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>inspect<code class="w"> </code>alpine:latest<code class="w"/></pre>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">[</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Id"</code><code class="p">:</code><code class="w"> </code><code class="s2">"sha256:3fd…353"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"RepoTags"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">            </code><code class="s2">"alpine:latest"</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">],</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"RepoDigests"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">            </code><code class="s2">"alpine@sha256:7b8…f8b"</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">],</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"GraphDriver"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"Data"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"MergedDir"</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"/var/lib/docker/overlay2/ea8…13a/merged"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"UpperDir"</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"/var/lib/docker/overlay2/ea8…13a/diff"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"WorkDir"</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"/var/lib/docker/overlay2/ea8…13a/work"</code><code class="w"/>&#13;
<code class="w">            </code><code class="p">},</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"Name"</code><code class="p">:</code><code class="w"> </code><code class="s2">"overlay2"</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">}</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">}</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>And then on the <code>spkane/scratch-helloworld:latest</code> image:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>inspect<code class="w"> </code>spkane/scratch-helloworld:latest<code class="w"/></pre>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">[</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Id"</code><code class="p">:</code><code class="w"> </code><code class="s2">"sha256:4fa…06d"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"RepoTags"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">            </code><code class="s2">"spkane/scratch-helloworld:latest"</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">],</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"RepoDigests"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">            </code><code class="s2">"spkane/scratch-helloworld@sha256:46d…a1d"</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">],</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"GraphDriver"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"Data"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"LowerDir"</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"/var/lib/docker/overlay2/37a…84d/diff:</code>&#13;
<code class="s2">                /var/lib/docker/overlay2/28d…ef4/diff"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"MergedDir"</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"/var/lib/docker/overlay2/fc9…c91/merged"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"UpperDir"</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"/var/lib/docker/overlay2/fc9…c91/diff"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"WorkDir"</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"/var/lib/docker/overlay2/fc9…c91/work"</code><code class="w"/>&#13;
<code class="w">            </code><code class="p">},</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"Name"</code><code class="p">:</code><code class="w"> </code><code class="s2">"overlay2"</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">}</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">}</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="p">]</code><code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>In this particular example, we are going to use Docker Desktop running on macOS, but this general approach will work on most Docker servers. However, you can access your Docker server via whatever method is easiest.</p>&#13;
</div>&#13;
&#13;
<p>Since we are using Docker Desktop,<a data-primary="nsenter for Docker server access" data-type="indexterm" id="idm46803152660848"/><a data-primary="Docker Desktop" data-primary-sortas="docker-a" data-secondary="nsenter for Docker server access" data-type="indexterm" id="idm46803152660240"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="nsenter for Docker server access" data-type="indexterm" id="idm46803152659056"/> we need to use our <code>nsenter</code> trick to enter the SSH-less VM and explore the filesystem:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>--privileged<code class="w"> </code>--pid<code class="o">=</code>host<code class="w"> </code>debian<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>nsenter<code class="w"> </code>-t<code class="w"> </code><code class="m">1</code><code class="w"> </code>-m<code class="w"> </code>-u<code class="w"> </code>-n<code class="w"> </code>-i<code class="w"> </code>sh<code class="w"/>&#13;
&#13;
<code class="go">/ #</code></pre>&#13;
&#13;
<p>Inside the VM, we should now be able to explore the various directories listed in the <code>GraphDriver</code> section of the <code>docker image inspect</code> commands.</p>&#13;
&#13;
<p>In this example, if we look at the first entry for the <code>alpine</code> image, we will see that it is labeled <code>MergedDir</code> and lists the folder <em>/var/lib/docker/overlay2/ea86408b2b15d33ee27d78ff44f82104705286221f055ba1331b58673f4b313a/merged</em>. If we list that directory, we will get an error, but from listing the parent directory, we quickly discover that we actually want to look at the <em>diff</em> directory:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="go">/ # ls -lFa /var/lib/docker/overlay2/ea…3a/merged</code>&#13;
&#13;
<code class="go">ls: /var/lib/docker/overlay2/ea..3a/merged: No such file or directory</code>&#13;
&#13;
<code class="go">/ # ls -lF /var/lib/docker/overlay2/ea…3a/</code>&#13;
&#13;
<code class="go">total 8</code>&#13;
<code class="go">drwxr-xr-x   18 root     root          4096 Mar 15 19:27 diff/</code>&#13;
<code class="go">-rw-r--r--    1 root     root            26 Mar 15 19:27 link</code>&#13;
&#13;
<code class="go">/ # ls -lF /var/lib/docker/overlay2/ea…3a/diff</code>&#13;
&#13;
<code class="go">total 64</code>&#13;
<code class="go">drwxr-xr-x    2 root     root          4096 Jan  9 19:37 bin/</code>&#13;
<code class="go">drwxr-xr-x    2 root     root          4096 Jan  9 19:37 dev/</code>&#13;
<code class="go">drwxr-xr-x   15 root     root          4096 Jan  9 19:37 etc/</code>&#13;
<code class="go">drwxr-xr-x    2 root     root          4096 Jan  9 19:37 home/</code>&#13;
<code class="go">drwxr-xr-x    5 root     root          4096 Jan  9 19:37 lib/</code>&#13;
<code class="go">drwxr-xr-x    5 root     root          4096 Jan  9 19:37 media/</code>&#13;
<code class="go">drwxr-xr-x    2 root     root          4096 Jan  9 19:37 mnt/</code>&#13;
<code class="go">dr-xr-xr-x    2 root     root          4096 Jan  9 19:37 proc/</code>&#13;
<code class="go">drwx------    2 root     root          4096 Jan  9 19:37 root/</code>&#13;
<code class="go">drwxr-xr-x    2 root     root          4096 Jan  9 19:37 run/</code>&#13;
<code class="go">drwxr-xr-x    2 root     root          4096 Jan  9 19:37 sbin/</code>&#13;
<code class="go">drwxr-xr-x    2 root     root          4096 Jan  9 19:37 srv/</code>&#13;
<code class="go">drwxr-xr-x    2 root     root          4096 Jan  9 19:37 sys/</code>&#13;
<code class="go">drwxrwxrwt    2 root     root          4096 Jan  9 19:37 tmp/</code>&#13;
<code class="go">drwxr-xr-x    7 root     root          4096 Jan  9 19:37 usr/</code>&#13;
<code class="go">drwxr-xr-x   11 root     root          4096 Jan  9 19:37 var/</code>&#13;
&#13;
<code class="go">/ # du -sh  /var/lib/docker/overlay2/ea…3a/diff</code>&#13;
<code class="go">4.5M    /var/lib/docker/overlay2/ea…3a/diff</code></pre>&#13;
&#13;
<p>Now, <code>alpine</code> happens to be a<a data-primary="Alpine Linux" data-secondary="small distribution size" data-type="indexterm" id="idm46803152558384"/><a data-primary="Linux" data-secondary="Alpine Linux for small distribution size" data-type="indexterm" id="idm46803152557472"/> very small base image, weighing in at only 4.5 MB, and it is ideal for building containers on top of it. However, we can see that there is still a lot of stuff in this container before we have started to build anything from it.</p>&#13;
&#13;
<p>Now, let’s take a look at the files in the <code>spkane/scratch-helloworld</code> image. In this case, we want to look at the first directory from the <code>LowerDir</code> entry of the <code>docker image inspect</code> output, which you’ll notice also ends in a directory called <em>diff</em>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="go">/ # ls -lFh /var/lib/docker/overlay2/37…4d/diff</code>&#13;
&#13;
<code class="go">total 3520</code>&#13;
<code class="go">-rwxr-xr-x    1 root     root        3.4M Jul  2  2014 helloworld*</code>&#13;
&#13;
<code class="go">/ # exit</code></pre>&#13;
&#13;
<p>You’ll notice that there is only a single file in this directory, and it is 3.4 MB. This <code>helloworld</code> binary is the only file shipped in this container and is smaller than the starting size of the <code>alpine</code> image before any application files have been added to it.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>It is possible to run the <code>helloworld</code> application from that directory on your Docker server because it does not require any other files. You really don’t want to do this on anything but a development box, but it can help drive the point home about how useful these types of statically compiled applications can be.<a data-startref="ch04-file" data-type="indexterm" id="idm46803152596432"/><a data-startref="ch04-file2" data-type="indexterm" id="idm46803152595760"/><a data-startref="ch04-file3" data-type="indexterm" id="idm46803152591936"/></p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Multistage builds" data-type="sect3"><div class="sect3" id="multi_stage">&#13;
<h3>Multistage builds</h3>&#13;
&#13;
<p>There is a way you can constrain<a data-primary="OCI images" data-secondary="optimizing" data-tertiary="smaller with multistage builds" data-type="indexterm" id="ch04-multi"/><a data-primary="multistage builds for smaller images" data-type="indexterm" id="ch04-multi2"/><a data-primary="OCI images" data-secondary="building an image" data-tertiary="multistage builds for smaller images" data-type="indexterm" id="ch04-multi3"/><a data-primary="OCI images" data-secondary="building an image" data-tertiary="multistage builds in production" data-type="indexterm" id="idm46803152585184"/><a data-primary="multistage builds for smaller images" data-secondary="production builds multistage" data-type="indexterm" id="idm46803152584000"/><a data-primary="Linux containers" data-secondary="small containers via multistage build" data-type="indexterm" id="idm46803152583120"/><a data-primary="production" data-secondary="multistage builds" data-type="indexterm" id="idm46803152524256"/> containers to an even smaller size in many cases: multistage builds. This is how we recommend that you build most production containers. You don’t have to worry as much about bringing in extra resources to build your application, and you can still run a lean production container. Multistage containers also encourage doing builds inside Docker, which is a great pattern for repeatability in your build system.</p>&#13;
&#13;
<p>As the original author of <a href="https://medium.com/@adriaandejonge/simplify-the-smallest-possible-docker-image-62c0e0d342ef">the <code>scratch-helloworld</code> application has written</a>, the release of multistage build support in Docker itself has made the process of creating small containers much easier than it used to be. In the past, to do the same thing that multistage delivers for nearly free, you were required to build one image that compiled your code, extract the resulting binary, and then build a second image without all the build dependencies that you would then inject that binary into. This was often difficult to set up and did not always work out of the box with standard deployment pipelines.</p>&#13;
&#13;
<p>Today, you can now achieve similar results using a <em>Dockerfile</em> as simple as this one:<a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="multistage builds for smaller containers" data-type="indexterm" id="idm46803152520896"/></p>&#13;
&#13;
<pre data-code-language="dockerfile" data-type="programlisting"><code class="c"># Build container</code><code class="w"/>&#13;
<code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/golang:alpine</code><code class="w"> </code><code class="k">as</code><code class="w"> </code><code class="s">builder</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>apk<code class="w"> </code>update<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>apk<code class="w"> </code>add<code class="w"> </code>git<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code><code class="nv">CGO_ENABLED</code><code class="o">=</code><code class="m">0</code><code class="w"> </code>go<code class="w"> </code>install<code class="w"> </code>-a<code class="w"> </code>-ldflags<code class="w"> </code><code class="s1">'-s'</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>github.com/spkane/scratch-helloworld@latest<code class="w"/>&#13;
&#13;
<code class="c"># Production container</code><code class="w"/>&#13;
<code class="k">FROM</code><code class="w"> </code><code class="s">scratch</code><code class="w"/>&#13;
<code class="k">COPY</code><code class="w"> </code>--from<code class="o">=</code>builder<code class="w"> </code>/go/bin/scratch-helloworld<code class="w"> </code>/helloworld<code class="w"/>&#13;
<code class="k">EXPOSE</code><code class="w"> </code><code class="s">8080</code><code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"/helloworld"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>The first thing you’ll notice about this <em>Dockerfile</em> is that it looks a lot like two <em>Dockerfile</em>s that have been combined into one. Indeed this is the case, but there is more to it. The <code>FROM</code> command has been extended so that you can name the image during the build phase. In this example, the first line, which reads <code>FROM docker.io/golang as builder</code>, means that you want to base your build on the <code>golang</code> image and will be referring to this build image/stage as <code>builder</code>.</p>&#13;
&#13;
<p>On the fourth line, you’ll see another <code>FROM</code> line, which was not allowed before the introduction of multistage builds. This <code>FROM</code> line uses a special image name, called <code>scratch</code>, that tells Docker to start from an empty image, which includes no additional files. The next line, which reads <code>COPY --from=builder &#13;
<span class="keep-together">/go/bin/scratch-helloworld /helloworld</span></code>, allows you to copy the binary that you built in the <em>builder</em> image directly into the current image. This will ensure that you end up with the smallest container possible.</p>&#13;
&#13;
<p>The <code>EXPOSE 8080</code> line is documentation that is intended to inform users which port(s) and protocols (TCP is the default protocol) the service listens on.</p>&#13;
&#13;
<p>Let’s try to build this and see what happens. First, create a directory where you can work, and then, using your favorite text editor, paste the content from the preceding example into a file called <em>Dockerfile</em>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>mkdir<code class="w"> </code>/tmp/multi-build<code class="w"/>&#13;
<code class="gp">$ </code><code class="nb">cd</code><code class="w"> </code>/tmp/multi-build<code class="w"/>&#13;
<code class="gp">$ </code>vi<code class="w"> </code>Dockerfile<code class="w"/></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>You can download a copy of this <em>Dockerfile</em> from <a href="https://oreil.ly/C1TSz">GitHub</a>.<sup><a data-type="noteref" href="ch04.html#idm46803152409712" id="idm46803152409712-marker">5</a></sup></p>&#13;
</div>&#13;
&#13;
<p>We can now start the multistage build:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">[+] Building 9.7s (7/7) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 37B</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 2B</code>&#13;
<code class="go"> =&gt; [internal] load metadata for docker.io/library/golang:alpine</code>&#13;
<code class="go"> =&gt; CACHED [builder 1/2] FROM docker.io/library/golang:alpine@sha256:7cc6257…</code>&#13;
<code class="go"> =&gt; [builder 2/2] RUN apk update &amp;&amp; apk add git &amp;&amp; CGO_ENABLED=0 go install …</code>&#13;
<code class="go"> =&gt; [stage-1 1/1] COPY --from=builder /go/bin/scratch-helloworld /helloworld</code>&#13;
<code class="go"> =&gt; exporting to image</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:bb853f23418161927498b9631f54692cf11d84d6bde3af2d…</code></pre>&#13;
&#13;
<p>You’ll notice that the output looks like most other builds and still ends by reporting the successful creation of our final, very minimal image.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>If you are compiling binaries on your local system that use shared libraries, you need to be careful to ensure that the correct versions of those shared libraries are also available to the process inside the container.</p>&#13;
</div>&#13;
&#13;
<p>You are not limited to two stages, and in fact, none of the stages need to even be related to one another. They will be run in order. You could, for example, have a stage based on the public Go image that builds your underlying Go application to serve an API, and another stage based on the Angular container to build your frontend web UI. The final stage could then combine outputs from both.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>As you start to build more complex images, you may find that being limited to a single build context is challenging. The <code>docker-buildx</code> plug-in, which we discuss near the end of this chapter, is capable of supporting <a href="https://www.docker.com/blog/dockerfiles-now-support-multiple-build-contexts">multiple build contexts</a>, which can be used to support some very advanced workflows.<a data-startref="ch04-small" data-type="indexterm" id="idm46803152386656"/><a data-startref="ch04-multi" data-type="indexterm" id="idm46803152385952"/><a data-startref="ch04-multi2" data-type="indexterm" id="idm46803152385280"/><a data-startref="ch04-multi3" data-type="indexterm" id="idm46803152384608"/></p>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Layers Are Additive" data-type="sect2"><div class="sect2" id="idm46803153194016">&#13;
<h2>Layers Are Additive</h2>&#13;
&#13;
<p>Something that is not apparent<a data-primary="OCI images" data-secondary="optimizing" data-tertiary="layers additive" data-type="indexterm" id="ch04-add"/><a data-primary="filesystem layers of Linux containers" data-secondary="additive" data-type="indexterm" id="ch04-add2"/><a data-primary="Linux containers" data-secondary="filesystem layers" data-tertiary="additive" data-type="indexterm" id="ch04-add3"/><a data-primary="OCI images" data-secondary="filesystem layers" data-tertiary="additive" data-type="indexterm" id="ch04-add4"/> until you dig much deeper into how images are built is that the filesystem layers that make up your images are strictly additive by design. Although you can shadow/mask files in previous layers, you cannot delete those files. In practice, this means that you cannot make your image smaller by simply deleting files that were generated in earlier steps.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If you enable experimental features<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="--squash to combine layers" data-tertiary-sortas="squash" data-type="indexterm" id="ch04-sqsh"/> on your Docker server, it is possible to squash a bunch of layers into a single layer using <code>docker image build --squash</code>. This will cause all of the files that were deleted in the intermediate layers to actually disappear from the final image and can therefore recover a lot of wasted space, but it also means that the whole layer must be downloaded by every system that requires it, even when only a single line of source code was updated, so there are real trade-offs to using this approach.</p>&#13;
</div>&#13;
&#13;
<p>The easiest way to explain the additive nature of image layers is by using some practical examples. In a new directory, <a href="https://github.com/bluewhalebook/docker-up-and-running-3rd-edition/blob/main/chapter_04/additive">download</a> or create the following file, which will generate an image that launches the Apache web server running on Fedora Linux:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/fedora</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>dnf<code class="w"> </code>install<code class="w"> </code>-y<code class="w"> </code>httpd<code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"/usr/sbin/httpd"</code><code class="p">,</code><code class="w"> </code><code class="s2">"-DFOREGROUND"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>and then build it like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">[+] Building 63.5s (6/6) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 130B</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 2B</code>&#13;
<code class="go"> =&gt; [internal] load metadata for docker.io/library/fedora:latest</code>&#13;
<code class="go"> =&gt; [1/2] FROM docker.io/library/fedora</code>&#13;
<code class="go"> =&gt; [2/2] RUN dnf install -y httpd</code>&#13;
<code class="go"> =&gt; exporting to image</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:543d61c956778b8ea3b32f1e09a9354a864467772e6…</code></pre>&#13;
&#13;
<p>Let’s go ahead and tag the resulting image so that you can easily refer to it in subsequent commands:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>tag<code class="w"> </code>sha256:543d61c956778b8ea3b32f1e09a9354a864467772e6…<code class="w"> </code>size1<code class="w"/></pre>&#13;
&#13;
<p>Now let’s take a look at our image<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="history" data-tertiary="filesystem layers and build steps" data-type="indexterm" id="idm46803152223504"/><a data-primary="OCI images" data-secondary="filesystem layers" data-tertiary="history and build steps" data-type="indexterm" id="idm46803152278912"/><a data-primary="filesystem layers of Linux containers" data-secondary="additive" data-tertiary="history and build steps" data-type="indexterm" id="idm46803152277696"/><a data-primary="Linux containers" data-secondary="filesystem layers" data-tertiary="history and build steps" data-type="indexterm" id="idm46803152276512"/> with the <code>docker image history</code> command. This command will give us some insight into the filesystem layers and build steps that our image uses:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code><code class="nb">history</code><code class="w"> </code>size1<code class="w"/>&#13;
<code class="go">IMAGE        CREATED            CREATED BY                            SIZE  …</code>&#13;
<code class="go">543d61c95677 About a minute ago CMD ["/usr/sbin/httpd" "-DFOREGROU…"] 0B</code>&#13;
<code class="go">&lt;missing&gt;    About a minute ago RUN /bin/sh -c dnf install -y httpd … 273MB</code>&#13;
<code class="go">&lt;missing&gt;    6 weeks ago        /bin/sh -c #(nop)  CMD ["/bin/bash"]… 0B</code>&#13;
<code class="go">&lt;missing&gt;    6 weeks ago        /bin/sh -c #(nop) ADD file:58865512c… 163MB</code>&#13;
<code class="go">&lt;missing&gt;    3 months ago       /bin/sh -c #(nop)  ENV DISTTAG=f36co… 0B</code>&#13;
<code class="go">&lt;missing&gt;    15 months ago      /bin/sh -c #(nop)  LABEL maintainer=… 0B</code></pre>&#13;
&#13;
<p>You’ll notice that three of the layers added no size to our final image, but two of them increase the size a great deal. The layer that is 163 MB makes sense, as this is the base Fedora image that includes a minimal Linux distribution; however, the 273 MB layer is surprising. The Apache web server shouldn’t be nearly that large, so what’s going on here, exactly?</p>&#13;
&#13;
<p>If you have experience with package managers like <code>apk</code>, <code>apt</code>, <code>dnf</code>, or <code>yum</code>, then you may know that <a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="deleting cache in image layers" data-type="indexterm" id="idm46803152161568"/>most of these tools rely heavily on a large cache that includes details about all the packages that are available for installation on the platform in question. This cache uses up a huge amount of space and is completely useless once you have installed the packages you need. The most obvious next step is to simply delete the cache. On Fedora systems, you could do this by editing your <em>Dockerfile</em> so that it looks like this:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/fedora</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>dnf<code class="w"> </code>install<code class="w"> </code>-y<code class="w"> </code>httpd<code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>dnf<code class="w"> </code>clean<code class="w"> </code>all<code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"/usr/sbin/httpd"</code><code class="p">,</code><code class="w"> </code><code class="s2">"-DFOREGROUND"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>and then building, tagging, and examining the resulting image:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">[+] Building 0.5s (7/7) FINISHED</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:b6bf99c6e7a69a1229ef63fc086836ada20265a793cb8f2d…</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>tag<code class="w"> </code>sha256:b6bf99c6e7a69a1229ef63fc086836ada20265a793cb8f2d17…<code class="w"/>&#13;
<code class="go">IMAGE        CREATED            CREATED BY                            SIZE  …</code>&#13;
<code class="go">b6bf99c6e7a6 About a minute ago CMD ["/usr/sbin/httpd" "-DFOREGROU…"] 0B</code>&#13;
<code class="go">&lt;missing&gt;    About a minute ago RUN /bin/sh -c dnf clean all # build… 71.8kB</code>&#13;
<code class="go">&lt;missing&gt;    10 minutes ago     RUN /bin/sh -c dnf install -y httpd … 273MB</code>&#13;
<code class="go">&lt;missing&gt;    6 weeks ago        /bin/sh -c #(nop)  CMD ["/bin/bash"]… 0B</code>&#13;
<code class="go">&lt;missing&gt;    6 weeks ago        /bin/sh -c #(nop) ADD file:58865512c… 163MB</code>&#13;
<code class="go">&lt;missing&gt;    3 months ago       /bin/sh -c #(nop)  ENV DISTTAG=f36co… 0B</code>&#13;
<code class="go">&lt;missing&gt;    15 months ago      /bin/sh -c #(nop)  LABEL maintainer=… 0B</code></pre>&#13;
&#13;
<p>If you look carefully at the output from the <code>docker image history</code> command, you’ll notice that you have created a new layer that adds <code>71.8kB</code> to the image, but you have not decreased the size of the problematic layer at all. What is happening, exactly?</p>&#13;
&#13;
<p>The important thing to understand is that image layers are strictly <em>additive</em> in nature. Once a layer is created, nothing can be removed from it. This means that you cannot make earlier layers in an image smaller by deleting files in subsequent layers. When you delete or edit files in subsequent layers, you’re simply masking the older version with the modified or removed version in the new layer. This means that the only way you can make a layer smaller is by removing files before you save the layer.</p>&#13;
&#13;
<p>The most common way to deal with<a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="&amp;&amp; operator to string commands" data-type="indexterm" id="idm46803152041440"/><a data-primary="&amp;&amp; operator in Dockerfiles" data-type="indexterm" id="idm46803152040336"/><a data-primary="OCI images" data-secondary="optimizing" data-tertiary="&amp;&amp; operator in Dockerfiles" data-type="indexterm" id="idm46803152039696"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="/ operator for command continuation" data-type="indexterm" id="idm46803152038512"/><a data-primary="/ operator in Dockerfiles" data-type="indexterm" id="idm46803152076592"/><a data-primary="OCI images" data-secondary="optimizing" data-tertiary="/ operator in Dockerfiles" data-type="indexterm" id="idm46803152075952"/> this is by stringing commands together on a single <em>Dockerfile</em> line. You can do this very easily by taking advantage of the <code>&amp;&amp;</code> operator. This operator acts as a Boolean <code>AND</code> statement and basically translates into English as “and if the previous command ran successfully, run this command.” In addition to this, you can take advantage of the <code>\</code> operator, which is used to indicate that a command continues after the newline. This can help improve the readability of long commands.</p>&#13;
&#13;
<p>With this knowledge in hand, you can rewrite the <em>Dockerfile</em> like this:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/fedora</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>dnf<code class="w"> </code>install<code class="w"> </code>-y<code class="w"> </code>httpd<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>dnf<code class="w"> </code>clean<code class="w"> </code>all<code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"/usr/sbin/httpd"</code><code class="p">,</code><code class="w"> </code><code class="s2">"-DFOREGROUND"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>Now you can rebuild the image and see how this change has impacted the size of the layer that includes the <code>http</code> daemon:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">[+] Building 0.5s (7/7) FINISHED</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:14fe7924bb0b641ddf11e08d3dd56f40aff4271cad7a421fe…</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>tag<code class="w"> </code>sha256:14fe7924bb0b641ddf11e08d3dd56f40aff4271cad7a421fe9b…<code class="w"/>&#13;
<code class="go">IMAGE        CREATED            CREATED BY                            SIZE   …</code>&#13;
<code class="go">14fe7924bb0b About a minute ago CMD ["/usr/sbin/httpd" "-DFOREGROUN"]… 0B</code>&#13;
<code class="go">&lt;missing&gt;    About a minute ago RUN /bin/sh -c dnf install -y httpd &amp;… 44.8MB</code>&#13;
<code class="go">&lt;missing&gt;    6 weeks ago        /bin/sh -c #(nop)  CMD ["/bin/bash"] … 0B</code>&#13;
<code class="go">&lt;missing&gt;    6 weeks ago        /bin/sh -c #(nop) ADD file:58865512ca… 163MB</code>&#13;
<code class="go">&lt;missing&gt;    3 months ago       /bin/sh -c #(nop)  ENV DISTTAG=f36con… 0B</code>&#13;
<code class="go">&lt;missing&gt;    15 months ago      /bin/sh -c #(nop)  LABEL maintainer=C… 0B</code></pre>&#13;
&#13;
<p>In the first two examples, the layer in question was 273 MB in size, but now that you have removed many unnecessary files that were added to that layer, you can shrink the layer down to 44.8 MB. This is a very large saving of space, especially when you consider how many servers might be pulling the image down during any given deployment.<a data-startref="ch04-add" data-type="indexterm" id="idm46803152004224"/><a data-startref="ch04-add2" data-type="indexterm" id="idm46803152003616"/><a data-startref="ch04-add3" data-type="indexterm" id="idm46803152003008"/><a data-startref="ch04-add4" data-type="indexterm" id="idm46803152002336"/><a data-startref="ch04-sqsh" data-type="indexterm" id="idm46803151953408"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Utilizing the Layer Cache" data-type="sect2"><div class="sect2" id="idm46803152322800">&#13;
<h2>Utilizing the Layer Cache</h2>&#13;
&#13;
<p>The final building technique that we<a data-primary="OCI images" data-secondary="optimizing" data-tertiary="layer cache utilized" data-type="indexterm" id="ch04-lcu"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="layer cache utilized" data-type="indexterm" id="ch04-lcu2"/> will cover here is related to keeping build times as fast as possible. One of the important goals of the DevOps movement is to keep feedback loops as tight as possible. This means that it is important to try to ensure that problems are discovered and reported as quickly as possible so that they can be fixed when people are still completely focused on the code in question and haven’t moved on to other unrelated tasks.</p>&#13;
&#13;
<p>During any standard build process, Docker uses a layer cache to try to avoid rebuilding any image layers that it has already built and that do not contain any noticeable changes. Because of this cache, the order in which you do things inside your &#13;
<span class="keep-together"><em>Dockerfile</em></span> can have a dramatic impact on how long your builds take on average.</p>&#13;
&#13;
<p>For starters, let’s take the <em>Dockerfile</em> from the previous example and customize it just a bit so that it looks like this.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Along with the other examples, you can also find these files on <a href="https://github.com/bluewhalebook/docker-up-and-running-3rd-edition/blob/main/chapter_04/cache">GitHub</a>.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/fedora</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>dnf<code class="w"> </code>install<code class="w"> </code>-y<code class="w"> </code>httpd<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>dnf<code class="w"> </code>clean<code class="w"> </code>all<code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>mkdir<code class="w"> </code>-p<code class="w"> </code>/var/www<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>mkdir<code class="w"> </code>-p<code class="w"> </code>/var/www/html<code class="w"/>&#13;
<code class="k">ADD</code><code class="w"> </code>index.html<code class="w"> </code>/var/www/html<code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"/usr/sbin/httpd"</code><code class="p">,</code><code class="w"> </code><code class="s2">"-DFOREGROUND"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>Now, in the same directory, let’s also create a new file called <em>index.html</em> that looks like this:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting"><code class="p">&lt;</code><code class="nt">html</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">head</code><code class="p">&gt;</code>&#13;
    <code class="p">&lt;</code><code class="nt">title</code><code class="p">&gt;</code>My custom Web Site<code class="p">&lt;/</code><code class="nt">title</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;/</code><code class="nt">head</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">body</code><code class="p">&gt;</code>&#13;
    <code class="p">&lt;</code><code class="nt">p</code><code class="p">&gt;</code>Welcome to my custom Web Site<code class="p">&lt;/</code><code class="nt">p</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;/</code><code class="nt">body</code><code class="p">&gt;</code>&#13;
<code class="p">&lt;/</code><code class="nt">html</code><code class="p">&gt;</code></pre>&#13;
&#13;
<p>For the first test, let’s time the build without using the Docker cache at all, by using the following command:<a data-primary="time command" data-type="indexterm" id="idm46803151820096"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>--no-cache<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">time docker image build --no-cache .</code>&#13;
<code class="go">[+] Building 48.3s (9/9) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 238B</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 2B</code>&#13;
<code class="go"> =&gt; [internal] load metadata for docker.io/library/fedora:latest</code>&#13;
<code class="go"> =&gt; CACHED [1/4] FROM docker.io/library/fedora</code>&#13;
<code class="go"> =&gt; [internal] load build context</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 32B</code>&#13;
<code class="go"> =&gt; [2/4] RUN dnf install -y httpd &amp;&amp;     dnf clean all</code>&#13;
<code class="go"> =&gt; [3/4] RUN mkdir -p /var/www &amp;&amp;     mkdir -p /var/www/html</code>&#13;
<code class="go"> =&gt; [4/4] ADD index.html /var/www/html</code>&#13;
<code class="go"> =&gt; exporting to image</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:7f94d0d6492f2d2c0b8576f0f492e03334e6a535cac85576c…</code>&#13;
&#13;
<code class="go">real  1m21.645s</code>&#13;
<code class="go">user  0m0.428s</code>&#13;
<code class="go">sys   0m0.323s</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Windows users should be able to run this command<a data-primary="PowerShell" data-secondary="Measure-Command" data-type="indexterm" id="idm46803151765312"/> in a WSL2 session or use the PowerShell <a href="https://oreil.ly/MQQY_"><code>Measure-Command</code></a><sup><a data-type="noteref" href="ch04.html#idm46803151763616" id="idm46803151763616-marker">6</a></sup> function to replace the Unix <code>time</code> command used in these examples.</p>&#13;
</div>&#13;
&#13;
<p>The output from the <code>time</code> command tells us that the build without the cache took about a minute and 21 seconds and only pulled the base image from the layer cache. If you rebuild the image immediately afterward and allow Docker to use the cache, you will see that the build is very fast:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">[+] Building 0.1s (9/9) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 37B</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 2B</code>&#13;
<code class="go"> =&gt; [internal] load metadata for docker.io/library/fedora:latest</code>&#13;
<code class="go"> =&gt; [1/4] FROM docker.io/library/fedora</code>&#13;
<code class="go"> =&gt; [internal] load build context</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 32B</code>&#13;
<code class="go"> =&gt; CACHED [2/4] RUN dnf install -y httpd &amp;&amp;     dnf clean all</code>&#13;
<code class="go"> =&gt; CACHED [3/4] RUN mkdir -p /var/www &amp;&amp;     mkdir -p /var/www/html</code>&#13;
<code class="go"> =&gt; CACHED [4/4] ADD index.html /var/www/html</code>&#13;
<code class="go"> =&gt; exporting to image</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:0d3aeeeeebd09606d99719e0c5197c1f3e59a843c4d7a21af…</code>&#13;
&#13;
<code class="go">real  0m0.416s</code>&#13;
<code class="go">user  0m0.120s</code>&#13;
<code class="go">sys   0m0.087s</code></pre>&#13;
&#13;
<p>Since none of the layers changed, and the cache could be fully leveraged for all four build steps, the build took only a fraction of a second to complete. Now, let’s make a small improvement to the <em>index.html</em> file so that it looks like this:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting"><code class="p">&lt;</code><code class="nt">html</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">head</code><code class="p">&gt;</code>&#13;
    <code class="p">&lt;</code><code class="nt">title</code><code class="p">&gt;</code>My custom Web Site<code class="p">&lt;/</code><code class="nt">title</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;/</code><code class="nt">head</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">body</code><code class="p">&gt;</code>&#13;
    <code class="p">&lt;</code><code class="nt">div</code> <code class="na">align</code><code class="o">=</code><code class="s">"center"</code><code class="p">&gt;</code>&#13;
      <code class="p">&lt;</code><code class="nt">p</code><code class="p">&gt;</code>Welcome to my custom Web Site!!!<code class="p">&lt;/</code><code class="nt">p</code><code class="p">&gt;</code>&#13;
    <code class="p">&lt;/</code><code class="nt">div</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;/</code><code class="nt">body</code><code class="p">&gt;</code>&#13;
<code class="p">&lt;/</code><code class="nt">html</code><code class="p">&gt;</code></pre>&#13;
&#13;
<p>and then let’s time the rebuild again:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">[+] Building 0.1s (9/9) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 37B</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 2B</code>&#13;
<code class="go"> =&gt; [internal] load metadata for docker.io/library/fedora:latest</code>&#13;
<code class="go"> =&gt; [internal] load build context</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 214B</code>&#13;
<code class="go"> =&gt; [1/4] FROM docker.io/library/fedora</code>&#13;
<code class="go"> =&gt; CACHED [2/4] RUN dnf install -y httpd &amp;&amp;     dnf clean all</code>&#13;
<code class="go"> =&gt; CACHED [3/4] RUN mkdir -p /var/www &amp;&amp;     mkdir -p /var/www/html</code>&#13;
<code class="go"> =&gt; [4/4] ADD index.html /var/www/html</code>&#13;
<code class="go"> =&gt;  ADD index.html /var/www/html</code>&#13;
<code class="go"> =&gt; exporting to image</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:daf792da1b6a0ae7cfb2673b29f98ef2123d666b8d14e0b74…</code>&#13;
&#13;
<code class="go">real  0m0.456s</code>&#13;
<code class="go">user  0m0.120s</code>&#13;
<code class="go">sys   0m0.068s</code></pre>&#13;
&#13;
<p class="pagebreak-before">If you look at the output carefully, you will see that the cache was used for most of the build. It wasn’t until step <code>4/4</code>, when Docker needed to copy <em>index.html</em>, that the cache was invalidated and the layers had to be re-created. Because the cache could be used for most of the build, the build still did not exceed a second.</p>&#13;
&#13;
<p>But what would happen if you changed the order of the commands in the <em>Dockerfile</em> so that they looked like this:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/fedora</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>mkdir<code class="w"> </code>-p<code class="w"> </code>/var/www<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>mkdir<code class="w"> </code>-p<code class="w"> </code>/var/www/html<code class="w"/>&#13;
<code class="k">ADD</code><code class="w"> </code>index.html<code class="w"> </code>/var/www/html<code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>dnf<code class="w"> </code>install<code class="w"> </code>-y<code class="w"> </code>httpd<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>dnf<code class="w"> </code>clean<code class="w"> </code>all<code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"/usr/sbin/httpd"</code><code class="p">,</code><code class="w"> </code><code class="s2">"-DFOREGROUND"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>Let’s quickly time another test build without the cache to get a baseline:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>--no-cache<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">[+] Building 51.5s (9/9) FINISHED</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:1cc5f2c5e4a4d1cf384f6fb3a34fd4d00e7f5e7a7308d5f1f…</code>&#13;
&#13;
<code class="go">real  0m51.859s</code>&#13;
<code class="go">user  0m0.237s</code>&#13;
<code class="go">sys   0m0.159s</code></pre>&#13;
&#13;
<p>In this case, the build took 51 seconds to complete: since we used the <code>--no-cache</code> argument, we know that nothing was pulled from the layer cache, except for the base image. The difference in time from the very first test is entirely due to fluctuating network speeds and has nothing to do with the changes that you have made to the <em>Dockerfile</em>.</p>&#13;
&#13;
<p>Now, let’s edit <em>index.html</em> again, like so:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting"><code class="p">&lt;</code><code class="nt">html</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">head</code><code class="p">&gt;</code>&#13;
    <code class="p">&lt;</code><code class="nt">title</code><code class="p">&gt;</code>My custom Web Site<code class="p">&lt;/</code><code class="nt">title</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;/</code><code class="nt">head</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">body</code><code class="p">&gt;</code>&#13;
    <code class="p">&lt;</code><code class="nt">div</code> <code class="na">align</code><code class="o">=</code><code class="s">"center"</code> <code class="na">style</code><code class="o">=</code><code class="s">"font-size:180%"</code><code class="p">&gt;</code>&#13;
      <code class="p">&lt;</code><code class="nt">p</code><code class="p">&gt;</code>Welcome to my custom Web Site<code class="p">&lt;/</code><code class="nt">p</code><code class="p">&gt;</code>&#13;
    <code class="p">&lt;/</code><code class="nt">div</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;/</code><code class="nt">body</code><code class="p">&gt;</code>&#13;
<code class="p">&lt;/</code><code class="nt">html</code><code class="p">&gt;</code></pre>&#13;
&#13;
<p>And now, let’s time the image rebuild while using the cache:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">[+] Building 43.4s (9/9) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 37B</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 2B</code>&#13;
<code class="go"> =&gt; [internal] load metadata for docker.io/library/fedora:latest</code>&#13;
<code class="go"> =&gt; [1/4] FROM docker.io/library/fedora</code>&#13;
<code class="go"> =&gt; [internal] load build context</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 233B</code>&#13;
<code class="go"> =&gt; CACHED [2/4] RUN mkdir -p /var/www &amp;&amp;     mkdir -p /var/www/html</code>&#13;
<code class="go"> =&gt; [3/4] ADD index.html /var/www/html</code>&#13;
<code class="go"> =&gt; [4/4] RUN dnf install -y httpd &amp;&amp;     dnf clean all</code>&#13;
<code class="go"> =&gt; exporting to image</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:9a05b2d01b5870649e0ad1d7ad68858e0667f402c8087f0b4…</code>&#13;
&#13;
<code class="go">real  0m43.695s</code>&#13;
<code class="go">user  0m0.211s</code>&#13;
<code class="go">sys   0m0.133s</code></pre>&#13;
&#13;
<p>The first time that you rebuilt the image, after editing the <em>index.html</em> file, it took only .456 seconds, but this time it took 43.695 seconds, almost exactly as long as it took to build the whole image without using the cache at all.</p>&#13;
&#13;
<p>This is because you have modified the <em>Dockerfile</em> so that the <em>index.html</em> file is copied into the image very early in the process. The problem with doing it this way is that the <em>index.html</em> file changes frequently and will often invalidate the cache. The other issue is that it is unnecessarily placed before a very time-consuming step in our <em>Dockerfile</em>: installing the Apache web server.</p>&#13;
&#13;
<p>The important lesson to take away from all of this is that order matters, and in general, you should always try to order your <em>Dockerfile</em> so that the most stable and time-consuming portions of your build process happen first and your code is added as late in the process as possible.</p>&#13;
&#13;
<p>For projects that require you to install dependencies based on your code using tools like <code>npm</code> and <code>bundle</code>, it is also a good idea to do some research about optimizing your Docker builds for those platforms. This often includes locking down your dependency versions and storing them along with your code so that they do not need to be downloaded for each and every build.<a data-startref="ch04-lcu" data-type="indexterm" id="idm46803151318560"/><a data-startref="ch04-lcu2" data-type="indexterm" id="idm46803151317856"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Directory Caching" data-type="sect2"><div class="sect2" id="idm46803151951856">&#13;
<h2>Directory Caching</h2>&#13;
&#13;
<p>One of the many features that<a data-primary="OCI images" data-secondary="optimizing" data-tertiary="directory caching" data-type="indexterm" id="ch04-dirca"/><a data-primary="directory caching" data-type="indexterm" id="ch04-dirca2"/><a data-primary="BuildKit" data-secondary="directory caching" data-type="indexterm" id="ch04-dirca3"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="directory caching" data-type="indexterm" id="ch04-dirca4"/> BuildKit adds to the image-building experience is directory caching. Directory caching is an incredibly useful tool for speeding up build times without saving a lot of files that are unnecessary for the runtime into your image. In essence, it allows you to save the contents of a directory inside your image in a special layer that can be bind-mounted at build time and then unmounted before the image snapshot is made. This is often used to handle directories where tools like Linux software installers (<code>apt</code>, <code>apk</code>, <code>dnf</code>, etc.), and language dependency managers (<code>npm</code>, <code>bundler</code>, <code>pip</code>, etc.), download their databases and archive files.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>If you are unfamiliar with<a data-primary="documentation" data-secondary="Docker" data-tertiary="bind mounts" data-type="indexterm" id="idm46803151337104"/><a data-primary="resources online" data-secondary="Docker documentation" data-tertiary="bind mounts" data-type="indexterm" id="idm46803151335856"/><a data-primary="bind mounts" data-secondary="documentation" data-type="indexterm" id="idm46803151334640"/> bind mounts and what they are, you can find a <a href="https://docs.docker.com/storage/bind-mounts">bind mount overview</a> in the Docker documentation.</p>&#13;
</div>&#13;
&#13;
<p>To make use of directory caching, you must have BuildKit enabled. In most circumstances, this should already be the case, but you can force it from the client side, by setting the environment variable <code>DOCKER_BUILDKIT=</code> to <code>1</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">export</code><code class="w"> </code><code class="nv">DOCKER_BUILDKIT</code><code class="o">=</code><code class="m">1</code><code class="w"/></pre>&#13;
&#13;
<p>Let’s explore directory caching by checking out the following git repository and seeing how utilizing directory caching can significantly improve consecutive builds while still keeping the resulting image sizes smaller:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>git<code class="w"> </code>clone<code class="w"> </code>https://github.com/spkane/open-mastermind.git<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--config<code class="w"> </code>core.autocrlf<code class="o">=</code>input<code class="w"/>&#13;
&#13;
<code class="gp">$ </code><code class="nb">cd</code><code class="w"> </code>open-mastermind<code class="w"/>&#13;
<code class="gp">$ </code>cat<code class="w"> </code>Dockerfile<code class="w"/></pre>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">python:3.9.15-slim-bullseye</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>mkdir<code class="w"> </code>/app<code class="w"/>&#13;
<code class="k">WORKDIR</code><code class="w"> </code><code class="s">/app</code><code class="w"/>&#13;
<code class="k">COPY</code><code class="w"> </code>.<code class="w"> </code>/app<code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>-r<code class="w"> </code>requirements.txt<code class="w"/>&#13;
<code class="k">WORKDIR</code><code class="w"> </code><code class="s">/app/mastermind</code><code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"python"</code><code class="p">,</code><code class="w"> </code><code class="s2">"mastermind.py"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>This codebase has a very generic <em>Dockerfile</em> checked into the repo. Let’s go ahead and see how long it takes to build this image, with and without the layer cache, and let’s also examine how large the resulting image is:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>build<code class="w"> </code>--no-cache<code class="w"> </code>-t<code class="w"> </code>docker.io/spkane/open-mastermind:latest<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 67.5s (12/12) FINISHED</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; =&gt; naming to docker.io/spkane/open-mastermind:latest                  0.0s</code>&#13;
&#13;
<code class="go">real    0m28.934s</code>&#13;
<code class="go">user    0m0.222s</code>&#13;
<code class="go">sys     0m0.248s</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>ls<code class="w"> </code>--format<code class="w"> </code><code class="s2">"{{ .Size }}"</code><code class="w"> </code>spkane/open-mastermind:latest<code class="w"/>&#13;
<code class="go">293MB</code>&#13;
&#13;
<code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>docker.io/spkane/open-mastermind:latest<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 1.5s (12/12) FINISHED</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; =&gt; naming to docker.io/spkane/open-mastermind:latest                  0.0s</code>&#13;
&#13;
<code class="go">real    0m1.083s</code>&#13;
<code class="go">user    0m0.098s</code>&#13;
<code class="go">sys     0m0.095s</code></pre>&#13;
&#13;
<p>From this output, we can see that this image takes just under 29 seconds to build without the layer cache and just under 2 seconds to build when it can fully utilize the layer cache. The resulting image size is 293 MB in total.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>BuildKit finally has support for<a data-primary="BuildKit" data-secondary="output color modification" data-type="indexterm" id="idm46803151065408"/><a data-primary="environment variables" data-secondary="BUILDKIT_COLORS" data-type="indexterm" id="idm46803151064304"/> <a href="https://github.com/moby/buildkit#color-output-controls">modifying or completely disabling the colors used for the output</a>. This is particularly nice for anyone who uses a dark background in their terminal. You can configure these colors by setting something like <code>export BUILDKIT_</code> &#13;
<span class="keep-together"><code>COLORS=run=green:warning=yellow:error=red:cancel=cyan</code></span> in your environment, or you can completely disable the colors by setting <code>export NO_COLOR=true</code>.<a data-primary="environment variables" data-secondary="NO_COLOR" data-type="indexterm" id="idm46803151060928"/></p>&#13;
&#13;
<p>Note that the BuildKit version used in various <code>docker</code> components and third-party tools is still being updated, so it might not work yet in every situation.</p>&#13;
</div>&#13;
&#13;
<p>If you want to test the build, go ahead and run it:<a data-primary="Mastermind game" data-type="indexterm" id="idm46803151058624"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-ti for interactive terminal" data-tertiary-sortas="ti" data-type="indexterm" id="idm46803151057920"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-it for interactive terminal" data-tertiary-sortas="it" data-type="indexterm" id="idm46803151091872"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>docker.io/spkane/open-mastermind:latest<code class="w"/></pre>&#13;
&#13;
<p>This will launch a <a href="https://github.com/philshem/open-mastermind">terminal-based open source version of the Mastermind game</a>. There are on-screen directions for the game, and as a fallback, you can always exit by typing Ctrl-C.<a data-primary="exiting via Ctrl-C" data-secondary="applications" data-type="indexterm" id="idm46803151086624"/></p>&#13;
&#13;
<p>Since this is a Python application, it uses the <em>requirements.txt</em> file to list all of the libraries that the application requires, and then the <code>pip</code> application is used in the <em>Dockerfile</em> to install these dependencies.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>We are installing some unnecessary dependencies simply to make the benefits of directory caching more obvious.</p>&#13;
</div>&#13;
&#13;
<p>Go ahead and open up the <em>requirements.txt</em> file and add a line that reads <code>log-symbols</code>, so that it looks like this:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">colorama&#13;
# These are not required - but are used for demonstration purposes&#13;
pandas&#13;
flask&#13;
log-symbols</pre>&#13;
&#13;
<p>Let’s rerun the build now:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>docker.io/spkane/open-mastermind:latest<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--progress<code class="o">=</code>plain<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="gp">#</code><code class="m">1</code><code class="w"> </code><code class="o">[</code>internal<code class="o">]</code><code class="w"> </code>load<code class="w"> </code>build<code class="w"> </code>definition<code class="w"> </code>from<code class="w"> </code>Dockerfile<code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="gp">#</code><code class="m">9</code><code class="w"> </code><code class="o">[</code><code class="m">5</code>/6<code class="o">]</code><code class="w"> </code>RUN<code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>-r<code class="w"> </code>requirements.txt<code class="w"/>&#13;
<code class="gp">#</code><code class="m">9</code><code class="w"> </code>sha256:82dbc10f1bb9fa476d93cc0d8104b76f46af8ece7991eb55393d6d72a230919e<code class="w"/>&#13;
<code class="gp">#</code><code class="m">9</code><code class="w"> </code><code class="m">1</code>.954<code class="w"> </code>Collecting<code class="w"> </code>colorama<code class="w"/>&#13;
<code class="gp">#</code><code class="m">9</code><code class="w"> </code><code class="m">2</code>.058<code class="w">   </code>Downloading<code class="w"> </code>colorama-0.4.5-py2.py3-none-any.whl<code class="w"> </code><code class="o">(</code><code class="m">16</code><code class="w"> </code>kB<code class="o">)</code><code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="go">real    0m16.379s</code>&#13;
<code class="go">user    0m0.112s</code>&#13;
<code class="go">sys     0m0.082s</code></pre>&#13;
&#13;
<p>If you look at the full output for step <code>5/6</code>, you will <a data-primary="dependencies" data-secondary="BuildKit directory caching" data-type="indexterm" id="idm46803151032512"/>notice that all the dependencies are downloaded again, even though <code>pip</code> would normally have most of those dependencies cached in <em>/root/.cache</em>. This inefficiency results from the builder seeing that we have made a change that impacts this layer and therefore completely re-creates the layer, so we lose that cache, even though we had it stored in the image layer.</p>&#13;
&#13;
<p>Let’s go ahead and improve this situation.<a data-primary="directory caching" data-secondary="documentation" data-type="indexterm" id="idm46803150939104"/><a data-primary="documentation" data-secondary="BuildKit directory caching" data-type="indexterm" id="idm46803150938128"/><a data-primary="resources online" data-secondary="BuildKit directory caching documentation" data-type="indexterm" id="idm46803150937216"/> To do this, we need to leverage the <a href="https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/reference.md#run---mounttypecache">BuildKit directory cache</a>, and to do that we need to make a few changes to the <em>Dockerfile</em> so that it looks like this:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="c"># syntax=docker/dockerfile:1</code><code class="w"/>&#13;
<code class="k">FROM</code><code class="w"> </code><code class="s">python:3.9.15-slim-bullseye</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>mkdir<code class="w"> </code>/app<code class="w"/>&#13;
<code class="k">WORKDIR</code><code class="w"> </code><code class="s">/app</code><code class="w"/>&#13;
<code class="k">COPY</code><code class="w"> </code>.<code class="w"> </code>/app<code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>--mount<code class="o">=</code><code class="nv">type</code><code class="o">=</code>cache,target<code class="o">=</code>/root/.cache<code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>-r<code class="w"> </code>requirements.txt<code class="w"/>&#13;
<code class="k">WORKDIR</code><code class="w"> </code><code class="s">/app/mastermind</code><code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"python"</code><code class="p">,</code><code class="w"> </code><code class="s2">"mastermind.py"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>There are two important changes in there. First, we added the following line:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="c"># syntax=docker/dockerfile:1</code><code class="w"/></pre>&#13;
&#13;
<p>This tells Docker that we are going to use a newer version of the <a href="https://hub.docker.com/r/docker/dockerfile"><em>Dockerfile</em> frontend</a>,  which provides us with access to BuildKit’s new features.</p>&#13;
&#13;
<p>Then we edited the <code>RUN</code> line to look like this:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">RUN</code><code class="w"> </code>--mount<code class="o">=</code><code class="nv">type</code><code class="o">=</code>cache,target<code class="o">=</code>/root/.cache<code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>-r<code class="w"> </code>requirements.txt<code class="w"/></pre>&#13;
&#13;
<p>This line tells BuildKit to mount a caching layer into the container at <em>/root/.cache</em> for the duration of this one build step. This will accomplish two goals for us. It will remove the contents of that directory from the resulting image, and it will also be remounted and available to <code>pip</code> in consecutive builds.</p>&#13;
&#13;
<p>Let’s go ahead and do a full rebuild of the image with these changes, to generate the initial cache directory contents. If you follow the output, you will see that <code>pip</code> downloads all the dependencies, exactly as before:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>build<code class="w"> </code>--no-cache<code class="w"> </code>-t<code class="w"> </code>docker.io/spkane/open-mastermind:latest<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 15.2s (15/15) FINISHED</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; =&gt; naming to docker.io/spkane/open-mastermind:latest                  0.0s</code>&#13;
<code class="go">…</code>&#13;
<code class="go">real    0m15.493s</code>&#13;
<code class="go">user    0m0.137s</code>&#13;
<code class="go">sys     0m0.096s</code></pre>&#13;
&#13;
<p>So, now let’s open up the <em>requirements.txt</em> file and add a line that reads <code>py-events</code>:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">colorama&#13;
# These are not required - but are used for demonstration purposes&#13;
pandas&#13;
flask&#13;
log-symbols&#13;
py-events</pre>&#13;
&#13;
<p>This is where the changes pay off. When we rebuild the image now, we will see that <code>py-events</code> and its dependencies are the only things that are downloaded; everything else uses the existing cache from our previous build, which has been mounted into the image for this build step:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>docker.io/spkane/open-mastermind:latest<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--progress<code class="o">=</code>plain<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="gp">#</code><code class="m">1</code><code class="w"> </code><code class="o">[</code>internal<code class="o">]</code><code class="w"> </code>load<code class="w"> </code>build<code class="w"> </code>definition<code class="w"> </code>from<code class="w"> </code>Dockerfile<code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="gp">#</code><code class="m">14</code><code class="w"> </code><code class="o">[</code>stage-0<code class="w"> </code><code class="m">5</code>/6<code class="o">]</code><code class="w"> </code>RUN<code class="w"> </code>--mount<code class="o">=</code><code class="nv">type</code><code class="o">=</code>cache,target<code class="o">=</code>/root/.cache<code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>…<code class="w"/>&#13;
<code class="gp">#</code><code class="m">14</code><code class="w"> </code>sha256:9bc72441fdf2ec5f5803d4d5df43dbe7bc6eeef88ebee98ed18d8dbb478270ba<code class="w"/>&#13;
<code class="gp">#</code><code class="m">14</code><code class="w"> </code><code class="m">1</code>.711<code class="w"> </code>Collecting<code class="w"> </code>colorama<code class="w"/>&#13;
<code class="gp">#</code><code class="m">14</code><code class="w"> </code><code class="m">1</code>.714<code class="w">   </code>Using<code class="w"> </code>cached<code class="w"> </code>colorama-0.4.5-py2.py3-none-any.whl<code class="w"> </code><code class="o">(</code><code class="m">16</code><code class="w"> </code>kB<code class="o">)</code><code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="gp">#</code><code class="m">14</code><code class="w"> </code><code class="m">2</code>.236<code class="w"> </code>Collecting<code class="w"> </code>py-events<code class="w"/>&#13;
<code class="gp">#</code><code class="m">14</code><code class="w"> </code><code class="m">2</code>.356<code class="w">   </code>Downloading<code class="w"> </code>py_events-0.1.2-py3-none-any.whl<code class="w"> </code><code class="o">(</code><code class="m">5</code>.8<code class="w"> </code>kB<code class="o">)</code><code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="gp">#</code><code class="m">16</code><code class="w"> </code>DONE<code class="w"> </code><code class="m">1</code>.4s<code class="w"/>&#13;
&#13;
<code class="go">real    0m12.624s</code>&#13;
<code class="go">user    0m0.180s</code>&#13;
<code class="go">sys     0m0.112s</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>ls<code class="w"> </code>--format<code class="w"> </code><code class="s2">"{{ .Size }}"</code><code class="w"> </code>spkane/open-mastermind:latest<code class="w"/>&#13;
<code class="go">261MB</code></pre>&#13;
&#13;
<p class="pagebreak-before">The build time has shrunk since there is no longer a need to re-download everything each time, and the image size is also 32 MB smaller, even though we have added new dependencies to the image. This is simply because the cache directory is no longer stored directly in the image that contains the application.</p>&#13;
&#13;
<p>BuildKit and the new <em>Dockerfile</em> frontends<a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="documentation" data-type="indexterm" id="idm46803150615072"/><a data-primary="documentation" data-secondary="Dockerfiles" data-type="indexterm" id="idm46803150613856"/><a data-primary="resources online" data-secondary="Dockerfiles documentation" data-type="indexterm" id="idm46803150595504"/> bring a lot of very useful features to the image-building process that you will want to be aware of. We highly recommend that you take the time to read through <a href="https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/reference.md">the reference guide</a> and become acquainted with all the available capabilities.<a data-startref="ch04-dirca" data-type="indexterm" id="idm46803150593840"/><a data-startref="ch04-dirca2" data-type="indexterm" id="idm46803150593136"/><a data-startref="ch04-dirca3" data-type="indexterm" id="idm46803150592464"/><a data-startref="ch04-dirca4" data-type="indexterm" id="idm46803150591792"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Troubleshooting Broken Builds" data-type="sect1"><div class="sect1" id="broken_builds">&#13;
<h1>Troubleshooting Broken Builds</h1>&#13;
&#13;
<p>We normally expect builds to just work,<a data-primary="OCI images" data-secondary="building an image" data-tertiary="debugging broken builds" data-type="indexterm" id="ch04-troub"/><a data-primary="debugging" data-secondary="broken builds" data-type="indexterm" id="ch04-troub2"/><a data-primary="OCI images" data-secondary="debugging broken builds" data-type="indexterm" id="ch04-troub3"/><a data-primary="debugging" data-secondary="broken builds" data-tertiary="about" data-type="indexterm" id="idm46803150585744"/><a data-primary="OCI images" data-secondary="debugging broken builds" data-tertiary="about" data-type="indexterm" id="idm46803150584528"/><a data-primary="troubleshooting" data-see="debugging" data-type="indexterm" id="idm46803150583312"/><a data-primary="Linux containers" data-secondary="debugging" data-see="debugging" data-type="indexterm" id="idm46803150582368"/> especially when we’ve scripted them, but in the real world things go wrong. Let’s spend a little bit of time discussing what you can do to troubleshoot a Docker build that is failing. In this section, we will explore two options: one that works with the pre-BuildKit approach to image building and one that works with BuildKit.</p>&#13;
&#13;
<p>For this demonstration, we are going to reuse the <code>docker-hello-node</code> repo from earlier in the chapter. If required, you can clone it again, like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>git<code class="w"> </code>clone<code class="w"> </code>https://github.com/spkane/docker-node-hello.git<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--config<code class="w"> </code>core.autocrlf<code class="o">=</code>input<code class="w"/>&#13;
<code class="go">Cloning into 'docker-node-hello'…</code>&#13;
<code class="go">remote: Counting objects: 41, done.</code>&#13;
<code class="go">remote: Total 41 (delta 0), reused 0 (delta 0), pack-reused 41</code>&#13;
<code class="go">Unpacking objects: 100% (41/41), done.</code>&#13;
&#13;
<code class="gp">$ </code><code class="nb">cd</code><code class="w"> </code>docker-node-hello<code class="w"/></pre>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Debugging Pre-BuildKit Images" data-type="sect2"><div class="sect2" id="idm46803150485296">&#13;
<h2>Debugging Pre-BuildKit Images</h2>&#13;
&#13;
<p>We need a patient for the next set of exercises,<a data-primary="OCI images" data-secondary="debugging broken builds" data-tertiary="pre-BuildKit images" data-type="indexterm" id="idm46803150499936"/><a data-primary="debugging" data-secondary="broken builds" data-tertiary="pre-BuildKit images" data-type="indexterm" id="idm46803150498720"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="debugging pre-BuildKit images" data-type="indexterm" id="idm46803150577280"/> so let’s create a failing build. To do that, edit the <em>Dockerfile</em> so that the line that reads:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">RUN</code><code class="w"> </code>apt-get<code class="w"> </code>-y<code class="w"> </code>update<code class="w"/></pre>&#13;
&#13;
<p>now reads:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">RUN</code><code class="w"> </code>apt-get<code class="w"> </code>-y<code class="w"> </code>update-all<code class="w"/></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>If you are using PowerShell on Windows,<a data-primary="PowerShell" data-secondary="disabling BuildKit before image build" data-type="indexterm" id="idm46803150571968"/><a data-primary="environment variables" data-secondary="DOCKER_BUILDKIT" data-type="indexterm" id="idm46803150571120"/> you will likely need to set the environment variable that disables BuildKit before running the following <code>docker image build</code> command, and then reset it afterward:</p>&#13;
&#13;
<pre data-code-language="ps1con" data-type="programlisting"><code class="gp">PS C:\&gt; </code><code class="nv">$env:DOCKER_BUILDKIT</code> <code class="p">=</code> <code class="n">0</code>&#13;
<code class="gp">PS C:\&gt; </code><code class="n">docker</code> <code class="n">image</code> <code class="n">build</code> <code class="p">`</code>&#13;
<code class="go">         -t example/docker-node-hello:latest `</code>&#13;
<code class="go">         --no-cache .</code>&#13;
<code class="gp">PS C:\&gt; </code><code class="nv">$env:DOCKER_BUILDKIT</code> <code class="p">=</code> <code class="n">1</code></pre>&#13;
</div>&#13;
&#13;
<p>If you try to build the image now, you should get the following error:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nv">DOCKER_BUILDKIT</code><code class="o">=</code><code class="m">0</code><code class="w"> </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>example/docker-node-hello:latest<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--no-cache<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">Sending build context to Docker daemon  9.216kB</code>&#13;
<code class="go">Step 1/14 : FROM docker.io/node:18.13.0</code>&#13;
<code class="go"> ---&gt; 9ff38e3a6d9d</code>&#13;
<code class="go">…</code>&#13;
<code class="go">Step 6/14 : ENV SCPATH /etc/supervisor/conf.d</code>&#13;
<code class="go"> ---&gt; Running in e903367eaeb8</code>&#13;
<code class="go">Removing intermediate container e903367eaeb8</code>&#13;
<code class="go"> ---&gt; 2a236efc3f06</code>&#13;
<code class="go">Step 7/14 : RUN apt-get -y update-all</code>&#13;
<code class="go"> ---&gt; Running in c7cd72f7d9bf</code>&#13;
<code class="go">E: Invalid operation update-all</code>&#13;
<code class="go">The command '/bin/sh -c apt-get -y update-all' returned a non-zero code: 100</code></pre>&#13;
&#13;
<p>So, how can we troubleshoot this, especially if we are not developing on a Linux system? The real trick here is to remember that almost all Docker images are layered on top of other Docker images and that you can start a container from any image. Although the meaning is not obvious on the surface, if you look at the output for <code>Step 6</code>, you will see this:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">Step 6/14 : ENV SCPATH /etc/supervisor/conf.d&#13;
 ---&gt; Running in e903367eaeb8&#13;
Removing intermediate container e903367eaeb8&#13;
 ---&gt; 2a236efc3f06</pre>&#13;
&#13;
<p>The first line that reads <code>Running in e903367eaeb8</code> is telling you that the build process has started a new container, based on the image created in <code>Step 5</code>. The next line, which reads <code>Removing intermediate container e903367eaeb8</code>, is telling you that Docker is now removing the container after having altered it based on the instruction in <code>Step 6</code>. In this case, it was simply adding a default environment variable via <code>ENV SCPATH /etc/supervisor/conf.d</code>. The final line, which reads <code>--→ 2a236efc3f06</code>, is the one we really care about because this is giving us the image ID for the image that was generated by <code>Step 6</code>. You need this to troubleshoot the build because it is the image from the last successful step in the build.</p>&#13;
&#13;
<p>With this information, it is possible<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="debugging a broken build" data-type="indexterm" id="idm46803150321424"/> to run an interactive container so that you can try to determine why your build is not working properly. Remember that every container image is based on the image layers below it. One of the great benefits of this is that we can just run the lower layer as a container itself, using a shell to look around!</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>2a236efc3f06<code class="w"> </code>/bin/bash<code class="w"/>&#13;
<code class="gp">root@b83048106b0f:/#</code></pre>&#13;
&#13;
<p>From inside the container, you can now run any commands that you might need to determine what is causing your build to fail and what you need to do to fix your <em>Dockerfile</em>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">root@b83048106b0f:/# </code>apt-get<code class="w"> </code>-y<code class="w"> </code>update-all<code class="w"/>&#13;
<code class="go">E: Invalid operation update-all</code>&#13;
&#13;
<code class="gp">root@b83048106b0f:/# </code>apt-get<code class="w"> </code>--help<code class="w"/>&#13;
<code class="go">apt 1.4.9 (amd64)</code>&#13;
<code class="go">…</code>&#13;
&#13;
<code class="go">Most used commands:</code>&#13;
<code class="go">  update - Retrieve new lists of packages</code>&#13;
<code class="go">…</code>&#13;
&#13;
<code class="gp">root@b83048106b0f:/# </code>apt-get<code class="w"> </code>-y<code class="w"> </code>update<code class="w"/>&#13;
<code class="go">Get:1 http://security.debian.org/debian-security stretch/updates … [53.0 kB]</code>&#13;
<code class="go">…</code>&#13;
<code class="go">Reading package lists… Done</code>&#13;
&#13;
<code class="gp">root@b83048106b0f:/# </code><code class="nb">exit</code><code class="w"/>&#13;
<code class="go">exit</code></pre>&#13;
&#13;
<p>Once the root cause has been determined, the <em>Dockerfile</em> can be fixed, so that <code>RUN apt-get -y update-all</code> now reads <code>RUN apt-get -y update</code>, and then rebuilding the image should result in success:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nv">DOCKER_BUILDKIT</code><code class="o">=</code><code class="m">0</code><code class="w"> </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>example/docker-node-hello:latest<code class="w"> </code>.<code class="w"/>&#13;
<code class="go">Sending build context to Docker daemon  15.87kB</code>&#13;
<code class="go">…</code>&#13;
<code class="go">Successfully built 69f5e83bb86e</code>&#13;
<code class="go">Successfully tagged example/docker-node-hello:latest</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Debugging BuildKit Images" data-type="sect2"><div class="sect2" id="idm46803150182768">&#13;
<h2>Debugging BuildKit Images</h2>&#13;
&#13;
<p>When using BuildKit, we have<a data-primary="OCI images" data-secondary="debugging broken builds" data-tertiary="BuildKit images" data-type="indexterm" id="ch04-debbk"/><a data-primary="debugging" data-secondary="broken builds" data-tertiary="BuildKit images" data-type="indexterm" id="ch04-debbk2"/><a data-primary="BuildKit" data-secondary="debugging broken builds" data-type="indexterm" id="ch04-debbk3"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="debugging BuildKit images" data-type="indexterm" id="ch04-debbk4"/> to take a slightly different approach to get access to the point where the build fails, because none of the intermediate build layers are exported from the build container to the Docker daemon.</p>&#13;
&#13;
<p>The options for debugging BuildKit will almost certainly evolve as we move forward, but let’s take a look at one approach that works now.</p>&#13;
&#13;
<p>Assuming that the <em>Dockerfile</em> has been reverted to its original state, let’s change the line that reads:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">RUN</code><code class="w"> </code>npm<code class="w"> </code>install<code class="w"/></pre>&#13;
&#13;
<p>so that it now reads:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">RUN</code><code class="w"> </code>npm<code class="w"> </code>installer<code class="w"/></pre>&#13;
&#13;
<p>and then attempt to build the image.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Make sure that you have BuildKit enabled!</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>example/docker-node-hello:debug<code class="w"> </code>--no-cache<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 51.7s (13/13) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile                      0.0s</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; [7/8] WORKDIR /data/app                                               0.0s</code>&#13;
<code class="go"> =&gt; ERROR [8/8] RUN npm installer                                         0.4s</code>&#13;
<code class="go">______</code>&#13;
<code class="go"> &gt; [8/8] RUN npm installer:</code>&#13;
<code class="gp">#</code><code class="m">13</code><code class="w"> </code><code class="m">0</code>.399<code class="w"/>&#13;
<code class="gp">#</code><code class="m">13</code><code class="w"> </code><code class="m">0</code>.399<code class="w"> </code>Usage:<code class="w"> </code>npm<code class="w"> </code>&lt;command&gt;<code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="gp">#</code><code class="m">13</code><code class="w"> </code><code class="m">0</code>.402<code class="w"> </code>Did<code class="w"> </code>you<code class="w"> </code>mean<code class="w"> </code>one<code class="w"> </code>of<code class="w"> </code>these?<code class="w"/>&#13;
<code class="gp">#</code><code class="m">13</code><code class="w"> </code><code class="m">0</code>.402<code class="w">     </code>install<code class="w"/>&#13;
<code class="gp">#</code><code class="m">13</code><code class="w"> </code><code class="m">0</code>.402<code class="w">     </code>install-test<code class="w"/>&#13;
<code class="gp">#</code><code class="m">13</code><code class="w"> </code><code class="m">0</code>.402<code class="w">     </code>uninstall<code class="w"/>&#13;
<code class="go">______</code>&#13;
<code class="go">executor failed running [/bin/sh -c npm installer]: exit code: 1</code></pre>&#13;
&#13;
<p>We see an error as we expected, but how are we going to get access to that layer so that we can troubleshoot this?<a data-primary="exit codes" data-secondary="debugging BuildKit images" data-type="indexterm" id="idm46803150124016"/></p>&#13;
&#13;
<p>One approach that works is to leverage<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="--target argument" data-tertiary-sortas="target" data-type="indexterm" id="idm46803150031056"/> multistage builds and the <code>--target</code> argument of <code>docker image build</code>.</p>&#13;
&#13;
<p>Let’s start by modifying the <em>Dockerfile</em> in two places. Change this line:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/node:18.13.0</code><code class="w"/></pre>&#13;
&#13;
<p>so that it now reads:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">docker.io/node:18.13.0</code><code class="w"> </code><code class="k">as</code><code class="w"> </code><code class="s">deploy</code><code class="w"/></pre>&#13;
&#13;
<p class="pagebreak-before">and then immediately before the line that causes the error, we are going to add a new <code>FROM</code> line:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">deploy</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>npm<code class="w"> </code>installer<code class="w"/></pre>&#13;
&#13;
<p>By doing this, we are creating a multistage build, where the first stage contains all of the steps that we know are working and the second stage starts with our problematic step.</p>&#13;
&#13;
<p>If we try to rebuild this using the same command as before, it will still fail:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>example/docker-node-hello:debug<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 51.7s (13/13) FINISHED</code>&#13;
<code class="go">…</code>&#13;
<code class="go">executor failed running [/bin/sh -c npm installer]: exit code: 1</code></pre>&#13;
&#13;
<p>So, instead of doing that, let’s tell Docker that we only want to build the first image in our multistage <em>Dockerfile</em>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>example/docker-node-hello:debug<code class="w"> </code>--target<code class="w"> </code>deploy<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 0.8s (12/12) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile                   0.0s</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 37B                                    0.0s</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; exporting to image                                                 0.1s</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers                                                0.1s</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:a42dfbcfc7b18ee3d30ace944ad4134ea2239a2c0  0.0s</code>&#13;
<code class="go"> =&gt; =&gt; naming to docker.io/example/docker-node-hello:debug             0.0s</code></pre>&#13;
&#13;
<p>Now, we can create a container from this image and do whatever testing we require:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>docker.io/example/docker-node-hello:debug<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">root@17807997176e:/data/app# </code>ls<code class="w"/>&#13;
<code class="go">index.js  package.json</code>&#13;
&#13;
<code class="gp">root@17807997176e:/data/app# </code>npm<code class="w"> </code>install<code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="go">added 18 packages from 16 contributors and audited 18 packages in 1.248s</code>&#13;
<code class="go">…</code>&#13;
&#13;
<code class="gp">root@17807997176e:/data/app# </code><code class="nb">exit</code><code class="w"/>&#13;
<code class="go">exit</code></pre>&#13;
&#13;
<p>And then once we understand what is wrong with the <em>Dockerfile</em>, we can revert our debugging changes and fix the <code>npm</code> line so that the whole build works as expected.<a data-startref="ch04-troub" data-type="indexterm" id="idm46803149834192"/><a data-startref="ch04-troub2" data-type="indexterm" id="idm46803149833696"/><a data-startref="ch04-troub3" data-type="indexterm" id="idm46803149833024"/><a data-startref="ch04-debbk" data-type="indexterm" id="idm46803149832352"/><a data-startref="ch04-debbk2" data-type="indexterm" id="idm46803149831680"/><a data-startref="ch04-debbk3" data-type="indexterm" id="idm46803149831008"/><a data-startref="ch04-debbk4" data-type="indexterm" id="idm46803149830336"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Multiarchitecture Builds" data-type="sect1"><div class="sect1" id="idm46803150208144">&#13;
<h1>Multiarchitecture Builds</h1>&#13;
&#13;
<p>Since the launch of Docker,<a data-primary="OCI images" data-secondary="multiarchitecture builds" data-type="indexterm" id="ch04-multar"/><a data-primary="OCI images" data-secondary="building an image" data-tertiary="multiarchitecture builds" data-type="indexterm" id="ch04-multar2"/><a data-primary="multiarchitecture image builds" data-type="indexterm" id="ch04-multar3"/><a data-primary="AMD and ARM platform builds" data-type="indexterm" id="ch04-multar4"/><a data-primary="ARM and AMD platform builds" data-type="indexterm" id="ch04-multar5"/><a data-primary="docker buildx" data-primary-sortas="docker-z" data-secondary="multi-compute-architecture builds" data-type="indexterm" id="ch04-multar6"/> the <em>AMD64/X86_64</em> architecture has been the primary platform that most containers have targeted. However, this has started to change significantly. More and more developers are using systems based on ARM64/AArch64, and cloud companies are starting to make ARM-based VMs available through their platforms, due to the lower computing costs associated with the ARM platform.</p>&#13;
&#13;
<p>This can cause some interesting challenges for anyone who needs to build and maintain images that will target multiple architectures. How can you maintain a single, streamlined codebase and pipeline while still supporting all of these different targets?</p>&#13;
&#13;
<p>Luckily, Docker has released a plug-in for the <code>docker</code> CLI, called <code>buildx</code>, which can help make this process pretty straightforward. In many cases, <code>docker-buildx</code> will already be installed on your system, and you can verify this like so:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>buildx<code class="w"> </code>version<code class="w"/>&#13;
<code class="go">github.com/docker/buildx v0.9.1 ed00243a0ce2a0aee75311b06e32d33b44729689</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>If you need to install the plug-in, you can follow <a href="https://github.com/docker/buildx#installing">the directions from the GitHub repo</a>.</p>&#13;
</div>&#13;
&#13;
<p>By default, <code>docker-buildx</code> will leverage<a data-primary="QEMU-based virtualization" data-type="indexterm" id="idm46803149776672"/><a data-primary="binfmt_misc" data-type="indexterm" id="idm46803149775968"/> <a href="https://www.qemu.org">QEMU-based virtualization</a> and <a href="https://docs.kernel.org/admin-guide/binfmt-misc.html"><code>binfmt_misc</code></a> to support architectures that differ from the underlying system. This may already be set up on your Linux system, but just in case, it is a good idea to run the following command when you are first setting up a new Docker server, just to ensure that the QEMU files are properly registered and up to date:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>--privileged<code class="w"> </code>multiarch/qemu-user-static<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--reset<code class="w"> </code>-p<code class="w"> </code>yes<code class="w"/>&#13;
&#13;
<code class="go">Setting /usr/bin/qemu-alpha-static as binfmt interpreter for alpha</code>&#13;
<code class="go">Setting /usr/bin/qemu-arm-static as binfmt interpreter for arm</code>&#13;
<code class="go">Setting /usr/bin/qemu-armeb-static as binfmt interpreter for armeb</code>&#13;
<code class="go">…</code>&#13;
<code class="go">Setting /usr/bin/qemu-aarch64-static as binfmt interpreter for aarch64</code>&#13;
<code class="go">Setting /usr/bin/qemu-aarch64_be-static as binfmt interpreter for aarch64_be</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>Unlike the original embedded<a data-primary="BuildKit" data-secondary="build container for building images" data-type="indexterm" id="idm46803149694240"/><a data-primary="OCI images" data-secondary="building an image" data-tertiary="build container for building images" data-type="indexterm" id="idm46803149693392"/><a data-primary="Linux containers" data-secondary="build container for building images" data-type="indexterm" id="idm46803149734720"/> Docker build functionality, which ran directly on the server, BuildKit can utilize a build container when it builds images, which means that there is a lot of functional flexibility that can be delivered with that build container. In the next step, we are going to create a default <code>buildx</code> container called <code>builder</code>.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>If you have an existing <code>buildx</code> container<a data-primary="Linux containers" data-secondary="removing a container" data-tertiary="buildx container" data-type="indexterm" id="idm46803149731168"/><a data-primary="removing a container" data-secondary="buildx container" data-type="indexterm" id="idm46803149729888"/><a data-primary="docker buildx" data-primary-sortas="docker-z" data-secondary="rm to remove a container" data-type="indexterm" id="idm46803149728944"/> by this name, you can either remove it by running <code>docker buildx rm builder</code> or you can change the name in the upcoming <code>docker buildx create</code> command.</p>&#13;
</div>&#13;
&#13;
<p>With the next two commands, we are going to create the build container, set it as the default, and then start it up:<a data-primary="docker buildx" data-primary-sortas="docker-z" data-secondary="create" data-type="indexterm" id="idm46803149726288"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>buildx<code class="w"> </code>create<code class="w"> </code>--name<code class="w"> </code>builder<code class="w"> </code>--driver<code class="w"> </code>docker-container<code class="w"> </code>--use<code class="w"/>&#13;
<code class="go">builder</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>buildx<code class="w"> </code>inspect<code class="w"> </code>--bootstrap<code class="w"/>&#13;
<code class="go">[+] Building 9.6s (1/1) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] booting buildkit                                           9.6s</code>&#13;
<code class="go"> =&gt; =&gt; pulling image moby/buildkit:buildx-stable-1                        8.6s</code>&#13;
<code class="go"> =&gt; =&gt; creating container buildx_buildkit_builder0                        0.9s</code>&#13;
<code class="go">Name:   builder</code>&#13;
<code class="go">Driver: docker-container</code>&#13;
&#13;
<code class="go">Nodes:</code>&#13;
<code class="go">Name:      builder0</code>&#13;
<code class="go">Endpoint:  unix:///var/run/docker.sock</code>&#13;
<code class="go">Status:    running</code>&#13;
<code class="go">Buildkit:  v0.10.5</code>&#13;
<code class="go">Platforms: linux/amd64, linux/amd64/v2, linux/arm64, linux/riscv64,</code>&#13;
<code class="go">           linux/ppc64le, linux/s390x, linux/386, linux/mips64le,</code>&#13;
<code class="go">           linux/mips64, linux/arm/v7, linux/arm/v6</code></pre>&#13;
&#13;
<p>For this example, let’s go ahead and download the<a data-primary="wordchain" data-type="indexterm" id="idm46803149635792"/><a data-primary="Git" data-secondary="cloning a Git repository" data-tertiary="wordchain" data-type="indexterm" id="idm46803149668720"/><a data-primary="cloning a Git repository" data-secondary="wordchain" data-type="indexterm" id="idm46803149667600"/> <code>wordchain</code> Git repository, which contains a useful tool that can generate random and deterministic word sequences to help with dynamic naming needs:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>git<code class="w"> </code>clone<code class="w"> </code>https://github.com/spkane/wordchain.git<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--config<code class="w"> </code>core.autocrlf<code class="o">=</code>input<code class="w"/>&#13;
<code class="gp">$ </code><code class="nb">cd</code><code class="w"> </code>wordchain<code class="w"/></pre>&#13;
&#13;
<p>Let’s go ahead and take a look at the included <em>Dockerfile</em>. You’ll notice that it is a pretty normal multistage <em>Dockerfile</em> and does not have anything special in it related to the platform architecture:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">golang:1.18-alpine3.15</code><code class="w"> </code><code class="k">AS</code><code class="w"> </code><code class="s">build</code><code class="w"/>&#13;
&#13;
<code class="k">RUN</code><code class="w"> </code>apk<code class="w"> </code>--no-cache<code class="w"> </code>add<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>bash<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>gcc<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>musl-dev<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>openssl<code class="w"/>&#13;
&#13;
<code class="k">ENV</code><code class="w"> </code><code class="nv">CGO_ENABLED</code><code class="o">=</code><code class="m">0</code><code class="w"/>&#13;
&#13;
<code class="k">COPY</code><code class="w"> </code>.<code class="w"> </code>/build<code class="w"/>&#13;
<code class="k">WORKDIR</code><code class="w"> </code><code class="s">/build</code><code class="w"/>&#13;
&#13;
<code class="k">RUN</code><code class="w"> </code>go<code class="w"> </code>install<code class="w"> </code>github.com/markbates/pkger/cmd/pkger@latest<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>pkger<code class="w"> </code>-include<code class="w"> </code>/data/words.json<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>go<code class="w"> </code>build<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="k">FROM</code><code class="w"> </code><code class="s">alpine:3.15</code><code class="w"> </code><code class="k">AS</code><code class="w"> </code><code class="s">deploy</code><code class="w"/>&#13;
&#13;
<code class="k">WORKDIR</code><code class="w"> </code><code class="s">/</code><code class="w"/>&#13;
<code class="k">COPY</code><code class="w"> </code>--from<code class="o">=</code>build<code class="w"> </code>/build/wordchain<code class="w"> </code>/<code class="w"/>&#13;
&#13;
<code class="k">USER</code><code class="w"> </code><code class="s">500</code><code class="w"/>&#13;
<code class="k">EXPOSE</code><code class="w"> </code><code class="s">8080</code><code class="w"/>&#13;
&#13;
<code class="k">ENTRYPOINT</code><code class="w"> </code><code class="p">[</code><code class="s2">"/wordchain"</code><code class="p">]</code><code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"listen"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>In the first step, we are going to build our statically compiled Go binary, and then in the second step, we are going to package it up into a small deployment image.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The <code>ENTRYPOINT</code> instruction<a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="ENTRYPOINT" data-type="indexterm" id="idm46803149481792"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="CMD instruction" data-type="indexterm" id="idm46803149480624"/><a data-primary="ENTRYPOINT in Dockerfiles" data-type="indexterm" id="idm46803149479408"/> in the <em>Dockerfile</em> is an advanced instruction that allows you to separate the default process that is run by the container (<code>ENTRYPOINT</code>) from the command-line arguments that are passed to that process (<code>CMD</code>). When <code>ENTRYPOINT</code> is missing from the <em>Dockerfile</em>, the <code>CMD</code> instruction is expected to contain both the process and all the required command-line &#13;
<span class="keep-together">arguments.</span></p>&#13;
</div>&#13;
&#13;
<p>We can go ahead and build this image and side-load it into our local Docker server by running the following command:<a data-primary="docker buildx" data-primary-sortas="docker-z" data-secondary="build" data-type="indexterm" id="idm46803149444976"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>buildx<code class="w"> </code>build<code class="w"> </code>--tag<code class="w"> </code>wordchain:test<code class="w"> </code>--load<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 2.4s (16/16) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore                                         0.0s</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 93B                                          0.0s</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile                      0.0s</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 461B                                      0.0s</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; exporting to oci image format                                         0.3s</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers                                                   0.0s</code>&#13;
<code class="go"> =&gt; =&gt; exporting manifest sha256:4bd1971f2ed820b4f64ffda97707c27aac3e8eb7 0.0s</code>&#13;
<code class="go"> =&gt; =&gt; exporting config sha256:ce8f8564bf53b283d486bddeb8cbb074ff9a9d4ce9 0.0s</code>&#13;
<code class="go"> =&gt; =&gt; sending tarball                                                    0.2s</code>&#13;
<code class="go"> =&gt; importing to docker                                                   0.0s</code></pre>&#13;
&#13;
<p>We can quickly test out the image by running the following commands:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>wordchain:test<code class="w"> </code>random<code class="w"/>&#13;
&#13;
<code class="go">witty-stack</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>wordchain:test<code class="w"> </code>random<code class="w"> </code>-l<code class="w"> </code><code class="m">3</code><code class="w"> </code>-d<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">odd.goo</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>wordchain:test<code class="w"> </code>--help<code class="w"/>&#13;
&#13;
<code class="go">wordchain is an application that can generate a readable chain</code>&#13;
<code class="go">  of customizable words for naming things like</code>&#13;
<code class="go">  containers, clusters, and other objects.</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>As long as you got some random word pairs back with the first two commands, then everything is working as expected.</p>&#13;
&#13;
<p>Now, to build this image for multiple architectures, we need to simply add the <code>--platform</code> argument to our build.<a data-primary="docker buildx" data-primary-sortas="docker-z" data-secondary="build" data-tertiary="--platform (for multiple architectures)" data-tertiary-sortas="platform" data-type="indexterm" id="idm46803149361392"/></p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Typically we would also replace <code>--load</code> with <code>--push</code>, which would push all the resulting images to the tagged repository, but in this case, we need to simply remove <code>--load</code>, because the Docker server cannot load images for multiple platforms at the moment, and we do not have a repository set up to push these images to. If we did have a repository and we tagged the images correctly, then we could very easily build and push all the resulting images in one step, with a command like this:</p>&#13;
&#13;
<p><code>docker buildx build --platform linux/amd64,linux/arm64 --tag docker.io/spkane/wordchain:latest --push .</code></p>&#13;
</div>&#13;
&#13;
<p>You can build this image for both the linux/amd64 and the linux/arm64 platforms like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>buildx<code class="w"> </code>build<code class="w"> </code>--platform<code class="w"> </code>linux/amd64,linux/arm64<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--tag<code class="w"> </code>wordchain:test<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 114.9s (23/23) FINISHED</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; [linux/arm64 internal] load metadata for docker.io/library/alpine:3.1 2.7s</code>&#13;
<code class="go"> =&gt; [linux/amd64 internal] load metadata for docker.io/library/alpine:3.1 2.7s</code>&#13;
<code class="go"> =&gt; [linux/arm64 internal] load metadata for docker.io/library/golang:1.1 3.0s</code>&#13;
<code class="go"> =&gt; [linux/amd64 internal] load metadata for docker.io/library/golang:1.1 2.8s</code>&#13;
<code class="go">…</code>&#13;
<code class="go"> =&gt; CACHED [linux/amd64 build 5/5] RUN go install github.com/markbates/pk 0.0s</code>&#13;
<code class="go"> =&gt; CACHED [linux/amd64 deploy 2/3] COPY --from=build /build/wordchain /  0.0s</code>&#13;
<code class="go"> =&gt; [linux/arm64 build 5/5] RUN go install github.com/markbates/pkger/c 111.7s</code>&#13;
<code class="go"> =&gt; [linux/arm64 deploy 2/3] COPY --from=build /build/wordchain /         0.0s</code>&#13;
<code class="go">WARNING: No output specified with docker-container driver. Build result will</code>&#13;
<code class="go">         only remain in the build cache. To push result image into registry</code>&#13;
<code class="go">         use --push or to load image into docker use --load</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Due to the emulation that is required when building images for nonnative architectures, you may notice that some steps take much longer than normal. This is to be expected due to the additional computational overhead from the emulation.</p>&#13;
&#13;
<p>It is possible to set up Docker so that it will build each image on a worker with a matching architecture, which should speed things up significantly in many cases. You can find some information about this in this <a href="https://www.docker.com/blog/speed-up-building-with-docker-buildx-and-graviton2-ec2">Docker blog article</a>.</p>&#13;
</div>&#13;
&#13;
<p>In the output for the build, you will notice lines that start with something like &#13;
<span class="keep-together"><code>=&gt; [linux/amd64 *]</code></span> or <code>=&gt; [linux/arm64 *]</code>. Each of these lines represents the builder working on this build step for the stated platform. Many of these steps will run in parallel, and due to caching and other considerations, each build might progress at differing speeds.</p>&#13;
&#13;
<p>Since we did not add <code>--push</code> to our build, you will also notice that we received a warning at the end of the build. This is because the <em>docker-container</em> driver that the builder is using just left everything in the build cache, which means that we can’t run the resulting images; at this point, we can only feel confident that the build is working.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>There are a few <a href="https://docs.docker.com/engine/reference/builder/#automatic-platform-args-in-the-global-scope"><code>build</code> arguments</a> that are automatically set by Docker that can be especially <a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="TARGETARCH" data-type="indexterm" id="idm46803149300832"/><a data-primary="TARGETARCH in Dockerfiles" data-type="indexterm" id="idm46803149299696"/>helpful to leverage inside your <em>Dockerfile</em> when you are doing multiarchitecture builds. As an example, <code>TARGETARCH</code> is frequently used to make sure that a given build step downloads the correct prebuilt binary for the current image’s platform.</p>&#13;
</div>&#13;
&#13;
<p>So, when we upload this image to a repository, how does Docker know which image to use for the local platform? <a data-primary="OCI images" data-secondary="multiarchitecture builds" data-tertiary="image manifest" data-type="indexterm" id="idm46803149297232"/><a data-primary="multiarchitecture image builds" data-secondary="image manifest" data-type="indexterm" id="idm46803149296016"/><a data-primary="ARM and AMD platform builds" data-secondary="image manifest" data-type="indexterm" id="idm46803149295104"/><a data-primary="AMD and ARM platform builds" data-secondary="image manifest" data-type="indexterm" id="idm46803149294192"/><a data-primary="docker manifest inspect" data-primary-sortas="docker-z" data-type="indexterm" id="idm46803149293280"/>This information is provided to the Docker server through something called an <em>image manifest</em>. We can look at the manifest for <em>docker.io/spkane/workdchain</em> by running the following:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>manifest<code class="w"> </code>inspect<code class="w"> </code>docker.io/spkane/wordchain:latest<code class="w"/></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="json" data-type="programlisting"><code class="p">{</code><code class="w"/>&#13;
<code class="w">   </code><code class="nt">"schemaVersion"</code><code class="p">:</code><code class="w"> </code><code class="mi">2</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">   </code><code class="nt">"mediaType"</code><code class="p">:</code><code class="w"> </code><code class="s2">"application/vnd.docker.distribution.manifest.list.v2+json"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">   </code><code class="nt">"manifests"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">      </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">         </code><code class="nt">"mediaType"</code><code class="p">:</code><code class="w"> </code><code class="s2">"application/vnd.docker.distribution.manifest.v2+json"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">         </code><code class="nt">"size"</code><code class="p">:</code><code class="w"> </code><code class="mi">739</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">         </code><code class="nt">"digest"</code><code class="p">:</code><code class="w"> </code><code class="s2">"sha256:4bd1…bfc0"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">         </code><code class="nt">"platform"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"architecture"</code><code class="p">:</code><code class="w"> </code><code class="s2">"amd64"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"os"</code><code class="p">:</code><code class="w"> </code><code class="s2">"linux"</code><code class="w"/>&#13;
<code class="w">         </code><code class="p">}</code><code class="w"/>&#13;
<code class="w">      </code><code class="p">},</code><code class="w"/>&#13;
<code class="w">      </code><code class="p">{</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">         </code><code class="nt">"platform"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"architecture"</code><code class="p">:</code><code class="w"> </code><code class="s2">"arm64"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"os"</code><code class="p">:</code><code class="w"> </code><code class="s2">"linux"</code><code class="w"/>&#13;
<code class="w">         </code><code class="p">}</code><code class="w"/>&#13;
<code class="w">      </code><code class="p">},</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">   </code><code class="p">]</code><code class="w"/>&#13;
<code class="p">}</code><code class="w"/></pre>&#13;
&#13;
<p>If you look through the output, you will see that there are blocks that identify the image that is required for every platform the image supports. This is accomplished via the individual <a href="https://github.com/opencontainers/image-spec/blob/main/descriptor.md#digests"><code>digest</code></a> entries that are then paired with a <em>platform</em> block. This manifest file is downloaded by the server when it requires an image, and then after referencing the manifest, the server will download the correct image for the local platform. This is why our <em>Dockerfile</em> works at all. Each <code>FROM</code> line lists a base image that we want to use, but it is the Docker server that utilizes this manifest file to determine exactly which image to download for each platform that the build is targeting.<a data-startref="ch04-multar" data-type="indexterm" id="idm46803149060768"/><a data-startref="ch04-multar2" data-type="indexterm" id="idm46803149150704"/><a data-startref="ch04-multar3" data-type="indexterm" id="idm46803149150032"/><a data-startref="ch04-multar4" data-type="indexterm" id="idm46803149149360"/><a data-startref="ch04-multar5" data-type="indexterm" id="idm46803149148688"/><a data-startref="ch04-multar6" data-type="indexterm" id="idm46803149148016"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Wrap-Up" data-type="sect1"><div class="sect1" id="idm46803149828880">&#13;
<h1>Wrap-Up</h1>&#13;
&#13;
<p>At this point, you should feel pretty comfortable with image creation for Docker and should have a solid understanding of many of the core tools and functionality you can leverage to streamline your build pipeline. In the next chapter, we will start to dig into how you can use your images to create containerized processes for your projects.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm46803155693712"><sup><a href="ch04.html#idm46803155693712-marker">1</a></sup> Full URL: <a class="bare" href="https://github.com/torvalds/linux/commit/e9be9d5e76e34872f0c37d72e25bc27fe9e2c54c"><em class="hyperlink">https://github.com/torvalds/linux/commit/e9be9d5e76e34872f0c37d72e25bc27fe9e2c54c</em></a></p><p data-type="footnote" id="idm46803155211200"><sup><a href="ch04.html#idm46803155211200-marker">2</a></sup> This code was originally forked from <a href="https://github.com/enokd/docker-node-hello">GitHub</a>.</p><p data-type="footnote" id="idm46803154385056"><sup><a href="ch04.html#idm46803154385056-marker">3</a></sup> Full URL: <a class="bare" href="https://docs.docker.com/registry/recipes/mirror/#configure-the-docker-daemon"><em class="hyperlink">https://docs.docker.com/registry/recipes/mirror/#configure-the-docker-daemon</em></a></p><p data-type="footnote" id="idm46803154382192"><sup><a href="ch04.html#idm46803154382192-marker">4</a></sup> Full URL: <a class="bare" href="https://docs.docker.com/registry/recipes/mirror/#run-a-registry-as-a-pull-through-cache"><em class="hyperlink">https://docs.docker.com/registry/recipes/mirror/#run-a-registry-as-a-pull-through-cache</em></a></p><p data-type="footnote" id="idm46803152409712"><sup><a href="ch04.html#idm46803152409712-marker">5</a></sup> Full URL: <a class="bare" href="https://github.com/bluewhalebook/docker-up-and-running-3rd-edition/blob/main/chapter_04/multistage/Dockerfile"><em class="hyperlink">https://github.com/bluewhalebook/docker-up-and-running-3rd-edition/blob/main/chapter_04/multistage/Dockerfile</em></a></p><p data-type="footnote" id="idm46803151763616"><sup><a href="ch04.html#idm46803151763616-marker">6</a></sup> Full URL: <a class="bare" href="https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/measure-command?view=powershell-7.3"><em class="hyperlink">https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/measure-command?view=powershell-7.3</em></a></p></div></div></section></body></html>