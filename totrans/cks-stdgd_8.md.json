["```\n    apiVersion: networking.k8s.io/v1\n    kind: NetworkPolicy\n    metadata:\n      name: deny-egress-external\n    spec:\n      podSelector:\n        matchLabels:\n          app: backend\n      policyTypes:\n      - Egress\n      egress:\n      - to:\n        - namespaceSelector: {}\n        ports:\n        - port: 53\n          protocol: UDP\n        - port: 53\n          protocol: TCP\n    ```", "```\n    $ kubectl apply -f deny-egress-external.yaml\n    ```", "```\n    $ kubectl run web --image=busybox:1.36.0 -l app=frontend --port=80 -it \\\n      --rm --restart=Never -- wget http://google.com --timeout=5 --tries=1\n    Connecting to google.com (142.250.69.238:80)\n    Connecting to www.google.com (142.250.72.4:80)\n    saving to /'index.xhtml'\n    index.xhtml           100% |************| 13987 \\\n    0:00:00 ETA\n    /'index.xhtml' saved\n    pod \"web\" deleted**********\n    ```", "```\n    $ kubectl run web --image=busybox:1.36.0 -l app=backend --port=80 -it \\\n      --rm --restart=Never -- wget http://google.com --timeout=5 --tries=1\n    wget: download timed out\n    pod \"web\" deleted\n    pod default/web terminated (Error)\n    ```", "```\n    $ kubectl get ns kubernetes-dashboard\n    NAME                   STATUS   AGE\n    kubernetes-dashboard   Active   109s\n    ```", "```\n    $ kubectl apply -f https://raw.githubusercontent.com/kubernetes/\\\n    dashboard/v2.6.0/aio/deploy/recommended.yaml\n    ```", "```\n    apiVersion: v1\n    kind: ServiceAccount\n    metadata:\n      name: observer-user\n      namespace: kubernetes-dashboard\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: ClusterRole\n    metadata:\n      annotations:\n        rbac.authorization.kubernetes.io/autoupdate: \"true\"\n      name: cluster-observer\n    rules:\n    - apiGroups:\n      - 'apps'\n      resources:\n      - 'deployments'\n      verbs:\n      - list\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: ClusterRoleBinding\n    metadata:\n      name: observer-user\n    roleRef:\n      apiGroup: rbac.authorization.k8s.io\n      kind: ClusterRole\n      name: cluster-observer\n    subjects:\n    - kind: ServiceAccount\n      name: observer-user\n      namespace: kubernetes-dashboard\n    ```", "```\n    $ kubectl apply -f dashboard-observer-user.yaml\n    ```", "```\n    $ kubectl create token observer-user -n kubernetes-dashboard \\\n      --duration 0s\n    eyJhbGciOiJSUzI1NiIsImtpZCI6Ik5lNFMxZ1...\n    ```", "```\n    $ kubectl proxy\n    ```", "```\n    $ curl -LO \"https://dl.k8s.io/v1.26.1/bin/linux/amd64/kube-apiserver\"\n    ```", "```\n    $ curl -LO \"https://dl.k8s.io/v1.23.1/bin/linux/amd64/\\\n    kube-apiserver.sha256\"\n    ```", "```\n    $ echo \"$(cat kube-apiserver.sha256)  kube-apiserver\" | shasum -a 256 \\\n      --check\n    kube-apiserver: FAILED\n    shasum: WARNING: 1 computed checksum did NOT match\n    ```", "```\n    $ openssl genrsa -out jill.key 2048\n    $ openssl req -new -key jill.key -out jill.csr -subj \\\n      \"/CN=jill/O=observer\"\n    ```", "```\n    $ cat jill.csr | base64 | tr -d \"\\n\"\n    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tL...\n    ```", "```\n    $ cat <<EOF | kubectl apply -f -\n    apiVersion: certificates.k8s.io/v1\n    kind: CertificateSigningRequest\n    metadata:\n      name: jill\n    spec:\n      request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tL...\n      signerName: kubernetes.io/kube-apiserver-client\n      expirationSeconds: 86400\n      usages:\n      - client auth\n    EOF\n    ```", "```\n    $ kubectl certificate approve jill\n    $ kubectl get csr jill -o jsonpath=*{.status.certificate}*| base64 \\\n      -d > jill.crt\n    ```", "```\n    $ kubectl config set-credentials jill --client-key=jill.key \\\n      --client-certificate=jill.crt --embed-certs=true\n    $ kubectl config set-context jill --cluster=minikube --user=jill\n    ```", "```\n    $ kubectl create role observer --verb=create --verb=get --verb=list \\\n      --verb=watch --resource=pods --resource=configmaps --resource=secrets\n    $ kubectl create rolebinding observer-binding --role=observer \\\n      --group=observer\n    ```", "```\n    $ kubectl config use-context jill\n    ```", "```\n    $ kubectl get configmaps\n    NAME               DATA   AGE\n    kube-root-ca.crt   1      16m\n    ```", "```\n    $ kubectl get nodes\n    Error from server (Forbidden): nodes is forbidden: User \"jill\" cannot \\\n    list resource \"nodes\" in API group \"\" at the cluster scope\n    ```", "```\n    $ kubectl config use-context minikube\n    ```", "```\n    $ kubectl create namespace t23\n    ```", "```\n    $ kubectl create serviceaccount api-call -n t23\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: service-list\n      namespace: t23\n    spec:\n      serviceAccountName: api-call\n      containers:\n      - name: service-list\n        image: alpine/curl:3.14\n        command: ['sh', '-c', 'while true; do curl -s -k -m 5 \\\n                  -H \"Authorization: Bearer $(cat /var/run/secrets/\\\n                  kubernetes.io/serviceaccount/token)\" https://kubernetes.\\\n                  default.svc.cluster.local/api/v1/namespaces/default/\\\n                  services; sleep 10; done']\n    ```", "```\n    $ kubectl apply -f pod.yaml\n    ```", "```\n    $ kubectl logs service-list -n t23\n    {\n      \"kind\": \"Status\",\n      \"apiVersion\": \"v1\",\n      \"metadata\": {},\n      \"status\": \"Failure\",\n      \"message\": \"services is forbidden: User \\\"system:serviceaccount:t23 \\\n                  :api-call\\\" cannot list resource \\\"services\\\" in API \\\n                  group \\\"\\\" in the namespace \\\"default\\\"\",\n      \"reason\": \"Forbidden\",\n      \"details\": {\n        \"kind\": \"services\"\n      },\n      \"code\": 403\n    }\n    ```", "```\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: ClusterRole\n    metadata:\n      name: list-services-clusterrole\n    rules:\n    - apiGroups: [\"\"]\n      resources: [\"services\"]\n      verbs: [\"list\"]\n    ```", "```\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: RoleBinding\n    metadata:\n      name: serviceaccount-service-rolebinding\n    subjects:\n    - kind: ServiceAccount\n      name: api-call\n      namespace: t23\n    roleRef:\n      kind: ClusterRole\n      name: list-services-clusterrole\n      apiGroup: rbac.authorization.k8s.io\n    ```", "```\n    $ kubectl apply -f clusterrole.yaml\n    $ kubectl apply -f rolebinding.yaml\n    ```", "```\n    $ kubectl logs service-list -n t23\n    {\n      \"kind\": \"ServiceList\",\n      \"apiVersion\": \"v1\",\n      \"metadata\": {\n        \"resourceVersion\": \"1108\"\n      },\n      \"items\": [\n         {\n           \"metadata\": {\n             \"name\": \"kubernetes\",\n             \"namespace\": \"default\",\n             \"uid\": \"30eb5425-8f60-4bb7-8331-f91fe0999e20\",\n             \"resourceVersion\": \"199\",\n             \"creationTimestamp\": \"2022-09-08T18:06:52Z\",\n             \"labels\": {\n               \"component\": \"apiserver\",\n               \"provider\": \"kubernetes\"\n           },\n           ...\n         }\n      ]\n    }\n    ```", "```\n    $ kubectl create token api-call -n t23\n    eyJhbGciOiJSUzI1NiIsImtpZCI6IjBtQkJzVWlsQjl...\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: service-list\n      namespace: t23\n    spec:\n      serviceAccountName: api-call\n      automountServiceAccountToken: false\n      containers:\n      - name: service-list\n        image: alpine/curl:3.14\n        command: ['sh', '-c', 'while true; do curl -s -k -m 5 \\\n                  -H \"Authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ij \\\n                  BtQkJzVWlsQjl\" https://kubernetes.default.svc.cluster. \\\n                  local/api/v1/namespaces/default/services; sleep 10; \\\n                  done']\n    ```", "```\n    $ kubectl logs service-list -n t23\n    {\n      \"kind\": \"ServiceList\",\n      \"apiVersion\": \"v1\",\n      \"metadata\": {\n        \"resourceVersion\": \"81194\"\n      },\n      \"items\": [\n         {\n           \"metadata\": {\n             \"name\": \"kubernetes\",\n             \"namespace\": \"default\",\n             \"uid\": \"30eb5425-8f60-4bb7-8331-f91fe0999e20\",\n             \"resourceVersion\": \"199\",\n             \"creationTimestamp\": \"2022-09-08T18:06:52Z\",\n             \"labels\": {\n               \"component\": \"apiserver\",\n               \"provider\": \"kubernetes\"\n           },\n           ...\n         }\n      ]\n    }\n    ```", "```\n    $ vagrant ssh kube-control-plane\n    ```", "```\n    $ sudo apt-mark unhold kubeadm && sudo apt-get update && sudo apt-get \\\n      install -y kubeadm=1.26.1-00 && sudo apt-mark hold kubeadm\n    $ sudo kubeadm upgrade apply v1.26.1\n    ```", "```\n    $ kubectl drain kube-control-plane --ignore-daemonsets\n    $ sudo apt-get update && sudo apt-get install -y \\\n      --allow-change-held-packages kubelet=1.26.1-00 kubectl=1.26.1-00\n    $ sudo systemctl daemon-reload\n    $ sudo systemctl restart kubelet\n    $ kubectl uncordon kube-control-plane\n    ```", "```\n    $ kubectl get nodes\n    $ exit\n    ```", "```\n    $ vagrant ssh kube-worker-1\n    ```", "```\n    $ sudo apt-get update && sudo apt-get install -y \\\n      --allow-change-held-packages kubeadm=1.26.1-00\n    $ sudo kubeadm upgrade node\n    ```", "```\n    $ kubectl drain kube-worker-1 --ignore-daemonsets\n    $ sudo apt-get update && sudo apt-get install -y \\\n      --allow-change-held-packages kubelet=1.26.1-00 kubectl=1.26.1-00\n    $ sudo systemctl daemon-reload\n    $ sudo systemctl restart kubelet\n    $ kubectl uncordon kube-worker-1\n    ```", "```\n    $ kubectl get nodes\n    $ exit\n    ```", "```\n    $ vagrant ssh kube-worker-1\n    ```", "```\n    $ sudo lsof -i :21\n    COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n    vsftpd  10178 root    3u  IPv6  56850      0t0  TCP *:ftp (LISTEN)\n    ```", "```\n    $ sudo ss -at -pn '( dport = :21 or sport = :21 )'\n    State   Recv-Q   Send-Q   Local Address:Port \\\n       Peer Address:Port   Process\n    LISTEN  0   32   *:21 \\\n       *:*   users:((\"vsftpd\",pid=10178,fd=3))\n\n    ```", "```\n    $ sudo systemctl status vsftpd\n    ● vsftpd.service - vsftpd FTP server\n         Loaded: loaded (/lib/systemd/system/vsftpd.service; enabled; \\\n                 vendor preset: enabled)\n         Active: active (running) since Thu 2022-10-06 14:39:12 UTC; \\\n                 11min ago\n       Main PID: 10178 (vsftpd)\n          Tasks: 1 (limit: 1131)\n         Memory: 604.0K\n         CGroup: /system.slice/vsftpd.service\n                 └─10178 /usr/sbin/vsftpd /etc/vsftpd.conf\n\n    Oct 06 14:39:12 kube-worker-1 systemd[1]: Starting vsftpd FTP server...\n    Oct 06 14:39:12 kube-worker-1 systemd[1]: Started vsftpd FTP server.\n    ```", "```\n    $ sudo systemctl stop vsftpd\n    $ sudo systemctl disable vsftpd\n    $ sudo apt purge --auto-remove -y vsftpd\n    ```", "```\n    $ sudo lsof -i :21\n    ```", "```\n    $ exit\n    ```", "```\n    $ vagrant ssh kube-worker-1\n    ```", "```\n    #include <tunables/global>\n\n    profile network-deny flags=(attach_disconnected) {\n      #include <abstractions/base>\n\n      network,\n    }\n    ```", "```\n    $ sudo apparmor_parser /etc/apparmor.d/network-deny\n    ```", "```\n    $ kubectl get pod -o yaml > pod.yaml\n    $ kubectl delete pod network-call\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: network-call\n      annotations:\n        container.apparmor.security.beta.kubernetes.io/network-call: \\\n        localhost/network-deny\n    spec:\n      containers:\n      - name: network-call\n        image: alpine/curl:3.14\n        command: [\"sh\", \"-c\", \"while true; do ping -c 1 google.com; \\\n                  sleep 5; done\"]\n    ```", "```\n    $ kubectl create -f pod.yaml\n    $ kubectl get pod network-call\n    NAME           READY   STATUS    RESTARTS   AGE\n    network-call   1/1     Running   0          27s\n    ```", "```\n    $ kubectl logs network-call\n    ...\n    sh: ping: Permission denied\n    sh: sleep: Permission denied\n    ```", "```\n    $ exit\n    ```", "```\n    $ vagrant ssh kube-worker-1\n    ```", "```\n    $ sudo mkdir -p /var/lib/kubelet/seccomp/profiles\n    ```", "```\n    {\n        \"defaultAction\": \"SCMP_ACT_LOG\"\n    }\n    ```", "```\n    $ kubectl get pod -o yaml > pod.yaml\n    $ kubectl delete pod network-call\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: network-call\n    spec:\n      securityContext:\n        seccompProfile:\n          type: Localhost\n          localhostProfile: profiles/audit.json\n      containers:\n      - name: network-call\n        image: alpine/curl:3.14\n        command: [\"sh\", \"-c\", \"while true; do ping -c 1 google.com; \\\n                  sleep 5; done\"]\n        securityContext:\n          allowPrivilegeEscalation: false\n    ```", "```\n    $ kubectl create -f pod.yaml\n    $ kubectl get pod network-call\n    NAME           READY   STATUS    RESTARTS   AGE\n    network-call   1/1     Running   0          27s\n    ```", "```\n    $ sudo cat /var/log/syslog\n    Oct  6 16:25:06 ubuntu-focal kernel: [ 2114.894122] audit: type=1326 \\\n    audit(1665073506.099:23761): auid=4294967295 uid=0 gid=0 \\\n    ses=4294967295 pid=19226 comm=\"sleep\" exe=\"/bin/busybox\" \\\n    sig=0 arch=c000003e syscall=231 compat=0 ip=0x7fc026adbf0b \\\n    code=0x7ffc0000\n    ```", "```\n    $ exit\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: sysctl-pod\n    spec:\n      securityContext:\n        sysctls:\n        - name: net.core.somaxconn\n          value: \"1024\"\n        - name: debug.iotrace\n          value: \"1\"\n      containers:\n      - name: nginx\n        image: nginx:1.23.1\n    ```", "```\n    $ kubectl create -f pod.yaml\n    $ kubectl get pods\n    NAME         READY   STATUS            RESTARTS   AGE\n    sysctl-pod   0/1     SysctlForbidden   0          4s\n    ```", "```\n    $ kubectl describe pod sysctl-pod\n    ...\n    Events:\n      Type     Reason           Age    From    \\\n                 Message\n      ----     ------           ----   ----    \\\n                 -------\n      Warning  SysctlForbidden  2m48s  kubelet \\\n                 forbidden sysctl: \"net.core.somaxconn\" \\\n                 not allowlisted\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: busybox-security-context\n    spec:\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 3000\n        fsGroup: 2000\n      volumes:\n      - name: vol\n        emptyDir: {}\n      containers:\n      - name: busybox\n        image: busybox:1.28\n        command: [\"sh\", \"-c\", \"sleep 1h\"]\n        volumeMounts:\n        - name: vol\n          mountPath: /data/test\n        securityContext:\n          allowPrivilegeEscalation: false\n    ```", "```\n    $ kubectl apply -f busybox-security-context.yaml\n    $ kubectl get pod busybox-security-context\n    NAME                       READY   STATUS    RESTARTS   AGE\n    busybox-security-context   1/1     Running   0          54s\n    ```", "```\n    $ kubectl exec busybox-security-context -it -- /bin/sh\n    / $ cd /data/test\n    /data/test $ touch hello.txt\n    /data/test $ ls -l\n    total 0\n    -rw-r--r--    1 1000     2000             0 Nov 21 18:29 hello.txt\n    /data/test $ exit\n    ```", "```\n    apiVersion: v1\n    kind: Namespace\n    metadata:\n      name: audited\n      labels:\n        pod-security.kubernetes.io/warn: baseline\n    ```", "```\n    $ kubectl apply -f psa-namespace.yaml\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: busybox\n      namespace: audited\n    spec:\n      hostNetwork: true\n      containers:\n      - name: busybox\n        image: busybox:1.28\n        command: [\"sh\", \"-c\", \"sleep 1h\"]\n    ```", "```\n    $ kubectl apply -f psa-pod.yaml\n    Warning: would violate PodSecurity \"baseline:latest\": host namespaces \\\n    (hostNetwork=true)\n    pod/busybox created\n    $ kubectl get pod busybox -n audited\n    NAME      READY   STATUS    RESTARTS   AGE\n    busybox   1/1     Running   0          2m21s\n    ```", "```\n    $ kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/\\\n    gatekeeper/master/deploy/gatekeeper.yaml\n    ```", "```\n    $ kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/\\\n    gatekeeper-library/master/library/general/replicalimits/template.yaml\n    ```", "```\n    apiVersion: constraints.gatekeeper.sh/v1beta1\n    kind: K8sReplicaLimits\n    metadata:\n      name: replica-limits\n    spec:\n      match:\n        kinds:\n          - apiGroups: [\"apps\"]\n            kinds: [\"Deployment\"]\n      parameters:\n        ranges:\n        - min_replicas: 3\n          max_replicas: 10\n    ```", "```\n    $ kubectl apply -f replica-limits-constraint.yaml\n    ```", "```\n    $ kubectl create deployment nginx --image=nginx:1.23.2 --replicas=15\n    error: failed to create deployment: admission webhook \\\n    \"validation.gatekeeper.sh\" denied the request: [replica-limits] \\\n    The provided number of replicas is not allowed for deployment: nginx. \\\n    Allowed ranges: {\"ranges\": [{\"max_replicas\": 10, \"min_replicas\": 3}]}\n    $ kubectl create deployment nginx --image=nginx:1.23.2 --replicas=7\n    deployment.apps/nginx created\n    ```", "```\n    $ kubectl create secret generic db-credentials \\\n      --from-literal=api-key=YZvkiWUkycvspyGHk3fQRAkt\n    ```", "```\n    $ sudo ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n    --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/\\\n    etcd/server.key get /registry/secrets/default/db-credentials | hexdump -C\n    ```", "```\n    $ vagrant ssh kube-worker-1\n    ```", "```\n    apiVersion: node.k8s.io/v1\n    kind: RuntimeClass\n    metadata:\n      name: container-runtime-sandbox\n    handler: runsc\n    ```", "```\n    $ kubectl apply -f runtime-class.yaml\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: nginx\n    spec:\n      runtimeClassName: container-runtime-sandbox\n      containers:\n      - name: nginx\n        image: nginx:1.23.2\n    ```", "```\n    $ kubectl apply -f pod.yaml\n    $ kubectl get pod nginx\n    NAME    READY   STATUS    RESTARTS   AGE\n    nginx   1/1     Running   0          2m21s\n    ```", "```\n    $ exit\n    ```", "```\n    $ docker build . -t node-app:0.0.1\n    ...\n    $ docker images\n    REPOSITORY   TAG       IMAGE ID       CREATED         SIZE\n    node-app     0.0.1     7ba99d4ba3af   3 seconds ago   998MB\n    $ docker run -p 3001:3001 -d node-app:0.0.1\n    c0c8a301eeb4ac499c22d10399c424e1063944f18fff70ceb5c49c4723af7969\n    $ curl -L http://localhost:3001/\n    Hello World\n    ```", "```\n    $ docker build . -t node-app:0.0.1\n    ...\n    $ docker images\n    REPOSITORY   TAG       IMAGE ID       CREATED          SIZE\n    node-app     0.0.1     ef2fbec41a75   2 seconds ago    176MB\n    ```", "```\n    $ kubectl create -f https://raw.githubusercontent.com/kyverno/\\\n    kyverno/main/config/install.yaml\n    ```", "```\n    apiVersion: kyverno.io/v1\n    kind: ClusterPolicy\n    metadata:\n      name: restrict-image-registries\n      annotations:\n        policies.kyverno.io/title: Restrict Image Registries\n        policies.kyverno.io/category: Best Practices, EKS Best Practices\n        policies.kyverno.io/severity: medium\n        policies.kyverno.io/minversion: 1.6.0\n        policies.kyverno.io/subject: Pod\n        policies.kyverno.io/description: >-\n          Images from unknown, public registries can be of dubious quality \\\n          and may not be scanned and secured, representing a high degree of \\\n          risk. Requiring use of known, approved registries helps reduce \\\n          threat exposure by ensuring image pulls only come from them. This \\\n          policy validates that container images only originate from the \\\n          registry `eu.foo.io` or `bar.io`. Use of this policy requires \\\n          customization to define your allowable registries.\n    spec:\n      validationFailureAction: Enforce\n      background: true\n      rules:\n      - name: validate-registries\n        match:\n          any:\n          - resources:\n              kinds:\n              - Pod\n        validate:\n          message: \"Unknown image registry.\"\n          pattern:\n            spec:\n              containers:\n              - image: \"gcr.io/*\"\n    ```", "```\n    $ kubectl apply -f restrict-image-registries.yaml\n    ```", "```\n    $ kubectl run nginx --image=nginx:1.23.3\n    Error from server: admission webhook \"validate.kyverno.svc-fail\" \\\n    denied the request:\n\n    policy Pod/default/nginx for resource violation:\n\n    restrict-image-registries:\n      validate-registries: 'validation error: Unknown image registry. \\\n      rule validate-registries\n        failed at path /spec/containers/0/image/'\n    $ kubectl run busybox --image=gcr.io/google-containers/busybox:1.27.2\n    pod/busybox created\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx@sha256:c1b9fe3c0c015486cf1e4a0ecabe78d05864475e279638 \\\n               e9713eb55f013f907f\n    ```", "```\n    $ kubectl apply -f pod-validate-image.yaml\n    pod/nginx created\n    $ kubectl get pods nginx\n    NAME    READY   STATUS    RESTARTS   AGE\n    nginx   1/1     Running   0          29s\n    ```", "```\n    $ docker run -i kubesec/kubesec:512c5e0 scan /dev/stdin < pod.yaml\n    [\n      {\n        \"object\": \"Pod/hello-world.default\",\n        \"valid\": true,\n        \"message\": \"Passed with a score of 0 points\",\n        \"score\": 0,\n        \"scoring\": {\n          \"advise\": [\n            {\n              \"selector\": \"containers[] .securityContext .capabilities \\\n                           .drop | index(\\\"ALL\\\")\",\n              \"reason\": \"Drop all capabilities and add only those \\\n                         required to reduce syscall attack surface\"\n            },\n            {\n              \"selector\": \"containers[] .resources .requests .cpu\",\n              \"reason\": \"Enforcing CPU requests aids a fair balancing \\\n                         of resources across the cluster\"\n            },\n            {\n              \"selector\": \"containers[] .securityContext .runAsNonRoot \\\n                           == true\",\n              \"reason\": \"Force the running image to run as a non-root \\\n                         user to ensure least privilege\"\n            },\n            {\n              \"selector\": \"containers[] .resources .limits .cpu\",\n              \"reason\": \"Enforcing CPU limits prevents DOS via resource \\\n                         exhaustion\"\n            },\n            {\n              \"selector\": \"containers[] .securityContext .capabilities \\\n                           .drop\",\n              \"reason\": \"Reducing kernel capabilities available to a \\\n                         container limits its attack surface\"\n            },\n            {\n              \"selector\": \"containers[] .resources .requests .memory\",\n              \"reason\": \"Enforcing memory requests aids a fair balancing \\\n                         of resources across the cluster\"\n            },\n            {\n              \"selector\": \"containers[] .resources .limits .memory\",\n              \"reason\": \"Enforcing memory limits prevents DOS via resource \\\n                         exhaustion\"\n            },\n            {\n              \"selector\": \"containers[] .securityContext \\\n                           .readOnlyRootFilesystem == true\",\n              \"reason\": \"An immutable root filesystem can prevent malicious \\\n                         binaries being added to PATH and increase attack \\\n                         cost\"\n            },\n            {\n              \"selector\": \".metadata .annotations .\\\"container.seccomp. \\\n                           security.alpha.kubernetes.io/pod\\\"\",\n              \"reason\": \"Seccomp profiles set minimum privilege and secure \\\n                         against unknown threats\"\n            },\n            {\n              \"selector\": \".metadata .annotations .\\\"container.apparmor. \\\n                           security.beta.kubernetes.io/nginx\\\"\",\n              \"reason\": \"Well defined AppArmor policies may provide greater \\\n                         protection from unknown threats. WARNING: NOT \\\n                         PRODUCTION READY\"\n            },\n            {\n              \"selector\": \"containers[] .securityContext .runAsUser -gt \\\n                           10000\",\n              \"reason\": \"Run as a high-UID user to avoid conflicts with \\\n                         the host's user table\"\n            },\n            {\n              \"selector\": \".spec .serviceAccountName\",\n              \"reason\": \"Service accounts restrict Kubernetes API access \\\n                         and should be configured with least privilege\"\n            }\n          ]\n        }\n      }\n    ]\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: hello-world\n    spec:\n      serviceAccountName: default\n      containers:\n      - name: linux\n        image: hello-world:linux\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n        securityContext:\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 20000\n          capabilities:\n            drop: [\"ALL\"]\n    ```", "```\n    $ kubectl apply -f setup.yaml\n    namespace/r61 created\n    pod/backend created\n    pod/loop created\n    pod/logstash created\n    ```", "```\n    $ kubectl get pods -n r61\n    NAME       READY   STATUS    RESTARTS   AGE\n    backend    1/1     Running   0          115s\n    logstash   1/1     Running   0          115s\n    loop       1/1     Running   0          115s\n    ```", "```\n    $ kubectl describe pod backend -n r61\n    ...\n    Containers:\n      hello:\n        Container ID:   docker://eb0bdefc75e635d03b625140d1e \\\n                        b229ca2db7904e44787882147921c2bd9c365\n        Image:          bmuschko/nodejs-hello-world:1.0.0\n        ...\n    ```", "```\n    $ trivy image bmuschko/nodejs-hello-world:1.0.0\n    $ trivy image alpine:3.13.4\n    $ trivy image elastic/logstash:7.13.3\n    ```", "```\n    $ kubectl delete pod backend -n r61\n    $ kubectl delete pod logstash -n r61\n    $ kubectl delete pod loop -n r61\n    ```", "```\n    $ vagrant ssh kube-worker-1\n    ```", "```\n    $ kubectl get pod malicious -o jsonpath='{.spec.containers[0].args}'\n    ...\n    spec:\n      containers:\n      - args:\n        - /bin/sh\n        - -c\n        - while true; do echo \"attacker intrusion\" >> /etc/threat; \\\n          sleep 5; done\n    ...\n\n    ```", "```\n    $ sudo journalctl -fu falco\n    Jan 24 23:40:18 kube-worker-1 falco[8575]: 23:40:18.359740123: Error \\\n    File below /etc opened for writing (user=<NA> user_loginuid=-1 \\\n    command=sh -c while true; do echo \"attacker intrusion\" >> /etc/threat; \\\n    sleep 5; done pid=9763 parent=<NA> pcmdline=<NA> file=/etc/threat \\\n    program=sh gparent=<NA> ggparent=<NA> gggparent=<NA> \\\n    container_id=e72a6dbb63b8 image=docker.io/library/alpine)\n    ...\n    ```", "```\n    - rule: Write below etc\n      desc: an attempt to write to any file below /etc\n      condition: write_etc_common\n      output: \"File below /etc opened for writing (user=%user.name \\\n               user_loginuid=%user.loginuid command=%proc.cmdline \\\n               pid=%proc.pid parent=%proc.pname pcmdline=%proc.pcmdline \\\n               file=%fd.name program=%proc.name gparent=%proc.aname[2] \\\n               ggparent=%proc.aname[3] gggparent=%proc.aname[4] \\\n               container_id=%container.id image=%container.image.repository)\"\n      priority: ERROR\n      tags: [filesystem, mitre_persistence]\n    ```", "```\n    - rule: Write below etc\n      desc: an attempt to write to any file below /etc\n      condition: write_etc_common\n      output: \"%evt.time,%user.name,%container.id\"\n      priority: ERROR\n      tags: [filesystem, mitre_persistence]\n    ```", "```\n    $ sudo systemctl restart falco\n    $ sudo journalctl -fu falco\n    Jan 24 23:48:18 kube-worker-1 falco[17488]: 23:48:18.516903001: \\\n    Error 23:48:18.516903001,<NA>,e72a6dbb63b8\n    ...\n    ```", "```\n    file_output:\n      enabled: true\n      keep_alive: false\n      filename: /var/log/falco.log\n\n    stdout_output:\n      enabled: false\n    ```", "```\n    $ sudo tail -f /var/log/falco.log\n    00:10:30.425084165: Error 00:10:30.425084165,<NA>,e72a6dbb63b8\n    ...\n    ```", "```\n    $ exit\n    ```", "```\n    $ kubectl apply -f setup.yaml\n    pod/hash created\n    $ kubectl get pod hash\n    NAME   READY   STATUS    RESTARTS   AGE\n    hash   1/1     Running   0          27s\n    $ kubectl exec -it hash -- /bin/sh\n    / # ls /var/config/hash.txt\n    /var/config/hash.txt\n    ```", "```\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: hash\n    spec:\n      containers:\n      - name: hash\n        image: alpine:3.17.1\n        securityContext:\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: hash-vol\n          mountPath: /var/config\n        command: [\"sh\", \"-c\", \"if [ ! -d /var/config ]; then mkdir -p \\\n                  /var/config; fi; while true; do echo $RANDOM | md5sum \\\n                  | head -c 20 >> /var/config/hash.txt; sleep 20; done\"]\n      volumes:\n      - name: hash-vol\n        emptyDir: {}\n    ```", "```\n    $ vagrant ssh kube-control-plane\n    ```", "```\n    apiVersion: audit.k8s.io/v1\n    kind: Policy\n    omitStages:\n      - \"RequestReceived\"\n    rules:\n      - level: RequestResponse\n        resources:\n        - group: \"\"\n          resources: [\"pods\"]\n      - level: Metadata\n        resources:\n        - group: \"\"\n          resources: [\"secrets\", \"configmaps\"]\n      - level: Request\n        resources:\n        - group: \"\"\n          resources: [\"services\"]\n    ```", "```\n    ...\n    spec:\n      containers:\n      - command:\n        - kube-apiserver\n        - --audit-policy-file=/etc/kubernetes/audit/rules/audit-policy.yaml\n        - --audit-log-path=/var/log/kubernetes/audit/logs/apiserver.log\n        - --audit-log-maxage=5\n        ...\n        volumeMounts:\n        - mountPath: /etc/kubernetes/audit/rules/audit-policy.yaml\n          name: audit\n          readOnly: true\n        - mountPath: /var/log/kubernetes/audit/logs/\n          name: audit-log\n          readOnly: false\n      ...\n      volumes:\n      - name: audit\n        hostPath:\n          path: /etc/kubernetes/audit/rules/audit-policy.yaml\n          type: File\n      - name: audit-log\n        hostPath:\n          path: /var/log/kubernetes/audit/logs/\n          type: DirectoryOrCreate\n    ```", "```\n    $ kubectl create configmap db-user --from-literal=username=tom\n    configmap/db-user created\n    ```", "```\n    $ sudo cat /var/log/kubernetes/audit/logs/apiserver.log\n    {\"kind\":\"Event\",\"apiVersion\":\"audit.k8s.io/v1\",\"level\":\"Metadata\", \\\n    \"auditID\":\"1fbb409a-3815-4da8-8a5e-d71c728b98b1\",\"stage\": \\\n    \"ResponseComplete\",\"requestURI\":\"/api/v1/namespaces/default/configmaps? \\\n    fieldManager=kubectl-create\\u0026fieldValidation=Strict\",\"verb\": \\\n    \"create\",\"user\":{\"username\":\"kubernetes-admin\",\"groups\": \\\n    [\"system:masters\",\"system:authenticated\"]},\"sourceIPs\": \\\n    [\"192.168.56.10\"], \"userAgent\":\"kubectl/v1.24.4 (linux/amd64) \\\n    kubernetes/95ee5ab\", \"objectRef\":{\"resource\":\"configmaps\", \\\n    \"namespace\":\"default\", \"name\":\"db-user\",\"apiVersion\":\"v1\"}, \\\n    \"responseStatus\":{\"metadata\": {},\"code\":201}, \\\n    \"requestReceivedTimestamp\":\"2023-01-25T18:57:51.367219Z\", \\\n    \"stageTimestamp\":\"2023-01-25T18:57:51.372094Z\",\"annotations\": \\\n    {\"authorization.k8s.io/decision\":\"allow\", \\\n    \"authorization.k8s.io/reason\":\"\"}}\n    ```", "```\n    $ exit\n    ```"]