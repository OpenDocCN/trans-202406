<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 3. Deploying a Kubernetes Cluster" data-type="chapter" epub:type="chapter"><div class="chapter" id="deploying_kubernetes">
<h1><span class="label">Chapter 3. </span>Deploying a Kubernetes Cluster</h1>
<p>Now that you have successfully built an application container, the next step is to learn how to transform it into a complete, reliable, scalable distributed system.<a data-primary="clusters" data-secondary="deploying" data-type="indexterm" id="ix_clsdep"/> To do that, you need a working Kubernetes cluster. At this point, there are cloud-based Kubernetes services in most public clouds that make it easy to create a cluster with a few command-line instructions.<a data-primary="cloud" data-secondary="creating a Kubernetes cluster" data-type="indexterm" id="idm45664080160112"/> We highly recommend this approach if you are just getting started with Kubernetes. Even if you are ultimately planning on running Kubernetes on bare metal, it’s a good way to quickly get started with Kubernetes, learn about Kubernetes itself, and then learn how to install it on physical machines. Furthermore, managing a Kubernetes cluster is a complicated task in itself, and, for most people, it makes sense to defer this management to the cloud—especially when the management service is free in most clouds.</p>
<p>Of course, using a cloud-based solution requires paying for those cloud-based resources as well as having an active network connection to the cloud. <a data-primary="minikube" data-type="indexterm" id="idm45664080158592"/>For these reasons, local development can be more attractive, and in that case, the <code>minikube</code> tool provides an easy-to-use way to get a local Kubernetes cluster up and running in a VM on your local laptop or desktop. Though this is a nice option, <code>minikube</code> only creates a single-node cluster, which doesn’t quite demonstrate all of the aspects of a complete Kubernetes cluster. For that reason, we recommend people start with a cloud-based solution, unless it really doesn’t work for their situation. A more recent alternative is to run a Docker-in-Docker cluster, which can spin up a multinode cluster on a single machine. This project is still in beta, though, so keep in mind that you may encounter unexpected issues.</p>
<p>If you truly insist on starting on bare metal, see the <a data-type="xref" href="app01.xhtml#rpi_cluster">Appendix</a> at the end of this book for instructions for building a cluster from a collection of Raspberry Pi single-board computers. <a data-primary="kubeadm tool" data-type="indexterm" id="idm45664080155408"/>These instructions use the <code>kubeadm</code> tool and can be adapted to other machines beyond Raspberry Pis.</p>
<section data-pdf-bookmark="Installing Kubernetes on a Public Cloud Provider" data-type="sect1"><div class="sect1" id="idm45664080154096">
<h1>Installing Kubernetes on a Public Cloud Provider</h1>
<p>This chapter covers installing Kubernetes on the three major cloud providers: the Google Cloud Platform, Microsoft Azure, and Amazon Web Services.<a data-primary="clusters" data-secondary="deploying" data-tertiary="installing Kubernetes on public cloud provider" data-type="indexterm" id="ix_clsdepcld"/><a data-primary="cloud" data-secondary="installing Kubernetes on public cloud provider" data-type="indexterm" id="ix_cldinstlKub"/></p>
<p>If you choose to use a cloud provider to manage Kubernetes, you need to install only one of these options; once you have a cluster configured and ready to go, you can skip to <a data-type="xref" href="#kubectl_gs">“The Kubernetes Client”</a>, unless you would prefer to install Kubernetes elsewhere.</p>
<section data-pdf-bookmark="Installing Kubernetes with Google Kubernetes Engine" data-type="sect2"><div class="sect2" id="idm45664080148096">
<h2>Installing Kubernetes with Google Kubernetes Engine</h2>
<p>The Google Cloud Platform (GCP) offers a hosted Kubernetes-as-a-Service called Google Kubernetes Engine (GKE).<a data-primary="Google Kubernetes Engine (GKE), installing Kubernetes with" data-type="indexterm" id="idm45664080146272"/><a data-primary="Google Cloud Platform (GCP)" data-type="indexterm" id="idm45664080145520"/><a data-primary="gcloud tool, installing" data-type="indexterm" id="idm45664080144784"/> To get started with GKE, you need a Google Cloud Platform account with billing enabled and the <a href="https://oreil.ly/uuUQD"><code>gcloud</code> tool</a> installed.</p>
<p>Once you have <code>gcloud</code> installed, set a default zone:</p>
<pre data-type="programlisting">$ <strong>gcloud config set compute/zone us-west1-a</strong></pre>
<p>Then you can create a cluster:</p>
<pre data-type="programlisting">$ <strong>gcloud container clusters create kuar-cluster --num-nodes=3</strong></pre>
<p>This will take a few minutes. When the cluster is ready, you can get credentials for the cluster using:</p>
<pre data-type="programlisting">$ <strong>gcloud container clusters get-credentials kuar-cluster</strong></pre>
<p>If you run into trouble, you can find the complete instructions for creating a GKE cluster in the <a href="https://oreil.ly/HMwnD">Google Cloud Platform documentation</a>.</p>
</div></section>
<section data-pdf-bookmark="Installing Kubernetes with Azure Kubernetes Service" data-type="sect2"><div class="sect2" id="idm45664080136288">
<h2>Installing Kubernetes with Azure Kubernetes Service</h2>
<p>Microsoft Azure offers a hosted Kubernetes-as-a-Service as part of the Azure Container Service. <a data-primary="Azure Kubernetes Service" data-secondary="installing Kubernetes with" data-type="indexterm" id="idm45664080134480"/>The easiest way to get started with Azure Container Service is to use the built-in Azure Cloud Shell in the Azure portal. You can activate the shell by clicking the shell icon in the upper-right toolbar:</p>
<figure><div class="figure">
<img alt="kur3 03in01" height="38" src="assets/kur3_03in01.png" width="44"/>
<h6/>
</div></figure>
<p>The shell has the <code>az</code> tool automatically installed and configured to work with your Azure environment.</p>
<p>Alternatively, you can install the <a href="https://oreil.ly/xpLCa"><code>az</code> CLI</a> on your local machine.</p>
<p>When you have the shell up and working, you can run:</p>
<pre data-type="programlisting">$ <strong>az group create --name=kuar --location=westus</strong></pre>
<p>Once the resource group is created, you can create a cluster using:</p>
<pre data-type="programlisting">$ <strong>az aks create --resource-group=kuar --name=kuar-cluster</strong></pre>
<p>This will take a few minutes. Once the cluster is created, you can get credentials for the cluster with:</p>
<pre data-type="programlisting">$ <strong>az aks get-credentials --resource-group=kuar --name=kuar-cluster</strong></pre>
<p>If you don’t already have the <code>kubectl</code> tool installed, you can install it using:</p>
<pre data-type="programlisting">$ <strong>az aks install-cli</strong></pre>
<p>You can find complete instructions for installing Kubernetes on Azure in the
<a href="https://oreil.ly/hsLWA">Azure documentation</a>.</p>
</div></section>
<section data-pdf-bookmark="Installing Kubernetes on Amazon Web Services" data-type="sect2"><div class="sect2" id="installing-kubernetes-on-aws">
<h2>Installing Kubernetes on Amazon Web Services</h2>
<p>Amazon offers a managed Kubernetes service called Elastic Kubernetes
Service (EKS). The easiest way to create an EKS cluster is via the <a href="https://eksctl.io">open source <code>eksctl</code> command-line tool</a>.</p>
<p>Once you have <code>eksctl</code> installed and in your path, you can run the following
command to create a cluster:</p>
<pre data-type="programlisting">$ <strong>eksctl create cluster</strong></pre>
<p>For more details on installation options (such as node size and more), view
the help using this command:</p>
<pre data-type="programlisting">$ <strong>eksctl create cluster --help</strong></pre>
<p>The cluster installation includes the right configuration for the <code>kubectl</code>
command-line tool. If you don’t already have <code>kubectl</code> installed,
follow the instructions in the <a href="https://oreil.ly/rorrD">documentation</a>.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Installing Kubernetes Locally Using minikube" data-type="sect1"><div class="sect1" id="idm45664080112736">
<h1>Installing Kubernetes Locally Using minikube</h1>
<p>If you need a local development experience, or you don’t want to pay for cloud resources, you can install a simple single-node cluster using <code>minikube</code>.<a data-primary="clusters" data-secondary="deploying" data-startref="ix_clsdepcld" data-tertiary="installing Kubernetes on public cloud provider" data-type="indexterm" id="idm45664080110624"/><a data-primary="cloud" data-secondary="installing Kubernetes on public cloud provider" data-startref="ix_cldinstlKub" data-type="indexterm" id="idm45664080108976"/><a data-primary="minikube" data-secondary="installing Kubernetes locally with" data-type="indexterm" id="idm45664080107728"/><a data-primary="clusters" data-secondary="deploying" data-tertiary="installing Kubernetes locally using minikube" data-type="indexterm" id="idm45664080106768"/> Alternatively, if you have already installed Docker Desktop, it comes bundled with a single-machine installation of Kubernetes.<a data-primary="Docker Desktop" data-type="indexterm" id="idm45664080105248"/></p>
<p>While <code>minikube</code> (or Docker Desktop) is a good simulation of a Kubernetes cluster, it’s really intended for local development, learning, and experimentation. Because it only runs in a VM on a single node, it doesn’t provide the reliability of a distributed Kubernetes cluster. In addition, certain features described in this book require 
<span class="keep-together">integration</span> with a cloud provider.  These features are either not available or work in a limited way with <span class="keep-together"><code>minikube</code></span>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You need <a data-primary="hypervisors" data-secondary="prerequisite for using minikube" data-type="indexterm" id="idm45664080100992"/><a data-primary="minikube" data-secondary="hypervisor as prerequisite for" data-type="indexterm" id="idm45664080099968"/>to have a hypervisor installed on your machine to use <code>minikube</code>. For Linux and macOS, this is generally <a href="https://virtualbox.org">VirtualBox</a>. On Windows, the Hyper-V hypervisor is the default option. Make sure you install the hypervisor before using <code>minikube</code>.</p>
</div>
<p>You can find the <code>minikube</code> tool on <a href="https://oreil.ly/iHcuV">GitHub</a>. There are binaries for Linux, macOS, and Windows that you can download. Once you have the <code>minikube</code> tool installed, you can create a local cluster using:</p>
<pre data-type="programlisting">$ <strong>minikube start</strong></pre>
<p>This will create a local VM, provision Kubernetes, and create a
local <code>kubectl</code> configuration that points to that cluster.<a data-primary="kubectl tool" data-secondary="local configuration file pointing to a cluster" data-type="indexterm" id="idm45664080092880"/> As mentioned
previously, this cluster only has a single node, so while it is useful, it
has some differences with most production deployments of Kubernetes.</p>
<p>When you are done with your cluster, you can stop the VM with:</p>
<pre data-type="programlisting">$ <strong>minikube stop</strong></pre>
<p>If you want to remove the cluster, you can run:</p>
<pre data-type="programlisting">$ <strong>minikube delete</strong></pre>
</div></section>
<section data-pdf-bookmark="Running Kubernetes in Docker" data-type="sect1"><div class="sect1" id="idm45664080088528">
<h1>Running Kubernetes in Docker</h1>
<p>A different approach to running <a data-primary="Docker" data-secondary="running Kubernetes in" data-type="indexterm" id="idm45664080087200"/><a data-primary="clusters" data-secondary="deploying" data-tertiary="running Kubernetes in Docker" data-type="indexterm" id="idm45664080086224"/>a Kubernetes cluster, which has been developed more recently, uses Docker containers to simulate multiple Kubernetes nodes
instead of running everything in a virtual machine. The <a href="https://kind.sigs.k8s.io">kind project</a> provides a great experience for launching and managing test clusters in Docker. (<em>kind</em> stands for Kubernetes IN Docker.) kind is still a work in progress (pre 1.0), but is widely used by those building Kubernetes for fast and easy testing.<a data-primary="kind (Kubernetes IN Docker)" data-type="indexterm" id="idm45664080083632"/></p>
<p>Installation instructions for your platform can be found <a href="https://oreil.ly/EOgJn">at the kind site</a>. Once you get it installed, creating a cluster is as easy as:</p>
<pre data-type="programlisting">$ <strong>kind create cluster --wait 5m</strong>
$ <strong>export KUBECONFIG="$(kind get kubeconfig-path)"</strong>
$ <strong>kubectl cluster-info</strong>
$ <strong>kind delete cluster</strong></pre>
</div></section>
<section data-pdf-bookmark="The Kubernetes Client" data-type="sect1"><div class="sect1" id="kubectl_gs">
<h1>The Kubernetes Client</h1>
<p>The official <a data-primary="kubectl tool" data-type="indexterm" id="idm45664080076768"/>Kubernetes client is <code>kubectl</code>: a command-line tool for interacting with the Kubernetes API. <code>kubectl</code> can be used to manage most Kubernetes objects,
such as Pods, ReplicaSets, and Services. <code>kubectl</code> can also be used to explore and verify the overall health of the cluster.<a data-primary="clusters" data-secondary="exploring with kubectl" data-type="indexterm" id="ix_clsexpkubectl"/><a data-primary="clients" data-secondary="kubectl" data-seealso="kubectl tool" data-type="indexterm" id="idm45664080073216"/></p>
<p>We’ll use the <code>kubectl</code> tool to explore the cluster you just created.</p>
<section data-pdf-bookmark="Checking Cluster Status" data-type="sect2"><div class="sect2" id="idm45664080071136">
<h2>Checking Cluster Status</h2>
<p>The first thing you can do is check the version of the<a data-primary="kubectl tool" data-secondary="checking cluster status" data-type="indexterm" id="idm45664080069376"/><a data-primary="clusters" data-secondary="exploring with kubectl" data-tertiary="checking cluster status" data-type="indexterm" id="idm45664080068400"/><a data-primary="versioning" data-secondary="in Kubernetes" data-type="indexterm" id="idm45664080067184"/> cluster that you are
running:</p>
<pre data-type="programlisting">$ <strong>kubectl version</strong></pre>
<p>This will display two different versions: the version of the local <code>kubectl</code> tool, as well as the version of the Kubernetes API server.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Don’t worry if these versions are different. The Kubernetes tools are backward- and forward-compatible with different versions of the Kubernetes API as long as you stay within two minor versions for both the tools and the cluster and don’t try to use newer features on an older cluster. Kubernetes follows the semantic versioning specification, where the minor version is the middle number (e.g., the 18 in 1.18.2). However, you will want to make sure that you are within the supported version skew, which
is three versions. If you are not, you may run into problems.</p>
</div>
<p>Now that we’ve established that you can communicate with your Kubernetes
cluster, we’ll explore the cluster in more depth.</p>
<p>First, you can get a simple diagnostic for the cluster. <a data-primary="health checks" data-secondary="verifying health of Kubernetes cluster" data-type="indexterm" id="idm45664080062032"/>This is a good way to verify that your cluster is generally healthy:</p>
<pre data-type="programlisting">$ <strong>kubectl get componentstatuses</strong></pre>
<p>The output should look like this:</p>
<pre data-type="programlisting">NAME                 STATUS    MESSAGE              ERROR
scheduler            Healthy   ok
controller-manager   Healthy   ok
etcd-0               Healthy   {"health": "true"}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>As Kubernetes changes and improves over time, the output of the <code>kubectl</code>
command sometimes changes. Don’t worry if the output doesn’t look exactly identical to what is shown in the examples in this book.</p>
</div>
<p>You can see here the components that make up the Kubernetes cluster. <a data-primary="controller-manager" data-type="indexterm" id="idm45664080056096"/>The <code>controller-manager</code> is responsible for running various controllers that regulate behavior in the cluster; for example, ensuring that all of the replicas of a service are available and healthy.<a data-primary="scheduler" data-type="indexterm" id="idm45664080054576"/> The <code>scheduler</code> is responsible for placing different Pods onto different nodes in the cluster.<a data-primary="etcd server" data-type="indexterm" id="idm45664080053328"/> Finally, the <code>etcd</code> server is the storage for the cluster where all of the API objects are stored.</p>
</div></section>
<section data-pdf-bookmark="Listing Kubernetes Nodes" data-type="sect2"><div class="sect2" id="idm45664080070480">
<h2>Listing Kubernetes Nodes</h2>
<p>Next, you can list out all of the nodes <a data-primary="clusters" data-secondary="exploring with kubectl" data-tertiary="listing Kubernetes nodes" data-type="indexterm" id="idm45664080050544"/><a data-primary="nodes" data-secondary="listing in Kubernetes cluster" data-type="indexterm" id="idm45664080049328"/><a data-primary="kubectl tool" data-secondary="listing nodes in a cluster" data-type="indexterm" id="idm45664080048368"/>in your cluster:</p>
<pre data-type="programlisting">$ <strong>kubectl get nodes</strong>
NAME     STATUS   ROLES                  AGE     VERSION
kube0    Ready    control-plane,master   45d     v1.22.4
kube1    Ready    &lt;none&gt;                 45d     v1.22.4
kube2    Ready    &lt;none&gt;                 45d     v1.22.4
kube3    Ready    &lt;none&gt;                 45d     v1.22.4
</pre>
<p>You can see this is a four-node cluster that’s been up for 45 days. <a data-primary="control-plane nodes" data-type="indexterm" id="idm45664080045632"/><a data-primary="worker nodes" data-type="indexterm" id="idm45664080044848"/>In
Kubernetes, nodes are separated into <code>control-plane</code> nodes that contain containers like the API server, scheduler, etc., which manage the cluster, and <code>worker</code> nodes where your containers will run. Kubernetes won’t generally schedule work onto <code>control-plane</code> nodes to ensure that user workloads don’t harm the overall operation of the cluster.</p>
<p>You can use the <code>kubectl describe</code> command to get more<a data-primary="kubectl tool" data-secondary="commands" data-tertiary="describe" data-type="indexterm" id="idm45664080041600"/> information about a specific node, such as <code>kube1</code>:</p>
<pre data-type="programlisting">$ <strong>kubectl describe nodes kube1</strong></pre>
<p>First, you see basic information about the node:</p>
<pre data-type="programlisting">Name:                   kube1
Role:
Labels:                 beta.kubernetes.io/arch=arm
                        beta.kubernetes.io/os=linux
                        kubernetes.io/hostname=node-1</pre>
<p>You can see that this node is running the Linux OS on an ARM processor.</p>
<p>Next, you see information about the operation of <code>kube1</code> itself (dates
have been removed from this output for concision):</p>
<pre data-type="programlisting">Conditions:
  Type                 Status  ...   Reason                       Message
 -----                 ------        ------                       -------
  NetworkUnavailable   False   ...   FlannelIsUp                  Flannel...
  MemoryPressure       False   ...   KubeletHasSufficientMemory   kubelet...
  DiskPressure         False   ...   KubeletHasNoDiskPressure     kubelet...
  PIDPressure          False   ...   KubeletHasSufficientPID      kubelet...
  Ready                True    ...   KubeletReady                 kubelet...</pre>
<p>These statuses show that the node has sufficient disk and memory space and is reporting that it is healthy to the Kubernetes master. Next, there is information about the capacity of the machine:</p>
<pre data-type="programlisting">Capacity:
 alpha.kubernetes.io/nvidia-gpu:        0
 cpu:                                   4
 memory:                                882636Ki
 pods:                                  110
Allocatable:
 alpha.kubernetes.io/nvidia-gpu:        0
 cpu:                                   4
 memory:                                882636Ki
 pods:                                  110</pre>
<p>Then there is information about the software on the node, including the version of Docker that is running, the versions of Kubernetes and the Linux kernel, and more:</p>
<pre data-type="programlisting">System Info:
  Machine ID:                 44d8f5dd42304af6acde62d233194cc6
  System UUID:                c8ab697e-fc7e-28a2-7621-94c691120fb9
  Boot ID:                    e78d015d-81c2-4876-ba96-106a82da263e
  Kernel Version:             4.19.0-18-amd64
  OS Image:                   Debian GNU/Linux 10 (buster)
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  containerd://1.4.12
  Kubelet Version:            v1.22.4
  Kube-Proxy Version:         v1.22.4
PodCIDR:                      10.244.1.0/24
PodCIDRs:                     10.244.1.0/24</pre>
<p>Finally, there is information <a data-primary="Pods" data-secondary="currently running on a node, information about" data-type="indexterm" id="idm45664080032736"/>about the Pods that are currently running on this node:</p>
<pre data-type="programlisting">Non-terminated Pods:            (3 in total)
  Namespace   Name        CPU Requests CPU Limits Memory Requests Memory Limits
  ---------   ----        ------------ ---------- --------------- -------------
  kube-system kube-dns...  260m (6%)    0 (0%)     140Mi (16%)     220Mi (25%)
  kube-system kube-fla...  0 (0%)       0 (0%)     0 (0%)          0 (0%)
  kube-system kube-pro...  0 (0%)       0 (0%)     0 (0%)          0 (0%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.
  CPU Requests  CPU Limits      Memory Requests Memory Limits
  ------------  ----------      --------------- -------------
  260m (6%)     0 (0%)          140Mi (16%)     220Mi (25%)
No events.</pre>
<p>From this output, you can see the Pods on the node (e.g., the <code>kube-dns</code> Pod that supplies DNS services for the cluster), the CPU and memory that each Pod is requesting from the node, as well as the total resources requested.<a data-primary="CPUs" data-secondary="requested by each Pod from the node" data-type="indexterm" id="idm45664080029616"/><a data-primary="memory" data-secondary="requested by each Pod from the node" data-type="indexterm" id="idm45664080028576"/> It’s worth noting here that Kubernetes tracks both the <em>requests</em> and the upper <em>limits</em> for resources for each Pod that runs on a machine.<a data-primary="limits" data-secondary="for resources for each Pod running on a machine" data-secondary-sortas="resources" data-type="indexterm" id="idm45664080026512"/><a data-primary="requests for resources" data-type="indexterm" id="idm45664080025168"/> The difference between requests and limits is described in detail in <a data-type="xref" href="ch05.xhtml#pods">Chapter 5</a>, but in a nutshell, resources requested by a Pod are guaranteed to be present on the node, while a Pod’s limit is the maximum amount of a given resource that a Pod can consume. A Pod’s limit can be higher than its request, in which case the extra resources are supplied on a best-effort basis. They are not guaranteed to be present on the node.<a data-primary="clusters" data-secondary="exploring with kubectl" data-startref="ix_clsexpkubectl" data-type="indexterm" id="idm45664080023488"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Cluster Components" data-type="sect1"><div class="sect1" id="idm45664080051616">
<h1>Cluster Components</h1>
<p>One of the interesting aspects of Kubernetes<a data-primary="clusters" data-secondary="components" data-type="indexterm" id="ix_clscmp"/> is that many of the components that make up the Kubernetes cluster are actually deployed using Kubernetes itself. We’ll take a look at a few of these. <a data-primary="kube-system namespace" data-type="indexterm" id="idm45664080019488"/>These components use a number of the concepts that we’ll introduce in later chapters. All of these components run in the <code>kube-system</code> namespace.<sup><a data-type="noteref" href="ch03.xhtml#idm45664080018160" id="idm45664080018160-marker">1</a></sup></p>
<section data-pdf-bookmark="Kubernetes Proxy" data-type="sect2"><div class="sect2" id="idm45664080017440">
<h2>Kubernetes Proxy</h2>
<p>The Kubernetes proxy is responsible for routing network traffic to load-balanced services in the Kubernetes cluster.<a data-primary="clusters" data-secondary="components" data-tertiary="Kubernetes proxy" data-type="indexterm" id="idm45664080015664"/><a data-primary="proxy (Kubernetes)" data-seealso="kube-proxy" data-type="indexterm" id="idm45664080014416"/> To do its job, the proxy must be present on every node in the cluster. <a data-primary="DaemonSets" data-type="indexterm" id="idm45664080013344"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="get daemonSets" data-type="indexterm" id="idm45664080012672"/>Kubernetes has an API object named DaemonSet, which you will learn about in <a data-type="xref" href="ch11.xhtml#daemon_sets">Chapter 11</a>, that is used in many clusters to accomplish this. If your cluster runs the Kubernetes proxy with a DaemonSet, you can see the proxies by <span class="keep-together">running</span>:</p>
<pre data-type="programlisting">$ <strong>kubectl get daemonSets --namespace=kube-system kube-proxy</strong>
NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR
kube-proxy   5         5         5       5            5           ...   45d</pre>
<p>Depending on how your cluster is set up, the DaemonSet for the <code>kube-proxy</code>
may be named something else, or it’s possible that it won’t use a DaemonSet at
all.<a data-primary="kube-proxy" data-type="indexterm" id="idm45664080007184"/> Regardless, the <code>kube-proxy</code> container should be running on all nodes
in a cluster.</p>
</div></section>
<section data-pdf-bookmark="Kubernetes DNS" data-type="sect2"><div class="sect2" id="idm45664080005616">
<h2>Kubernetes DNS</h2>
<p>Kubernetes also runs a DNS server, which provides naming and discovery for the services that are defined in the cluster.<a data-primary="clusters" data-secondary="components" data-tertiary="Kubernetes DNS server" data-type="indexterm" id="idm45664080003792"/><a data-primary="DNS" data-secondary="Kubernetes DNS server" data-type="indexterm" id="idm45664080002544"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="get deployments" data-type="indexterm" id="idm45664080001600"/> This DNS server also runs as a replicated service on the cluster. Depending on the size of your cluster, you may see one or more DNS servers running in your cluster. The DNS service is run as a Kubernetes deployment, which manages these replicas
(this may also be named <code>coredns</code> or some other variant):</p>
<pre data-type="programlisting">$ <strong>kubectl get deployments --namespace=kube-system core-dns</strong>
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
core-dns   1         1         1            1           45d</pre>
<p>There is also a Kubernetes service <a data-primary="load balancing" data-secondary="Kubernetes service performing for DNS server" data-type="indexterm" id="idm45664079998128"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="get services" data-type="indexterm" id="idm45664079997056"/>that performs load balancing for the DNS server:</p>
<pre data-type="programlisting">$ <strong>kubectl get services --namespace=kube-system core-dns</strong>
NAME       CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE
core-dns   10.96.0.10   &lt;none&gt;  53/UDP,53/TCP   45d</pre>
<p>This shows that the DNS service for the cluster has the address 10.96.0.10. If you log in to a container in the cluster, you’ll see that this has been populated into the <em>/etc/resolv.conf</em> file for the container.</p>
</div></section>
<section data-pdf-bookmark="Kubernetes UI" data-type="sect2"><div class="sect2" id="idm45664079993248">
<h2>Kubernetes UI</h2>
<p>If you want to visualize your cluster in a graphical user interface, most
of the cloud providers integrate such a visualization into the GUI for
their cloud.<a data-primary="UI (user interface) for Kubernetes" data-type="indexterm" id="idm45664079991920"/><a data-primary="clusters" data-secondary="components" data-tertiary="Kubernetes UI" data-type="indexterm" id="idm45664079991200"/><a data-primary="GUIs (graphical user interfaces)" data-type="indexterm" id="idm45664079989984"/> If your cloud provider doesn’t provide such a UI, or you prefer an in-cluster GUI, there is a community supported GUI that you can install. See the <a href="https://oreil.ly/wKfEx">documentation</a> on how to install the dashboard for these clusters. You can also use extensions for development environments like Visual Studio Code to see the state of your cluster at a glance.<a data-primary="clusters" data-secondary="components" data-startref="ix_clscmp" data-type="indexterm" id="idm45664079988160"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45664079986528">
<h1>Summary</h1>
<p>Hopefully at this point you have a Kubernetes cluster (or three) up and running and you’ve used a few commands to explore the cluster you have created. Next, we’ll spend some more time exploring the CLI to that Kubernetes cluster and teach you how to master the <code>kubectl</code> tool. Throughout the rest of the book, you’ll be using <code>kubectl</code> and your test cluster to explore the various objects in the Kubernetes API.<a data-primary="clusters" data-secondary="deploying" data-startref="ix_clsdep" data-type="indexterm" id="idm45664079984320"/></p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="idm45664080018160"><sup><a href="ch03.xhtml#idm45664080018160-marker">1</a></sup> As you’ll learn in the next chapter, a namespace in Kubernetes is an entity for organizing Kubernetes resources. You can think of it like a folder in a filesystem.</p></div></div></section></div></body></html>