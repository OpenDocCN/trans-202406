- en: Chapter 2\. Enterprise Storage for Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To make Kubernetes storage ready for the enterprise, one must solve the problems
    of elasticity and scale to meet the velocity and volume of big data. Cloud native
    storage solutions have emerged for orchestrating pools of persistent storage that
    are *software defined*, meaning that they are abstracted away from the underlying
    hardware. Unlike software-defined storage (SDS) solutions for VM-based environments,
    cloud native software-defined storage runs natively as containers that can be
    managed by the same orchestration system that handles application containers.
    This paves the way for dynamic, elastic storage for containerized applications
    running on Kubernetes at scale. This chapter discusses Kubernetes storage concepts,
    how software-defined storage brings scale to Kubernetes, and how the CSI works
    with software-defined storage.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Storage Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes represents application entities as *primitives*, which are the basic
    Kubernetes building blocks. Primitives represent real or logical entities so that
    Kubernetes can manage them as if they were software objects. Storage is no exception.
    Kubernetes provides a number of storage primitives, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: PersistentVolume (PV)
  prefs: []
  type: TYPE_NORMAL
- en: A unit of persistent storage
  prefs: []
  type: TYPE_NORMAL
- en: PersistentVolumeClaim (PVC)
  prefs: []
  type: TYPE_NORMAL
- en: A storage request, which becomes the binding between a PV and a pod
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSet
  prefs: []
  type: TYPE_NORMAL
- en: An object that manages the identity of a set of pods
  prefs: []
  type: TYPE_NORMAL
- en: StorageClass
  prefs: []
  type: TYPE_NORMAL
- en: Describes the classes of storage the cluster offers
  prefs: []
  type: TYPE_NORMAL
- en: There are many other primitives, of course, but these four are interesting as
    we consider how to bring enterprise-ready scale to Kubernetes storage.
  prefs: []
  type: TYPE_NORMAL
- en: PersistentVolume
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A PV is an object that represents storage at a specific location. PVs provide
    the ability to keep data longer than the lifetime of the workload or pod that
    uses the volume. PVs can store a workload’s data on networked storage, on a cloud
    provider, or locally on the pod where the workload is running ([Figure 2-1](#fig_1_local_cloud_and_networked_persistentvolume_locat)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Local  cloud  and networked PersistentVolume locations](Images/csdp_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. Local, cloud, and networked PersistentVolume locations
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Kubernetes manages every PV’s lifecycle, defining the following stages:'
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning
  prefs: []
  type: TYPE_NORMAL
- en: A storage administrator creates the PV statically ahead of time, or dynamically
    using a *StorageClass*, which isa resource that provides a way for the administrator
    to describe the storage.
  prefs: []
  type: TYPE_NORMAL
- en: Binding
  prefs: []
  type: TYPE_NORMAL
- en: A PVC binds the PV to a specific container.
  prefs: []
  type: TYPE_NORMAL
- en: Use
  prefs: []
  type: TYPE_NORMAL
- en: Workloads running on the container use the PVC to access the PV.
  prefs: []
  type: TYPE_NORMAL
- en: Release
  prefs: []
  type: TYPE_NORMAL
- en: The container removes its claim to the volume by removing the PVC.
  prefs: []
  type: TYPE_NORMAL
- en: Retention
  prefs: []
  type: TYPE_NORMAL
- en: While the data is needed, the PV retains it, even across container and pod lifecycles.
  prefs: []
  type: TYPE_NORMAL
- en: Deletion and reclamation
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes deletes the data when it is no longer needed, reclaiming the storage
    space for use by other volumes.
  prefs: []
  type: TYPE_NORMAL
- en: The storage administrator can provision PVs dynamically as needed, or ahead
    of time based on predicted storage needs. PVs define additional details about
    the data, including lifecycle policy, routes, IP addresses, and credentials.
  prefs: []
  type: TYPE_NORMAL
- en: PersistentVolumeClaim
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A PVC is both a request for storage and an identifier that establishes a claim
    on the storage once it’s granted. PVs on their own are not owned by specific applications
    or projects. A PVC requests access to a PV using one of the following access modes:'
  prefs: []
  type: TYPE_NORMAL
- en: ReadWriteOnce (RWO)
  prefs: []
  type: TYPE_NORMAL
- en: Read-write access by all pods on a single node
  prefs: []
  type: TYPE_NORMAL
- en: ReadOnlyMany (ROX)
  prefs: []
  type: TYPE_NORMAL
- en: Read-only access by multiple nodes
  prefs: []
  type: TYPE_NORMAL
- en: ReadWriteMany (RWX)
  prefs: []
  type: TYPE_NORMAL
- en: Read-write access by multiple nodes
  prefs: []
  type: TYPE_NORMAL
- en: ReadWriteOncePod (RWOP)
  prefs: []
  type: TYPE_NORMAL
- en: Read-write access by a single pod only
  prefs: []
  type: TYPE_NORMAL
- en: 'PVs and PVCs work together as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: An application developer creates one or more PVCs describing the storage resources
    the application needs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The storage administrator can either create PVs explicitly in response, or create
    a StorageClass that can dynamically provision new PVs as needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes manages the binding of PVCs to PVs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Together, PVs and PVCs provide a way for pods to define requests based on the
    storage requirements of their containers and applications. The storage administrator
    can either configure dynamic *provisioners* that allocate storage and a PV in
    response to these requests, or create PVs in anticipation of an application’s
    storage needs. When the storage is granted, the cluster finds the PV associated
    with the PVC and mounts it for the pod. In other words, the pod uses the PVC as
    a volume. The PV is exclusively available to the pod as long as it’s needed.
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A StatefulSet is the primitive that manages the deployment and scaling of a
    set of pods, maintaining a unique ID for each pod so that it can be identified
    for the purposes of persistent data or networking, or when the pod migrates to
    a different node. By providing unique, persistent IDs for pods, the StatefulSet
    API lets administrators manage the deployment and scaling of a set of pods. When
    individual pods fail, the persistent IDs help restore connections between their
    replacements and the existing volumes that serve them.
  prefs: []
  type: TYPE_NORMAL
- en: StorageClass
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The StorageClass primitive lets the cluster administrator describe the different
    classes of storage the cluster offers. Storage classes can indicate different
    policies or levels of service. For example, the administrator might set up different
    StorageClass objects to represent different backup policies. Users can request
    a specific storage class by name.
  prefs: []
  type: TYPE_NORMAL
- en: Software-Defined Storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just as containerized application architecture decouples application logic from
    the hardware where the code runs, software-defined storage decouples persistent
    data and storage policies from storage media. SDS is distributed and hardware
    agnostic, and can run in a variety of environments including the cloud. By abstracting
    storage from its hardware, SDS enables the presentation of hardware capacity to
    applications, users, and other clients as a unified storage pool. SDS makes a
    storage administrator’s job easier immediately by making it possible to manage
    a diverse assortment of different storage types consistently without worrying
    about the different characteristics of each type of storage ([Figure 2-2](#fig_2_software_defined_storage)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Software defined storage](Images/csdp_0202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. Software-defined storage
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Just as Kubernetes brings elasticity, scale, and high availability to compute
    resources, SDS is the foundation for bringing these important characteristics
    to storage. Because the storage is abstracted, it’s possible to build systems
    that distribute and scale storage in different environments, integrating them
    with Kubernetes or other orchestration systems and building in fault tolerance
    and high availability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantages for the enterprise are clear:'
  prefs: []
  type: TYPE_NORMAL
- en: Developers and users don’t need to think about storage hardware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scale becomes a matter of on-demand provisioning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data can be placed anywhere it is needed, regardless of the environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because SDS presents all available physical storage as a shared pool, the resources
    can be allocated efficiently, reducing wasted storage space.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting SDS to Kubernetes with the CSI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CSI is an interface between containerized workloads and a third-party storage
    layer, making it possible for cloud native applications to create, manage, and
    use storage outside of Kubernetes. The CSI makes storage available in a pool that
    all instances of each application can access, keeping instances in sync and making
    it possible to back up applications consistently. The CSI provides abstracted
    access to Kubernetes over an interface, meaning that third parties can create
    plug-ins for accessing storage systems from Kubernetes without touching the core
    Kubernetes code. Using the CSI, containerized applications can use the normal
    Kubernetes storage primitives on top of these storage systems ([Figure 2-3](#fig_3_connecting_software_defined_storage_to_kubernetes)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Connecting software defined storage to Kubernetes with the CSI](Images/csdp_0203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3\. Connecting software-defined storage to Kubernetes with the container
    storage interface
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The CSI gives storage vendors the freedom to design and manage storage as they
    see fit, providing Kubernetes and other orchestration platforms the freedom to
    provision and manage storage transparently using native abstractions. At the time
    of this writing, Kubernetes and the CSI don’t know how to provide application-aware
    backups, high availability, or other functions necessary for the enterprise, but
    the CSI makes it possible to add these capabilities at the storage layer itself.
    This is where SDS comes in.
  prefs: []
  type: TYPE_NORMAL
- en: Software-designed storage is not limited by hardware or standards, meaning that
    any required capabilities can be implemented and abstracted away from the underlying
    mechanics. For this reason, it doesn’t matter that the CSI is a slow-moving standard,
    as standards should be. By connecting SDS to Kubernetes, the CSI makes it possible
    to build Kubernetes-ready storage that is granular at the container level, self-healing,
    and topology aware, without requiring Kubernetes itself to have these capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud Native Storage: Bringing Scale to Kubernetes Storage'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adapting traditional SDS for containerized workloads is challenging for a number
    of reasons.
  prefs: []
  type: TYPE_NORMAL
- en: First, because containers are dynamic and ephemeral, they require storage that
    can be provisioned, attached, and deleted instantly, whenever and wherever it
    is needed. For high availability, it must be possible to create and move volumes
    as needed, with awareness of topology, and to back them up regularly and automatically.
    Manual storage provisioning can’t keep up with these needs at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Second, the number of volumes that physical and virtual servers can support
    is often insufficient for the number of pods or containers that need storage.
    A single host might run hundreds of small containers, requiring more volumes than
    the OS can provide.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, because the point of containers is to be infrastructure agnostic, they
    should not care about the physical storage they’re using. Different environments
    provide different types of storage, often multiple types within a single deployment.
    It must be possible to move data between storage pools without affecting the way
    containerized applications run.
  prefs: []
  type: TYPE_NORMAL
- en: Enter cloud native storage, a new model of SDS designed for distributed, containerized
    applications. Cloud native storage runs in containers on the cluster, meaning
    it can be provisioned and orchestrated, offering data locality and Kubernetes-integrated
    features like [Stork (Storage Operator Runtime for Kubernetes)](https://github.com/libopenstorage/stork)
    to provide storage-aware scheduling. [Figure 2-4](#fig_4_cloud_native_storage)
    shows how cloud native storage becomes part of Kubernetes itself.
  prefs: []
  type: TYPE_NORMAL
- en: '![Cloud native storage](Images/csdp_0204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4\. Cloud native storage
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Cloud native storage must be container aware, and all operations must take place
    at the level of the application. Snapshots, backups, compression, encryption,
    and other operations are not relevant to the cluster or the storage pool as a
    whole, but to the container itself. This key aspect gives operational control
    over data to the application owner, relieving IT admins of the responsibility
    for provisioning storage and protecting application data.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, redefining storage for Kubernetes at scale requires rethinking the
    nature of storage itself. To meet the needs of containerized applications at scale,
    a storage paradigm must be elastic, nimble, able to serve multiple replicas of
    data to multiple instances of application services concurrently, and decoupled
    from the application logic itself. In other words, to bring scale to Kubernetes
    data, storage must be cloud native, which means it must be both software defined
    and containerized.
  prefs: []
  type: TYPE_NORMAL
