<html><head></head><body><section data-pdf-bookmark="Chapter 6. Server Metrics" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch06">&#13;
<h1><span class="label">Chapter 6. </span>Server Metrics</h1>&#13;
&#13;
&#13;
<p>MySQL <a data-primary="server metrics" data-type="indexterm" id="server-metrics"/>metrics are closely related to MySQL performance—that’s obvious.&#13;
After all, the purpose of metrics in any system is to measure and report how the system is operating.&#13;
What’s not obvious is how they are related.&#13;
It’s not unreasonable if you currently see MySQL metrics as depicted in <a data-type="xref" href="#mysql-metrics-blackbox">Figure 6-1</a>: MySQL is a black box with metrics inside that, in some way, indicate something about MySQL.</p>&#13;
&#13;
<figure><div class="figure" id="mysql-metrics-blackbox">&#13;
<img alt="emsp 0601" src="assets/emsp_0601.png"/>&#13;
<h6><span class="label">Figure 6-1. </span>MySQL as a black box: metrics are not revealing</h6>&#13;
</div></figure>&#13;
&#13;
<p>That view is not unreasonable (or uncommon) because MySQL metrics are often discussed but never taught.&#13;
Even in my career with MySQL, I have never read or heard an exposition of MySQL metrics—and I have worked with people who created them.&#13;
The lack of pedagogy for MySQL metrics is due to a false presumption that metrics do not require understanding or interpretation because their meaning is self-evident.&#13;
That presumption has a semblance of truth when considering a single metric in isolation, such as <code>Threads_running</code>; it’s the number of threads running—what more is there to know?&#13;
But isolation is the fallacy: MySQL performance is revealed through a spectrum of MySQL metrics.</p>&#13;
&#13;
<p class="pagebreak-before">Think of MySQL as a <a data-primary="prism, MySQL as a" data-type="indexterm" id="idm45829111196112"/>prism.&#13;
The application figuratively shines a workload into MySQL.&#13;
That workload physically interacts with MySQL and the hardware on which it runs.&#13;
Metrics are the spectrum revealed by the figurative refraction of the workload through MySQL, as depicted in <a data-type="xref" href="#mysql-metrics-prism">Figure 6-2</a>.</p>&#13;
&#13;
<figure><div class="figure" id="mysql-metrics-prism">&#13;
<img alt="emsp 0602" src="assets/emsp_0602.png"/>&#13;
<h6><span class="label">Figure 6-2. </span>MySQL as a prism: metrics reveal workload performance</h6>&#13;
</div></figure>&#13;
&#13;
<p>In the physical sciences, this technique is <a data-primary="spectrometry" data-type="indexterm" id="idm45829111191664"/>called <em>spectrometry</em>: understanding matter through its interaction with light.&#13;
For MySQL, this is more than a clever analogy, it’s the actual relationship between MySQL metrics and MySQL server performance, and there are two proofs:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>When you shine a light through a real prism, the resulting color spectrum reveals properties of the light, not the prism. Likewise, when you run a workload on MySQL, the resulting metrics reveal properties of the workload, not MySQL.</p>&#13;
</li>&#13;
<li>&#13;
<p>Given previous chapters—especially <a data-type="xref" href="ch04.html#mysql-does-nothing">“MySQL Does Nothing”</a>—performance is directly attributable to workload: queries, data, and access patterns. Without a workload, all metric values are zero (generally speaking).</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Viewed this way, MySQL metrics can be taught in a new light, and that is the focus of this chapter.</p>&#13;
&#13;
<p>This analogy has another pedagogical utility: it separates MySQL metrics into <em>spectra</em> (the plural of <em>spectrum</em>).&#13;
This is very useful because MySQL metrics are vast and unorganized (several hundred metrics strewn throughout MySQL), but effective teaching requires focus and organization.&#13;
As a result, the <a data-type="xref" data-xrefstyle="select:nopage" href="#spectra">“Spectra”</a> section, which illuminates over 70 metrics divided into 11 spectra, makes up the bulk of this chapter.</p>&#13;
&#13;
<p>A final note before we shine a light on MySQL: only a fraction of metrics are essential for understanding and analyzing MySQL server performance.&#13;
The relevance and importance of the remaining metrics varies widely:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Some are noise</p>&#13;
</li>&#13;
<li>&#13;
<p>Some are historical</p>&#13;
</li>&#13;
<li>&#13;
<p>Some are disabled by default</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<ul class="pagebreak-before less_space">&#13;
<li>&#13;
<p>Some are very technically specific</p>&#13;
</li>&#13;
<li>&#13;
<p>Some are only useful in specific cases</p>&#13;
</li>&#13;
<li>&#13;
<p>Some are informational, not proper metrics</p>&#13;
</li>&#13;
<li>&#13;
<p>Some are inscrutable by feeble mortal creatures</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>This chapter analyzes the spectra of MySQL metrics that are essential for understanding how the workload interacts with and affects MySQL server performance.&#13;
There are six major sections.&#13;
The first draws a distinction between query performance and server performance.&#13;
Previous chapters focus on the former, but this chapter focuses on the latter.&#13;
The second is boring—you’ll see why.&#13;
The third lists key performance indicators (KPIs) that quickly gauge MySQL performance.&#13;
The fourth explores the field of metrics: a model to more deeply understand how metrics describe and relate to MySQL server performance.&#13;
The fifth presents the spectra of MySQL metrics: over 70 MySQL metrics organized into 11 spectra—an epic and exciting journey that tours the inner workings of MySQL, after which you will see MySQL in a new light.&#13;
The sixth addresses important topics related to monitoring and alerting.<a data-primary="server metrics" data-startref="server-metrics" data-type="indexterm" id="idm45829111173840"/></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Query Performance Versus Server Performance" data-type="sect1"><div class="sect1" id="idm45829111172736">&#13;
<h1>Query Performance Versus Server Performance</h1>&#13;
&#13;
<p>MySQL performance <a data-primary="server performance" data-type="indexterm" id="server-performance-ch6"/>has two sides: query performance and server performance.&#13;
Previous chapters address <em>query performance</em>: improving response time by optimizing the workload.&#13;
This chapter addresses <em>server performance</em>: analyzing the performance of MySQL as a function of executing the workload.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>In this chapter, <em>MySQL performance</em> means <em>server performance</em>.</p>&#13;
</div>&#13;
&#13;
<p>In simplest terms, the workload is input and server performance is output, as shown in <a data-type="xref" href="#query-and-server-perf">Figure 6-3</a>.</p>&#13;
&#13;
<p>If you put an optimized workload into MySQL, you get high performance out of MySQL.&#13;
Server performance is almost always an issue with the workload, not MySQL.&#13;
Why?&#13;
Because MySQL is incredibly good at executing a variety of workloads.&#13;
MySQL is a mature, highly optimized data store—<em>decades</em> of tuning by world-class database experts.&#13;
That’s why the first five chapters of this book extol query performance, and only one chapter (this one) analyzes server performance.</p>&#13;
&#13;
<figure><div class="figure" id="query-and-server-perf">&#13;
<img alt="emsp 0603" src="assets/emsp_0603.png"/>&#13;
<h6><span class="label">Figure 6-3. </span>Query and server performance</h6>&#13;
</div></figure>&#13;
&#13;
<p>There are three reasons to analyze server performance:</p>&#13;
<dl>&#13;
<dt>Concurrency and contention</dt>&#13;
<dd>&#13;
<p>Concurrency <a data-primary="concurrency" data-type="indexterm" id="idm45829111160304"/>leads to contention that reduces query performance.&#13;
A query executed in isolation exhibits different performance when executed with other queries.&#13;
Recall the Universal Scalability Law in <a data-type="xref" href="ch04.html#usl">Equation 4-1</a>: contention (<code>α</code>) <a data-primary="contention" data-type="indexterm" id="idm45829111158016"/>is in the divisor of the equation, which means it reduces throughput as load increases.&#13;
Unless you’re living in a different universe than the rest of us, concurrency and contention are unavoidable.</p>&#13;
&#13;
<p>Analyzing server performance is most useful and most commonly undertaken to see how MySQL handles the workload when all queries (concurrency) are competing for shared and limited system resources (contention).&#13;
Certain workloads have very little—if any—contention, while other workloads kill performance—both query and server performance—despite the best efforts of MySQL.&#13;
The access pattern trait <a data-type="xref" href="ch04.html#ap-concurrency">“Concurrency”</a> is, unsurprisingly, a major factor in contention, but all the access pattern traits are important, too.&#13;
Analyzing server performance reveals how well the queries in the workload play together.&#13;
As engineers responsible for those queries, we need to ensure that they play well.</p>&#13;
</dd>&#13;
<dt>Tuning</dt>&#13;
<dd>&#13;
<p>Server <a data-primary="tuning MySQL" data-type="indexterm" id="idm45829111153744"/>performance is directly <em>but not entirely</em> attributable to workload.&#13;
There are three additional factors in server performance: MySQL, operating system, and hardware.&#13;
In query performance, it’s presumed that MySQL, operating system, and hardware are properly configured and adequate for the workload.&#13;
Problems (like faulty hardware) and bugs notwithstanding, these three affect performance far less than the workload because we’re living in an age of abundance: MySQL is very mature and highly optimized, operating systems are advanced and sophisticated, and hardware is fast and affordable.</p>&#13;
&#13;
<p>Matters discussed in <a data-type="xref" href="ch02.html#mysql-tuning">“MySQL Tuning”</a> still hold true: tuning MySQL is akin to squeezing blood from a turnip.&#13;
You most likely never need to tune MySQL.&#13;
But if you do, it requires analyzing server performance with a known and stable workload; otherwise, you cannot be certain that any performance gains are the result of tuning—it’s basic science: controls, variables, reproducibility, and falsifiability.</p>&#13;
</dd>&#13;
<dt>Performance regressions</dt>&#13;
<dd>&#13;
<p>I <a data-primary="performance regressions" data-type="indexterm" id="idm45829111148928"/>praise MySQL throughout this book, but I would be remiss if I did not, at least once, clearly state: sometimes, MySQL is wrong.&#13;
But MySQL did not become the most popular open source relational database in the world by being wrong. It is usually correct, and suspecting a performance regression (or bug) is the last resort of experts after ensuring that query performance, MySQL tuning, and faulty hardware are not the problem.</p>&#13;
&#13;
<p>The blog posts <a href="https://oreil.ly/MuRIt">“Checkpointing in MySQL and MariaDB”</a> and <a href="https://oreil.ly/NDQkP">“More on Checkpoints in InnoDB MySQL 8”</a> by renowned MySQL expert Vadim Tkachenko <a data-primary="Tkachenko, Vadim" data-type="indexterm" id="idm45829111145632"/>contain perfect examples of analyzing server performance to reveal a performance regression. It’s normal for Vadim to be doing this type of work; the rest of us plod through much simpler problems, like indexing and whether or not to have a third cup of coffee before lunch.</p>&#13;
</dd>&#13;
</dl>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45829111144288">&#13;
<h5>Flawed Optics</h5>&#13;
<p>Tuning and performance regressions are an exception to the analogy of MySQL as a <a data-primary="prism, MySQL as a" data-type="indexterm" id="idm45829111142992"/>prism (<a data-type="xref" href="#mysql-metrics-prism">Figure 6-2</a>) that only reveals properties of the workload, not MySQL.&#13;
A known and stable workload is analogous to shining a pure blue light through a prism: presuming the input is correct, an incorrect output reveals something about the prism.</p>&#13;
</div></aside>&#13;
&#13;
<p>Concurrency and contention are the implicit focus of this chapter because they are the responsibility of the engineers who maintain the application that executes the queries.&#13;
Tuning and performance regressions are the responsibility of MySQL DBAs and experts.&#13;
Learning to analyze server performance for the former (concurrency and contention) is excellent training for the latter because the difference is primarily a matter of focus.&#13;
I hope the former sparks an interests in the latter because the MySQL industry needs more DBAs and experts.<a data-primary="server performance" data-startref="server-performance-ch6" data-type="indexterm" id="idm45829111140000"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Normal and Stable: The Best Database Is a Boring Database" data-type="sect1"><div class="sect1" id="normal-and-stable">&#13;
<h1>Normal and Stable: The Best Database <span class="keep-together">Is a Boring Database</span></h1>&#13;
&#13;
<p>For the <a data-primary="server metrics" data-secondary="normal and stable" data-type="indexterm" id="idm45829111136752"/>most part, <em>normal</em> and <em>stable</em> are <a data-primary="boring database" data-type="indexterm" id="idm45829111134752"/>intuitively understood by engineers once they become familiar with the application and how its workload runs on MySQL.&#13;
Humans are good at pattern recognition, so it’s easy to see when the charts for any metric are unusual.&#13;
Therefore, I won’t belabor terminology that is generally well understood, but I need to make two clarifying points to ensure that we’re on the same page, and to address the rare times when engineers ask “What is normal?” with respect to MySQL performance:</p>&#13;
<dl>&#13;
<dt>Normal</dt>&#13;
<dd>&#13;
<p>Every application, workload, MySQL configuration, and environment are different.&#13;
Therefore, normal is whatever performance MySQL exhibits for your application on a typical day when everything is working properly.&#13;
That normal—your normal—is the baseline for determining if some aspect of performance is higher or lower, faster or slower, better or worse than normal.&#13;
It’s as simple as that.</p>&#13;
&#13;
<p>When I state a presumptive norm like “It’s normal for <code>Threads_running</code> to be less than 50,” it’s only an abbreviation of language, short for “A stable value for <code>Threads_running</code> is less than 50 given my experience, and given that current hardware typically has less than 48 CPU cores, and given that benchmarks show that MySQL performance does not currently scale well past 64 running threads.”&#13;
But if 60 threads running is normal and stable for your application, then great: you have achieved extraordinary performance.</p>&#13;
</dd>&#13;
<dt>Stable</dt>&#13;
<dd>&#13;
<p>Don’t lose sight of stable performance in your quest for greater performance.&#13;
<a data-type="xref" href="ch04.html#perf-at-the-limit">“Performance Destabilizes at the Limit”</a> illustrates and explains why squeezing maximum performance from MySQL is not the goal: at the limit, performance destabilizes, and then you have bigger problems than performance.&#13;
Stability does not limit performance; it ensures that performance—at any level—is sustainable, because that’s what we really want: MySQL fast all the time, not sometimes.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>At times, MySQL performance is glamorous—the highs, the lows, the screaming fans and packed stadiums—but the real art is optimizing the database into pristine boredom: all queries respond quickly, all metrics are stable and normal, and all users are happy.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Key Performance Indicators" data-type="sect1"><div class="sect1" id="kpi">&#13;
<h1>Key Performance Indicators</h1>&#13;
&#13;
<p>Four metrics quickly <a data-primary="server metrics" data-secondary="key performance indicators (KPIs)" data-type="indexterm" id="key-performance-indicators_index1"/><a data-primary="key performance indicators (KPIs)" data-type="indexterm" id="key-performance-indicators_index2"/>gauge MySQL performance:</p>&#13;
<dl>&#13;
<dt>Response time</dt>&#13;
<dd>&#13;
<p>Response time <a data-primary="response time" data-type="indexterm" id="idm45829111119760"/>is no surprise: as noted in <a data-type="xref" href="ch01.html#north-star">“North Star”</a>, it’s the only metric anyone truly cares about.&#13;
Even if response time is great, you must factor in other KPIs.&#13;
For example, if every query fails with an error, response time might be amazing (near zero), but that’s not normal.&#13;
The goal is normal and stable response time, and lower is better.</p>&#13;
</dd>&#13;
<dt>Errors</dt>&#13;
<dd>&#13;
<p>Errors <a data-primary="errors" data-type="indexterm" id="idm45829111116496"/>is the rate of errors.&#13;
Which errors?&#13;
At least query errors, but ideally all errors: query, connection, client, and server.&#13;
Don’t expect a zero error rate because, for example, there’s nothing you, the application, or MySQL can do if a client aborts a connection.&#13;
The goal is a normal and stable error rate, and lower (near zero) is better.</p>&#13;
</dd>&#13;
<dt>QPS</dt>&#13;
<dd>&#13;
<p>Queries per second <a data-primary="queries per second" data-type="indexterm" id="idm45829111114000"/>is also no surprise: executing queries is the main purpose and work of MySQL.&#13;
QPS indicates performance, but it does not equal performance.&#13;
Abnormally high QPS, for example, can signal problems.&#13;
The goal is normal and stable QPS, and the value is arbitrary.</p>&#13;
</dd>&#13;
<dt>Threads running</dt>&#13;
<dd>&#13;
<p>Threads running <a data-primary="threads running" data-type="indexterm" id="idm45829111111584"/>gauges how hard MySQL is working to achieve QPS.&#13;
One thread executes one query, so you must consider both metrics because they’re closely related.&#13;
The goal is normal and stable threads running; lower is better.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>I expound these metrics in <a data-type="xref" href="#spectra">“Spectra”</a>.&#13;
Here, the point is that these four metrics are the KPIs for MySQL: when the values for all four are normal, MySQL performance is practically guaranteed also to be normal.&#13;
Always monitor response time, errors, QPS, and threads running.&#13;
Whether or not to alert on them is discussed later in <a data-type="xref" href="#alert-on">“Alert on User Experience and Objective Limits”</a>.</p>&#13;
&#13;
<p>Simplifying the performance of a complex system to a handful of metrics is not unique to MySQL or computers.&#13;
For example, you have vital signs (I hope): height, weight, age, blood pressure, and heart rate.&#13;
Five biological metrics succinctly and accurately gauge your health.&#13;
Likewise, four MySQL metrics succinctly and accurately gauge server performance.&#13;
That’s nifty, but what’s really insightful is the field of metrics in which all metrics are situated.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45829111107024">&#13;
<h5>Four Golden Signals, et al.</h5>&#13;
<p>KPIs are not a new concept.&#13;
In 2016, <em>Site Reliability Engineering</em> (O’Reilly) by Betsy Beyer et al. made the term and concept of <em>golden signals</em> a mainstay of engineering: latency, traffic, errors, and saturation.&#13;
Renowned system performance expert Brendan Gregg created a similar methodology, <a href="https://oreil.ly/mZ5SV"><em>The USE Method</em></a>, with signals on usage, saturations, and errors.&#13;
Tom Wilkie at Weaveworks created another methodology, <a href="https://oreil.ly/1fD6B">“The RED Method: Key Metrics for Microservices Architecture”</a>, with signals on rate, errors, and duration.&#13;
The terms vary, but the concept is the <a data-primary="server metrics" data-secondary="key performance indicators (KPIs)" data-startref="key-performance-indicators_index1" data-type="indexterm" id="idm45829111102816"/><a data-primary="key performance indicators (KPIs)" data-startref="key-performance-indicators_index2" data-type="indexterm" id="idm45829111101440"/>same.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Field of Metrics" data-type="sect1"><div class="sect1" id="field-of-metrics-toc">&#13;
<h1>Field of Metrics</h1>&#13;
&#13;
<p>Every MySQL metric <a data-primary="server metrics" data-secondary="field of metrics" data-type="indexterm" id="field-of-metrics_index1"/><a data-primary="field of metrics" data-type="indexterm" id="field-of-metrics_index2"/>belongs to one of six classes shown as boxes in <a data-type="xref" href="#field-of-metrics">Figure 6-4</a>.&#13;
Collectively, I call it the <em>field of metrics</em>.</p>&#13;
&#13;
<figure><div class="figure" id="field-of-metrics">&#13;
<img alt="emsp 0604" src="assets/emsp_0604.png"/>&#13;
<h6><span class="label">Figure 6-4. </span>Field of metrics</h6>&#13;
</div></figure>&#13;
&#13;
<p>MySQL performance cannot be fully understood by analyzing metrics in isolation because performance is not an isolated property.&#13;
Performance is the result of many factors for which there are many related metrics.&#13;
The field of metrics is a model to understand how metrics are related.&#13;
The relationships connect the proverbial dots (the metrics) to complete the intricate picture that is MySQL performance.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Response Time" data-type="sect2"><div class="sect2" id="field-response-time">&#13;
<h2>Response Time</h2>&#13;
&#13;
<p>Response time <a data-primary="response time metrics" data-type="indexterm" id="response-time-metrics"/>metrics indicate <em>how long</em> MySQL takes to respond.&#13;
They are top level in the field because they encompass (or hide) details from lower levels.</p>&#13;
&#13;
<p>Query response time is, of course, the most important one and the only one commonly monitored.&#13;
MySQL executes statements in stages, and stages can be timed.&#13;
These are response time metrics, too, but they measure around query execution, not within it.&#13;
Actual query execution is just one stage of many.&#13;
If you recall <a data-type="xref" href="ch01.html#update-stages">Example 1-3</a> in <a data-type="xref" href="ch01.html#ch01">Chapter 1</a>, executing the actual <code>UPDATE</code> of an <code>UPDATE</code> statement was only 1 of 15 stages.&#13;
Consequently, stage response times are mostly used by MySQL experts to investigate deep server performance issues.</p>&#13;
&#13;
<p>Response time metrics are important but also completely opaque: what was MySQL doing that accounts for the time?&#13;
To answer that, we must dig deeper into the field.<a data-primary="response time metrics" data-startref="response-time-metrics" data-type="indexterm" id="idm45829111084304"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Rate" data-type="sect2"><div class="sect2" id="field-rate">&#13;
<h2>Rate</h2>&#13;
&#13;
<p>Rate metrics <a data-primary="rate metrics" data-type="indexterm" id="idm45829111081392"/>indicate <em>how fast</em> MySQL completes a discrete task.&#13;
Queries per second (QPS) is the ubiquitous and universally known database rate metric.&#13;
Most MySQL metrics are rates because—no surprise—MySQL does many discrete tasks.</p>&#13;
&#13;
<p>When a rate increases, it can increase related utilizations.&#13;
Some rates are innocuous and don’t increase utilization, but the important and commonly monitored rates do increase utilization.</p>&#13;
&#13;
<p>The rate-utilization relationship presumes no other changes.&#13;
That means you can increase a rate without increasing utilization only if you change something about the rate or the utilization that it affects.&#13;
It’s usually easier to change the rate rather than the utilization because the rate is the cause in the relationship.&#13;
For example, when QPS increases across the board, CPU utilization could increase because more queries require more CPU time.&#13;
(Increasing QPS could increase other utilizations; CPU is just one example.)&#13;
To avoid or reduce the increase in CPU utilization, you should optimize the queries so they require less CPU time to execute.&#13;
Or, you could increase the number of CPU cores by scaling up the hardware, but <a data-type="xref" href="ch02.html#better-faster-hardware">“Better, Faster Hardware!”</a> and <a data-type="xref" href="ch04.html#better-faster-hardware-again">“Better, Faster Hardware?”</a> address the shortcomings of this approach.</p>&#13;
&#13;
<p>The rate-utilization relationship is not a novel insight—you probably already knew it—but it’s important to highlight because it’s the beginning of a series of relationships that unify the field.&#13;
Don’t feel sorry for utilization: it pushes back.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Utilization" data-type="sect2"><div class="sect2" id="field-util">&#13;
<h2>Utilization</h2>&#13;
&#13;
<p>Utilization metrics <a data-primary="utilization metrics" data-type="indexterm" id="utilization-metrics"/>indicate <em>how much</em> MySQL uses a finite resource.&#13;
Utilization metrics are everywhere in computers: CPU usage, memory usage, disk usage, and so on.&#13;
Since computers are finite machines, almost everything can be expressed as a utilization because nothing has infinite capacity—not even the cloud.</p>&#13;
&#13;
<p><em>Bounded rates</em> <a data-primary="bounded rates" data-type="indexterm" id="idm45829111071296"/>can be expressed as a utilization.&#13;
A rate is bounded if there is a maximum rate.&#13;
Disk I/O, for example, is usually expressed as a rate (IOPS), but every storage device has a maximum rate.&#13;
Therefore, disk I/O utilization is the current rate over the maximum rate.&#13;
By <a data-primary="unbounded rates" data-type="indexterm" id="idm45829111070144"/>contrast, <em>unbounded rates</em> cannot be expressed as a utilization because there’s no maximum rate: QPS, bytes sent and received, and so forth.</p>&#13;
&#13;
<p>When a utilization increases, it can decrease related rates.&#13;
I bet you’ve seen or experienced something like this before: a rogue query causes 100% disk I/O utilization, which causes QPS to drop precipitously, which causes an outage.&#13;
Or, MySQL uses 100% of memory and is killed by the operating system kernel, which causes the ultimate rate decrease: to zero.&#13;
This relationship is an expression of the USL (recall <a data-type="xref" href="ch04.html#usl">Equation 4-1</a>) because utilization increases contention (<code>α</code>) and coherency (<code>β</code>), which are in the divisor of the equation.</p>&#13;
&#13;
<p>What happens at <em>or near</em> 100% utilization?&#13;
MySQL waits.&#13;
In <a data-type="xref" href="#field-of-metrics">Figure 6-4</a>, this is indicated by the arrow between <em>Utilization</em> and <em>Wait</em>—the utilization-wait relationship.&#13;
The arrow is labeled <em>Stall</em> because query execution waits, then resumes—perhaps many times.&#13;
I emphasize <em>or near</em> because, as discussed in <a data-type="xref" href="ch04.html#perf-at-the-limit">“Performance Destabilizes at the Limit”</a>, stalls can occur before 100% utilization.</p>&#13;
&#13;
<p>Stalls are anti-stable but unavoidable for two reasons: MySQL load is usually greater than hardware capacity; and latency is inherent in all systems, especially hardware.&#13;
The first reason can be ameliorated by reducing load (optimizing the workload) or increasing hardware capacity.&#13;
The second reason is difficult to address but not impossible.&#13;
If, for example, you still use spinning disks, upgrading to NVMe storage will dramatically reduce storage latency.<a data-primary="utilization metrics" data-startref="utilization-metrics" data-type="indexterm" id="idm45829111060864"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Wait" data-type="sect2"><div class="sect2" id="field-wait">&#13;
<h2>Wait</h2>&#13;
&#13;
<p>Wait <a data-primary="waits" data-secondary="field of metrics" data-type="indexterm" id="waits-field-of-metrics-ch6"/>metrics indicate idle time during query execution.&#13;
Waits occur when query execution stalls due to contention and coherency.&#13;
(Waits also occur due to MySQL bugs or performance regressions, but these are exceedingly rare enough not to raise concern.)</p>&#13;
&#13;
<p>Wait metrics are calculated as rates or response times (depending on the metric), but they merit a separate class because they reveal when MySQL is <em>not working</em> (idle), which is the opposite of performance.&#13;
<em>Not working</em> is why the wait class in <a data-type="xref" href="#field-of-metrics">Figure 6-4</a> is darker: MySQL has gone dark.</p>&#13;
&#13;
<p>Waits are unavoidable.&#13;
Eliminating waits is not the goal; the goal is reducing and stabilizing them.&#13;
When waits are stabilized and reduced to an acceptable level, they effectively disappear, blending into response time as an inherent part of query <span class="keep-together">execution</span>.</p>&#13;
<aside class="pagebreak-before less_space" data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45829111052528">&#13;
<h5>Event Waits</h5>&#13;
<p>Waits are so important that they constitute a class in the hierarchy of MySQL events:</p>&#13;
&#13;
<pre data-type="programlisting">transactions&#13;
└── statements&#13;
    └── stages&#13;
        └── waits</pre>&#13;
&#13;
<p>The Performance Schema instruments many wait events, but these metrics are not commonly monitored because they are figuratively deep (in understanding what they represent) and literally deep (in the event hierarchy).&#13;
A small book could be written about wait events.&#13;
Until someone writes that book, refer to <a href="https://oreil.ly/VE55D">“Performance Schema Wait Event Tables”</a> in the MySQL manual for more information.</p>&#13;
</div></aside>&#13;
&#13;
<p>When MySQL waits too long, it times out—the wait-error relationship.&#13;
The most important, high-level MySQL waits have configurable timeouts:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="https://oreil.ly/H0fwi"><code>MAX_EXECUTION_TIME</code></a> (SQL statement optimizer hint)</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://oreil.ly/2rdKw"><code>max_execution_time</code></a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://oreil.ly/WD6p7"><code>lock_wait_timeout</code></a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://oreil.ly/4uT4F"><code>innodb_lock_wait_timeout</code></a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://oreil.ly/R7HwC"><code>connect_timeout</code></a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://oreil.ly/C7M9a"><code>wait_timeout</code></a></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Use these but don’t rely on them because, for example, take a guess at the default value for <code>lock_wait_timeout</code>.&#13;
The default value for <code>lock_wait_timeout</code> is 31,536,000 seconds—365 days.&#13;
Establishing default values is not easy, so we must give MySQL some leeway, but wow—365 days.&#13;
Consequently, applications should always employ code-level timeouts, too.&#13;
Long-running transactions and queries are a common problem because MySQL is fast but, perhaps, too <a data-primary="waits" data-secondary="field of metrics" data-startref="waits-field-of-metrics-ch6" data-type="indexterm" id="idm45829111036576"/>patient.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Error" data-type="sect2"><div class="sect2" id="field-error">&#13;
<h2>Error</h2>&#13;
&#13;
<p>Error metrics <a data-primary="error metrics" data-type="indexterm" id="error-metrics"/>indicate errors.&#13;
(I allow myself one tautological statement in this book; there it is.)&#13;
Wait timeouts are one type of error, and there are many more (see <a href="https://oreil.ly/Jtpqd">“MySQL Error Message Reference”</a> for more).&#13;
I don’t need to enumerate MySQL errors because, with respect to server performance and MySQL metrics, the point is simple and clear: an abnormal error rate is bad.&#13;
Like waits, errors are also calculated as rates, but they merit a separate class because they indicate when MySQL or the client (the application) has failed, which is why the error class in <a data-type="xref" href="#field-of-metrics">Figure 6-4</a> is darker.</p>&#13;
&#13;
<p>To reiterate a point about errors from <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>: don’t expect a zero error rate because, for example, there’s nothing you, the application, or MySQL can do if a client aborts a connection.<a data-primary="error metrics" data-startref="error-metrics" data-type="indexterm" id="idm45829111028848"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Access Pattern" data-type="sect2"><div class="sect2" id="field-access">&#13;
<h2>Access Pattern</h2>&#13;
&#13;
<p>Access pattern metrics <a data-primary="access pattern metrics" data-type="indexterm" id="idm45829111025856"/>indicate how the application uses MySQL.&#13;
These metrics relate to <a data-type="xref" href="ch04.html#access-patterns">“Data Access Patterns”</a>.&#13;
For example, MySQL has metrics for each type of SQL statement (<code>Com_select</code>, <code>Com_insert</code>, and so on) that relate to <a data-type="xref" href="ch04.html#ap-read-write">“Read/Write”</a>.</p>&#13;
&#13;
<p>As indicated in <a data-type="xref" href="#field-of-metrics">Figure 6-4</a>, access pattern metrics underlie higher level metrics.&#13;
The <code>Com_select</code> access pattern metric counts the number of <code>SELECT</code> statements executed.&#13;
This can be represented as a rate (<code>SELECT</code> QPS) or a utilization (<code>% SELECT</code>); either way, it reveals something deeper about server performance that helps explain higher level metrics.&#13;
For example, if response time is abysmal and the access pattern metric <code>Select_full_join</code> is high, that’s a smoking gun (see <a data-type="xref" href="ch01.html#Select-full-join">“Select full join”</a>).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Internal" data-type="sect2"><div class="sect2" id="field-internal">&#13;
<h2>Internal</h2>&#13;
&#13;
<p>There’s a seventh class of metrics shown <a data-primary="internal metrics" data-type="indexterm" id="internal-metrics"/>in <a data-type="xref" href="#field-of-metrics-with-internal">Figure 6-5</a>: internal metrics.</p>&#13;
&#13;
<figure><div class="figure" id="field-of-metrics-with-internal">&#13;
<img alt="emsp 0605" src="assets/emsp_0605.png"/>&#13;
<h6><span class="label">Figure 6-5. </span>Field of metrics with internal metrics</h6>&#13;
</div></figure>&#13;
&#13;
<p>I didn’t mention this class at the beginning of <a data-type="xref" href="#field-of-metrics-toc">“Field of Metrics”</a> because, as engineers and users of MySQL, we’re not supposed to know or care about it.&#13;
But it’s the most interesting—if not arcane—part of the field, and I want you to be fully informed in case you need or want to fathom the depths of MySQL.&#13;
Down here, things are esoteric.</p>&#13;
&#13;
<p>Of course, <em>esoteric</em> is subjective.&#13;
What I consider to be an internal metric might be the most favorite and useful rate metric for another engineer.&#13;
But metrics like <code>buffer_page_read_index_ibuf_non_leaf</code> make a strong case for the internal class of metrics.&#13;
That metric indicates the number of non-leaf index pages read in the change buffer.&#13;
Not exactly your daily bread.<a data-primary="server metrics" data-secondary="field of metrics" data-startref="field-of-metrics_index1" data-type="indexterm" id="idm45829111008528"/><a data-primary="field of metrics" data-startref="field-of-metrics_index2" data-type="indexterm" id="idm45829111007312"/><a data-primary="internal metrics" data-startref="internal-metrics" data-type="indexterm" id="idm45829111006368"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Spectra" data-type="sect1"><div class="sect1" id="spectra">&#13;
<h1>Spectra</h1>&#13;
&#13;
<p>Prepare <a data-primary="spectra (MySQL server metrics)" data-type="indexterm" id="spectra_index1"/>yourself for another journey: into the penumbra of MySQL metrics.&#13;
This section examines over 70 MySQL metrics divided into 11 spectra, some of which have sub-spectra.&#13;
I organize MySQL metrics into spectra for two reasons:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Spectra give the journey waypoints.&#13;
Without them, we face a vast and unorganized universe swirling with nearly <em>one thousand</em> metrics from different sources that vary by MySQL version, distribution, and configuration.</p>&#13;
</li>&#13;
<li>&#13;
<p>Spectra reveal important areas of MySQL to understand and monitor with respect to performance.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Even with spectra illuminating a path through the darkness, we need a metric naming convention to talk clearly and precisely about the MySQL metrics and system variables that constitute each spectrum.&#13;
The reason is simple: MySQL does not have a metric naming convention, and there is no industry standard, either.&#13;
<a data-type="xref" href="#metric-naming-convention">Table 6-1</a> is the MySQL metric naming convention that I use in this book.</p>&#13;
<table id="metric-naming-convention">&#13;
<caption><span class="label">Table 6-1. </span>MySQL metric naming convention</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Example</th>&#13;
<th>Refers to</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p><code>Threads_running</code></p></td>&#13;
<td><p>Global status variables</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>var.max_connections</code></p></td>&#13;
<td><p>Global system variables</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>innodb.log_lsn_checkpoint_age</code></p></td>&#13;
<td><p>InnoDB metrics</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><em><code>replication lag</code></em></p></td>&#13;
<td><p>Derived metrics</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Most metrics are global status variables that you have likely seen or used by executing <a href="https://oreil.ly/NacuT"><code>SHOW GLOBAL STATUS</code></a>: <code>Aborted_connects</code>, <code>Queries</code>, <code>Threads_running</code>, and so forth.&#13;
In MySQL and this book, global status variable names begin with a single uppercase letter followed by lowercase letters, even if the first word is an acronym: <code>Ssl_client_connects</code>, <em>not</em> <code>SSL_client_connects</code>.&#13;
(This is one aspect of MySQL metrics that is consistent.)&#13;
By contrast, global system variables are lowercase; and to make them more distinct, I prefix them with <code>var.</code>, which is important given the next convention.&#13;
InnoDB metrics are also lowercase, like <code>lock_timeouts</code>.&#13;
Since that can look like a global system variable, I prefix InnoDB metrics with <code>innodb.</code>, like <code>innodb.lock_timeouts</code>.&#13;
Derived metrics are ubiquitous in monitoring but not native to MySQL.&#13;
<em><code>Replication lag</code></em>, for example, is a metric that nearly every monitor will emit, but the precise metric name depends on the monitor, which is why I use a descriptive name without underscore characters rather than a specific technical name.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The InnoDB metrics in this section require <span class="keep-together">enabling</span> certain counters or modules.&#13;
For example, <span class="keep-together">starting</span> MySQL with <code>inno​db_​mon​itor_​enable=​module_​log,​mod⁠ule_​buffer,​module_​trx</code>.&#13;
See <a href="https://oreil.ly/nFKFT"><code>var.innodb_monitor_enable</code></a> and <a href="https://oreil.ly/e0wpA">“InnoDB INFORMATION_SCHEMA Metrics Table”</a> in the MySQL manual.</p>&#13;
</div>&#13;
&#13;
<p>Second to last bit of mental equipment: <em>global</em> refers to the entire MySQL server: all clients, all users, all queries, and so on—combined.&#13;
By contrast, there are <em>session</em> and <em>summary</em> metrics.&#13;
Session metrics are global metrics scoped to a single client connection.&#13;
Summary metrics are usually a subset of global metrics scoped to a variety of aspects: account, host, thread, transaction, and so on.&#13;
This chapter looks only at global metrics since they underlie all metrics.&#13;
(Global metrics are also the original: in ancient times, MySQL had only global metrics; then it added session metrics; then it added summary metrics.)</p>&#13;
&#13;
<p>Last bit of mental equipment before we begin the journey: most MySQL metrics are simple counters, and only a few are gauges.&#13;
I explicitly note the gauges; otherwise, counter is implied.&#13;
Let’s begin!<a data-primary="spectra (MySQL server metrics)" data-startref="spectra_index1" data-type="indexterm" id="idm45829110971872"/></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Query Response Time" data-type="sect2"><div class="sect2" id="metrics-qrt">&#13;
<h2>Query Response Time</h2>&#13;
&#13;
<p>Global query response time <a data-primary="spectra (MySQL server metrics)" data-secondary="query response time" data-type="indexterm" id="query-response-time3_index1"/><a data-primary="query response time" data-type="indexterm" id="query-response-time3_index2"/>is one of the four <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>.&#13;
Surprisingly, MySQL did not have this metric until version 8.0.&#13;
As of MySQL 8.0.1, you can obtain the 95th percentile (P95) global query response time in milliseconds from the <a href="https://oreil.ly/dj06D">Performance Schema</a> by executing the query in <a data-type="xref" href="#qrt-query">Example 6-1</a>.</p>&#13;
<div data-type="example" id="qrt-query">&#13;
<h5><span class="label">Example 6-1. </span>Global 95th percentile query response time</h5>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">SELECT</code>&#13;
  <code class="n">ROUND</code><code class="p">(</code><code class="n">bucket_quantile</code> <code class="o">*</code> <code class="mi">100</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code> <code class="k">AS</code> <code class="n">p</code><code class="p">,</code>&#13;
  <code class="n">ROUND</code><code class="p">(</code><code class="n">BUCKET_TIMER_HIGH</code> <code class="o">/</code> <code class="mi">1000000000</code><code class="p">,</code> <code class="mi">3</code><code class="p">)</code> <code class="k">AS</code> <code class="n">ms</code>&#13;
<code class="k">FROM</code>&#13;
  <code class="n">performance_schema</code><code class="p">.</code><code class="n">events_statements_histogram_global</code>&#13;
<code class="k">WHERE</code>&#13;
  <code class="n">bucket_quantile</code> <code class="o">&gt;=</code> <code class="mi">0</code><code class="p">.</code><code class="mi">95</code>&#13;
<code class="k">ORDER</code> <code class="k">BY</code> <code class="n">bucket_quantile</code> <code class="k">LIMIT</code> <code class="mi">1</code><code class="p">;</code></pre></div>&#13;
&#13;
<p>That query returns a percentile very close to—but not exactly—the P95: 95.2% instead of 95.0%, for example.<sup><a data-type="noteref" href="ch06.html#idm45829110960368" id="idm45829110960368-marker">1</a></sup>&#13;
The difference is negligible and does not affect monitoring.</p>&#13;
&#13;
<p>You can replace <code>0.95</code> in the query to return a different percentile: <code>0.99</code> for P99, or <code>0.999</code> for P999.&#13;
I prefer and advise P999 for the reasons stated in <a data-type="xref" href="ch01.html#avg-p-max-distro">“Average, Percentile, and Maximum”</a>.</p>&#13;
&#13;
<p>The rest of this section is for MySQL 5.7 and older—skip it if you’re running MySQL 8.0 or newer.</p>&#13;
<dl>&#13;
<dt>MySQL 5.7 and older</dt>&#13;
<dd>&#13;
<p>MySQL 5.7 and older do not expose a global query response time metric.&#13;
Only query metrics include response time (see <a data-type="xref" href="ch01.html#Query-time">“Query time”</a>), but that is per-query response time.&#13;
To calculate global response time, you would need to aggregate it from every query.&#13;
That’s possible, but there are two better alternatives: upgrade to MySQL 8.0; or, switch to Percona Server or MariaDB, which have a plug-in to capture global response time.</p>&#13;
</dd>&#13;
<dt>Percona Server 5.7</dt>&#13;
<dd>&#13;
<p>Way back in 2010, <a data-primary="Percona Server" data-secondary="query response time" data-type="indexterm" id="idm45829110883280"/><a href="https://oreil.ly/Gyq8J">Percona Server</a> introduced a plug-in to capture global response time called <a href="https://oreil.ly/PE5kh">Response Time Distribution</a>.&#13;
It’s easy to install the plug-in, but it takes work to configure and use because it’s a histogram of response time ranges, which means you need to set <code>var.query_response_time_range_base</code>—a global system variable that the plug-in creates—to configure the histogram bucket ranges, then compute a percentile from the bucket counts.&#13;
MySQL 8.0 global response time is also a histogram, but the bucket ranges and percentiles are preset and precomputed, which is why the query in <a data-type="xref" href="#qrt-query">Example 6-1</a> works out of the box.&#13;
It’s not that difficult to set up; it only sounds complicated.&#13;
The benefit of having global response time is well worth the effort.</p>&#13;
</dd>&#13;
<dt>MariaDB 10.0</dt>&#13;
<dd>&#13;
<p><a href="https://oreil.ly/oeGJO">MariaDB</a> uses <a data-primary="MariaDB" data-type="indexterm" id="idm45829110877200"/>the same plug-in from Percona but it has a slightly different name: <a href="https://oreil.ly/kb4gA">Query Response Time Plugin</a>.&#13;
Although introduced in MariaDB 10.0, it was not marked stable until MariaDB 10.1.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Before MySQL 8.0, obtaining global query response time is not trivial, but it’s worth the effort if you’re running Percona Server or MariaDB.&#13;
If you’re running MySQL in the cloud, check the cloud provider metrics because some provide a response time metric (which the cloud provider might call <em>latency</em>).&#13;
If nothing else, frequently review the query profile to keep an eye on response times.<a data-primary="spectra (MySQL server metrics)" data-secondary="query response time" data-startref="query-response-time3_index1" data-type="indexterm" id="idm45829110874272"/><a data-primary="query response time" data-startref="query-response-time3_index2" data-type="indexterm" id="idm45829110872992"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Errors" data-type="sect2"><div class="sect2" id="metrics-errors">&#13;
<h2>Errors</h2>&#13;
&#13;
<p>Errors <a data-primary="spectra (MySQL server metrics)" data-secondary="errors" data-type="indexterm" id="spectra-errors_index1"/><a data-primary="errors" data-type="indexterm" id="errors-ch6"/>are one of the four <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>.&#13;
As of MySQL 8.0.0, it’s easy to obtain a count of <em>all</em> errors from the <a href="https://oreil.ly/glJUC">Performance Schema</a> by executing the query in <a data-type="xref" href="#all-errors-query">Example 6-2</a>.</p>&#13;
<div data-type="example" id="all-errors-query">&#13;
<h5><span class="label">Example 6-2. </span>Global error count</h5>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">SELECT</code>&#13;
  <code class="k">SUM</code><code class="p">(</code><code class="n">SUM_ERROR_RAISED</code><code class="p">)</code> <code class="k">AS</code> <code class="n">global_errors</code>&#13;
<code class="k">FROM</code>&#13;
  <code class="n">performance_schema</code><code class="p">.</code><code class="n">events_errors_summary_global_by_error</code>&#13;
<code class="k">WHERE</code>&#13;
  <code class="n">ERROR_NUMBER</code> <code class="k">NOT</code> <code class="k">IN</code> <code class="p">(</code><code class="mi">1287</code><code class="p">);</code></pre></div>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Error number 1287, excluded in the <code>WHERE</code> clause in <a data-type="xref" href="#all-errors-query">Example 6-2</a>, is for deprecation warnings: when a query uses a feature that is deprecated, MySQL issues a warning.&#13;
Including this error number is likely to make the global error count too noisy, which is why I exclude it.</p>&#13;
</div>&#13;
&#13;
<p>Since MySQL has so many errors and warnings, there’s no telling what your global error rate will be.&#13;
Don’t expect or try to achieve a zero error rate.&#13;
That’s essentially impossible because clients can cause errors, and there’s nothing you, the application, or MySQL can do to prevent that.&#13;
The goal is to establish the normal error rate for the application.&#13;
If the query in <a data-type="xref" href="#all-errors-query">Example 6-2</a> is too noisy—which means it produces a high rate of errors but you are certain the application is functioning normally—then fine tune the query by excluding additional error numbers.&#13;
MySQL error codes are documented in the <a href="https://oreil.ly/wKfnV">“MySQL Error Message Reference”</a>.</p>&#13;
&#13;
<p>Before MySQL 8.0, you cannot obtain a global error count from MySQL, but you can obtain a count of all <em>query</em> errors from the <a href="https://oreil.ly/QiHj8">Performance Schema</a> by executing the query in <a data-type="xref" href="#query-errors-query">Example 6-3</a>.</p>&#13;
<div data-type="example" id="query-errors-query">&#13;
<h5><span class="label">Example 6-3. </span>Query error count</h5>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">SELECT</code>&#13;
  <code class="k">SUM</code><code class="p">(</code><code class="n">sum_errors</code><code class="p">)</code> <code class="k">AS</code> <code class="n">query_errors</code>&#13;
<code class="k">FROM</code>&#13;
  <code class="n">performance_schema</code><code class="p">.</code><code class="n">events_statements_summary_global_by_event_name</code>&#13;
<code class="k">WHERE</code>&#13;
  <code class="n">event_name</code> <code class="k">LIKE</code> <code class="s1">'statement/sql/%'</code><code class="p">;</code></pre></div>&#13;
&#13;
<p class="pagebreak-before less_space">Since this works in all distributions as of MySQL 5.6, there is no reason not to monitor all query errors.&#13;
Granted, the application should report query errors, too; but if it also retries on error, it might hide a certain amount of errors.&#13;
By contrast, this will expose all query errors, potentially revealing a problem that application retries are masking.</p>&#13;
&#13;
<p>The last error metrics are client connection errors:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Aborted_clients</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Aborted_connects</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Connection_errors_%</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The first two metrics are commonly monitored to ensure that there are no issues <em>while connecting</em> or <em>already connected</em> to MySQL.&#13;
That wording is precise: if the application cannot make a network connection to MySQL, then MySQL does not see the client and does not report a client connection error because, from the MySQL point of view, there is no client connection yet.&#13;
Low-level network connection issues should be reported by the application.&#13;
However, if the application cannot connect, you’re likely to see a drop in the other three KPIs (QPS, threads running, and response time) because the application isn’t executing queries.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The <code>%</code> character in <code>Connection_errors_%</code> is a MySQL wildcard; several metrics exist with the prefix <code>Connection_errors_</code>. To list them, execute <code>SHOW GLOBAL STATUS LIKE <em>Connection_errors_%</em>;</code>.</p>&#13;
</div>&#13;
&#13;
<p>Before moving on to the next spectrum, let’s address a problem that’s also not a problem—at least not for MySQL.&#13;
If the application begins to spew errors but MySQL does not and the other three KPIs are normal, then the problem is with the application or the network.&#13;
MySQL has many quirks, but lying is not one of them.&#13;
If MySQL KPIs are thumbs up (all okay and normal), then you can trust that MySQL is working normally.<a data-primary="spectra (MySQL server metrics)" data-secondary="errors" data-startref="spectra-errors_index1" data-type="indexterm" id="idm45829110786688"/><a data-primary="errors" data-startref="errors-ch6" data-type="indexterm" id="idm45829110759744"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Queries" data-type="sect2"><div class="sect2" id="metrics-queries">&#13;
<h2>Queries</h2>&#13;
&#13;
<p>Metrics <a data-primary="spectra (MySQL server metrics)" data-secondary="query" data-type="indexterm" id="spectra-queries_index1"/><a data-primary="query" data-secondary="spectra (MySQL server metrics)" data-type="indexterm" id="spectra-queries_index2"/>related to queries reveal how fast MySQL is working and what type of work it’s doing—at a very high level.&#13;
These metrics reveal two access pattern traits:  throughput and read/write (see <a data-type="xref" data-xrefstyle="select:nopage" href="ch04.html#ap-throughput">“Throughput”</a> and <a data-type="xref" href="ch04.html#ap-read-write">“Read/Write”</a>).</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="QPS" data-type="sect3"><div class="sect3" id="metrics-qps">&#13;
<h3>QPS</h3>&#13;
&#13;
<p>QPS <a data-primary="queries per second" data-type="indexterm" id="queries-per-second2"/>is one of the four <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>.&#13;
The underlying metric is aptly named:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Queries</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>That metric is a counter, but QPS is a rate, so technically QPS equals the difference of two <code>Queries</code> measurements divided by the number of seconds between the measurements: QPS = (Queries @ T1 – Queries @ T0) / (T1 – T0), where T0 is the time of the first measurement and T1 is the time of the second measurement.&#13;
Metric graphing systems (like <a href="https://grafana.com">Grafana</a>) convert counters to rates by default.&#13;
As a result, you should not need to convert <code>Queries</code> or any other counters to rates.&#13;
Just be aware that most MySQL metrics are counters, but they are converted to and expressed as rates.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Metric graphing systems convert counters to rates by default.</p>&#13;
</div>&#13;
&#13;
<p>QPS receives a lot of attention because it indicates overall MySQL throughput—how fast MySQL is executing queries—but don’t fixate on it.&#13;
As mentioned in <a data-type="xref" href="ch03.html#less-qps-is-better">“Less QPS Is Better”</a>, QPS reveals nothing qualitative about the queries or performance in general.&#13;
If QPS is incredibly high but response time is also incredibly high, then QPS indicates a problem, not great performance.&#13;
Other metrics reveal more about MySQL performance than QPS.</p>&#13;
&#13;
<p>When everything is running normally, QPS fluctuates with application usage.&#13;
When there is a problem, QPS fluctuations correlate with other metrics.&#13;
To analyze performance or diagnose a problem, I glance at QPS to see where (in a chart) its value is abnormal.&#13;
Then I correlate that period (time along the X axis of the chart) with other, more specific metrics in the spectra.&#13;
As a KPI, QPS indicates a problem, but other metrics pinpoint the problem.</p>&#13;
&#13;
<p>All abnormal changes in QPS are suspect and worth investigating.&#13;
Most, if not all, engineers know that a drop in QPS is bad, but an abnormal increase in QPS can be equally bad or worse.&#13;
Also bad but more rare is flatline QPS—a nearly constant QPS value—because minor fluctuations are normal.&#13;
When QPS changes abnormally, the first question is usually: what’s the cause?&#13;
I address that later in this chapter (see <a data-type="xref" href="#cause-and-effect">“Cause and Effect”</a>).</p>&#13;
&#13;
<p>MySQL exposes another closely related metric: <code>Questions</code>.&#13;
(The term <em>question</em> is only used for this metric; it’s not used for anything else inside MySQL.)&#13;
<code>Questions</code> counts only queries sent by clients, not queries executed by stored programs.&#13;
For example, queries executed by a trigger do <em>not</em> count in <code>Questions</code> because a client did not send them; but they do count in <code>Queries</code>.&#13;
Since <code>Questions</code> is a subset of <code>Queries</code>, the difference is only informational, and monitoring <code>Questions</code> is optional.&#13;
For QPS, always use <code>Queries</code>.<a data-primary="queries per second" data-startref="queries-per-second2" data-type="indexterm" id="idm45829110733184"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="TPS" data-type="sect3"><div class="sect3" id="metrics-tps">&#13;
<h3>TPS</h3>&#13;
&#13;
<p>If the application relies on explicit, multistatement transactions, then transactions per second (TPS) <a data-primary="transactions per second (TPS)" data-type="indexterm" id="transactions-per-second"/>is as important as QPS.&#13;
For some applications, a database transaction represents a unit of work in the application, so TPS is a better rate than QPS because the application unit of work is all or nothing, which is why it’s executed in an explicit transaction.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>An <em>implicit transaction</em> is a single SQL statement with <a href="https://oreil.ly/zrjQK"><code>autocommit</code></a> enabled, which is the default.&#13;
An <em>explicit transaction</em> starts with <code>BEGIN</code> or <code>START TRANSACTION</code> and ends with either <code>COMMIT</code> or <code>ROLLBACK</code>, regardless of <code>autocommit</code>.</p>&#13;
</div>&#13;
&#13;
<p>In MySQL, explicit transaction throughput is revealed by three metrics:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Com_begin</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_commit</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_rollback</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Normally, the rate of <code>Com_begin</code> and <code>Com_commit</code> are the same because every transaction must begin and successful transactions must commit.&#13;
When there’s a problem that causes transactions to stall (one of the <a data-type="xref" href="ch08.html#trx-problems">“Common Problems”</a>), the rate of <code>Com_begin</code> exceeds the other two metrics.</p>&#13;
&#13;
<p>Use <code>Com_commit</code> to measure TPS because transaction throughput implies successful transactions.</p>&#13;
&#13;
<p>A transaction rollback is supposed to indicate an error—since transactions are all or nothing—but the <code>ROLLBACK</code> statement is also commonly used for cleanup: it ensures that the previous transaction—if any—is closed before starting the next transaction.&#13;
Consequently, the rollback rate might not be zero.&#13;
As with most metrics, normal and stable is the goal (see <a data-type="xref" href="#normal-and-stable">“Normal and Stable: The Best Database <span class="keep-together">Is a Boring Database</span>”</a>).</p>&#13;
&#13;
<p>Another gauge metric that indicates the current number of active transactions is <code>innodb.trx_active_transactions</code>.</p>&#13;
&#13;
<p><code>BEGIN</code> starts a transaction, but a transaction is not <em>active</em> until, generally speaking, a query accesses a table.&#13;
For example, <code>BEGIN; SELECT NOW();</code> starts a transaction that is not active because no query accesses a table.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45829110711600">&#13;
<h5>SHOW ENGINE INNODB STATUS</h5>&#13;
<p>InnoDB metrics <a data-primary="InnoDB" data-secondary="metrics" data-type="indexterm" id="idm45829110710032"/>are exposed in the <code>information_schema.innodb_metrics</code> table.&#13;
(See <a href="https://oreil.ly/GHalc">“InnoDB INFORMATION_SCHEMA Metrics Table”</a> for details.)&#13;
Before this table was mainstream, InnoDB metrics were exposed using the <code>SHOW ENGINE INNODB STATUS</code> command, but the output is a long blob of text.&#13;
The text is divided into sections, which makes it a little easier for humans to read, but it’s programmatically unorganized: it requires parsing and pattern matching to extract specific metric values.&#13;
Some MySQL monitors still use <code>SHOW ENGINE INNODB STATUS</code>, but avoid this if you can because using the Information Schema (and Performance Schema) is the best practice.</p>&#13;
&#13;
<p>I no longer consider <code>SHOW ENGINE INNODB STATUS</code> authoritative.&#13;
For example, with respect to active transactions, <code>BEGIN; SELECT col FROM tbl;</code> does <em>not</em> show as active in <code>SHOW ENGINE INNODB STATUS</code>, but it correctly shows as active in <code>innodb.trx_active_transactions</code>.<a data-primary="transactions per second (TPS)" data-startref="transactions-per-second" data-type="indexterm" id="idm45829110703648"/></p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Read/write" data-type="sect3"><div class="sect3" id="metrics-read-write">&#13;
<h3>Read/write</h3>&#13;
&#13;
<p>There <a data-primary="read/write" data-type="indexterm" id="read-write2"/>are nine read/write metrics named according to a type of SQL statement:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Com_select</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_delete</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_delete_multi</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_insert</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_insert_select</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_replace</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_replace_select</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_update</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_update_multi</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>For example, <code>Com_select</code> is a counter for the number of <code>SELECT</code> statements.&#13;
The <code>_multi</code> suffix in <code>Com_delete_multi</code> and <code>Com_update_multi</code> refers to queries that reference multiple tables.&#13;
A multitable <code>DELETE</code> increments only <code>Com_delete_multi</code>, whereas a single-table <code>DELETE</code> only updates <code>Com_delete</code>.&#13;
The same is true for <code>UPDATE</code> statements with respect to <code>Com_update_multi</code> and <code>Com_update</code>.</p>&#13;
&#13;
<p>Read/write metrics reveal the important types and throughputs of queries that constitute <code>Queries</code>.&#13;
These metrics do not fully account for <code>Queries</code>; they are only the most important metrics with respect to performance.</p>&#13;
&#13;
<p>Monitor these metrics as individual rates and percentages of <code>Queries</code>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Com_select</code> indicates the read percentage of the workload:</p>&#13;
<div data-type="equation">&#13;
(Com_select / Queries) × 100.&#13;
</div>&#13;
</li>&#13;
<li>&#13;
<p>The sum of the other eight metrics indicates the write percentage of the <span class="keep-together">workload</span>.<sup><a data-type="noteref" href="ch06.html#idm45829110678032" id="idm45829110678032-marker">2</a></sup></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The read and write percentages will <em>not</em> equal 100% because <code>Queries</code> accounts for other types of SQL statements: <code>SHOW</code>, <code>FLUSH</code>, <code>GRANT</code>, and many more.&#13;
If the remaining percentage is suspiciously high (more than 20%), it probably won’t affect performance, but it’s worth investigating: examine other <code>Com_</code> metrics to account for other types of SQL statements.<a data-primary="read/write" data-startref="read-write2" data-type="indexterm" id="idm45829110672832"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Admin" data-type="sect3"><div class="sect3" id="metrics-admin">&#13;
<h3>Admin</h3>&#13;
&#13;
<p>Admin <a data-primary="admin metrics" data-type="indexterm" id="idm45829110670048"/>metrics refer to commands that, typically, only database administrators invoke:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Com_flush</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_kill</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_purge</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_admin_commands</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The first three metrics refer to <a href="https://oreil.ly/O6j77"><code>FLUSH</code></a>, <a href="https://oreil.ly/fMbiY"><code>KILL</code></a>, and <a href="https://oreil.ly/czxYb"><code>PURGE</code></a>, respectively.&#13;
These commands could affect performance, but they should be very rare.&#13;
If not, ask your DBA or cloud provider what they’re doing.</p>&#13;
&#13;
<p>The last metric, <code>Com_admin_commands</code>, is an oddity.&#13;
It refers to other admin commands for which there are not specific <code>Com_</code> status variables.&#13;
For example, the MySQL protocol has a ping command that is commonly used by MySQL client drivers to test the connection.&#13;
This is harmless in moderation, but problems can result from a lack of moderation.&#13;
Don’t expect <code>Com_admin_commands</code> to indicate any problems, but monitoring it is still a best practice.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="SHOW" data-type="sect3"><div class="sect3" id="metrics-show">&#13;
<h3>SHOW</h3>&#13;
&#13;
<p>MySQL <a data-primary="SHOW metrics" data-type="indexterm" id="idm45829110657424"/>has over 40 <a href="https://oreil.ly/u7Xzs"><code>SHOW</code></a> statements, most of which have a corresponding <code>Com_show_</code> metric.&#13;
<code>SHOW</code> commands never change MySQL or modify data, so in that sense they’re harmless.&#13;
But they are queries, which means they use a thread, time, and resources in MySQL.&#13;
<code>SHOW</code> commands can stall, too.&#13;
<code>SHOW GLOBALS STATUS</code>, for example, can take a full second or more on a busy server.&#13;
Consequently, it’s a best practice to monitor at least the following 10 metrics:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Com_show_databases</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_engine_status</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_errors</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_processlist</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_slave_status</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_status</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_table_status</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_tables</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_variables</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_show_warnings</code></p>&#13;
</li>&#13;
</ul>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>As of MySQL 8.0.22, monitor <code>Com_show_replica_status</code> instead of <code>Com_show_slave_status</code>.</p>&#13;
</div>&#13;
&#13;
<p>Don’t expect <code>SHOW</code> metrics to indicate any problems, but don’t be surprised if one does because it wouldn’t be the first time.<a data-primary="spectra (MySQL server metrics)" data-secondary="query" data-startref="spectra-queries_index1" data-type="indexterm" id="idm45829110639968"/><a data-primary="query" data-secondary="spectra" data-startref="spectra-queries_index2" data-type="indexterm" id="idm45829110638704"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Threads and Connections" data-type="sect2"><div class="sect2" id="metrics-threads">&#13;
<h2>Threads and Connections</h2>&#13;
&#13;
<p><code>Threads_running</code> <a data-primary="spectra (MySQL server metrics)" data-secondary="threads and connections" data-type="indexterm" id="threads-and-connections_index1"/><a data-primary="threads" data-type="indexterm" id="threads-and-connections_index2"/><a data-primary="connections" data-type="indexterm" id="threads-and-connections_index3"/>is one of the four <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>.&#13;
It indicates how hard MySQL is working because it’s directly connected to active query execution (when a client connection is not executing a query, its thread is idle), and it’s effectively limited by the number of CPU cores.&#13;
Let’s come back to <code>Threads_running</code> after looking at related metrics.</p>&#13;
&#13;
<p>Threads and connections are one spectrum because they are directly related: MySQL runs one thread per client connection.&#13;
The four most important metrics for threads and connections are:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Connections</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Max_used_connections</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Threads_connected</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Threads_running</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><code>Connections</code> is the number of connection attempts to MySQL, both successful and failed.&#13;
It reveals the stability of the application connection pool to MySQL.&#13;
Usually, application connections to MySQL are long-lived, where <em>long</em> is at least a few seconds, if not minutes or hours.&#13;
Long-lived connections avoid the overhead of establishing a connection.&#13;
When the application and MySQL are on the same local network, the overhead is negligible: 1 millisecond or less.&#13;
But network latency between the application and MySQL adds up quickly when multiplied by hundreds of connections and multiplied again by the connection rate.&#13;
(<code>Connections</code> is a counter but expressed as a rate: connections/second.)&#13;
MySQL can easily handle hundreds of connections per second, but if this metric reveals an abnormally high rate of connections, find and fix the root cause.</p>&#13;
&#13;
<p><code>Max_used_connections</code> as a percentage of <a href="https://oreil.ly/MVZaQ"><code>var.max_connections</code></a> reveals connection utilization.&#13;
The default value for <code>var.max_connections</code> is 151, which is probably too low for most applications but <em>not</em> because the application needs more connections for performance.&#13;
The application needs more connections only because each application instance has its own connection pool.&#13;
(I presume the application is scaled out.)&#13;
If the connection pool size is 100 and there are 3 application instances, then the application (all instances) can create 300 connections to MySQL.&#13;
That is the main reason why 151 max connections is not sufficient.</p>&#13;
&#13;
<p>A common misconception is that the application needs thousands of connections to MySQL for performance or to support thousands of users.&#13;
This is patently not true.&#13;
The limiting factor is threads, not connections—more on <code>Threads_running</code> in a moment.&#13;
A single MySQL instance can easily handle thousands of connections.&#13;
I’ve seen 4,000 connections in production and more in benchmarks.&#13;
But for most applications, several hundred connections (total) is more than sufficient.&#13;
If your application demonstrably requires several thousand connections, then you need to shard (see <a data-type="xref" href="ch05.html#ch05">Chapter 5</a>).</p>&#13;
&#13;
<p>The real problem to monitor and avoid is 100% connection utilization.&#13;
If MySQL runs out of available connections, an application outage is essentially guaranteed.&#13;
If connection utilization rises suddenly, approaching 100%, the cause is always an external problem, or bug, or both.&#13;
(MySQL cannot connect to itself, so the cause must be external.)&#13;
In response to an external problem—like a network issue, for example—the application creates more connections than normal.&#13;
Or, a bug causes the application not to close connections—commonly known as a <em>connection leak</em>.&#13;
Or, an external problem triggers a bug in the application—I’ve seen it happen.&#13;
Either way, the underlying cause is always external: something outside MySQL is connecting to MySQL and using all the connections.</p>&#13;
&#13;
<p>As clients connect and disconnect, MySQL increments and decrements the <code>Threads_connected</code> gauge metric.&#13;
The name of this metric is a little misleading since <em>clients</em> are connected, not threads, but it reflects that MySQL runs one thread per client connection.</p>&#13;
&#13;
<p><code>Threads_running</code> is a gauge metric and an implicit utilization relative to the number of CPU cores.&#13;
Although <code>Threads_running</code> can spike into the hundreds and thousands, performance will degrade sharply at much lower values: around twice the number of CPU cores.&#13;
The reason is simple: one CPU core runs one thread.&#13;
When the number of threads running is greater than the number of CPU cores, it means that some threads are stalled—waiting for CPU time.&#13;
This is analogous to rush hour traffic: thousands of cars in gridlock on the highway, engines running but barely moving.&#13;
(Or, for electric cars: batteries running but barely moving.)&#13;
Consequently, it’s normal for <code>Threads_running</code> to be quite low: less than 30.&#13;
Bursts lasting seconds or less are possible with good hardware and an optimized workload, but sustained (normal and stable) <code>Threads_running</code> should be as low as possible.&#13;
As in <a data-type="xref" href="ch03.html#less-qps-is-better">“Less QPS Is Better”</a>, less <code>Threads_running</code> is better too.</p>&#13;
&#13;
<p>High throughput (QPS) with very low threads running is a strong indication of efficient performance because there is only one way to achieve both: very fast query response time.&#13;
<a data-type="xref" href="#threads-running-qps">Table 6-2</a> lists threads running and QPS from five real (and different) applications.</p>&#13;
<table id="threads-running-qps">&#13;
<caption><span class="label">Table 6-2. </span>Threads running and QPS</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Threads running</th>&#13;
<th>QPS</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>4</p></td>&#13;
<td><p>8,000</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>8</p></td>&#13;
<td><p>6,000</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>8</p></td>&#13;
<td><p>30,000</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>12</p></td>&#13;
<td><p>23,000</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>15</p></td>&#13;
<td><p>33,000</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The second and third rows highlight how profoundly the application workload affects performance: with one workload, 6,000 QPS needs 8 threads running; but another workload achieves 5x QPS (30,000) with the same number of threads.&#13;
For the last row, 33,000 QPS is not exceptionally high, but that database is sharded: total QPS across all shards exceeds one million.&#13;
Empirically, high throughput is possible with few threads running.<a data-primary="spectra (MySQL server metrics)" data-secondary="threads and connections" data-startref="threads-and-connections_index1" data-type="indexterm" id="idm45829110596416"/><a data-primary="threads" data-startref="threads-and-connections_index2" data-type="indexterm" id="idm45829110595136"/><a data-primary="connections" data-startref="threads-and-connections_index3" data-type="indexterm" id="idm45829110594176"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Temporary Objects" data-type="sect2"><div class="sect2" id="metrics-temp-objects">&#13;
<h2>Temporary Objects</h2>&#13;
&#13;
<p>Temporary objects <a data-primary="spectra (MySQL server metrics)" data-secondary="temporary objects" data-type="indexterm" id="idm45829110591408"/><a data-primary="temporary objects" data-type="indexterm" id="idm45829110590384"/>are temporary files and tables that MySQL uses for various purposes: sorting rows, large joins, and so on.&#13;
Three metrics count the number of temporary tables on disk, temporary tables in memory, and temporary files (on disk) created:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Created_tmp_disk_tables</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Created_tmp_tables</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Created_tmp_files</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>These metrics are rarely zero because temporary objects are common and harmless as long as the rates are stable.&#13;
The most impactful metric is <code>Created_tmp_disk_tables</code>, which is the reciprocal of <code>Created_tmp_tables</code>.&#13;
When MySQL needs a temporary table to execute a query (for <code>GROUP BY</code>, for example), it starts with an in-memory temporary table and increments <code>Created_tmp_tables</code>.&#13;
This shouldn’t impact performance because it’s in memory.&#13;
But if that temporary table grows larger than <a href="https://oreil.ly/4plVm"><code>var.tmp_table_size</code></a>—the system variable that determines the in-memory temporary table size—then MySQL writes the temporary table to disk and increments <span class="keep-together"><code>Created_tmp_disk_tables</code></span>.&#13;
In moderation, this probably won’t impact performance, but it certainly doesn’t help, either, because storage is significantly slower than memory.&#13;
The same is true for <code>Created_tmp_files</code>: acceptable in moderation, but not helping performance.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>As of MySQL 8.0, <code>Created_tmp_disk_tables</code> does <em>not</em> count temporary tables created on disk.&#13;
This is due to the new storage engine used for internal temporary tables: <code>TempTable</code>.&#13;
The corresponding metric is a Performance Schema memory instrument: <code>memory/temptable/physical_disk</code>.&#13;
(A related instrument is <code>memory/temptable/physical_ram</code>, which tracks <code>TempTable</code> memory allocation for in-memory temporary tables.)&#13;
If you’re using MySQL 8.0, talk with your DBA to ensure that this metric is collected and reported correctly.</p>&#13;
</div>&#13;
&#13;
<p>Since temporary objects are side effects of queries, these metrics are most revealing when a change in one correlates to a change in KPIs.&#13;
For example, a sudden increase in <code>Created_tmp_disk_tables</code> coupled with a sudden increase in response time screams “Look at me!”<sup><a data-type="noteref" href="ch06.html#idm45829110575632" id="idm45829110575632-marker">3</a></sup></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Prepared Statements" data-type="sect2"><div class="sect2" id="metrics-prep-stmt">&#13;
<h2>Prepared Statements</h2>&#13;
&#13;
<p>Prepared statements <a data-primary="spectra (MySQL server metrics)" data-secondary="prepared statements" data-type="indexterm" id="prepared-statements_index1"/><a data-primary="prepared statements" data-type="indexterm" id="prepared-statements_index2"/>are a double-edged sword: used properly, they increase efficiency; but used improperly (or unknowingly), they increase waste.&#13;
The proper and most efficient way to use prepared statements is to prepare once and execute many times, which is counted by two metrics:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Com_stmt_prepare</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Com_stmt_execute</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><code>Com_stmt_execute</code> should be significantly greater than <code>Com_stmt_prepare</code>.&#13;
If it isn’t, then prepared statements are increasing waste due to extra queries to prepare and close the statement.&#13;
The worst case is when these metrics are one-to-one, or close to it, because a single query incurs two wasted roundtrips to MySQL: one to prepare and another to close the statement.&#13;
When MySQL and the application are on the same local network, two extra roundtrips might not be noticeable, but they are pure waste multiplied by QPS.&#13;
For example, an extra 1 millisecond at 1,000 QPS is a wasted second—a second during which another 1,000 queries could have been executed.</p>&#13;
&#13;
<p>Aside from the performance implications, you should monitor these prepared statement metrics because the application might be using prepared statements unintentionally.&#13;
For example, the MySQL driver for the Go programming language defaults to using prepared statements for security: to avoid SQL injection vulnerabilities.&#13;
At first glance (or any number of glances), you would not think that the Go code in <a data-type="xref" href="#hidden-ps">Example 6-4</a> uses a prepared statement, but it does.</p>&#13;
<div data-type="example" id="hidden-ps">&#13;
<h5><span class="label">Example 6-4. </span>Hidden prepared statement</h5>&#13;
&#13;
<pre data-type="programlisting">id := 75&#13;
db.QueryRow("SELECT col FROM tbl WHERE id = ?", id)</pre></div>&#13;
&#13;
<p>Check the documentation for the MySQL driver that the application uses.&#13;
If it does not explicitly mention if and when it uses prepared statements, then verify manually: on a development instance of MySQL (your laptop, for example), enable the <a href="https://oreil.ly/1Vczu">general query log</a> and write a test program to execute SQL statements using the same methods and function calls that the application uses.&#13;
The general log indicates when prepared statements are used:</p>&#13;
&#13;
<pre data-type="programlisting">2022-03-01T00:06:51.164761Z	   32 Prepare	SELECT col FROM tbl WHERE id=?&#13;
2022-03-01T00:06:51.164870Z	   32 Execute	SELECT col FROM tbl WHERE id=75&#13;
2022-03-01T00:06:51.165127Z	   32 Close stmt</pre>&#13;
&#13;
<p>Finally, the number of open prepared statements is limited to <a href="https://oreil.ly/K2MWz"><code>var.max_​pre⁠pared_​stmt_count</code></a>, which is 16,382 by default.&#13;
(Even 1,000 prepared statements is a lot for one application, unless the application is programmatically generating <span class="keep-together">statements</span>.)&#13;
This gauge metric reports the current number of open prepared <span class="keep-together">statements</span>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Prepared_stmt_count</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Don’t let <code>Prepared_stmt_count</code> reach <code>var.max_prepared_stmt_count</code>, else the application will stop working.&#13;
If this happens, it’s an application bug due to leaking (not closing) prepared statements.<a data-primary="spectra (MySQL server metrics)" data-secondary="prepared statements" data-startref="prepared-statements_index1" data-type="indexterm" id="idm45829110554160"/><a data-primary="prepared statements" data-startref="prepared-statements_index2" data-type="indexterm" id="idm45829110552864"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Bad SELECT" data-type="sect2"><div class="sect2" id="metrics-bad-select">&#13;
<h2>Bad SELECT</h2>&#13;
&#13;
<p>Four metrics <a data-primary="spectra (MySQL server metrics)" data-secondary="bad SELECT" data-type="indexterm" id="idm45829110550096"/><a data-primary="bad SELECT" data-type="indexterm" id="idm45829110549072"/>count the occurrence of <code>SELECT</code> statements that are usually bad for performance:<sup><a data-type="noteref" href="ch06.html#idm45829110547888" id="idm45829110547888-marker">4</a></sup></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Select_scan</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Select_full_join</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Select_full_range_join</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Select_range_check</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><code>Select_scan</code> and <code>Select_full_join</code> are described in <a data-type="xref" href="ch01.html#ch01">Chapter 1</a>: <a data-type="xref" href="ch01.html#Select-scan">“Select scan”</a> and <a data-type="xref" href="ch01.html#Select-full-join">“Select full join”</a>, respectively.&#13;
The only difference here is that these two metrics apply globally (all queries).</p>&#13;
&#13;
<p><code>Select_full_range_join</code> is the lesser evil of <code>Select_full_join</code>: instead of a full table scan to join a table, MySQL uses an index to do a range scan.&#13;
It’s possible that the range is limited and response time for the <code>SELECT</code> is acceptable, but it’s bad enough to warrant its own metric.</p>&#13;
&#13;
<p><code>Select_range_check</code> is similar to but worse than <code>Select_full_range_join</code>.&#13;
It’s easiest to explain with a simple query: <code>SELECT * FROM t1, t2 WHERE t1.id &gt; t2.id</code>.&#13;
When MySQL joins tables <code>t1</code> and <code>t2</code> (in that order), it does <em>range checks</em> on <code>t2</code>: for every value from <code>t1</code>, MySQL checks if it can use an index on <code>t2</code> to do a range scan or index merge.&#13;
Rechecking every value from <code>t1</code> is necessary because, given the query, MySQL cannot know <code>t1</code> values ahead of time.&#13;
But rather than do the worst possible execution plan—<code>Select_full_join</code>—MySQL keeps trying to use an index on <code>t2</code>.&#13;
In the <code>EXPLAIN</code> output, the <code>Extra</code> field for <code>t2</code> lists “Range checked for each record,” and <code>Select_range_check</code> is incremented once for the table.&#13;
The metric is <em>not</em> incremented for each range change; it’s incremented once to signal that a table was joined by doing range checks.</p>&#13;
&#13;
<p>Bad <code>SELECT</code> metrics should be zero or virtually zero (if you round down).&#13;
A few <code>Select_scan</code> or <code>Select_full_range_join</code> are inevitable, but the other two—<code>Select_full_join</code> and <code>Select_range_check</code>—should be found and fixed immediately if not zero.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Network Throughput" data-type="sect2"><div class="sect2" id="metrics-net">&#13;
<h2>Network Throughput</h2>&#13;
&#13;
<p>The MySQL protocol <a data-primary="spectra (MySQL server metrics)" data-secondary="network throughput" data-type="indexterm" id="idm45829110522016"/><a data-primary="network throughput" data-type="indexterm" id="idm45829110520992"/>is very efficient and rarely uses any noticeable amount of network bandwidth.&#13;
Usually, it’s the network affecting MySQL rather than MySQL affecting the network.&#13;
Nevertheless, it’s good to monitor network throughput as recorded by MySQL:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Bytes_sent</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Bytes_received</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Since these metrics count network bytes sent and received, respectively, convert the values to network units: Mbps or Gbps, whichever matches the link speed of the server running MySQL.&#13;
Gigabit links are most common, even in the cloud.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Metric graphing systems convert counters to rates by default, but you probably need to multiply these metrics by eight (8 bits per byte) and set the graph unit to bits to display as Mbps or Gbps.</p>&#13;
</div>&#13;
&#13;
<p>I have seen MySQL saturate a network only once.&#13;
The cause was related to a system variable that’s not usually a problem: <a href="https://oreil.ly/tboxy"><code>var.binlog_row_image</code></a>.&#13;
This system variable is related to replication that <a data-type="xref" href="ch07.html#ch07">Chapter 7</a> addresses in more detail, but the short version is: this system variable controls whether or not <code>BLOB</code> and <code>TEXT</code> columns are logged in the binary logs and replicated.&#13;
The default value is <code>full</code>, which logs and replicates <code>BLOB</code> and <code>TEXT</code> columns.&#13;
Normally, that’s not a problem, but one application created a perfect storm by having all of the following attributes at once:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Using MySQL as a queue</p>&#13;
</li>&#13;
<li>&#13;
<p>Huge <code>BLOB</code> values</p>&#13;
</li>&#13;
<li>&#13;
<p>Write-heavy</p>&#13;
</li>&#13;
<li>&#13;
<p>High throughput</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>These access patterns combined to replicate a small flood of data, causing major replication lag.&#13;
The solution was changing <code>var.binlog_row_image</code> to <code>noblob</code> to stop replicating the <code>BLOB</code> values, which didn’t need to be replicated.&#13;
This true story leads to the next spectrum: replication.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Replication" data-type="sect2"><div class="sect2" id="metrics-repl">&#13;
<h2>Replication</h2>&#13;
&#13;
<p><em>Lag</em> is <a data-primary="lag" data-type="indexterm" id="idm45829110502032"/>the bane of <a data-primary="spectra (MySQL server metrics)" data-secondary="replication" data-type="indexterm" id="idm45829110501168"/><a data-primary="replication" data-type="indexterm" id="idm45829110500176"/>replication: the delay between a write on the source MySQL instance and when that write is applied on a replica MySQL instance.&#13;
When replication (and the network) is working normally, replication lag is subsecond, limited only by network latency.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Before MySQL 8.0.22, the replica lag metric and command were <code>Sec​onds_​Behind_Master</code> and <code>SHOW SLAVE STATUS</code>, respectively.&#13;
As of MySQL 8.0.22, the metric and command are <code>Sec​onds_​Behind_Source</code> and <code>SHOW REPLICA STATUS</code>.&#13;
I use the current metric and command in this book.</p>&#13;
</div>&#13;
&#13;
<p>MySQL has an infamous gauge metric for replication lag: <code>Seconds_Behind_Source</code>.&#13;
This metric is infamous because it’s not wrong but it’s also not what you expect.&#13;
It can jump between zero and a high value, which is as amusing as it is confusing.&#13;
Consequently, the best practice is to ignore this metric and, instead, use a tool like <a href="https://oreil.ly/VMg4c"><code>pt-heartbeat</code></a> to measure true replication lag.&#13;
Then you have to configure your MySQL monitor software (or service) to measure and report <em>replication lag</em> from <code>pt-heartbeat</code>.&#13;
Since <code>pt-heartbeat</code> has been around for so long, some MySQL monitors support it natively; and there’s a good chance that the engineers who manage your MySQL instances are already using it.</p>&#13;
&#13;
<p>MySQL exposes one metric related to replication that is not infamous: <code>Binlog_cache_disk_use</code>.&#13;
<a data-type="xref" href="ch07.html#ch07">Chapter 7</a> clarifies the following details; for now, a high level explanation is sufficient.&#13;
For each client connection, a in-memory binary log cache buffers writes before they’re written to the binary log files—from which the writes replicate to replicas.&#13;
If the binary log cache is too small to hold all the writes for a transaction, the changes are written to disk and <code>Binlog_cache_disk_use</code> is incremented.&#13;
In moderation, this is acceptable, but it shouldn’t be frequent.&#13;
If it becomes frequent, you can alleviate it by increasing the binary log cache size: <a href="https://oreil.ly/0TEIJ"><code>var.binlog_cache_size</code></a>.</p>&#13;
&#13;
<p>From the example in the previous section, we know that  <code>var.binlog_row_image</code> affects the binary log cache, too: full row images can require a lot of space if the table has <code>BLOB</code> or <code>TEXT</code> columns.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data Size" data-type="sect2"><div class="sect2" id="metrics-data-size">&#13;
<h2>Data Size</h2>&#13;
&#13;
<p><a data-type="xref" href="ch03.html#ch03">Chapter 3</a> <a data-primary="spectra (MySQL server metrics)" data-secondary="data size" data-type="indexterm" id="spectra-data-size_index1"/><a data-primary="data size" data-type="indexterm" id="spectra-data-size_index2"/>explains why less data is more performance.&#13;
Monitoring data size is important because it’s common for databases to grow larger than expected.&#13;
If data growth is due to application growth—the application is becoming increasingly popular—then it’s a good problem to have, but it’s a problem nevertheless.</p>&#13;
&#13;
<p>It’s also easy to overlook because MySQL performance scales effortlessly as data grows, but not forever.&#13;
A database can grow from 10 GB to 300 GB—a 30x increase—and not encounter performance issues if queries and access patterns are optimized well.&#13;
But another 30x increase to 9 TB?&#13;
Not possible.&#13;
Even a 3x increase to 900 GB is asking too much—it could happen if the access patterns are exceptionally favorable, but don’t bet on it.</p>&#13;
&#13;
<p>MySQL exposes table sizes (and other table metadata) in an Information Schema table: <a href="https://oreil.ly/PqATu"><code>information_schema.tables</code></a>.&#13;
The query in <a data-type="xref" href="#db-size-query">Example 6-5</a> returns the size of each database in gigabytes.</p>&#13;
<div data-type="example" id="db-size-query">&#13;
<h5><span class="label">Example 6-5. </span>Database sizes (GB)</h5>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">SELECT</code>&#13;
  <code class="n">table_schema</code> <code class="k">AS</code> <code class="n">db</code><code class="p">,</code>&#13;
  <code class="n">ROUND</code><code class="p">(</code><code class="k">SUM</code><code class="p">(</code><code class="n">data_length</code> <code class="o">+</code> <code class="n">index_length</code><code class="p">)</code> <code class="o">/</code> <code class="mi">1073741824</code> <code class="p">,</code> <code class="mi">2</code><code class="p">)</code> <code class="k">AS</code> <code class="s1">'size_GB'</code>&#13;
<code class="k">FROM</code>&#13;
  <code class="n">information_schema</code><code class="p">.</code><code class="n">tables</code>&#13;
<code class="k">GROUP</code> <code class="k">BY</code> <code class="n">table_schema</code><code class="p">;</code></pre></div>&#13;
&#13;
<p>The query in <a data-type="xref" href="#tbl-size-query">Example 6-6</a> returns the size of each table in gigabytes.</p>&#13;
<div data-type="example" id="tbl-size-query">&#13;
<h5><span class="label">Example 6-6. </span>Table sizes (GB)</h5>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">SELECT</code>&#13;
  <code class="n">table_schema</code> <code class="k">AS</code> <code class="n">db</code><code class="p">,</code>&#13;
  <code class="k">table_name</code> <code class="k">as</code> <code class="n">tbl</code><code class="p">,</code>&#13;
  <code class="n">ROUND</code><code class="p">((</code><code class="n">data_length</code> <code class="o">+</code> <code class="n">index_length</code><code class="p">)</code> <code class="o">/</code> <code class="mi">1073741824</code> <code class="p">,</code> <code class="mi">2</code><code class="p">)</code> <code class="k">AS</code> <code class="s1">'size_GB'</code>&#13;
<code class="k">FROM</code>&#13;
  <code class="n">information_schema</code><code class="p">.</code><code class="n">tables</code>&#13;
<code class="k">WHERE</code>&#13;
      <code class="n">table_type</code> <code class="o">=</code> <code class="s1">'BASE TABLE'</code>&#13;
  <code class="k">AND</code> <code class="n">table_schema</code> <code class="o">!=</code> <code class="s1">'performance_schema'</code><code class="p">;</code></pre></div>&#13;
&#13;
<p>There is no standard for database and table size metrics.&#13;
Query and aggregate values from <code>information_schema.tables</code> to suit your needs.&#13;
At a bare minimum, collect database sizes (<a data-type="xref" href="#db-size-query">Example 6-5</a>) every hour.&#13;
It’s better to be more precise and collect table sizes every 15 minutes.</p>&#13;
&#13;
<p>Be sure that, wherever you store or send MySQL metrics, you can retain data size metrics for at least a year.&#13;
Near-term data growth trending is used to estimate when the disk will run out of space; or, in the cloud, when more storage will need to be provisioned.&#13;
Long-term data growth trending is used to estimate when sharding (<a data-type="xref" href="ch05.html#ch05">Chapter 5</a>) becomes necessary, as covered in <a data-type="xref" href="ch05.html#ch05-ai">“Practice: Four-Year Fit”</a>.<a data-primary="spectra (MySQL server metrics)" data-secondary="data size" data-startref="spectra-data-size_index1" data-type="indexterm" id="idm45829110347184"/><a data-primary="data size" data-startref="spectra-data-size_index2" data-type="indexterm" id="idm45829110345904"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="InnoDB" data-type="sect2"><div class="sect2" id="metrics-innodb">&#13;
<h2>InnoDB</h2>&#13;
&#13;
<p><a href="https://oreil.ly/4b5qP">InnoDB</a> is complex.</p>&#13;
&#13;
<p>However, <a data-primary="spectra (MySQL server metrics)" data-secondary="InnoDB" data-type="indexterm" id="spectra-InnoDB"/><a data-primary="InnoDB" data-type="indexterm" id="idm45829110340896"/>since it is the default MySQL storage engine, we must steel ourselves to embrace it.&#13;
A deep dive is not necessary—or even possible within the limits of this book.&#13;
Although this section is long, it barely breaks the surface of InnoDB internals.&#13;
Nevertheless, the following InnoDB metrics reveal some of the inner workings of the storage engine responsible for reading and writing data.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="History list length (metric)" data-type="sect3"><div class="sect3" id="metrics-hll">&#13;
<h3>History list length (metric)</h3>&#13;
&#13;
<p>History list length (HLL) <a data-primary="InnoDB" data-secondary="history list length (HLL)" data-type="indexterm" id="idm45829110337744"/><a data-primary="history list length (HLL)" data-type="indexterm" id="idm45829110336704"/>is a curious metric because every engineer that uses MySQL learns what it <em>means</em>, but very few know what it <em>is</em>.&#13;
When HLL increases significantly over a period of minutes or hours, it means that InnoDB is keeping a significant number of old row versions instead of purging them because one or more long-running transaction has not committed or was abandoned without being rolled back due to an undetected lost client connection.&#13;
All of that, which I explain later in <a data-type="xref" href="ch08.html#hll">“History List Length”</a>, is revealed by one gauge metric:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.trx_rseg_history_len</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>A normal value for <code>innodb.trx_rseg_history_len</code> is less than 1,000.&#13;
You should monitor and alert if HLL is greater than 100,000.&#13;
Contrary to <a data-type="xref" data-xrefstyle="select:nopage" href="#thresholds">“Wild Goose Chase (Thresholds)”</a> and <a data-type="xref" data-xrefstyle="select:nopage" href="#alert-on">“Alert on User Experience and Objective Limits”</a>  later in this chapter, this is a reliable threshold and actionable alert.&#13;
The action: find and terminate the long-running or abandoned transaction.</p>&#13;
&#13;
<p>History list length does not directly affect performance, but it is a harbinger of trouble—do not ignore it.&#13;
The trouble relates to the fact that, since InnoDB is a transactional storage engine, every query on an InnoDB table is a transaction.&#13;
Transactions incur overhead, and the HLL metric reveals when a long-running or abandoned transaction is causing InnoDB to handle an unreasonable amount of overhead.&#13;
Some overhead is necessary—even beneficial—but too much amounts to waste, and waste is antithetical to performance.</p>&#13;
&#13;
<p>There’s so much more to say about transactions and HLL that it won its own chapter: <a data-type="xref" href="ch08.html#ch08">Chapter 8</a>.&#13;
For now, let’s stay focused on metrics because we’ve only begun with InnoDB.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deadlock" data-type="sect3"><div class="sect3" id="idm45829110326400">&#13;
<h3>Deadlock</h3>&#13;
&#13;
<p>A deadlock <a data-primary="InnoDB" data-secondary="deadlock" data-type="indexterm" id="idm45829110325216"/><a data-primary="deadlock" data-type="indexterm" id="idm45829110324208"/>occurs when two (or more) transactions hold row locks that the other transaction needs.&#13;
For example, transaction <em>A</em> holds a lock on row 1 and needs a lock on row 2, and transaction <em>B</em> holds a lock on row 2 and needs a lock on row 1.&#13;
MySQL automatically detects and rolls back one transaction to resolve the deadlock, and increments one metric:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.lock_deadlocks</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Deadlocks should not occur.&#13;
A prevalence of deadlocks is related to the concurrency access pattern trait (see <a data-type="xref" href="ch04.html#ap-concurrency">“Concurrency”</a>).&#13;
Highly concurrent data access must be designed (in the application) to avoid deadlocks by ensuring that different transactions accessing the same rows (or nearby rows) examine the rows in roughly the same order.&#13;
In the earlier example of transaction <em>A</em> and transaction <em>B</em>, they access the same two rows in opposite order, which can lead to a deadlock when the transactions execute at the same time.&#13;
To learn more about deadlocks, read <a href="https://oreil.ly/UpX0r">“Deadlocks in InnoDB”</a> in the MySQL manual.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Row lock" data-type="sect3"><div class="sect3" id="idm45829110316992">&#13;
<h3>Row lock</h3>&#13;
&#13;
<p>Row lock <a data-primary="InnoDB" data-secondary="row locking" data-type="indexterm" id="InnoDB-row-locking_index1"/><a data-primary="row locking" data-type="indexterm" id="InnoDB-row-locking_index2"/>metrics reveal <em>lock contention</em>: how quickly (or not) queries acquire row locks to write data.&#13;
The most fundamental row lock metrics are:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.lock_row_lock_time</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.lock_row_lock_current_waits</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.lock_row_lock_waits</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.lock_timeouts</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The first metric, <code>innodb.lock_row_lock_time</code>, is a rare type: the total number of milliseconds spent acquiring row locks.&#13;
It’s in the class of response time metrics (see <a data-type="xref" href="#field-response-time">“Response Time”</a>), but unlike <a data-type="xref" href="#metrics-qrt">“Query Response Time”</a>, it is collected as a running total rather than a histogram.&#13;
Consequently, it’s not possible to report <code>innodb.lock_row_lock_time</code> as a percentile, which would be ideal.&#13;
And reporting it as a rate (see <a data-type="xref" href="#field-rate">“Rate”</a>) is nonsensical: milliseconds per second.&#13;
Instead, this metric must be reported as a difference: if 500 milliseconds at time T1 and 700 milliseconds at time T2, then report T2 value – T1 value = 200 ms.&#13;
(Use maximum for the chart rollup function.&#13;
Don’t average the data points because it’s better to see the worst case.)&#13;
As a response time metric, lower is better.&#13;
The value of <code>innodb.lock_row_lock_time</code> cannot be zero (unless the workload is read-only and never needs to acquire a single row lock) because it takes a nonzero amount of time to acquire locks.&#13;
The goal, as always, is that the metric is normal and stable.&#13;
When it’s not, the other row lock metrics will not be normal either.</p>&#13;
&#13;
<p><code>innodb.lock_row_lock_current_waits</code> is a gauge metric for the current number of queries waiting to acquire a row lock.&#13;
<code>innodb.lock_row_lock_waits</code> is a count of the number of queries that waited to acquire a row.&#13;
The two variables are essentially the same: the former is a current gauge, and the latter is a historical counter and rate.&#13;
When the rate of row lock waits increases, it’s a sure sign of trouble because MySQL does not wait by accident: something must cause it to wait.&#13;
In this case, the cause will be concurrent queries accessing the same (or nearby) rows.</p>&#13;
&#13;
<p><code>innodb.lock_timeouts</code> is incremented when a row lock wait times out.&#13;
The default row lock wait timeout is 50 seconds, configured by <a href="https://oreil.ly/4kCLg"><code>var.innodb_lock_wait_timeout</code></a>, and applies <em>per row lock</em>.&#13;
This is far too long for any normal application to wait; I advise a much lower value: 10 seconds or less.</p>&#13;
&#13;
<p>InnoDB locking is sophisticated and nuanced.&#13;
As a result, lock contention is <em>not</em> a common problem unless the workload exhibits three particular access patterns:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Write-heavy (<a data-type="xref" href="ch04.html#ap-read-write">“Read/Write”</a>)</p>&#13;
</li>&#13;
<li>&#13;
<p>High throughput (<a data-type="xref" href="ch04.html#ap-throughput">“Throughput”</a>)</p>&#13;
</li>&#13;
<li>&#13;
<p>High concurrency (<a data-type="xref" href="ch04.html#ap-concurrency">“Concurrency”</a>)</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>That would be a very particular application and workload.&#13;
But lock contention can become a problem for any application and workload (even with low throughput and concurrency), so always monitor rock lock metrics.<a data-primary="InnoDB" data-secondary="row locking" data-startref="InnoDB-row-locking_index1" data-type="indexterm" id="idm45829110291616"/><a data-primary="row locking" data-startref="InnoDB-row-locking_index2" data-type="indexterm" id="idm45829110290304"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data throughput" data-type="sect3"><div class="sect3" id="idm45829110289216">&#13;
<h3>Data throughput</h3>&#13;
&#13;
<p>Data throughput <a data-primary="InnoDB" data-secondary="data throughput" data-type="indexterm" id="idm45829110287840"/><a data-primary="data throughput" data-type="indexterm" id="idm45829110286832"/>in bytes per seconds is measured by two metrics:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Innodb_data_read</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Innodb_data_written</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Data throughput is rarely an issue: SSD is fast; PCIe and NVMe made it even faster.&#13;
Regardless, monitoring data throughput is a best practice because storage throughput is limited, especially in the cloud.&#13;
Do not expect to achieve published storage throughput rates because published rates are measured under ideal conditions: data straight to (or from) disk.&#13;
InnoDB is super fast and efficient, but it’s still a complex layer of software between the data and the disk that inherently precludes achieving published storage throughput rates.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Be careful about throughput in the cloud: storage is unlikely to be locally attached, which limits throughput to network speeds.&#13;
1 Gbps equals 125 MB/s, which is throughput similar to spinning disks.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="IOPS" data-type="sect3"><div class="sect3" id="metrics-iops">&#13;
<h3>IOPS</h3>&#13;
&#13;
<p>InnoDB <a data-primary="InnoDB" data-secondary="IOPS" data-type="indexterm" id="IOPS_index1"/><a data-primary="IOPS" data-type="indexterm" id="IOPS_index2"/>has a deep and sometimes complicated relationship with storage I/O capacity, measured in IOPS.&#13;
But first, the easy part: InnoDB read and write IOPS are counted by two metrics, respectively:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.os_data_reads</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.os_data_writes</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>These metrics are counters, so like other counters, they are converted to and expressed as rates by metric graphing systems.&#13;
Be sure to set the graph unit to IOPS for each.</p>&#13;
&#13;
<p>The performance raison d’être of InnoDB is to optimize and reduce storage I/O.&#13;
Although high IOPS are impressive from an engineering point of view, they are the bane of performance because storage is slow.&#13;
But storage is required for durability—persisting data changes to disk—so InnoDB goes to great lengths to be fast <em>and</em> durable.&#13;
Consequently, as in <a data-type="xref" href="ch03.html#less-qps-is-better">“Less QPS Is Better”</a>, fewer IOPS are better.</p>&#13;
&#13;
<p>But don’t underutilize IOPS, either.&#13;
If your company runs its own hardware, the maximum number of storage IOPS is determined by the storage device—check the device specifications, or ask the engineers who manage the hardware.&#13;
In the cloud, storage IOPS are allocated or provisioned, so it’s usually easier to tell the maximum because you purchase the IOPS—check the storage settings, or ask the cloud provider.&#13;
If InnoDB never uses more than 2,000 IOPS, for example, then don’t purchase (or provision) 40,000 IOPS: InnoDB simply won’t use the excess IOPS.&#13;
By contrast, if InnoDB constantly uses the maximum number of storage IOPS, then either the application workload needs to be optimized to reduce storage I/O (see Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch01.html#ch01">1</a>–<a data-type="xref" data-xrefstyle="select:labelnumber" href="ch05.html#ch05">5</a>), or InnoDB legitimately needs more IOPS.</p>&#13;
&#13;
<p>InnoDB I/O capacity for <em>background tasks</em> is largely configured by <a href="https://oreil.ly/zU6iW"><code>var​.inno​db_​io_capacity</code></a> and <a href="https://oreil.ly/LiilY"><code>var.innodb_io_capacity_max</code></a>, two system variables that default to 200 and 2,000 IOPS, respectively.&#13;
(There are other variables, but I must gloss over them to stay focused on metrics.&#13;
To learn more, read <a href="https://oreil.ly/G9Bcw">“Configuring InnoDB I/O Capacity”</a> in the MySQL manual.)&#13;
Background tasks include page flushing, change buffer merging, and more.&#13;
In this book, I cover only page flushing, which is arguably the single most important background task.&#13;
Limiting background task storage I/O ensures that InnoDB does not overwhelm the server.&#13;
It also allows InnoDB to optimize and stabilize storage I/O rather than bombard the storage device with erratic access.&#13;
By contrast, foreground tasks do not have any configurable I/O capacities or limits: they use as many IOPS as necessary and available.&#13;
The primary foreground task is executing queries, but this does not mean queries use high or excessive IOPS because, remember, the performance raison d’être of InnoDB is to optimize and reduce storage I/O.&#13;
For reads, the buffer pool purposefully optimizes and reduces IOPS.&#13;
For writes, page flushing algorithms and the transaction log purposefully optimize and reduce storage I/O.&#13;
The following sections reveal how.</p>&#13;
&#13;
<p>InnoDB can achieve high IOPS, but can the application?&#13;
Probably not because there are many layers between the application and the IOPS that preclude the former from achieving a high number of the latter.&#13;
In my experience, applications use hundreds to thousands of IOPS, and exceptionally optimized applications that are “going viral” push around 10,000 IOPS on a single MySQL instance.&#13;
Recently, I was benchmarking MySQL in the cloud and hit a ceiling at 40,000 IOPS.&#13;
The cloud provider publishes 80,000 IOPS as the maximum and allows me to provision that, but their storage system is capped at 40,000 IOPS.&#13;
Point being: InnoDB can achieve high IOPS, but everything around it is a different question.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45829110262000">&#13;
<h5>Millions of IOPS</h5>&#13;
<p>High end storage is capable of over one million IOPS.&#13;
This class of storage is used in bare metal (physical) servers designed to host many virtual servers.&#13;
The same is true for high-end CPUs and memory: it’s too much hardware for one application.</p>&#13;
</div></aside>&#13;
&#13;
<p>This section is only a primer on InnoDB I/O because it underlies the final three InnoDB spectra that consume IOPS: <a data-type="xref" href="#metrics-buff-pool">“Buffer pool efficiency”</a>, <a data-type="xref" href="#metrics-page-flushing">“Page flushing”</a>, and <a data-type="xref" href="#metrics-trx-log">“Transaction log”</a>.</p>&#13;
&#13;
<p>To learn more InnoDB I/O, start by reading <a href="https://oreil.ly/w9MOg">“Configuring InnoDB I/O Capacity”</a> in the MySQL manual.&#13;
To really dive into the nitty-gritty details of InnoDB I/O, read an illuminating three-part blog post by renowned MySQL experts Yves Trudeau <a data-primary="Trudeau, Yves" data-type="indexterm" id="idm45829110255728"/>and Francisco <a data-primary="Bordenhave, Francisco" data-type="indexterm" id="idm45829110254928"/>Bordenave: <a href="https://oreil.ly/q0L61">“Give Love to Your SSDs: Reduce innodb_io_capacity_max!”</a>, <a href="https://oreil.ly/ZY2Xe">“InnoDB Flushing in Action for Percona Server for MySQL”</a>, and <a href="https://oreil.ly/P03EX">“Tuning MySQL/InnoDB Flushing for a Write-Intensive Workload”</a>.&#13;
But finish this chapter first because it’s a great foundation for those blog posts.</p>&#13;
&#13;
<p>InnoDB works with data in memory, not on disk.&#13;
It reads data from disk when necessary, and it writes data to disk to make changes durable, but these are lower level operations into which the next three sections delve.&#13;
At a higher level, InnoDB works with data in memory because storage is too slow—even with a million IOPS.&#13;
Consequently, there is not a direct correlation between queries, rows, and IOPS.&#13;
Writes always consume IOPS (for durability).&#13;
Reads can execute without consuming any IOPS, but it depends on buffer pool efficiency.<a data-primary="InnoDB" data-secondary="IOPS" data-startref="IOPS_index1" data-type="indexterm" id="idm45829110251216"/><a data-primary="IOPS" data-startref="IOPS_index2" data-type="indexterm" id="idm45829110249968"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Buffer pool efficiency" data-type="sect3"><div class="sect3" id="metrics-buff-pool">&#13;
<h3>Buffer pool efficiency</h3>&#13;
&#13;
<p>The InnoDB buffer pool <a data-primary="InnoDB" data-secondary="buffer pool efficiency" data-type="indexterm" id="buffer-pool-efficiency_index1"/><a data-primary="buffer pool efficiency" data-type="indexterm" id="buffer-pool-efficiency_index2"/>is an <em>in-memory</em> cache of table data and other internal data structures.&#13;
From <a data-type="xref" href="ch02.html#tables-are-indexes">“InnoDB Tables Are Indexes”</a>, you know that the buffer pool contains index pages—more on pages in the next section.&#13;
InnoDB certainly understands rows, but internally it’s far more concerned with pages.&#13;
At this depth of MySQL performance, the focus changes from rows to pages.</p>&#13;
&#13;
<p>At a high level, InnoDB accesses (reads and writes) all data by pages in the buffer pool.&#13;
(Low-level writes are more complicated and addressed in the last InnoDB <span class="keep-together">section</span>: <a data-type="xref" href="#metrics-trx-log">“Transaction log”</a>.)&#13;
If data is not in the buffer pool when accessed, InnoDB reads it from storage and saves it in the buffer pool.</p>&#13;
&#13;
<p><em>Buffer pool efficiency</em> is the percentage of data accessed from memory, calculated from two metrics:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>Innodb_buffer_pool_read_request</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>Innodb_buffer_pool_reads</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><code>Innodb_buffer_pool_read_request</code> counts all requests to access data in the buffer pool.&#13;
If the requested data is <em>not</em> in memory, InnoDB increments <code>Inno​db_​buf​fer_​pool_reads</code> and loads the data from disk.&#13;
Buffer pool efficiency equals (<code>Innodb_buffer_pool_read_request</code> / <code>Innodb_buffer_pool_reads</code>) × 100.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The word <em>read</em> in these metrics does not mean <code>SELECT</code>.&#13;
InnoDB reads data from the buffer pool for all queries: <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>, and <code>SELECT</code>.&#13;
For example, on <code>UPDATE</code>, InnoDB reads the row from the buffer pool.&#13;
If not in the buffer pool, it loads the row from disk into the buffer pool.</p>&#13;
</div>&#13;
&#13;
<p>Buffer pool efficiency will be very low when MySQL starts.&#13;
This is normal; it’s called a <em>cold buffer pool</em>.<a data-primary="cold buffer pool" data-type="indexterm" id="idm45829110229472"/>&#13;
Loading data warms the buffer pool—like throwing logs on a fire.&#13;
It usually takes several minutes to fully warm the buffer pool, which is indicated when buffer pool efficiency reaches its normal and stable value.</p>&#13;
&#13;
<p>Buffer pool efficiency should be extremely close to 100%—ideally 99.0% or greater—but don’t fixate on the value.&#13;
Technically, this metric is a cache hit ratio, but that’s not how it’s used.&#13;
A cache hit ratio reveals little beyond the metric: values are cached, or they’re not.&#13;
On the contrary, buffer pool efficiency reveals how well InnoDB is able to keep frequently accessed data—the working set—in memory while balancing speed and durability.&#13;
To put it colorfully, buffer pool efficiency is how well InnoDB can keep a match lit in a hurricane.&#13;
The working set is the flame; durability is the rain (it dampens throughput);<sup><a data-type="noteref" href="ch06.html#idm45829110227344" id="idm45829110227344-marker">5</a></sup> the application is the wind.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>In a bygone era, performance equated to cache hit ratios.&#13;
Today, that is no longer true: performance is query response time.&#13;
If buffer pool efficiency is extremely low but response time is great, then performance is great.&#13;
That probably won’t happen, but the point is not to lose focus—recall <a data-type="xref" href="ch01.html#north-star">“North Star”</a>.</p>&#13;
</div>&#13;
&#13;
<p>If total data size is less than available memory, then all data can fit in the buffer pool at once.&#13;
(Buffer pool size is configured by <a href="https://oreil.ly/N4lnI"><code>var.innodb_buffer_pool_size</code></a>.&#13;
Or, as of MySQL 8.0.3, enabling <a href="https://oreil.ly/I5KaC"><code>var.innodb_dedicated_server</code></a> automatically configures buffer pool size and other related system variables.)&#13;
In this case, buffer pool efficiency is a nonissue and performance bottlenecks—if any—will occur in CPU or storage (since all data is in memory).&#13;
But this case is the exception, not the norm.&#13;
The norm is total data size being <em>far greater</em> than available memory.&#13;
In this (normal) case, buffer pool efficiency has three primary influences:</p>&#13;
<dl>&#13;
<dt>Data access</dt>&#13;
<dd>&#13;
<p>Data access brings data into the buffer pool.&#13;
The data age access pattern trait (see <a data-type="xref" href="ch04.html#ap-data-age">“Data Age”</a>) is the primary influence because only new data needs to be loaded into the buffer pool.</p>&#13;
</dd>&#13;
<dt>Page flushing</dt>&#13;
<dd>&#13;
<p>Page flushing allows data to be evicted from the buffer pool.&#13;
Page flushing is necessary for new data to be loaded into the buffer pool. The next section goes into more detail.</p>&#13;
</dd>&#13;
<dt>Available memory</dt>&#13;
<dd>&#13;
<p>The more data that InnoDB keeps in memory, the less it needs to load or flush data.&#13;
In the exceptional case previously mentioned, when all data fits in memory, buffer pool efficiency is a nonissue.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Buffer pool efficiency reveals the combined effect of those three influences.&#13;
As a combined effect, it cannot pinpoint one cause.&#13;
If its value is lower than normal, the cause could be one, two, or all three influences.&#13;
You must analyze all three to determine which is the greatest <em>or</em> the most feasible to change.&#13;
For example, as detailed in <a data-type="xref" href="ch04.html#ch04">Chapter 4</a>, changing access patterns is a best practice for improving performance, but if you’re page-deep in MySQL performance, you’ve probably already done that.&#13;
In that case, more memory or faster storage (more IOPS) might be more feasible—and more justified since you’ve already optimized the workload.&#13;
Although buffer pool efficiency cannot give you answers, it tells you where to look: access patterns (especially <a data-type="xref" href="ch04.html#ap-data-age">“Data Age”</a>), page flushing, and memory size.</p>&#13;
&#13;
<p>InnoDB buffer pool efficiency is the tip of the iceberg.&#13;
Underneath, page flushing is the internal machinery that keeps it afloat.<a data-primary="InnoDB" data-secondary="buffer pool efficiency" data-startref="buffer-pool-efficiency_index1" data-type="indexterm" id="idm45829110211552"/><a data-primary="buffer pool efficiency" data-startref="buffer-pool-efficiency_index2" data-type="indexterm" id="idm45829110210240"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Page flushing" data-type="sect3"><div class="sect3" id="metrics-page-flushing">&#13;
<h3>Page flushing</h3>&#13;
&#13;
<p>This spectrum is large and complicated, so it’s further subdivided into <em>Pages</em> and <em>Flushing</em>, which are inextricable.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pages" data-type="sect4"><div class="sect4" id="pg-pages">&#13;
<h4>Pages</h4>&#13;
&#13;
<p>As <a data-primary="InnoDB" data-secondary="pages" data-type="indexterm" id="pages_index1"/><a data-primary="pages (InnoDB)" data-type="indexterm" id="pages_index2"/>mentioned in the previous section, the buffer pool contains index pages.&#13;
There are four types of pages:</p>&#13;
<dl>&#13;
<dt>Free pages</dt>&#13;
<dd>&#13;
<p>These <a data-primary="free pages" data-type="indexterm" id="free-pages"/>contain no data; InnoDB can load new data into them.</p>&#13;
</dd>&#13;
<dt>Data pages</dt>&#13;
<dd>&#13;
<p>These <a data-primary="data pages" data-type="indexterm" id="data-pages"/>contain data that has not been modified; also called <em>clean pages</em>.</p>&#13;
</dd>&#13;
<dt>Dirty pages</dt>&#13;
<dd>&#13;
<p>These contain <a data-primary="dirty pages" data-type="indexterm" id="idm45829110195088"/>modified data that has not been flushed to disk.</p>&#13;
</dd>&#13;
<dt>Misc pages</dt>&#13;
<dd>&#13;
<p>These contain <a data-primary="misc pages" data-type="indexterm" id="idm45829110192880"/>miscellaneous internal data not covered in this book.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Since InnoDB keeps the buffer pool full of data, monitoring the number of data pages is not necessary.&#13;
Free and dirty pages are the most revealing with respect to performance, especially when viewed with flushing metrics in the next section.&#13;
Three gauges and one counter (the last metric) reveal how many free and dirty pages are sloshing around in the buffer pool:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.buffer_pool_pages_total</code></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.buffer_pool_pages_dirty</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.buffer_pool_pages_free</code></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.buffer_pool_wait_free</code></p>&#13;
</li>&#13;
</ul>&#13;
</li>&#13;
</ul>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><code>innodb.buffer_pool_pages_total</code> is the total number of pages in the buffer pool (total page count), which depends on the buffer pool size (<a href="https://oreil.ly/fXHQ4"><code>var​.inno​db_​buffer_pool_size</code></a>).&#13;
(Technically, this is a gauge metric because, as of MySQL 5.7.5, the InnoDB buffer pool size is dynamic.&#13;
But frequently changing the buffer pool size is not common because it’s sized according to system memory, which cannot change quickly—even cloud instances require a few minutes to resize.)&#13;
Total page count calculates the percentage of free and dirty pages: <code>innodb.buffer_pool_pages_free</code> and <code>innodb.buffer_pool_pages_dirty</code> divided by total pages, respectively.&#13;
Both percentages are gauge metrics, and the values change frequently due to page flushing.</p>&#13;
&#13;
<p>To ensure that free pages are available when needed, InnoDB maintains a nonzero balance of free pages that I call the <em>free page target</em>.&#13;
The free page target <a data-primary="free page target" data-type="indexterm" id="free-page-target-ch6"/>is equal to the product of two system variables:&#13;
the system variable <a href="https://oreil.ly/TG9hj"><code>var.innodb_lru_scan_depth</code></a> multiplied by <a href="https://oreil.ly/srIHw"><code>var.innodb_buffer_pool_instances</code></a>.&#13;
The name of the former system variable is somewhat misleading, but it configures the number of free pages that InnoDB maintains in <em>each</em> buffer pool instance; the default is 1024 free pages.&#13;
Until now, I have written about <em>the buffer pool</em> as one logical part of InnoDB.&#13;
Under the hood, the buffer pool is divided into multiple <em>buffer pool instances</em>, each with its own internal data structures to reduce contention under heavy load.&#13;
The default for <code>var.innodb_buffer_pool_instances</code> is 8 (or 1 if the buffer pool size is less than 1 GB).&#13;
Therefore, with defaults for both system variables, InnoDB maintains 1024 × 8 = 8192 free pages.&#13;
Free pages should hover around the free page target.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Reducing <code>var.innodb_lru_scan_depth</code> is a best practice because, with default values, it yields 134 MB of free page size: 8192 free pages × 16 KB/page = 134 MB.&#13;
That is excessive given that rows are typically hundreds of bytes.&#13;
It’s more efficient for free pages <a data-primary="waits" data-secondary="free page" data-type="indexterm" id="idm45829110174208"/>to be as low as possible without hitting zero and incurring free page waits (explained in the next paragraph).&#13;
It’s good to be aware of this, but it’s MySQL tuning, which is beyond the scope of this book.&#13;
The default does not hinder performance; MySQL experts just abhor inefficiency.</p>&#13;
</div>&#13;
&#13;
<p>If free pages are consistently near zero (below the free page target), that’s fine as long as <code>innodb.buffer_pool_wait_free</code> remains zero.&#13;
When InnoDB needs a free page but none is available, it increments <code>innodb.buffer_pool_wait_free</code> and waits.&#13;
This is called a <em>free page wait</em> and it should be exceptionally rare—even when the buffer pool is full of data—because InnoDB actively maintains the free page target.&#13;
But under very heavy load, it might not be able to flush and free pages fast enough.&#13;
Simply put: InnoDB is reading new data faster than it can flush old data.&#13;
Presuming that the workload is already optimized, there are three solutions to free page waits:</p>&#13;
<dl>&#13;
<dt>Increase free page target</dt>&#13;
<dd>&#13;
<p>If your storage can provide more IOPS (or you can provision more IOPS in the cloud), then increasing <code>var.innodb_lru_scan_depth</code> causes InnoDB to flush and free more pages, which requires more IOPS (see <a data-type="xref" href="#metrics-iops">“IOPS”</a>).</p>&#13;
</dd>&#13;
<dt>Better storage system</dt>&#13;
<dd>&#13;
<p>If your storage cannot provide more IOPS, upgrade to better storage, then increase the free page target.</p>&#13;
</dd>&#13;
<dt>More memory</dt>&#13;
<dd>&#13;
<p>The more memory, the bigger the buffer pool, and the more pages can fit in memory without needing to flush and evict old pages to load new pages.&#13;
There’s one more detail about free page waits that I clarify later when explaining LRU flushing.</p>&#13;
</dd>&#13;
</dl>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Remember from <a data-type="xref" href="#metrics-buff-pool">“Buffer pool efficiency”</a>: <em>read</em> doesn’t mean <code>SELECT</code>.&#13;
InnoDB reads new data from the buffer pool for all queries: <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>, and <code>SELECT</code>.&#13;
When data is accessed but not in the buffer pool (in memory), InnoDB reads it from disk.</p>&#13;
</div>&#13;
&#13;
<p>If free pages are consistently much higher than the free page target, or never decrease to the target, then the buffer pool is too large.&#13;
For example, 50 GB of data fills only 39% of 128 GB of RAM.&#13;
MySQL is optimized to use only the memory that it needs, so giving it an overabundance of memory will not increase performance—MySQL simply won’t use the excess memory.&#13;
Don’t waste <a data-primary="free page target" data-startref="free-page-target-ch6" data-type="indexterm" id="idm45829110158528"/>memory.</p>&#13;
&#13;
<p>Dirty pages <a data-primary="dirty pages" data-type="indexterm" id="idm45829110157008"/>as a percentage of total pages varies between 10% and 90% by default.&#13;
Although dirty pages contain modified data that has not been flushed to disk, the data changes have been flushed to disk in the transaction log—more on this in the next two sections.&#13;
Even with 90% dirty pages, all data changes are guaranteed durable—persisted to disk.&#13;
It’s completely normal to have a high percentage of dirty pages.&#13;
In fact, it’s expected unless the workload is exceptionally read-heavy (recall access pattern trait <a data-type="xref" href="ch04.html#ap-read-write">“Read/Write”</a>) and simply does not modify data very often.&#13;
(In this case, I would consider whether another data store is better suited to the workload.)</p>&#13;
&#13;
<p>Since a high percentage of dirty pages is expected, this metric is used to corroborate other metrics related to page flushing (next section), the transaction log (<a data-type="xref" href="#metrics-trx-log">“Transaction log”</a>), and disk I/O (<a data-type="xref" href="#metrics-iops">“IOPS”</a>).&#13;
For example, writing data causes dirty pages, so a spike in dirty pages corroborates a spike in IOPS and transaction log metrics.&#13;
But a spike in IOPS without a corresponding spike in dirty pages cannot be caused by writes; it must be another issue—maybe an engineer manually executed an ad hoc query that dredged up a mass of old data that hadn’t seen the light of day in eons, and now InnoDB is reading it from disk in a maelstrom of IOPS.&#13;
Ultimately, dirty pages rise and fall with the gentle tides of page flushing.<a data-primary="InnoDB" data-secondary="pages" data-startref="pages_index1" data-type="indexterm" id="idm45829110151888"/><a data-primary="pages (InnoDB)" data-startref="pages_index2" data-type="indexterm" id="idm45829110150672"/><a data-primary="free pages" data-startref="free-pages" data-type="indexterm" id="idm45829110149728"/><a data-primary="data pages" data-startref="data-pages" data-type="indexterm" id="idm45829110148784"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Page flushing" data-type="sect4"><div class="sect4" id="pg-flushing">&#13;
<h4>Page flushing</h4>&#13;
&#13;
<p><em>Page flushing</em> cleans <a data-primary="InnoDB" data-secondary="page flushing" data-type="indexterm" id="page-flushing_index1"/><a data-primary="page flushing" data-type="indexterm" id="page-flushing_index2"/>dirty pages by writing the data modifications to disk.&#13;
Page flushing serves three closely related purposes: durability, checkpointing, and page eviction.&#13;
For simplicity, this section focuses on page flushing with respect to page eviction.&#13;
<a data-type="xref" href="#metrics-trx-log">“Transaction log”</a> clarifies how page flushing serves durability and checkpointing.</p>&#13;
&#13;
<p>From <a data-type="xref" href="#metrics-buff-pool">“Buffer pool efficiency”</a>, you know that page flushing makes space for new data to be loaded into the buffer pool.&#13;
More specifically, page flushing makes dirty pages clean, and clean pages can be evicted from the buffer pool.&#13;
Thus, the circle of page life is complete:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A free page becomes a clean (data) page when data is loaded</p>&#13;
</li>&#13;
<li>&#13;
<p>A clean page becomes a dirty page when its data is modified</p>&#13;
</li>&#13;
<li>&#13;
<p>A dirty page becomes a clean page again when the data modifications are flushed</p>&#13;
</li>&#13;
<li>&#13;
<p>A clean page becomes a free page again when it’s evicted from the buffer pool</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The implementation of page flushing is complex and varies among distributions (Oracle MySQL, Percona Server, <a data-primary="Percona Server" data-secondary="page flushing" data-type="indexterm" id="idm45829110135552"/>and MariaDB <a data-primary="MariaDB" data-type="indexterm" id="idm45829110134448"/>Server), so you might want to reread the following information to fully absorb the many intricate details.&#13;
<a data-type="xref" href="#page-flushing">Figure 6-6</a> depicts the high-level components and flow of InnoDB page flushing from committing transactions in the transaction log (at top) to flushing and evicting pages from the buffer pool (at bottom).</p>&#13;
&#13;
<p>Figuratively, InnoDB page flushing works top to bottom in <a data-type="xref" href="#page-flushing">Figure 6-6</a>, but I’m going to explain it from the bottom up.&#13;
In the buffer pool, dirty pages <a data-primary="dirty pages" data-type="indexterm" id="dirty-pages"/>are dark, clean (data) pages are white, and free pages have a dotted outline.</p>&#13;
&#13;
<figure><div class="figure" id="page-flushing">&#13;
<img alt="emsp 0606" src="assets/emsp_0606.png"/>&#13;
<h6><span class="label">Figure 6-6. </span>InnoDB page flushing</h6>&#13;
</div></figure>&#13;
&#13;
<p>Dirty pages are recorded in two internal lists (for each buffer pool instance):</p>&#13;
<dl>&#13;
<dt>Flush list</dt>&#13;
<dd>&#13;
<p>Dirty pages <a data-primary="flush list" data-type="indexterm" id="idm45829110126032"/>from writes committed in the transaction log.</p>&#13;
</dd>&#13;
<dt>LRU list</dt>&#13;
<dd>&#13;
<p>Clean and <a data-primary="LRU list" data-type="indexterm" id="idm45829110123824"/>dirty pages in the buffer pool ordered by data age.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Strictly speaking, the LRU list tracks all pages with data, and that just happens to include dirty pages; whereas the flush list explicitly tracks only dirty pages.&#13;
Either way, MySQL uses both lists to find dirty pages to flush.&#13;
(In <a data-type="xref" href="#page-flushing">Figure 6-6</a>, the LRU list is connected to [tracking] only one dirty page, but this only a simplification to avoid a clutter of lines.)</p>&#13;
&#13;
<p>Once every second, dirty pages are flushed from both lists by background threads aptly named <em>page cleaner threads</em>.&#13;
By default, InnoDB uses four page cleaner threads, <a data-primary="page cleaner threads" data-type="indexterm" id="idm45829110120048"/>configured by <a href="https://oreil.ly/ELUoy"><code>var.innodb_page_cleaners</code></a>.&#13;
Each page cleaner flushes both lists; but for simplicity, <a data-type="xref" href="#page-flushing">Figure 6-6</a> shows one page cleaner flushing one list.<a data-primary="dirty pages" data-startref="dirty-pages" data-type="indexterm" id="idm45829110117456"/></p>&#13;
&#13;
<p>Two flushing algorithms are primarily responsible for flush list flushing and LRU list flushing, respectively:</p>&#13;
<dl>&#13;
<dt>Adaptive flushing</dt>&#13;
<dd>&#13;
<p>Adaptive flushing <a data-primary="adaptive flushing" data-type="indexterm" id="idm45829110114496"/>determines the rate at which page cleaners flush dirty pages from the flush list.<sup><a data-type="noteref" href="ch06.html#idm45829110113632" id="idm45829110113632-marker">6</a></sup>&#13;
The algorithm is <em>adaptive</em> because it varies the page flush rate based on the rate of transaction log writes.&#13;
Faster writes, faster page flushing.&#13;
The algorithm responds to write load, but it’s also finely tuned to produce a stable rate of page flushing under varying write loads.</p>&#13;
&#13;
<p>Page flushing by page cleaners is a background task, therefore the page flush rate is limited by the configured InnoDB I/O capacity explained in <a data-type="xref" href="#metrics-iops">“IOPS”</a>, specifically: <code>var.innodb_io_capacity</code> and <code>var.innodb_io_capacity_max</code>.&#13;
Adaptive flushing does a fantastic job of keeping the flush rate (in terms of IOPS) between these two values.</p>&#13;
&#13;
<p>The purpose of adaptive flushing is to allow checkpointing to reclaim space in the transaction logs.&#13;
(Actually, this is the purpose of flush list flushing in general; algorithms are just different methods of accomplishing it.)&#13;
I explain checkpointing in <a data-type="xref" href="#metrics-trx-log">“Transaction log”</a>, but I mention it here to clarify that, although flushing makes pages clean and candidates for eviction, that is not the purpose of adaptive flushing.</p>&#13;
&#13;
<p>The intricate details of the adaptive flushing algorithm are beyond the scope of this book.&#13;
The important point is: adaptive flushing flushes dirty pages from the flush list in response to transaction log writes.</p>&#13;
</dd>&#13;
<dt>LRU flushing</dt>&#13;
<dd>&#13;
<p>LRU flushing <a data-primary="LRU flushing" data-type="indexterm" id="LRU-flushing"/>flushes dirty pages from the tail of the LRU list, which contains the oldest pages.&#13;
Simply put: LRU flushing flushes and evicts old pages from the buffer pool.</p>&#13;
&#13;
<p>LRU flushing happens in the background and the foreground.&#13;
Foreground LRU flushing happens when a user thread (a thread executing a query) needs a free page but there are none.&#13;
This is not good for performance because it’s a wait—it increases query response time.&#13;
When it occurs, MySQL increments <code>innodb.buffer_pool_wait_free</code>, which is the “one more detail about free page waits” mentioned earlier.</p>&#13;
&#13;
<p>Page cleaners <a data-primary="page cleaner threads" data-type="indexterm" id="idm45829110101232"/>handle background LRU flushing (because page cleaners are background threads).&#13;
When a page cleaner flushes a dirty page from the LRU list, it also frees the page by adding it to the free list.&#13;
This is primarily how InnoDB maintains the free page target <a data-primary="free page target" data-type="indexterm" id="idm45829110100096"/>(see <a data-type="xref" href="#pg-pages">“Pages”</a>) and avoids free page waits.</p>&#13;
&#13;
<p>Although background LRU flushing is a background task, it is <em>not</em> limited by the configured InnoDB I/O capacity explained (<code>var.innodb_io_capacity</code> and <code>var.innodb_io_capacity_max</code>).<sup><a data-type="noteref" href="ch06.html#idm45829110096368" id="idm45829110096368-marker">7</a></sup>&#13;
It’s effectively limited (per buffer pool instance) by <a href="https://oreil.ly/fGGjJ"><code>var.innodb_lru_scan_depth</code></a>.&#13;
For various reasons beyond the scope of this book, this is not a problem in terms of excessive background storage I/O.</p>&#13;
&#13;
<p>The purpose of LRU flushing is to flush and free (evict) the oldest pages.&#13;
<em>Old</em>, as detailed in <a data-type="xref" href="ch04.html#ap-data-age">“Data Age”</a>, means the least recently used pages, hence <em>LRU</em>.&#13;
The intricate details of LRU flushing, the LRU list, and how it all relates to the buffer pool are beyond the scope of this book; but if you’re curious, start by reading <a href="https://oreil.ly/OyBeI">“Buffer Pool”</a> in the MySQL manual.&#13;
The important point is that LRU flushing frees pages and its maximum rate is the free page target (per second), not the configured InnoDB I/O capacity.<a data-primary="LRU flushing" data-startref="LRU-flushing" data-type="indexterm" id="idm45829104110128"/></p>&#13;
</dd>&#13;
</dl>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idle-flushing">&#13;
<h5>Idle Flushing and Legacy Flushing</h5>&#13;
<p>There are two more flushing algorithms in addition to adaptive flushing and LRU flushing: idle flushing and legacy flushing.</p>&#13;
&#13;
<p><em>Idle flushing</em> <a data-primary="idle flushing" data-type="indexterm" id="idm45829104106368"/>occurs when InnoDB is not processing any writes (the transaction log is not being written to).&#13;
In this rare situation, InnoDB flushes dirty pages from the flush list at the configured I/O capacity (see <a data-type="xref" href="#metrics-iops">“IOPS”</a>).&#13;
Idle flushing also flushes the <a href="https://oreil.ly/uKb08">change buffer</a> and handles flushing when MySQL shuts down.</p>&#13;
&#13;
<p><em>Legacy flushing</em> <a data-primary="legacy flushing" data-type="indexterm" id="idm45829104103008"/>is my term for the simple algorithm that InnoDB employed before adaptive flushing became the standard.<sup><a data-type="noteref" href="ch06.html#idm45829104102032" id="idm45829104102032-marker">8</a></sup>&#13;
InnoDB flushes dirty pages when the percentage of dirty pages is between&#13;
<a href="https://oreil.ly/OSqCZ"><code>var.innodb_max_dirty_pages_pct_lwm</code></a>&#13;
and&#13;
<a href="https://oreil.ly/zsCWL"><code>var.innodb_max_dirty_pages_pct</code></a>.&#13;
Although this algorithm is still active in MySQL 8.0, it’s essentially never used, and you can ignore it.</p>&#13;
</div></aside>&#13;
&#13;
<p>With that crash course on InnoDB flushing, the following four metrics are now <span class="keep-together">intelligible</span>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.buffer_flush_batch_total_pages</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.buffer_flush_adaptive_total_pages</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.buffer_LRU_batch_flush_total_pages</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.buffer_flush_background_total_pages</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>All four metrics are counters that, when converted to rates, reveal page flush rates for each algorithm.&#13;
<code>innodb.buffer_flush_batch_total_pages</code> is the total page flush rate for all algorithms.&#13;
It’s a high-level rate that’s useful as a KPI for InnoDB: the total page flush rate should be normal and stable.&#13;
If not, one of the metrics indicates which part of InnoDB is not flushing normally.</p>&#13;
&#13;
<p><code>innodb.buffer_flush_adaptive_total_pages</code> is the number of pages flushed by adaptive flushing.&#13;
<code>innodb.buffer_LRU_batch_flush_total_pages</code> is the number of pages flushed by background LRU flushing.&#13;
Given the earlier explanation of these flushing algorithms, you know which parts of InnoDB they reflect: the transaction log and free pages, respectively.</p>&#13;
&#13;
<p><code>innodb.buffer_flush_background_total_pages</code> is included for completeness: it is the number of pages flushed by other algorithms described in <a data-type="xref" href="#idle-flushing">“Idle Flushing and Legacy Flushing”</a>.&#13;
If the rate of background page flushing is problematic, you will need to consult a MySQL expert because that’s not supposed to happen.</p>&#13;
&#13;
<p>Although different flushing algorithms have different rates, the storage system underlies all of them because flushing requires IOPS.&#13;
If you’re running MySQL on spinning disks, for example, the storage system (both the storage bus and the storage device) simply do not provide many IOPS.&#13;
If you run MySQL on high-end storage, then IOPS may never be an underlying issue.&#13;
And if you’re running MySQL in the cloud, you can provision as many IOPS as you need, but the cloud uses network-attached storage, which is slow.&#13;
Also remember that IOPS have latency—especially in the cloud—ranging from microseconds to milliseconds.&#13;
This is deep knowledge verging on expert-level internals, but let’s keep going because it’s powerful knowledge worth learning.<a data-primary="InnoDB" data-secondary="page flushing" data-startref="page-flushing_index1" data-type="indexterm" id="idm45829104086496"/><a data-primary="page flushing" data-startref="page-flushing_index2" data-type="indexterm" id="idm45829104085248"/></p>&#13;
</div></section>&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Transaction log" data-type="sect3"><div class="sect3" id="metrics-trx-log">&#13;
<h3>Transaction log</h3>&#13;
&#13;
<p>The final and perhaps most important spectrum: the transaction log, <a data-primary="InnoDB" data-secondary="transaction log" data-type="indexterm" id="transaction-log_index1"/><a data-primary="transaction log" data-type="indexterm" id="transaction-log_index2"/>also known as the redo <a data-primary="redo log (InnoDB)" data-type="indexterm" id="redo-log-InnoDB-ch6"/>log.&#13;
For brevity, it’s called <em>the log</em> when the context is clear and unambiguous, as it is here.</p>&#13;
&#13;
<p>The transaction log guarantees durability.&#13;
When a transaction commits, all data changes are recorded in the transaction log and flushed to disk—which makes the data changes durable—and corresponding dirty pages remain in memory.&#13;
(If MySQL crashes with dirty pages, the data changes are not lost because they were already flushed to disk in the transaction log.)&#13;
Transaction log flushing is <em>not</em> page flushing.&#13;
The two processes are separate but inextricable.</p>&#13;
&#13;
<p>The InnoDB transaction log is a fixed-size ring buffer on disk, as shown in <a data-type="xref" href="#trx-log">Figure 6-7</a>.&#13;
By default, it comprises two physical log files.&#13;
The size of each is configured by <a href="https://oreil.ly/ItAxz"><code>var.innodb_log_file_size</code></a>.&#13;
Or, as of MySQL 8.0.3, enabling <a href="https://oreil.ly/gv38o"><code>var.innodb_dedicated_server</code></a> automatically configures the log file size and other related system variables.</p>&#13;
&#13;
<p>The transaction log contains data changes (technically, <em>redo logs</em>), not pages; but the data changes are linked to dirty pages in the buffer pool.&#13;
When a transaction commits, its data changes are written to the head of the transaction log and flushed (synced) to disk, which advances the head clockwise, and the corresponding dirty pages are added to the flush list shown earlier in <a data-type="xref" href="#page-flushing">Figure 6-6</a>.&#13;
(In <a data-type="xref" href="#trx-log">Figure 6-7</a>, the head and tail move clockwise, but this is only an illustration.&#13;
Unless you have spinning disks, the transaction log does not literally move.)&#13;
Newly written data changes overwrite old data changes for which the corresponding pages have been flushed.</p>&#13;
&#13;
<figure><div class="figure" id="trx-log">&#13;
<img alt="emsp 0607" src="assets/emsp_0607.png"/>&#13;
<h6><span class="label">Figure 6-7. </span>InnoDB transaction log</h6>&#13;
</div></figure>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>A simplified illustration and explanation of the InnoDB transaction log makes it appear serialized.&#13;
But that is only an artifact of simplifying a complex process.&#13;
The actual low-level implementation is highly concurrent: many user threads are committing changes to the transaction log in parallel.</p>&#13;
</div>&#13;
&#13;
<p><em>Checkpoint age</em> is the <a data-primary="checkpoint age" data-type="indexterm" id="idm45829104066560"/>length of the transaction log (in bytes) between the head and the tail.&#13;
<em>Checkpointing</em> <a data-primary="checkpointing" data-type="indexterm" id="idm45829104065312"/>reclaims space in the transaction log by flushing dirty pages from the buffer pool, which allows the tail to advance.&#13;
Once dirty pages have been flushed, the corresponding data changes in the transaction log can be overwritten with new data changes.&#13;
Adaptive flushing <a data-primary="adaptive flushing" data-type="indexterm" id="idm45829104064160"/> implements checkpointing in InnoDB, which is why the checkpoint age is an input to the adaptive flushing algorithm shown in <a data-type="xref" href="#page-flushing">Figure 6-6</a>.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>By default, all data changes (redo logs) <a data-primary="redo log (InnoDB)" data-startref="redo-log-InnoDB-ch6" data-type="indexterm" id="idm45829104061440"/>in the transaction log are durable (flushed to disk), but corresponding dirty pages in the buffer pool are not durable until flushed by checkpointing.</p>&#13;
</div>&#13;
&#13;
<p>Checkpointing advances the tail to ensure that the checkpoint age does not become too old (which really means <em>too large</em> because it’s measured in bytes, but <em>too old</em> is the more common phrase).&#13;
But what happens if the checkpoint age becomes so old that the head meets the tail?&#13;
Since the transaction log is a fixed-size ring buffer, the head can wrap around and meet the tail if the write rate consistently exceeds the flush rate.&#13;
InnoDB won’t let this happen.&#13;
There are two safeguard points called <em>async</em> and <em>sync</em>, as shown in <a data-type="xref" href="#trx-log">Figure 6-7</a>.&#13;
<em>Async</em> is the point at which InnoDB begins asynchronous flushing: writes are allowed, but the page flushing rate is increased to near maximum.&#13;
Although writes are allowed, flushing will use so much InnoDB I/O capacity that you can (and should) expect a noticeable drop in overall server performance.&#13;
<em>Sync</em> is the point at which InnoDB begins synchronous flushing: <em>all writes stop</em>, and page flushing takes over.&#13;
Needless to say, that’s terrible for performance.</p>&#13;
&#13;
<p>InnoDB exposes metrics for the checkpoint age and the async flush point, <span class="keep-together">respectively</span>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.log_lsn_checkpoint_age</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.log_max_modified_age_async</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><code>innodb.log_lsn_checkpoint_age</code> is a gauge metric measured in bytes, but the raw value is meaningless to humans (it ranges from zero to the log file size).&#13;
What is meaningful to humans and critical to monitor is how close the checkpoint age is to the async flush point, which I <a data-primary="transaction log utilization" data-type="indexterm" id="transaction-log-utilization"/>call <em>transaction log utilization</em>:</p>&#13;
<div data-type="equation">&#13;
(innodb.log_lsn_checkpoint_age / innodb.log_max_modified_age_async) × 100&#13;
</div>&#13;
&#13;
<p>Transaction log utilization is conservative because the async flush point is at 6/8 (75%) of the log file size.&#13;
Therefore, at 100% transaction log utilization, 25% of the log is free to record new writes, but remember: server performance drops noticeably at the async flush point.&#13;
It’s important to monitor and know when this point is reached.&#13;
If you want to live dangerously, InnoDB exposes a metric for the sync flush point (which is at 7/8 [87.5%] of the log file size) that you can substitute for the async flush point metric (or monitor both): <code>innodb.log_max_modified_age_sync</code>.<a data-primary="transaction log utilization" data-startref="transaction-log-utilization" data-type="indexterm" id="idm45829104046288"/></p>&#13;
&#13;
<p>There’s one small but important detail about how queries log data changes to the transaction log: data changes are first written to an in-memory <em>log buffer</em> <a data-primary="log buffer" data-type="indexterm" id="idm45829104044272"/>(not to be confused with the <em>log file</em> <a data-primary="log file" data-type="indexterm" id="idm45829104043024"/>that refers to the actual on-disk transaction log), then the log buffer is written to the log file, and the log file is synced.&#13;
I’m glossing over myriad details, but the point is: there’s an in-memory log buffer.&#13;
If the log buffer is too small and a query has to wait for free space, InnoDB increments:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.log_waits</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><code>innodb.log_waits</code> should be zero.&#13;
If it isn’t, the log buffer size is configured by <a href="https://oreil.ly/2I1cq"><code>var.innodb_log_buffer_size</code></a>.&#13;
The default 16 MB is usually more than sufficient.</p>&#13;
&#13;
<p>Since the transaction log comprises two physical files on disk (two files, but one logical log), writing and syncing data changes to disk are the most fundamental tasks.&#13;
Two gauge metrics report how many of those tasks are pending—waiting to be completed:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.os_log_pending_writes</code></p>&#13;
</li>&#13;
<li>&#13;
<p><code>innodb.os_log_pending_fsyncs</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Since writes and syncs are supposed to happen extremely quickly—nearly all write performance depends on it—these metrics should always be zero.&#13;
If not, they indicate a low-level problem with either InnoDB or, more likely, the storage system—presuming other metrics are normal or were normal before pending writes and syncs.&#13;
Don’t expect problems at this depth, but monitor it.</p>&#13;
&#13;
<p>Last but not least, a simple but important metric that counts the number of bytes written to the transaction log:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>innodb.os_log_bytes_written</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>It’s best practice to monitor total log bytes written per hour as a basis for determining log file size.&#13;
Log file size is the product of system variables <a href="https://oreil.ly/sinUV"><code>var​.inno​db_​log_file_size</code></a> and <a href="https://oreil.ly/0hYp1"><code>var.innodb_log_files_in_group</code></a>.&#13;
Or, as of MySQL 8.0.14, enabling <a href="https://oreil.ly/f2UqB"><code>var.innodb_dedicated_server</code></a> automatically configures both system variables.&#13;
The default log file size is only 96 MB (two log files at 48 MB each).&#13;
As an engineer using MySQL, not a DBA, I presume whoever is managing your MySQL has properly configured these system variables, but it’s wise to verify.</p>&#13;
&#13;
<p>We made it: the end of InnoDB metrics.&#13;
The spectrum of InnoDB metrics is much wider and deeper than presented here; these are only the most essential InnoDB metrics for analyzing MySQL performance.&#13;
Moreover, significant changes were made to InnoDB from MySQL 5.7 to 8.0.&#13;
For example, the internal implementation of the transaction log was rewritten and improved as of MySQL 8.0.11.&#13;
There are other parts of InnoDB not covered here: double-write buffer, change buffer, adaptive hash index, and so on.&#13;
I encourage you to learn more about InnoDB, for it is a fascinating storage engine.&#13;
You can begin that journey at <a href="https://oreil.ly/s0PZk">“The InnoDB Storage Engine”</a> in the MySQL manual.<a data-primary="spectra (MySQL server metrics)" data-secondary="InnoDB" data-startref="spectra-InnoDB" data-type="indexterm" id="idm45829104027328"/><a data-primary="InnoDB" data-secondary="transaction log" data-startref="transaction-log_index1" data-type="indexterm" id="idm45829104026016"/><a data-primary="transaction log" data-startref="transaction-log_index2" data-type="indexterm" id="idm45829104024800"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Monitoring and Alerting" data-type="sect1"><div class="sect1" id="monitoring-and-alerting">&#13;
<h1>Monitoring and Alerting</h1>&#13;
&#13;
<p>MySQL <a data-primary="server metrics" data-secondary="monitoring and alerting" data-type="indexterm" id="monitoring-and-alerting_index1"/><a data-primary="monitoring" data-type="indexterm" id="monitoring-and-alerting_index2"/><a data-primary="alerting" data-type="indexterm" id="monitoring-and-alerting_index3"/>metrics reveal the spectrum of MySQL performance, and they’re also great for waking engineers in the middle of the night—otherwise known as monitoring and alerting.</p>&#13;
&#13;
<p>Monitoring and alerting are external to MySQL, so they cannot affect its performance, but I am compelled to address the following four topics because they are related to metrics and important to success with MySQL.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Resolution" data-type="sect2"><div class="sect2" id="idm45829104019232">&#13;
<h2>Resolution</h2>&#13;
&#13;
<p><em>Resolution</em> means <a data-primary="resolution (metrics)" data-type="indexterm" id="resolution-metrics-ch6"/>the frequency at which metrics are collected and reported: 1 second, 10 seconds, 30 seconds, 5 minutes, and so on.&#13;
Higher resolution entails higher frequency: 1 second is higher resolution than 30 seconds.&#13;
Like a television, the higher the resolution, the more detail you see.&#13;
And since “seeing is believing,” let’s see three charts of the same data over 30 seconds.&#13;
The first chart, <a data-type="xref" href="#qps-at-1s">Figure 6-8</a>, shows QPS values at maximum resolution: 1 second.</p>&#13;
&#13;
<figure><div class="figure" id="qps-at-1s">&#13;
<img alt="emsp 0608" src="assets/emsp_0608.png"/>&#13;
<h6><span class="label">Figure 6-8. </span>QPS at 1-second resolution</h6>&#13;
</div></figure>&#13;
&#13;
<p>In the first 20 seconds, QPS is normal and stable, bouncing between 100 and 200 QPS.&#13;
From 20 to 25 seconds, there is a 5-second stall (the 5 data points below 100 QPS in the box).&#13;
For the last five seconds, QPS spikes to an abnormally high value, which is common after a stall.&#13;
This chart isn’t dramatic, but it’s realistic and it begins to illustrate a point that the next two charts bring into focus.</p>&#13;
&#13;
<p>The second chart, <a data-type="xref" href="#qps-at-5s">Figure 6-9</a>, is the exact same data but at 5-second resolution.</p>&#13;
&#13;
<figure><div class="figure" id="qps-at-5s">&#13;
<img alt="emsp 0609" src="assets/emsp_0609.png"/>&#13;
<h6><span class="label">Figure 6-9. </span>QPS at 5-second resolution</h6>&#13;
</div></figure>&#13;
&#13;
<p>At 5-second resolution, some fine detail is lost, but critical details remain: normal and stable QPS in the first 20 seconds; the stall around 25 seconds; and the spike after the stall.&#13;
This chart is acceptable for daily monitoring—especially considering that collecting, storing, and charting metrics at 1-second resolution is so difficult that it’s almost never done.</p>&#13;
&#13;
<p>The third chart, <a data-type="xref" href="#qps-at-10s">Figure 6-10</a>, is the exact same data but at 10-second resolution.</p>&#13;
&#13;
<p>At 10-second resolution, nearly all detail is lost.&#13;
According to the chart, QPS is stable and normal, but it’s misleading: QPS destabilized and was not normal for 10 seconds (five second stall and five second spike).</p>&#13;
&#13;
<p>At the very least, collect KPIs (see <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>) at 5-second resolution or better.&#13;
If possible, collect most of the metrics in <a data-type="xref" href="#spectra">“Spectra”</a> at 5-second resolution too, with the following exceptions: Admin, <code>SHOW</code>, and bad <code>SELECT</code> metrics can be collected slowly (10, 20, or 30 seconds), and data size can be collected very slowly (5, 10, or 20 minutes).</p>&#13;
&#13;
<p>Strive for the highest resolution possible because, unlike query metrics that are logged, MySQL metrics are either collected or gone for all eternity.<a data-primary="resolution (metrics)" data-startref="resolution-metrics-ch6" data-type="indexterm" id="idm45829104002096"/></p>&#13;
&#13;
<figure><div class="figure" id="qps-at-10s">&#13;
<img alt="emsp 0610" src="assets/emsp_0610.png"/>&#13;
<h6><span class="label">Figure 6-10. </span>QPS at 10-second resolution</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Wild Goose Chase (Thresholds)" data-type="sect2"><div class="sect2" id="thresholds">&#13;
<h2>Wild Goose Chase (Thresholds)</h2>&#13;
&#13;
<p>A <em>threshold</em> <a data-primary="thresholds" data-type="indexterm" id="thresholds_index1"/>is a static value past which a monitoring alert triggers, often times paging the engineer who’s on-call.&#13;
Thresholds seem like a good and reasonable idea, but they don’t work.&#13;
That’s a very strong claim, but it’s closer to the truth than the opposite—claiming that thresholds work.</p>&#13;
&#13;
<p>The problem is that a threshold also needs a <em>duration</em>: how long the metric value must remain past the threshold until the alert triggers.&#13;
Consider the chart in <a data-type="xref" href="#qps-at-1s">Figure 6-8</a> from the previous section (QPS at 1-second resolution).&#13;
Without a duration, a threshold at QPS less than 100 would trigger seven times in 30 seconds: the five second stall, and the third and thirteenth data points.&#13;
That’s “too noisy” in the parlance of monitoring and alerting, so what about a threshold at QPS less than 50?&#13;
Surely, a 50% drop in QPS—from 100 QPS to 50 QPS—signals a problem worth alerting a human.&#13;
Sorry, the alert never triggers: the lowest data point is 50 QPS, which is not <em>less than</em> 50 QPS.</p>&#13;
&#13;
<p>This example seems contrived but it’s not, and it gets worse.&#13;
Suppose you add a 5-second duration to the alert, and reset the threshold to QPS less than 100.&#13;
Now the alert only triggers after the five-second stall.&#13;
But what if the stall wasn’t a stall?&#13;
What if there was a network blip that caused packet loss during those five seconds, so the problem was neither MySQL nor the application?&#13;
The poor on-call human who was alerted is on a wild goose chase.</p>&#13;
&#13;
<p>I know it seems like I’m tailoring the example to suit my point, but all joking aside: thresholds are notoriously difficult to perfect, where <em>perfect</em> means that it alerts only on truly legitimate problems—no false-positives.<a data-primary="thresholds" data-startref="thresholds_index1" data-type="indexterm" id="idm45829103990864"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Alert on User Experience and Objective Limits" data-type="sect2"><div class="sect2" id="alert-on">&#13;
<h2>Alert on User Experience and Objective Limits</h2>&#13;
&#13;
<p>There <a data-primary="user experience alerts" data-type="indexterm" id="user-experience-alerts"/><a data-primary="objective limits alerts" data-type="indexterm" id="objective-limits-alerts"/>are two proven solutions that work in lieu of thresholds:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Alert on what users experience</p>&#13;
</li>&#13;
<li>&#13;
<p>Alert on <em>objective</em> limits</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>From <a data-type="xref" href="ch01.html#north-star">“North Star”</a> and <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>, there are only two MySQL metrics that users experience: response time and errors.&#13;
These are reliable signals not only because users experience them, but because they cannot be false-positive.&#13;
A change in QPS might be a legitimate change in user traffic.&#13;
But a change in response time can only be explained by a change in response time.&#13;
The same is true for errors.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>With microservices, the user might be another application.&#13;
In that case, normal response times could be very low (tens of milliseconds), but the monitoring and alerting principles are the same.</p>&#13;
</div>&#13;
&#13;
<p>Thresholds and duration are simpler for response time and errors, too, because we can imagine the abnormal conditions past the thresholds.&#13;
For example, presume the normal P99 response time for an application is 200 milliseconds, and the normal error rate is 0.5 per second.&#13;
If P99 response time increased to 1 second (or more) for a full a minute, would that be a bad user experience?&#13;
If yes, then make those the threshold and duration.&#13;
If errors increased to 10 per second for a full 20 seconds, would that be a bad user experience?&#13;
If yes, then make those the threshold and duration.</p>&#13;
&#13;
<p>For a more concrete example, let’s clarify the implementation of the previous example where 200 milliseconds is the normal P99 response time.&#13;
Measure and report P99 response time every five seconds (see <a data-type="xref" href="#metrics-qrt">“Query Response Time”</a>).&#13;
Create a rolling one minute alert on the metric that triggers when the last 12 values are greater than one second.&#13;
(Since the metric is reported every five seconds, there are 60 / 5 seconds = 12 values/minute.)&#13;
From a technical point of view, a sustained 5x increase in query response time is drastic and merits investigation—it’s probably an early warning that a larger problem is brewing and, if ignored, will cause an application outage.&#13;
But the intention of the alert is more practical than technical: if users are used to subsecond responses from the application, then one-second responses are noticeably sluggish.</p>&#13;
&#13;
<p>Objective limits are minimum or maximum values that MySQL cannot pass.&#13;
These are common objective limits external to MySQL:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Zero free disk space</p>&#13;
</li>&#13;
<li>&#13;
<p>Zero free memory</p>&#13;
</li>&#13;
<li>&#13;
<p>100% CPU utilization</p>&#13;
</li>&#13;
<li>&#13;
<p>100% storage IOPS utilization</p>&#13;
</li>&#13;
<li>&#13;
<p>100% network utilization</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>MySQL has many <em>max</em> system variables, but these are the most common ones that affect applications:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="https://oreil.ly/0ODxA"><code>max_connections</code></a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://oreil.ly/jqNuk"><code>max_prepared_stmt_count</code></a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://oreil.ly/qM3R5"><code>max_allowed_packet</code></a></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>There’s one more object limit that has surprised more than one engineer: maximum <a href="https://oreil.ly/tkXWP"><code>AUTO_INCREMENT</code></a> value.&#13;
MySQL does not have a native metric or method for checking if an <code>AUTO_INCREMENT</code> column is approaching its maximum value.&#13;
Instead, common MySQL monitoring solutions create a metric by executing a SQL statement similar to <a data-type="xref" href="#auto-inc-max">Example 6-7</a>, which was written by renowned MySQL expert Shlomi Noach <a data-primary="Noach, Shlomi" data-type="indexterm" id="idm45829103961616"/>in <a href="https://oreil.ly/LJ64E">“Checking for AUTO_INCREMENT capacity with single query”</a>.</p>&#13;
<div data-type="example" id="auto-inc-max">&#13;
<h5><span class="label">Example 6-7. </span>SQL statement that checks maximum <code>AUTO_INCREMENT</code></h5>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">SELECT</code>&#13;
  <code class="n">TABLE_SCHEMA</code><code class="p">,</code>&#13;
  <code class="k">TABLE_NAME</code><code class="p">,</code>&#13;
  <code class="k">COLUMN_NAME</code><code class="p">,</code>&#13;
  <code class="n">DATA_TYPE</code><code class="p">,</code>&#13;
  <code class="n">COLUMN_TYPE</code><code class="p">,</code>&#13;
  <code class="n">IF</code><code class="p">(</code>&#13;
    <code class="n">LOCATE</code><code class="p">(</code><code class="s1">'unsigned'</code><code class="p">,</code> <code class="n">COLUMN_TYPE</code><code class="p">)</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">,</code>&#13;
    <code class="mi">1</code><code class="p">,</code>&#13;
    <code class="mi">0</code>&#13;
  <code class="p">)</code> <code class="k">AS</code> <code class="n">IS_UNSIGNED</code><code class="p">,</code>&#13;
  <code class="p">(</code>&#13;
    <code class="k">CASE</code> <code class="n">DATA_TYPE</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'tinyint'</code> <code class="k">THEN</code> <code class="mi">255</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'smallint'</code> <code class="k">THEN</code> <code class="mi">65535</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'mediumint'</code> <code class="k">THEN</code> <code class="mi">16777215</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'int'</code> <code class="k">THEN</code> <code class="mi">4294967295</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'bigint'</code> <code class="k">THEN</code> <code class="mi">18446744073709551615</code>&#13;
    <code class="k">END</code> <code class="o">&gt;&gt;</code> <code class="n">IF</code><code class="p">(</code><code class="n">LOCATE</code><code class="p">(</code><code class="s1">'unsigned'</code><code class="p">,</code> <code class="n">COLUMN_TYPE</code><code class="p">)</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>&#13;
  <code class="p">)</code> <code class="k">AS</code> <code class="n">MAX_VALUE</code><code class="p">,</code>&#13;
  <code class="n">AUTO_INCREMENT</code><code class="p">,</code>&#13;
  <code class="n">AUTO_INCREMENT</code> <code class="o">/</code> <code class="p">(</code>&#13;
    <code class="k">CASE</code> <code class="n">DATA_TYPE</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'tinyint'</code> <code class="k">THEN</code> <code class="mi">255</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'smallint'</code> <code class="k">THEN</code> <code class="mi">65535</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'mediumint'</code> <code class="k">THEN</code> <code class="mi">16777215</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'int'</code> <code class="k">THEN</code> <code class="mi">4294967295</code>&#13;
      <code class="k">WHEN</code> <code class="s1">'bigint'</code> <code class="k">THEN</code> <code class="mi">18446744073709551615</code>&#13;
    <code class="k">END</code> <code class="o">&gt;&gt;</code> <code class="n">IF</code><code class="p">(</code><code class="n">LOCATE</code><code class="p">(</code><code class="s1">'unsigned'</code><code class="p">,</code> <code class="n">COLUMN_TYPE</code><code class="p">)</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>&#13;
  <code class="p">)</code> <code class="k">AS</code> <code class="n">AUTO_INCREMENT_RATIO</code>&#13;
<code class="k">FROM</code>&#13;
  <code class="n">INFORMATION_SCHEMA</code><code class="p">.</code><code class="n">COLUMNS</code>&#13;
  <code class="k">INNER</code> <code class="k">JOIN</code> <code class="n">INFORMATION_SCHEMA</code><code class="p">.</code><code class="n">TABLES</code> <code class="k">USING</code> <code class="p">(</code><code class="n">TABLE_SCHEMA</code><code class="p">,</code> <code class="k">TABLE_NAME</code><code class="p">)</code>&#13;
<code class="k">WHERE</code>&#13;
  <code class="n">TABLE_SCHEMA</code> <code class="k">NOT</code> <code class="k">IN</code> <code class="p">(</code><code class="s1">'mysql'</code><code class="p">,</code> <code class="s1">'INFORMATION_SCHEMA'</code><code class="p">,</code> <code class="s1">'performance_schema'</code><code class="p">)</code>&#13;
  <code class="k">AND</code> <code class="n">EXTRA</code><code class="o">=</code><code class="s1">'auto_increment'</code>&#13;
<code class="p">;</code></pre></div>&#13;
&#13;
<p>What about the other two key performance indicators: QPS and threads running?&#13;
Monitoring QPS and threads running is a best practice, but alerting on them is not.&#13;
These metrics are pivotal when investigating a legitimate problem signaled by response time or errors, but otherwise they fluctuate too much to be reliable signals.</p>&#13;
&#13;
<p>If this approach seems radical, remember: these are alerts for engineers using MySQL, not DBAs.<a data-primary="user experience alerts" data-startref="user-experience-alerts" data-type="indexterm" id="idm45829103945696"/><a data-primary="objective limits alerts" data-startref="objective-limits-alerts" data-type="indexterm" id="idm45829103944848"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Cause and Effect" data-type="sect2"><div class="sect2" id="cause-and-effect">&#13;
<h2>Cause and Effect</h2>&#13;
&#13;
<p>I won’t mince words: when MySQL is slow to respond, the application is the cause the vast majority (maybe 80%) of the time—in my experience—because the application drives MySQL. Without it, MySQL is idle.&#13;
If the application isn’t the cause, there are a few other common causes of slow MySQL performance. Another application—any application, not just MySQL—is a likely culprit maybe 10% of the time, as I discuss later in <a data-type="xref" href="ch09.html#noisy-neighbors">“Noisy Neighbors”</a>.&#13;
Hardware, which includes the network, causes problems a mere 5% of the time because modern hardware is quite reliable (especially enterprise-grade hardware, which lasts longer [and costs more] than consumer-grade hardware).&#13;
Last and least: I estimate only a 1% chance that MySQL is the root cause of its own slowness.</p>&#13;
&#13;
<p>Once identified, the cause is presumed to be the root cause, not a side effect of some prior, unseen cause.&#13;
For example, application causes presume something like a poorly written query that, once deployed in production, immediately causes a problem in MySQL.&#13;
Or, hardware causes presume something like a degraded storage system that’s working but significantly slower than usual, which causes MySQL to respond slowly.&#13;
When this presumption is false—the identified cause is <em>not</em> the root cause—an especially pernicious situation occurs.&#13;
Consider the following sequence of events:</p>&#13;
<ol>&#13;
<li>&#13;
<p>A network issue lasting 20 seconds causes significant packet loss or low-level network retries.</p>&#13;
</li>&#13;
<li>&#13;
<p>The network issue causes query errors or timeouts (due to packet loss or retries, respectively).</p>&#13;
</li>&#13;
<li>&#13;
<p>Both the application and MySQL log errors (query errors and client errors, respectively).</p>&#13;
</li>&#13;
<li>&#13;
<p>The application retries queries.</p>&#13;
</li>&#13;
<li>&#13;
<p>While retrying old queries, the application continues executing new queries.</p>&#13;
</li>&#13;
<li>&#13;
<p>QPS increases due to executing new and old queries.</p>&#13;
</li>&#13;
<li>&#13;
<p>Utilization increases due to QPS increasing.</p>&#13;
</li>&#13;
<li>&#13;
<p>Waits increase due to utilization increasing.</p>&#13;
</li>&#13;
<li>&#13;
<p>Timeouts increase due to waits increasing.</p>&#13;
</li>&#13;
<li>&#13;
<p>The application retries queries again, which creates a feedback loop.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>By the time you step into this situation, the problem is apparent but the root cause is not.&#13;
You know that everything was normal and stable before the problem: no application changes or deployments; MySQL key performance indicators were normal and stable; and DBAs confirm that no work was done on their side.&#13;
That’s what makes this situation especially pernicious: as far as you can tell, it shouldn’t be happening, but there’s no denying that it is.</p>&#13;
&#13;
<p>Technically speaking, all causes are knowable because computers are finite and discrete.&#13;
But practically speaking, causes are only as knowable as monitoring and logging allow.&#13;
In this example, if you have exceptionally good networking monitoring and application logging (and access to the MySQL error log), you can figure out the root cause: the 20-second network blip.&#13;
But that’s a lot easier said than done because in the midst of this situation—your application is down, customers are calling, and it’s 4:30 p.m. on a Friday—engineers are focused on fixing the problem, not elucidating its root cause.&#13;
When focused on fixing the problem, it’s easy to see MySQL as the cause that needs to be fixed: make MySQL run faster and the application will be OK.&#13;
But there is no way to fix MySQL in this sense—recall, <a data-type="xref" href="ch04.html#mysql-does-nothing">“MySQL Does Nothing”</a>.&#13;
Since everything was normal before the problem, the goal is to return to that normal, starting with the application because it drives MySQL.&#13;
The correct solution depends on the application, but common tactics are: restarting the application, throttling incoming application requests, and disabling application features.</p>&#13;
&#13;
<p>I’m not favoring MySQL.&#13;
The simple reality is that MySQL is a mature database with more than 20 years in the field.&#13;
Moreover, as an open source database, it has been scrutinized by engineers from all over the world.&#13;
At this juncture in the storied life of MySQL, inherent slowness is not its weakness.&#13;
Rather than ask why MySQL is slow, a more powerful and effective question that leads to a root cause or immediate fix is “What is causing MySQL to run slowly?”<a data-primary="server metrics" data-secondary="monitoring and alerting" data-startref="monitoring-and-alerting_index1" data-type="indexterm" id="idm45829103708544"/><a data-primary="monitoring" data-startref="monitoring-and-alerting_index2" data-type="indexterm" id="idm45829103707328"/><a data-primary="alerting" data-startref="monitoring-and-alerting_index3" data-type="indexterm" id="idm45829103706416"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45829103705328">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>This chapter analyzed the spectra of MySQL metrics that are the most important for understanding the nature of the workload, which accounts for MySQL performance.&#13;
The illuminating takeaway points are:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>MySQL performance has two sides: query performance and server performance.</p>&#13;
</li>&#13;
<li>&#13;
<p>Query performance is input; server performance is output.</p>&#13;
</li>&#13;
<li>&#13;
<p>Normal  and stable are whatever performance MySQL exhibits for your application on a typical day when everything is working properly.</p>&#13;
</li>&#13;
<li>&#13;
<p>Stability does not limit performance; it ensures that performance—at any level—is sustainable.</p>&#13;
</li>&#13;
<li>&#13;
<p>MySQL KPIs are response time, errors, QPS, and threads running.</p>&#13;
</li>&#13;
<li>&#13;
<p>The field of metrics comprises six classes of metrics: response time, rate, utilization, wait, error, and access pattern (seven, if you count internal metrics).</p>&#13;
</li>&#13;
<li>&#13;
<p>Metric classes are related: rate increases utilization; utilization pushes back to decrease rate; high (maximum) utilization incurs wait; wait timeout incurs error.</p>&#13;
</li>&#13;
<li>&#13;
<p>The spectra of MySQL metrics are vast; see <a data-type="xref" href="#spectra">“Spectra”</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>Resolution</em> means the frequency at which metrics are collected and reported.</p>&#13;
</li>&#13;
<li>&#13;
<p>High resolution metrics (5 seconds or less) reveal important performance details that are lost in low resolution metrics.</p>&#13;
</li>&#13;
<li>&#13;
<p>Alert on what users experience (like response time) and objective limits.</p>&#13;
</li>&#13;
<li>&#13;
<p>Application issues (your application or another) are the most likely cause of slow MySQL performance.</p>&#13;
</li>&#13;
<li>&#13;
<p>MySQL server performance is revealed through a spectrum of metrics that are the figurative refraction of&#13;
the workload through MySQL.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The next chapter investigates replication lag.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Practice: Review Key Performance Indicators" data-type="sect1"><div class="sect1" id="idm45829103689136">&#13;
<h1>Practice: Review Key Performance Indicators</h1>&#13;
&#13;
<p>The goal of this practice is to know the normal and stable values of the four KPIs <a data-primary="key performance indicators (KPIs)" data-type="indexterm" id="idm45829103687360"/>for MySQL, as addressed in <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>.&#13;
To make this practice interesting first, write down what you think the KPI values are for your application.&#13;
You probably have a good idea about QPS; what about response time (P99 or P999), errors, and threads running?</p>&#13;
&#13;
<p>Start collecting the four <a data-type="xref" href="#kpi">“Key Performance Indicators”</a>, if you’re not already.&#13;
Your method depends on the software (or service) that you use to collect MySQL metrics.&#13;
Any decent MySQL monitor should collect all four; if your current solution does not, seriously consider a better MySQL monitor because if it doesn’t collect key performance indicators, it’s unlikely to collect many of the metrics detailed in <a data-type="xref" href="#spectra">“Spectra”</a>.</p>&#13;
&#13;
<p>Review at least one full day of KPI metrics.&#13;
Are the real values close to what you thought?&#13;
If response time is higher than you thought, then you know where to begin: <a data-type="xref" href="ch01.html#query-profile">“Query profile”</a>.&#13;
If the rate of errors is higher than you thought, then query table <code>performance_schema.events_errors_summary_global_by_error</code> to see which error numbers are occurring.&#13;
Use <a href="https://oreil.ly/F9z9W">“MySQL Error Message Reference”</a> to look up the error code.&#13;
If threads running is higher than you thought, diagnosis is tricky because a single thread executes different queries (presuming the application uses a connection pool).&#13;
Start with the slowest queries in the query profile.&#13;
If your query metric tool reports query load, focus on queries with the highest load; otherwise, focus on queries with the highest total query time.&#13;
If necessary, investigate using the <a href="https://oreil.ly/ZgtGW">Performance Schema <code>threads</code> table</a>.</p>&#13;
&#13;
<p>Review the KPIs for different periods throughout the day.&#13;
Are the values stable all day, or do they decrease in the middle of the night?&#13;
Are there periods when the values are abnormal?&#13;
Overall, what are the normal and stable KPI values for your application?</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Practice: Review Alerts and Thresholds" data-type="sect1"><div class="sect1" id="idm45829103677984">&#13;
<h1>Practice: Review Alerts and Thresholds</h1>&#13;
&#13;
<p>The goal of this practice is to help you sleep at night.<a data-primary="user experience alerts" data-type="indexterm" id="idm45829103676400"/><a data-primary="objective limits alerts" data-type="indexterm" id="idm45829103675616"/>&#13;
Whereas charts for MySQL metrics are front and center, alerts—and configuration of those alerts—are usually hidden away.&#13;
Consequently, engineers—especially newly hired engineers—do not know what alerts lurk in the darkness, waiting to page them while they sleep.&#13;
Take a morning or afternoon to shine a light on all your alerts and how they are configured—their thresholds, if any.&#13;
And while you’re at it: document the alerts (or update the current documentation).&#13;
Review <a data-type="xref" href="#thresholds">“Wild Goose Chase (Thresholds)”</a> and <a data-type="xref" href="#alert-on">“Alert on User Experience and Objective Limits”</a>, and adjust or remove superfluous alerts.</p>&#13;
&#13;
<p>The goal for alerting is simple: every page is legitimate and actionable.&#13;
<em>Legitimate</em> means that something is already broken, or certain to break very soon, and it requires fixing right now.&#13;
<em>Actionable</em> means that the engineer (who was paged) has the knowledge, skills, and access to fix it.&#13;
This is possible with MySQL. Say <em>no</em> to the wild goose chase and <em>yes</em> to a good night’s sleep.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45829110960368"><sup><a href="ch06.html#idm45829110960368-marker">1</a></sup> The <a href="https://oreil.ly/2kFWK">MySQL worklog 5384</a> explains how response time quantiles are implemented in the Performance Schema.</p><p data-type="footnote" id="idm45829110678032"><sup><a href="ch06.html#idm45829110678032-marker">2</a></sup> <code>Com_insert_select</code> and <code>Com_replace_select</code> are technically both reads and writes, but for simplicity I count them as writes.</p><p data-type="footnote" id="idm45829110575632"><sup><a href="ch06.html#idm45829110575632-marker">3</a></sup> “I’m Mr. Meeseeks, look at me!”</p><p data-type="footnote" id="idm45829110547888"><sup><a href="ch06.html#idm45829110547888-marker">4</a></sup> See my blog post <a href="https://oreil.ly/OpJvS">“MySQL Select and Sort Status Variables”</a> for an in-depth explanation of all <code>Select_%</code> and <code>Sort_%</code> metrics.</p><p data-type="footnote" id="idm45829110227344"><sup><a href="ch06.html#idm45829110227344-marker">5</a></sup> You can disable durability, but that’s a terrible idea.</p><p data-type="footnote" id="idm45829110113632"><sup><a href="ch06.html#idm45829110113632-marker">6</a></sup> The MySQL adaptive flushing algorithm was created in 2008 by renowned MySQL expert <a data-primary="Kinoshita, Yasufumi" data-type="indexterm" id="idm45829110112912"/>Yasufumi Kinoshita while working at Percona. See his blog post <a href="https://oreil.ly/8QG6X">“Adaptive checkpointing”</a>.</p><p data-type="footnote" id="idm45829110096368"><sup><a href="ch06.html#idm45829110096368-marker">7</a></sup> For proof and a deep dive, read my blog post <a href="https://oreil.ly/YHEcj">“MySQL LRU Flushing and I/O Capacity”</a>.</p><p data-type="footnote" id="idm45829104102032"><sup><a href="ch06.html#idm45829104102032-marker">8</a></sup> <em>Legacy flushing</em> is also called <em>dirty pages percentage flushing</em>, but I prefer my term because it’s simpler and frames it more accurately: <em>legacy</em> implies that it’s no longer current, which is true.</p></div></div></section></body></html>