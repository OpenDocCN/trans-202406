<html><head></head><body><section data-pdf-bookmark="Chapter 7. Secret Management" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter7">&#13;
<h1><span class="label">Chapter 7. </span>Secret Management</h1>&#13;
&#13;
&#13;
<p>In any application stack, we are almost guaranteed to run into secret data. This is the data that applications want to keep, well, secret.<a data-primary="secrets" data-type="indexterm" id="idm45611987209336"/> Commonly, we associate secrets with credentials. Often these credentials are used to access systems within or external to the cluster, such as databases or message queues. We also run into secret data when using private keys, which may support our application’s ability to perform mutual TLS with other applications. These kinds of concerns are covered in <a data-type="xref" href="ch11.html#building_platform_services">Chapter 11</a>. The existence of secrets bring in many operational concerns <a data-primary="security" data-seealso="secrets" data-type="indexterm" id="idm45611987184872"/><a data-primary="secrets" data-secondary="operational concerns" data-type="indexterm" id="idm45611987184024"/>to consider, such as:</p>&#13;
<dl>&#13;
<dt>Secret rotation policies</dt>&#13;
<dd>&#13;
<p>How long is a secret allowed to remain before it must be changed?</p>&#13;
</dd>&#13;
<dt>Key (encryption) rotation policies</dt>&#13;
<dd>&#13;
<p>Assuming secret data is encrypted at the application layer before being persisted to disk, how long is an encryption key allowed to stay around before it must be rotated?</p>&#13;
</dd>&#13;
<dt>Secret storage policies</dt>&#13;
<dd>&#13;
<p>What requirements must be satisfied in order to store secret data? Do you need to persist secrets to isolated hardware? Do you need your secret management solution to integrate with a hardware security module (HSM)?</p>&#13;
</dd>&#13;
<dt>Remediation plan</dt>&#13;
<dd>&#13;
<p>If secret(s) or encryption key(s) are compromised, how do you plan to remediate? Can your plan or automation be run without impact to applications?</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>A good starting point is to determine what layer to offer secret management for your applications. Some organizations choose to not solve this at a platform level and instead expect application teams to inject secrets into their applications dynamically. For example, if an organization is running a secret management system such as Vault, applications can talk directly to the API to authenticate and retrieve secrets. &#13;
<span class="keep-together">Application</span> frameworks may even offer libraries to talk directly to these systems. For example, Spring offers the spring-vault project to authenticate against Vault, retrieve secrets, and inject their values directly into Java classes. While possible to do at the application layer, many platform teams aspire to offer enterprise-grade secret capabilities as platform services, perhaps in a way that application developers need not be concerned with how the secret got there or what external provider (e.g., Vault) is being used under the hood.</p>&#13;
&#13;
<p>In this chapter we’ll dive into how to think about secret data in Kubernetes. We’ll start at lower-level layers Kubernetes runs on and work up to the APIs Kubernetes exposes that make secret data available to workloads. Like many topics in this book, you’ll find these considerations and recommendations to live on a spectrum—one end of the spectrum includes how secure you’re willing to get relative to engineering effort and tolerance for risk, and the other end focuses on what level of abstractions you’d like to provide to developers consuming this platform.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Defense in Depth" data-type="sect1"><div class="sect1" id="idm45611987173608">&#13;
<h1>Defense in Depth</h1>&#13;
&#13;
<p>Protection of our secret data largely comes down to what depths we’re willing to go to make it secure.<a data-primary="secrets" data-secondary="protection of" data-type="indexterm" id="ix_secrpro"/> As much as we’d like to say we always choose the most secure options, the reality is we make sensible decisions that keep us “safe enough” and ideally harden them over time. This comes with risk and technical debt that is quintessential to our work. However, there’s no denying that a misjudgment of what is “safe enough” can quickly make us famous, and not in a good way. In the following sections, we’ll look at these layers of security and call out some of the most critical points.</p>&#13;
&#13;
<p>Defense can start literally at the physical layer.<a data-primary="physical layer, security at" data-type="indexterm" id="idm45611987169704"/><a data-primary="security" data-secondary="datacenter, Google's approach to" data-type="indexterm" id="idm45611987169032"/><a data-primary="cloud computing" data-secondary="security measures to protect hardware" data-type="indexterm" id="idm45611987168120"/> A prime example is Google. It has multiple <a href="https://cloud.google.com/security/overview/whitepaper">whitepapers</a>, and even a video on <a href="https://oreil.ly/dtHUx">YouTube</a>, that describe its approach to datacenter security. This includes metal detectors, vehicle barriers capable of stopping a semi truck, and several layers of building security just to get into the datacenter. This attention to detail extends beyond what is live and racked. When drives are retired, Google has authorized staff zero-out the data and then potentially crush and shred the drives. While the subject of physical security is interesting, this book will not go into depth around physical security of your datacenter, but the steps cloud providers take to ensure the security of their hardware are amazing, and that’s just the start.</p>&#13;
&#13;
<p>Let’s say a human did somehow get access to a disk before it was zeroed out or crushed. Most cloud providers and datacenters are securing their physical disks by ensuring the drive is encrypted at rest. Providers may do this with their own encryption keys and/or they allow customers to provide their own keys, which makes it near impossible for providers to access your unencrypted data. This is a perfect example of defense in depth. We are protected from a physical standpoint, intra-datacenter, and we extend that to encrypting data on the physical disks themselves, closing off further opportunities for bad actors internally to do anything with users’ data.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Disk Encryption" data-type="sect2"><div class="sect2" id="idm45611987163656">&#13;
<h2>Disk Encryption</h2>&#13;
&#13;
<p>Let’s take a closer look at the disk encryption domain. <a data-primary="encryption" data-secondary="disk" data-type="indexterm" id="idm45611987162168"/><a data-primary="disk encryption" data-type="indexterm" id="idm45611987161320"/><a data-primary="secrets" data-secondary="protection of" data-tertiary="disk encryption" data-type="indexterm" id="idm45611987160680"/>There are several ways to encrypt disks. A common method in Linux for full block encryption is leveraging Linux Unified Key System (LUKS).<a data-primary="Linux Unified Key System (LUKS)" data-type="indexterm" id="idm45611987159096"/> LUKS works in conjunction with the dm-crypt encryption subsystem, which has been available in the Linux kernel since version 2.6. For dedicated storage systems such as vSAN, ceph, or Gluster, each provide one or many means to provide encryption at rest. In cloud providers, the default encryption behavior can vary.<a data-primary="AWS (Amazon Web Services)" data-secondary="disk encryption" data-type="indexterm" id="idm45611987157896"/> For AWS, you should explore its documentation to enable encryption for Elastic Block Storage.<a data-primary="AWS Elastic Block Storage (EBS)" data-secondary="encryption of" data-type="indexterm" id="idm45611987156696"/> AWS offers the ability to enable encryption by default, which we recommend as a best-practice setting. Google Cloud, on the other hand, performs encryption at rest as its default mode. Similar to AWS, it can be configured with the Key Management Service (KMS), which enables you to customize the encryption behavior, such as providing your own encryption keys.</p>&#13;
&#13;
<p>Regardless of the trust you do or don’t have for your cloud provider or datacenter operators, we highly recommend encryption at rest as your default practice.<a data-primary="encryption" data-secondary="encryption at rest" data-type="indexterm" id="idm45611987154792"/><a data-primary="storage" data-secondary="encryption of stored data" data-type="indexterm" id="idm45611987153784"/> Encryption at rest essentially means the data is <em>stored</em> encrypted. Not only is this good for mitigating attack vectors, but it provides some protection against possible mistakes. For example, the world of virtual machines has made it trivial to create snapshots of hosts.<a data-primary="snapshots of storage volumes" data-secondary="security for" data-type="indexterm" id="idm45611987151960"/> Snapshots end up like any other file, data that is too easy to accidentally expose to an internal or external network. In the spirit of defense in depth, we should protect ourselves against this scenario where, if we select the wrong button via a UI or field in an API, the leaked data is useless for those without private key access. <a data-type="xref" href="#permission_setting">Figure 7-1</a> shows the UI for how easily these permissions can be toggled.</p>&#13;
&#13;
<figure><div class="figure" id="permission_setting">&#13;
<img alt="prku 0701" src="assets/prku_0701.png"/>&#13;
<h6><span class="label">Figure 7-1. </span>Permission setting on an AWS snapshot, as the warning says “making public” will give others access to create a volume from this snapshot and, potentially, access the data.</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Transport Security" data-type="sect2"><div class="sect2" id="idm45611987147272">&#13;
<h2>Transport Security</h2>&#13;
&#13;
<p>With a better understanding of encrypted data at rest, how about data that is actively in flight?<a data-primary="TLS" data-secondary="encryption over" data-type="indexterm" id="idm45611987145832"/><a data-primary="transport security" data-seealso="TLS" data-type="indexterm" id="idm45611987144856"/><a data-primary="secrets" data-secondary="protection of" data-tertiary="transport security" data-type="indexterm" id="idm45611987143912"/> Without having explored the Kubernetes secret architecture yet, let’s look at the paths a secret can take when being transported between services. <a data-type="xref" href="#diagram_demonstrating_points_where_a_secret_may_pass_over_the_wire">Figure 7-2</a> shows some of the interaction points for secrets. The arrows represent the secret moving through the network between hosts.</p>&#13;
&#13;
<figure><div class="figure" id="diagram_demonstrating_points_where_a_secret_may_pass_over_the_wire">&#13;
<img alt="prku 0702" src="assets/prku_0702.png"/>&#13;
<h6><span class="label">Figure 7-2. </span>Diagram demonstrating points where a secret may pass over the wire.</h6>&#13;
</div></figure>&#13;
&#13;
<p>The figure shows secret data moving across the network to reach different hosts. No matter how strong our encryption at rest strategy is, if any of the interaction points do not communicate over TLS, we have exposed our secret data. As seen <a data-type="xref" href="#diagram_demonstrating_points_where_a_secret_may_pass_over_the_wire">Figure 7-2</a>, this includes the human-to-system interaction, kubectl, and the system-to-system interaction, kubelet to API server.<a data-primary="API server" data-secondary="secret data moving through network" data-type="indexterm" id="idm45611987137672"/> In summary, it’s crucial communications with the API server and etcd that happen exclusively over TLS. We won’t spend much time discussing this need as it is the default for almost every mode of installing or bootstrapping Kubernetes clusters. Often the only configuration you may wish to do is to provide a Certificate Authority (CA) to generate the certificates.<a data-primary="certificate management" data-secondary="Certificate Authority for TLS certificates" data-type="indexterm" id="idm45611987136200"/> However, keep in mind these certificates are internal to Kubernetes system components. With this in mind, you might not need to overwrite the default CA Kubernetes will generate.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Application Encryption" data-type="sect2"><div class="sect2" id="idm45611987134584">&#13;
<h2>Application Encryption</h2>&#13;
&#13;
<p>Application encryption is the encryption we perform within our system components or workloads <a data-primary="secrets" data-secondary="protection of" data-tertiary="application encryption" data-type="indexterm" id="idm45611987133000"/><a data-primary="application encryption" data-type="indexterm" id="idm45611987131752"/><a data-primary="encryption" data-secondary="application" data-type="indexterm" id="idm45611987131080"/>running in Kubernetes. Application encryption can have many layers itself. For example, a workload in Kubernetes can encrypt data before persisting it to Kubernetes, which could then encrypt it, and then persisting it to etcd where it’ll be encrypted at the filesystem level. The first two encryption points are considered “application-level.” That’s a lot of encryption!</p>&#13;
&#13;
<p class="pagebreak-before">While we won’t always have encryption or decryption take place at that many levels, there is something to be said about data being encrypted at least once at the application level. Consider what we’ve talked about thus far: encryption over TLS and encryption at rest. If we’d stopped there, we’d have a decent start. When secret data is in flight, it will be encrypted, and it’ll also be encrypted on the physical disk. But what about on the running system? While the bits persisted to disk may be encrypted, if a user were to gain access to the system they would likely be able to read the data! Consider your encrypted desktop computer where you may keep sensitive credentials in a dotfile (we’ve all done it). If I steal your computer and try to access this data by sledding the drive, I won’t be able to get the information I’m after. However, if I succeed at booting your computer <em>and logging in as you</em>, I now have full access to this data.</p>&#13;
&#13;
<p>Application encryption is the act of encrypting that data with a key at the userspace level. In this computer example, I could use a (strongly) password protected gpg key to encrypt that dotfile, requiring my user to decrypt it before it can be used. Writing a simple script can automate this process and you’re off to the races with a far <em>deeper</em> security model. As the attacker logged in as you, even the decryption key is useless because without the password it’s just useless bits. The same consideration applies to Kubernetes. Going forward we’re going to assume two things are set up in your &#13;
<span class="keep-together">cluster</span>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Encryption at rest is enabled in the filesystem and/or storage systems used by Kubernetes.</p>&#13;
</li>&#13;
<li>&#13;
<p>TLS is enabled for all Kubernetes components and etcd.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>With this, let’s begin our exploration of encryption at the Kubernetes application level.<a data-primary="secrets" data-secondary="protection of" data-startref="ix_secrpro" data-type="indexterm" id="idm45611987122632"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Kubernetes Secret API" data-type="sect1"><div class="sect1" id="idm45611987121256">&#13;
<h1>The Kubernetes Secret API</h1>&#13;
&#13;
<p>The Kubernetes Secret API is one of the most-used APIs in Kubernetes.<a data-primary="secrets" data-secondary="Secret API" data-type="indexterm" id="ix_secrAPI"/> While there are many ways for us to populate the Secret objects, the API provides a consistent means for workloads to interact with secret data.<a data-primary="secrets" data-secondary="Secret API" data-tertiary="Secret object" data-type="indexterm" id="idm45611987118040"/> Secret objects heavily resemble ConfigMaps. They also have similar mechanics around how workloads can consume the objects, via environment variables or volume data. Consider the following Secret object:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">v1</code>&#13;
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Secret</code>&#13;
<code class="nt">metadata</code><code class="p">:</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">mysecret</code>&#13;
<code class="nt">type</code><code class="p">:</code> <code class="l-Scalar-Plain">Opaque</code>&#13;
<code class="nt">data</code><code class="p">:</code>&#13;
  <code class="nt">dbuser</code><code class="p">:</code> <code class="l-Scalar-Plain">aGVwdGlvCg==</code>&#13;
  <code class="nt">dbkey</code><code class="p">:</code> <code class="l-Scalar-Plain">YmVhcmNhbm9lCg==</code></pre>&#13;
&#13;
<p>In the <code>data</code> field, <code>dbuser</code> and <code>dbkey</code> are base64 encoded.<a data-primary="base64 encoded secret data" data-type="indexterm" id="idm45611987104120"/><a data-primary="API server" data-secondary="submitting nonencoded string data to" data-type="indexterm" id="idm45611987103416"/> All Kubernetes secret data is. If you wish to submit nonencoded string data to the API server, you can use the <code>stringData</code> field as follows:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">v1</code>&#13;
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Secret</code>&#13;
<code class="nt">metadata</code><code class="p">:</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">mysecret</code>&#13;
<code class="nt">type</code><code class="p">:</code> <code class="l-Scalar-Plain">Opaque</code>&#13;
<code class="nt">stringData</code><code class="p">:</code>&#13;
  <code class="nt">dbuser</code><code class="p">:</code> <code class="l-Scalar-Plain">heptio</code>&#13;
  <code class="nt">dbkey</code><code class="p">:</code> <code class="l-Scalar-Plain">bearcanoe</code></pre>&#13;
&#13;
<p>When applied, the <code>stringData</code> will be encoded at the API server and applied to etcd. A common misconception is that Kubernetes is encoding this data as a practice of security. This is not the case. Secret data can contain all kinds of strange characters or binary data. In order to ensure it’s stored correctly, it is base64 encoded. By default, the key mechanism for ensuring that Secrets aren’t compromised is RBAC.<a data-primary="RBAC (role-based access control)" data-type="indexterm" id="idm45611987080408"/> Understanding the implications of RBAC verbs as they pertain to Secrets is crucial to prevent introducing vectors of attack:</p>&#13;
<dl>&#13;
<dt><code>get</code></dt>&#13;
<dd>&#13;
<p>Retrieve the data of a known secret by its name.</p>&#13;
</dd>&#13;
<dt><code>list</code></dt>&#13;
<dd>&#13;
<p>Get a list of all secrets and/or <em>secret data</em>.</p>&#13;
</dd>&#13;
<dt><code>watch</code></dt>&#13;
<dd>&#13;
<p>Watch any secret change and/or change to <em>secret data</em>.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>As you can imagine, small RBAC mistakes, such as giving the user list access, expose every Secret in a Namespace or, worse, the entire cluster if a ClusterRoleBinding is accidentally used. The truth is, in many cases, users don’t need any of these permissions. This is because a user’s RBAC does not determine what secrets the workload can have access to. Generally the kubelet is responsible for making the secret available to the container(s) in a Pod. In summary, as long as your Pod references a valid secret, the kubelet will make it available through the means you specify. There are a few options to how we expose the secret in the workload, which is covered next.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45611987033640">&#13;
<h5>The Scope of Secrets</h5>&#13;
<p>The kubelet handling<a data-primary="kubelet" data-secondary="handling of secrets" data-type="indexterm" id="idm45611987032312"/> secret retrieval and injection is very convenient.<a data-primary="secrets" data-secondary="scope of" data-type="indexterm" id="idm45611987031112"/> However, it begs the question, How does the kubelet know whether my application should be able to access a secret? The model for workload access to secrets in Kubernetes is very simple, for better or for worse.<a data-primary="Namespace-scoped secrets" data-type="indexterm" id="idm45611987029816"/> Secrets are Namespace scoped, meaning that without replicating the Secret across Namespaces, a Pod may reference Secret(s) only in its Namespace. Which also means that Pods may access <em>any</em> Secret available in their Namespace. This is one reason careful consideration of how Namespaces are shared among workloads is critical. If this model is unacceptable, there are ways to add additional checks at the admission control layer, which will be covered in a future chapter.</p>&#13;
</div></aside>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Secret Consumption Models" data-type="sect2"><div class="sect2" id="idm45611987027896">&#13;
<h2>Secret Consumption Models</h2>&#13;
&#13;
<p>For workloads wishing to consume a Secret, there are several choices. The preference on <a data-primary="secrets" data-secondary="Secret API" data-tertiary="consumption models for Secrets" data-type="indexterm" id="ix_secrAPIcons"/>how secret data is ingested may depend on the application. However, there are trade-offs to the approach you choose. In the coming sections, we’ll look at three means of consuming secret data in workloads.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Environment variables" data-type="sect3"><div class="sect3" id="idm45611987024280">&#13;
<h3>Environment variables</h3>&#13;
&#13;
<p>Secret data may be injected into environment variables.<a data-primary="environment variables" data-secondary="secret data injected into" data-type="indexterm" id="idm45611987022744"/> In the workload YAML, an arbitrary key and reference to the secret may be specified. This can be a nice feature for workloads moving onto Kubernetes that already expect an environment variable by reducing the need to change application codes. Consider the following Pod &#13;
<span class="keep-together">example</span>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting" id="EX3"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Pod</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">nginx</code><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">containers</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">nginx</code><code>&#13;
</code><code>    </code><code class="nt">image</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">nginx</code><code>&#13;
</code><code>    </code><code class="nt">env</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">USER</code><code> </code><a class="co" href="#callout_secret_management_CO1-1" id="co_secret_management_CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>        </code><code class="nt">valueFrom</code><code class="p">:</code><code>&#13;
</code><code>          </code><code class="nt">secretKeyRef</code><code class="p">:</code><code>&#13;
</code><code>            </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">mysecret</code><code> </code><a class="co" href="#callout_secret_management_CO1-2" id="co_secret_management_CO1-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>            </code><code class="nt">key</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">dbuser</code><code> </code><a class="co" href="#callout_secret_management_CO1-3" id="co_secret_management_CO1-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>      </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">PASS</code><code>&#13;
</code><code>        </code><code class="nt">valueFrom</code><code class="p">:</code><code>&#13;
</code><code>          </code><code class="nt">secretKeyRef</code><code class="p">:</code><code>&#13;
</code><code>            </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">mysecret</code><code>&#13;
</code><code>            </code><code class="nt">key</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">dbkey</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_secret_management_CO1-1" id="callout_secret_management_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The environment variable key that will be available in the application.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO1-2" id="callout_secret_management_CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The name of the Secret object in Kubernetes.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO1-3" id="callout_secret_management_CO1-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>The key in the Secret object that should be injected into the <code>USER</code> variable.</p></dd>&#13;
</dl>&#13;
&#13;
<p>The downside to exposing secrets in environment variables is their inability to be hot reloaded. A change in a Secret object will not be reflected until the Pod is re-created. This could occur through manual intervention or system events such as the need to reshedule. Additionally, it is worth calling out that some consider secrets in environment variables to be less secure than reading from volume mounts. This point can be debated, but it is fair to call out some of the common opportunities to leak. Namely, when processes or container runtimes are inspected, there may be ways to see the environment variables in plain text. Additionally, some frameworks, libraries, or languages may support debug or crash modes where they dump (spew) environment variables out to the logs. Before using environment variables, these risks should be considered.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Volumes" data-type="sect3"><div class="sect3" id="idm45611986905128">&#13;
<h3>Volumes</h3>&#13;
&#13;
<p>Alternatively, secret objects may be injected via volumes.<a data-primary="volumes" data-secondary="secrets consumed via" data-type="indexterm" id="idm45611986903528"/> In the workload’s YAML, a volume is configured where the secret is referenced. The container that the secret should be injected into references that volume using a <code>volumeMount</code>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting" id="EX4"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Pod</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">nginx</code><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">containers</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">nginx</code><code>&#13;
</code><code>    </code><code class="nt">image</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">nginx</code><code>&#13;
</code><code>    </code><code class="nt">volumeMounts</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">creds</code><code> </code><a class="co" href="#callout_secret_management_CO2-2" id="co_secret_management_CO2-1"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>      </code><code class="nt">readOnly</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">true</code><code>&#13;
</code><code>      </code><code class="nt">mountPath</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">/etc/credentials</code><code class="s">"</code><code> </code><a class="co" href="#callout_secret_management_CO2-3" id="co_secret_management_CO2-2"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>  </code><code class="nt">volumes</code><code class="p">:</code><code> </code><a class="co" href="#callout_secret_management_CO2-1" id="co_secret_management_CO2-3"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">creds</code><code>&#13;
</code><code>    </code><code class="nt">secret</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">secretName</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">mysecret</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_secret_management_CO2-3" id="callout_secret_management_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Pod-level volumes available for mounting. Name specified must be referenced in the mount.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO2-1" id="callout_secret_management_CO2-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The volume object to mount into the container filesystem.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO2-2" id="callout_secret_management_CO2-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Where in the container filesystem the mount is made available.</p></dd>&#13;
</dl>&#13;
&#13;
<p>With this Pod manifest, the secret data is available under <em>/etc/credentials</em> with each key/value pair in the secret object getting its own file:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">root@nginx:/# cat /etc/credentials/db&#13;
dbkey   dbuser</pre>&#13;
&#13;
<p>The biggest benefit to the volume approach is that secrets may be updated dynamically, without the Pod restarting. When a change to the secret is seen, the kubelet will reload the secret and it’ll show as updated in the container’s filesystem. It’s important to call out that the kubelet is using tmpfs, on Linux, to ensure secret data is stored exclusively in memory. We can see this by examining the mount table file on the Linux host:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="c"># grep 'secret/creds' secret/creds</code>&#13;
&#13;
tmpfs&#13;
/var/lib/kubelet/pods/&#13;
e98df9fe-a970-416b-9ddf-bcaff15dff87/volumes/&#13;
kubernetes.io~secret/creds tmpfs rw,relatime <code class="m">0</code> 0</pre>&#13;
&#13;
<p>If the <code>nginx</code> Pod is removed from this host, this mount is discarded. With this model in mind, it’s especially important to consider that Secret data should <em>never</em> be large in size. Ideally it holds credentials or keys and is never used as a pseudo database.</p>&#13;
&#13;
<p>From an application perspective, a simple watch on the directory or file, then re-injecting values into the application, is all it would take to handle a secret change. No need to understand or communicate with the Kubernetes API server. This is an ideal pattern we’ve seen success with in many workloads.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Client API Consumption" data-type="sect3"><div class="sect3" id="idm45611986746312">&#13;
<h3>Client API Consumption</h3>&#13;
&#13;
<p>The last consumption model, Client API Consumption, is not a core Kubernetes feature.<a data-primary="Client API consumption of secrets" data-type="indexterm" id="idm45611986735464"/> This model puts the onus on the application to communicate with the kube-apiserver to retrieve Secret(s) and inject them into the application. There are several frameworks and libraries out there that make communicating with Kubernetes trivial for your application. For Java, Spring’s Spring Cloud Kubernetes brings this functionality to Spring applications.<a data-primary="Spring Cloud Kubernetes" data-type="indexterm" id="idm45611986734280"/> It takes the commonly used Spring PropertySource type and enables it to be wired up by connecting to Kubernetes and retreiving Secrets and/or ConfigMaps.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45611986733176">&#13;
<h5>Caution: Carefully Consider This Approach</h5>&#13;
<p>While consumption of Secret objects directly from the client application is possible, we generally discourage this approach.<a data-primary="API server" data-secondary="and Client API consumption of secrets" data-secondary-sortas="Client" data-type="indexterm" id="idm45611986731768"/> Previously, we talked about Spring’s affinity toward mounting secrets but talking to the API server for ConfigMap.<a data-primary="ConfigMaps" data-type="indexterm" id="idm45611986730296"/> Even in the case of ConfigMaps, it’s less than ideal to require each application to communicate directly to the API server. From a philosophical standpoint, when possible, we’d rather the application not be aware of where it’s running. Meaning, if we can make it run on a VM as we could on Kubernetes or another container service, that’s preferable. Most languages and frameworks have primitives needed to read environment variables and files. The kubelet can ensure our containers get Secret data through these mediums, so why add provider-specific logic into our applications for this use case? Philosophy aside, this is another client that will need to connect and establish a watch on the API server.<a data-primary="Service Accounts" data-type="indexterm" id="idm45611986744296"/> Not only is this another unnecessary connection, but we now need to ensure the workloads get their own Service Account with accompanying RBAC to access their Secret object(s). Whereas, in delegating this work to the kubelet, no Service Account is required. In fact, the Service Account (<code>default</code>) can and should be disabled altogether!</p>&#13;
</div></aside>&#13;
&#13;
<p>Now that we have covered consumption of secrets at a workload level, it is time to talk about storing secret data.<a data-primary="secrets" data-secondary="Secret API" data-startref="ix_secrAPIcons" data-tertiary="consumption models for Secrets" data-type="indexterm" id="idm45611986742136"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Secret Data in etcd" data-type="sect2"><div class="sect2" id="idm45611986740392">&#13;
<h2>Secret Data in etcd</h2>&#13;
&#13;
<p>Like most Kubernetes objects, Secrets are stored in etcd.<a data-primary="etcd" data-secondary="Secrets stored in" data-type="indexterm" id="ix_etcdsec"/><a data-primary="secrets" data-secondary="Secret API" data-tertiary="secret data in etcd" data-type="indexterm" id="ix_secrAPIetcd"/> By default, <em>no</em> encryption is done at the Kubernetes layer before persisting Secrets to etcd. <a data-type="xref" href="#default_secret">Figure 7-3</a> shows the flow of a secret from manifest to etcd.</p>&#13;
&#13;
<figure><div class="figure" id="default_secret">&#13;
<img alt="prku 0703" src="assets/prku_0703.png"/>&#13;
<h6><span class="label">Figure 7-3. </span>Default secret data flow in Kubernetes (the colocated etcd is sometimes run on a separate host).</h6>&#13;
</div></figure>&#13;
&#13;
<p>While Kubernetes did <em>not</em> encrypt the secret data, this does not imply access to the data upon gaining hardware access. Remember that encryption at rest can be performed on disks through methods such as Linux Unified Key Setup (LUKS), where physical access to hardware gives you access only to encrypted data. For many cloud providers and enterprise datacenters, this is a default mode of operation. However, should we gain <code>ssh</code> access to the server running etcd and a user that has privileges or can escalate to see its filesystem, then we can potentially gain access to the secret data.<a data-primary="ssh access to server running etcd, attack on secret data via" data-type="indexterm" id="idm45611986706168"/></p>&#13;
&#13;
<p>For some cases, this default model can be acceptable. etcd can be run external to the Kubernetes API server, ensuring it is separated by at least a hypervisor.<a data-primary="hypervisors" data-type="indexterm" id="idm45611986688456"/> In this model, an attacker would likely need to obtain root access to the etcd node, find the data location, and then read the secrets from the etcd database. The other entry point would be an adversary getting root access to the API server, locating the API server and etcd certs, then impersonating the API server in communicating with etcd to read secrets. Both cases assume potentially other breaches. For example, the attacker would have had to gain access to the internal network or subnet that is running the control-plane components. Additionally, they’d need to get the appropriate key to <code>ssh</code> into the node. Frankly, it’s far more likely that an RBAC mistake or application compromise would expose a secret before this case.</p>&#13;
&#13;
<p>To better understand the threat model, let’s work through an example of how an attacker could gain access to Secrets. Let’s consider the case where an attacker SSHs and gains root access to the kube-apiserver node. The attacker could set up a script as follows:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="c">#!/bin/bash</code>&#13;
&#13;
<code class="c"># Change this based on location of etcd nodes</code>&#13;
<code class="nv">ENDPOINTS</code><code class="o">=</code><code class="s1">'192.168.3.43:2379'</code>&#13;
&#13;
<code class="nv">ETCDCTL_API</code><code class="o">=</code><code class="m">3</code> etcdctl <code class="se">\</code>&#13;
  --endpoints<code class="o">=</code><code class="si">${</code><code class="nv">ENDPOINTS</code><code class="si">}</code> <code class="se">\</code>&#13;
  --cacert<code class="o">=</code><code class="s2">"/etc/kubernetes/pki/etcd/ca.crt"</code> <code class="se">\</code>&#13;
  --cert<code class="o">=</code><code class="s2">"/etc/kubernetes/pki/apiserver-etcd-client.crt"</code> <code class="se">\</code>&#13;
  --key<code class="o">=</code><code class="s2">"/etc/kubernetes/pki/apiserver-etcd-client.key"</code> <code class="se">\</code>&#13;
  <code class="si">${</code><code class="p">@</code><code class="si">}</code></pre>&#13;
&#13;
<p>The certificate and key locations seen in this snippet are the default when Kubernetes was bootstrapped by kubeadm, which is also used by many tools such as cluster-api. etcd stores the secret data within the directory <em>/registry/secrets/${NAMESPACE}/${SECRET_NAME}</em>. Using this script to get a secret, named <code>login1</code>, would look as &#13;
<span class="keep-together">follows</span>:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="c"># ./etcctl-script get /registry/secrets/default/login1</code>&#13;
&#13;
/registry/secrets/default/login1&#13;
k8s&#13;
&#13;
&#13;
v1Secret&#13;
&#13;
login1default<code class="s2">"*</code><code class="nv">$6c991b48</code><code class="s2">-036c-48f8-8be3-58175913915c2bB</code>&#13;
<code class="s2">0kubectl.kubernetes.io/last-applied-configuration{"</code>apiVersion<code class="s2">":"</code>v1<code class="s2">","</code>data<code class="s2">":</code>&#13;
<code class="s2">{"</code>dbkey<code class="s2">":"</code><code class="nv">YmVhcmNhbm9lCg</code><code class="o">==</code><code class="s2">","</code>dbuser<code class="s2">":"</code><code class="nv">aGVwdGlvCg</code><code class="o">==</code><code class="s2">"},"</code>kind<code class="s2">":"</code>Secret<code class="s2">",</code>&#13;
<code class="s2">"</code>metadata<code class="s2">":{"</code>annotations<code class="s2">":{},"</code>name<code class="s2">":"</code>login1<code class="s2">","</code>namespace<code class="s2">":"</code>default<code class="s2">"},</code>&#13;
<code class="s2">"</code><code class="nb">type</code><code class="s2">":"</code>Opaque<code class="s2">"}</code>&#13;
<code class="s2">z</code>&#13;
<code class="s2">dbkey</code>&#13;
<code class="s2">bearcanoe</code>&#13;
&#13;
<code class="s2">dbuserheptio</code>&#13;
<code class="s2">Opaque"</code></pre>&#13;
&#13;
<p>With this, we have successfully compromised the secret <code>login1</code>.</p>&#13;
&#13;
<p>Even though storing Secrets without encryption can be acceptable, many platform operators choose not to stop here.<a data-primary="encryption" data-secondary="data within etcd" data-type="indexterm" id="idm45611986591608"/> Kubernetes supports a few ways to encrypt the data within etcd, furthering the depth of your defense with respect to secrets. These include models to support encryption at rest (where encryption occurs at the Kubernetes layer) before it rests in etcd. These models include static-key encryption and envelope encryption.<a data-primary="etcd" data-secondary="Secrets stored in" data-startref="ix_etcdsec" data-type="indexterm" id="idm45611986590344"/><a data-primary="secrets" data-secondary="Secret API" data-startref="ix_secrAPIetcd" data-tertiary="secret data in etcd" data-type="indexterm" id="idm45611986589128"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Static-Key Encryption" data-type="sect2"><div class="sect2" id="idm45611986739800">&#13;
<h2>Static-Key Encryption</h2>&#13;
&#13;
<p>The Kubernetes API server supports encrypting secrets at rest.<a data-primary="API server" data-secondary="support for encrypting secrets at rest" data-type="indexterm" id="idm45611986585624"/><a data-primary="secrets" data-secondary="Secret API" data-tertiary="static-key encryption" data-type="indexterm" id="idm45611986584680"/><a data-primary="static-key encryption" data-type="indexterm" id="idm45611986583464"/><a data-primary="encryption" data-secondary="static key" data-type="indexterm" id="idm45611986582792"/><a data-primary="keys" data-secondary="static-key encryption" data-type="indexterm" id="idm45611986581848"/> This is achieved by providing the Kubernetes API server with an encryption key, which it will use to encrypt all secret objects before persisting them to etcd. <a data-type="xref" href="#encryption_key">Figure 7-4</a> shows the flow of a secret when static-key encryption is in play.</p>&#13;
&#13;
<figure><div class="figure" id="encryption_key">&#13;
<img alt="prku 0704" src="assets/prku_0704.png"/>&#13;
<h6><span class="label">Figure 7-4. </span>The relationship between an encryption key, on the API server, being used to encrypt secrets before storing them in etcd.</h6>&#13;
</div></figure>&#13;
&#13;
<p>The key, held within an <code>EncryptionConfiguration</code>, is used to encrypt and decrypt Secret objects as they move through the API server. <a data-primary="EncryptionConfiguration" data-type="indexterm" id="idm45611986576888"/>Should an attacker get access to etcd, they would see the encrypted data within, meaning the Secret data is not compromised. Keys can be created using a variety of providers, including secretbox, aescbc, and aesgcm.</p>&#13;
&#13;
<p>Each provider has its own trade-offs, and we recommend working with your security team to select the appropriate option. Kubernetes issue #81127 is a good read on some considerations around these providers. If your enterprise needs to comply with standards such as the Federal Information Processing Standards (FIPS), these choices should be carefully considered. In our example we’ll use secretbox, which acts as a fairly performant and secure encryption provider.<a data-primary="secretbox" data-type="indexterm" id="idm45611986574968"/></p>&#13;
&#13;
<p>To set up static-key encryption, we must generate a 32-byte key. Our encryption and decryption model is symmetric, so a single key serves both purposes. How you generate a key can vary enterprise to enterprise. Using a Linux host, we can easily use <code>/dev/urandom</code> if we’re satisfied with its entropy:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">head -c <code class="m">32</code> /dev/urandom <code class="p">|</code> base64</pre>&#13;
&#13;
<p>Using this key data, an EncryptionConfiguration should be added to all nodes running a kube-apiserver.<a data-primary="kube-apiserver" data-secondary="EncryptionConfiguration for all nodes running" data-type="indexterm" id="idm45611986547288"/> This static file should be added using configuration management such as ansible or KubeadmConfigSpec if using Cluster API. This ensures keys can be added, deleted, and rotated. The following example assumes the configuration is stored at <em>/etc/kubernetes/pki/secrets/encryption-config.yaml</em>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">apiserver.config.k8s.io/v1</code>&#13;
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">EncryptionConfiguration</code>&#13;
<code class="nt">resources</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="nt">resources</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">secrets</code>&#13;
    <code class="nt">providers</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="nt">secretbox</code><code class="p">:</code>&#13;
        <code class="nt">keys</code><code class="p">:</code>&#13;
        <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">secret-key-1</code>&#13;
          <code class="nt">secret</code><code class="p">:</code> <code class="l-Scalar-Plain">u7mcOcHKbFh9eVluB18hbFIsVfwpvgbXv650QacDYXA==</code>&#13;
    <code class="c1"># identity is a required (default) provider</code>&#13;
    <code class="p-Indicator">-</code> <code class="nt">identity</code><code class="p">:</code> <code class="p-Indicator">{}</code></pre>&#13;
&#13;
<p>The list of providers is ordered, meaning encryption will always occur using the first key and decryption will be attempted in order of keys listed. Identity is the default plain-text provider and should be last. If it’s first, secrets will not be encrypted.</p>&#13;
&#13;
<p>To respect the preceding configuration, every instance of the kube-apiserver must be updated to load the EncryptionConfiguration locally. In <em>/etc/kubernetes/manifests/kube-apiserver.yaml</em>, an argument can be added as follows.</p>&#13;
&#13;
<pre data-type="programlisting">--encryption-provider-config=/etc/kubernetes/pki/secrets/encryption-config.yaml</pre>&#13;
&#13;
<p>Once the kube-apiserver(s) restart, this change will take effect and secrets will be encrypted before being sent to etcd. The kube-apiserver restart may be automatic. For example, when using static Pods to run the API server, a change to the manifest file will trigger a restart. Once you’re past stages of experimentation, it’s recommended you pre-provision hosts with this file and ensure the <code>encryption-provider</code> is enabled by default. The EncryptionConfiguration file can be added using configuration management tools such as Ansible or, with cluster-api, by setting that static file in a kubeadmConfigSpec. Note this cluster-api approach will put the EncryptionConfiguration in user data; make sure the user data is encrypted!  Adding the <code>encryption-provider-config</code> flag to the API server can be done by adding the argument to the <code>apiServer</code> within a ClusterConfiguration, assuming you’re using kubeadm. <a data-primary="ClusterConfiguration" data-type="indexterm" id="idm45611986471256"/>Otherwise, ensure the flag is present based on your mechanism for starting the server.</p>&#13;
&#13;
<p>To validate the encryption, you can apply a new secret object to the API server. Assuming the secret is named <code>login2</code>, using the script from the previous section we can retrieve it as follows:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="c"># ./etcctl-script get /registry/secrets/default/login2</code>&#13;
&#13;
/registry/secrets/default/login2&#13;
k8s:enc:secretbox:v1:secret-key-1:^Dʜ&#13;
                                     HN,lU/:L kdR&lt;_h <code class="o">(</code>fO<code class="nv">$V</code>&#13;
y.&#13;
  r/m&#13;
MٜjVĄGP&lt;%B0kZHY<code class="o">}</code>-&gt;q<code class="p">|&amp;</code>c?a<code class="se">\i</code><code class="c">#xoZsVXd+8_rCצgcj[Mv&lt;X5N):MQ'7݋t</code>&#13;
<code class="s1">'pLBxqݡ)b݉/+r49ޓ`f</code>&#13;
<code class="s1">                 6(iciQⰪſ$'</code>.ejbprλ<code class="o">=</code>Cp+R-D%q!r/pbv1_.izyPlQ<code class="o">)</code>1!7@X<code class="se">\0</code>&#13;
                                                                  EiĿr<code class="o">(</code>dwlS</pre>&#13;
&#13;
<p>Here <a data-primary="secretbox" data-type="indexterm" id="idm45611986457736"/>we can see the data is fully encrypted in etcd. Note there is metadata specifying which provider (<code>secretbox</code>) and key (<code>secret-key-1</code>) was used to do the encryption. This is important to Kubernetes as it supports many providers and keys at once. Any object created before the encryption key was set; let’s assume <code>login1</code> can be queried and will still show up in plain text:</p>&#13;
&#13;
<pre data-type="programlisting"># ./etcctl-script get /registry/secrets/default/login1&#13;
&#13;
/registry/secrets/default/login1&#13;
k8s</pre>&#13;
&#13;
<p>This demonstrates two important concepts. One, <code>login1</code> is <em>not</em> encrypted. While the encryption key is in place, only newly created or altered secret objects will be encrypted using this key. Secondly, when passing back through the kube-apiserver, no provider/key mapping is present and no decryption will be attempted. This latter concept is important because it is highly recommended you rotate encryption keys over a defined span. Let’s say you rotate once every three months. When three months have elapsed, we’d alter the EncryptionConfiguation as follows:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="p-Indicator">-</code> <code class="nt">secretbox</code><code class="p">:</code>&#13;
        <code class="nt">keys</code><code class="p">:</code>&#13;
        <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">secret-key-2</code>&#13;
          <code class="nt">secret</code><code class="p">:</code> <code class="l-Scalar-Plain">xgI5XTIRQHN/C6mlS43MuAWTSzuwkGSvIDmEcw6DDl8=</code>&#13;
        <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">secret-key-1</code>&#13;
          <code class="nt">secret</code><code class="p">:</code> <code class="l-Scalar-Plain">u7mcOcHKbFh9eVluB18hbFIsVfwpvgbXv650QacDYXA=</code></pre>&#13;
&#13;
<p>It is <em>crucial</em> that <code>secret-key-1</code> is not removed. While it will not be used for new encryption, it is used for existing secret objects, previously encrypted by it, for decryption! The removal of this key will prevent the API server from returning secret objects, such as <code>login2</code>, to clients. Since this key is first, it will be used for all new encryption. When secret objects are updated, they will be re-encrypted using this new key over time. Until then, the original key can remain in the list as a fallback decryption option. If you delete the key, you’ll see the following responses from your client:</p>&#13;
&#13;
<pre data-type="programlisting">Error from server (InternalError): Internal error occurred: unable to transform&#13;
key "/registry/secrets/default/login1": no matching key was found for the&#13;
provided Secretbox transformer</pre>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45611986405896">&#13;
<h5>Authors Recommendation: Understand New Vectors</h5>&#13;
<p>With each step taken toward increasing your defense in depth, it is crucial you understand how attack vectors have shifted.<a data-primary="attack vectors, new, understanding" data-type="indexterm" id="idm45611986404392"/> The static-key encryption model is certainly more secure than no encryption. However, note that the encryption key lives on the same host at the API server. Many Kubernetes deployments run etcd and the kube-apiserver on the same host, meaning with root access, the attacker could decrypt the data they query from etcd.&#13;
Ideally, you should not rely solely on encryption at rest using a static key. If this is unacceptable, it may be time to consider using an external secret store or leveraging a KMS-plug-in. Both of these alternative approaches are covered in subsequent sections.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Envelope Encryption" data-type="sect2"><div class="sect2" id="idm45611986586728">&#13;
<h2>Envelope Encryption</h2>&#13;
&#13;
<p>Kubernetes 1.10 and later supports integrating with a KMS to achieve envelope encryption.<a data-primary="encryption" data-secondary="envelope" data-type="indexterm" id="idm45611986382632"/><a data-primary="secrets" data-secondary="Secret API" data-tertiary="envelope encryption" data-type="indexterm" id="idm45611986381656"/><a data-primary="envelope encryption" data-type="indexterm" id="idm45611986380440"/><a data-primary="keys" data-secondary="envelope encryption" data-type="indexterm" id="idm45611986379768"/> Envelope encryption involves two keys: the key encryption key (KEK) and the data encryption key (DEK). KEKs are stored externally in a KMS and aren’t at risk unless the KMS provider is compromised. KEKs are used to encrypt DEKs, which are responsible for encrypting Secret objects. Each Secret object gets its own unique DEK to encrypt and decrypt the data. Since DEKs are encrypted by a KEK, they can be stored with the data itself, preventing the kube-apiserver from needing to be aware of many keys. Architecturally, the flow of envelope encryption would look like the diagram shown in <a data-type="xref" href="#envelope_encryption">Figure 7-5</a>.</p>&#13;
&#13;
<figure><div class="figure" id="envelope_encryption">&#13;
<img alt="prku 0705" src="assets/prku_0705.png"/>&#13;
<h6><span class="label">Figure 7-5. </span>Flow to encrypt secrets using envelope encryption. The KMS layer lives outside the cluster.</h6>&#13;
</div></figure>&#13;
&#13;
<p>There can be some variance in how this flow works, based on a KMS provider, but generally this demonstrates how envelope encryption functions. There are multiple benefits to this model:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>KMS is external to Kubernetes, increasing security via isolation.</p>&#13;
</li>&#13;
<li>&#13;
<p>Centralization of KEKs enables easy rotation of keys.</p>&#13;
</li>&#13;
<li>&#13;
<p>Separation of DEK and KEK means that secret data is never sent to or known by the KMS</p>&#13;
</li>&#13;
<li>&#13;
<p>KMS is concerned only with decrypting DEKs.</p>&#13;
</li>&#13;
<li>&#13;
<p>Encryption of DEKs means they are easy to store alongside their secret, making management of keys in relation to their secrets easy.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The provider plug-ins work by running a privileged container implementing a gRPC server that can communicate with a remote KMS. This container runs exclusively on master nodes where a kube-apiserver is present. Then, similar to setting up encryption in the previous section, an EncryptionConfiguration must be added to master nodes with settings to communicate with the KMS plug-in:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">apiserver.config.k8s.io/v1</code>&#13;
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">EncryptionConfiguration</code>&#13;
<code class="nt">resources</code><code class="p">:</code>&#13;
<code class="p-Indicator">-</code> <code class="nt">resources</code><code class="p">:</code>&#13;
<code class="p-Indicator">-</code> <code class="l-Scalar-Plain">secrets</code>&#13;
<code class="nt">providers</code><code class="p">:</code>&#13;
<code class="p-Indicator">-</code> <code class="nt">kms</code><code class="p">:</code>&#13;
    <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">myKmsPlugin</code>&#13;
    <code class="nt">endpoint</code><code class="p">:</code> <code class="l-Scalar-Plain">unix:///tmp/socketfile.sock</code>&#13;
    <code class="nt">cachesize</code><code class="p">:</code> <code class="l-Scalar-Plain">100</code>&#13;
    <code class="nt">timeout</code><code class="p">:</code> <code class="l-Scalar-Plain">3s</code>&#13;
<code class="c1"># required, but not used for encryption</code>&#13;
<code class="p-Indicator">-</code> <code class="nt">identity</code><code class="p">:</code> <code class="p-Indicator">{}</code></pre>&#13;
&#13;
<p>Assuming the EncryptionConfiguration is saved on each master node at <em>/etc/kubernetes/pki/secrets/encryption-config.yaml</em>, the kube-apiserver arguments must be updated to include the following:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">--encryption-provider-config<code class="o">=</code>/etc/kubernetes/pki/secrets/encryption-config.yaml</pre>&#13;
&#13;
<p>Changing the value should restart the kube-apiserver. If it doesn’t, a restart is required for the change to take effect.</p>&#13;
&#13;
<p>From a design perspective, this is a viable model. However, KMS plug-in implementations are scarce and the ones that do exist are immature. When we wrote this book, the following data points are true. There are no tagged releases for the aws-encryption-provider (AWS) or the k8s-cloudkms-plugin (Google). Azure’s plug-in kubernetes-kms has notable limitations, such as no support for key rotation. So with the exception of running in a managed service, such as GKE where the KMS plug-in is automatically available and supported by Google, usage may prove unstable. Lastly, the only cloud provider-agnostic KMS plug-in available was kubernetes-vault-kms-plugin, which was only partially implemented and has been archived (abandoned).<a data-primary="secrets" data-secondary="Secret API" data-startref="ix_secrAPI" data-type="indexterm" id="idm45611986281000"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="External Providers" data-type="sect1"><div class="sect1" id="idm45611987120792">&#13;
<h1>External Providers</h1>&#13;
&#13;
<p>Kubernetes is not what we’d consider an enterprise-grade secret store.<a data-primary="secrets" data-secondary="external providers of secret management" data-type="indexterm" id="ix_secrext"/> While it does offer a Secret API that will be used for things like Service Accounts, for enterprise secret data it may fall short. There is nothing inherently wrong with using it to store application secrets, as long as the risks and options are understood, which is largely what this chapter has described thus far! However, many of our clients demand more than what the Secret API can offer, especially those working in sectors such as financial services. These users need capabilities such as integration with a hardware security module (HSM) and have advanced key rotation policies.</p>&#13;
&#13;
<p>Our guidance is generally to start with what Kubernetes offers and see if the approaches to harden its security (i.e., encryption) are adequate. As described in the previous section, KMS encryption models that offer envelope encryption provide a pretty strong story around the safety of secret data in etcd. If we need to extend beyond this (and we often do), we then look to what secret management tooling preexists that the engineering team(s) have operational knowledge of. Running secret management systems in a production-ready capacity can be a challenging task, similar to running any stateful service where the data contained within needs to be not only highly available but protected from potential attackers.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Vault" data-type="sect2"><div class="sect2" id="idm45611986300072">&#13;
<h2>Vault</h2>&#13;
&#13;
<p>Vault is an open source project by HashiCorp.<a data-primary="secrets" data-secondary="external providers of secret management" data-tertiary="Vault" data-type="indexterm" id="idm45611986298680"/><a data-primary="Vault" data-type="indexterm" id="idm45611986297464"/><a data-primary="Hashicorp, Vault" data-type="indexterm" id="idm45611986296792"/> It is by far the most popular project we run into with our clients when it comes to secret management solutions.  Vault has found several ways to integrate in the cloud native space. Work has been done around providing first-class integration in frameworks such as Spring and in Kubernetes itself. One emerging pattern is to run Vault within Kubernetes and enable Vault to use the TokenReview API to <a data-primary="TokenReview API" data-type="indexterm" id="idm45611986295576"/>authenticate requests against the Kubernetes API Server. Next, we’ll explore two common Kubernetes integration points, including sidecar and initContainer injection along with a newer approach, CSI integration.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Cyberark" data-type="sect2"><div class="sect2" id="idm45611986293832">&#13;
<h2>Cyberark</h2>&#13;
&#13;
<p>Cyberark is another popular option we see with clients.<a data-primary="Cyberark" data-type="indexterm" id="idm45611986292584"/><a data-primary="secrets" data-secondary="external providers of secret management" data-tertiary="Cyberark" data-type="indexterm" id="idm45611986291880"/> As a company, it’s been around for a while, and often we find preexisting investments to exist and a desire to integrate Kubernetes with it. Cyberark offers a Credential Provider and Dynamic Access Provider (DAP). DAP provides multiple enterprise mechanisms Kubernetes administrators may want to integrate with. Similar to Vault, it supports the ability to use initContainers alongside your application to communicate with DAP.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Injection Integration" data-type="sect2"><div class="sect2" id="idm45611986289816">&#13;
<h2>Injection Integration</h2>&#13;
&#13;
<p>Once an external secret store is available to workloads in Kubernetes, there are several options for retrieval.<a data-primary="Vault" data-secondary="injection integration of secret store" data-type="indexterm" id="ix_Vltinjint"/><a data-primary="injection integration, external secret store" data-type="indexterm" id="ix_injint"/><a data-primary="secrets" data-secondary="external providers of secret management" data-tertiary="injection integration" data-type="indexterm" id="ix_secrextII"/> This section covers these approaches, our recommendations, and trade-offs. We’ll cover each design approach to consuming secrets and describe Vault’s implementation.</p>&#13;
&#13;
<p>This approach runs an initContainer and/or sidecar container to communicate with an external secret store. Typically, secrets are injected into the Pod’s filesystem, making them available to all containers running in a Pod. We highly recommend this approach when possible. The major benefit is that it decouples the secret store entirely from the application. However, this does make the platform more complex, as facilitating secret injection is now an offering of the Kubernetes-based platform.</p>&#13;
&#13;
<p>Vault’s implementation of this model uses a MutatingWebhook pointed at a vault-agent-injector.<a data-primary="MutatingWebhook (Vault)" data-type="indexterm" id="idm45611986232152"/><a data-primary="sidecars" data-secondary="Vault injection architecture" data-type="indexterm" id="idm45611986231512"/> As Pods are created, based on annotations, the vault-agent-injector adds an initContainer (used for retrieval of the initial secret) and a sidecar container to keep secrets updated, if needed. <a data-type="xref" href="#sidecar_injection_architecture_along_with_my_app">Figure 7-6</a> demonstrates this flow of interaction between the Pod and Vault.</p>&#13;
&#13;
<figure><div class="figure" id="sidecar_injection_architecture_along_with_my_app">&#13;
<img alt="prku 0706" src="assets/prku_0706.png"/>&#13;
<h6><span class="label">Figure 7-6. </span>Sidecar injection architecture. Along with my-app-container, all Vault Pods are run as sidecars.</h6>&#13;
</div></figure>&#13;
&#13;
<p>The configuration of the MutatingWebhook that will inject these vault-specific containers is as follows:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">admissionregistration.k8s.io/v1</code>&#13;
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">MutatingWebhookConfiguration</code>&#13;
<code class="nt">metadata</code><code class="p">:</code>&#13;
  <code class="nt">labels</code><code class="p">:</code>&#13;
    <code class="nt">app.kubernetes.io/instance</code><code class="p">:</code> <code class="l-Scalar-Plain">vault</code>&#13;
    <code class="nt">app.kubernetes.io/managed-by</code><code class="p">:</code> <code class="l-Scalar-Plain">Helm</code>&#13;
    <code class="nt">app.kubernetes.io/name</code><code class="p">:</code> <code class="l-Scalar-Plain">vault-agent-injector</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">vault-agent-injector-cfg</code>&#13;
<code class="nt">webhooks</code><code class="p">:</code>&#13;
<code class="p-Indicator">-</code> <code class="nt">admissionReviewVersions</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">v1beta1</code>&#13;
  <code class="nt">clientConfig</code><code class="p">:</code>&#13;
    <code class="nt">caBundle</code><code class="p">:</code> <code class="l-Scalar-Plain">REDACTED</code>&#13;
    <code class="nt">service</code><code class="p">:</code>&#13;
      <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">vault-agent-injector-svc</code>&#13;
      <code class="nt">namespace</code><code class="p">:</code> <code class="l-Scalar-Plain">default</code>&#13;
      <code class="nt">path</code><code class="p">:</code> <code class="l-Scalar-Plain">/mutate</code>&#13;
      <code class="nt">port</code><code class="p">:</code> <code class="l-Scalar-Plain">443</code>&#13;
  <code class="nt">failurePolicy</code><code class="p">:</code> <code class="l-Scalar-Plain">Ignore</code>&#13;
  <code class="nt">matchPolicy</code><code class="p">:</code> <code class="l-Scalar-Plain">Exact</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">vault.hashicorp.com</code>&#13;
  <code class="nt">namespaceSelector</code><code class="p">:</code> <code class="p-Indicator">{}</code>&#13;
  <code class="nt">objectSelector</code><code class="p">:</code> <code class="p-Indicator">{}</code>&#13;
  <code class="nt">reinvocationPolicy</code><code class="p">:</code> <code class="l-Scalar-Plain">Never</code>&#13;
  <code class="nt">rules</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="nt">apiGroups</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="s">""</code>&#13;
    <code class="nt">apiVersions</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">v1</code>&#13;
    <code class="nt">operations</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">CREATE</code>&#13;
    <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">UPDATE</code>&#13;
    <code class="nt">resources</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">pods</code>&#13;
    <code class="nt">scope</code><code class="p">:</code> <code class="s">'*'</code>&#13;
  <code class="nt">sideEffects</code><code class="p">:</code> <code class="l-Scalar-Plain">Unknown</code>&#13;
  <code class="nt">timeoutSeconds</code><code class="p">:</code> <code class="l-Scalar-Plain">30</code></pre>&#13;
&#13;
<p>The MutatingWebhook is invoked on every Pod CREATE or UPDATE event. While evaluation will occur on every Pod, not every Pod will be mutated, or injected with a vault-agent.<a data-primary="Pods" data-secondary="vault-agent injection" data-type="indexterm" id="idm45611986224152"/> The vault-agent-injector is looking for two annotations in every Pod spec:</p>&#13;
<dl>&#13;
<dt><code>vault.hashicorp.com/agent-inject: "true"</code></dt>&#13;
<dd>&#13;
<p>Instructs the injector to include a vault-agent initContainer, which retrieves secrets and writes them to the Pod’s filesystem, prior to other containers starting.</p>&#13;
</dd>&#13;
<dt><code>vault.hashicorp.com/agent-inject-status: "update"</code></dt>&#13;
<dd>&#13;
<p>Instructs the injector to include a vault-agent sidecar, which runs alongside the workload. It will update the secret, should it change in Vault. The initContainer still runs in this mode. This parameter is optional and when it is not included, the sidecar is not added.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>When the vault-agent-injector does a mutation based on <code>vault.hashicorp.com/agent-inject: "true"</code>, the following is added:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">initContainers</code><code class="p">:</code>&#13;
<code class="p-Indicator">-</code> <code class="nt">args</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">echo ${VAULT_CONFIG?} | base64 -d &gt; /tmp/config.json</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">vault agent -config=/tmp/config.json</code>&#13;
  <code class="nt">command</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">/bin/sh</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">-ec</code>&#13;
  <code class="nt">env</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">VAULT_CONFIG</code>&#13;
    <code class="nt">value</code><code class="p">:</code> <code class="l-Scalar-Plain">eyJhd</code>&#13;
  <code class="nt">image</code><code class="p">:</code> <code class="l-Scalar-Plain">vault:1.3.2</code>&#13;
  <code class="nt">imagePullPolicy</code><code class="p">:</code> <code class="l-Scalar-Plain">IfNotPresent</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">vault-agent-init</code>&#13;
  <code class="nt">securityContext</code><code class="p">:</code>&#13;
    <code class="nt">runAsGroup</code><code class="p">:</code> <code class="l-Scalar-Plain">1000</code>&#13;
    <code class="nt">runAsNonRoot</code><code class="p">:</code> <code class="l-Scalar-Plain">true</code>&#13;
    <code class="nt">runAsUser</code><code class="p">:</code> <code class="l-Scalar-Plain">100</code>&#13;
  <code class="nt">volumeMounts</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="nt">mountPath</code><code class="p">:</code> <code class="l-Scalar-Plain">/vault/secrets</code>&#13;
    <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">vault-secrets</code></pre>&#13;
&#13;
<p>When the vault-agent-injector sees the annotation <code>vault.hashicorp.com/agent-inject-status: "update"</code>, the following is added:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">containers</code><code class="p">:</code>&#13;
  <code class="c1">#</code>&#13;
  <code class="c1"># ORIGINAL WORKLOAD CONTAINER REMOVED FOR BREVITY</code>&#13;
  <code class="c1">#</code>&#13;
<code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">vault-agent</code>&#13;
  <code class="nt">args</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">echo ${VAULT_CONFIG?} | base64 -d &gt; /tmp/config.json</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">vault agent -config=/tmp/config.json</code>&#13;
  <code class="nt">command</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">/bin/sh</code>&#13;
  <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">-ec</code>&#13;
  <code class="nt">env</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">VAULT_CONFIG</code>&#13;
    <code class="nt">value</code><code class="p">:</code> <code class="l-Scalar-Plain">asdfasdfasd</code>&#13;
  <code class="nt">image</code><code class="p">:</code> <code class="l-Scalar-Plain">vault:1.3.2</code>&#13;
  <code class="nt">imagePullPolicy</code><code class="p">:</code> <code class="l-Scalar-Plain">IfNotPresent</code>&#13;
  <code class="nt">securityContext</code><code class="p">:</code>&#13;
    <code class="nt">runAsGroup</code><code class="p">:</code> <code class="l-Scalar-Plain">1000</code>&#13;
    <code class="nt">runAsNonRoot</code><code class="p">:</code> <code class="l-Scalar-Plain">true</code>&#13;
    <code class="nt">runAsUser</code><code class="p">:</code> <code class="l-Scalar-Plain">100</code>&#13;
  <code class="nt">volumeMounts</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="nt">mountPath</code><code class="p">:</code> <code class="l-Scalar-Plain">/vault/secrets</code>&#13;
    <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">vault-secrets</code></pre>&#13;
&#13;
<p>With the agents present, they will retrieve and download secrets based on the Pod annotations, such as the following annotation that requests a database secret from Vault:</p>&#13;
&#13;
<pre data-type="programlisting">vault.hashicorp.com/agent-inject-secret-db-creds: "serets/db/creds"</pre>&#13;
&#13;
<p>By default, the secret value will be persisted as if a Go map was printed out. Syntactically, it appears as follows. All secrets are put into <em>/vault/secrets</em>:</p>&#13;
&#13;
<pre data-type="programlisting">key: map[k:v],&#13;
key: map[k:v]</pre>&#13;
&#13;
<p>To ensure that formatting of a secret is optimal for consumption, Vault supports adding templates into the annotation of Pods. This uses standard Go templating. For example, to create a JDBC connection string, the following template can be applied to a secret named <code>creds</code>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">spec</code><code class="p">:</code>&#13;
  <code class="nt">template</code><code class="p">:</code>&#13;
    <code class="nt">metadata</code><code class="p">:</code>&#13;
      <code class="nt">annotations</code><code class="p">:</code>&#13;
        <code class="nt">vault.hashicorp.com/agent-inject</code><code class="p">:</code> <code class="s">"true"</code>&#13;
        <code class="nt">vault.hashicorp.com/agent-inject-status</code><code class="p">:</code> <code class="s">"update"</code>&#13;
        <code class="nt">vault.hashicorp.com/agent-inject-secret-db-creds</code><code class="p">:</code> <code class="s">"secrets/db/creds"</code>&#13;
        <code class="nt">vault.hashicorp.com/agent-inject-template-db-creds</code><code class="p">:</code> <code class="p-Indicator">|</code>&#13;
          <code class="no">{{- with secret "secrets/db/creds" -}}</code>&#13;
          <code class="no">jdbc:oracle:thin:{{ .Data.data.username }}/{{ .Data.data.password }}</code>&#13;
          <code class="no">{{- end }}</code></pre>&#13;
&#13;
<p>A primary area of complexity in this model is authentication and authorization of the requesting Pod.<a data-primary="authentication" data-secondary="methods provided by Vault" data-type="indexterm" id="idm45611985877352"/> Vault provides several <a href="https://www.vaultproject.io/docs/auth">authentication methods</a>. When running Vault within Kubernetes and especially in this sidecar injection model, you may wish to set up Vault to authenticate against Kubernetes so that Pods can provide their existing Service Account tokens as identity. Setting up this authentication mechanism appears as follows:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="c"># from within a vault container&#13;
</code><code>&#13;
</code><code>vault</code><code> </code><code>write</code><code> </code><code>auth/kubernetes/config</code><code> </code><code class="se">\&#13;
</code><code>    </code><code class="nv">kubernetes_host</code><code class="o">=</code><code class="s2">"</code><code class="s2">https://</code><code class="nv">$KUBERNETES_PORT_443_TCP_ADDR</code><code class="s2">:443</code><code class="s2">"</code><code> </code><code class="se">\ </code><a class="co" href="#callout_secret_management_CO3-1" id="co_secret_management_CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
    </code><code class="nv">kubernetes_ca_cert</code><code class="o">=</code><code>@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</code><code> </code><code class="se">\&#13;
</code><code>    </code><code class="nv">token_reviewer_jwt</code><code class="o">=</code><code class="se">\&#13;
</code><code>    </code><code class="s2">"</code><code class="k">$(</code><code>cat</code><code> </code><code>/var/run/secrets/kubernetes.io/serviceaccount/token</code><code class="k">)</code><code class="s2">"</code><code> </code><a class="co" href="#callout_secret_management_CO3-2" id="co_secret_management_CO3-2"><img alt="2" src="assets/2.png"/></a></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_secret_management_CO3-1" id="callout_secret_management_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This environment variable should be present in the Vault Pod by default.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO3-2" id="callout_secret_management_CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Location of this Pod’s Service Account token, used to auth against the Kubernetes API server when performing TokenReview requests.</p></dd>&#13;
</dl>&#13;
&#13;
<p>When requests for secrets enter Vault, the requester’s Service Account can then be validated by Vault.<a data-primary="TokenReview API" data-type="indexterm" id="idm45611985787944"/> Vault does this by communicating through the Kubernetes TokenReview API to validate the identity of the requester. Assuming the identity is validated, Vault must then determine whether the Service Account is authorized to access the secret.<a data-primary="authorization" data-secondary="requests for secrets in Vault" data-type="indexterm" id="idm45611985786856"/> These authorization policies and bindings between Service Accounts and policies must be configured and maintained within Vault. In Vault, a policy is written as follows:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="c"># from within a vault container</code>&#13;
vault policy write team-a - <code class="s">&lt;&lt;EOF</code>&#13;
&#13;
<code class="s">path "secret/data/team-a/*" {</code>&#13;
<code class="s">  capabilities = ["read"]</code>&#13;
<code class="s">}</code>&#13;
<code class="s">EOF</code></pre>&#13;
&#13;
<p>This has created a policy in Vault referred to as <code>team-a</code>, which provides read access to all the secrets within <em>secret/data/team-a/</em>:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">vault policy list&#13;
default&#13;
team-a&#13;
root</pre>&#13;
&#13;
<p>The last step is to associate the requester’s Service Account with the policy so Vault can authorize access:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code>vault</code><code> </code><code>write</code><code> </code><code>auth/kubernetes/role/database</code><code> </code><code class="se">\&#13;
</code><code>    </code><code class="nv">bound_service_account_names</code><code class="o">=</code><code>webapp</code><code> </code><code class="se">\ </code><a class="co" href="#callout_secret_management_CO4-1" id="co_secret_management_CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
    </code><code class="nv">bound_service_account_namespaces</code><code class="o">=</code><code>team-a</code><code> </code><code class="se">\ </code><a class="co" href="#callout_secret_management_CO4-2" id="co_secret_management_CO4-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
    </code><code class="nv">policies</code><code class="o">=</code><code>team-a</code><code> </code><code class="se">\ </code><a class="co" href="#callout_secret_management_CO4-3" id="co_secret_management_CO4-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
    </code><code class="nv">ttl</code><code class="o">=</code><code>20m</code><code> </code><a class="co" href="#callout_secret_management_CO4-4" id="co_secret_management_CO4-4"><img alt="4" src="assets/4.png"/></a></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_secret_management_CO4-1" id="callout_secret_management_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Name of the requester’s Service Account.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO4-2" id="callout_secret_management_CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Namespace of the requester.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO4-3" id="callout_secret_management_CO4-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Binding to associate this account to one or many policies.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO4-4" id="callout_secret_management_CO4-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Duration the vault-specific authorization token should live for. Once expired, authn/authz is performed again.</p></dd>&#13;
</dl>&#13;
&#13;
<p>The vault-specific process we have explored so far likely applies to any variety of external secret management stores. You’ll be faced with some amount of overhead regarding integration of identity and authorization around secret access when dealing with systems beyond Kubernetes core.<a data-primary="Vault" data-secondary="injection integration of secret store" data-startref="ix_Vltinjint" data-type="indexterm" id="idm45611985649400"/><a data-primary="injection integration, external secret store" data-startref="ix_injint" data-type="indexterm" id="idm45611985648392"/><a data-primary="secrets" data-secondary="external providers of secret management" data-startref="ix_secrextII" data-tertiary="injection integration" data-type="indexterm" id="idm45611985647352"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="CSI Integration" data-type="sect2"><div class="sect2" id="idm45611986288904">&#13;
<h2>CSI Integration</h2>&#13;
&#13;
<p>A newer approach to secret store integration is to leverage the secrets-store-csi-driver.<a data-primary="secrets-store-csi-driver" data-type="indexterm" id="ix_SSCSI"/><a data-primary="secrets" data-secondary="external providers of secret management" data-tertiary="CSI integration of secret store" data-type="indexterm" id="ix_secrextCSI"/><a data-primary="Container Storage Interface (CSI)" data-secondary="integration of secret store" data-type="indexterm" id="ix_CSIsecr"/> At the time of this writing, this is a Kubernetes subproject within kubernetes-sigs. This approach enables integration with secret management systems at a lower level. Namely, it enables Pods to gain access to externally hosted secrets without running a sidecar or initContainer to inject secret data into the Pod. The result is secret interaction feeling more like a platform service and less like something applications need to integrate with. The secrets-store-csi-driver runs a driver Pod (as a DaemonSet) on every host, simliar to how you’d expect a CSI driver to work with a storage provider.</p>&#13;
&#13;
<p>The driver then relies on a provider that is responsible for secret lookup in the external system.<a data-primary="Vault" data-secondary="vault-provider installation on hosts" data-type="indexterm" id="idm45611985639432"/> In the case of Vault, this would involve installing the <code>vault-provider</code> binary on every host. The binary location is expected to be where the driver’s <code>provider-dir</code> mount is set. This binary may preexist on the host or, most commonly, it is installed via a DaemonSet-like process. The overall architecture would appear close to what’s shown in <a data-type="xref" href="#CSI_driver">Figure 7-7</a>.</p>&#13;
&#13;
<figure><div class="figure" id="CSI_driver">&#13;
<img alt="prku 0707" src="assets/prku_0707.png"/>&#13;
<h6><span class="label">Figure 7-7. </span>CSI driver interaction flow.</h6>&#13;
</div></figure>&#13;
&#13;
<p>This is a fairly new approach that seems promising based on its UX and ability to abstract secret providers. However, it does pose additional challenges. For example, how is identity handled when the Pod itself is not requesting the secret? This is something the driver and/or provider must figure out since they’re making requests on behalf of the Pod.<a data-primary="SecretProviderClass" data-type="indexterm" id="idm45611985633736"/> For now, we can look at the primary API, which includes the SecretProviderClass. To interact with an external system such as Vault, the SecretProviderClass would look as follows:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">secrets-store.csi.x-k8s.io/v1alpha1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">SecretProviderClass</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">apitoken</code><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">provider</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">vault</code><code>&#13;
</code><code>  </code><code class="nt">parameters</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">roleName</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">teama</code><code class="s">"</code><code>&#13;
</code><code>    </code><code class="nt">vaultAddress</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">https://vault.secret-store:8000</code><code class="s">"</code><code> </code><a class="co" href="#callout_secret_management_CO5-1" id="co_secret_management_CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>    </code><code class="nt">objects</code><code class="p">:</code><code>  </code><code class="p-Indicator">|</code><code>&#13;
</code><code>      </code><code class="no">array:</code><code>&#13;
</code><code>        </code><code class="no">- |</code><code>&#13;
</code><code>          </code><code class="no">objectPath: "/secret/team-a" </code><a class="co" href="#callout_secret_management_CO5-2" id="co_secret_management_CO5-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>          </code><code class="no">objectName: "apitoken" </code><a class="co" href="#callout_secret_management_CO5-3" id="co_secret_management_CO5-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>          </code><code class="no">objectVersion: ""</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_secret_management_CO5-1" id="callout_secret_management_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This is the location of Vault and would have the Service name (<code>vault</code>) followed by the Namespace <code>secret-store</code>.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO5-2" id="callout_secret_management_CO5-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>This is the path in Vault the Key/Value object was written to.</p></dd>&#13;
<dt><a class="co" href="#co_secret_management_CO5-3" id="callout_secret_management_CO5-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>This is the actual object to lookup in <code>team-a</code>.</p></dd>&#13;
</dl>&#13;
&#13;
<p>With the SecretProviderClass in place, a Pod can consume and reference this as &#13;
<span class="keep-together">follows</span>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Pod</code>&#13;
<code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">v1</code>&#13;
<code class="nt">metadata</code><code class="p">:</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">busybox</code>&#13;
<code class="nt">spec</code><code class="p">:</code>&#13;
  <code class="nt">containers</code><code class="p">:</code>&#13;
  <code class="p-Indicator">-</code> <code class="nt">image</code><code class="p">:</code>&#13;
    <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">busybox</code>&#13;
    <code class="nt">volumeMounts</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">secrets-api</code>&#13;
      <code class="nt">mountPath</code><code class="p">:</code> <code class="s">"/etc/secrets/apitoken"</code>&#13;
      <code class="nt">readOnly</code><code class="p">:</code> <code class="l-Scalar-Plain">true</code>&#13;
  <code class="nt">volumes</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">secrets-api</code>&#13;
      <code class="nt">csi</code><code class="p">:</code>&#13;
        <code class="nt">driver</code><code class="p">:</code> <code class="l-Scalar-Plain">secrets-store.csi.k8s.com</code>&#13;
        <code class="nt">readOnly</code><code class="p">:</code> <code class="l-Scalar-Plain">true</code>&#13;
        <code class="nt">volumeAttributes</code><code class="p">:</code>&#13;
          <code class="nt">secretProviderClass</code><code class="p">:</code> <code class="s">"apitoken"</code></pre>&#13;
&#13;
<p>When this Pod starts, the driver and provider attempt to retrieve the secret data. The secret data will appear in a volume mount as any Kubernetes secret would, assuming authentication and authorization to the external provider is successful. From the driver Pod on the node, you can examine the logs to see the command sent to the provider:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">level=info msg="provider command invoked: /etc/kubernetes/&#13;
secrets-store-csi-providers/vault/provider-vault --attributes [REDACTED]&#13;
--secrets [REDACTED] [--targetPath /var/lib/kubelet/pods/&#13;
643d7d88-fa58-4f3f-a7eb-341c0adb5a88/volumes/kubernetes.io~csi/&#13;
secrets-store-inline/mount --permission 420]"</pre>&#13;
&#13;
<p>In summary, secret-store-csi-drive is an approach worth keeping an eye on. Over time, if the project stabilizes and providers begin to mature, we could see the approach becoming common for those building application platforms on top of Kubernetes.<a data-primary="secrets-store-csi-driver" data-startref="ix_SSCSI" data-type="indexterm" id="idm45611985476136"/><a data-primary="Container Storage Interface (CSI)" data-secondary="integration of secret store" data-startref="ix_CSIsecr" data-type="indexterm" id="idm45611985475288"/><a data-primary="secrets" data-secondary="external providers of secret management" data-startref="ix_secrextCSI" data-tertiary="CSI integration of secret store" data-type="indexterm" id="idm45611985474200"/><a data-primary="secrets" data-secondary="external providers of secret management" data-startref="ix_secrext" data-type="indexterm" id="idm45611985432376"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Secrets in the Declarative World" data-type="sect1"><div class="sect1" id="idm45611985645592">&#13;
<h1>Secrets in the Declarative World</h1>&#13;
&#13;
<p>A common aspiration of application deployments, continuous integration, and continuous delivery is to move purely into a declarative model.<a data-primary="declarative model, secrets in" data-type="indexterm" id="ix_decmod"/><a data-primary="secrets" data-secondary="in the declarative model" data-secondary-sortas="declarative" data-type="indexterm" id="ix_secrdec"/> This is the same model used in Kubernetes where you declare a desired state and over time controllers work to reconcile the desired state with current state. For application developers and DevOps teams, these aspirations commonly surface in a pattern called GitOps.<a data-primary="GitOps" data-type="indexterm" id="idm45611985471096"/> A &#13;
<span class="keep-together">central</span> tenet of most GitOps approaches is to use one or many git repositories as the source of truth for workloads. When a commit is seen on some branch or tag, it can be picked up by build and deploy processes, often inside a cluster. This eventually aims to make the available workload capable of receiving traffic. Models such as GitOps are covered at greater length in <a data-type="xref" href="ch15.html#chapter15">Chapter 15</a>.</p>&#13;
&#13;
<p>When taking a purist-declarative approach, secret data creates a unique challenge. Sure you can commit your configurations alongside your code, but what about the credentials and keys used by your application? We have a feeling an API key showing up in a commit might make some people unhappy. There are some ways around this. One is, of course, to keep secret data outside of this declarative model and repent your sins toward the GitOps gods. Another is to consider “sealing” your secret data, in a way that accessing the data exposes nothing about the meaningful value, which is what we’ll explore in the next section.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sealing Secrets" data-type="sect2"><div class="sect2" id="idm45611985467208">&#13;
<h2>Sealing Secrets</h2>&#13;
&#13;
<p>How can we truly seal a secret?<a data-primary="secrets" data-secondary="in the declarative model" data-secondary-sortas="declarative" data-tertiary="sealing secrets" data-type="indexterm" id="idm45611985465880"/> The concept is nothing new.<a data-primary="encryption" data-secondary="public and private keys" data-type="indexterm" id="idm45611985463528"/><a data-primary="public/private key cryptography" data-type="indexterm" id="ix_pubpri"/> Using asymmetric cryptography, we can ensure a way to encrypt secrets, commit them to places, and not worry about anyone exposing the data. In this model, we have an encryption key (typically public) and a decryption key (typically private). The idea is that any secret created by the encryption key cannot have its value compromised without the private key being compromised. Of course, we need to ensure many things to stay safe in this model, such as choose a cipher we can trust, ensure the private key is <em>always</em> safe, and establish both encryption key and secret data rotation policies. A model we’ll explore in the coming sections is how this looks when a private key is generated in the cluster, and developers can be distributed their own encryption key that they can use on their secret data.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sealed Secrets Controller" data-type="sect2"><div class="sect2" id="idm45611985459976">&#13;
<h2>Sealed Secrets Controller</h2>&#13;
&#13;
<p>Bitnami-labs/sealed-secrets is a commonly used, open source project for achieving what has been described.<a data-primary="secrets" data-secondary="in the declarative model" data-secondary-sortas="declarative" data-tertiary="sealed secrets controller" data-type="indexterm" id="ix_secrdecSSC"/><a data-primary="declarative model, secrets in" data-secondary="sealed secrets controller" data-type="indexterm" id="ix_decmodSSC"/><a data-primary="sealed-secret-controller" data-type="indexterm" id="ix_SSCtrl"/><a data-primary="Bitnami-labs/sealed-secrets" data-type="indexterm" id="idm45611985454072"/> However, should you choose alternative tooling or build something yourself, the key concepts are unlikely to change drastically.</p>&#13;
&#13;
<p>The key component to this project is a sealed-secret-controller that runs inside the cluster. By default, it generates the keys needed to perform encryption and decryption. On the client side, developers use a command-line utility called kubeseal.<a data-primary="kubeseal utility" data-type="indexterm" id="idm45611985452472"/> Being that we’re using asymmetric encryption, kubeseal needs to know only about the public key (for encryption). Once developers encrypt their data using it, they won’t even be able to decrypt the values directly. To get started, we first deploy the controller to the cluster:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">kubectl apply -f&#13;
https://github.com/bitnami-labs/sealed-secrets/releases/<code class="se">\</code>&#13;
download/v0.9.8/controller.yaml</pre>&#13;
&#13;
<p>By default, the controller will create encryption and decryption keys for us. However, it is possible to bring your own certificates. The public (cert) and private (key) are stored in a Kubernetes Secret under <em>kube-system/sealed-secret-key</em>. The next step is allowing developers to retrieve the encryption key so they can get to work. This should <em>not</em> be done by accessing the Kubernetes Secret directly. Instead, the controller exposes an endpoint that can be used to retrieve the encryption key. How you access this service is up to you, but clients need to be able to call it using the following command, which<a data-primary="kubeseal utility" data-secondary="kubeseal --fetch-cert command" data-type="indexterm" id="idm45611985394776"/> has its flow detailed in <a data-type="xref" href="#sealed_secret">Figure 7-8</a>:</p>&#13;
&#13;
<pre data-type="programlisting">kubeseal --fetch-cert</pre>&#13;
&#13;
<figure><div class="figure" id="sealed_secret">&#13;
<img alt="prku 0708" src="assets/prku_0708.png"/>&#13;
<h6><span class="label">Figure 7-8. </span>Sealed-secret-controller architecture.</h6>&#13;
</div></figure>&#13;
&#13;
<p>Once the public key is loaded in kubeseal, you can generate SealedSecret CRDs that contain (encrypted) secret data. These CRDs are stored in etcd. The sealed-secret-controller makes the secrets available using standard Kubernetes Secrets. To ensure SealedSecret data is converted to a Secret correctly, you can specify templates in the SealedSecret object.</p>&#13;
&#13;
<p>You can start with a Kubernetes Secret, like any other:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">v1</code>&#13;
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Secret</code>&#13;
<code class="nt">metadata</code><code class="p">:</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">mysecret</code>&#13;
<code class="nt">type</code><code class="p">:</code> <code class="l-Scalar-Plain">Opaque</code>&#13;
<code class="nt">data</code><code class="p">:</code>&#13;
  <code class="nt">dbuser</code><code class="p">:</code> <code class="l-Scalar-Plain">aGVwdGlvCg==</code>&#13;
  <code class="nt">dbkey</code><code class="p">:</code> <code class="l-Scalar-Plain">YmVhcmNhbm9lCg==</code></pre>&#13;
&#13;
<p>To “seal” the secret, you can<a data-primary="kubeseal utility" data-secondary="sealing a secret" data-type="indexterm" id="idm45611985380136"/> run kubeseal<a data-primary="SealedSecret object" data-type="indexterm" id="idm45611985336696"/> against it and generate an encrypted output in JSON:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">kubeseal mysecret.yaml</pre>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">{</code>&#13;
  <code class="nt">"kind"</code><code class="p">:</code> <code class="s2">"SealedSecret"</code><code class="p">,</code>&#13;
  <code class="nt">"apiVersion"</code><code class="p">:</code> <code class="s2">"bitnami.com/v1alpha1"</code><code class="p">,</code>&#13;
  <code class="nt">"metadata"</code><code class="p">:</code> <code class="p">{</code>&#13;
    <code class="nt">"name"</code><code class="p">:</code> <code class="s2">"mysecret"</code><code class="p">,</code>&#13;
    <code class="nt">"namespace"</code><code class="p">:</code> <code class="s2">"default"</code><code class="p">,</code>&#13;
    <code class="nt">"creationTimestamp"</code><code class="p">:</code> <code class="kc">null</code>&#13;
  <code class="p">},</code>&#13;
  <code class="nt">"spec"</code><code class="p">:</code> <code class="p">{</code>&#13;
    <code class="nt">"template"</code><code class="p">:</code> <code class="p">{</code>&#13;
      <code class="nt">"metadata"</code><code class="p">:</code> <code class="p">{</code>&#13;
        <code class="nt">"name"</code><code class="p">:</code> <code class="s2">"mysecret"</code><code class="p">,</code>&#13;
        <code class="nt">"namespace"</code><code class="p">:</code> <code class="s2">"default"</code><code class="p">,</code>&#13;
        <code class="nt">"creationTimestamp"</code><code class="p">:</code> <code class="kc">null</code>&#13;
      <code class="p">},</code>&#13;
      <code class="nt">"type"</code><code class="p">:</code> <code class="s2">"Opaque"</code>&#13;
    <code class="p">},</code>&#13;
    <code class="nt">"encryptedData"</code><code class="p">:</code> <code class="p">{</code>&#13;
      <code class="nt">"dbkey"</code><code class="p">:</code> <code class="s2">"gCHJL+3bTRLw6vL4Gf......"</code><code class="p">,</code>&#13;
      <code class="nt">"dbuser"</code><code class="p">:</code> <code class="s2">"AgCHJL+3bT......"</code>&#13;
    <code class="p">}</code>&#13;
  <code class="p">},</code>&#13;
  <code class="nt">"status"</code><code class="p">:</code> <code class="p">{</code>&#13;
&#13;
  <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>The preceding SealedSecret object can be placed anywhere. As long as the sealing key, held by the sealed-secret-controller is not compromised, the data will be safe. Rotation is especially important in this model, which is covered in a subsequent section.</p>&#13;
&#13;
<p>Once applied, the flow and storage look as described in <a data-type="xref" href="#sealed_secret_controller">Figure 7-9</a>.</p>&#13;
&#13;
<p>The Secret object made by the sealed-secret-controller is owned by its corresponding SealedSecret CRD:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">ownerReferences</code><code class="p">:</code>&#13;
<code class="p-Indicator">-</code> <code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">bitnami.com/v1alpha1</code>&#13;
  <code class="nt">controller</code><code class="p">:</code> <code class="l-Scalar-Plain">true</code>&#13;
  <code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">SealedSecret</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">mysecret</code>&#13;
  <code class="nt">uid</code><code class="p">:</code> <code class="l-Scalar-Plain">49ce4ab0-3b48-4c8c-8450-d3c90aceb9ee</code></pre>&#13;
&#13;
<figure><div class="figure" id="sealed_secret_controller">&#13;
<img alt="prku 0709" src="assets/prku_0709.png"/>&#13;
<h6><span class="label">Figure 7-9. </span>Sealed-secret-controller interaction around managing sealed and unsealed secrets.</h6>&#13;
</div></figure>&#13;
&#13;
<p>This means that if the SealedSecret is deleted, its corresponding Secret object will be garbage collected.<a data-primary="secrets" data-secondary="in the declarative model" data-secondary-sortas="declarative" data-startref="ix_secrdecSSC" data-tertiary="sealed secrets controller" data-type="indexterm" id="idm45611985198552"/><a data-primary="declarative model, secrets in" data-secondary="sealed secrets controller" data-startref="ix_decmodSSC" data-type="indexterm" id="idm45611985196776"/><a data-primary="sealed-secret-controller" data-startref="ix_SSCtrl" data-type="indexterm" id="idm45611985195528"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Key Renewal" data-type="sect2"><div class="sect2" id="idm45611985459352">&#13;
<h2>Key Renewal</h2>&#13;
&#13;
<p>If the sealed-secret private key is leaked (perhaps due to RBAC misconfiguration), every secret should be considered compromised.<a data-primary="secrets" data-secondary="in the declarative model" data-secondary-sortas="declarative" data-tertiary="renewing sealed secret keys" data-type="indexterm" id="idm45611985192888"/><a data-primary="declarative model, secrets in" data-secondary="renewing sealed secret keys" data-type="indexterm" id="idm45611985191336"/> It’s especially important that the sealing key is renewed on an interval and that you understand the scope of “renewal.” The default behavior is for this key to be renewed every 30 days. It does not replace the existing keys; instead, it is appended to the existing list of keys capable of unsealing the data. However, the new key is used for all new encryption activity. Most importantly, existing sealed secrets are not re-encrypted.</p>&#13;
&#13;
<p>In the event of a leaked key, you should:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Immediately rotate your encryption key.</p>&#13;
</li>&#13;
<li>&#13;
<p>Rotate all existing secrets.</p>&#13;
</li>&#13;
<li>&#13;
<p>Remember that just re-encrypting isn’t good enough. For example, someone could easily go into git history, find the old encrypted asset, and use the compromised key on it. Generally speaking, you should have rotation and renewal strategies for passwords and keys, respectively.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p class="pagebreak-before">SealedSecrets uses a trick where the Namespace is used during encryption. This provides an <a data-primary="SealedSecret object" data-secondary="Namespace used during encryption" data-type="indexterm" id="idm45611985185208"/>isolation mechanic where a SealedSecret truly belongs to the Namespace it was created in and cannot just be moved between them. Generally, this default behavior is the most secure and should just be left as is. However, it does support configurable access policies, which are covered in the sealed-secrets documentation.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Multicluster Models" data-type="sect2"><div class="sect2" id="idm45611985183576">&#13;
<h2>Multicluster Models</h2>&#13;
&#13;
<p>Another key consideration for sealed-secret models is deployment topologies involving many clusters.<a data-primary="declarative model, secrets in" data-secondary="multicluster deployment of sealed secrets" data-type="indexterm" id="idm45611985182168"/><a data-primary="secrets" data-secondary="in the declarative model" data-secondary-sortas="declarative" data-tertiary="multicluster deployment of sealed secrets" data-type="indexterm" id="idm45611985181128"/> Many of these topologies treat clusters ephemerally. In cases such as these, it may be harder to run sealed-secret-style controllers because—unless you are sharing private keys among them all—you now need to worry about having unique keys for each cluster. Additionally, the point of interaction a developer has to get the encryption key (as described in previous sections) goes from one cluster to many. While by no means an impossible problem to solve, it is worth considering.<a data-primary="public/private key cryptography" data-startref="ix_pubpri" data-type="indexterm" id="idm45611985178968"/></p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45611985177880">&#13;
<h5>Know the Scope!</h5>&#13;
<p>When working with clients, we often run into a misunderstanding around what SealedSecrets solves for.<a data-primary="SealedSecret object" data-secondary="misunderstanding of scope" data-type="indexterm" id="idm45611985176472"/> Commonly, there is the perception that you can use a SealedSecret approach as an alternative to encrypting etcd or running an enterprise-grade secret store such as Vault. These concerns are <em>not</em> what sealed secrets aim to solve! This approach enables us to encrypt and safely store data in git repositories. However, the private key and unencrypted secrets <em>still</em> end up in Kubernetes. This means, in the absence of taking any steps beyond Kubernetes Secret API defaults, they will exist in an unencrypted state (at the application layer). In summary, be sure to know the scope of this and all other solutions talked about in this chapter!<a data-primary="declarative model, secrets in" data-startref="ix_decmod" data-type="indexterm" id="idm45611985173880"/><a data-primary="secrets" data-secondary="in the declarative model" data-secondary-sortas="declarative" data-startref="ix_secrdec" data-type="indexterm" id="idm45611985172888"/></p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Best Practices for Secrets" data-type="sect1"><div class="sect1" id="idm45611985171000">&#13;
<h1>Best Practices for Secrets</h1>&#13;
&#13;
<p>Application consumption of secrets is highly dependent on the language and frameworks at play.<a data-primary="secrets" data-secondary="best practices" data-type="indexterm" id="ix_secrBP"/> While variance is high, there are general best practices we recommend and encourage application developers to consider.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Always Audit Secret Interaction" data-type="sect2"><div class="sect2" id="idm45611985116328">&#13;
<h2>Always Audit Secret Interaction</h2>&#13;
&#13;
<p>A Kubernetes cluster should be configured with auditing enabled.<a data-primary="auditing secret interaction" data-type="indexterm" id="idm45611985115064"/> Auditing allows you to specify the events that occur around specific resources. This will tell you when and by whom a resource was interacted with. For mutations, it will also detail what changed. Auditing secret events is critical in reacting to access issues. For details about auditing, see the cluster audit documentation.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Don’t Leak Secrets" data-type="sect2"><div class="sect2" id="idm45611985113576">&#13;
<h2>Don’t Leak Secrets</h2>&#13;
&#13;
<p>While leaking secrets is never desirable, in multitenant Kubernetes environments<a data-primary="leaking secrets" data-type="indexterm" id="idm45611985112280"/> it’s important to consider how secrets can be leaked. A common occurrence is to accidentally log a secret. For example, we have seen this a few times when platform engineers build operators (covered in <a data-type="xref" href="ch11.html#building_platform_services">Chapter 11</a>). These operators often deal with secrets for the systems they are managing and potentially external systems they need to connect to. During the development phase, it can be common to log this secret data for the sake of debugging. Logs go to stdout/stderr and are, in many Kubernetes-based platforms, forwarded to a log analysis platform. This means the secret may pass in plain text through many environments and systems.</p>&#13;
&#13;
<p>Kubernetes is primarily a declarative system. Developers write manifests that can easily contain secret data, especially when testing. Developers should work with caution to ensure that secrets used while testing don’t get committed into source control repositories.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Prefer Volumes Over Environment Variables" data-type="sect2"><div class="sect2" id="idm45611985109032">&#13;
<h2>Prefer Volumes Over Environment Variables</h2>&#13;
&#13;
<p>The most common ways to access secrets provided by Kubernetes is to propagate the value into an environment variable or volumes.<a data-primary="volumes" data-secondary="preferring over environment variables for access to secrets" data-type="indexterm" id="idm45611985107592"/><a data-primary="environment variables" data-secondary="for access to secrets, preferring volumes over" data-type="indexterm" id="idm45611985106648"/> For most applications, volumes should be preferred. Environment variables can have a higher chance of being leaked through various means—for example, an echo command performed while testing or a framework automatically dumping environment variables on startup or during a crash. This doesn’t mean these concerns are inherently solved for with volumes!</p>&#13;
&#13;
<p>Security aside, the key benefit to app developers is that when secrets change, volumes are automatically updated; this will enable hot-reloading of secrets such as tokens. For a secret change to take place with environment variables, Pods must be restarted.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Make Secret Store Providers Unknown to Your Application" data-type="sect2"><div class="sect2" id="idm45611985104200">&#13;
<h2>Make Secret Store Providers Unknown to Your Application</h2>&#13;
&#13;
<p>There are several approaches an application can take to retrieve and consume its required secrets.<a data-primary="secret store providers, making unknown to application" data-type="indexterm" id="idm45611985102792"/> These can range from calling a secret store within business logic to expecting an environment variable to be set on startup. Following the philosophy of separation of concerns, we recommend implementing secret consumption in a way that whether Kubernetes, Vault, or other providers are managing the secret does not matter to the application. Achieving this makes your application portable and platform agnostic, and it reduces the complexity of your app’s interaction. Complexity is reduced because for an application to retrieve secrets from a provider it needs to both understand how to talk to the provider and be able to authenticate for communication with the provider.</p>&#13;
&#13;
<p class="pagebreak-before">To achieve this provider-agnostic implementation, applications should prefer loading secrets from environment variables or volumes. As we said earlier, volumes are the most ideal. In this model, an application will assume the presence of secrets in one or many volumes. Since volumes can be updated dynamically (without Pod restart) the application can watch the filesystem if a hot-reload of secrets is desired. By consuming from the container’s local filesystem, it does not matter whether the backing store is Kubernetes or otherwise.</p>&#13;
&#13;
<p>Some application frameworks, such as Spring, include libraries to communicate directly to the API server and auto-inject secrets and configuration. While these utilities are convenient, consider the points just discussed to determine what approaches hold the most value to your application.<a data-primary="secrets" data-secondary="best practices" data-startref="ix_secrBP" data-type="indexterm" id="idm45611985099240"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45611985097736">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In this chapter we’ve explored the Kubernetes Secret API, ways to interact with secrets, means of storing secrets, how to seal secrets, and some best practices. With this knowledge, it’s important we consider the amount of depth we’re interested in protecting, and with that, determining how to prioritize solving for each layer.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>