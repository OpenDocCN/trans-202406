["```\n# build custom controller binary:\n$ go build -o cnat-controller .\n\n# launch custom controller locally:\n$ ./cnat-controller -kubeconfig=$HOME/.kube/config\n```", "```\n$ kubectl apply -f artifacts/examples/crd.yaml\n```", "```\n$ kubectl get crds\nNAME                            CREATED AT\nfoos.samplecontroller.k8s.io    2019-05-29T12:16:57Z\n```", "```\n$ kubectl apply -f artifacts/examples/example-foo.yaml\nfoo.samplecontroller.k8s.io/example-foo created\n\n$ kubectl get po,rs,deploy,foo\nNAME                                           READY   STATUS    RESTARTS   AGE\npod/example-foo-5b8c9679d8-xjhdf               1/1     Running   0          67s\n\nNAME                                           DESIRED   CURRENT   READY AGE\nreplicaset.extensions/example-foo-5b8c9679d8   1         1         1     67s\n\nNAME                                           READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.extensions/example-foo              1/1     1            1           67s\n\nNAME                                           AGE\nfoo.samplecontroller.k8s.io/example-foo        67s\n```", "```\n$ cat artifacts/examples/cnat-crd.yaml\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ats.cnat.programming-kubernetes.info\nspec:\n  group: cnat.programming-kubernetes.info\n  version: v1alpha1\n  names:\n    kind: At\n    plural: ats\n  scope: Namespaced\n\n$ cat artifacts/examples/cnat-example.yaml\napiVersion: cnat.programming-kubernetes.info/v1alpha1\nkind: At\nmetadata:\n  labels:\n    controller-tools.k8s.io: \"1.0\"\n  name: example-at\nspec:\n  schedule: \"2019-04-12T10:12:00Z\"\n  command: \"echo YAY\"\n```", "```\n$ ./hack/update-codegen.sh\n```", "```\n// +genclient\n// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\n\nconst (\n    PhasePending = \"PENDING\"\n    PhaseRunning = \"RUNNING\"\n    PhaseDone    = \"DONE\"\n)\n\n// AtSpec defines the desired state of At\ntype AtSpec struct {\n    // Schedule is the desired time the command is supposed to be executed.\n    // Note: the format used here is UTC time https://www.utctime.net\n    Schedule string `json:\"schedule,omitempty\"`\n    // Command is the desired command (executed in a Bash shell) to be\n    // executed.\n    Command string `json:\"command,omitempty\"`\n}\n\n// AtStatus defines the observed state of At\ntype AtStatus struct {\n    // Phase represents the state of the schedule: until the command is\n    // executed it is PENDING, afterwards it is DONE.\n    Phase string `json:\"phase,omitempty\"`\n}\n```", "```\nif when, err := c.syncHandler(key); err != nil {\n    c.workqueue.AddRateLimited(key)\n    return fmt.Errorf(\"error syncing '%s': %s, requeuing\", key, err.Error())\n} else if when != time.Duration(0) {\n    c.workqueue.AddAfter(key, when)\n} else {\n    // Finally, if no error occurs we Forget this item so it does not\n    // get queued again until another change happens.\n    c.workqueue.Forget(obj)\n}\n```", "```\n// syncHandler compares the actual state with the desired state and attempts\n// to converge the two. It then updates the Status block of the At resource\n// with the current status of the resource. It returns how long to wait\n// until the schedule is due.\nfunc (c *Controller) syncHandler(key string) (time.Duration, error) {\n    ...\n}\n```", "```\n...\n// If no phase set, default to pending (the initial phase):\nif instance.Status.Phase == \"\" {\n    instance.Status.Phase = cnatv1alpha1.PhasePending\n}\n\n// Now let's make the main case distinction: implementing\n// the state diagram PENDING -> RUNNING -> DONE\nswitch instance.Status.Phase {\ncase cnatv1alpha1.PhasePending:\n    klog.Infof(\"instance %s: phase=PENDING\", key)\n    // As long as we haven't executed the command yet, we need\n    // to check if it's time already to act:\n    klog.Infof(\"instance %s: checking schedule %q\", key, instance.Spec.Schedule)\n    // Check if it's already time to execute the command with a\n    // tolerance of 2 seconds:\n    d, err := timeUntilSchedule(instance.Spec.Schedule)\n    if err != nil {\n        utilruntime.HandleError(fmt.Errorf(\"schedule parsing failed: %v\", err))\n        // Error reading the schedule - requeue the request:\n        return time.Duration(0), err\n    }\n    klog.Infof(\"instance %s: schedule parsing done: diff=%v\", key, d)\n    if d > 0 {\n        // Not yet time to execute the command, wait until the\n        // scheduled time\n        return d, nil\n    }\n\n    klog.Infof(\n       \"instance %s: it's time! Ready to execute: %s\", key,\n       instance.Spec.Command,\n    )\n    instance.Status.Phase = cnatv1alpha1.PhaseRunning\ncase cnatv1alpha1.PhaseRunning:\n    klog.Infof(\"instance %s: Phase: RUNNING\", key)\n\n    pod := newPodForCR(instance)\n\n    // Set At instance as the owner and controller\n    owner := metav1.NewControllerRef(\n        instance, cnatv1alpha1.SchemeGroupVersion.\n        WithKind(\"At\"),\n    )\n    pod.ObjectMeta.OwnerReferences = append(pod.ObjectMeta.OwnerReferences, *owner)\n\n    // Try to see if the pod already exists and if not\n    // (which we expect) then create a one-shot pod as per spec:\n    found, err := c.kubeClientset.CoreV1().Pods(pod.Namespace).\n        Get(pod.Name, metav1.GetOptions{})\n    if err != nil && errors.IsNotFound(err) {\n        found, err = c.kubeClientset.CoreV1().Pods(pod.Namespace).Create(pod)\n        if err != nil {\n            return time.Duration(0), err\n        }\n        klog.Infof(\"instance %s: pod launched: name=%s\", key, pod.Name)\n    } else if err != nil {\n        // requeue with error\n        return time.Duration(0), err\n    } else if found.Status.Phase == corev1.PodFailed ||\n        found.Status.Phase == corev1.PodSucceeded {\n        klog.Infof(\n            \"instance %s: container terminated: reason=%q message=%q\",\n            key, found.Status.Reason, found.Status.Message,\n        )\n        instance.Status.Phase = cnatv1alpha1.PhaseDone\n    } else {\n        // Don't requeue because it will happen automatically\n        // when the pod status changes.\n        return time.Duration(0), nil\n    }\ncase cnatv1alpha1.PhaseDone:\n    klog.Infof(\"instance %s: phase: DONE\", key)\n    return time.Duration(0), nil\ndefault:\n    klog.Infof(\"instance %s: NOP\")\n    return time.Duration(0), nil\n}\n\n// Update the At instance, setting the status to the respective phase:\n_, err = c.cnatClientset.CnatV1alpha1().Ats(instance.Namespace).\n    UpdateStatus(instance)\nif err != nil {\n    return time.Duration(0), err\n}\n\n// Don't requeue. We should be reconcile because either the pod or\n// the CR changes.\nreturn time.Duration(0), nil\n```", "```\n// NewController returns a new cnat controller\nfunc NewController(\n    kubeClientset kubernetes.Interface,\n    cnatClientset clientset.Interface,\n    atInformer informers.AtInformer,\n    podInformer corev1informer.PodInformer) *Controller {\n\n    // Create event broadcaster\n    // Add cnat-controller types to the default Kubernetes Scheme so Events\n    // can be logged for cnat-controller types.\n    utilruntime.Must(cnatscheme.AddToScheme(scheme.Scheme))\n    klog.V(4).Info(\"Creating event broadcaster\")\n    eventBroadcaster := record.NewBroadcaster()\n    eventBroadcaster.StartLogging(klog.Infof)\n    eventBroadcaster.StartRecordingToSink(&typedcorev1.EventSinkImpl{\n        Interface: kubeClientset.CoreV1().Events(\"\"),\n    })\n    source := corev1.EventSource{Component: controllerAgentName}\n    recorder := eventBroadcaster.NewRecorder(scheme.Scheme, source)\n\n    rateLimiter := workqueue.DefaultControllerRateLimiter()\n    controller := &Controller{\n        kubeClientset: kubeClientset,\n        cnatClientset: cnatClientset,\n        atLister:      atInformer.Lister(),\n        atsSynced:     atInformer.Informer().HasSynced,\n        podLister:     podInformer.Lister(),\n        podsSynced:    podInformer.Informer().HasSynced,\n        workqueue:     workqueue.NewNamedRateLimitingQueue(rateLimiter, \"Ats\"),\n        recorder:      recorder,\n    }\n\n    klog.Info(\"Setting up event handlers\")\n    // Set up an event handler for when At resources change\n    atInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{\n        AddFunc: controller.enqueueAt,\n        UpdateFunc: func(old, new interface{}) {\n            controller.enqueueAt(new)\n        },\n    })\n    // Set up an event handler for when Pod resources change\n    podInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{\n        AddFunc: controller.enqueuePod,\n        UpdateFunc: func(old, new interface{}) {\n            controller.enqueuePod(new)\n        },\n    })\n    return controller\n}\n```", "```\nfunc timeUntilSchedule(schedule string) (time.Duration, error) {\n    now := time.Now().UTC()\n    layout := \"2006-01-02T15:04:05Z\"\n    s, err := time.Parse(layout, schedule)\n    if err != nil {\n        return time.Duration(0), err\n    }\n    return s.Sub(now), nil\n}\n```", "```\nfunc newPodForCR(cr *cnatv1alpha1.At) *corev1.Pod {\n    labels := map[string]string{\n        \"app\": cr.Name,\n    }\n    return &corev1.Pod{\n        ObjectMeta: metav1.ObjectMeta{\n            Name:      cr.Name + \"-pod\",\n            Namespace: cr.Namespace,\n            Labels:    labels,\n        },\n        Spec: corev1.PodSpec{\n            Containers: []corev1.Container{\n                {\n                    Name:    \"busybox\",\n                    Image:   \"busybox\",\n                    Command: strings.Split(cr.Spec.Command, \" \"),\n                },\n            },\n            RestartPolicy: corev1.RestartPolicyOnFailure,\n        },\n    }\n}\n```", "```\n$ dep version\ndep:\n version     : v0.5.1\n build date  : 2019-03-11\n git hash    : faa6189\n go version  : go1.12\n go compiler : gc\n platform    : darwin/amd64\n features    : ImportDuringSolve=false\n\n$ kustomize version\nVersion: {KustomizeVersion:v2.0.3 GitCommit:a6f65144121d1955266b0cd836ce954c04122dc8\n          BuildDate:2019-03-18T22:15:21+00:00 GoOs:darwin GoArch:amd64}\n\n$ kubebuilder version\nVersion: version.Version{\n  KubeBuilderVersion:\"1.0.8\",\n  KubernetesVendor:\"1.13.1\",\n  GitCommit:\"1adf50ed107f5042d7472ba5ab50d5e1d357169d\",\n  BuildDate:\"2019-01-25T23:14:29Z\", GoOs:\"unknown\", GoArch:\"unknown\"\n}\n```", "```\n$ kubebuilder init \\\n              --domain programming-kubernetes.info \\\n              --license apache2 \\\n              --owner \"Programming Kubernetes authors\"\nRun `dep ensure` to fetch dependencies (Recommended) [y/n]?\ny\ndep ensure\nRunning make...\nmake\ngo generate ./pkg/... ./cmd/...\ngo fmt ./pkg/... ./cmd/...\ngo vet ./pkg/... ./cmd/...\ngo run vendor/sigs.k8s.io/controller-tools/cmd/controller-gen/main.go all\nCRD manifests generated under 'config/crds'\nRBAC manifests generated under 'config/rbac'\ngo test ./pkg/... ./cmd/... -coverprofile cover.out\n?       github.com/mhausenblas/cnat-kubebuilder/pkg/apis        [no test files]\n?       github.com/mhausenblas/cnat-kubebuilder/pkg/controller  [no test files]\n?       github.com/mhausenblas/cnat-kubebuilder/pkg/webhook     [no test files]\n?       github.com/mhausenblas/cnat-kubebuilder/cmd/manager     [no test files]\ngo build -o bin/manager github.com/mhausenblas/cnat-kubebuilder/cmd/manager\n```", "```\n$ tree -I vendor\n.\n├── Dockerfile\n├── Gopkg.lock\n├── Gopkg.toml\n├── Makefile\n├── PROJECT\n├── bin\n│   └── manager\n├── cmd\n│   └── manager\n│       └── main.go\n├── config\n│   ├── crds\n│   ├── default\n│   │   ├── kustomization.yaml\n│   │   ├── manager_auth_proxy_patch.yaml\n│   │   ├── manager_image_patch.yaml\n│   │   └── manager_prometheus_metrics_patch.yaml\n│   ├── manager\n│   │   └── manager.yaml\n│   └── rbac\n│       ├── auth_proxy_role.yaml\n│       ├── auth_proxy_role_binding.yaml\n│       ├── auth_proxy_service.yaml\n│       ├── rbac_role.yaml\n│       └── rbac_role_binding.yaml\n├── cover.out\n├── hack\n│   └── boilerplate.go.txt\n└── pkg\n    ├── apis\n    │   └── apis.go\n    ├── controller\n    │   └── controller.go\n    └── webhook\n        └── webhook.go\n\n13 directories, 22 files\n```", "```\n$ kubebuilder create api \\\n              --group cnat \\\n              --version v1alpha1 \\\n              --kind At\nCreate Resource under pkg/apis [y/n]?\ny\nCreate Controller under pkg/controller [y/n]?\ny\nWriting scaffold for you to edit...\npkg/apis/cnat/v1alpha1/at_types.go\npkg/apis/cnat/v1alpha1/at_types_test.go\npkg/controller/at/at_controller.go\npkg/controller/at/at_controller_test.go\nRunning make...\ngo generate ./pkg/... ./cmd/...\ngo fmt ./pkg/... ./cmd/...\ngo vet ./pkg/... ./cmd/...\ngo run vendor/sigs.k8s.io/controller-tools/cmd/controller-gen/main.go all\nCRD manifests generated under 'config/crds'\nRBAC manifests generated under 'config/rbac'\ngo test ./pkg/... ./cmd/... -coverprofile cover.out\n?       github.com/mhausenblas/cnat-kubebuilder/pkg/apis        [no test files]\n?       github.com/mhausenblas/cnat-kubebuilder/pkg/apis/cnat   [no test files]\nok      github.com/mhausenblas/cnat-kubebuilder/pkg/apis/cnat/v1alpha1  9.011s\n?       github.com/mhausenblas/cnat-kubebuilder/pkg/controller  [no test files]\nok      github.com/mhausenblas/cnat-kubebuilder/pkg/controller/at       8.740s\n?       github.com/mhausenblas/cnat-kubebuilder/pkg/webhook     [no test files]\n?       github.com/mhausenblas/cnat-kubebuilder/cmd/manager     [no test files]\ngo build -o bin/manager github.com/mhausenblas/cnat-kubebuilder/cmd/manager\n```", "```\n$ tree config/ pkg/\nconfig/\n├── crds\n│   └── cnat_v1alpha1_at.yaml\n├── default\n│   ├── kustomization.yaml\n│   ├── manager_auth_proxy_patch.yaml\n│   ├── manager_image_patch.yaml\n│   └── manager_prometheus_metrics_patch.yaml\n├── manager\n│   └── manager.yaml\n├── rbac\n│   ├── auth_proxy_role.yaml\n│   ├── auth_proxy_role_binding.yaml\n│   ├── auth_proxy_service.yaml\n│   ├── rbac_role.yaml\n│   └── rbac_role_binding.yaml\n└── samples\n    └── cnat_v1alpha1_at.yaml\npkg/\n├── apis\n│   ├── addtoscheme_cnat_v1alpha1.go\n│   ├── apis.go\n│   └── cnat\n│       ├── group.go\n│       └── v1alpha1\n│           ├── at_types.go\n│           ├── at_types_test.go\n│           ├── doc.go\n│           ├── register.go\n│           ├── v1alpha1_suite_test.go\n│           └── zz_generated.deepcopy.go\n├── controller\n│   ├── add_at.go\n│   ├── at\n│   │   ├── at_controller.go\n│   │   ├── at_controller_suite_test.go\n│   │   └── at_controller_test.go\n│   └── controller.go\n└── webhook\n    └── webhook.go\n\n11 directories, 27 files\n```", "```\n$ kubectl create ns cnat && \\\n  kubectl config set-context $(kubectl config current-context) --namespace=cnat\n```", "```\n$ make install\ngo run vendor/sigs.k8s.io/controller-tools/cmd/controller-gen/main.go all\nCRD manifests generated under 'config/crds'\nRBAC manifests generated under 'config/rbac'\nkubectl apply -f config/crds\ncustomresourcedefinition.apiextensions.k8s.io/ats.cnat.programming-kubernetes.info created\n```", "```\n$ make run\ngo generate ./pkg/... ./cmd/...\ngo fmt ./pkg/... ./cmd/...\ngo vet ./pkg/... ./cmd/...\ngo run ./cmd/manager/main.go\n{\"level\":\"info\",\"ts\":1559152740.0550249,\"logger\":\"entrypoint\",\n  \"msg\":\"setting up client for manager\"}\n{\"level\":\"info\",\"ts\":1559152740.057556,\"logger\":\"entrypoint\",\n  \"msg\":\"setting up manager\"}\n{\"level\":\"info\",\"ts\":1559152740.1396701,\"logger\":\"entrypoint\",\n  \"msg\":\"Registering Components.\"}\n{\"level\":\"info\",\"ts\":1559152740.1397,\"logger\":\"entrypoint\",\n  \"msg\":\"setting up scheme\"}\n{\"level\":\"info\",\"ts\":1559152740.139773,\"logger\":\"entrypoint\",\n  \"msg\":\"Setting up controller\"}\n{\"level\":\"info\",\"ts\":1559152740.139831,\"logger\":\"kubebuilder.controller\",\n  \"msg\":\"Starting EventSource\",\"controller\":\"at-controller\",\n  \"source\":\"kind source: /, Kind=\"}\n{\"level\":\"info\",\"ts\":1559152740.139929,\"logger\":\"kubebuilder.controller\",\n  \"msg\":\"Starting EventSource\",\"controller\":\"at-controller\",\n  \"source\":\"kind source: /, Kind=\"}\n{\"level\":\"info\",\"ts\":1559152740.139971,\"logger\":\"entrypoint\",\n  \"msg\":\"setting up webhooks\"}\n{\"level\":\"info\",\"ts\":1559152740.13998,\"logger\":\"entrypoint\",\n  \"msg\":\"Starting the Cmd.\"}\n{\"level\":\"info\",\"ts\":1559152740.244628,\"logger\":\"kubebuilder.controller\",\n  \"msg\":\"Starting Controller\",\"controller\":\"at-controller\"}\n{\"level\":\"info\",\"ts\":1559152740.344791,\"logger\":\"kubebuilder.controller\",\n  \"msg\":\"Starting workers\",\"controller\":\"at-controller\",\"worker count\":1}\n```", "```\n$ kubectl apply -f config/crds/cnat_v1alpha1_at.yaml\ncustomresourcedefinition.apiextensions.k8s.io/ats.cnat.programming-kubernetes.info\nconfigured\n\n$ kubectl get crds\nNAME                                   CREATED AT\nats.cnat.programming-kubernetes.info   2019-05-29T17:54:51Z\n\n$ kubectl apply -f config/samples/cnat_v1alpha1_at.yaml\nat.cnat.programming-kubernetes.info/at-sample created\n```", "```\n...\n{\"level\":\"info\",\"ts\":1559153311.659829,\"logger\":\"controller\",\n  \"msg\":\"Creating Deployment\",\"namespace\":\"cnat\",\"name\":\"at-sample-deployment\"}\n{\"level\":\"info\",\"ts\":1559153311.678407,\"logger\":\"controller\",\n  \"msg\":\"Updating Deployment\",\"namespace\":\"cnat\",\"name\":\"at-sample-deployment\"}\n{\"level\":\"info\",\"ts\":1559153311.6839428,\"logger\":\"controller\",\n  \"msg\":\"Updating Deployment\",\"namespace\":\"cnat\",\"name\":\"at-sample-deployment\"}\n{\"level\":\"info\",\"ts\":1559153311.693443,\"logger\":\"controller\",\n  \"msg\":\"Updating Deployment\",\"namespace\":\"cnat\",\"name\":\"at-sample-deployment\"}\n{\"level\":\"info\",\"ts\":1559153311.7023401,\"logger\":\"controller\",\n  \"msg\":\"Updating Deployment\",\"namespace\":\"cnat\",\"name\":\"at-sample-deployment\"}\n{\"level\":\"info\",\"ts\":1559153332.986961,\"logger\":\"controller\",#\n  \"msg\":\"Updating Deployment\",\"namespace\":\"cnat\",\"name\":\"at-sample-deployment\"}\n```", "```\nconst (\n    PhasePending = \"PENDING\"\n    PhaseRunning = \"RUNNING\"\n    PhaseDone    = \"DONE\"\n)\n\n// AtSpec defines the desired state of At\ntype AtSpec struct {\n    // Schedule is the desired time the command is supposed to be executed.\n    // Note: the format used here is UTC time https://www.utctime.net\n    Schedule string `json:\"schedule,omitempty\"`\n    // Command is the desired command (executed in a Bash shell) to be executed.\n    Command string `json:\"command,omitempty\"`\n}\n\n// AtStatus defines the observed state of At\ntype AtStatus struct {\n    // Phase represents the state of the schedule: until the command is executed\n    // it is PENDING, afterwards it is DONE.\n    Phase string `json:\"phase,omitempty\"`\n}\n```", "```\nfunc (r *ReconcileAt) Reconcile(req reconcile.Request) (reconcile.Result, error) {\n    reqLogger := log.WithValues(\"namespace\", req.Namespace, \"at\", req.Name)\n    reqLogger.Info(\"=== Reconciling At\")\n    // Fetch the At instance\n    instance := &cnatv1alpha1.At{}\n    err := r.Get(context.TODO(), req.NamespacedName, instance)\n    if err != nil {\n        if errors.IsNotFound(err) {\n            // Request object not found, could have been deleted after\n            // reconcile request—return and don't requeue:\n            return reconcile.Result{}, nil\n        }\n            // Error reading the object—requeue the request:\n        return reconcile.Result{}, err\n    }\n\n    // If no phase set, default to pending (the initial phase):\n    if instance.Status.Phase == \"\" {\n        instance.Status.Phase = cnatv1alpha1.PhasePending\n    }\n\n    // Now let's make the main case distinction: implementing\n    // the state diagram PENDING -> RUNNING -> DONE\n    switch instance.Status.Phase {\n    case cnatv1alpha1.PhasePending:\n        reqLogger.Info(\"Phase: PENDING\")\n        // As long as we haven't executed the command yet, we need to check if\n        // it's already time to act:\n        reqLogger.Info(\"Checking schedule\", \"Target\", instance.Spec.Schedule)\n        // Check if it's already time to execute the command with a tolerance\n        // of 2 seconds:\n        d, err := timeUntilSchedule(instance.Spec.Schedule)\n        if err != nil {\n            reqLogger.Error(err, \"Schedule parsing failure\")\n            // Error reading the schedule. Wait until it is fixed.\n            return reconcile.Result{}, err\n        }\n        reqLogger.Info(\"Schedule parsing done\", \"Result\", \"diff\",\n            fmt.Sprintf(\"%v\", d))\n        if d > 0 {\n            // Not yet time to execute the command, wait until the scheduled time\n            return reconcile.Result{RequeueAfter: d}, nil\n        }\n        reqLogger.Info(\"It's time!\", \"Ready to execute\", instance.Spec.Command)\n        instance.Status.Phase = cnatv1alpha1.PhaseRunning\n    case cnatv1alpha1.PhaseRunning:\n        reqLogger.Info(\"Phase: RUNNING\")\n        pod := newPodForCR(instance)\n        // Set At instance as the owner and controller\n        err := controllerutil.SetControllerReference(instance, pod, r.scheme)\n        if err != nil {\n            // requeue with error\n            return reconcile.Result{}, err\n        }\n        found := &corev1.Pod{}\n        nsName := types.NamespacedName{Name: pod.Name, Namespace: pod.Namespace}\n        err = r.Get(context.TODO(), nsName, found)\n        // Try to see if the pod already exists and if not\n        // (which we expect) then create a one-shot pod as per spec:\n        if err != nil && errors.IsNotFound(err) {\n            err = r.Create(context.TODO(), pod)\n            if err != nil {\n            // requeue with error\n                return reconcile.Result{}, err\n            }\n            reqLogger.Info(\"Pod launched\", \"name\", pod.Name)\n        } else if err != nil {\n            // requeue with error\n            return reconcile.Result{}, err\n        } else if found.Status.Phase == corev1.PodFailed ||\n                  found.Status.Phase == corev1.PodSucceeded {\n            reqLogger.Info(\"Container terminated\", \"reason\",\n                found.Status.Reason, \"message\", found.Status.Message)\n            instance.Status.Phase = cnatv1alpha1.PhaseDone\n        } else {\n            // Don't requeue because it will happen automatically when the\n            // pod status changes.\n            return reconcile.Result{}, nil\n        }\n    case cnatv1alpha1.PhaseDone:\n        reqLogger.Info(\"Phase: DONE\")\n        return reconcile.Result{}, nil\n    default:\n        reqLogger.Info(\"NOP\")\n        return reconcile.Result{}, nil\n    }\n\n    // Update the At instance, setting the status to the respective phase:\n    err = r.Status().Update(context.TODO(), instance)\n    if err != nil {\n        return reconcile.Result{}, err\n    }\n\n    // Don't requeue. We should be reconcile because either the pod\n    // or the CR changes.\n    return reconcile.Result{}, nil\n}\n```", "```\n$ make run\n...\n{\"level\":\"info\",\"ts\":1555063897.488535,\"logger\":\"controller\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063897.488621,\"logger\":\"controller\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063897.4886441,\"logger\":\"controller\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Target\":\"2019-04-12T10:12:00Z\"}\n{\"level\":\"info\",\"ts\":1555063897.488703,\"logger\":\"controller\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 10:12:00 +0000 UTC with a diff of 22.511336s\"}\n{\"level\":\"info\",\"ts\":1555063907.489264,\"logger\":\"controller\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063907.489402,\"logger\":\"controller\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063907.489428,\"logger\":\"controller\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Target\":\"2019-04-12T10:12:00Z\"}\n{\"level\":\"info\",\"ts\":1555063907.489486,\"logger\":\"controller\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 10:12:00 +0000 UTC with a diff of 12.510551s\"}\n{\"level\":\"info\",\"ts\":1555063917.490178,\"logger\":\"controller\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063917.4902349,\"logger\":\"controller\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063917.490247,\"logger\":\"controller\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Target\":\"2019-04-12T10:12:00Z\"}\n{\"level\":\"info\",\"ts\":1555063917.490278,\"logger\":\"controller\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 10:12:00 +0000 UTC with a diff of 2.509743s\"}\n{\"level\":\"info\",\"ts\":1555063927.492718,\"logger\":\"controller\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063927.49283,\"logger\":\"controller\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063927.492857,\"logger\":\"controller\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Target\":\"2019-04-12T10:12:00Z\"}\n{\"level\":\"info\",\"ts\":1555063927.492915,\"logger\":\"controller\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 10:12:00 +0000 UTC with a diff of -7.492877s\"}\n{\"level\":\"info\",\"ts\":1555063927.4929411,\"logger\":\"controller\",\n  \"msg\":\"It's time!\",\"namespace\":\"cnat\",\"at\":\n  \"example-at\",\"Ready to execute\":\"echo YAY\"}\n{\"level\":\"info\",\"ts\":1555063927.626236,\"logger\":\"controller\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063927.626303,\"logger\":\"controller\",\n  \"msg\":\"Phase: RUNNING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063928.07445,\"logger\":\"controller\",\n  \"msg\":\"Pod launched\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"name\":\"example-at-pod\"}\n{\"level\":\"info\",\"ts\":1555063928.199562,\"logger\":\"controller\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063928.199645,\"logger\":\"controller\",\n  \"msg\":\"Phase: DONE\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063937.631733,\"logger\":\"controller\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555063937.631783,\"logger\":\"controller\",\n  \"msg\":\"Phase: DONE\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n...\n```", "```\n$ kubectl get at,pods\nNAME                                                  AGE\nat.cnat.programming-kubernetes.info/example-at        11m\n\nNAME                 READY   STATUS        RESTARTS   AGE\npod/example-at-pod   0/1     Completed     0          38s\n```", "```\n$ kubectl logs example-at-pod\nYAY\n```", "```\n$ export IMG=quay.io/pk/cnat:v1\n\n$ make docker-build\n\n$ make docker-push\n```", "```\n$ dep version\ndep:\n version     : v0.5.1\n build date  : 2019-03-11\n git hash    : faa6189\n go version  : go1.12\n go compiler : gc\n platform    : darwin/amd64\n features    : ImportDuringSolve=false\n\n $ operator-sdk --version\noperator-sdk version v0.6.0\n```", "```\n$ operator-sdk new cnat-operator && cd cnat-operator\n```", "```\n$ operator-sdk add api \\\n               --api-version=cnat.programming-kubernetes.info/v1alpha1 \\\n               --kind=At\n\n$ operator-sdk add controller \\\n               --api-version=cnat.programming-kubernetes.info/v1alpha1 \\\n               --kind=At\n```", "```\n$ kubectl apply -f deploy/crds/cnat_v1alpha1_at_crd.yaml\n\n$ kubectl get crds\nNAME                                             CREATED AT\nats.cnat.programming-kubernetes.info             2019-04-01T14:03:33Z\n```", "```\n$ OPERATOR_NAME=cnatop operator-sdk up local --namespace \"cnat\"\nINFO[0000] Running the operator locally.\nINFO[0000] Using namespace cnat.\n{\"level\":\"info\",\"ts\":1555041531.871706,\"logger\":\"cmd\",\n  \"msg\":\"Go Version: go1.12.1\"}\n{\"level\":\"info\",\"ts\":1555041531.871785,\"logger\":\"cmd\",\n  \"msg\":\"Go OS/Arch: darwin/amd64\"}\n{\"level\":\"info\",\"ts\":1555041531.8718028,\"logger\":\"cmd\",\n  \"msg\":\"Version of operator-sdk: v0.6.0\"}\n{\"level\":\"info\",\"ts\":1555041531.8739321,\"logger\":\"leader\",\n  \"msg\":\"Trying to become the leader.\"}\n{\"level\":\"info\",\"ts\":1555041531.8743382,\"logger\":\"leader\",\n  \"msg\":\"Skipping leader election; not running in a cluster.\"}\n{\"level\":\"info\",\"ts\":1555041536.1611362,\"logger\":\"cmd\",\n  \"msg\":\"Registering Components.\"}\n{\"level\":\"info\",\"ts\":1555041536.1622112,\"logger\":\"kubebuilder.controller\",\n  \"msg\":\"Starting EventSource\",\"controller\":\"at-controller\",\n  \"source\":\"kind source: /, Kind=\"}\n{\"level\":\"info\",\"ts\":1555041536.162519,\"logger\":\"kubebuilder.controller\",\n  \"msg\":\"Starting EventSource\",\"controller\":\"at-controller\",\n  \"source\":\"kind source: /, Kind=\"}\n{\"level\":\"info\",\"ts\":1555041539.978822,\"logger\":\"metrics\",\n  \"msg\":\"Skipping metrics Service creation; not running in a cluster.\"}\n{\"level\":\"info\",\"ts\":1555041539.978875,\"logger\":\"cmd\",\n  \"msg\":\"Starting the Cmd.\"}\n{\"level\":\"info\",\"ts\":1555041540.179469,\"logger\":\"kubebuilder.controller\",\n  \"msg\":\"Starting Controller\",\"controller\":\"at-controller\"}\n{\"level\":\"info\",\"ts\":1555041540.280784,\"logger\":\"kubebuilder.controller\",\n  \"msg\":\"Starting workers\",\"controller\":\"at-controller\",\"worker count\":1}\n```", "```\n$ cat deploy/crds/cnat_v1alpha1_at_cr.yaml\napiVersion: cnat.programming-kubernetes.info/v1alpha1\nkind: At\nmetadata:\n  name: example-at\nspec:\n  schedule: \"2019-04-11T14:56:30Z\"\n  command: \"echo YAY\"\n\n$ kubectl apply -f deploy/crds/cnat_v1alpha1_at_cr.yaml\n\n$ kubectl get at\nNAME                                             AGE\nat.cnat.programming-kubernetes.info/example-at   54s\n```", "```\n// AtSpec defines the desired state of At\n// +k8s:openapi-gen=true\ntype AtSpec struct {\n    // Schedule is the desired time the command is supposed to be executed.\n    // Note: the format used here is UTC time https://www.utctime.net\n    Schedule string `json:\"schedule,omitempty\"`\n    // Command is the desired command (executed in a Bash shell) to be executed.\n    Command string `json:\"command,omitempty\"`\n}\n\n// AtStatus defines the observed state of At\n// +k8s:openapi-gen=true\ntype AtStatus struct {\n    // Phase represents the state of the schedule: until the command is executed\n    // it is PENDING, afterwards it is DONE.\n    Phase string `json:\"phase,omitempty\"`\n}\n```", "```\nfunc (r *ReconcileAt) Reconcile(request reconcile.Request) (reconcile.Result, error) {\n    *`the``-``same``-``as``-``for``-``kubebuilder`*\n}\n\n```", "```\n$ OPERATOR_NAME=cnatop operator-sdk up local --namespace \"cnat\"\nINFO[0000] Running the operator locally.\nINFO[0000] Using namespace cnat.\n...\n{\"level\":\"info\",\"ts\":1555044934.023597,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044934.023713,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044934.0237482,\"logger\":\"controller_at\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\n  \"example-at\",\"Target\":\"2019-04-12T04:56:00Z\"}\n{\"level\":\"info\",\"ts\":1555044934.02382,\"logger\":\"controller_at\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 04:56:00 +0000 UTC with a diff of 25.976236s\"}\n{\"level\":\"info\",\"ts\":1555044934.148148,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044934.148224,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044934.148243,\"logger\":\"controller_at\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Target\":\"2019-04-12T04:56:00Z\"}\n{\"level\":\"info\",\"ts\":1555044934.1482902,\"logger\":\"controller_at\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 04:56:00 +0000 UTC with a diff of 25.85174s\"}\n{\"level\":\"info\",\"ts\":1555044944.1504588,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044944.150568,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044944.150599,\"logger\":\"controller_at\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Target\":\"2019-04-12T04:56:00Z\"}\n{\"level\":\"info\",\"ts\":1555044944.150663,\"logger\":\"controller_at\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 04:56:00 +0000 UTC with a diff of 15.84938s\"}\n{\"level\":\"info\",\"ts\":1555044954.385175,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044954.3852649,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044954.385288,\"logger\":\"controller_at\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Target\":\"2019-04-12T04:56:00Z\"}\n{\"level\":\"info\",\"ts\":1555044954.38534,\"logger\":\"controller_at\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 04:56:00 +0000 UTC with a diff of 5.614691s\"}\n{\"level\":\"info\",\"ts\":1555044964.518383,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044964.5184839,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: PENDING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044964.518566,\"logger\":\"controller_at\",\n  \"msg\":\"Checking schedule\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Target\":\"2019-04-12T04:56:00Z\"}\n{\"level\":\"info\",\"ts\":1555044964.5186381,\"logger\":\"controller_at\",\n  \"msg\":\"Schedule parsing done\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Result\":\"2019-04-12 04:56:00 +0000 UTC with a diff of -4.518596s\"}\n{\"level\":\"info\",\"ts\":1555044964.5186849,\"logger\":\"controller_at\",\n  \"msg\":\"It's time!\",\"namespace\":\"cnat\",\"at\":\"example-at\",\n  \"Ready to execute\":\"echo YAY\"}\n{\"level\":\"info\",\"ts\":1555044964.642559,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044964.642622,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: RUNNING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044964.911037,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044964.9111192,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: RUNNING\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044966.038684,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044966.038771,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: DONE\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044966.708663,\"logger\":\"controller_at\",\n  \"msg\":\"=== Reconciling At\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n{\"level\":\"info\",\"ts\":1555044966.708749,\"logger\":\"controller_at\",\n  \"msg\":\"Phase: DONE\",\"namespace\":\"cnat\",\"at\":\"example-at\"}\n...\n```", "```\n$ kubectl get at,pods\nNAME                                                  AGE\nat.cnat.programming-kubernetes.info/example-at        23m\n\nNAME                 READY   STATUS        RESTARTS   AGE\npod/example-at-pod   0/1     Completed     0          46s\n\n$ kubectl logs example-at-pod\nYAY\n```", "```\n$ operator-sdk build $REGISTRY/PROJECT/IMAGE\n```"]