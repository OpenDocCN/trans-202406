<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 8. Automating Analysis Execution with Workflows"><div class="chapter" id="automating_analysis_execution_with_work">
<h1><span class="label">Chapter 8. </span>Automating Analysis Execution <span class="keep-together">with Workflows</span></h1>

<p>So far, we’ve been <a contenteditable="false" data-primary="automating analysis execution with workflows" data-type="indexterm" id="ix_autoan"/>running individual commands<a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-type="indexterm" id="ix_wkfaut"/> manually in the terminal. However, the overwhelming majority of genomics work proper—the secondary analysis, in which we go from raw data to distilled information that we’ll then feed into downstream analysis to ultimately produce biological insight—involves running the same commands in the same order on all the data as it rolls off the sequencer. Look again at the GATK Best Practices workflows described in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06.xhtml#best_practices_for_germline_short_varia">6</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch07.xhtml#gatk_best_practices_for_somatic_variant">7</a>; imagine how tedious it would be to do all that manually for every sample. Newcomers to the field often find it beneficial to run through the commands involved step by step on test data, to gain an appreciation of the key steps, their requirements, and their quirks—that’s why we walked you through all that in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06.xhtml#best_practices_for_germline_short_varia">6</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch07.xhtml#gatk_best_practices_for_somatic_variant">7</a>—but at the end of the day, you’re going to want to automate all of that as much as possible. Automation not only reduces the amount of tedious manual work you need to do, but also increases the throughput of your analysis and reduces the opportunity for human error.</p>

<p>In this chapter, we cover that shift from individual commands or one-off scripts to repeatable workflows. We show you how to use a workflow management system (<em>Cromwell</em>), and language, WDL, that we selected primarily for their portability. We walk you through writing your first example workflow, executing it, and interpreting Cromwell’s output. Then, we do the same thing with a couple of more realistic workflows that run GATK and use scatter-gather parallelism.</p>

<section class="pagebreak-before" data-type="sect1" data-pdf-bookmark="Introducing WDL and Cromwell"><div class="sect1" id="introducing_wdl_and_cromwell">
<h1 class="less_space">Introducing WDL and Cromwell</h1>

<p>You might<a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-tertiary="WDL and Cromwell" data-type="indexterm" id="ix_wkfautWDL"/> remember<a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="WDL and Cromwell" data-type="indexterm" id="ix_autoanWDL"/> that we introduced the concept of workflows<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="and Cromwell" data-type="indexterm" id="ix_WDLCrm"/> in the technology primer (<a data-type="xref" href="ch03.xhtml#computing_technology_basics_for_life_sc">Chapter 3</a>). As we noted at the time, many tooling options are available for writing and running workflows, with a variety of features, strengths, and weaknesses. We can’t tell you the <em>best option overall</em>, because much of that determination would depend on your particular backgrounds and needs. For the purposes of this book, we’ve selected an option, the combination of Cromwell and WDL, that is most suitable for the breadth of audience and scope of needs that we are targeting.<a contenteditable="false" data-primary="WDL" data-see="Workflow Description Language" data-type="indexterm" id="idm45625632257608"/></p>

<p>We already briefly introduced WDL at that time, as well, but let’s recap the main points given that it was half a book ago and a lot of water under the bridge. As just mentioned, its full name is <em>Workflow Description Language</em>, but it’s generally referred to as WDL (pronounced “widdle”) for short. <a contenteditable="false" data-primary="domain-specific languages (DSLs)" data-type="indexterm" id="idm45625632255256"/>It’s a DSL commonly used for genomics workflows that was originally developed at the Broad Institute and has since<a contenteditable="false" data-primary="OpenWDL" data-type="indexterm" id="idm45625632253912"/> then evolved into a community-driven open source project under the auspices of a public group named <a href="https://openwdl.org">OpenWDL</a>. As a workflow language, it’s designed to be very accessible to bioinformatics newcomers who do not have any formal training in software programming while maximizing portability across different systems.</p>

<p>The workflow management system we’re going to use to actually <em>run</em> workflows written in WDL is <a contenteditable="false" data-primary="Cromwell workflow management system" data-type="indexterm" id="ix_Crmwl"/>Cromwell, an open source application, also developed at the Broad Institute. Cromwell is designed to be runnable in just about any modern Java-enabled computing environment, including popular HPC systems like Slurm and SGE, commercial clouds like GCP and AWS, and any laptop or desktop computer running on some flavor of Linux. This portability is a core feature of Cromwell, which is intended to facilitate running the same workflows at multiple institutions in order to maximize scientific collaboration and computational reproducibility in research. Another major portability-oriented feature of Cromwell is that it supports (but does not require) the use of containers for providing the code that you want to run within each component task of a given workflow. You’ll have the opportunity to try running both ways in the exercises in this chapter.</p>

<p>Finally, continuing in the spirit of collaboration and interoperability, Cromwell is also designed to support multiple workflow languages.<a contenteditable="false" data-primary="workflow languages" data-secondary="Cromwell support for" data-type="indexterm" id="idm45625632247736"/> Currently, it supports WDL as well as the CWL, another popular workflow language designed for portability and computational reproducibility.<a contenteditable="false" data-primary="Common Workflow Language (CWL)" data-type="indexterm" id="idm45625632246072"/></p>

<p>Cromwell offers two modes of operation: the one-shot run mode and the server mode.<a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="operating in one-shot run mode or server mode" data-type="indexterm" id="idm45625632244536"/> The <em>one-shot run mode</em> is a simple way of running Cromwell that involves a single command line: you give it a workflow and a file that lists workflow inputs, and it will start running, execute the workflow, and finally shut down when the workflow is done. This is convenient for running workflows episodically with minimal hassle, and it’s what we use in the exercises in this chapter. The <em>server mode</em> of operation involves setting up a persistent server that is always running, and submitting workflow execution requests to that server via a REST API (a type of programmatic <span class="keep-together">interface</span>).</p>

<p>Starting the Cromwell server is quite easy. After it’s running, it offers functionality that is not available in the single-run mode, some of which we cover in <a data-type="xref" href="ch11.xhtml#running_many_workflows_conveniently_in">Chapter 11</a>. However, managing its operation securely on an ongoing basis requires a specialized skill set that most individual researchers or small groups without dedicated support staff do not possess. In <a data-type="xref" href="ch11.xhtml#running_many_workflows_conveniently_in">Chapter 11</a>, we introduce you to Terra, a managed system operated by the Broad Institute that provides access to a persistent Cromwell server<a contenteditable="false" data-primary="Terra platform" data-type="indexterm" id="idm45625632237752"/> through a GUI as well as an API. <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="Terra platform, offering persistent Cromwell server and API" data-type="indexterm" id="idm45625632236504"/>That will give you the opportunity to try out Cromwell in server mode without having to administer a server yourself.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>We won’t cover Cromwell server administration in this book, so see the <a href="https://oreil.ly/8T7j8">Cromwell documentation</a> if you’re interested in learning more.</p>
</div>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="jamie_cromwellcomma_the_warp_pig">
<h5>Jamie Cromwell, the Warp Pig</h5>

<p>Wildly <a contenteditable="false" data-primary="Jamie the Warp Pig" data-type="indexterm" id="idm45625632230856"/>popular in sticker form, Jamie the Warp Pig is the Cromwell development team’s homage<a contenteditable="false" data-primary="Cromwell, James" data-type="indexterm" id="idm45625632229592"/> to James Cromwell, the American movie actor who starred in classics including nerd favorite <em>Star Trek 8: First Contact</em> and the children’s live-action farm tale <em>Babe</em>.</p>

<figure class="width-30 no-frame"><div id="the_mascot_of_the_cromwell_workflow_eng" class="figure"><img alt="The mascot of the Cromwell workflow engine." src="Images/gitc_08in01.png" width="1440" height="780"/></div></figure>

<p>In <em>First Contact</em>, Mr. Cromwell played Zefram Cochrane, the brilliant but frequently inebriated inventor of warp drive. In <em>Babe</em>, he played the gruff but ultimately kind-hearted farmer who wins the movie’s eponymous piglet at a country fair and changes his Christmas dinner plans when he realizes the young pig has the makings of a great sheepdog (er, sheep-pig?). The development team at the Broad Institute recognized in Mr. Cromwell’s dramatic range the flexibility that is frequently required from Cromwell the workflow engine, which is expected to run workloads ranging from trivial to extreme in a variety of computing environments. That’ll do, pig. That’ll do.</p>
</div></aside>

<p>Whether you run it as a one-shot or in server mode, Cromwell has interesting features that aim to promote efficiency and scalability—but no one wants to read a <span class="keep-together">laundry</span> list of features in a book like this, so let’s move on to the exercises and we’ll bring up those key features as they become <a contenteditable="false" data-primary="Cromwell workflow management system" data-startref="ix_Crmwl" data-type="indexterm" id="idm45625632222248"/>relevant<a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="WDL and Cromwell" data-startref="ix_autoanWDL" data-type="indexterm" id="idm45625632220776"/> along the<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="and Cromwell" data-startref="ix_WDLCrm" data-type="indexterm" id="idm45625632218936"/> way.<a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-startref="ix_wkfautWDL" data-tertiary="WDL and Cromwell" data-type="indexterm" id="idm45625632217112"/></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Installing and Setting Up Cromwell"><div class="sect1" id="installing_and_setting_up_cromwell">
<h1>Installing and Setting Up Cromwell</h1>

<p>In this chapter, we <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="installing and setting up" data-type="indexterm" id="ix_Crmwlins"/>examine and execute some <a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-tertiary="installing and setting up Cromwell" data-type="indexterm" id="ix_wkfautCrm"/>workflows <a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="installing and setting up Cromwell" data-type="indexterm" id="ix_autoanCrm"/>written in WDL to become acquainted with the basic structure of the language and learn how Cromwell manages inputs and outputs, logs, and so on. For continuity with the previous chapters, we run Cromwell on the GCP Compute Engine VM that we used earlier, in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#first_steps_in_the_cloud">4</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch05.xhtml#first_steps_with_gatk">5</a>. However, we’re no longer running anything from within the GATK container. Instead, we install and run Cromwell directly in the VM environment.</p>

<p>You’ll need to run a few installation commands because Cromwell requires Java, which is not preinstalled on the VM we’re using. To do so, log back in to your VM via SSH, just as you did in earlier chapters. Remember that you can always find your list of VM instances in the GCP console by going directly to the <a href="https://oreil.ly/sGeug">Compute Engine</a>, or, in the menu of GCP services on the left side of the console, click Compute Engine, if you’ve forgotten the URL.</p>

<p>In your VM, type <code><strong>java -version</strong></code> at the prompt. You should get the following output:</p>

<pre data-type="programlisting">
$ java -version
Command ’java’ not found, but can be installed with:
apt install openjdk-11-jre-headless  # version 11.0.3+7-1ubuntu2~19.04.1, or
apt install default-jre              # version 2:1.11-71
apt install openjdk-8-jre-headless   # version 8u212-b03-0ubuntu1.19.04.2
apt install openjdk-12-jre-headless  # version 12.0.1+12-1
apt install openjdk-13-jre-headless  # version 13~13-0ubunt1
Ask your administrator to install one of them.</pre>

<p>Cromwell<a contenteditable="false" data-primary="Java" data-secondary="version 8, requirement for Cromwell" data-type="indexterm" id="idm45625632199896"/> requires Java version 8, so let’s install the <code>openjdk-8-jre-headless</code> option, which<a contenteditable="false" data-primary="openjdk-8-jre-headless option, installing" data-type="indexterm" id="idm45625632197864"/> is a lightweight environment sufficient for our needs:</p>

<pre data-type="programlisting">
$ sudo apt install openjdk-8-jre-headless
Reading package lists... Done
Building dependency tree      
Reading state information... Done
[...]
done.</pre>

<p>This triggers the installation process, which should run to completion without error. You might see a few notifications but as long as you see that final <code>done</code> output, you should be fine. You can run the Java version check again to satisfy yourself that the installation was successful:</p>

<pre data-type="programlisting">
$ java -version
openjdk version "1.8.0_222"
OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~19.04.1-b10)
OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)</pre>

<p>With Java installed, let’s set up Cromwell itself, which comes with a companion utility called <code>Womtool</code> that we use for<a contenteditable="false" data-primary="Womtool" data-type="indexterm" id="idm45625632192456"/> syntax validation <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="installing and setting up" data-tertiary="setting up Cromwell" data-type="indexterm" id="idm45625632191192"/>and creating input files. They are both distributed as compiled <em>.jar</em> files, and we’ve included a copy in the book bundle, so you don’t need to do anything fancy except point to where they are located. To keep our commands as short as possible, let’s set up an environment variable pointing to their location. Let’s call it <em>BIN</em> for binary, a term often used to refer to the compiled form of a program:</p>

<pre data-type="programlisting">
$ export BIN=~/book/bin</pre>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="updating_cromwell_and_womtool_on_your_v">
<h5>Updating Cromwell and Womtool on Your VM</h5>

<p>In this book, we use<a contenteditable="false" data-primary="virtual machines (VMs)" data-secondary="updating Cromwell and Womtool on" data-type="indexterm" id="idm45625632185480"/> the latest release of Cromwell and <code>Womtool</code> available as of this writing, version 48.<a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="updating on your VM" data-type="indexterm" id="idm45625632183496"/><a contenteditable="false" data-primary="Womtool" data-secondary="updating on your VM" data-type="indexterm" id="idm45625632182056"/> Because you live in the future, newer versions might be available from the <a href="https://oreil.ly/FJQwF">Cromwell GitHub repository</a>. <a contenteditable="false" data-primary="curl utility" data-secondary="using to update Cromwell and Womtool on your VM" data-type="indexterm" id="idm45625632179864"/>If you want or need to use a more recent version on your VM, you can copy the newer <em>.jars</em> from the repository to your VM using <code>curl</code>, a classic command-line tool that retrieves files via URL, as shown in the following example:</p>

<pre class="small" data-type="programlisting">
$ curl -L -o ~/book/bin/cromwell-48.jar \
https://github.com/broadinstitute/cromwell/releases/download/48/cromwell-48.jar
 % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                Dload  Upload   Total   Spent    Left  Speed
100   605    0   605    0     0   3151      0 --:--:-- --:--:-- --:--:--  3151
100  186M  100  186M    0     0  78.1M      0  0:00:02  0:00:02 --:--:-- 92.3M</pre>

<p>In this command, the <code>-o</code> specifies the destination and filename of the copy, and the <code>-L</code> flag tells <code>curl</code> to follow redirect links, which is important because GitHub uses redirects to serve the actual file (hence, two lines appearing in <code>curl</code>’s log output).</p>

<p>To use this for a different version of Cromwell, simply change the version number accordingly. It shows up in three places: once in the destination filename, and twice in the URL. You can run the same command for <code>Womtool</code> as well; just substitute <span class="keep-together"><code><strong>womtool</strong></code></span> for <code>cromwell</code> in the destination filename and in the URL.</p>
</div></aside>

<p>Let’s check that we can run Cromwell <a contenteditable="false" data-primary="help" data-secondary="for Cromwell" data-type="indexterm" id="idm45625632170120"/>by asking for its <code>help</code> output, which presents a summary of the <a contenteditable="false" data-primary="server command (Cromwell)" data-type="indexterm" id="idm45625632168104"/>three commands you can give it: <code>server</code> and <code>submit</code> are part of the server mode we  discussed earlier, and <code>run</code> is the one-shot mode<a contenteditable="false" data-primary="server command (Cromwell)" data-type="indexterm" id="idm45625632165496"/> that <a contenteditable="false" data-primary="run command (Cromwell)" data-type="indexterm" id="idm45625632164168"/>we <a contenteditable="false" data-primary="submit command (Cromwell)" data-type="indexterm" id="idm45625632162904"/>use shortly:</p>

<pre data-type="programlisting">
$ java -jar $BIN/cromwell-48.jar --help
cromwell 48
Usage: java -jar /path/to/cromwell.jar [server|run|submit] [options] &lt;args&gt;...
 --help                   Cromwell - Workflow Execution Engine
 --version               
Command: server
Starts a web server on port 8000.  See the web server documentation for more 
details about the API endpoints.
Command: run [options] workflow-source
Run the workflow and print out the outputs in JSON format.
 workflow-source          Workflow source file or workflow url.
 --workflow-root &lt;value&gt;  Workflow root.
 -i, --inputs &lt;value&gt;     Workflow inputs file.
 -o, --options &lt;value&gt;    Workflow options file.
 -t, --type &lt;value&gt;       Workflow type.
 -v, --type-version &lt;value&gt;
                          Workflow type version.
 -l, --labels &lt;value&gt;     Workflow labels file.
 -p, --imports &lt;value&gt;    A directory or zipfile to search for workflow imports.
 -m, --metadata-output &lt;value&gt;
                          An optional directory path to output metadata.
Command: submit [options] workflow-source
Submit the workflow to a Cromwell server.
 workflow-source          Workflow source file or workflow url.
 --workflow-root &lt;value&gt;  Workflow root.
 -i, --inputs &lt;value&gt;     Workflow inputs file.
 -o, --options &lt;value&gt;    Workflow options file.
 -t, --type &lt;value&gt;       Workflow type.
 -v, --type-version &lt;value&gt;
                          Workflow type version.
 -l, --labels &lt;value&gt;     Workflow labels file.
 -p, --imports &lt;value&gt;    A directory or zipfile to search for workflow imports.
 -h, --host &lt;value&gt;       Cromwell server URL.</pre>

<p>It’s also worth doing the same thing for <code>Womtool</code>, to get a sense of the various utility commands available:</p>

<pre data-type="programlisting">
$ java -jar $BIN/womtool-48.jar --help
Womtool 48
Usage: java -jar Womtool.jar
[validate|inputs|parse|highlight|graph|upgrade|womgraph] [options]
workflow-source
 workflow-source          Path to workflow file.
 -i, --inputs &lt;value&gt;     Workflow inputs file.
 -h, --highlight-mode &lt;value&gt;
                          Highlighting mode, one of 'html', 'console'
(used only with 'highlight' command)
 -o, --optional-inputs &lt;value&gt;
                          If set, optional inputs are also included in the
inputs set. Default is 'true' (used onl
y with the inputs command)
 --help                  
 --version               
Command: validate
Validate a workflow source file. If inputs are provided then 'validate'
also checks that the inputs file is a valid set of inputs for the
workflow.
Command: inputs
Generate and output a new inputs JSON for this workflow.
Command: parse
(Deprecated; WDL draft 2 only) Print out the Hermes parser’s abstract
syntax tree for the source file.
Command: highlight
(Deprecated; WDL draft 2 only) Print out the Hermes parser’s abstract
syntax tree for the source file. Requires at least one of 'html' or 'console'
Command: graph
Generate and output a graph visualization of the workflow in .dot format
Command: upgrade
Automatically upgrade the WDL to version 1.0 and output the result.
Command: womgraph
(Advanced) Generate and output a graph visualization of Cromwell’s
internal Workflow Object Model structure for this workflow in .dot format</pre>

<p>Of the functions just listed, you’ll have the opportunity to use <code>inputs</code>, <code>validate</code>, and <code>graph</code> in this chapter.<a contenteditable="false" data-primary="graph function (Cromwell)" data-type="indexterm" id="idm45625632154456"/><a contenteditable="false" data-primary="validate function (Cromwell)" data-type="indexterm" id="idm45625632153352"/><a contenteditable="false" data-primary="inputs function (Cromwell)" data-type="indexterm" id="idm45625632152232"/></p>

<p>Now let’s check that you have all the workflow files that we provide for this chapter. If you followed the setup instructions in <a data-type="xref" href="ch04.xhtml#first_steps_in_the_cloud">Chapter 4</a>, you should have a code directory that you cloned from GitHub. Under <em>~/book/code</em>, you’ll see a directory <a contenteditable="false" data-primary="workflows directory" data-type="indexterm" id="idm45625632149064"/>called <em>workflows</em> that contains all of the code and related files that you’ll use in this chapter (aside from the data, which came from the bucket). You’re going to run commands from the home directory (instead of moving into a subdirectory as we did in earlier chapters), so to keep paths short in the various commands, let’s set up an environment variable to point to where the workflow files reside:</p>

<pre data-type="programlisting">
$ export WF=~/book/code/workflows</pre>

<p>Finally, let’s talk about text editors. <a contenteditable="false" data-primary="text editors" data-type="indexterm" id="idm45625632145608"/>In all but one of the exercises that follow, you’re simply going to view and run prewritten scripts that we provide, so for viewing you could just download or clone the files to your laptop and open them in your preferred text editor. In one exception, we suggest you modify a WDL to break it in order to see what Cromwell’s error messaging and handling behavior looks like, so you’ll need to actually edit the file. We show you how to do this using one of the shell’s<a contenteditable="false" data-primary="nano text editor" data-type="indexterm" id="idm45625632143912"/> built-in text editors, called <code>nano</code>, which is considered one of the most accessible for people who aren’t used to command-line text editors. You are of course welcome to use another shell editor like <code>vi</code> or <code>emacs</code> if you prefer; if so, it will be up to you to adapt the commands we provide accordingly.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45625632141112">
<h5>Choosing a Text Editor for WDL Development</h5>

<p>Moving beyond the scope of the book, if you want to write or edit your own WDLs, you might<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your own workflows" data-type="indexterm" id="idm45625632139640"/> find the shell <a contenteditable="false" data-primary="IDEs (integrated development environments)" data-type="indexterm" id="idm45625632138104"/>command-line text editors too limited. Whether you prefer to use a full integrated development environment (IDE) application like IntelliJ, or a simpler text editor with a GUI like Sublime, you can find a few recommended options that accept WDL<a contenteditable="false" data-primary="text editors" data-secondary="accepting WDL syntax highlighting" data-type="indexterm" id="idm45625632136488"/> syntax highlighting plug-ins in <a href="https://oreil.ly/JSNo1">this online documentation</a>. Note that you’ll need to transfer any code that you edit on your local machine back to your VM every time you want to try it out. Alternatively, you could test your code locally (Cromwell can run on your desktop) and run in the cloud only when you want to run at scale.</p>

<p>Another alternative is to use<a contenteditable="false" data-primary="Google Cloud Shell" data-secondary="using for WDL development" data-type="indexterm" id="idm45625632133512"/> Google Cloud Shell, which we introduced in <a data-type="xref" href="ch04.xhtml#first_steps_in_the_cloud">Chapter 4</a>, for your WDL development purposes. Cloud Shell provides a point-and-click code editor interface (currently in beta) which is a solid option for working entirely in the cloud. Unfortunately, it does not yet accept WDL syntax highlighting.</p>
</div></aside>

<p>Whatever you decide to use as a text editor, just make sure not to use a <em>word processor</em> like Microsoft Word or Google Docs. Those applications can introduce hidden characters and are therefore not appropriate for editing code files. With that all<a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-startref="ix_wkfautCrm" data-tertiary="installing and setting up Cromwell" data-type="indexterm" id="idm45625632129608"/> sorted <a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="installing and setting up Cromwell" data-startref="ix_autoanCrm" data-type="indexterm" id="idm45625632127480"/>out, let’s buckle up<a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="installing and setting up" data-startref="ix_Crmwlins" data-type="indexterm" id="idm45625632125560"/> and tackle your very first WDL workflow.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Your First WDL: Hello World"><div class="sect1" id="your_first_wdl_hello_world">
<h1>Your First WDL: Hello World</h1>

<p>We begin with <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-type="indexterm" id="ix_WDLwrHW"/>the simplest possible working<a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-tertiary="your first WDL, Hello World" data-type="indexterm" id="ix_wkfautHW"/> example of a <a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="your first WDL script, Hello World" data-type="indexterm" id="ix_autoanWDLHW"/>WDL script: the quintessential <code>HelloWorld</code>. If you’re not familiar with this, it’s a common trope in the documentation of programming languages; in a nutshell, the idea is to provide an introductory example with the minimum amount of code that produces the phrase <code>HelloWorld!</code>. We’re actually going to run through three basic WDL workflows to demonstrate this level of functionality, starting with the absolute minimum example, and then adding on just enough code to show core functionality that is technically not required yet needed for realistic use.</p>

<section data-type="sect2" data-pdf-bookmark="Learning Basic WDL Syntax Through a Minimalist Example"><div class="sect2" id="learning_basic_wdl_syntax_through_a_min">
<h2>Learning Basic WDL Syntax Through a Minimalist Example</h2>

<p>Let’s pull up the simplest <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-tertiary="learning basic WDL syntax" data-type="indexterm" id="idm45625632112568"/>example by loading the <em>hello-world.wdl</em> workflow file into the <code>nano</code> editor:</p>

<pre data-type="programlisting">
$ nano $WF/hello-world/hello-world.wdl</pre>

<p>As noted earlier, <code>nano</code> is a basic editor. <a contenteditable="false" data-primary="nano text editor" data-secondary="WDL Hello World script in" data-type="indexterm" id="idm45625632108200"/>You can use the arrow keys on your keyboard to move through the file. To exit the editor, press Ctrl+X.</p>

<p>This is what the minimalistic Hello World for WDL looks like:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">version</code> <code class="mf">1.0</code>

<code class="k">workflow</code> <code class="n">HelloWorld</code> <code class="p">{</code>
  <code class="k">call</code> <code class="n">WriteGreeting</code>
<code class="p">}</code>

<code class="k">task</code> <code class="n">WriteGreeting</code> <code class="p">{</code>
  <code class="k">command</code> <code class="p">{</code>
     <code class="n">echo</code> <code class="s">"Hello World"</code>
  <code class="p">}</code>
  <code class="k">output</code> <code class="p">{</code>
     <code class="kt">File</code> <code class="n">output_greeting</code> <code class="o">=</code> <code class="n">stdout</code><code class="p">()</code>
  <code class="p">}</code>
<code class="p">}</code></pre>

<p>First, let’s ignore everything except the one line that has the phrase <code>HelloWorld</code> in it, the one in which it’s in quotes. Do you recognize the command on that line? That’s right, it’s a simple <code>echo</code> command; you can run<a contenteditable="false" data-primary="echo command" data-secondary="in WDL Hello World script" data-type="indexterm" id="idm45625631723096"/> that line by itself right now in your terminal:</p>

<pre data-type="programlisting">
$ echo "Hello World"
Hello World</pre>

<p>So that’s the command at the heart of our script that performs the desired action, and everything else is wrapping to make it runnable in scripted form through our workflow management system.</p>

<p>Now let’s unpack that wrapping. At the highest level, we have just two distinct stanzas, or blocks <a contenteditable="false" data-primary="code blocks in WDL" data-type="indexterm" id="idm45625631676232"/>of code: the one starting with <code>workflow HelloWorld</code>, and the one starting with <code>task WriteGreeting</code>, with several lines of code between the curly <a contenteditable="false" data-primary="{} (curly braces)" data-secondary="enclosing code blocks in WDL" data-type="indexterm" id="idm45625631674168"/>braces in each case (the original designer of WDL really liked curly braces; you’ll see a lot more of them). We can summarize them like this:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">workflow</code> <code class="n">HelloWorld</code> <code class="p">{...}</code>

<code class="k">task</code> <code class="n">WriteGreeting</code> <code class="p">{...}</code></pre>

<p>This makes it really clear that our script is structured in two parts: the <code>workflow</code> block, which is where we call out the actions that we want the workflow to perform, and a <code>task</code> block, where we define the action details. Here we have only one task, which is not really typical given that most workflows consist of two or more tasks; we cover workflows with multiple tasks further in this section.</p>

<p>Let’s take a closer look at how the action—that is, the <a contenteditable="false" data-primary="tasks" data-secondary="task block in WDL script" data-type="indexterm" id="idm45625631669608"/>command—is defined in the <code>WriteGreeting</code> task:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">task</code> <code class="n">WriteGreeting</code> <code class="p">{</code>
  <code class="k">command</code> <code class="p">{</code>
     <code class="n">echo</code> <code class="s">"Hello World"</code>
  <code class="p">}</code>
  <code class="k">output</code> <code class="p">{</code>
     <code class="kt">File</code> <code class="n">output_greeting</code> <code class="o">=</code> <code class="n">stdout</code><code class="p">()</code>
  <code class="p">}</code>
<code class="p">}</code></pre>

<p>In the first line, we’re declaring that this is a task called <code>WriteGreeting</code>. Within the outermost curly braces, we can break the structure of the code into another two blocks of code: <code>command {...}</code> and <code>output {...}</code>. The <code>command</code> block is quite straightforward: it contains the <code>echo "Hello World"</code> command. <a contenteditable="false" data-primary="command block in WDL code" data-type="indexterm" id="idm45625631568744"/>So that’s pretty self-explanatory, right? In general, you can stick just about anything in there that you would run in your terminal shell, including pipes, multiline commands, and even blocks of “foreign” code like Python or R, provided that you wrap it in <a href="https://oreil.ly/VK1F8">heredoc syntax</a>. We provide examples of what that looks like in <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a>.</p>

<p>Meanwhile the <code>output</code> block is perhaps a bit less obvious. <a contenteditable="false" data-primary="output block in WDL code" data-type="indexterm" id="idm45625631494024"/>The goal here is to define the output of the <code>command</code> block we plan to run. We’re declaring that we expect the output will be a <code>File</code>, which we choose to call <code>output_greeting</code> (this name can be anything you want, except one of the reserved keywords, which are defined in the WDL specification). Then, in the slightly tricky bit, we’re stating that the output <a contenteditable="false" data-primary="I/O (input/output)" data-secondary="WDL code output to stdout" data-type="indexterm" id="idm45625631491416"/>content itself will be whatever is emitted to <code>stdout</code>. If you’re not that familiar<a contenteditable="false" data-primary="stdout" data-type="indexterm" id="idm45625631489416"/> with command-line terminology, <code>stdout</code> is short for <em>standard out</em>, and refers to the text output to the terminal window, meaning it’s what you see displayed in the terminal when you run a command. By default, this content is also saved to a text file in the execution directory (which we examine shortly), so here we’re saying that we designate that text file as the output of our command. It’s not a terribly realistic thing to do in a genomics workflow (although you might be surprised…we’ve seen stranger things), but then that’s what a Hello World is like!</p>

<p>Anyway, that’s our <code>task</code> block explained away. Now, let’s<a contenteditable="false" data-primary="workflow block in WDL script, Hello World" data-type="indexterm" id="idm45625631486168"/> look at the <code>workflow</code> block:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">workflow</code> <code class="n">HelloWorld</code> <code class="p">{</code>
  <code class="k">call</code> <code class="n">WriteGreeting</code>
<code class="p">}</code></pre>

<p>Well, that’s pretty simple. First, we declare that our workflow is called <code>HelloWorld</code>, and then, within the braces, we make a <code>call</code> statement to invoke the <code>WriteGreeting</code> task. <a contenteditable="false" data-primary="call statement in WDL script" data-type="indexterm" id="idm45625631450008"/>This means that when we actually run the workflow through Cromwell, it will attempt to execute the <code>WriteGreeting</code> task. Let’s try that out.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Running a Simple WDL with Cromwell on Your Google VM"><div class="sect2" id="running_a_simple_wdl_with_cromwell_on_y">
<h2>Running a Simple WDL with Cromwell on Your Google VM</h2>

<p>Exit the <code>nano</code> editor by pressing Ctrl+X and return<a contenteditable="false" data-primary="virtual machines (VMs)" data-secondary="running simple WDL with Cromwell on your Google VM" data-type="indexterm" id="idm45625631446344"/> to the shell <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-tertiary="running simple WDL with Cromwell on Google VM" data-type="indexterm" id="idm45625631444872"/>of your VM. You’re going to launch the <em>hello-world.wdl</em> workflow using the Cromwell <em>.jar</em> file that resides in the <em>~/book/bin</em> directory, which we aliased as <code>$BIN</code> during the setup part of this chapter. <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="running simple WDL on your Google VM" data-type="indexterm" id="idm45625631441272"/>The command is straightforward Java:</p>

<pre data-type="programlisting">
$ java -jar $BIN/cromwell-48.jar run $WF/hello-world/hello-world.wdl</pre>

<p>This command invokes<a contenteditable="false" data-primary="Java" data-secondary="running Cromwell in one-off workflow execution mode" data-type="indexterm" id="idm45625631438488"/> Java to run Cromwell using its one-off (run) workflow execution<a contenteditable="false" data-primary="one-off run execution mode, running Cromwell in" data-type="indexterm" id="idm45625631436856"/> mode, which we contrasted with the persistent <code>server</code> mode earlier in this chapter.<a contenteditable="false" data-primary="run command (Cromwell)" data-type="indexterm" id="idm45625631435176"/> So it’s just going to start up, run the workflow we provided as an input to the <code>run</code> command, and shut down when that’s done. For the moment, there is nothing else involved because our workflow is entirely self-contained; we cover how to parameterize the workflow to accept input files next.</p>

<p>Go ahead and run that command. If you have everything set up correctly, you should now see Cromwell begin to spit out a lot of output to the terminal. We show the most relevant parts of the output here, but we’ve omitted some blocks (indicated by <code>[...]</code>) that are of no interest for our immediate purposes:</p>

<pre data-type="programlisting">
[...]  
[2018-09-08 10:40:34,69] [info] SingleWorkflowRunnerActor: Workflow submitted
b6d224b0-ccee-468f-83fa-ab2ce7e62ab7  
[...]  
Call-to-Backend assignments: HelloWorld.WriteGreeting -&gt; Local
[2018-09-08 10:40:37,15] [info] WorkflowExecutionActor-b6d224b0-ccee-468f-83fa-
ab2ce7e62ab7 [b6d224b0]: Starting HelloWorld.WriteGreeting
[2018-09-08 10:40:38,08] [info] BackgroundConfigAsyncJobExecutionActor
[b6d224b0HelloWorld.WriteGreeting:NA:1]: echo "Hello World"
[2018-09-08 10:40:38,14] [info] BackgroundConfigAsyncJobExecutionActor 
[...]  
[2018-09-08 10:40:40,24] [info] WorkflowExecutionActor-b6d224b0-ccee-468f-83fa-
ab2ce7e62ab7 [b6d224b0]: Workflow HelloWorld complete. Final Outputs:
{  
  "HelloWorld.WriteGreeting.output_greeting": "/home/username/cromwell-
executions/HelloWorld/b6d224b0-ccee-468f-83fa-ab2ce7e62ab7/call-
WriteGreeting/execution/stdout"  
}  
[2018-09-08 10:40:40,28] [info] WorkflowManagerActor WorkflowActor-b6d224b0-ccee-
468f-83fa-ab2ce7e62ab7 is in a terminal state: WorkflowSucceededState
[2018-09-08 10:40:45,96] [info] SingleWorkflowRunnerActor workflow finished with
status ’Succeeded’.
[...]  
[2018-09-08 10:40:48,85] [info] Shutdown finished.</pre>

<p>As you can see, Cromwell’s standard output is a tad…well, verbose. Cromwell has been designed primarily for use as part of a suite of interconnected services, which we discuss in <a data-type="xref" href="ch11.xhtml#running_many_workflows_conveniently_in">Chapter 11</a>, where there is a dedicated interface for monitoring progress and output during routine use. The single-run mode is more commonly used for troubleshooting, so the development team has chosen to make the local execution mode very chatty to help with debugging. This can feel a bit overwhelming at first, but don’t worry: we’re here to show you how to decipher it all—or at least the parts that we care about.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Interpreting the Important Parts of Cromwell’s Logging Output"><div class="sect2" id="interpreting_the_important_parts_of_cro">
<h2>Interpreting the Important Parts of Cromwell’s Logging Output</h2>

<p>First, let’s check <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="interpreting important parts of logging output from Cromwell execution of WDL script" data-type="indexterm" id="ix_Crmwllog"/>that the output of our workflow<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-tertiary="interpreting parts of Cromwell's logging output" data-type="indexterm" id="ix_WDLwrHWCL"/> is what we expected. Find this set of lines in the terminal output:</p>

<pre data-type="programlisting">
WorkflowExecutionActor-b6d224b0-ccee-468f-83fa-ab2ce7e62ab7 [b6d224b0]: Workflow
HelloWorld complete. Final Outputs:
{  
  "HelloWorld.WriteGreeting.output_greeting": "/home/username/cromwell-
executions/HelloWorld/b6d224b0-ccee-468f-83fa-ab2ce7e62ab7/call-
WriteGreeting/execution/stdout"
}  </pre>

<p>Without going into the details just yet, we see that this provides a list in JSON format of the output files that were produced; in this case, just the one file that captured the <code>stdout</code> of our one <code>echo "Hello World"</code> command. <a contenteditable="false" data-primary="stdout" data-secondary="file capturing stdout of echo &quot;Hello World&quot;" data-type="indexterm" id="idm45625631398984"/>Cromwell gives us the fully <span class="keep-together">qualified</span> path, meaning it includes the directory structure above the working directory, which is really convenient because it allows us to use it in any command with a quick copy and paste. You can do that right now to look at the contents of the output file and verify that it contains what we expect:</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Keep in mind that in the command we show here, you need to replace the username and the execution directory hash. It might be easier to look for the equivalent line in your output than to customize our command.</p>
</div>

<pre data-type="programlisting">
$ cat ~/cromwell-executions/HelloWorld/b6d224b0-ccee-468f-83fa-
ab2ce7e62ab7/call-WriteGreeting/execution/stdout
Hello World</pre>

<p>And there it is! So we know it worked.</p>

<p>Now let’s take a few minutes to walk through the information that Cromwell is giving us in all that log output to identify the most relevant nuggets:</p>

<pre class="small" data-type="programlisting">
SingleWorkflowRunnerActor: Workflow submitted b6d224b0-ccee-468f-83fa-ab2ce7e62ab7</pre>

<blockquote>
<p>= <em>I’m looking at this one workflow and assigning it this unique identifier.</em></p>
</blockquote>

<p>Cromwell assigns a randomly generated unique identifier to every run of every workflow and creates a directory with that identifier, within which all of the intermediate and final files will be written. We go over the details of the output directory structure in a little bit. For now, all you really need to know is that this is designed to ensure that you will never overwrite the results of a previous run of the same workflow or experience collisions between different workflows that have the same name:</p>

<pre data-type="programlisting">
Call-to-Backend assignments: HelloWorld.WriteGreeting -&gt; Local </pre>

<blockquote>
<p>= <em>I’m planning to send this to the local machine for execution (as opposed to a remote server).</em></p>
</blockquote>

<p>By default, Cromwell runs workflows directly on your local machine; for example, your laptop. As we mentioned earlier, you can configure it to send jobs to a remote server or cloud service, instead; that’s what in Cromwell lingo is called a <em>backend assignment</em> (not to be confused with diaper duty):</p>

<pre data-type="programlisting">
Starting HelloWorld.WriteGreeting</pre>

<blockquote>
<p>= <em>I’m executing the <code>WriteGreeting</code> task call from the <code>HelloWorld</code> workflow now.</em></p>
</blockquote>

<p>Cromwell treats each task call in the workflow as a separate job to execute, and will give you individual updates about each one accordingly. If the workflow involves multiple task calls, Cromwell will organize them in a queue and send each out for execution when appropriate. We discuss some aspects of how that works a little later. With regard to the status reporting aspect, you can imagine that as soon as we move to running more complex workflows, getting these reports through the standard out is rather impractical. This is where frontend software that provides an interface to parse and organize all of this information can really come in handy; you’ll have an opportunity to experience that in <a data-type="xref" href="ch11.xhtml#running_many_workflows_conveniently_in">Chapter 11</a>:</p>

<pre data-type="programlisting">
[b6d224b0HelloWorld.WriteGreeting:NA:1]: echo "Hello World"</pre>

<blockquote>
<p>= <em>This is the actual command I’m running for this call.</em></p>
</blockquote>

<p>It’s not obvious from this particular call because we didn’t include any variables in our minimal Hello World example, but what Cromwell outputs here is the real command that will be executed. In the parameterized example that comes next, you can see that if we include a variable in the script, the log output will show the form of the command in which the variable has been replaced by the input value that we provide. This fully interpreted command also is output to the execution directory for the record:</p>

<pre data-type="programlisting">
[b6d224b0]: Workflow HelloWorld complete. Final Outputs:
{
"HelloWorld.WriteGreeting.output_greeting": "/home/username/cromwell-
executions/HelloWorld/b6d224b0-ccee-468f-83fa-ab2ce7e62ab7/call-
WriteGreeting/execution/stdout"
}</pre>

<blockquote>
<p>= <em>I’m done running this workflow. This is the full path to that output file(s) you wanted.</em></p>
</blockquote>

<p>As noted earlier, this provides a list in JSON format of all the output files that were produced, identified by their full namespace.<a contenteditable="false" data-primary="JSON" data-secondary="list of output files produced running WDL script with Cromwell" data-type="indexterm" id="idm45625631376536"/><a contenteditable="false" data-primary="namespace in file paths" data-type="indexterm" id="idm45625631375192"/> The namespace</p>

<pre data-type="programlisting">
HelloWorld.WriteGreeting.output_greeting </pre>

<p>tells us that we are looking at the <code>output_greeting</code> output by the call to the <code>WriteGreeting</code> task belonging to the <code>HelloWorld</code> workflow.</p>

<p>The <a contenteditable="false" data-primary="fully qualified file paths" data-type="indexterm" id="idm45625631370936"/>fully qualified path to the output file shows the entire directory structure; let’s unroll that and examine what each segment corresponds to:</p>

<pre data-type="programlisting">
~                                       (working directory)
cromwell-executions/                    (Cromwell master directory)
 HelloWorld                             (name of our workflow)
  b6d224b0-ccee-468f-83fa-ab2ce7e62ab7  (unique identifier of the run)
   call-WriteGreeting                   (name of our task call)
    execution                           (directory of execution files)</pre>

<p>The important piece in this structure is the nesting of workflow/identifier/calls. As you’ll see in the next exercise, any runs of a workflow with the same name will be added under the <em>HelloWorld</em> workflow directory, in a new directory with another unique identifier.</p>

<pre data-type="programlisting">
SingleWorkflowRunnerActor workflow finished with status 'Succeeded'.</pre>

<blockquote>
<p>= <em>Yo, everything worked!</em></p>
</blockquote>

<pre data-type="programlisting">
[2018-09-08 10:40:48,85] [info] Shutdown finished.</pre>

<blockquote>
<p>= <em>I’m all done here. Buh-bye.</em></p>
</blockquote>

<p>And that’s really all you need to care about at this point, concluding your first Cromwell workflow execution. <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-startref="ix_WDLwrHWCL" data-tertiary="interpreting parts of Cromwell's logging output" data-type="indexterm" id="idm45625631362984"/>Well done!<a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="interpreting important parts of logging output from Cromwell execution of WDL script" data-startref="ix_Crmwllog" data-type="indexterm" id="idm45625631360760"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Adding a Variable and Providing Inputs via JSON"><div class="sect2" id="adding_a_variable_and_providing_inputs">
<h2>Adding a Variable and Providing Inputs via JSON</h2>

<p>OK, but running a <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-tertiary="adding a variable and providing inputs via JSON" data-type="indexterm" id="ix_WDLwrHWvarin"/>completely self-contained WDL is unrealistic, so let’s look at how we add variables to bring in some external input that can change from run to run. In the <code>nano</code> editor, go ahead and open the <em>hello-world-var.wdl</em> from the code directory:</p>

<pre data-type="programlisting">
$ nano $WF/hello-world/hello-world-var.wdl</pre>

<p>What’s different? The <code>workflow</code> block is exactly the same, but now there’s a bit more going on in the <code>WriteGreeting</code> <code>task</code> block:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">task</code> <code class="n">WriteGreeting</code> <code class="p">{</code>
  
  <code class="k">input</code> <code class="p">{</code>
      <code class="kt">String</code> <code class="n">greeting</code>
  <code class="p">}</code>

  <code class="k">command</code> <code class="p">{</code>
     <code class="n">echo</code> <code class="s">"${greeting}"</code>
  <code class="p">}</code>

  <code class="k">output</code> <code class="p">{</code>
     <code class="kt">File</code> <code class="n">output_greeting</code> <code class="o">=</code> <code class="n">stdout</code><code class="p">()</code>
  <code class="p">}</code>
<code class="p">}</code></pre>

<p>The <code>Hello World</code> input to the <a contenteditable="false" data-primary="variables" data-secondary="adding variable to WDL script" data-type="indexterm" id="idm45625631333624"/><code>echo</code> command has <a contenteditable="false" data-primary="I/O (input/output)" data-secondary="input block in WDL script, Hello World" data-type="indexterm" id="idm45625631329288"/>been replaced by <code>${greeting}</code>, and we now have a new <code>input</code> block before the <code>command</code> block that contains the line <code>String greeting</code>. This line declares the variable called <code>greeting</code> and states that its value should be of type <code>String</code>; in other words, an alphanumeric sequence. <a contenteditable="false" data-primary="String type" data-type="indexterm" id="idm45625631325112"/><a contenteditable="false" data-primary="$ (dollar sign)" data-secondary="preceding variables" data-type="indexterm" id="idm45625631324008"/>This means that we have parameterized the greeting that will be echoed to the terminal; we’re going to be able to instruct Cromwell what to insert into the command on a run-by-run basis.</p>

<p>This leads to the next question: how do we provide<a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="providing inputs to WDL scripts in JSON format" data-type="indexterm" id="idm45625631322104"/> Cromwell with that value? We definitely don’t want to have to give it directly on the command line, because although this particular case is simple, in the future we might need to run workflows that expect dozens of values, many of them more complex than a simple <code>String</code>.</p>

<p>Cromwell expects you to provide inputs in <a href="https://www.json.org">JavaScript Object Notation</a> (JSON) text format. <a contenteditable="false" data-primary="JSON" data-secondary="providing inputs to WDL scripts in JSON format" data-type="indexterm" id="idm45625631318648"/>JSON has a key:value pair structure that allows us to assign a value to each variable. You can see an example of this in the <em>$WF/hello-world/hello-world.inputs.json</em> file that we provide:</p>

<pre data-code-language="json" data-type="programlisting">
<code class="p">{</code>
 <code class="nt">"HelloWorld.WriteGreeting.greeting"</code><code class="p">:</code> <code class="s2">"Hello Variable World"</code>
<code class="p">}</code></pre>

<p>In this simple <em>inputs</em> JSON file, we have defined the <code>greeting</code> variable from our <code>HelloWorld</code> workflow by its fully qualified name, which includes the name of the workflow itself (<code>HelloWorld</code>) and then the name of the task (<code>WriteGreeting</code>) because we declared the variable at the task level and then the name of the variable itself.</p>

<p>To provide the <em>inputs</em> JSON file to Cromwell, simply add it by using the <code>-i</code> argument (short for <code>--input</code>) to your Cromwell command, as follows:</p>

<pre data-type="programlisting">
$ java -jar $BIN/cromwell-48.jar run $WF/hello-world/hello-world-var.wdl \
-i $WF/hello-world/hello-world.inputs.json</pre>

<p>Look for the output the same way you did earlier; you should see the message in the file output by the workflow match the text in the JSON file.</p>

<p>Cromwell enforces the use of fully qualified names at all levels, which makes it impossible to declare global variables.<a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="enforcing use of fully qualified names at all levels" data-type="indexterm" id="idm45625630450296"/> Although this might feel like a burdensome constraint, it is much safer than the alternative, because it means that you can have variables with the same name in different parts of a workflow without causing collisions. In simple workflows, it’s easy enough to keep track of variables and prevent such problems, but in more complex workflows with dozens of more variables, that can become quite difficult. That is especially the case when you use imports and subworkflows to facilitate code reuse, which we cover in <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a> (ooh, spoilers). Note that you can declare a variable at the workflow level (and use the input naming syntax <em><code>WorkflowName.variable</code></em> in the <em>inputs</em> JSON file), but you’ll need to pass it explicitly to any task calls in which you want to use it. You’ll see an example of this in action later in this chapter.<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-startref="ix_WDLwrHWvarin" data-tertiary="adding a variable and providing inputs via JSON" data-type="indexterm" id="idm45625629189704"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Adding Another Task to Make It a Proper Workflow"><div class="sect2" id="adding_another_task_to_make_it_a_proper">
<h2>Adding Another Task to Make It a Proper Workflow</h2>

<p>Real-world workflows usually have more than one task, and some of their tasks are dependent on the outputs of others.<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-tertiary="adding another task for proper workflow" data-type="indexterm" id="ix_WDLwrHWtsk"/> In the <code>nano</code> editor, open <em>hello-world-again.wdl</em>:</p>

<pre data-type="programlisting">
$ nano $WF/hello-world/hello-world-again.wdl</pre>

<p>Here’s our third iteration attempt at a Hello World example, showing two tasks chained into a proper workflow:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">version</code> <code class="mf">1.0</code>

<code class="k">workflow</code> <code class="n">HelloWorldAgain</code> <code class="p">{</code>

  <code class="k">call</code> <code class="n">WriteGreeting</code>

  <code class="k">call</code> <code class="n">ReadItBackToMe</code> <code class="p">{</code>
     <code class="k">input</code><code class="o">:</code>
        <code class="n">written_greeting</code> <code class="o">=</code> <code class="n">WriteGreeting</code><code class="p">.</code><code class="n">output_greeting</code>
  <code class="p">}</code>

  <code class="k">output</code> <code class="p">{</code>
     <code class="kt">File</code> <code class="n">outfile</code> <code class="o">=</code> <code class="n">ReadItBackToMe</code><code class="p">.</code><code class="n">repeated_greeting</code>
  <code class="p">}</code>
<code class="p">}</code>

<code class="k">task</code> <code class="n">WriteGreeting</code> <code class="p">{</code>

  <code class="k">input</code> <code class="p">{</code> 
     <code class="kt">String</code> <code class="n">greeting</code>
  <code class="p">}</code>

  <code class="k">command</code> <code class="p">{</code>
     <code class="n">echo</code> <code class="s">"${greeting}"</code>
  <code class="p">}</code>
  <code class="k">output</code> <code class="p">{</code>
     <code class="kt">File</code> <code class="n">output_greeting</code> <code class="o">=</code> <code class="n">stdout</code><code class="p">()</code>
  <code class="p">}</code>
<code class="p">}</code>

<code class="k">task</code> <code class="n">ReadItBackToMe</code> <code class="p">{</code>

  <code class="k">input</code> <code class="p">{</code>
     <code class="kt">String</code> <code class="o">=</code> <code class="n">read_string</code><code class="p">(</code><code class="n">written_greeting</code><code class="p">)</code>
  <code class="p">}</code>

  <code class="k">command</code> <code class="p">{</code>
     <code class="n">echo</code> <code class="s">"${original_greeting} to you too"</code>
  <code class="p">}</code>
  <code class="k">output</code> <code class="p">{</code>
     <code class="kt">File</code> <code class="n">repeated_greeting</code> <code class="o">=</code> <code class="n">stdout</code><code class="p">()</code>
  <code class="p">}</code>
<code class="p">}</code></pre>

<p>You can see that the <code>workflow</code> block has quite a bit more going on now; it has an additional call statement pointing to a new task, <code>ReadItBackToMe</code>, and that call statement has some code in curly braces attached to it, which we’ll call the <code>input</code> block:</p>

<pre data-code-language="wdl" data-type="programlisting">
  <code class="k">call</code> <code class="n">ReadItBackToMe</code> <code class="p">{</code>
     <code class="k">input</code><code class="o">:</code>
        <code class="n">written_greeting</code> <code class="o">=</code> <code class="n">WriteGreeting</code><code class="p">.</code><code class="n">output_greeting</code>
  <code class="p">}</code></pre>

<p>The <code>input</code> block allows us to pass values from the workflow level to a particular task call. <a contenteditable="false" data-primary="I/O (input/output)" data-secondary="in WDL script Hello World, with another task added" data-type="indexterm" id="idm45625619162408"/>In this case, we’re referencing the output of the <code>WriteGreeting</code> task and assigning it to a variable called <code>written_greeting</code> for use within the <code>ReadItBackToMe</code> call.</p>

<p class="pagebreak-before">Let’s have a look at that new task definition:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">task</code> <code class="n">ReadItBackToMe</code> <code class="p">{</code>

  <code class="k">input</code> <code class="p">{</code>
    <code class="kt">File</code> <code class="n">written_greeting</code>
  <code class="p">}</code>

  <code class="kt">String</code> <code class="n">greeting</code> <code class="o">=</code> <code class="n">read_string</code><code class="p">(</code><code class="n">written_greeting</code><code class="p">)</code>

  <code class="k">command</code> <code class="p">{</code>
     <code class="n">echo</code> <code class="s">"${greeting} to you too"</code>
  <code class="p">}</code>
  <code class="k">output</code> <code class="p">{</code>
     <code class="kt">File</code> <code class="n">repeated_greeting</code> <code class="o">=</code> <code class="n">stdout</code><code class="p">()</code>
  <code class="p">}</code></pre>

<p>The <code>read_string()</code> bit is a function from the WDL standard library<a contenteditable="false" data-primary="read_string function (WDL)" data-type="indexterm" id="idm45625619097672"/> that reads in the contents of a text file and returns them in the form of a single string. So this task is meant to read in the contents of a file into a <code>String</code> variable and then use that variable to compose a new greeting and echo it to <code>stdout</code>.</p>

<p>In light of that, the extra code attached to the <code>ReadItBackToMe</code> call statement makes perfect sense. We’re calling the <code>ReadItBackToMe</code> task and specifying that the input file we used to compose the new greeting should be the output of the call to the <code>Write​Greeting</code> task.</p>

<p>Finally, let’s look at the last block of code we haven’t examined in this new version of the workflow:</p>

<pre data-code-language="wdl" data-type="programlisting">
  <code class="k">output</code> <code class="p">{</code>
     <code class="kt">File</code> <code class="n">outfile</code> <code class="o">=</code> <code class="n">ReadItBackToMe</code><code class="p">.</code><code class="n">repeated_greeting</code>
  <code class="p">}</code></pre>

<p>This workflow has an <code>output</code> block defined at the workflow level in addition to the individual task-level <code>output</code> blocks. This workflow-level output definition is entirely optional when the workflow is intended to be run by itself; it’s more a matter of convention than function. By defining a workflow-level output, we communicate which of the outputs produced by the workflow we care about. That being said, you can use this output definition for functional purposes; for example, when the workflow is going to be used as a nested subworkflow and we need to pass its output to<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-startref="ix_WDLwrHWtsk" data-tertiary="adding another task for proper workflow" data-type="indexterm" id="idm45625619073640"/> further calls.<a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="your first WDL script, Hello World" data-startref="ix_autoanWDLHW" data-type="indexterm" id="idm45625619087032"/><a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-startref="ix_wkfautHW" data-tertiary="your first WDL, Hello World" data-type="indexterm" id="idm45625619085416"/><a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="writing your first script, Hello World" data-startref="ix_WDLwrHW" data-type="indexterm" id="idm45625619083512"/> You’ll see that in action in <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a>. For now, try running this workflow with the same input JSON as the previous workflow, then poke around the execution directories to see how the task directories relate to each other and where the outputs are located.</p>
</div></section>
</div></section>

<section class="pagebreak-before" data-type="sect1" data-pdf-bookmark="Your First GATK Workflow: Hello HaplotypeCaller"><div class="sect1" id="your_first_gatk_workflow_hello_haplotyp">
<h1 class="less_space">Your First GATK Workflow: Hello HaplotypeCaller</h1>

<p>Now that you<a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-tertiary="your first GATK workflow, Hello HaplotypeCaller" data-type="indexterm" id="ix_wkfautGATK"/> have a firm grasp of basic <a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-type="indexterm" id="ix_GATKwkf"/>WDL syntax, let’s turn to a <a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="your first GATK workflow, Hello HaplotypeCaller" data-type="indexterm" id="ix_autoanGATK"/>more realistic set of examples: actual GATK pipelines!<a contenteditable="false" data-primary="HaplotypeCaller" data-secondary="running with workflow" data-type="indexterm" id="ix_HCwkf"/> We begin with a very simple workflow in order to build your familiarity with the language gradually. We want a workflow that runs GATK <code>HaplotypeCaller</code> linearly (no parallelization) in GVCF mode on a single sample BAM file, as illustrated in <a data-type="xref" href="#concept_diagram_of_a_hypothetical_workf">Figure 8-1</a>.</p>

<figure class="width-50"><div id="concept_diagram_of_a_hypothetical_workf" class="figure"><img alt="Concept diagram of a hypothetical workflow that runs HaplotypeCaller." src="Images/gitc_0801.png" width="1440" height="895"/>
<h6><span class="label">Figure 8-1. </span>A hypothetical workflow that runs HaplotypeCaller.</h6>
</div></figure>

<p>The workflow should take the usual required files—the genome reference, input reads, and a file of intervals to analyze (technically optional as far as GATK is concerned, but here we made it required by the WDL)—and output a GVCF file named based on the input file.</p>

<section data-type="sect2" data-pdf-bookmark="Exploring the WDL"><div class="sect2" id="explore_the_wdl">
<h2>Exploring the WDL</h2>

<p>To illustrate <a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-tertiary="exploring the WDL" data-type="indexterm" id="ix_GATKwkfWDL"/>all of that, we put <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="in Hello HaplotypeCaller workflow" data-type="indexterm" id="ix_WDLHHCwkf"/>together a WDL workflow that fulfills these requirements through a single task, <code>HaplotypeCallerGVCF</code>. Open it now in the <code>nano</code> editor:</p>

<pre data-type="programlisting">
$ nano $WF/hello-hc/hello-haplotypecaller.wdl</pre>

<p>Let’s walk through the main sections of the script, recalling the structure of our HelloWorld example:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">version</code> <code class="mf">1.0</code>

<code class="k">workflow</code> <code class="n">HelloHaplotypeCaller</code> <code class="p">{</code>

    <code class="k">call</code> <code class="n">HaplotypeCallerGVCF</code>
<code class="p">}</code>

<code class="k">task</code> <code class="n">HaplotypeCallerGVCF</code> <code class="p">{</code>

 <code class="k">input</code> <code class="p">{</code>
  		<code class="kt">String</code> <code class="n">docker_image</code>
        <code class="kt">String</code> <code class="n">java_opt</code>

        <code class="kt">File</code> <code class="n">ref_fasta</code>
        <code class="kt">File</code> <code class="n">ref_index</code>
        <code class="kt">File</code> <code class="n">ref_dict</code>
        <code class="kt">File</code> <code class="n">input_bam</code>
        <code class="kt">File</code> <code class="n">input_bam_index</code>
        <code class="kt">File</code> <code class="n">intervals</code>
    <code class="p">}</code>

    <code class="kt">String</code> <code class="n">gvcf_name</code> <code class="o">=</code> <code class="n">basename</code><code class="p">(</code><code class="n">input_bam</code><code class="p">,</code> <code class="s">".bam"</code><code class="p">)</code> <code class="o">+</code> <code class="s">".g.vcf"</code>

    <code class="k">command</code> <code class="p">{</code>
        <code class="n">gatk</code> <code class="o">--</code><code class="n">java</code><code class="o">-</code><code class="n">options</code> <code class="nv">$</code><code class="p">{</code><code class="n">java_opt</code><code class="p">}</code> <code class="n">HaplotypeCaller</code> \
            <code class="o">-</code><code class="n">R</code> <code class="nv">$</code><code class="p">{</code><code class="n">ref_fasta</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">I</code> <code class="nv">$</code><code class="p">{</code><code class="n">input_bam</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">O</code> <code class="nv">$</code><code class="p">{</code><code class="n">gvcf_name</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">L</code> <code class="nv">$</code><code class="p">{</code><code class="n">intervals</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">ERC</code> <code class="n">GVCF</code>
    <code class="p">}</code>

    <code class="k">output</code> <code class="p">{</code>
        <code class="kt">File</code> <code class="n">output_gvcf</code> <code class="o">=</code> <code class="s">"${gvcf_name}"</code>
    <code class="p">}</code>

    <code class="k">runtime</code> <code class="p">{</code>
        <code class="nl">docker</code><code class="p">:</code> <code class="n">docker_image</code>
    <code class="p">}</code>

<code class="p">}</code></pre>

<p>Collapsing the task for clarity, you can see that it is indeed a single-task workflow, with only that single call and nothing else going on in the <code>workflow</code> block:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">workflow</code> <code class="n">HelloHaplotypeCaller</code> <code class="p">{</code>

    <code class="k">call</code> <code class="n">HaplotypeCallerGVCF</code>
<code class="p">}</code>

<code class="k">task</code> <code class="n">HaplotypeCallerGVCF</code> <code class="p">{</code> <code class="err">…</code> <code class="p">}</code></pre>

<p>So let’s look at that <code>HaplotypeCallerGVCF</code> task in more detail, starting with the <code>command</code> block, because ultimately that’s where we’ll glean the most information about what the task actually does:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">command</code> <code class="p">{</code>
        <code class="n">gatk</code> <code class="o">--</code><code class="n">java</code><code class="o">-</code><code class="n">options</code> <code class="nv">$</code><code class="p">{</code><code class="n">java_opt</code><code class="p">}</code> <code class="n">HaplotypeCaller</code> \
            <code class="o">-</code><code class="n">R</code> <code class="nv">$</code><code class="p">{</code><code class="n">ref_fasta</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">I</code> <code class="nv">$</code><code class="p">{</code><code class="n">input_bam</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">O</code> <code class="nv">$</code><code class="p">{</code><code class="n">gvcf_name</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">L</code> <code class="nv">$</code><code class="p">{</code><code class="n">intervals</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">ERC</code> <code class="n">GVCF</code>
    <code class="p">}</code></pre>

<p>We see a classic GATK command that invokes <code>HaplotypeCaller</code> in GVCF mode. It uses placeholder variables for the expected input files as well as the output file. It also includes a placeholder variable for passing in Java options such as memory heap size, as described in <a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a>. So far, that’s pretty straightforward.</p>

<p>Those variables should all be <a contenteditable="false" data-primary="variables" data-secondary="in Hello HaplotypeCaller workflow" data-type="indexterm" id="idm45625618762472"/>defined somewhere, so let’s look for them. Conventionally, we do this at the start of the task description, before the <code>command</code> block. This is what we see there:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">input</code> <code class="p">{</code>
        <code class="kt">String</code> <code class="n">docker_image</code>
        <code class="kt">String</code> <code class="n">java_opt</code>

        <code class="kt">File</code> <code class="n">ref_fasta</code>
        <code class="kt">File</code> <code class="n">ref_index</code>
        <code class="kt">File</code> <code class="n">ref_dict</code>
        <code class="kt">File</code> <code class="n">input_bam</code>
        <code class="kt">File</code> <code class="n">input_bam_index</code>
        <code class="kt">File</code> <code class="n">intervals</code>
    <code class="p">}</code>

    <code class="kt">String</code> <code class="n">gvcf_name</code> <code class="o">=</code> <code class="n">basename</code><code class="p">(</code><code class="n">input_bam</code><code class="p">,</code> <code class="s">".bam"</code><code class="p">)</code> <code class="o">+</code> <code class="s">".g.vcf"</code></pre>

<p>Ignoring the <code>String docker_image</code> line for now, this shows that we declared all of the variables for the input files as well as the Java options, but we didn’t assign a value to them. So the task will expect to receive values for all of them at runtime. Not only <a contenteditable="false" data-primary="accessory files for GATK in WDL workflow" data-type="indexterm" id="idm45625618700920"/>that, but it will also expect values <a contenteditable="false" data-primary="refIndex file" data-type="indexterm" id="idm45625618699752"/>for all<a contenteditable="false" data-primary="refDict file" data-type="indexterm" id="idm45625618698520"/> the accessory <a contenteditable="false" data-primary="inputBamIndex file" data-type="indexterm" id="idm45625618697256"/>files we often take for granted: <code>refIndex</code>, <code>refDict</code>, and <code>inputBamIndex</code>, which refer to the indices and sequence dictionary. We don’t include those files in the command itself because GATK detects their presence automatically (as long as their names conform with their master file’s respective format conventions), but we do need to inform Cromwell that they exist so that it can make them available for execution at runtime.</p>

<p>There is one exception, though; for the output file, we see this line:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="kt">String</code> <code class="n">gvcf_name</code> <code class="o">=</code> <code class="n">basename</code><code class="p">(</code><code class="n">input_bam</code><code class="p">,</code> <code class="s">".bam"</code><code class="p">)</code> <code class="o">+</code> <code class="s">".g.vcf"</code></pre>

<p>The <code>basename(input_bam, ".bam")</code> piece is a convenience <a contenteditable="false" data-primary="basename function (WDL)" data-type="indexterm" id="idm45625618684008"/>function from the WDL standard library that allows us to create a name for our output file based on the name of the input file. The <code>basename()</code> function takes the full path of the input file, strips off the part of the path that’s in front of the filename, and, optionally, strips off a given string from the end of the filename. In this case, we’re stripping off the expected <em>.bam</em> extension and then we’re using the <code>+ ".g.vcf"</code> part of the line to add the new extension that will be appropriate for the output file.</p>

<p>Speaking of the <a contenteditable="false" data-primary="I/O (input/output)" data-secondary="GVCF output file for Hello HaplotypeCaller workflow" data-type="indexterm" id="idm45625618646264"/>output file, let’s now skip over to the task-level <code>output</code> block:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">output</code> <code class="p">{</code>
    <code class="kt">File</code> <code class="n">output_gvcf</code> <code class="o">=</code> <code class="s">"${gvcf_name}"</code>
<code class="p">}</code></pre>

<p>This is also straightforward; we’re stating that the command will produce an output file that we care about, giving it a name for handling it within the workflow, and providing the corresponding placeholder variable so that Cromwell can identify the correct file after the command has run to completion.</p>

<p>Technically, that is all you need to have in the workflow and task definition if you’re planning to run this on a system with a local installation of the program that you want to run. However, in this chapter you’re working in your VM but outside the GATK container, and as a result, GATK is not available directly to your workflow. Fortunately, Cromwell<a contenteditable="false" data-primary="containers" data-secondary="specifying Docker container image for Hello HaplotypeCaller workflow" data-type="indexterm" id="idm45625618673560"/> is capable <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="using Docker container in Hello HaplotypeCaller workflow" data-type="indexterm" id="idm45625618672216"/>of utilizing Docker containers, so we just need to add a <code>runtime</code> block to the workflow in order to specify a container image:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">runtime</code> <code class="p">{</code>
    <code class="nl">docker</code><code class="p">:</code> <code class="n">docker_image</code>
<code class="p">}</code></pre>

<p>That’s why we had that <code>String docker_image</code> line in our task variables: we’re also using a placeholder variable for the container image. When we fill out the input JSON in the next step, we’ll specify the <code>us.gcr.io/broad-gatk/gatk:4.1.3.0</code> image. Then, when we launch the workflow, Cromwell will spin up a new container from the image we specified and run GATK inside of it.</p>

<p>Technically we could hardcode the image name here, using double quotes (e.g., <code>docker: "us.gcr.io/broad-gatk/gatk:4.1.3.0"</code>) but we don’t recommend doing that unless you really want to peg a particular script to a particular version, which reduces flexibility significantly. Some people use the <code>latest</code> tag to make their workflows always run with the latest available version of the program, but we consider that to be a bad practice with more downsides than upsides because you never know what might change in the latest version and break your workflow.<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-startref="ix_GATKwkfWDL" data-tertiary="exploring the WDL" data-type="indexterm" id="idm45625618619688"/><a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="in Hello HaplotypeCaller workflow" data-startref="ix_WDLHHCwkf" data-type="indexterm" id="idm45625618617832"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Generating the Inputs JSON"><div class="sect2" id="generating_the_inputs_json">
<h2>Generating the Inputs JSON</h2>

<p>Alright, we’ve<a contenteditable="false" data-primary="I/O (input/output)" data-secondary="generating inputs JSON for Hello HaplotypeCaller workflow" data-type="indexterm" id="ix_IOJSON"/> gone through<a contenteditable="false" data-primary="JSON" data-secondary="generating inputs JSON for Hello HaplotypeCaller workflow" data-type="indexterm" id="ix_JSONHHC"/> all of the code in the<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-tertiary="generating inputs JSON" data-type="indexterm" id="ix_GATKwkfJSON"/> workflow; now we need to determine how we’re going to provide the inputs to the workflow when we run it. In <a data-type="xref" href="#your_first_wdl_hello_world">“Your First WDL: Hello World”</a>, we were running an extremely simple workflow, first without any variable inputs and then with a single one. In the single-input case, we created a JSON file specifying that one input. Now we have eight inputs that we need to specify. We could proceed in the same way as before—create a JSON file and write in the name of every input expected by the <code>HaplotypeCallerGVCF</code> task—but there’s an easier way: we’re going to use the <code>Womtool inputs</code> command to create a template JSON.</p>

<p>First, because we’re going to be writing files that we care about for the first time in the chapter, let’s make a <em>sandbox</em> directory<a contenteditable="false" data-primary="sandbox directory" data-type="indexterm" id="idm45625618581944"/> to keep our outputs organized:</p>

<pre data-type="programlisting">
$ mkdir ~/sandbox-8</pre>

<p>Now, you<a contenteditable="false" data-primary="Womtool" data-secondary="command generating inputs JSON template" data-type="indexterm" id="idm45625618579544"/> can run the <code>Womtool</code> command that generates the <em>inputs</em> JSON template file:</p>

<pre data-type="programlisting">
$ java -jar $BIN/womtool-48.jar \
    inputs $WF/hello-hc/hello-haplotypecaller.wdl \
    &gt; ~/sandbox-8/hello-haplotypecaller.inputs.json</pre>

<p>Because we specify an output file on the last line of this command (which is actually optional), the command writes its output to that file. If everything goes smoothly, you shouldn’t see any output in the terminal. Let’s look at the contents of the file that we just created:</p>

<pre data-type="programlisting">
$ cat ~/sandbox-8/hello-haplotypecaller.inputs.json
</pre>

<pre data-code-language="json" data-type="programlisting">
<code class="p">{</code>
 <code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.input_bam_index"</code><code class="p">:</code> <code class="s2">"File"</code><code class="p">,</code>
 <code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.input_bam"</code><code class="p">:</code> <code class="s2">"File"</code><code class="p">,</code>
 <code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.ref_fasta"</code><code class="p">:</code> <code class="s2">"File"</code><code class="p">,</code>
 <code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.ref_index"</code><code class="p">:</code> <code class="s2">"File"</code><code class="p">,</code>
 <code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.ref_dict"</code><code class="p">:</code> <code class="s2">"File"</code><code class="p">,</code>
 <code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.intervals"</code><code class="p">:</code> <code class="s2">"File"</code><code class="p">,</code>
 <code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.docker_image"</code><code class="p">:</code> <code class="s2">"String"</code><code class="p">,</code>
 <code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.java_opt"</code><code class="p">:</code> <code class="s2">"String"</code>
<code class="p">}</code></pre>

<p>There you go: all of the inputs that the <code>HaplotypeCallerGVCF</code> task expects are listed appropriately, with a placeholder value stating their type, in JSON format (although they might be in a different order in yours). Now we just need to fill in the values; those are the paths to the relevant files for the first six, and the runtime parameters (container image and Java options) for the last two. In the spirit of laziness, we provide a filled-out version that uses the snippet data that we used in <a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a>, but you could also go through the exercise of filling in the <em>inputs</em> JSON with other inputs from the data bundle that you downloaded in <a data-type="xref" href="ch04.xhtml#first_steps_in_the_cloud">Chapter 4</a> if you like. This is what the prefilled JSON looks like (paths are relative to the home directory):</p>

<pre data-type="programlisting">
$ cat $WF/hello-hc/hello-haplotypecaller.inputs.json</pre>

<pre data-code-language="json" data-type="programlisting">
<code class="p">{</code>
<code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.input_bam_index"</code><code class="p">:</code>
<code class="s2">"book/data/germline/bams/mother.bai"</code><code class="p">,</code>
<code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.input_bam"</code><code class="p">:</code>
<code class="s2">"book/data/germline/bams/mother.bam"</code><code class="p">,</code>
<code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.ref_fasta"</code><code class="p">:</code>
<code class="s2">"book/data/germline/ref/ref.fasta"</code><code class="p">,</code>
<code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.ref_index"</code><code class="p">:</code>
<code class="s2">"book/data/germline/ref/ref.fasta.fai"</code><code class="p">,</code>
<code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.ref_dict"</code><code class="p">:</code>
<code class="s2">"book/data/germline/ref/ref.dict"</code><code class="p">,</code>
<code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.intervals"</code><code class="p">:</code>
<code class="s2">"book/data/germline/intervals/snippet-intervals-min.list"</code><code class="p">,</code>
<code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.docker_image"</code><code class="p">:</code> <code class="s2">"us.gcr.io/broad-</code>
<code class="s2">gatk/gatk:4.1.3.0"</code><code class="p">,</code>
<code class="nt">"HelloHaplotypeCaller.HaplotypeCallerGVCF.java_opt"</code><code class="p">:</code> <code class="s2">"-Xmx8G"</code>
<code class="p">}</code></pre>

<p>Notice that all of the values are shown in double quotes, but this is a bit of an artifact because these values are all of <code>String</code> type. <a contenteditable="false" data-primary="String type" data-secondary="enclosing with double quotes" data-type="indexterm" id="idm45625618440792"/><a contenteditable="false" data-primary="&quot;&quot; (double quotes) enclosing strings" data-type="indexterm" id="idm45625618439640"/>For other types such as numbers, Booleans, and arrays, you should not use double quotes.<a contenteditable="false" data-primary="[] (square brackets), enclosing array values" data-type="indexterm" id="idm45625618438280"/> Except, of course, for arrays of strings, for which you should use double quotes around the strings, though<a contenteditable="false" data-primary="I/O (input/output)" data-secondary="generating inputs JSON for Hello HaplotypeCaller workflow" data-startref="ix_IOJSON" data-type="indexterm" id="idm45625618436888"/> not <a contenteditable="false" data-primary="JSON" data-secondary="generating inputs JSON for Hello HaplotypeCaller workflow" data-startref="ix_JSONHHC" data-type="indexterm" id="idm45625618435144"/>around<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-startref="ix_GATKwkfJSON" data-tertiary="generating inputs JSON" data-type="indexterm" id="idm45625618433368"/> the array itself, <code>["like","this"]</code>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Running the Workflow"><div class="sect2" id="running_the_workflow">
<h2>Running the Workflow</h2>

<p>To run the workflow, we’re going to use <a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-tertiary="running the workflow" data-type="indexterm" id="idm45625618428984"/>the same command-line syntax as earlier. Make sure to execute this in your home directory so that the relative paths in the <em>inputs</em> JSON file match the location of the data files:</p>

<pre data-type="programlisting">
$ java -jar $BIN/cromwell-48.jar \
    run $WF/hello-hc/hello-haplotypecaller.wdl \
    -i $WF/hello-hc/hello-haplotypecaller.inputs.json</pre>

<p>As mentioned earlier, Cromwell output is quite verbose. <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="output from Hello HaplotypeCaller workflow" data-type="indexterm" id="idm45625618425320"/>For this exercise, you’re looking for lines that look like these in the terminal output:</p>

<pre data-type="programlisting">
[2019-08-14 06:27:14,15] [info] BackgroundConfigAsyncJobExecutionActor
[9a6a9c97HelloHaplotypeCaller.HaplotypeCallerGVCF:NA:1]: Status change from
WaitingForReturnCode to Done
[2019-08-14 06:27:15,46] [info] WorkflowExecutionActor-9a6a9c97-7453-455c-8cd8-
be8af8cb6f7c [9a6a9c97]: Workflow HelloHaplotypeCaller complete. Final Outputs:
{
 "HelloHaplotypeCaller.HaplotypeCallerGVCF.output_gvcf": "/home/username/cromwell-
executions/HelloHaplotypeCaller/9a6a9c97-7453-455c-8cd8-be8af8cb6f7c/call-
HaplotypeCallerGVCF/execution/mother.g.vcf"
}
[2019-08-14 06:27:15,51] [info] WorkflowManagerActor WorkflowActor-9a6a9c97-7453-
455c-8cd8-be8af8cb6f7c is in a terminal state: WorkflowSucceededState
[2019-08-14 06:27:21,31] [info] SingleWorkflowRunnerActor workflow 
status ’Succeeded’.
{
 "outputs": {
   "HelloHaplotypeCaller.HaplotypeCallerGVCF.output_gvcf":
"/home/username/cromwell-executions/HelloHaplotypeCaller/9a6a9c97-7453-455c-8cd8-
be8af8cb6f7c/call-HaplotypeCallerGVCF/execution/mother.g.vcf"
workflow HelloHaplotypeCaller {
 },
 "id": "9a6a9c97-7453-455c-8cd8-be8af8cb6f7c"
}</pre>

<p>The most exciting snippets here are <code>Status change from WaitingForReturnCode to Done</code> and <code>finished with status 'Succeeded'</code>, which together mean that your workflow is done running and that all commands that were run stated that they were successful.</p>

<p>The other exciting part of the output is the path to the outputs. In the next section, we talk a bit about why they’re listed twice; for now, let’s just be happy that Cromwell tells us precisely where to find our output file so that we can easily peek into it. Of course, the output of this particular workflow is a GVCF file, so it’s not exactly pleasant to read through, but the point is that the file is there and its contents are what you expect to see.</p>

<p>We use the <code>head</code> utility for this<a contenteditable="false" data-primary="head utility" data-secondary="using to read GVCF output file from Hello HaplotypeCaller workflow" data-type="indexterm" id="idm45625618418984"/> purpose; keep in mind that you’ll need to substitute the execution directory hash in the file path shown in the following example (<code>9a6a9c97-7453-455c-8cd8-be8af8cb6f7c</code>) to the one displayed in your output:</p>

<pre data-type="programlisting">
$ head ~/cromwell-executions/HelloHaplotypeCaller/9a6a9c97-7453-455c
-8cd8-be8af8cb6f7c/call-HaplotypeCallerGVCF/execution/mother.g.vcf
##fileformat=VCFv4.2
##ALT=&lt;ID=NON_REF,Description="Represents any possible alternative allele at this
location"&gt;
##FILTER=&lt;ID=LowQual,Description="Low quality"&gt;
##FORMAT=&lt;ID=AD,Number=R,Type=Integer,Description="Allelic depths for the ref and
alt alleles in the order listed"&gt;
##FORMAT=&lt;ID=DP,Number=1,Type=Integer,Description="Approximate read depth (reads
with MQ=255 or with bad mates are filtered)"&gt;
##FORMAT=&lt;ID=GQ,Number=1,Type=Integer,Description="Genotype Quality"&gt;
##FORMAT=&lt;ID=GT,Number=1,Type=String,Description="Genotype"&gt;
##FORMAT=&lt;ID=MIN_DP,Number=1,Type=Integer,Description="Minimum DP observed within
the GVCF block"&gt;
##FORMAT=&lt;ID=PGT,Number=1,Type=String,Description="Physical phasing haplotype
information, describing how the alternate alleles are phased in relation to one
another"&gt;
##FORMAT=&lt;ID=PID,Number=1,Type=String,Description="Physical phasing ID information,
where each unique ID within a given sample (but not across samples) connects
records
within a phasing group"&gt;</pre>

<p>This run should complete quickly because we’re using an intervals list that spans only a short region. Most of the time spent here is Cromwell getting started and spinning up the container, whereas GATK <code>HaplotypeCaller</code> itself runs for only the briefest of moments. As with the Hello World example, you might feel that this is an awful lot of work for such a small workload, and you’d be right; it’s like swatting a fly with a bazooka. For toy examples, the overhead of getting Cromwell going dwarfs the analysis itself. It’s when we get into proper full-scale analyses that a workflow management system like Cromwell really shows its value, which you’ll experience in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch10.xhtml#running_single_workflows_at_scale_with">10</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch11.xhtml#running_many_workflows_conveniently_in">11</a>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Breaking the Workflow to Test Syntax Validation and Error Messaging"><div class="sect2" id="breaking_the_workflow_to_test_syntax_va">
<h2>Breaking the Workflow to Test Syntax Validation and Error Messaging</h2>

<p>Hopefully, so far everything<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-tertiary="breaking workflow to test syntax validation and error messaging" data-type="indexterm" id="ix_GATKwkfbrk"/> ran as expected for you, so you know what success looks like. But in reality, things occasionally go wrong, so now let’s look at what failure looks like.<a contenteditable="false" data-primary="syntax validation (WDL) in Hello HaplotypeCaller workflow" data-type="indexterm" id="ix_synval"/><a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="in Hello HaplotypeCaller workflow" data-tertiary="testing syntax validation and error messaging" data-type="indexterm" id="ix_WDLHHCwkfvalerr"/> Specifically, we’re going to look at how Cromwell handles two common types of scripting error, WDL syntax and <code>command</code> block syntax errors, by introducing some errors in the WDL. First, let’s make a copy of the workflow file so that we can play freely:</p>

<pre data-type="programlisting">
$ cp $WF/hello-hc/hello-haplotypecaller.wdl ~/sandbox-8/hc-break1.wdl</pre>

<p>Now, in your preferred text editor, open the new file and introduce an error in the WDL syntax. For example, you could mangle one of the variable names, one of the reserved keywords, or delete a curly brace to mess with the block structure. Here, we’ll be a bit sadistic and delete the second parenthesis in the <code>basename()</code> function call. It’s the kind of small error that is fatal yet really easy to overlook. Let’s see what happens when we run this:</p>

<pre data-type="programlisting">
$ java -jar $BIN/cromwell-48.jar \
    run ~/sandbox-8/hc-break1.wdl \
    -i $WF/hello-hc/hello-haplotypecaller.inputs.json</pre>

<p>As expected, the workflow<a contenteditable="false" data-primary="error messaging, testing in Hello HaplotypeCaller workflow" data-type="indexterm" id="ix_errmess"/> execution fails, and <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="error message from Hello HaplotypeCaller workflow" data-type="indexterm" id="idm45625618397000"/>Cromwell serves us with some verbose error messaging:</p>

<pre data-type="programlisting">
[2019-08-14 07:30:49,55] [error] WorkflowManagerActor Workflow 0891bf2c-4539-498c-
a082-bab457150baf failed (during MaterializingWorkflowDescriptorState):
cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorAct
or$$anon$1: Workflow input processing failed:
ERROR: Unexpected symbol (line 20, col 2) when parsing ’_gen18’.

Expected rparen, got command .
       command {
^
$e = :string

[stack trace]
[2019-08-14 07:30:49,57] [info] WorkflowManagerActor WorkflowActor-0891bf2c-4539-
498c-a082-bab457150baf is in a terminal state: WorkflowFailedState</pre>

<p>There’s a lot in there that we don’t care about, such as the stack trace, which we’re not showing here. The really important piece is <code>Workflow input processing failed: ERROR: Unexpected symbol</code>. That is a dead giveaway that you have a syntax issue. Cromwell will try to give you more specifics indicating where the syntax error might lie; in this case, it’s pretty accurate—it expected but didn’t find the closing parenthesis (<code>rparen</code> for right parenthesis) on line 20—but be aware that sometimes it’s not as obvious.</p>

<p>When you’re actively developing a new workflow, you probably won’t want to have to launch the workflow through Cromwell each time you need to test the syntax of some new code<a contenteditable="false" data-primary="Womtool" data-secondary="validate command, validating WDL syntax" data-type="indexterm" id="idm45625618391768"/>. Good news: you can save time by using <code>Womtool</code>’s validate command instead. That’s what Cromwell actually runs under the hood, and it’s a very lightweight way to test your syntax. Try it now on your broken workflow:</p>

<pre data-type="programlisting">
$ java -jar $BIN/womtool-48.jar \
    validate ~/sandbox-8/hc-break1.wdl 

ERROR: Unexpected symbol (line 20, col 2) when parsing '_gen18'.
Expected rparen, got command .
       command {
^
$e = :string</pre>

<p>See? You get the important part of Cromwell’s output in a much shorter time frame—and you don’t even need to provide valid inputs to the workflow. As an additional exercise, try introducing other WDL syntax errors; for example, try deleting a variable declaration, changing a variable name in only one of its appearances, and misspelling a reserved keyword like <code>workflow</code>, <code>command</code>, or <code>outputs</code>. This will help you to recognize validation errors and interpret how they are reported by <code>Womtool</code>. In general, we heartily recommend using <code>Womtool validate</code> systematically on any new or updated WDLs (and yes, it works on CWL too).</p>

<p>That being said, it’s important<a contenteditable="false" data-primary="Womtool" data-secondary="validate command, validating WDL syntax" data-tertiary="limitations of" data-type="indexterm" id="idm45625618363576"/> to understand that <code>Womtool</code>’s WDL syntax validation will get you only so far: it can’t do anything about any other errors you might make that are outside its scope of expertise; for example, if you mess up the command syntax for the tool you want to run. To see what happens in that case, make another copy of the original workflow in your sandbox (call it <em>hc-break2.wdl</em>) and open it up to introduce an error in the GATK command this time; for example, by mangling the name of the tool, changing it to <code>HaploCaller</code>:</p>

<pre data-code-language="wdl" data-type="programlisting">
       <code class="k">command</code> <code class="p">{</code>
               <code class="n">gatk</code> <code class="o">--</code><code class="n">java</code><code class="o">-</code><code class="n">options</code> <code class="nv">$</code><code class="p">{</code><code class="n">java_opt</code><code class="p">}</code> <code class="n">HaploCaller</code> \
                       <code class="o">-</code><code class="n">R</code> <code class="nv">$</code><code class="p">{</code><code class="n">refFasta</code><code class="p">}</code> \
                       <code class="o">-</code><code class="n">I</code> <code class="nv">$</code><code class="p">{</code><code class="n">inputBam</code><code class="p">}</code> \
                       <code class="o">-</code><code class="n">O</code> <code class="nv">$</code><code class="p">{</code><code class="n">gvcfName</code><code class="p">}</code> \
                       <code class="o">-</code><code class="n">L</code> <code class="nv">$</code><code class="p">{</code><code class="n">intervals</code><code class="p">}</code> \
                       <code class="o">-</code><code class="n">ERC</code> <code class="n">GVCF</code>
       <code class="p">}</code></pre>

<p>If you run <code>Womtool validate</code>, you’ll see this workflow sails right through validation; <code>Womtool</code> cheerfully reports <code>Success!</code> Yet if you actually run it through Cromwell, the workflow will most definitely fail:</p>

<pre data-type="programlisting">
$ java -jar $BIN/cromwell-48.jar \
    run ~/sandbox-8/hc-break2.wdl \
    -i $WF/hello-hc/hello-haplotypecaller.inputs.json</pre>

<p>Scroll through the output to find the line showing the failure message:</p>

<pre data-type="programlisting">
[2019-08-14 07:09:52,12] [error] WorkflowManagerActor Workflow dd77316f-7c18-4eb1
-aa86-e307113c1668 failed (during ExecutingWorkflowState): Job
HelloHaplotypeCaller.HaplotypeCallerGVCF:NA:1 exited with return code 2 which has
not been declared as a valid return code. See ’continueOnReturnCode’ runtime
attribute for more details.
Check the content of stderr for potential additional information:
/home/username/cromwell-executions/HelloHaplotypeCaller/dd77316f-7c18-4eb1-aa86-
e307113c1668/call-HaplotypeCallerGVCF/execution/stderr.
[First 300 bytes]:Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-
executions/HelloHaplotypeCaller/dd77316f-7c18-4eb1-aa86-e307113c1668/call-
HaplotypeCallerGVCF/tmp
.e6f08f65
USAGE:  &lt;program name&gt; [-h]
Available Programs:</pre>

<p>The log line that says <code>Job HelloHaplotypeCaller.HaplotypeCallerGVCF:NA:1 exited with return code 2</code> means that <code>HaplotypeCallerGVCF</code> was the task that failed and, specifically, that the command it was running reported an exit code of <code>2</code>. This typically indicates that the tool you were trying to run choked on something—a syntax issue, unsatisfied input requirements, formatting errors, insufficient memory, and so on.</p>

<p>The error message goes on to point out that you can find out more by looking at the standard error (<code>stderr</code>) output produced <a contenteditable="false" data-primary="stderr, output produced by GATK workflow" data-type="indexterm" id="idm45625618313480"/>by the command, and it helpfully includes the full file path so that you easily can peek inside it. It also includes the first few lines of the <code>stderr</code> log for convenience, which is sometimes enough if the tool’s error output was very brief. The <code>stderr</code> output produced by GATK is of the more verbose variety. So here we’ll need to check out the full <code>stderr</code> to find out what went wrong. Again, make sure to substitute the username and execution directory hash shown here (<code>dd77316f-7c18-4eb1-aa86-e307113c1668</code>) with the ones in your output:</p>

<pre data-type="programlisting">
$ cat /home/username/cromwell-executions/HelloHaplotypeCaller/dd77316f-7c18-4eb1
-aa86-e307113c1668/call-HaplotypeCallerGVCF/execution/stderr
(...)
***********************************************************************
A USER ERROR has occurred: 'HaploCaller' is not a valid command.
Did you mean this?
       HaplotypeCaller
***********************************************************************
(...)</pre>

<p>Ah, look at that! We wrote the name of the tool wrong; who knew? Props to GATK for suggesting a correction, by the way; that’s new in GATK4.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>All command-line tools output a <em>return code</em> <a contenteditable="false" data-primary="command-line tools" data-secondary="return code output" data-type="indexterm" id="idm45625618307080"/>when they finish running as a concise way to report their status. Depending on the tool, the return code can be more or less meaningful. Conventionally, a return code of 0 indicates success, and anything else is a failure. In some cases, a nonzero code can mean the run was successful; for example, the Picard tool <code>ValidateSamFile</code> reports nonzero codes when it ran successfully but found format validation errors in the files it examined.</p>
</div>

<p>Other things can go wrong that we haven’t covered here, such as if you have the wrong paths for input files, or if you forgot to wrap string inputs in double quotes in the inputs JSON. Again, we recommend that you experiment by making those errors on purpose, <a contenteditable="false" data-primary="syntax validation (WDL) in Hello HaplotypeCaller workflow" data-startref="ix_synval" data-type="indexterm" id="idm45625618303624"/>because it<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-startref="ix_GATKwkfbrk" data-tertiary="breaking workflow to test syntax validation and error messaging" data-type="indexterm" id="idm45625618302152"/> will help <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="in Hello HaplotypeCaller workflow" data-startref="ix_WDLHHCwkfvalerr" data-tertiary="testing syntax validation and error messaging" data-type="indexterm" id="idm45625618300120"/>you learn <a contenteditable="false" data-primary="error messaging, testing in Hello HaplotypeCaller workflow" data-startref="ix_errmess" data-type="indexterm" id="idm45625618297976"/>to diagnose issues more quickly.<a contenteditable="false" data-primary="HaplotypeCaller" data-secondary="running with workflow" data-startref="ix_HCwkf" data-type="indexterm" id="idm45625618296472"/><a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first GATK workflow, Hello HaplotypeCaller" data-startref="ix_GATKwkf" data-type="indexterm" id="idm45625618294824"/><a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-startref="ix_wkfautGATK" data-tertiary="your first GATK workflow, Hello HaplotypeCaller" data-type="indexterm" id="idm45625618293080"/><a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="your first GATK workflow, Hello HaplotypeCaller" data-startref="ix_autoanGATK" data-type="indexterm" id="idm45625618291112"/> </p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Introducing Scatter-Gather Parallelism"><div class="sect1" id="introducing_scatter_gather_parallelism">
<h1>Introducing Scatter-Gather Parallelism</h1>

<p>We’re going to <a contenteditable="false" data-primary="parallel computing" data-secondary="scatter-gather parallelism in GATK workflow" data-type="indexterm" id="ix_parcmpscga"/>go over one more workflow<a contenteditable="false" data-primary="scatter-gather parallelism" data-type="indexterm" id="ix_scgapar"/> example in <a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-tertiary="parallelizing operation of" data-type="indexterm" id="ix_GATKwkfpar"/>this <a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="using scatter-gather parallelism" data-type="indexterm" id="ix_autoanpar"/>chapter to round out your first exposure to WDL and Cromwell, because we really want you to get a taste of the power of parallelization if you haven’t experienced that previously. So now we’re going to look at a workflow that parallelizes the operation of the <code>HaplotypeCaller</code> task we ran previously through a <code>scatter()</code> function and then merges the outputs of the parallel jobs in a subsequent step, as illustrated in <a data-type="xref" href="#concept_diagram_of_a_workflow_that_para">Figure 8-2</a>.</p>

<figure class="width-50"><div id="concept_diagram_of_a_workflow_that_para" class="figure"><img alt="Concept diagram of a workflow that parallelizes the execution of HaplotypeCaller." src="Images/gitc_0802.png" width="1208" height="1471"/>
<h6><span class="label">Figure 8-2. </span>A workflow that parallelizes the execution of HaplotypeCaller.</h6>
</div></figure>

<p>This workflow will expose you to the magic of scatter-gather parallelism, which is a staple of genomics workflows, especially in the cloud. It will also give you an opportunity to dig into the mechanics of stringing multiple tasks together based on their inputs and outputs in a bit more detail than we covered earlier.</p>

<section data-type="sect2" data-pdf-bookmark="Exploring the WDL"><div class="sect2" id="exploring_the_wdl">
<h2>Exploring the WDL</h2>

<p>Here’s<a contenteditable="false" data-primary="scatter-gather parallelism" data-secondary="WDL parallelizing HaplotypeCallerGVCF operation" data-type="indexterm" id="ix_scgaparWDL"/> a full WDL that parallelizes<a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="in Hello HaplotypeCaller workflow" data-tertiary="parallelizing operation of" data-type="indexterm" id="ix_WDLHHCwkfpar"/> the operation of <code>HaplotypeCallerGVCF</code> over subsets of intervals. In the <code>nano</code> editor, open it as usual:</p>

<pre data-type="programlisting">
$ nano $WF/scatter-hc/scatter-haplotypecaller.wdl</pre>

<p>Let’s walk through the main sections of the script, calling out what has changed compared to the linear implementation of this workflow:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">version</code> <code class="mf">1.0</code>

<code class="k">workflow</code> <code class="n">ScatterHaplotypeCallerGVCF</code> <code class="p">{</code>

 <code class="k">input</code> <code class="p">{</code>
        <code class="kt">File</code> <code class="n">input_bam</code>
        <code class="kt">File</code> <code class="n">input_bam_index</code>
        <code class="kt">File</code> <code class="n">intervals_list</code>
    <code class="p">}</code>

    <code class="kt">String</code> <code class="n">output_basename</code> <code class="o">=</code> <code class="n">basename</code><code class="p">(</code><code class="n">input_bam</code><code class="p">,</code> <code class="s">".bam"</code><code class="p">)</code> 

    <code class="kt">Array</code><code class="p">[</code><code class="kt">String</code><code class="p">]</code> <code class="n">calling_intervals</code> <code class="o">=</code> <code class="n">read_lines</code><code class="p">(</code><code class="n">intervals_list</code><code class="p">)</code>

    <code class="k">scatter</code><code class="p">(</code><code class="n">interval</code> <code class="n">in</code> <code class="n">calling_intervals</code><code class="p">)</code> <code class="p">{</code>
        <code class="k">call</code> <code class="n">HaplotypeCallerGVCF</code> <code class="p">{</code> 
            <code class="k">input</code><code class="o">:</code> 
                <code class="n">input_bam</code> <code class="o">=</code> <code class="n">input_bam</code><code class="p">,</code>
                <code class="n">input_bam_index</code> <code class="o">=</code> <code class="n">input_bam_index</code><code class="p">,</code>
                <code class="n">intervals</code> <code class="o">=</code> <code class="n">interval</code><code class="p">,</code> 
                <code class="n">gvcf_name</code> <code class="o">=</code> <code class="n">output_basename</code> <code class="o">+</code> <code class="s">".scatter.g.vcf"</code>
        <code class="p">}</code>
    <code class="p">}</code>
    <code class="k">call</code> <code class="n">MergeVCFs</code> <code class="p">{</code> 
        <code class="k">input</code><code class="o">:</code> 
            <code class="n">vcfs</code> <code class="o">=</code> <code class="n">HaplotypeCallerGVCF</code><code class="p">.</code><code class="n">output_gvcf</code><code class="p">,</code> 
            <code class="n">merged_vcf_name</code> <code class="o">=</code> <code class="n">output_basename</code> <code class="o">+</code> <code class="s">".merged.g.vcf"</code>
    <code class="p">}</code>

    <code class="k">output</code> <code class="p">{</code>
        <code class="kt">File</code> <code class="n">output_gvcf</code> <code class="o">=</code> <code class="n">MergeVCFs</code><code class="p">.</code><code class="n">mergedGVCF</code>
    <code class="p">}</code>
<code class="p">}</code>

<code class="k">task</code> <code class="n">HaplotypeCallerGVCF</code> <code class="p">{</code>

 <code class="k">input</code> <code class="p">{</code>
        <code class="kt">String</code> <code class="n">docker_image</code>
        <code class="kt">String</code> <code class="n">java_opt</code>

        <code class="kt">File</code> <code class="n">ref_fasta</code>
        <code class="kt">File</code> <code class="n">ref_index</code>
        <code class="kt">File</code> <code class="n">ref_dict</code>
        <code class="kt">File</code> <code class="n">input_bam</code>
        <code class="kt">File</code> <code class="n">input_bam_index</code>
        <code class="kt">String</code> <code class="n">intervals</code>
        <code class="kt">String</code> <code class="n">gvcf_name</code>
    <code class="p">}</code>

    <code class="k">command</code> <code class="p">{</code>
        <code class="n">gatk</code> <code class="o">--</code><code class="n">java</code><code class="o">-</code><code class="n">options</code> <code class="nv">$</code><code class="p">{</code><code class="n">java_opt</code><code class="p">}</code> <code class="n">HaplotypeCaller</code> \
            <code class="o">-</code><code class="n">R</code> <code class="nv">$</code><code class="p">{</code><code class="n">ref_fasta</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">I</code> <code class="nv">$</code><code class="p">{</code><code class="n">input_bam</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">O</code> <code class="nv">$</code><code class="p">{</code><code class="n">gvcf_name</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">L</code> <code class="nv">$</code><code class="p">{</code><code class="n">intervals</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">ERC</code> <code class="n">GVCF</code> 
    <code class="p">}</code>
    
    <code class="k">output</code> <code class="p">{</code>
        <code class="kt">File</code> <code class="n">output_gvcf</code> <code class="o">=</code> <code class="s">"${gvcf_name}"</code>
    <code class="p">}</code>

 <code class="k">runtime</code> <code class="p">{</code>
        <code class="nl">docker</code><code class="p">:</code> <code class="n">docker_image</code>
    <code class="p">}</code>
<code class="p">}</code>

<code class="k">task</code> <code class="n">MergeVCFs</code> <code class="p">{</code>

    <code class="k">input</code> <code class="p">{</code>
        <code class="kt">String</code> <code class="n">docker_image</code>
  <code class="kt">String</code> <code class="n">java_opt</code>

        <code class="kt">Array</code><code class="p">[</code><code class="kt">File</code><code class="p">]</code> <code class="n">vcfs</code>
        <code class="kt">String</code> <code class="n">merged_vcf_name</code>
    <code class="p">}</code>

    <code class="k">command</code> <code class="p">{</code>
        <code class="n">gatk</code> <code class="o">--</code><code class="n">java</code><code class="o">-</code><code class="n">options</code> <code class="nv">$</code><code class="p">{</code><code class="n">java_opt</code><code class="p">}</code> <code class="n">MergeVcfs</code> \
            <code class="o">-</code><code class="n">I</code> <code class="nv">$</code><code class="p">{</code><code class="n">sep</code><code class="o">=</code><code class="err">’</code> <code class="o">-</code><code class="n">I</code><code class="err">’</code> <code class="n">vcfs</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">O</code> <code class="nv">$</code><code class="p">{</code><code class="n">merged_vcf_name</code><code class="p">}</code>
    <code class="p">}</code>

    <code class="k">output</code> <code class="p">{</code>
        <code class="kt">File</code> <code class="n">merged_vcf</code> <code class="o">=</code> <code class="s">"${merged_vcf_name}"</code>
    <code class="p">}</code>

 <code class="k">runtime</code> <code class="p">{</code>
        <code class="nl">docker</code><code class="p">:</code> <code class="n">docker_image</code>
    <code class="p">}</code>
<code class="p">}</code></pre>

<p>The most obvious difference is that now a lot more is happening in the <code>workflow</code> block. <a contenteditable="false" data-primary="scatter-gather parallelism" data-secondary="WDL parallelizing HaplotypeCallerGVCF operation" data-tertiary="scatter function" data-type="indexterm" id="idm45625618220056"/>The core of the action is this subset (collapsing the two <code>call</code> blocks for <span class="keep-together">readability</span>):</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">scatter</code><code class="p">(</code><code class="n">intervals</code> <code class="n">in</code> <code class="n">calling_intervals</code><code class="p">)</code> <code class="p">{</code>
        <code class="k">call</code> <code class="n">HaplotypeCallerGVCF</code> <code class="p">{</code> <code class="p">...</code> <code class="p">}</code>
    <code class="p">}</code>
    <code class="k">call</code> <code class="n">MergeVCFs</code> <code class="p">{</code> <code class="p">...</code> <code class="p">}</code></pre>

<p>Previously, we were simply making one call to the <code>HaplotypeCallerGVCF</code> task, and that was it. Now, you see that the call to <code>HaplotypeCallerGVCF</code> is subordinated to a higher-level action, under this line, which opens a <code>scatter</code> block:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">scatter</code><code class="p">(</code><code class="n">intervals</code> <code class="n">in</code> <code class="n">calling_intervals</code><code class="p">)</code> <code class="p">{</code> </pre>

<p>For such a short line, it does a lot of work: this is how we parallelize the execution of <code>HaplotypeCaller</code> over subsets of <a contenteditable="false" data-primary="intervals, specifying for scatter function calling_intervals" data-type="indexterm" id="idm45625617972072"/>intervals, which are specified in the parentheses. The <code>calling_intervals</code> variable refers to a list of intervals, and the <code>HaplotypeCallerGVCF</code> task will be run as a separate invocation on each interval provided in that file.<a contenteditable="false" data-primary="for loop versus scatter function" data-type="indexterm" id="idm45625617969880"/> This might look a lot like a <em>for loop</em>, if you’re familiar with that scripting construct, and indeed it is similar in the sense that its purpose is to apply the same operation to each element in a list. However, the scatter is specifically designed to allow independent execution of each operation, whereas a for loop leads to linear execution in which each operation can be run only after the previous one (if any) has run to completion.</p>

<p>So now that you understand what the <code>scatter()</code> instruction does, let’s look into the <code>HaplotypeCallerGVCF</code> task itself, starting with how it’s being called:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">call</code> <code class="n">HaplotypeCallerGVCF</code> <code class="p">{</code> 
            <code class="k">input</code><code class="o">:</code> 
                <code class="n">input_bam</code> <code class="o">=</code> <code class="n">input_bam</code><code class="p">,</code>
                <code class="n">input_bam_index</code> <code class="o">=</code> <code class="n">input_bam_index</code><code class="p">,</code>
                <code class="n">intervals</code> <code class="o">=</code> <code class="n">intervals</code><code class="p">,</code> 
                <code class="n">gvcf_name</code> <code class="o">=</code> <code class="n">output_basename</code> <code class="o">+</code> <code class="s">".scatter.g.vcf"</code>
        <code class="p">}</code></pre>

<p>In the previous version of the workflow, the call to the task was just that: the <code>call</code> keyword followed by the task name. In this version, the statement includes an <code>input</code> block that specifies values for some of the variables that are required by the task: the input BAM file and its index, the intervals file, and the name of the GVCF output file.<a contenteditable="false" data-primary="basename function (WDL)" data-type="indexterm" id="idm45625617832696"/> Speaking of which, you’ll notice that the <code>basename</code> function call that we use to generate a name for the output is now happening within this <code>input</code> block instead of happening within the task. If you compare the task definitions for <code>HaplotypeCallerGVCF</code> between this version of the workflow and the previous one, that’s the only difference. Let’s make a mental note of that because it will come up again in a few minutes.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45625617829976">
<h5>Working with Intervals</h5>

<p>GATK provides a lot of flexibility for specifying intervals; the <code>--intervals</code> argument can recognize simple strings, interval list files in several formats, and even VCF files. As a result, it is possible to scatter the execution of a tool like <code>HaplotypeCaller</code> in several ways. Here, we’re showing the simplest option, which involves a single text file containing interval strings.</p>

<p>This works great if you have a small number of intervals, but it can become unwieldy if you are using lists with many intervals; for example, a list of exome targets, which typically contains thousands of very short intervals. If you were to use that directly here, you would end up with thousands of parallel jobs that run so quickly that the overhead of managing those jobs would be prohibitively inefficient, especially in the cloud context, where each requires spinning up a separate VM. Instead, we recommend extracting subsets of intervals into separate files, and providing a list of those separate files to <code>calling_intervals</code>. Here’s the good news: you don’t need to change anything in the WDL itself for this to work.</p>
</div></aside>

<p>Now let’s talk about what follows <a contenteditable="false" data-primary="MergeVCFs task" data-type="indexterm" id="ix_MrgVCF"/>the <code>scatter</code> block containing the <code>HaplotypeCallerGVCF</code> call: a call to a new task named <code>MergeVCFs</code>. To be clear, this call statement is <em>outside</em> of the <code>scatter</code> block, so it will be run only once:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">call</code> <code class="n">MergeVCFs</code> <code class="p">{</code> <code class="p">...</code> <code class="p">}</code></pre>

<p>You probably already have a pretty good idea of what this task is for based on its name, but let’s pretend it’s not that obvious and follow the logical path for deciphering the structure of the workflow. Peeking ahead into the <code>MergeVCFs</code> task definition, we see that the command it runs is a GATK command that invokes a tool called <code>MergeVcfs</code> (actually, a Picard tool bundled into GATK4). As input, it takes one or more VCF files (of which GVCFs are a subtype) and outputs a single merged file:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">command</code> <code class="p">{</code>
        <code class="n">gatk</code> <code class="o">--</code><code class="n">java</code><code class="o">-</code><code class="n">options</code> <code class="nv">$</code><code class="p">{</code><code class="n">java_opt</code><code class="p">}</code> <code class="n">MergeVcfs</code> \
            <code class="o">-</code><code class="n">I</code> <code class="nv">$</code><code class="p">{</code><code class="n">sep</code><code class="o">=</code><code class="nv">'</code> <code class="o">-</code><code class="n">I</code><code class="nv">'</code> <code class="n">vcfs</code><code class="p">}</code> \
            <code class="o">-</code><code class="n">O</code> <code class="nv">$</code><code class="p">{</code><code class="n">vcf_name</code><code class="p">}</code>
    <code class="p">}</code></pre>

<p>We can infer this from the command arguments and the variable names, and confirm it by looking up the <code>MergeVcfs</code> tool documentation on the GATK website.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>One novel point of WDL syntax to note here: the <code>-I ${sep=' -I' vcfs}</code> formulation is <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="list of items of arbitrary length to put into the command line" data-type="indexterm" id="idm45625617677400"/>how we deal with having a list of items of arbitrary length that we need to put into the command line with the same argument for each item. Given a list of files <code>[FileA, FileB, FileC]</code>, the preceding code would generate the following portion of the command line: <code>-I FileA -I FileB -I FileC</code>.</p>
</div>

<p>The <code>MergeVCFs</code> task definition also tells us that this task expects a list of files (technically expressed as <code>Array[<em>File</em>]</code>) as its main input. Let’s look at how the task is called in the <code>workflow</code> block:</p>

<pre data-code-language="wdl" data-type="programlisting">
<code class="k">call</code> <code class="n">MergeVCFs</code> <code class="p">{</code> 
            <code class="k">input</code><code class="o">:</code> 
            <code class="n">vcfs</code> <code class="o">=</code> <code class="n">HaplotypeCallerGVCF</code><code class="p">.</code><code class="n">output_gvcf</code><code class="p">,</code> 
            <code class="n">merged_vcf_name</code> <code class="o">=</code> <code class="n">output_basename</code> <code class="o">+</code> <code class="s">".merged.g.vcf"</code>
    <code class="p">}</code></pre>

<p>This might feel familiar if you remember the <code>ReadItBackToMe</code> task in the <code>HelloWorld​Again</code> workflow. Much as we did then, we’re assigning the <code>vcfs</code> input variable by referencing the output of the <code>HaplotypeCallerGVCF</code> task. The difference is that in that case, we were passing a single-file output to a single-file input. In contrast, here we’re referencing the output of a task call that resides inside a <code>scatter</code> block. What does that even look like?</p>

<p>Excellent question. By definition, each separate invocation of the task made within the <code>scatter</code> block generates its own separate output. The neat thing about the scatter construct is that those separate outputs are automatically collected into a list (technically an array) under the name of the output variable specified by the task. So here, although the output value of a single invocation of the <code>HaplotypeCallerGVCF</code> task, named <code>HaplotypeCallerGVCF.output_gvcf</code>, is a single GVCF file, the value of <code>HaplotypeCallerGVCF.output_gvcf</code> referenced in the <code>workflow</code> block is a list of the GVCF files generated within the <code>scatter</code> block. When we pass that reference to the next task call, we’re effectively providing the full list of files as an array.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45625617631848">
<h5>Order of Operations</h5>

<p>The order calls are executed in is <a contenteditable="false" data-primary="order of operations" data-type="indexterm" id="idm45625617630408"/>entirely determined by the dependencies between the inputs and outputs of task calls. Because <code>MergeVCFs</code> takes in the outputs of the scattered <code>HaplotypeCallerGVCF</code> call, it can start running only after all of the invocations of <code>HaplotypeCallerGVCF</code> have finished and their outputs are available. This means that we could place the <code>MergeVCFs</code> call statement first in the <code>workflow</code> block, and it would still be run last. However, we prefer to write our workflows in logical order for readability and encourage you to do the same, unless you’re some kind of sadist.</p>
</div></aside>

<p>Let’s finish this exploration by calling out a few more details. First, you might notice that we explicitly declare the output of the <code>MergeVCFs</code> call as the final output of the workflow in the workflow-level <code>output</code> block. This is technically not required, but it is good practice. Second, the variable declarations for the BAM file, its index, and the intervals file were all pushed up to the workflow level. In the case of the BAM file and its index, this move allows us to generate the names of the output files in the <code>input</code> blocks of both task calls, which among other advantages gives us more flexibility if we want to put our task definitions into a common library. For something like that, we want the tasks to be as generic as possible, and leave details like file-naming conventions up to the workflow implementations. As for the intervals file, we need to have it available at the workflow level in order to implement the <code>scatter</code> block.<a contenteditable="false" data-primary="MergeVCFs task" data-startref="ix_MrgVCF" data-type="indexterm" id="idm45625617623752"/></p>

<p>Finally, you<a contenteditable="false" data-primary="JSON" data-secondary="generating inputs JSON for Hello HaplotypeCaller workflow" data-type="indexterm" id="idm45625617621704"/> should now be able to generate the <em>inputs</em> JSON, fill it out based on the previous exercise, and run the workflow using the same setup as previously. We included a prefilled JSON if you want to save yourself the hassle of filling in file paths; just make sure to use the <em>.local.inputs.json</em> version rather than the <em>.gcs.inputs.json</em>, which we use in <a data-type="xref" href="ch10.xhtml#running_single_workflows_at_scale_with">Chapter 10</a>.</p>

<p>Here’s the <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="command using prefilled local input JSON" data-type="indexterm" id="idm45625617617368"/>Cromwell command using the prefilled local inputs JSON. Make sure to execute this in your home directory so that the relative paths in the <em>inputs</em> JSON file match the location of the data files:</p>

<pre data-type="programlisting">
$ java -jar $BIN/cromwell-48.jar \
       run $WF/scatter-hc/scatter-haplotypecaller.wdl \
       -i $WF/scatter-hc/scatter-haplotypecaller.local.inputs.json</pre>

<p>When you run this command, you might notice the scatter jobs running in parallel on your VM.<a contenteditable="false" data-primary="virtual machines (VMs)" data-secondary="scatter jobs running in parallel on your VM" data-type="indexterm" id="idm45625617613528"/> This is great because it means jobs will finish sooner. However, what happens if you’re trying to run five hundred scatter calls across a full genome? Running these all in parallel is going to cause problems; if it doesn’t outright crash, it will at least grind your VM to a halt as it swaps RAM to disk frantically. The good news is there are a couple solutions for this. <a contenteditable="false" data-primary="Cromwell workflow management system" data-secondary="local backend for, controlling level of parallelism" data-type="indexterm" id="idm45625617586904"/>First, you can control the level of parallelism allowed by the “local” backend for Cromwell, as described in the <a href="https://oreil.ly/8F4hp">online documentation</a>. Alternatively, you can use a different backend that is designed to handle this kind of situation gracefully. In <a data-type="xref" href="ch10.xhtml#running_single_workflows_at_scale_with">Chapter 10</a>, we show you how to use  the Google backend to automatically send <a contenteditable="false" data-primary="Workflow Description Language (WDL)" data-secondary="in Hello HaplotypeCaller workflow" data-startref="ix_WDLHHCwkfpar" data-tertiary="parallelizing operation of" data-type="indexterm" id="idm45625617583368"/>parallel<a contenteditable="false" data-primary="scatter-gather parallelism" data-secondary="WDL parallelizing HaplotypeCallerGVCF operation" data-startref="ix_scgaparWDL" data-type="indexterm" id="idm45625617581256"/> jobs to multiple VMs.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Generating a Graph Diagram for Visualization"><div class="sect2" id="generating_a_graph_diagram_for_visualiz">
<h2>Generating a Graph Diagram for Visualization</h2>

<p>As a coda to <a contenteditable="false" data-primary="graphs" data-secondary="generating graph diagram for workflow visualization" data-type="indexterm" id="ix_graph"/>this exercise, let’s <a contenteditable="false" data-primary="scatter-gather parallelism" data-secondary="generating graph diagram for workflow visualization" data-type="indexterm" id="ix_scgapargr"/>learn to apply <a contenteditable="false" data-primary="Womtool" data-secondary="graph command, generating graph diagram for workflow visualization" data-type="indexterm" id="ix_Wmtoolgr"/>one more <code>Womtool</code> utility: the <code>graph</code> command.  The workflows we’ve looked at so far have been quite simple in terms of the number of steps and overall plumbing. In the next chapter (and out in the real world), you will encounter more complex workflows, for which it might be difficult to build a mental model based on the code alone. That’s where it can be incredibly helpful to be able to generate a visualization of the workflow. The <code>Womtool graph</code> command allows you to generate a graph file in <em>.dot</em> format and visualize it using generic graph visualization tools:</p>

<pre data-type="programlisting">
$ java -jar $BIN/womtool-48.jar \
       graph $WF/scatter-hc/scatter-haplotypecaller.wdl \
       &gt; ~/sandbox-8/scatter-haplotypecaller.dot</pre>

<p>The <em>.dot</em> file is a plain-text file, so you can view it in the terminal; for example:</p>

<pre class="small" data-code-language="wdl" data-type="programlisting">
<code class="nv">$</code> <code class="n">cat</code> <code class="o">~/</code><code class="n">sandbox</code><code class="o">-</code><code class="mi">8</code><code class="o">/</code><code class="k">scatter</code><code class="o">-</code><code class="n">haplotypecaller</code><code class="p">.</code><code class="n">dot</code>
<code class="n">digraph</code> <code class="n">ScatterHaplotypeCallerGVCF</code> <code class="p">{</code>
 <code class="cp">#rankdir=LR;</code>
 <code class="n">compound</code><code class="o">=</code><code class="nb">true</code><code class="p">;</code>
 <code class="cp"># Links</code>
 <code class="n">CALL_HaplotypeCallerGVCF</code> <code class="o">-&gt;</code> <code class="n">CALL_MergeVCFs</code>
 <code class="n">SCATTER_0_VARIABLE_interval</code> <code class="o">-&gt;</code> <code class="n">CALL_HaplotypeCallerGVCF</code>
 <code class="cp"># Nodes</code>
 <code class="n">CALL_MergeVCFs</code> <code class="p">[</code><code class="n">label</code><code class="o">=</code><code class="s">"call MergeVCFs"</code><code class="p">]</code>
 <code class="n">subgraph</code> <code class="n">cluster_0</code> <code class="p">{</code>
   <code class="n">style</code><code class="o">=</code><code class="s">"filled,solid"</code><code class="p">;</code>
   <code class="n">fillcolor</code><code class="o">=</code><code class="n">white</code><code class="p">;</code>
   <code class="n">CALL_HaplotypeCallerGVCF</code> <code class="p">[</code><code class="n">label</code><code class="o">=</code><code class="s">"call HaplotypeCallerGVCF"</code><code class="p">]</code>
   <code class="n">SCATTER_0_VARIABLE_interval</code> <code class="p">[</code><code class="n">shape</code><code class="o">=</code><code class="s">"hexagon"</code> <code class="n">label</code><code class="o">=</code><code class="s">"scatter over String as interval"</code><code class="p">]</code>
 <code class="p">}</code>
<code class="p">}</code></pre>

<p>However, that’s not terribly visual, so let’s load it into a graph viewer. <a contenteditable="false" data-primary="Womtool" data-secondary="graph command, generating graph diagram for workflow visualization" data-startref="ix_Wmtoolgr" data-type="indexterm" id="idm45625617564968"/><a contenteditable="false" data-primary="GraphViz package" data-type="indexterm" id="idm45625617497896"/>There are many available options, including the very popular open source package <a href="https://oreil.ly/FS_SR">Graphviz</a>. You can either install the package on your local machine or use it through one of its <a href="https://oreil.ly/WSMml">many online implementations</a>. To do so, simply copy the contents of the <em>.dot</em> file into the text window of the visualizer app, and it will generate the graph diagram for you, as shown in <a data-type="xref" href="#visualizing_the_workflow_graph_in_an_on">Figure 8-3</a>.</p>

<figure><div id="visualizing_the_workflow_graph_in_an_on" class="figure"><img alt="Visualizing the workflow graph in an online Graphviz application." src="Images/gitc_0803.png" width="1442" height="528"/>
<h6><span class="label">Figure 8-3. </span>Visualizing the workflow graph in an online Graphviz application.</h6>
</div></figure>

<p>When we visualize a workflow graph like this, we typically look at the ovals first, which represent calls to tasks in the workflow. Here you can see that the two task calls in our workflow are indeed present, <code>HaplotypeCallerGVCF</code> and <code>MergeVCFs</code>. The direction of the arrows connecting the ovals indicates the flow of execution, so in <a data-type="xref" href="#visualizing_the_workflow_graph_in_an_on">Figure 8-3</a>, you can see that the output of <code>HaplotypeCallerGVCF</code> is going to be the input to <code>MergeVCFs</code>.</p>

<p>Interestingly, the call to <code>HaplotypeCallerGVCF</code> is displayed with a box around it, which means it is under the control of a modifying function. The modifier function is represented as a hexagon, and here you can see the hexagon is labeled “scatter over String as interval.” That all makes sense because we just discussed how in this workflow the execution of the <code>HaplotypeCaller</code> task is scattered over a list of intervals.</p>

<p>In this case, the workflow was straightforward enough that the graph visualization didn’t really tell us anything we didn’t already know, but when we tackle more complex workflows in the next chapter, graph visualization is going to be a crucial part of our toolkit.<a contenteditable="false" data-primary="graphs" data-secondary="generating graph diagram for workflow visualization" data-startref="ix_graph" data-type="indexterm" id="idm45625617485928"/><a contenteditable="false" data-primary="scatter-gather parallelism" data-secondary="generating graph diagram for workflow visualization" data-startref="ix_scgapargr" data-type="indexterm" id="idm45625617484184"/><a contenteditable="false" data-primary="automating analysis execution with workflows" data-secondary="using scatter-gather parallelism" data-startref="ix_autoanpar" data-type="indexterm" id="idm45625617482440"/><a contenteditable="false" data-primary="parallel computing" data-secondary="scatter-gather parallelism in GATK workflow" data-startref="ix_parcmpscga" data-type="indexterm" id="idm45625617480744"/><a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="your first workflow, Hello HaplotypeCaller" data-startref="ix_GATKwkfpar" data-tertiary="parallelizing operation of" data-type="indexterm" id="idm45625617479064"/><a contenteditable="false" data-primary="scatter-gather parallelism" data-startref="ix_scgapar" data-type="indexterm" id="idm45625617477080"/></p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This concludes the exercises in this chapter, so don’t forget to stop your VM; otherwise, you’ll be paying just to have it idly ponder the futility of existence.</p>
</div>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrap-Up and Next Steps"><div class="sect1" id="wrap_up_and_next_steps-id00005">
<h1>Wrap-Up and Next Steps</h1>

<p>In this chapter, we looked at how to string individual commands into a simple Hello World workflow, and we executed it using Cromwell in one-shot run mode on the single VM that we had set up in <a data-type="xref" href="ch04.xhtml#first_steps_in_the_cloud">Chapter 4</a>. We covered the basics of interpreting Cromwell’s terminal output and finding output files. We iterated on the original <code>Hello​World</code> workflow, adding variables and an additional task. Then, we moved on to examine more realistic workflows that run real GATK commands and use scatter-gather parallelism, though still at a fairly small scale. Along the way, we exercised key utilities for generating JSON templates, validating WDL syntax, testing error handling, and generating graph visualizations.</p>

<p>However, we only scratched the surface of WDL’s capabilities as a workflow language, so now it’s time to move on to some more sophisticated workflows. In <a data-type="xref" href="ch09.xhtml#deciphering_real_genomics_workflows">Chapter 9</a>, we examine two mystery workflows and try to reverse engineer what they do, which will give you the opportunity to hone your detective skills and also learn some useful patterns that are used in real genomics analysis workflows.<a contenteditable="false" data-primary="automating analysis execution with workflows" data-startref="ix_autoan" data-type="indexterm" id="idm45625617468936"/><a contenteditable="false" data-primary="workflows" data-secondary="automating analysis execution with" data-startref="ix_wkfaut" data-type="indexterm" id="idm45625617467560"/></p>
</div></section>
</div></section></div>



  </body></html>