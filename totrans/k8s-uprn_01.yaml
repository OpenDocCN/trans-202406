- en: Chapter 1\. Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。介绍
- en: Kubernetes is an open source orchestrator for deploying containerized applications.
    It was originally developed by Google, inspired by a decade of experience deploying
    scalable, reliable systems in containers via application-oriented APIs.^([1](ch01.xhtml#idm45664088726992))
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个用于部署容器化应用程序的开源编排器。它最初由Google开发，灵感来自于十年在容器中通过面向应用程序的API部署可扩展、可靠系统的经验。^([1](ch01.xhtml#idm45664088726992))
- en: Since its introduction in 2014, Kubernetes has grown to be one of the largest
    and most popular open source projects in the world. It has become the standard
    API for building cloud native applications, present in nearly every public cloud.
    Kubernetes is a proven infrastructure for distributed systems that is suitable
    for cloud native developers of all scales, from a cluster of Raspberry Pi computers
    to a datacenter full of the latest machines. It provides the software necessary
    to successfully build and deploy reliable, scalable distributed systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 自2014年推出以来，Kubernetes已经成长为世界上最大和最受欢迎的开源项目之一。它已成为构建云原生应用程序的标准API，在几乎每个公共云中都可以找到。Kubernetes是一个经过验证的适用于各种规模云原生开发者的分布式系统基础设施，从一组树莓派计算机到充满最新机器的数据中心。它提供了成功构建和部署可靠、可扩展分布式系统所需的软件支持。
- en: You may be wondering what we mean when we say “reliable, scalable distributed
    systems.” More and more services are delivered over the network via APIs. These
    APIs are often delivered by a *distributed system*, the various pieces that implement
    the API running on different machines, connected via the network and coordinating
    their actions via network communication. Because we increasingly rely on these
    APIs for all aspects of our daily lives (e.g., finding directions to the nearest
    hospital), these systems must be highly *reliable*. They cannot fail, even if
    a part of the system crashes or otherwise stops working. Likewise, they must maintain
    *availability* even during software rollouts or other maintenance events. Finally,
    because more and more of the world is coming online and using such services, they
    must be highly *scalable* so that they can grow their capacity to keep up with
    ever-increasing usage without radical redesign of the distributed system that
    implements the services. In many cases this also means growing (and shrinking)
    the capacity automatically so that your application can be maximally efficient.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说“可靠、可扩展的分布式系统”时，您可能会想知道我们的意思。越来越多的服务通过API在网络上传送。这些API通常由*分布式系统*提供支持，实现API的各个部分运行在不同的机器上，通过网络连接并通过网络通信协调它们的操作。因为我们日常生活中对这些API的依赖越来越多（例如，寻找到最近医院的路线），这些系统必须具备极高的*可靠性*。即使系统的某个部分崩溃或停止工作，它们也不能失败。同样，它们必须在软件部署或其他维护事件期间保持*可用性*。最后，因为越来越多的世界正在上网并使用这类服务，它们必须具备高度*可扩展性*，以便能够根据不断增长的使用需求扩展其容量，而不需要彻底重新设计实现服务的分布式系统。在许多情况下，这还意味着自动增加（和减少）容量，以使您的应用程序能够达到最大效率。
- en: Depending on when and why you have come to hold this book in your hands, you
    may have varying degrees of experience with containers, distributed systems, and
    Kubernetes. You may be planning on building your application on top of public
    cloud infrastructure, in private data centers, or in some hybrid environment.
    Regardless of your experience, this book should enable you to make the most of
    Kubernetes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您何时以及为何拿起这本书，您对容器、分布式系统和Kubernetes可能有不同的经验程度。您可能计划在公共云基础设施、私有数据中心或混合环境中构建应用程序。无论您的经验如何，本书都应能帮助您充分利用Kubernetes。
- en: 'There are many reasons people come to use containers and container APIs like
    Kubernetes, but we believe they can all be traced back to one of these benefits:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人们开始使用容器和像Kubernetes这样的容器API的原因有很多，但我们认为它们都可以追溯到以下几个好处之一：
- en: Development velocity
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发速度
- en: Scaling (of both software and teams)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展（软件和团队）
- en: Abstracting your infrastructure
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽象化您的基础设施
- en: Efficiency
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 效率
- en: Cloud native ecosystem
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云原生生态系统
- en: In the following sections, we describe how Kubernetes can help provide each
    of these features.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将描述Kubernetes如何帮助提供每个功能。
- en: Velocity
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速度
- en: Velocity is the key component in nearly all software development today. The
    software industry has evolved from shipping products as boxed CDs or DVDs to software
    that is delivered over the network via web-based services that are updated hourly.
    This changing landscape means that the difference between you and your competitors
    is often the speed with which you can develop and deploy new components and features,
    or the speed with which you can respond to innovations developed by others.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 速度是当今几乎所有软件开发的关键组成部分。软件行业已经从以盒装 CD 或 DVD 发货的产品转变为通过网络交付的基于 Web 服务的软件，这些软件每小时更新。这种变化的格局意味着，你和竞争对手之间的差异往往是你开发和部署新组件和功能的速度，或者是你对他人开发的创新作出响应的速度。
- en: It is important to note, however, that velocity is not defined in terms of simply
    raw speed. While your users are always looking for iterative improvements, they
    are more interested in a highly reliable service. Once upon a time, it was OK
    for a service to be down for maintenance at midnight every night. But today, all
    users expect constant uptime, even if the software they are running is changing
    constantly.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，速度并不是简单的原始速度定义。虽然用户始终在寻求迭代改进，但他们更感兴趣的是高度可靠的服务。曾经，服务每晚午夜进行维护关闭是可以接受的。但是今天，所有用户都期望服务始终可用，即使运行的软件不断变化。
- en: Consequently, velocity is measured not in terms of the raw number of features
    you can ship per hour or day, but rather in terms of the number of things you
    can ship while maintaining a highly available service.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，速度的衡量不是以每小时或每天可以发布的原始功能数量为准，而是以在保持高度可用服务的同时可以发布的事物数量为准。
- en: 'In this way, containers and Kubernetes can provide the tools that you need
    to move quickly, while staying available. The core concepts that enable this are:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，容器和 Kubernetes 可以提供您需要快速操作同时保持可用性的工具。实现这一点的核心概念包括：
- en: Immutability
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可变性
- en: Declarative configuration
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 声明性配置
- en: Online self-healing systems
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线自愈系统
- en: Shared reusable libraries and tools
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享可重用的库和工具
- en: These ideas all interrelate to radically improve the speed with which you can
    reliably deploy new software.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些想法都相互关联，以显著提高您可靠部署新软件的速度。
- en: The Value of Immutability
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不可变性的价值
- en: Containers and Kubernetes encourage developers to build distributed systems
    that adhere to the principles of immutable infrastructure. With *immutable* infrastructure,
    once an artifact is created in the system, it does not change via user modifications.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 容器和 Kubernetes 鼓励开发者构建符合不可变基础设施原则的分布式系统。通过*不可变*基础设施，一旦在系统中创建了一个构件，它就不会通过用户修改而改变。
- en: Traditionally, computers and software systems have been treated as *mutable*
    infrastructure. With mutable infrastructure, changes are applied as incremental
    updates to an existing system. These updates can occur all at once, or spread
    out across a long period of time. A system upgrade via the `apt-get update` tool
    is a good example of an update to a mutable system. Running `apt` sequentially
    downloads any updated binaries, copies them on top of older binaries, and makes
    incremental updates to configuration files. With a mutable system, the current
    state of the infrastructure is not represented as a single artifact, but rather
    as an accumulation of incremental updates and changes over time. On many systems,
    these incremental updates come not just from system upgrades, but operator modifications
    as well. Furthermore, in any system run by a large team, it is highly likely that
    these changes will have been performed by many different people and, in many cases,
    will not have been recorded anywhere.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，计算机和软件系统被视为*可变*基础设施。在可变基础设施中，更改被应用为对现有系统的增量更新。这些更新可以一次性完成，也可以在很长一段时间内分散进行。通过
    `apt-get update` 工具进行系统升级是对可变系统的一个很好的例子。运行 `apt` 时，逐个下载任何更新的二进制文件，将它们复制到旧的二进制文件上，并对配置文件进行增量更新。在可变系统中，基础设施的当前状态不是表示为单个构件，而是作为随时间累积的增量更新和变化的累积。在许多系统中，这些增量更新不仅来自系统升级，还来自操作员的修改。此外，在由大型团队运行的任何系统中，很可能这些变更将由许多不同的人执行，并且在许多情况下，这些变更并没有记录在任何地方。
- en: In contrast, in an immutable system, rather than a series of incremental updates
    and changes, an entirely new, complete image is built, where the update simply
    replaces the entire image with the newer image in a single operation. There are
    no incremental changes. As you can imagine, this is a significant shift from the
    more traditional world of configuration management.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，在一个不可变系统中，与增量更新和更改的系列相比，一个全新的、完整的镜像被构建，其中更新只需在单个操作中用新镜像替换整个镜像。没有增量变化。可以想象，这与配置管理的传统世界是一个重大的转变。
- en: 'To make this more concrete in the world of containers, consider two different
    ways to upgrade your software:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在容器的世界中更具体化，考虑升级软件的两种不同方式：
- en: You can log in to a container, run a command to download your new software,
    kill the old server, and start the new one.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以登录到一个容器中，运行一个命令来下载你的新软件，关闭旧服务器，然后启动新的服务器。
- en: You can build a new container image, push it to a container registry, kill the
    existing container, and start a new one.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以构建一个新的容器镜像，推送到容器注册表，杀死现有的容器，然后启动一个新的容器。
- en: At first blush, these two approaches might seem largely indistinguishable. So
    what is it about the act of building a new container that improves reliability?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，这两种方法可能看起来几乎无法区分。那么是什么让构建一个新的容器镜像提高了可靠性呢？
- en: The key differentiation is the artifact that you create, and the record of how
    you created it. These records make it easy to understand exactly the differences
    in some new version and, if something goes wrong, to determine what has changed
    and how to fix it.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 关键的区别在于你创建的构件，以及如何创建它的记录。这些记录使得能够准确理解某个新版本的差异，如果出现问题，也能确定发生了什么变化以及如何修复它。
- en: Additionally, building a new image rather than modifying an existing one means
    the old image is still around, and can quickly be used for a rollback if an error
    occurs. In contrast, once you copy your new binary over an existing binary, such
    a rollback is nearly impossible.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，构建新镜像而不是修改现有镜像意味着旧镜像仍然存在，并且可以在错误发生时快速用于回滚。相比之下，一旦你将新的二进制文件复制到现有二进制文件上，回滚几乎是不可能的。
- en: Immutable container images are at the core of everything that you will build
    in Kubernetes. It is possible to imperatively change running containers, but this
    is an antipattern to be used only in extreme cases where there are no other options
    (e.g., if it is the only way to temporarily repair a mission-critical production
    system). And even then, the changes must also be recorded through a declarative
    configuration update at some later time, after the fire is out.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 不可变容器镜像是你在 Kubernetes 中构建的一切的核心。虽然可以命令式地更改运行中的容器，但这是一种反模式，只应在极端情况下使用（例如，如果这是唯一的临时修复关键生产系统的方法）。即使如此，这些更改也必须在稍后通过声明式配置更新时记录。
- en: Declarative Configuration
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 声明式配置对象
- en: Immutability extends beyond containers running in your cluster to the way you
    describe your application to Kubernetes. Everything in Kubernetes is a *declarative
    configuration object* that represents the desired state of the system. It is the
    job of Kubernetes to ensure that the actual state of the world matches this desired
    state.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不可变性扩展到在集群中运行的容器以及描述你的应用程序给 Kubernetes 的方式上。在 Kubernetes 中，一切都是*声明式配置对象*，代表系统的期望状态。Kubernetes
    的工作是确保实际世界的状态与这个期望状态匹配。
- en: Much like mutable versus immutable infrastructure, declarative configuration
    is an alternative to *imperative* configuration, where the state of the world
    is defined by the execution of a series of instructions rather than a declaration
    of the desired state of the world. While imperative commands define actions, declarative
    configurations define state.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 就像可变与不可变基础架构一样，声明式配置是对*命令式*配置的一种替代，其中世界的状态是通过执行一系列指令来定义的，而不是声明世界期望的状态。虽然命令式命令定义了动作，声明式配置定义了状态。
- en: To understand these two approaches, consider the task of producing three replicas
    of a piece of software. With an imperative approach, the configuration would say
    “run A, run B, and run C.” The corresponding declarative configuration would be
    “replicas equals three.”
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这两种方法，考虑一下生产软件的三个副本的任务。使用命令式方法，配置会说“运行 A，运行 B 和运行 C”。相应的声明式配置将是“副本等于三”。
- en: Because it describes the state of the world, declarative configuration does
    not have to be executed to be understood. Its impact is concretely declared. Since
    the effects of declarative configuration can be understood before they are executed,
    declarative configuration is far less error-prone. Further, the traditional tools
    of software development, such as source control, code review, and unit testing,
    can be used in declarative configuration in ways that are impossible for imperative
    instructions. The idea of storing declarative configuration in source control
    is often referred to as “infrastructure as code.”
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它描述了世界的状态，声明性配置不必执行就能理解。它的影响被明确声明。由于声明性配置的效果可以在执行之前理解，因此声明性配置的错误可能性要少得多。此外，传统的软件开发工具，如源代码控制、代码审查和单元测试，可以以不可能用于命令式指令的方式用于声明性配置。将声明性配置存储在源代码控制中的想法通常被称为“基础设施即代码”。
- en: Lately the idea of GitOps has begun to formalize the practice of infrastructure
    as code with source control as the source of truth. When you adopt GitOps, changes
    to production are made entirely via pushes to a Git repository, which are then
    reflected into your cluster via automation. Indeed, your production Kubernetes
    cluster is viewed as effectively a read-only environment. Additionally, GitOps
    is being increasingly integrated into cloud-provided Kubernetes services as the
    easiest way to declaratively manage your cloud native infrastructure.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 近来，GitOps 的理念已经开始通过源代码控制正式化基础设施即代码的实践。当您采用 GitOps 时，对生产环境的更改完全通过推送到 Git 仓库来进行，然后通过自动化反映到您的集群中。实际上，您的生产
    Kubernetes 集群被视为一个有效的只读环境。此外，GitOps 被越来越多地集成到由云提供的 Kubernetes 服务中，作为管理您的云原生基础设施的最简单方式。
- en: The combination of declarative state stored in a version control system and
    the ability of Kubernetes to make reality match this declarative state makes rollback
    of a change trivially easy. It is simply restating the previous declarative state
    of the system. This is usually impossible with imperative systems, because although
    the imperative instructions describe how to get you from point A to point B, they
    rarely include the reverse instructions that can get you back.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 存储在版本控制系统中的声明性状态与 Kubernetes 使现实与这种声明性状态匹配的能力结合起来，使回滚变更变得极为简单。它只是重新声明系统的先前声明状态。这通常对于命令式系统来说是不可能的，因为尽管命令式指令描述了如何从点A到点B，但很少包括可以使您回到原点的反向指令。
- en: Self-Healing Systems
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自我修复系统
- en: Kubernetes is an online, self-healing system. When it receives a desired state
    configuration, it does not simply take a set of actions to make the current state
    match the desired state a single time. It *continuously* takes actions to ensure
    that the current state matches the desired state. This means that not only will
    Kubernetes initialize your system, but it will guard it against any failures or
    perturbations that might destabilize the system and affect reliability.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个在线的、自我修复的系统。当它接收到期望的状态配置时，不只是单次地执行一组操作使当前状态与期望状态匹配。它**持续**地执行操作，确保当前状态始终与期望状态一致。这意味着
    Kubernetes 不仅会初始化您的系统，还会防范可能会破坏系统稳定性和可靠性的任何故障或干扰。
- en: A more traditional operator repair involves a manual series of mitigation steps,
    or human intervention, performed in response to some sort of alert. Imperative
    repair like this is more expensive (since it generally requires an on-call operator
    to be available to enact the repair). It is also generally slower, since a human
    must often wake up and log in to respond. Furthermore, it is less reliable because
    the imperative series of repair operations suffers from all of the problems of
    imperative management described in the previous section. Self-healing systems
    like Kubernetes both reduce the burden on operators and improve the overall reliability
    of the system by performing reliable repairs more quickly.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 更传统的操作员修复方式包括一系列手动的缓解步骤，或者对某种警报进行人工干预。这样的命令式修复更昂贵（因为通常需要值班操作员随时待命进行修复）。而且通常更慢，因为人类必须经常唤醒并登录以响应。此外，它也不太可靠，因为命令式修复操作序列具有前一节中描述的所有命令式管理问题。像
    Kubernetes 这样的自我修复系统通过更快、更可靠地执行可靠的修复操作，不仅减轻了操作员的负担，还提高了系统的整体可靠性。
- en: As a concrete example of this self-healing behavior, if you assert a desired
    state of three replicas to Kubernetes, it does not just create three replicas—it
    continuously ensures that there are exactly three replicas. If you manually create
    a fourth replica, Kubernetes will destroy one to bring the number back to three.
    If you manually destroy a replica, Kubernetes will create one to again return
    you to the desired state.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这种自我修复行为的一个具体例子，如果您向 Kubernetes 断言一个期望状态为三个副本，它不仅仅创建三个副本 —— 它会持续确保恰好有三个副本。如果您手动创建第四个副本，Kubernetes
    将销毁一个以确保数量恢复到三个。如果您手动销毁一个副本，Kubernetes 将创建一个副本以再次将您带回到期望的状态。
- en: Online self-healing systems improve developer velocity because the time and
    energy you might otherwise have spent on operations and maintenance can instead
    be spent on developing and testing new features.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在线自我修复系统提高了开发人员的速度，因为您本来可能花在运营和维护上的时间和精力可以用来开发和测试新功能。
- en: In a more advanced form of self-healing, there has been significant recent work
    in the *operator* paradigm for Kubernetes. With operators, more advanced logic
    needed to maintain, scale, and heal a specific piece of software (MySQL, for example)
    is encoded into an operator application that runs as a container in the cluster.
    The code in the operator is responsible for more targeted and advanced health
    detection and healing than can be achieved via Kubernetes’s generic self-healing.
    Often this is packaged up as “operators,” which are discussed in [Chapter 17](ch17.xhtml#extending_kubernetes).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 的*操作员*范式中，有了更高级的自我修复形式。使用操作员，编码进入集群中作为容器运行的操作员应用程序中的更高级逻辑，以维护、扩展和修复特定软件（例如
    MySQL）。操作员中的代码负责比 Kubernetes 的通用自我修复更具针对性和高级的健康检测和修复。通常这被打包成“操作员”，这些在[第 17 章](ch17.xhtml#extending_kubernetes)中有所讨论。
- en: Scaling Your Service and Your Teams
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展您的服务和团队
- en: As your product grows, it’s inevitable that you will need to scale both your
    software and the teams that develop it. Fortunately, Kubernetes can help with
    both of these goals. Kubernetes achieves scalability by favoring *decoupled* architectures.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 随着产品的增长，您需要扩展开发它的软件和团队是不可避免的。幸运的是，Kubernetes 可以帮助实现这两个目标。Kubernetes 通过偏爱*解耦*架构来实现可伸缩性。
- en: Decoupling
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解耦
- en: In a decoupled architecture, each component is separated from other components
    by defined APIs and service load balancers. APIs and load balancers isolate each
    piece of the system from the others. APIs provide a buffer between implementer
    and consumer, and load balancers provide a buffer between running instances of
    each service.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在解耦架构中，每个组件通过定义的 API 和服务负载均衡器与其他组件分离。API 和负载均衡器将系统的每个部分隔离开来。API 提供了实施者和使用者之间的缓冲，负载均衡器为每个服务的运行实例之间提供了一个缓冲区。
- en: Decoupling components via load balancers makes it easy to scale the programs
    that make up your service, because increasing the size (and therefore the capacity)
    of the program can be done without adjusting or reconfiguring any of the other
    layers of your service.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过负载均衡器解耦组件使得可以轻松扩展构成您服务的程序，因为增加程序的规模（因此增加了容量）可以在不调整或重新配置服务的任何其他层的情况下完成。
- en: Decoupling servers via APIs makes it easier to scale the development teams because
    each team can focus on a single, smaller *microservice* with a comprehensible
    surface area. Crisp APIs between microservices limit the amount of cross-team
    communication overhead required to build and deploy software. This communication
    overhead is often the major restricting factor when scaling teams.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 API 解耦服务器使得扩展开发团队变得更容易，因为每个团队可以专注于单个、更小的*微服务*，其可理解的表面积。清晰的微服务之间的 API 限制了构建和部署软件所需的跨团队通信开销。这种通信开销通常是扩展团队时的主要限制因素。
- en: Easy Scaling for Applications and Clusters
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用程序和集群的轻松扩展
- en: Concretely, when you need to scale your service, the immutable, declarative
    nature of Kubernetes makes this scaling trivial to implement. Because your containers
    are immutable, and the number of replicas is merely a number in a declarative
    config, scaling your service upward is simply a matter of changing a number in
    a configuration file, asserting this new declarative state to Kubernetes, and
    letting it take care of the rest. Alternatively, you can set up autoscaling and
    let Kubernetes do it for you.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，当你需要扩展你的服务时，Kubernetes的不可变声明性质使得这种扩展变得轻而易举。因为你的容器是不可变的，并且副本的数量仅仅是配置文件中的一个数字，将服务扩展至更大规模只需要改变配置文件中的一个数字，声明这种新的状态给Kubernetes，然后让它处理其余的工作。另外，你也可以设置自动扩展，让Kubernetes来处理。
- en: Of course, that sort of scaling assumes that there are resources available in
    your cluster to consume. Sometimes you actually need to scale up the cluster itself.
    Again, Kubernetes makes this task easier. Because many machines in a cluster are
    entirely identical to other machines in that set and the applications themselves
    are decoupled from the details of the machine by containers, adding additional
    resources to the cluster is simply a matter of imaging a new machine of the same
    class and joining it into the cluster. This can be accomplished via a few simple
    commands or via a prebaked machine image.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这种缩放方式假定你的集群有足够的资源可供使用。有时候，实际上需要扩展集群本身。同样，Kubernetes使得这项任务更加简单。由于集群中的许多机器与该集合中的其他机器完全相同，并且应用程序本身通过容器与机器的具体细节解耦，因此向集群添加额外的资源只是将一个新的同类机器映像并加入集群的简单任务。这可以通过几个简单的命令或预制的机器映像来完成。
- en: One of the challenges of scaling machine resources is predicting their use.
    If you are running on physical infrastructure, the time to obtain a new machine
    is measured in days or weeks. On both physical and cloud infrastructures, predicting
    future costs is difficult because it is hard to predict the growth and scaling
    needs of specific applications.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展机器资源的一个挑战是预测它们的使用情况。如果你在物理基础设施上运行，获取新机器的时间以天数或周数来计算。在物理和云基础设施上，预测未来的成本很困难，因为很难预测特定应用程序的增长和扩展需求。
- en: 'Kubernetes can simplify forecasting future compute costs. To understand why
    this is true, consider scaling up three teams: A, B, and C. Historically you have
    seen that each team’s growth is highly variable and thus hard to predict. If you
    are provisioning individual machines for each service, you have no choice but
    to forecast based on the maximum expected growth for each service, since machines
    dedicated to one team cannot be used for another team. If, instead, you use Kubernetes
    to decouple the teams from the specific machines they are using, you can forecast
    growth based on the aggregate growth of all three services. Combining three variable
    growth rates into a single growth rate reduces statistical noise and produces
    a more reliable forecast of expected growth. Furthermore, decoupling the teams
    from specific machines means that teams can share fractional parts of one another’s
    machines, reducing even further the overheads associated with forecasting growth
    of computing resources.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes可以简化预测未来的计算成本。要理解这一点为何成立，请考虑将A、B和C三个团队进行扩展：历史上你会看到每个团队的增长高度不确定，因此难以预测。如果为每个服务预留单独的机器，你只能根据每个服务的最大预期增长进行预测，因为专用于一个团队的机器无法用于另一个团队。相反，如果使用Kubernetes将团队与它们使用的具体机器解耦，你可以基于所有三个服务的总体增长来预测增长。将三个变化率合并为单一增长率可以减少统计噪声，并产生更可靠的预期增长预测。此外，将团队与特定机器解耦意味着团队可以共享彼此机器的部分资源，进一步降低了计算资源增长预测所带来的开销。
- en: Finally, Kubernetes makes it possible to achieve automatic scaling (both up
    and down) of resources. Especially in a cloud environment where new machines can
    be created via APIs, combining Kubernetes with autoscaling for both the applications
    and the clusters themselves means that you can always rightsize your costs for
    the current load.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Kubernetes使得资源可以自动扩展（扩展和收缩）。特别是在云环境中，可以通过API创建新的机器，结合Kubernetes和应用程序以及集群本身的自动缩放，意味着你可以根据当前负载始终调整你的成本。
- en: Scaling Development Teams with Microservices
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用微服务扩展开发团队
- en: As noted in a variety of research, the ideal team size is the “two-pizza team,”
    or roughly six to eight people. This group size often results in good knowledge
    sharing, fast decision making, and a common sense of purpose. Larger teams tend
    to suffer from issues of hierarchy, poor visibility, and infighting, which hinder
    agility and success.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 据多种研究指出，理想的团队规模是“两块披萨团队”，大约六到八人。这种团队规模通常会促进良好的知识共享、快速决策以及共同的目标感。而较大的团队往往会遭受层级问题、能见度不足和内讧等问题，这些问题会阻碍敏捷性和成功。
- en: However, many projects require significantly more resources to be successful
    and achieve their goals. Consequently, there is a tension between the ideal team
    size for agility and the necessary team size for the product’s end goals.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，许多项目需要更多的资源才能成功实现其目标。因此，敏捷性的理想团队规模与产品最终目标所需团队规模之间存在紧张关系。
- en: The common solution to this tension has been the development of decoupled, service-oriented
    teams that each build a single microservice. Each small team is responsible for
    the design and delivery of a service that is consumed by other small teams. The
    aggregation of all of these services ultimately provides the implementation of
    the overall product’s surface area.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这种紧张关系的常见方法是开发独立、面向服务的团队，每个团队负责构建一个单一的微服务。每个小团队负责设计和交付一个被其他小团队消费的服务。所有这些服务的聚合最终提供了整体产品表面的实现。
- en: 'Kubernetes provides numerous abstractions and APIs that make it easier to build
    these decoupled microservice architectures:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了多种抽象和 API，使得构建这些独立的微服务架构变得更加容易：
- en: '*Pods*, or groups of containers, can group together container images developed
    by different teams into a single deployable unit.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pods*，或者说是容器组，可以将由不同团队开发的容器镜像组合成一个可部署的单元。'
- en: Kubernetes *services* provide load balancing, naming, and discovery to isolate
    one microservice from another.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes *服务* 提供负载均衡、命名和发现功能，以隔离一个微服务与另一个微服务。
- en: '*Namespaces* provide isolation and access control, so that each microservice
    can control the degree to which other services interact with it.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*命名空间* 提供了隔离和访问控制，以便每个微服务可以控制其他服务与其交互的程度。'
- en: '*Ingress* objects provide an easy-to-use frontend that can combine multiple
    microservices into a single externalized API surface area.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*入口* 对象提供了一个易于使用的前端，可以将多个微服务组合成单个外部化的 API 表面。'
- en: Finally, decoupling the application container image and machine means that different
    microservices can colocate on the same machine without interfering with one another,
    reducing the overhead and cost of microservice architectures. The health-checking
    and rollout features of Kubernetes guarantee a consistent approach to application
    rollout and reliability, which ensures that a proliferation of microservice teams
    does not also result in a proliferation of different approaches to service production
    life cycle and operations.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，解耦应用程序容器镜像和机器意味着不同的微服务可以共同部署在同一台机器上而不会相互干扰，从而降低微服务架构的开销和成本。Kubernetes 的健康检查和部署功能保证了应用程序部署和可靠性的一致方法，确保微服务团队的增加不会导致服务生产生命周期和运维的不同方法大量增加。
- en: Separation of Concerns for Consistency and Scaling
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一致性和扩展的关注点分离
- en: In addition to the consistency that Kubernetes brings to operations, the decoupling
    and separation of concerns produced by the Kubernetes stack lead to significantly
    greater consistency for the lower levels of your infrastructure. This enables
    you to scale infrastructure operations to manage many machines with a single small,
    focused team. We have talked at length about the decoupling of application container
    and machine/operating system (OS), but an important aspect of this decoupling
    is that the container orchestration API becomes a crisp contract that separates
    the responsibilities of the application operator from the cluster orchestration
    operator. We call this the “not my monkey, not my circus” line. The application
    developer relies on the service-level agreement (SLA) delivered by the container
    orchestration API, without worrying about the details of how this SLA is achieved.
    Likewise, the container orchestration API reliability engineer focuses on delivering
    the orchestration API’s SLA without worrying about the applications that are running
    on top of it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 Kubernetes 带来的运营一致性之外，Kubernetes 堆栈产生的解耦和关注点分离显著提高了基础设施的一致性。这使得您能够通过一个小而专注的团队扩展基础设施运营，以管理多台机器。我们已经详细讨论了应用容器与机器/操作系统（OS）的解耦，但这种解耦的一个重要方面是容器编排
    API 成为一个清晰的合同，分离了应用操作员和集群编排操作员的责任。我们称之为“不是我的猴子，不是我的马戏团”的界线。应用开发人员依赖容器编排 API 提供的服务级别协议（SLA），而不用担心如何实现这个
    SLA 的细节。同样，容器编排 API 可靠性工程师专注于提供编排 API 的 SLA，而不用担心运行在其上的应用程序。
- en: Decoupling concerns means that a small team running a Kubernetes cluster can
    be responsible for supporting hundreds or even thousands of teams running applications
    within that cluster ([Figure 1-1](#fig0101)). Likewise, a small team can be responsible
    for dozens (or more) of clusters running around the world. It’s important to note
    that the same decoupling of containers and OS enables the OS reliability engineers
    to focus on the SLA of the individual machine’s OS. This becomes another line
    of separate responsibility, with the Kubernetes operators relying on the OS SLA,
    and the OS operators worrying solely about delivering that SLA. Again, this enables
    you to scale a small team of OS experts to a fleet of thousands of machines.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 解耦关注点意味着运行 Kubernetes 集群的小团队可以负责支持在该集群内运行的数百甚至数千个团队的应用程序（参见[图 1-1](#fig0101)）。同样，一个小团队可以负责全球各地运行的数十个（甚至更多）集群。需要注意的是，容器和操作系统的这种解耦使得操作系统可靠性工程师能够专注于单个机器操作系统的
    SLA。这成为另一条分离责任的界线，Kubernetes 操作员依赖操作系统的 SLA，而操作系统操作员则专注于交付该 SLA。同样，这使得您能够将一小队操作系统专家扩展到数千台机器的集群。
- en: '![kur3 0101](assets/kur3_0101.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![kur3 0101](assets/kur3_0101.png)'
- en: Figure 1-1\. An illustration of how different operations teams are decoupled
    using APIs
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-1\. 通过 API 解耦不同运营团队的示意图
- en: Of course, devoting even a small team to managing an OS is beyond the scope
    of many organizations. In these environments, a managed Kubernetes-as-a-Service
    (KaaS) provided by a public cloud provider is a great option. As Kubernetes has
    become increasingly ubiquitous, KaaS has become increasingly available as well,
    to the point where it is now offered on nearly every public cloud. Of course,
    using KaaS has some limitations, since the operator makes decisions for you about
    how the Kubernetes clusters are built and configured. For example, many KaaS platforms
    disable alpha features because they can destabilize the managed cluster.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，即使是将一个小团队用于操作系统管理也超出了许多组织的范围。在这些环境中，由公共云提供商提供的托管 Kubernetes 服务（KaaS）是一个很好的选择。随着
    Kubernetes 的普及，KaaS 的可用性也越来越高，几乎每个公共云现在都提供这种服务。当然，使用 KaaS 也有一些限制，因为运营商为您做出了关于如何构建和配置
    Kubernetes 集群的决策。例如，许多 KaaS 平台禁用了 alpha 特性，因为它们可能会使托管的集群不稳定。
- en: In addition to a fully managed Kubernetes service, there is a thriving ecosystem
    of companies and projects that help to install and manage Kubernetes. There is
    a full spectrum of solutions between doing it “the hard way” and a fully managed
    service.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 除了完全托管的 Kubernetes 服务之外，还有许多公司和项目构成的蓬勃生态系统帮助安装和管理 Kubernetes。在“硬方式”和完全托管服务之间有完整的解决方案谱系。
- en: Consequently, whether to use KaaS or manage it yourself (or something in between)
    is a decision each user needs to make based on the skills and demands of their
    situation. Often for small organizations, KaaS provides an easy-to-use solution
    that enables them to focus their time and energy on building the software to support
    their work rather than managing a cluster. For larger organizations that can afford
    a dedicated team for managing its Kubernetes cluster, managing it that way may
    make sense since it enables greater flexibility in terms of cluster capabilities
    and operations.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，是使用 KaaS 还是自己管理（或介于两者之间），是每个用户根据其情况的技能和需求来决定的。通常对于小型组织来说，KaaS 提供了一个易于使用的解决方案，使他们能够将时间和精力集中在构建支持他们工作的软件上，而不是管理一个集群。对于可以承担专门团队来管理其
    Kubernetes 集群的大型组织来说，以这种方式管理可能更有意义，因为它能够在集群能力和操作方面提供更大的灵活性。
- en: Abstracting Your Infrastructure
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抽象你的基础设施
- en: The goal of the public cloud is to provide easy-to-use, self-service infrastructure
    for developers to consume. However, too often cloud APIs are oriented around mirroring
    the infrastructure that IT expects (e.g., “virtual machines”), not the concepts
    (e.g., “applications”) that developers want to consume. Additionally, in many
    cases the cloud comes with particular details in implementation or services that
    are specific to the cloud provider. Consuming these APIs directly makes it difficult
    to run your application in multiple environments, or spread between cloud and
    physical environments.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 公共云的目标是为开发人员提供易于使用的自助服务基础设施。然而，云 API 往往是围绕着 IT 期望的基础设施（例如“虚拟机”），而不是开发人员希望消费的概念（例如“应用程序”）来定位的。此外，在许多情况下，云服务还伴随着特定的实施细节或服务，这些细节是特定于云提供商的。直接使用这些
    API 使得在多个环境中运行您的应用程序或在云和物理环境之间进行分布变得困难。
- en: The move to application-oriented container APIs like Kubernetes has two concrete
    benefits. First, as we described previously, it separates developers from specific
    machines. This makes the machine-oriented IT role easier, since machines can simply
    be added in aggregate to scale the cluster, and in the context of the cloud it
    also enables a high degree of portability since developers are consuming a higher-level
    API that is implemented in terms of the specific cloud infrastructure APIs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用面向应用的容器 API（如 Kubernetes）有两个具体的好处。首先，正如我们之前描述的那样，它将开发人员与具体的机器分离开来。这使得以机器为中心的
    IT 角色更加容易，因为机器可以简单地按照总体来增加以扩展集群，并且在云环境中，它还能够提供高度的可移植性，因为开发人员是在使用一个更高级别的 API，这个
    API 是基于特定云基础设施的 API 实现的。
- en: When your developers build their applications in terms of container images and
    deploy them in terms of portable Kubernetes APIs, transferring your application
    between environments, or even running in hybrid environments, is simply a matter
    of sending the declarative config to a new cluster. Kubernetes has a number of
    plug-ins that can abstract you from a particular cloud. For example, Kubernetes
    services know how to create load balancers on all major public clouds as well
    as several different private and physical infrastructures. Likewise, Kubernetes
    PersistentVolumes and PersistentVolumeClaims can be used to abstract your applications
    away from specific storage implementations. Of course, to achieve this portability,
    you need to avoid cloud-managed services (e.g., Amazon’s DynamoDB, Azure’s Cosmos
    DB, or Google’s Cloud Spanner), which means that you will be forced to deploy
    and manage open source storage solutions like Cassandra, MySQL, or MongoDB.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当开发人员基于容器镜像构建其应用程序，并基于可移植的 Kubernetes API 部署它们时，将应用程序迁移到不同环境，甚至在混合环境中运行，只是将声明性配置发送到新集群的问题。Kubernetes
    拥有许多插件，可以使您从特定的云中抽象出来。例如，Kubernetes 服务知道如何在所有主要的公共云以及几种不同的私有和物理基础设施上创建负载均衡器。同样，Kubernetes
    持久卷和持久卷声明可以用来将您的应用程序与特定的存储实现分离开来。当然，为了实现这种可移植性，您需要避免使用云管理服务（例如 Amazon 的 DynamoDB、Azure
    的 Cosmos DB 或 Google 的 Cloud Spanner），这意味着您将被迫部署和管理开源存储解决方案，如 Cassandra、MySQL
    或 MongoDB。
- en: Putting it all together, building on top of Kubernetes application-oriented
    abstractions ensures that the effort you put into building, deploying, and managing
    your application is truly portable across a wide variety of environments.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，基于 Kubernetes 应用程序导向的抽象构建确保您在构建、部署和管理应用程序时投入的努力在各种环境中都是真正可移植的。
- en: Efficiency
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 效率
- en: In addition to the developer and IT management benefits that containers and
    Kubernetes provide, there is also a concrete economic benefit to the abstraction.
    Because developers no longer think in terms of machines, their applications can
    be colocated on the same machines without impacting the applications themselves.
    This means that tasks from multiple users can be packed tightly onto fewer machines.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 除了容器和 Kubernetes 提供的开发人员和 IT 管理好处外，抽象化还带来了明显的经济效益。因为开发人员不再考虑机器的问题，他们的应用程序可以共同部署在同一台机器上，而不会影响应用程序本身。这意味着可以将来自多个用户的任务紧密地打包到更少的机器上。
- en: Efficiency can be measured by the ratio of the useful work performed by a machine
    or process to the total amount of energy spent doing so. When it comes to deploying
    and managing applications, many of the available tools and processes (e.g., bash
    scripts, `apt` updates, or imperative configuration management) are somewhat inefficient.
    When discussing efficiency, it’s often helpful to think of both the monetary cost
    of running a server and the human cost required to manage it.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 效率可以通过机器或进程执行的有效工作与所花费的总能量的比率来衡量。在部署和管理应用程序时，许多可用的工具和流程（例如 bash 脚本、`apt` 更新或命令式配置管理）有些效率低下。在讨论效率时，通常有助于同时考虑运行服务器的货币成本和管理所需的人力成本。
- en: Running a server incurs a cost based on power usage, cooling requirements, data-center
    space, and raw compute power. Once a server is racked and powered on (or clicked
    and spun up), the meter literally starts running. Any idle CPU time is money wasted.
    Thus, it becomes part of the system administrator’s responsibilities to keep utilization
    at acceptable levels, which requires ongoing management. This is where containers
    and the Kubernetes workflow come in. Kubernetes provides tools that automate the
    distribution of applications across a cluster of machines, ensuring higher levels
    of utilization than are possible with traditional tooling.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 运行服务器会产生基于功耗、冷却需求、数据中心空间和原始计算能力的成本。一旦服务器安装并上电（或者点击并启动），计费就开始了。任何空闲的 CPU 时间都是浪费金钱。因此，系统管理员有责任保持利用率在可接受的水平，这需要持续的管理。这就是容器和
    Kubernetes 工作流发挥作用的地方。Kubernetes 提供的工具自动化分发应用程序到机群上，确保比传统工具更高的利用率。
- en: 'A further increase in efficiency comes from the fact that a developer’s test
    environment can be quickly and cheaply created as a set of containers running
    in a personal view of a shared Kubernetes cluster (using a feature called *namespaces*).
    In the past, turning up a test cluster for a developer might have meant turning
    up three machines. With Kubernetes, it is simple to have all developers share
    a single test cluster, aggregating their usage onto a much smaller set of machines.
    Reducing the overall number of machines used in turn drives up the efficiency
    of each system: since more of the resources (CPU, RAM, etc.) on each individual
    machine are used, the overall cost of each container becomes much lower.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步提高效率的一项措施是，开发人员的测试环境可以快速、廉价地创建为运行在共享 Kubernetes 集群的一组容器（使用名为*命名空间*的功能）。过去，为开发人员启动测试集群可能意味着启动三台机器。有了
    Kubernetes，所有开发人员共享单个测试集群变得非常简单，将他们的使用聚合到更少的机器上。进一步减少使用的机器总数从而提高了每个系统的效率：因为每台单独机器上的资源（CPU、内存等）被更多利用，每个容器的整体成本大大降低。
- en: Reducing the cost of development instances in your stack enables development
    practices that might previously have been cost-prohibitive. For example, with
    your application deployed via Kubernetes, it becomes conceivable to deploy and
    test every single commit contributed by every developer throughout your entire
    stack.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 减少堆栈中开发实例的成本使得以前可能成本过高的开发实践变得可行。例如，通过 Kubernetes 部署应用程序，可以考虑部署和测试每个开发人员在整个堆栈中贡献的每个提交。
- en: When the cost of each deployment is measured in terms of a small number of containers,
    rather than multiple complete virtual machines (VMs), the cost you incur for such
    testing is dramatically lower. Returning to the original value of Kubernetes,
    this increased testing also increases velocity, since you have strong signals
    as to the reliability of your code as well as the granularity of detail required
    to quickly identify where a problem may have been introduced.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当每次部署的成本是以少量容器而不是多个完整虚拟机（VMs）的形式衡量时，您为此类测试所需的成本大大降低。回到Kubernetes的原始价值，这种增加的测试也增加了速度，因为您具有有关代码可靠性的强信号，以及快速识别问题可能已引入的细节粒度。
- en: Finally, as mentioned in previous sections, the use of automatic scaling to
    add resources when needed, but remove them when they are not, can also be used
    to drive the overall efficiency of your applications while maintaining their required
    performance characteristics.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如前文所述，使用自动扩展在需要时增加资源，但在不需要时删除资源，也可以用来推动应用程序的整体效率，同时保持其所需的性能特征。
- en: Cloud Native Ecosystem
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云原生生态系统
- en: Kubernetes was designed from the ground up to be an extensible environment and
    a broad and welcoming community. These design goals and its ubiquity in so many
    compute environments have led to a vibrant and large ecosystem of tools and services
    that have grown up around Kubernetes. Following the lead of Kubernetes (and Docker
    and Linux before it), most of these projects are also open source. This means
    that a developer beginning to build does not have to start from scratch. In the
    years since it was released, tools for nearly every task, from machine learning
    to continuous development and serverless programming models have been built for
    Kubernetes. Indeed, in many cases the challenge isn’t finding a potential solution,
    but rather deciding which of the many solutions is best suited to the task. The
    wealth of tools in the cloud native ecosystem has itself become a strong reason
    for many people to adopt Kubernetes. When you leverage the cloud native ecosystem,
    you can use community-built and supported projects for nearly every part of your
    system, allowing you to focus on the development of the core business logic and
    services that are uniquely yours.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes从一开始就被设计为一个可扩展的环境和一个广泛而友好的社区。这些设计目标以及它在众多计算环境中的普及，导致了围绕Kubernetes形成了一个充满活力和庞大的工具和服务生态系统。跟随Kubernetes（以及之前的Docker和Linux），大多数这些项目也是开源的。这意味着开发人员在开始构建时无需从头开始。自发布以来的这些年里，几乎为每个任务构建了针对Kubernetes的工具，从机器学习到持续开发和无服务器编程模型。事实上，在许多情况下，挑战不在于找到潜在的解决方案，而是决定哪一个解决方案最适合该任务。云原生生态系统中丰富的工具已经成为许多人采用Kubernetes的一个重要原因。当您利用云原生生态系统时，您可以使用社区构建和支持的项目来几乎涵盖系统的每个部分，从而让您专注于开发核心业务逻辑和独特的服务。
- en: As with any open source ecosystem, the primary challenge is the variety of possible
    solutions and the fact that there is often a lack of end-to-end integration. One
    possible way to navigate this complexity is the technical guidance of the Cloud
    Native Computing Foundation (CNCF). The CNCF acts as a industry-neutral home for
    cloud native projects’ code and intellectual property. It has three levels of
    project maturity to help guide your adoption of cloud native projects. The majority
    of projects in the CNCF are in the *sandbox* stage. Sandbox indicates that a project
    is still in early development, and adoption is not recommended unless you are
    an early adopter and/or interested in contributing to the development of the project.
    The next stage in maturity is *incubating*. Incubating projects are ones that
    have proven their utility and stability via adoption and production usage; however,
    they are still developing and growing their communities. While there are hundreds
    of sandbox projects, there are barely more than 20 incubating projects. The final
    stage of CNCF projects is *graduated*. These projects are fully mature and widely
    adopted. There are only a few graduated projects, including Kubernetes itself.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何开源生态系统一样，主要挑战在于可能的解决方案多样性，以及往往存在端到端集成不足的问题。解决这种复杂性的一种可能方式是依靠云原生计算基金会（CNCF）的技术指导。CNCF
    是云原生项目代码和知识产权的行业中立承载机构。它有三个项目成熟度级别，帮助指导你采纳云原生项目。CNCF 中的大多数项目处于 *sandbox* 阶段。Sandbox
    表示项目仍处于早期开发阶段，不建议采纳，除非你是早期采纳者或有兴趣为项目开发做贡献。项目成熟度的下一个阶段是 *incubating*。Incubating
    项目通过采纳和生产使用已经证明了它们的实用性和稳定性，但它们仍在发展和扩展它们的社区。尽管有数百个 sandbox 项目，但 incubating 项目只有20多个。CNCF
    项目的最终阶段是 *graduated*。这些项目已经完全成熟并被广泛采用。只有少数几个 graduated 项目，包括 Kubernetes 本身。
- en: Another way to navigate the cloud native ecosystem is via integration with Kubernetes-as-a-Service.
    At this point, most of the KaaS offerings also have additional services via open
    source projects from the cloud native ecosystem. Because these services are integrated
    into cloud-supported products, you can be assured that the projects are mature
    and production ready.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通过与 Kubernetes 服务集成，是另一种浏览云原生生态系统的方式。在此阶段，大多数 KaaS 提供的还有来自云原生生态系统的开源项目的额外服务。因为这些服务已经集成到云支持的产品中，你可以放心这些项目是成熟且可用于生产的。
- en: Summary
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Kubernetes was built to radically change the way that applications are built
    and deployed in the cloud. Fundamentally, it was designed to give developers more
    velocity, efficiency, and agility. At this point, many of the internet services
    and applications that you use every day are running on top of Kubernetes. You
    are probably already a Kubernetes user, you just didn’t know it! We hope this
    chapter has given you an idea of why you should deploy your applications using
    Kubernetes. Now that you are convinced of that, the following chapters will teach
    you *how* to deploy your applications.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的建立旨在彻底改变应用程序在云中的构建和部署方式。从根本上讲，它被设计为提供开发人员更高的速度、效率和敏捷性。在此时，你每天使用的许多互联网服务和应用程序都在
    Kubernetes 之上运行。你可能已经是 Kubernetes 的用户，只是你还不知道！我们希望本章节让你明白为什么应该使用 Kubernetes 部署你的应用程序。既然你已经被说服了，接下来的章节将教你如何部署你的应用程序。
- en: '^([1](ch01.xhtml#idm45664088726992-marker)) Brendan Burns et al., “Borg, Omega,
    and Kubernetes: Lessons Learned from Three Container-Management Systems over a
    Decade,” *ACM Queue* 14 (2016): 70–93, available at [*https://oreil.ly/ltE1B*](https://oreil.ly/ltE1B).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.xhtml#idm45664088726992-marker)) Brendan Burns 等人，“Borg、Omega 和 Kubernetes：三种容器管理系统十年来的经验教训”，*ACM
    Queue* 14（2016）：70–93，可在[*https://oreil.ly/ltE1B*](https://oreil.ly/ltE1B)找到。
