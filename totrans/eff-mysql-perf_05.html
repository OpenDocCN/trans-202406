<html><head></head><body><section data-pdf-bookmark="Chapter 5. Sharding" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch05">&#13;
<h1><span class="label">Chapter 5. </span>Sharding</h1>&#13;
&#13;
&#13;
<p>On a single <a data-primary="sharding" data-type="indexterm" id="idm45829111592480"/>instance of MySQL, performance depends on queries, data, access patterns, and hardware.&#13;
When direct and indirect query optimization—assiduously applied—no longer deliver acceptable performance, you have reached the relative limit of single-instance MySQL performance for the application workload.&#13;
To surpass that relative limit, you must divide the application workload across multiple instances of MySQL to achieve MySQL at scale.</p>&#13;
&#13;
<p><em>Sharding</em> a database is the common and widely used technique of <em>scaling out</em> (or, <em>horizontal scaling</em>): increasing performance by distributing the workload across multiple databases.&#13;
(By contrast, <em>scaling up</em>, or <em>vertical scaling</em>, increases performance by increasing hardware capacity.)&#13;
Sharding divides one database into many databases.&#13;
Each database is a shard, and each shard is typically stored on a separate MySQL instance running on separate hardware.&#13;
Shards are physically separate but logically the same (very large) database.</p>&#13;
&#13;
<p>MySQL at scale requires sharding.&#13;
I’m going to repeat that sentence several times in this chapter because it’s a fact that engineers hesitate to accept.&#13;
Why?&#13;
Because sharding is not an intrinsic feature or capability of MySQL.&#13;
Consequently, sharding is complex and entirely application-specific, which means there’s no easy solution.&#13;
But don’t be discouraged: sharding is a solved problem.&#13;
Engineers have been scaling out MySQL for decades.</p>&#13;
&#13;
<p>This chapter introduces the basic mechanics of sharding to achieve MySQL at scale.&#13;
There are four major sections.&#13;
The first explains why a single database does not scale—why sharding is necessary.&#13;
The second completes the analogy from Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch03.html#ch03">3</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.html#ch04">4</a>: why pebbles (database shards) are better than boulders (huge databases).&#13;
The third is a brief introduction to the complex topic of relational database sharding.&#13;
The fourth presents alternatives to sharding.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Why a Single Database Does Not Scale" data-type="sect1"><div class="sect1" id="idm45829111583936">&#13;
<h1>Why a Single Database Does Not Scale</h1>&#13;
&#13;
<p>Nobody questions that a single application can overload a single server—that’s why scaling out is necessary for all types of servers and applications, not just MySQL.&#13;
Sharding is therefore necessary because it’s how MySQL scales out: more databases.&#13;
But it’s reasonable to wonder why a single MySQL database does not scale given that very powerful hardware is available and some benchmarks demonstrate incredible performance on that hardware.&#13;
Five reasons follow, beginning with the most fundamental: the application workload can significantly outpace the speed and capacity of single-server hardware.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Application Workload" data-type="sect2"><div class="sect2" id="scale-up-app-workload">&#13;
<h2>Application Workload</h2>&#13;
&#13;
<p><a data-type="xref" href="#hw-no-load">Figure 5-1</a> is a simple illustration <a data-primary="sharding" data-secondary="application workload" data-type="indexterm" id="application-workload_index1"/><a data-primary="application workload" data-type="indexterm" id="application-workload_index2"/>of hardware capacity on a single server with zero load.</p>&#13;
&#13;
<figure><div class="figure" id="hw-no-load">&#13;
<img alt="emsp 0501" src="assets/emsp_0501.png"/>&#13;
<h6><span class="label">Figure 5-1. </span>Hardware without load</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-type="xref" href="#hw-no-load">Figure 5-1</a> is intentionally simple—but not simplistic—because it subtly conveys a critically important point: <em>hardware capacity is finite and limited</em>.&#13;
The circle represents the limits of the hardware.&#13;
Let’s presume the hardware is dedicated to running a single MySQL instance for one application—no virtualization, crypto coin mining, or other load.&#13;
Everything that runs on the hardware must fit inside the circle.&#13;
Since this is dedicated hardware, the only thing running on it is the application workload shown in <a data-type="xref" href="#hw-normal-load">Figure 5-2</a>: queries, data, and access patterns.</p>&#13;
&#13;
<figure><div class="figure" id="hw-normal-load">&#13;
<img alt="emsp 0502" src="assets/emsp_0502.png"/>&#13;
<h6><span class="label">Figure 5-2. </span>Hardware with standard MySQL workload</h6>&#13;
</div></figure>&#13;
&#13;
<p>It’s no coincidence that <em>Queries</em> refer to <a data-type="xref" href="ch02.html#ch02">Chapter 2</a>, <em>Data</em> to <a data-type="xref" href="ch03.html#ch03">Chapter 3</a>, and <em>Access Patterns</em> to <a data-type="xref" href="ch04.html#ch04">Chapter 4</a>.&#13;
These constitute the application workload: everything that causes load on MySQL which, in turn, causes load on the hardware (CPU utilization, disk I/O, and so forth).&#13;
The box sizes are important: the bigger the box, the bigger the load.&#13;
In <a data-type="xref" href="#hw-normal-load">Figure 5-2</a>, the workload is within the capacity of the hardware, with a little room to spare because the operating system needs hardware resources, too.</p>&#13;
&#13;
<p>Queries, data, and access patterns are inextricable with respect to performance.&#13;
(I proved this with <code>TRUNCATE TABLE</code> in <a data-type="xref" href="ch01.html#indirect-query-optimization">“Indirect Query Optimization”</a>.)&#13;
Data size is a common reason for scaling out because, as shown in <a data-type="xref" href="#hw-too-much-data">Figure 5-3</a>, it causes the workload to exceed the capacity of a single server.</p>&#13;
&#13;
<figure><div class="figure" id="hw-too-much-data">&#13;
<img alt="emsp 0503" src="assets/emsp_0503.png"/>&#13;
<h6><span class="label">Figure 5-3. </span>Hardware with too much data</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before less_space">Data size cannot increase without eventually affecting queries and access patterns.&#13;
Buying a bigger hard drive won’t solve the problem because, as <a data-type="xref" href="#hw-too-much-data">Figure 5-3</a> shows, there’s plenty of capacity for the data, but the data is not the only part of the workload.</p>&#13;
&#13;
<p><a data-type="xref" href="#hw-all-data">Figure 5-4</a> illustrates a common misconception that leads engineers to think that a single database can scale to maximum data size, which is currently 64 TB for a single InnoDB table.</p>&#13;
&#13;
<figure><div class="figure" id="hw-all-data">&#13;
<img alt="emsp 0504" src="assets/emsp_0504.png"/>&#13;
<h6><span class="label">Figure 5-4. </span>Hardware with only data (scaling misconception)</h6>&#13;
</div></figure>&#13;
&#13;
<p>Data is only one part of the workload, and the other two parts (queries and access patterns) cannot be ignored.&#13;
Realistically, for acceptable performance with a lot of data on a single sever, the workload must look like <a data-type="xref" href="#hw-large-data">Figure 5-5</a>.</p>&#13;
&#13;
<figure><div class="figure" id="hw-large-data">&#13;
<img alt="emsp 0505" src="assets/emsp_0505.png"/>&#13;
<h6><span class="label">Figure 5-5. </span>Hardware with large data</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">If the queries are simple and have exceptionally good indexes, and the access patterns are trivial (for example, very low-throughput reads), then a single server can store a lot of data.&#13;
This isn’t just a clever illustration; real applications have workloads like <a data-type="xref" href="#hw-large-data">Figure 5-5</a>.</p>&#13;
&#13;
<p>These five illustrations reveal that a single database cannot scale because the application workload—which comprises queries, data, and access patterns—must fit within the capacity of the hardware.&#13;
After <a data-type="xref" href="ch02.html#better-faster-hardware">“Better, Faster Hardware!”</a> and <a data-type="xref" href="ch04.html#better-faster-hardware-again">“Better, Faster Hardware?”</a>, you already know that hardware won’t solve this problem.</p>&#13;
&#13;
<p>MySQL at scale requires sharding because application workloads can significantly outpace the speed and capacity of single-server hardware.<a data-primary="sharding" data-secondary="application workload" data-startref="application-workload_index1" data-type="indexterm" id="idm45829111546160"/><a data-primary="application workload" data-startref="application-workload_index2" data-type="indexterm" id="idm45829111544896"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Benchmarks Are Synthetic" data-type="sect2"><div class="sect2" id="idm45829111580976">&#13;
<h2>Benchmarks Are Synthetic</h2>&#13;
&#13;
<p>Benchmarks <a data-primary="sharding" data-secondary="benchmarks" data-type="indexterm" id="benchmarks_index1"/><a data-primary="benchmarks" data-type="indexterm" id="benchmarks_index2"/>use synthetic (fake) queries, data, and access patterns.&#13;
These are necessarily fake because they’re not real applications and certainly not your application.&#13;
Therefore, benchmarks cannot tell you—or even suggest—how your application will perform and scale—even on the same hardware.&#13;
Moreover, benchmarks largely focus on one or more access pattern (see <a data-type="xref" href="ch04.html#access-patterns">“Data Access Patterns”</a>), which produces a workload like the one pictured in <a data-type="xref" href="#hw-benchmark">Figure 5-6</a>.</p>&#13;
&#13;
<figure><div class="figure" id="hw-benchmark">&#13;
<img alt="emsp 0506" src="assets/emsp_0506.png"/>&#13;
<h6><span class="label">Figure 5-6. </span>Hardware with benchmark workload</h6>&#13;
</div></figure>&#13;
&#13;
<p>Most applications don’t have a workload where performance is dominated by one or more access pattern.&#13;
But it’s common for benchmarks because it allows MySQL experts to stress and measure a particular aspect of MySQL.&#13;
For example, if a MySQL expert wants to measure the effectiveness of a new page flushing algorithm, they might use a 100% write-only workload with a few perfectly optimized queries and very little data.</p>&#13;
&#13;
<p class="pagebreak-before">But let me be perfectly clear: benchmarks are important and necessary for MySQL experts and the MySQL industry.&#13;
(As mentioned in <a data-type="xref" href="ch02.html#mysql-tuning">“MySQL Tuning”</a>, benchmarking is laboratory work.)&#13;
Benchmarks are used to do the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Compare hardware (one storage device against another)</p>&#13;
</li>&#13;
<li>&#13;
<p>Compare server optimizations (one flushing algorithm against another)</p>&#13;
</li>&#13;
<li>&#13;
<p>Compare different data stores (MySQL versus PostgreSQL—the classic rivalry)</p>&#13;
</li>&#13;
<li>&#13;
<p>Test MySQL at the limit (see <a data-type="xref" href="ch04.html#perf-at-the-limit">“Performance Destabilizes at the Limit”</a>)</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>That work is incredibly important for MySQL, and it’s why MySQL is capable of amazing performance.&#13;
But conspicuously absent from that list is anything related to your application and its particular workload.&#13;
Consequently, whatever amazing MySQL performance you read or hear about in benchmarks will not translate to your application, and the very same experts producing those benchmarks will tell you: MySQL at scale requires sharding.<a data-primary="sharding" data-secondary="benchmarks" data-startref="benchmarks_index1" data-type="indexterm" id="idm45829111527888"/><a data-primary="benchmarks" data-startref="benchmarks_index2" data-type="indexterm" id="idm45829111526640"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Writes" data-type="sect2"><div class="sect2" id="idm45829111525568">&#13;
<h2>Writes</h2>&#13;
&#13;
<p>Writes <a data-primary="sharding" data-secondary="writes" data-type="indexterm" id="writes_index1"/><a data-primary="writes" data-type="indexterm" id="writes_index2"/>are difficult to scale on a single MySQL instance for several reasons:</p>&#13;
<dl>&#13;
<dt>Single writable (source) instance</dt>&#13;
<dd>&#13;
<p>  For high <a data-primary="single writable (source) instance" data-type="indexterm" id="idm45829111520016"/>availability, MySQL in production employs several instances connected in a replication topology.&#13;
But writes are effectively limited to a single MySQL instance to avoid <em>write conflicts</em>: multiple writes to the same row at the same time.&#13;
MySQL supports multiple writable instances, but you will have a difficult time finding anyone who uses this feature because write conflicts are too troublesome.</p>&#13;
</dd>&#13;
<dt>Transactions and locking</dt>&#13;
<dd>&#13;
<p>  Transactions <a data-primary="transactions" data-type="indexterm" id="idm45829111516736"/>use locking <a data-primary="locking" data-type="indexterm" id="idm45829111515872"/>to guarantee consistency—the <em>C</em> in an <a data-primary="ACID (atomicity, consistency, isolation, and durability) properties" data-type="indexterm" id="idm45829111514656"/>ACID-compliant database.&#13;
Writes must acquire row locks, and sometimes they lock significantly more rows than you might expect—<a data-type="xref" href="ch08.html#row-locking">“Row Locking”</a> explains why.&#13;
Locks lead to lock contention, which makes access pattern trait <a data-type="xref" href="ch04.html#ap-concurrency">“Concurrency”</a> a critical factor in how well writes scale.&#13;
If the workload is write-heavy on the same data, even the best hardware in the world won’t help.</p>&#13;
</dd>&#13;
<dt>Page flushing (durability)</dt>&#13;
<dd>&#13;
<p>  <em>Page flushing</em> is the <a data-primary="page flushing" data-type="indexterm" id="idm45829111510176"/><a data-primary="durability" data-type="indexterm" id="idm45829111509440"/>delayed process by which MySQL persists changes (from writes) to disk.&#13;
The entire process is too complex to explain in this section, but the salient point is: page flushing is the bottleneck of write performance.&#13;
Although MySQL is very efficient, the process is inherently slow because it must ensure that data is <em>durable</em>: persisted to disk.&#13;
Without durability, writes are incredibly fast due to caching, but durability is a requirement because all hardware crashes eventually.</p>&#13;
</dd>&#13;
<dt>Write amplification</dt>&#13;
<dd>&#13;
<p>  <em>Write amplification</em> <a data-primary="write amplification" data-type="indexterm" id="idm45829111505984"/>refers to writes requiring more writes.&#13;
Secondary indexes are the simplest example.&#13;
If a table has 10 secondary indexes, a single write could write 10 additional writes to update those indexes.&#13;
Page flushing (durability) incurs additional writes, and replication incurs even more writes.&#13;
This is not unique to MySQL; it affects other data stores, too.</p>&#13;
</dd>&#13;
<dt>Replication</dt>&#13;
<dd>&#13;
<p>  Replication <a data-primary="replication" data-type="indexterm" id="idm45829111503472"/>is required for high availability, so all writes must replicate to other MySQL instances—replicas.&#13;
<a data-type="xref" href="ch07.html#ch07">Chapter 7</a> addresses replication, but here are a few salient points with respect to scaling writes.&#13;
MySQL supports asynchronous replication, semisynchronous replication, and <a href="https://oreil.ly/oeJtD">Group Replication</a>.&#13;
Asynchronous replication has a small effect on write performance because data changes are written and flushed to binary logs on transaction commit—but after that, there’s no effect.&#13;
Semisynchronous replication has a greater effect on write performance: it attenuates transaction throughput to network latency because every commit must be acknowledged by at least one replica.&#13;
Since network latency measures in milliseconds, the effect on write performance is noticeable, but it’s a worthwhile trade-off because it guarantees that no committed transactions are lost, which is not true for asynchronous replication.&#13;
Group Replication is more complex and it’s more difficult to scale writes. For various reasons explained in <a data-type="xref" href="ch07.html#ch07">Chapter 7</a>, I do not cover Group Replication in this book.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>These five reasons are formidable challenges to scaling writes on a single MySQL instance—even for MySQL experts.&#13;
MySQL at scale requires sharding to overcome these challenges and scale write performance.<a data-primary="sharding" data-secondary="writes" data-startref="writes_index1" data-type="indexterm" id="idm45829111498608"/><a data-primary="writes" data-startref="writes_index2" data-type="indexterm" id="idm45829111497360"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Schema Changes" data-type="sect2"><div class="sect2" id="osc-1">&#13;
<h2>Schema Changes</h2>&#13;
&#13;
<p>Schema changes <a data-primary="sharding" data-secondary="schema changes" data-type="indexterm" id="schema-changes_index1"/><a data-primary="schema changes" data-type="indexterm" id="schema-changes_index2"/>are more than routine; they’re practically required.&#13;
Furthermore, it’s not uncommon for the largest tables to change frequently because their size reflects their usage, and usage leads to development, which leads to changes.&#13;
Even if you manage to overcome all other obstacles and scale a single table to an enormous size, the time required to change that table will be untenable.&#13;
How long?&#13;
It can take days or weeks to alter a large table.</p>&#13;
&#13;
<p>The long wait is not a problem for MySQL or the application because online schema change (OSC) tools like <a href="https://oreil.ly/tSrrr">pt-online-schema-change</a> and <a href="https://oreil.ly/nUuvv"><code>gh-ost</code></a> and certain built-in <a href="https://oreil.ly/5KiA7">online DDL operations</a> can run for days or weeks while allowing the application to function normally—​which is why they’re called <em>online</em>.&#13;
But it is a problem for engineers <span class="keep-together">developing</span> the application because waiting that long does not go unnoticed; rather, it tends to become an increasingly annoying blocker to you, other engineers, and possibly other teams.</p>&#13;
&#13;
<p>For example, just a few weeks ago I helped a team alter several tables, each with one <em>billion</em> rows, that had failed to complete after nearly two weeks of trying (for various technical reasons not related to MySQL).&#13;
The blocker went far beyond the table or the team: long story short, it blocked an organization-level goal—months of work by several other teams.&#13;
Luckily, the needed schema change happened to be an instant <a href="https://oreil.ly/5KiA7">online DDL operation</a>.&#13;
But instant schema changes are exceedingly rare, so don’t count on them.&#13;
Instead, don’t let a table become so large that you cannot alter it in a reasonable amount of time—whatever you, your team, and your company deem <em>reasonable</em>.</p>&#13;
&#13;
<p>MySQL at scale requires sharding because engineers cannot wait days or weeks to change a schema.<a data-primary="sharding" data-secondary="schema changes" data-startref="schema-changes_index1" data-type="indexterm" id="idm45829111484160"/><a data-primary="schema changes" data-startref="schema-changes_index2" data-type="indexterm" id="idm45829111482912"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Operations" data-type="sect2"><div class="sect2" id="idm45829111481840">&#13;
<h2>Operations</h2>&#13;
&#13;
<p>If you <a data-primary="sharding" data-secondary="operations" data-type="indexterm" id="idm45829111480464"/><a data-primary="operations" data-type="indexterm" id="idm45829111479456"/>directly and indirectly optimize queries with exacting precision and unmitigated meticulousness, you can scale up a single database to a size that people won’t believe until you show them.&#13;
But the illustrations of hardware and workload in <a data-type="xref" href="#scale-up-app-workload">“Application Workload”</a> do not depict the following <em>operations</em> (or <em>ops</em> as they’re more commonly called):</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Backup and restore</p>&#13;
</li>&#13;
<li>&#13;
<p>Rebuilding failed instances</p>&#13;
</li>&#13;
<li>&#13;
<p>Upgrading MySQL</p>&#13;
</li>&#13;
<li>&#13;
<p>MySQL shutdown, startup, and crash recovery</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The larger the database, the longer those operations take.&#13;
As an application developer, you might not manage any of those operations, but they will affect you unless the engineers managing the database are exceptionally adept at—and deeply committed to—zero-downtime operations.&#13;
Cloud providers, for example, are neither adept nor committed; they only attempt to minimize downtime, which can mean anything from 20 seconds to hours of the database being offline.</p>&#13;
&#13;
<p>MySQL at scale requires sharding to efficiently manage the data, which leads us to the next section: pebbles, not boulders.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Pebbles, Not Boulders" data-type="sect1"><div class="sect1" id="pebbles-not-boulders">&#13;
<h1>Pebbles, Not Boulders</h1>&#13;
&#13;
<p>It’s <a data-primary="sharding" data-secondary="data size" data-type="indexterm" id="idm45829111468592"/><a data-primary="data size" data-type="indexterm" id="idm45829111467584"/>significantly easier to move pebbles <a data-primary="pebbles" data-type="indexterm" id="idm45829111466784"/>than <a data-primary="boulders" data-type="indexterm" id="idm45829111465984"/>boulders.&#13;
I belabor this analogy because it’s apt: MySQL at scale is achieved by using many small instances.&#13;
(To refresh your memory on the analogy, read the introductory sections of Chapters <a href="ch03.html#ch03">3</a> and <a href="ch04.html#ch04">4</a>.)</p>&#13;
&#13;
<p><em>Small</em>, in this context, means two things:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The application workload runs with acceptable performance on the hardware.</p>&#13;
</li>&#13;
<li>&#13;
<p>Standard operations (including OSC) take an acceptable amount of time.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>At first glance, that makes <em>small</em> seem so relative that it’s useless, but in practice the limited range of hardware capacity significantly narrows the scope to an almost objective measure.&#13;
For example, at the time of this writing, I advise engineers to limit the total data size of a single MySQL instance to 2 or 4 TB:</p>&#13;
<dl>&#13;
<dt>2 TB</dt>&#13;
<dd>&#13;
<p>For average queries and access patterns, commodity hardware is sufficient for acceptable performance, and operations complete in reasonable time.</p>&#13;
</dd>&#13;
<dt>4 TB</dt>&#13;
<dd>&#13;
<p>For exceptionally optimized queries and access patterns, mid- to high-end hardware is sufficient for acceptable performance, but operations might take slightly longer than acceptable.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>These limits only reflect the hardware capacity that you can readily purchase today (December 2021).&#13;
Years ago, the limits were significantly lower.&#13;
(Remember when disks would physically spin and make crackling sounds? Weird.)&#13;
Years from now, the limits will be significantly greater.</p>&#13;
&#13;
<p>Once a database is sharded, the number of shards is trivial to the application because it accesses them programmatically.&#13;
But to operations—especially the engineers operating the MySQL instances—the <em>size</em> of shards is critically important: it’s significantly easier to manage a 500 GB database than a 7 TB database.&#13;
And since operations are automated, it’s easy to mange any number of small databases.</p>&#13;
&#13;
<p>MySQL performance is truly unlimited when sharded and operated as many small databases—pebbles, not boulders.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Sharding: A Brief Introduction" data-type="sect1"><div class="sect1" id="sharding-intro">&#13;
<h1>Sharding: A Brief Introduction</h1>&#13;
&#13;
<p>The solution and implementation of sharding are necessarily coupled to the application workload.&#13;
This is true even for the alternative solutions presented in the next section, <a data-type="xref" href="#shard-alt">“Alternatives”</a>.&#13;
Consequently, no one can tell you how to shard, and there are no fully-automated solutions.&#13;
Prepare for a long but worthwhile journey.</p>&#13;
&#13;
<p>Sharding has two paths from idea to implementation:</p>&#13;
<dl>&#13;
<dt>Designing a new application for sharding</dt>&#13;
<dd>&#13;
<p>  The first <a data-primary="sharding" data-secondary="design for" data-type="indexterm" id="idm45829111448304"/>and rarest path is when an application is designed from the beginning for sharding.&#13;
If you’re developing a new application, I highly encourage you to take this path <em>if needed</em> because it’s incomparably easier to shard from the start than to migrate later.</p>&#13;
&#13;
<p>To determine whether sharding is needed, estimate data size and growth for the next four years.&#13;
If the estimated data size in four years fits within the capacity of your hardware <em>today</em>, then sharding might not be needed.&#13;
I call this the <em>four-year fit</em>.&#13;
Also try to estimate the four-year fit <a data-primary="four-year fit" data-primary-sortas="fouryear fit" data-type="indexterm" id="idm45829111444848"/>for the other two aspects of the application workload: queries and access patterns.&#13;
These are difficult to estimate (and likely to change) for a new application, but you should have some ideas and expectations because they’re a necessary part of designing and implementing an application.</p>&#13;
&#13;
<p>Also consider whether the data set is bounded or unbounded.&#13;
A <em>bounded data set</em> has <a data-primary="bounded data set" data-type="indexterm" id="idm45829111442336"/>an intrinsic maximum size or intrinsically slow growth.&#13;
For example, the number of new smart phones released every year is very small, and its growth is intrinsically slow because there’s no reason to believe that manufacturers will ever release thousands of new phones per year.&#13;
An <em>unbounded data set</em> <a data-primary="unbounded data set" data-type="indexterm" id="idm45829111440784"/>has no intrinsic limits.&#13;
For example, pictures are unbounded: people can post unlimited pictures.&#13;
Since hardware capacity is bounded, applications should always define and impose extrinsic limits on unbounded data sets.&#13;
Never let data grow unbounded.&#13;
An unbounded data set strongly indicates the need for sharding, unless old data is frequently deleted or archived (see <a data-type="xref" href="ch03.html#delete-or-archive">“Delete or Archive Data”</a>).</p>&#13;
</dd>&#13;
<dt>Migrating an existing application to sharding</dt>&#13;
<dd>&#13;
<p>  The second <a data-primary="sharding" data-secondary="migration to" data-type="indexterm" id="migration-to"/>and more common path is migrating an existing database and application to sharding.&#13;
This path is significantly more difficult, time-consuming, and risky because, by the time it’s required, the database is large—MySQL is hauling a <a data-primary="boulders" data-type="indexterm" id="idm45829111435856"/>boulder uphill.&#13;
With a team of experienced developers, plan for the migration to take a year or longer.</p>&#13;
&#13;
<p>In this book, I cannot cover how to migrate a single database to a sharded database because it’s a bespoke process: it depends on the sharding solution and application workload.&#13;
But one thing is certain: you will copy data from the original (single) database to the new shards—probably many times—because the initial migration is essentially the first resharding, which is a challenge addressed in <a data-type="xref" href="#resharding">“Resharding”</a>.</p>&#13;
</dd>&#13;
</dl>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45829111432928">&#13;
<h5>Four-Year Fit</h5>&#13;
<p>Why <a data-primary="four-year fit" data-primary-sortas="fouryear fit" data-type="indexterm" id="idm45829111431600"/>estimate data size and growth for the next four years?&#13;
One or two years is too soon: it takes at least a year to implement a big project like sharding.&#13;
Three years is reasonable, and four years is safe: better hardware is a safe bet in four years.&#13;
Also, stock grants commonly vest after four years, which causes turnover.&#13;
Read <a href="https://oreil.ly/goj9j">“Tours of Duty: The New Employer-Employee Compact”</a> by Reid Hoffman, Ben Casnocha, and Chris Yeh.&#13;
A responsible engineer improves the system for future engineers.&#13;
If the database won’t scale past one’s four-year tenure, they should fix it now to ensure that future engineers inherit a scalable system.</p>&#13;
</div></aside>&#13;
&#13;
<p>Sharding is a complex process for either path.&#13;
To begin, choose a shard key and strategy, and understand the challenges that you will face.&#13;
This knowledge gives the journey a destination: a sharded database that you can operate with relative ease.&#13;
Then chart a path from one database to that destination.<a data-primary="sharding" data-secondary="migration to" data-startref="migration-to" data-type="indexterm" id="idm45829111428304"/></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Shard Key" data-type="sect2"><div class="sect2" id="shard-key">&#13;
<h2>Shard Key</h2>&#13;
&#13;
<p>To <a data-primary="sharding" data-secondary="shard key" data-type="indexterm" id="shard-key_index1"/><a data-primary="shard key" data-type="indexterm" id="shard-key_index2"/>shard MySQL, the application must programmatically map data to shards.&#13;
Therefore, the most fundamental decision is the <em>shard key</em>: the column (or columns) by which the data is sharded.&#13;
The shard key is used with a sharding strategy (discussed in the next section) to map data to shards.&#13;
The application, not MySQL, is responsible for mapping and accessing data by shard key because MySQL has no built-in concept of sharding—MySQL is oblivious to sharding.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The term <em>shard</em> is used interchangeably for the database or the MySQL instance where the database is stored.</p>&#13;
</div>&#13;
&#13;
<p>An ideal shard key has three properties:</p>&#13;
<dl>&#13;
<dt><em>High cardinality</em></dt>&#13;
<dd>&#13;
<p>An ideal <a data-primary="high cardinality" data-type="indexterm" id="idm45829111417936"/>shard key has high cardinality (see <a data-type="xref" href="ch02.html#extreme-selectivity">“Extreme Selectivity”</a>) so that data is evenly distributed across shards.&#13;
A great example is a website that lets you watch videos: it could assign each video a unique identifier like <code>dQw4w9WgXcQ</code>.&#13;
The column that stores that identifier is an ideal shard key because every value is unique, therefore cardinality is maximal.</p>&#13;
</dd>&#13;
<dt><em>Reference application entities</em></dt>&#13;
<dd>&#13;
<p>An ideal <a data-primary="reference application entities" data-type="indexterm" id="idm45829111414112"/>shard key references application entities so that access patterns do <em>not</em> cross shards.&#13;
A great example is an application that stores payments: although each payment is unique (maximal cardinality), the customer is the application entity.&#13;
Therefore, the primary access pattern for the application is by customer, not by payment.&#13;
Sharding by customer is ideal because all payments for a single customer should be located on the same shard.</p>&#13;
</dd>&#13;
<dt><em>Small</em></dt>&#13;
<dd>&#13;
<p>An ideal shard key is as small as possible because it’s heavily used: most—if not all—queries include the shard key to avoid scatter queries—one of several <a data-type="xref" href="#sharding-challenges">“Challenges”</a>.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>It should go without saying, but to ensure that it has been said: an ideal shard key, in combination with the sharding strategy, avoids or mitigates the <a data-type="xref" href="#sharding-challenges">“Challenges”</a>, especially transactions and joins.</p>&#13;
&#13;
<p>Spend ample time to identify or create the ideal shard key for your application.&#13;
This decision is half of the foundation: the other half is the sharding strategy that uses the shard key.<a data-primary="sharding" data-secondary="shard key" data-startref="shard-key_index1" data-type="indexterm" id="idm45829111407744"/><a data-primary="shard key" data-startref="shard-key_index2" data-type="indexterm" id="idm45829111406496"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Strategies" data-type="sect2"><div class="sect2" id="shard-strategy">&#13;
<h2>Strategies</h2>&#13;
&#13;
<p>A sharding <a data-primary="sharding" data-secondary="strategies" data-type="indexterm" id="sharding-strategies"/>strategy maps data to shards by shard key value.&#13;
The application implements the sharding strategy to route queries to the shard with the data corresponding to the shard key value.&#13;
This decision is the other half of the foundation.&#13;
Once the shard key and strategy are implemented, it’s exceedingly difficult to change, so choose very carefully.</p>&#13;
&#13;
<p>There are three common strategies: hash, range, and lookup (or directory).&#13;
All three are widely used.&#13;
The best choice depends on the application access patterns—especially row access (see <a data-type="xref" href="ch04.html#ap-row-access">“Row Access”</a>), as mentioned in the next three sections.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Hash" data-type="sect3"><div class="sect3" id="hash-sharding">&#13;
<h3>Hash</h3>&#13;
&#13;
<p>Hash sharding <a data-primary="hash sharding" data-type="indexterm" id="hash-sharding_index1"/>maps hash key values to shards using a hashing algorithm (to produce an integer hash value), the modulo operator (<code>mod</code>), and the number of shards (<code>N</code>).&#13;
<a data-type="xref" href="#hash-sharding-img">Figure 5-7</a> depicts the strategy starting with the hash key value at top and following the solid arrows to a shard at bottom.</p>&#13;
&#13;
<figure><div class="figure" id="hash-sharding-img">&#13;
<img alt="emsp 0507" src="assets/emsp_0507.png"/>&#13;
<h6><span class="label">Figure 5-7. </span>Hash sharding</h6>&#13;
</div></figure>&#13;
&#13;
<p>A hashing algorithm outputs a hash value using the shard key value as input.&#13;
The hash value (which is an integer) <code>mod</code> the number of shards (<code>N</code>) returns the shard number: an integer between zero and N – 1, inclusive.&#13;
In <a data-type="xref" href="#hash-sharding-img">Figure 5-7</a>, the hash value <code>75482 mod 3 = 2</code>, so the data for the shard key value is located on shard <code>2</code>.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>How to map shard numbers to MySQL instances is your choice.&#13;
For example, you could deploy a map of shard numbers to MySQL hostnames with each application instance.&#13;
Or, applications could query a service like <a href="https://etcd.io">etcd</a> to discover how shard numbers map to MySQL instances.</p>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before less_space">If you’re thinking, “Won’t changing the number of shards (<code>N</code>) affect the mapping of data to shards?” you are correct.&#13;
For example, <code>75483 mod 3 = 0</code>, but increase the number of shards to five and the same shard key value maps to a new shard number: <code>75483 mod 5 = 3</code>.&#13;
Luckily, this is a solved problem: a <em>consistent hashing algorithm</em> outputs a consistent hash value independent of <code>N</code>.&#13;
The key word is <em>consistent</em>: it’s still possible, but far less likely, that hash values will change when shards change.&#13;
Since shards are likely to change, you should choose a consistent hashing algorithm.</p>&#13;
&#13;
<p>Hash sharding works for all shard keys because it abstracts the value to an integer.&#13;
That doesn’t mean it’s better or faster, only that it’s easier because the hashing algorithm automatically maps all shard key values.&#13;
However, <em>automatically</em> is also its downside because, as <a data-type="xref" href="#rebalancing">“Rebalancing”</a> discusses, it’s virtually impossible to manually relocate data.</p>&#13;
&#13;
<p>Point access (see <a data-type="xref" href="ch04.html#ap-row-access">“Row Access”</a>) works well with hash sharding because one row can map to only one shard.&#13;
By contrast, range access is probably infeasible with hash sharding—unless the ranges are <em>very</em> small—because of <a data-type="xref" href="#cross-shard-queries">“Cross-shard queries”</a> (one of the common challenges).&#13;
Random access is probably infeasible, too, for the same reason.<a data-primary="hash sharding" data-startref="hash-sharding_index1" data-type="indexterm" id="idm45829111379600"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Range" data-type="sect3"><div class="sect3" id="range-sharding">&#13;
<h3>Range</h3>&#13;
&#13;
<p>Range sharding <a data-primary="range sharding" data-type="indexterm" id="range-sharding_index1"/>defines contiguous key value ranges and maps a shard to each, as depicted in <a data-type="xref" href="#range-sharding-img">Figure 5-8</a>.</p>&#13;
&#13;
<figure><div class="figure" id="range-sharding-img">&#13;
<img alt="emsp 0508" src="assets/emsp_0508.png"/>&#13;
<h6><span class="label">Figure 5-8. </span>Range sharding</h6>&#13;
</div></figure>&#13;
&#13;
<p>You must define the key value ranges in advance.&#13;
This gives you flexibility when mapping data to shards, but it requires a thorough knowledge of data distribution to ensure that the data is evenly distributed across shards.&#13;
Since data distribution changes, expect to deal with  resharding (see <a data-type="xref" href="#resharding">“Resharding”</a>).&#13;
A benefit to range sharding is that, unlike hash sharding, you can change (redefine) the ranges, which helps to manually relocate data.</p>&#13;
&#13;
<p>All data can be sorted and divided into ranges, but this doesn’t make sense for some data, like random identifiers.&#13;
And some data appears random but, upon closer inspection, is actually closely ordered.&#13;
For example, here are three UUIDs generated by MySQL:</p>&#13;
&#13;
<pre data-type="programlisting">f15e7e66-b972-11ab-bc5a-62c7db17db19&#13;
f1e382fa-b972-11ab-bc5a-62c7db17db19&#13;
f25f1dfc-b972-11ab-bc5a-62c7db17db19</pre>&#13;
&#13;
<p>Can you spot the differences?&#13;
Those three UUIDs appear random but would most likely sort into the same range, depending on the range size.&#13;
At scale, this would map most data to the same shard, thereby defeating the purpose of sharding.&#13;
(UUID algorithms vary: some intentionally generate closely ordered values, while others intentionally generate randomly ordered values.)</p>&#13;
&#13;
<p>Range sharding works best when:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The range of shard key values is bounded</p>&#13;
</li>&#13;
<li>&#13;
<p>You can determine the range (minimum and maximum values)</p>&#13;
</li>&#13;
<li>&#13;
<p>You know the distribution of values, and it’s mostly even</p>&#13;
</li>&#13;
<li>&#13;
<p>The range and distribution are unlikely to change</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>For example, stock data could be sharded by stock symbols ranging from <code>AAAA</code> to <code>ZZZZ</code>.&#13;
Although the distribution is probably less in the <code>Z</code> range, overall it will be even enough to ensure that one shard is not significantly larger or accessed more frequently than the other shards.</p>&#13;
&#13;
<p>Point access (see <a data-type="xref" href="ch04.html#ap-row-access">“Row Access”</a>) works well with range sharding as long as row access distributes evenly over the ranges, avoiding hot shards—a common challenge discussed in <a data-type="xref" href="#rebalancing">“Rebalancing”</a>.&#13;
Range access works well with range sharding as long as the row ranges are within the shard ranges; if not, <a data-type="xref" href="#cross-shard-queries">“Cross-shard queries”</a> become a problem.&#13;
Random access is probably infeasible for the same reason: cross-shard queries.<a data-primary="range sharding" data-startref="range-sharding_index1" data-type="indexterm" id="idm45829111358816"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Lookup" data-type="sect3"><div class="sect3" id="idm45829111377936">&#13;
<h3>Lookup</h3>&#13;
&#13;
<p>Lookup (or directory) <a data-primary="lookup sharding" data-type="indexterm" id="lookup-sharding"/>sharding is custom mapping of shard key values to shards.&#13;
<a data-type="xref" href="#lookup-sharding-img">Figure 5-9</a> depicts a lookup table that maps country code top-level domains to shards.</p>&#13;
&#13;
<figure><div class="figure" id="lookup-sharding-img">&#13;
<img alt="emsp 0509" src="assets/emsp_0509.png"/>&#13;
<h6><span class="label">Figure 5-9. </span>Lookup (directory) sharding</h6>&#13;
</div></figure>&#13;
&#13;
<p>Lookup sharding is the most flexible, but it requires maintaining a lookup table.&#13;
A <em>lookup table</em> functions as a key-value map: shard key values are the keys, and database shards are the values.&#13;
You can implement a lookup table as a database table, a data structure in a durable cache, a configuration file deployed with the application, and so forth.</p>&#13;
&#13;
<p>The keys in the lookup table can be singular values (as shown in <a data-type="xref" href="#lookup-sharding-img">Figure 5-9</a>) or ranges.&#13;
If the keys are ranges, then it’s essentially range sharding, but the lookup table gives you more control of the ranges.&#13;
But that control has a cost: changing ranges means resharding—one of the common challenges.&#13;
If the keys are singular values, then lookup sharding is sensible when the number of unique shard key values is manageable.&#13;
For example, a website that stores public health statistics in the United States could shard by state and county name because there are fewer than 3,500 counties total, and they almost never change.<sup><a data-type="noteref" href="ch05.html#idm45829111349312" id="idm45829111349312-marker">1</a></sup>&#13;
Lookup sharding has an advantage that makes it a good choice for this example: it’s trivial to map all the counties with very low population to one shard, whereas this custom mapping isn’t possible with hash or range sharding.</p>&#13;
&#13;
<p>All three row access patterns (see <a data-type="xref" href="ch04.html#ap-row-access">“Row Access”</a>) work with lookup sharding, but how well they work depends on the size and complexity of the lookup table you need to create and maintain to map shard key values to database shards.&#13;
The notable mention is random access: lookup sharding allows you to map (or remap) shard key values to alleviate cross-shard queries caused by random access, which is nearly impossible with hash and range sharding.<a data-primary="sharding" data-secondary="strategies" data-startref="sharding-strategies" data-type="indexterm" id="idm45829111346736"/><a data-primary="lookup sharding" data-startref="lookup-sharding" data-type="indexterm" id="idm45829111345520"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Challenges" data-type="sect2"><div class="sect2" id="sharding-challenges">&#13;
<h2>Challenges</h2>&#13;
&#13;
<p>If <a data-primary="sharding" data-secondary="challenges" data-type="indexterm" id="sharding-challenges_index1"/>sharding were perfect, you would shard only once, and every shard would have equal data size and access.&#13;
That might be the case when you first shard, but it won’t remain the case.&#13;
The following challenges will affect your application and sharded database, so plan ahead: know how you will avoid or mitigate them.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Transactions" data-type="sect3"><div class="sect3" id="idm45829111340912">&#13;
<h3>Transactions</h3>&#13;
&#13;
<p>Transactions <a data-primary="transactions" data-type="indexterm" id="idm45829111339520"/>do not work across shards.&#13;
This is more of a blocker than a challenge because there is essentially no workaround short of implementing a two-phase commit in the application, which is perilous and far beyond the scope of this book.</p>&#13;
&#13;
<p>I strongly recommend that you avoid this blocker.&#13;
Review your application transactions (see <a data-type="xref" href="ch08.html#trx-reporting">“Reporting”</a>) and the data they access.&#13;
Then choose a shard key and strategy that work given how the transactions access data.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Joins" data-type="sect3"><div class="sect3" id="idm45829111336704">&#13;
<h3>Joins</h3>&#13;
&#13;
<p>A SQL statement <a data-primary="joins" data-type="indexterm" id="idm45829111335408"/>cannot join tables across shards.&#13;
The solution is a <em>cross-shard join</em>: the application join results from multiple queries executed on multiple shards.&#13;
It’s not a trivial solution—it might even be complex depending on the join—but it’s feasible.&#13;
Apart from complexity, the main concern is consistency: since transactions do not work across shards, the results from each shard are not a consistent view of all data.</p>&#13;
&#13;
<p>A cross-shard join is a special-purpose cross-shard query (joining the results is the special purpose); therefore, it’s susceptible to the same challenges.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Cross-shard queries" data-type="sect3"><div class="sect3" id="cross-shard-queries">&#13;
<h3>Cross-shard queries</h3>&#13;
&#13;
<p>A <em>cross-shard query</em> <a data-primary="cross-shard queries" data-type="indexterm" id="cross-shard-queries_index1"/>requires the application to access more than one shard.&#13;
The term refers to application access, not literal queries, because a single query cannot execute on more than one MySQL instance.&#13;
(A more accurate term would be <em>cross-shard application access</em>.)</p>&#13;
&#13;
<p>Cross-shard queries incur latency: delay inherent to accessing multiple MySQL instances.&#13;
Sharding is most effective when cross-shard queries are the exception, not the norm.</p>&#13;
&#13;
<p>If sharding were perfect, every application request would access <em>only one</em> shard.&#13;
That’s the goal, but don’t drive yourself crazy trying to achieve it because some applications, even when efficiently sharded, must access multiple shards to accomplish certain requests.&#13;
A peer-to-peer payment application is a good example.&#13;
Each customer is a well delineated application entity: all data related to a customer should be located on the same shard, which entails that the data is sharded by customer.&#13;
But customers interact by sending and receiving money.&#13;
Inevitably, the application will access at least two shards: one for the customer sending money, and another for the customer receiving the money.&#13;
Cross-shard queries should be minimized, but again: don’t drive yourself crazy trying to eliminate them, especially if the application logic necessitates them for certain requests.</p>&#13;
&#13;
<p>A related challenge is <em>scatter queries</em> <a data-primary="scatter queries" data-type="indexterm" id="idm45829111325504"/>(or <em>scatter-gather queries</em>): queries that require the application to access many (or all) shards.&#13;
(Again, the term refers to application access, not literal queries.)&#13;
A moderate number of cross-shard queries is inevitable and acceptable, but scatter queries are antithetical to the purpose and benefits of sharding.&#13;
Therefore, you should both prevent and eliminate scatter queries.&#13;
If you cannot—if the application requires scatter queries—then sharding is probably not the correct solution, or the access pattern needs to be changed (see <a data-type="xref" href="ch04.html#access-patterns">“Data Access Patterns”</a>).<a data-primary="cross-shard queries" data-startref="cross-shard-queries_index1" data-type="indexterm" id="idm45829111322864"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Resharding" data-type="sect3"><div class="sect3" id="resharding">&#13;
<h3>Resharding</h3>&#13;
&#13;
<p><em>Resharding</em> <a data-primary="resharding" data-type="indexterm" id="resharding_index1"/>(or a <em>shard split</em>) <a data-primary="shard split" data-type="indexterm" id="shard-split"/>divides one shard into two or more new shards.&#13;
Resharding is necessary to accommodate data growth, and it can also be used to redistribute data across shards.&#13;
If and when resharding is necessary depends on capacity planning: the estimated rate of data growth and how many shards are created initially.&#13;
For example, I’ve seen a team split a database into four shards then reshard less than two years later because data size increased much faster than estimated.&#13;
By contrast, I’ve seen a team split a database into 64 shards to accommodate more than five years of estimated data growth.&#13;
If you can afford extra shards at the beginning (when you first shard), then create enough shards for at least four years of data growth—don’t wildly overestimate, but estimate generously.</p>&#13;
&#13;
<p>This is the dark secret of sharding: sharding begets more sharding.&#13;
If you’re wondering, “Can I shard once and be done?” the answer is “probably not.”&#13;
Since your database grew to the point of needing to shard, it’s likely to keep growing and keep needing more shards—unless you become fervent about the idea that less data is better (see <a data-type="xref" href="ch03.html#less-data-is-better">“Less Data Is Better”</a>).</p>&#13;
&#13;
<p>Resharding is a challenge because it requires a data migration process from the old shard to the new shards.&#13;
Describing how to migrate data is beyond the scope of this book, but I will point out three high-level requirements:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>An initial bulk data copy from old to new shards</p>&#13;
</li>&#13;
<li>&#13;
<p>Sync changes on old shard to new shards (during and after data copy)</p>&#13;
</li>&#13;
<li>&#13;
<p>Cutover process to switch to new shards</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Deep MySQL expertise is required to migrate data safely and correctly.&#13;
Since data migrations are specific to the application and infrastructure, you won’t find any books or other resources that detail the process.&#13;
If necessary, hire a MySQL consultant to help design a process.&#13;
Also check out <a href="https://oreil.ly/7aM3I">Ghostferry</a> by the engineers at Shopify who are experts in MySQL sharding.<a data-primary="resharding" data-startref="resharding_index1" data-type="indexterm" id="idm45829111309440"/><a data-primary="shard split" data-startref="shard-split" data-type="indexterm" id="idm45829111308384"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Rebalancing" data-type="sect3"><div class="sect3" id="rebalancing">&#13;
<h3>Rebalancing</h3>&#13;
&#13;
<p><em>Rebalancing</em> <a data-primary="rebalancing (sharding)" data-type="indexterm" id="idm45829111305216"/>relocates data in order to distribute access more evenly.&#13;
Rebalancing is necessary to handle <em>hot shards</em>: shards with significantly more access than other shards.&#13;
Although the shard key and sharding strategy determine how data is distributed, the application and its users determine how data is accessed.&#13;
If one shard (a hot shard) contains all the most frequently accessed data, then performance is not evenly distributed, which defeats the purpose of scaling out.&#13;
The goal is equal access—and equal performance—on all shards.</p>&#13;
&#13;
<p>Rebalancing depends on the sharding strategy:</p>&#13;
<dl>&#13;
<dt>Hash</dt>&#13;
<dd>&#13;
<p>  It’s virtually impossible to relocate data with hash sharding <a data-primary="hash sharding" data-type="indexterm" id="idm45829111301264"/>because the hashing algorithm automatically maps data to shards.&#13;
One solution (or workaround) is to use a lookup table that contains relocated shard keys.&#13;
The application checks the lookup table first: if the shard key is present, it uses the shard indicated by the lookup table; otherwise, it uses the hashing algorithm.</p>&#13;
</dd>&#13;
<dt>Range</dt>&#13;
<dd>&#13;
<p>  Relocating data with range sharding <a data-primary="range sharding" data-type="indexterm" id="idm45829111298736"/>is possible (but nontrivial) by redefining the ranges to divide the hot shard into smaller, separate shards.&#13;
This is the same process as resharding.</p>&#13;
</dd>&#13;
<dt>Lookup</dt>&#13;
<dd>&#13;
<p>Relocating data with lookup sharding <a data-primary="lookup sharding" data-type="indexterm" id="idm45829111296464"/>is relatively easy because you control the mapping of data to shards. Therefore, you update the lookup table to remap the shard key value corresponding to the hot data.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Physically relocating the hot data requires the same (or similar) data migration process used for resharding.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Online schema changes" data-type="sect3"><div class="sect3" id="idm45829111294672">&#13;
<h3>Online schema changes</h3>&#13;
&#13;
<p>Altering a table on one database is easy, but how do you alter it on every shard?&#13;
You run the OSC on each shard, but that’s not the challenge.&#13;
The challenge is automating the OSC process to run on multiple shards, and keeping track of which shards have been altered.&#13;
For MySQL, there are no open source solutions at the time of this writing; you must develop a solution.&#13;
(However, a couple of the alternatives to MySQL in the next section have a solution.)&#13;
This is the least complex challenge of sharding, but it’s a challenge nevertheless. It cannot be overlooked because schema changes are routine.<a data-primary="sharding" data-secondary="challenges" data-startref="sharding-challenges_index1" data-type="indexterm" id="idm45829111292720"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Alternatives" data-type="sect1"><div class="sect1" id="shard-alt">&#13;
<h1>Alternatives</h1>&#13;
&#13;
<p>Sharding <a data-primary="sharding" data-secondary="alternatives to" data-type="indexterm" id="alternatives-to-sharding"/>is complex, and it’s not directly valuable to users or customers.&#13;
It’s valuable to the application to keep scaling, but it’s exacting work for engineers.&#13;
Unsurprisingly, alternative solutions are increasingly popular and robust.&#13;
However, don’t be too quick to trust your data to new technology.&#13;
MySQL is eminently reliable and deeply understood—a very mature technology—which makes it a safe and reasonable choice.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="NewSQL" data-type="sect2"><div class="sect2" id="shard-alt-newsql">&#13;
<h2>NewSQL</h2>&#13;
&#13;
<p><em>NewSQL</em> <a data-primary="NewSQL" data-type="indexterm" id="NewSQL"/>refers to a relational, <a data-primary="ACID (atomicity, consistency, isolation, and durability) properties" data-type="indexterm" id="idm45829111284384"/>ACID-compliant data store with built-in support for scaling out.&#13;
In other words, it’s a SQL database that you don’t have to shard.&#13;
If you’re thinking, “Wow! Then why use MySQL at all?” the following five points explain why MySQL—sharded or not—is still the most popular open source database in the world:</p>&#13;
<dl>&#13;
<dt><em>Maturity</em></dt>&#13;
<dd>&#13;
<p>SQL hails from the 1970s and MySQL from the 1990s.&#13;
Database maturity means two things: you can trust the data store not to lose or corrupt your data, and there is deep knowledge about every aspect of the data store.&#13;
Pay close attention to the maturity of NewSQL data stores: when was the first truly stable GA (generally available) release? What has the cadence and quality of releases been since then? What deep and authoritative knowledge is publicly available?</p>&#13;
</dd>&#13;
<dt>SQL compatibility</dt>&#13;
<dd>&#13;
<p>NewSQL data stores use SQL (it’s in the name, after all) but compatibility varies significantly.&#13;
Do not expect any NewSQL data store to be a drop-in replacement for MySQL.</p>&#13;
</dd>&#13;
<dt><em>Complex operations</em></dt>&#13;
<dd>&#13;
<p>Built-in support for scaling out is achieved with a distributed system.&#13;
That usually entails multiple different yet coordinated components.&#13;
(If MySQL is as a solo saxophonist, then NewSQL is as a five-piece band.)&#13;
If the NewSQL data store is fully managed, then perhaps its complexity doesn’t matter.&#13;
But if you have to manage it, then read its documentation to understand how it’s operated.</p>&#13;
</dd>&#13;
<dt><em>Distributed system performance</em></dt>&#13;
<dd>&#13;
<p>Recall the Universal Scalability Law (<a data-type="xref" href="ch04.html#usl">Equation 4-1</a>):</p>&#13;
<div data-type="equation">&#13;
<math>&#13;
  <mrow>&#13;
    <mi>X</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>N</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <mfrac><mrow><mi>γ</mi><mi>N</mi></mrow> <mrow><mn>1</mn><mo>+</mo><mi>α</mi><mo>(</mo><mi>N</mi><mo>-</mo><mn>1</mn><mo>)</mo><mo>+</mo><mi>β</mi><mi>N</mi><mo>(</mo><mi>N</mi><mo>-</mo><mn>1</mn><mo>)</mo></mrow></mfrac>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p><code>N</code> represents software load (concurrent requests, running processes, and forth), or hardware processors, <em>or nodes in a distributed system</em>.&#13;
If the application has queries that require a response time less than 10 milliseconds, a NewSQL data store might not work because of the latency inherent in distributed systems.&#13;
But that level of response time is not the bigger, more common problem that NewSQL solves: built-in scale out to large data size (relative to a single instance) with reasonable response time (75 ms, for example).</p>&#13;
</dd>&#13;
<dt><em>Performance characteristics</em></dt>&#13;
<dd>&#13;
<p>What accounts for the response time (performance) of a query? For MySQL, the high-level constituents are indexes, data, access patterns, and hardware—everything in the previous four chapters.&#13;
Add to those some lower-level details—like <a data-type="xref" href="ch02.html#LPR">“Leftmost Prefix Requirement”</a>, <a data-type="xref" href="ch03.html#working-set-size">“Working set size”</a>, and <a data-type="xref" href="ch04.html#mysql-does-nothing">“MySQL Does Nothing”</a>—and you understand MySQL performance and how to improve it.&#13;
A NewSQL data store will have new and different performance characteristics.&#13;
For example, indexes always provide the most and the best leverage, but they can work differently for a NewSQL data store because of how the data is stored and accessed in the distributed system.&#13;
Likewise, some access patterns that are good on MySQL are bad on NewSQL, and vice versa.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Those five points are a disclaimer: NewSQL is a promising technology that you should investigate as an alternative to sharding MySQL, but NewSQL is not an effortless drop-in replacement for MySQL.</p>&#13;
&#13;
<p>At the time of this writing, there are only two viable open source NewSQL solutions that are MySQL-compatible: <a href="https://oreil.ly/GSCc0">TiDB</a> and <a href="https://oreil.ly/wKZ2Z">CockroachDB</a>.&#13;
Both of these solutions are exceptionally new for a data store: <a data-primary="CockroachDB" data-type="indexterm" id="idm45829111255680"/>CockroachDB v1.0 GA released May 10, 2017; and <a data-primary="TiDB" data-type="indexterm" id="idm45829111254848"/>TiDB v1.0 GA released October 16, 2017.&#13;
Therefore, be cautious and diligent using TiDB and CockroachDB until at least 2027—even MySQL was 10 years old by the time it was mainstream in the early 2000s.&#13;
If you use TiDB or CockroachDB, please write about what you learn and, if possible, contribute to these open source projects.<a data-primary="NewSQL" data-startref="NewSQL" data-type="indexterm" id="idm45829111253696"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Middleware" data-type="sect2"><div class="sect2" id="shard-alt-middleware">&#13;
<h2>Middleware</h2>&#13;
&#13;
<p>A middleware <a data-primary="middleware (sharding)" data-type="indexterm" id="middleware"/>solution works between the application and the MySQL shards.&#13;
It attempts to hide or abstract the details of sharding, or at least make sharding easier.&#13;
When direct, manual sharding is too difficult, and NewSQL is infeasible, a middleware solution could help bridge the gap.&#13;
The two leading open source solutions are <a href="https://oreil.ly/6AvRY">Vitess</a> and <a href="https://oreil.ly/5iTkH">ProxySQL</a>, and they are entirely different.&#13;
ProxySQL <em>can</em> shard and Vitess <em>is</em> sharding.</p>&#13;
&#13;
<p>ProxySQL, <a data-primary="ProxySQL" data-type="indexterm" id="idm45829111246560"/>as its name suggests, is a proxy that supports sharding by several mechanisms.&#13;
To get an idea how it works, read <a href="https://oreil.ly/N0eYa">“Sharding in ProxySQL”</a> and <a href="https://oreil.ly/KDvjE">“MySQL Sharding with ProxySQL”</a>.&#13;
Using a proxy in front of MySQL is similar to the classic Vim versus Emacs rift minus all the vitriol: engineers do a lot of great work with both editors; it’s just a matter of personal preference.&#13;
Likewise, companies are successful with and without a proxy; it’s just a matter of personal preference.</p>&#13;
&#13;
<p>Vitess <a data-primary="Vitess" data-type="indexterm" id="idm45829111243472"/>is a purpose-built MySQL sharding solution.&#13;
Since sharding is complex, Vitess is not without its own complexity, but its greatest advantage is that it addresses all challenges, especially resharding and rebalancing.&#13;
Moreover, Vitess was created by MySQL experts at YouTube who deeply understand MySQL at massive scale.</p>&#13;
&#13;
<p>Before you shard, be sure to evaluate ProxySQL and Vitess.&#13;
Any middleware solution entails additional infrastructure to learn and maintain, but the benefits can outweigh the costs because manually sharding MySQL also costs significant engineering time, effort, and serenity.<a data-primary="middleware (sharding)" data-startref="middleware" data-type="indexterm" id="idm45829111241600"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Microservices" data-type="sect2"><div class="sect2" id="shard-alt-microservices">&#13;
<h2>Microservices</h2>&#13;
&#13;
<p>Sharding <a data-primary="microservices" data-type="indexterm" id="idm45829111238928"/>focuses on one application (or service) and its data, especially data size and access.&#13;
But sometimes the real problem is the application: it has too much data or access because it serves too many purposes or business functions.&#13;
Avoiding monolithic applications is standard engineering design and practice, but that doesn’t mean it’s always achieved.&#13;
Before you shard, review the application design and its data to ensure that parts cannot be factored out into a separate microservice.&#13;
This is a lot easier than sharding because the new microservice and its database are completely independent—no shard key or strategy required.&#13;
It might also be the case that the new microservice has completely different access patterns (see <a data-type="xref" href="ch04.html#access-patterns">“Data Access Patterns”</a>) that allow it to use less hardware while storing more data—or perhaps the new microservice doesn’t need a relational data store.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Don’t Use MySQL" data-type="sect2"><div class="sect2" id="shard-alt-dont-use-mysql">&#13;
<h2>Don’t Use MySQL</h2>&#13;
&#13;
<p>Similar to <a data-type="xref" href="ch04.html#dont-use-mysql">“Don’t Use MySQL”</a>, a completely honest assessment of the alternatives to sharding MySQL must conclude with: don’t use MySQL if another data store or technology works better.&#13;
If your path is designing a new application for sharding, then definitely evaluate other solutions.&#13;
Sharding MySQL is a solved problem, but it’s never a quick or easy solution.&#13;
If your path is migrating an existing application to sharding, then you should still consider the trade-offs of sharding MySQL against migrating to another solution.&#13;
That sounds burdensome at scale—and it is—but companies do it all the time, and so can you.<a data-primary="sharding" data-secondary="alternatives to" data-startref="alternatives-to-sharding" data-type="indexterm" id="idm45829111233056"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="ch05-summary">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>This chapter introduced the basic mechanics of sharding MySQL to achieve MySQL at scale.&#13;
The essential takeaway points are:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>MySQL scales out by sharding.</p>&#13;
</li>&#13;
<li>&#13;
<p>Sharding divides one database into many databases.</p>&#13;
</li>&#13;
<li>&#13;
<p>A single database does not scale primarily because the combination of queries, data, and access patterns—the application workload—significantly outpace the speed and capacity of single-server hardware.</p>&#13;
</li>&#13;
<li>&#13;
<p>It’s significantly easier to manage many small databases (shards) than one huge database—pebbles, not boulders.</p>&#13;
</li>&#13;
<li>&#13;
<p>Data is sharded (divided) by a shard key, which you must choose carefully.</p>&#13;
</li>&#13;
<li>&#13;
<p>The shard key is used with a sharding strategy to map data (by shard key) to shards.</p>&#13;
</li>&#13;
<li>&#13;
<p>The most common sharding strategies are hash (a hashing algorithm), range, and lookup (directory).</p>&#13;
</li>&#13;
<li>&#13;
<p>Sharding has several challenges that must be addressed.</p>&#13;
</li>&#13;
<li>&#13;
<p>There are alternatives to sharding that you should evaluate.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The next chapter looks into MySQL server metrics.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Practice: Four-Year Fit" data-type="sect1"><div class="sect1" id="ch05-ai">&#13;
<h1>Practice: Four-Year Fit</h1>&#13;
&#13;
<p>The <a data-primary="sharding" data-secondary="four-year fit" data-type="indexterm" id="four-year-fit"/>goal <a data-primary="four-year fit" data-primary-sortas="fouryear fit" data-type="indexterm" id="four-year-fit-ch5"/>of this practice is to determine the four-year fit of the data size.&#13;
From <a data-type="xref" href="#sharding-intro">“Sharding: A Brief Introduction”</a>, the four-year fit is an estimate of data size or access in four years applied to the capacity of your hardware <em>today</em>.&#13;
Sharding might not be required if the estimated data size or access fits (figuratively) within your hardware capacity today.&#13;
(Refer back to <a data-type="xref" href="#scale-up-app-workload">“Application Workload”</a> for the discussion of hardware fit.)</p>&#13;
&#13;
<p>You will need historical data sizes to complete this practice.&#13;
If you’re not already measuring and recording data sizes, then jump ahead to <a data-type="xref" href="ch06.html#metrics-data-size">“Data Size”</a> to learn how.</p>&#13;
&#13;
<p>The simplest possible calculation is sufficient.&#13;
If, for example, a database has historically increased by 10 GB every month, then the database will be 12 months × 4 years × 10 GB/month = 480 GB <em>larger</em> in four years—if no data is deleted or archived (see <a data-type="xref" href="ch03.html#delete-or-archive">“Delete or Archive Data”</a>).&#13;
If the database is 100 GB today, then 580 GB in four years fits: you don’t need to shard any time soon (four-year fit for access load notwithstanding) because MySQL on hardware <em>today</em> can easily handle 580 GB of data.</p>&#13;
&#13;
<p>If your four-year fit for data size indicates that you might need to shard, take it seriously and dive deeper to determine for sure: is the database on a steady path to becoming too large for a single MySQL instance?&#13;
If yes, then <em>shard early</em> because sharding is essentially a complex data migration process; therefore, the less data, the easier the process.&#13;
If not, then congratulations: ensuring that the system will continue to scale for years to come is an expert practice in all fields of<a data-primary="four-year fit" data-primary-sortas="fouryear fit" data-startref="four-year-fit-ch5" data-type="indexterm" id="idm45829111207520"/> engineering.<a data-primary="sharding" data-secondary="four-year fit" data-startref="four-year-fit" data-type="indexterm" id="idm45829111206144"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45829111349312"><sup><a href="ch05.html#idm45829111349312-marker">1</a></sup> County names are unique only within a state, which is why the state name is required.</p></div></div></section></body></html>