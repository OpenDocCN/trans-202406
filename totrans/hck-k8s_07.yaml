- en: Chapter 7\. Hard Multitenancy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 严格多租户
- en: Sharing a Kubernetes cluster securely is hard. By default, Kubernetes is not
    configured to host multiple tenants, and work is needed to make it secure. “Secure”
    means it should be divided fairly between isolated tenants, who shouldn’t be able
    to see each other and shouldn’t be able to break shared resources for anybody
    else.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 安全地共享 Kubernetes 集群是困难的。默认情况下，Kubernetes 没有配置为托管多个租户，并且需要进行工作以使其安全。 “安全”意味着应该在隔离的租户之间公平分割，并且他们不应该能够看到彼此，也不应该能够破坏共享资源。
- en: Each tenant may run their own choice of workloads, confined to their own set
    of namespaces. The combination of security settings in the namespace configuration
    and the cluster’s access to external and cloud services defines how securely tenants
    are separated.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 每个租户可以运行他们自己选择的工作负载，限制在他们自己的一组命名空间中。命名空间配置中的安全设置与集群对外部和云服务的访问组合定义了租户如何安全分离。
- en: Each tenant in a cluster can be considered friendly or hostile, and cluster
    admins deploy appropriate controls to keep other tenants and the cluster components
    free from harm. The level of these controls is set for the type of tenants expected
    by the system’s threat model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中的每个租户都可以被视为友好或敌对，并且集群管理员部署适当的控制措施，以确保其他租户和集群组件免受伤害。这些控制措施的级别是根据系统的威胁模型预期的租户类型设置的。
- en: Note
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: A tenant is the cluster’s customer. They may be a team, test or production environment,
    a hosted tool, or any logical grouping of resources.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一个租户是集群的客户。他们可以是一个团队，测试或生产环境，托管工具，或者任何资源的逻辑分组。
- en: In this chapter you will sail the shark-infested waters of Kubernetes multitenancy
    and their namespaced “security boundaries.” The control plane’s lockdown techniques
    are inspected for signs of fraying, we compare the data classification of workloads
    and their cargo, and look at how to monitor our resources.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将航行在 Kubernetes 多租户的鲨鱼密布的水域中，并且它们的命名空间“安全边界”。我们检查了控制平面的锁定技术，比较了工作负载及其载货的数据分类，并探讨了如何监控我们的资源。
- en: Defaults
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 默认值
- en: Namespaces exist to group resources, and Kubernetes doesn’t have an inherent
    namespace tenancy model. The namespaced tenancy concept only works for interactions
    within the Kubernetes API, not the entire cluster.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间存在于组资源的群组，并且 Kubernetes 没有固有的命名空间租户模型。命名空间租户概念仅适用于 Kubernetes API 内部的交互，而不适用于整个集群。
- en: By default, cross-tenant visibility is not protected by networking, DNS, and
    some namespaced policy unless the cluster is hardened with specific configuration
    that we’ll examine in this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，跨租户可见性未受网络、DNS 和一些命名空间策略的保护，除非集群通过特定配置进行了硬化，我们将在本章中详细讨论。
- en: A careful defender will segregate a tenant application into multiple namespaces
    to more clearly delineate the RBAC permissions each service account has and to
    make it easier to reason and deploy network policy, quotas and limits, and other
    security tooling. You should only allow one tenant to use each namespace because
    of those namespace-bound policies and resources.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一个谨慎的防御者将租户应用程序分隔成多个命名空间，以更清晰地划分每个服务帐户的 RBAC 权限，并使理解和部署网络策略、配额和限制以及其他安全工具变得更容易。由于命名空间绑定的策略和资源，您应只允许一个租户使用每个命名空间。
- en: Tip
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: A tenant could be a single application, a complex application divided in multiple
    namespaces, a test environment required for its development, a project, or any
    trust boundary.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个租户可以是一个单独的应用程序，一个被分成多个命名空间的复杂应用程序，其开发所需的测试环境，一个项目，或者任何信任边界。
- en: Threat Model
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 威胁模型
- en: 'The [Kubernetes multitenancy working group](https://oreil.ly/cHmPD) considers
    two categories of multitenancy:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kubernetes 多租户工作组](https://oreil.ly/cHmPD)考虑了两类多租户：'
- en: '*Soft multitenancy* is easier for tenants to use and allows greater configuration'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*软多租户*更易于租户使用，并允许更大的配置。'
- en: '*Hard multitenancy* aims to be “secure by default,” with security settings
    preconfigured and immutable'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*严格多租户*旨在“默认情况下安全”，具有预配置和不可变的安全设置。'
- en: Soft multitenancy is a friendly, more permissive security model. It assumes
    tenants are partially trusted and have the cluster’s best interest at heart, and
    it permits them to configure parts of their own namespaces.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 软多租户是一种友好的、更宽松的安全模型。它假设租户部分受信任，并关心集群的最佳利益，并允许他们配置自己命名空间的部分。
- en: 'Hard multitenancy is locked down and assumes tenants are hostile. Multiple
    controls reduce opportunity for attackers: workload isolation, admission control,
    network policy, security monitoring, and intrusion detection systems (IDS) are
    configured in the platform, and tenants only perform a restricted set of operations.
    The trade-off for such a restrictive configuration is tenant usability.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 硬多租户已锁定，并假设租户是敌对的。多个控制措施降低了攻击者的机会：工作负载隔离、入场控制、网络策略、安全监控和入侵检测系统（IDS）在平台上配置，租户只执行受限的操作集。这种严格配置的代价是租户可用性的牺牲。
- en: Our threat model is scoped for hard multitenancy, to strengthen every possible
    defense against our arch nemesis, the scourge of the digital seas, Dread Pirate
    Captain Hashjack.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的威胁模型专注于强硬的多租户，以加强对我们的宿敌、数字海洋之恶棍海盗哈希杰克船长的每一个可能防御。
- en: Namespaced Resources
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命名空间资源
- en: 'Before we get into hard and soft multitenancy, let’s have a look at how we
    can separate resources: namespaces and nodes.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入讨论硬和软多租户之前，让我们看看如何分离资源：命名空间和节点。
- en: Tip
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Networking doesn’t adhere the idea of namespacing: we can apply policy to shape
    it, but fundamentally it’s a flat subnet.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 网络不遵循命名空间的概念：我们可以应用策略来塑造它，但从根本上说它是一个平面子网。
- en: Visibility of your Kubernetes RBAC resources (covered in [Chapter 8](ch08.xhtml#ch-policy))
    is either scoped to a namespace such as pods or service accounts or to the whole
    cluster like nodes or persistent volumes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您的 Kubernetes RBAC 资源的可见性（在 [第 8 章](ch08.xhtml#ch-policy) 中涵盖）要么限定于诸如 pods 或服务帐户等命名空间，要么涵盖整个集群，例如节点或持久卷。
- en: Spreading a single tenant across multiple namespaces reduces the impact of stolen
    or compromised credentials and increases the resistance of the system to compromise,
    at the cost of some operational complexity. Your teams should be able to automate
    their jobs, which will result in a secure and fast-to-patch system.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 将单个租户跨多个命名空间进行分散可以降低被窃取或被破坏的凭证的影响，并增加系统对抗妥协的抵抗力，但会增加一些操作复杂性的成本。您的团队应该能够自动化其工作，这将导致一个安全且快速补丁的系统。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: GitOps operators may be deployed in a dedicated per-operator namespace. For
    example, an application may be deployed into the namespaces `myapp-front-end`,
    `myapp-middleware`, and `myapp-data`. A privileged operator that deploys and modifies
    the application in those namespaces may be deployed into a `myapp-gitops` namespace,
    so compromise of any namespaces under its control (e.g., the `myapp-front-end`)
    doesn’t directly or indirectly lead to the compromise of the privileged operator.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: GitOps 运算符可能部署在专用的每个运算符命名空间中。例如，一个应用程序可能部署在命名空间 `myapp-front-end`、`myapp-middleware`
    和 `myapp-data` 中。一个特权运算符可以部署并修改这些命名空间中的应用程序，例如 `myapp-gitops` 命名空间，因此任何受其控制的命名空间（例如
    `myapp-front-end`）的妥协都不会直接或间接导致特权运算符的妥协。
- en: GitOps deploys whatever is committed to the repository it is monitoring, so
    control of production assets extends to the the source repository. For more on
    securing Git, see [“Hardening Git for GitOps”](https://oreil.ly/FRDzv).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GitOps 部署了提交到其监控的存储库的任何内容，因此对生产资产的控制延伸到了源代码存储库。有关更多关于保护 Git 的信息，请参阅 [“为 GitOps
    加固 Git”](https://oreil.ly/FRDzv)。
- en: 'In the Kubernetes RBAC model, namespaces are cluster-scoped and so suffer coarse
    cluster-level RBAC: if a user in a tenant namespace has permission to view their
    own namespace, they can also view all other namespaces on the cluster.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 的 RBAC 模型中，命名空间是集群范围的，因此遭受粗糙的集群级 RBAC：如果租户命名空间中的用户有权限查看自己的命名空间，则他们也可以查看集群上的所有其他命名空间。
- en: Tip
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: OpenShift introduces the “project” concept, which is a namespace with additional
    annotations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: OpenShift 引入了“项目”概念，它是带有额外注释的命名空间。
- en: 'The API server can tell you which of its resources are not namespaced with
    this query (output edited to fit):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器可以通过此查询告诉您哪些资源不在命名空间中（输出已编辑以适应）：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Kubernetes’ shared DNS model also exposes other namespaces and services and
    is an example of the difficulties of hard multitenancy. CoreDNS’s firewall plug-in
    can be configured to “prevent Pods in certain Namespaces from looking up Services
    in other Namespaces.” IP and DNS addresses are useful to an attacker who surveys
    the visible horizon for their next target.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的共享 DNS 模型还暴露了其他命名空间和服务，并且是硬多租户困难的一个例子。CoreDNS 的防火墙插件可以配置为“防止某些命名空间中的
    Pod 查找其他命名空间中的服务”。IP 和 DNS 地址对于调查其下一个目标的可见地平线的攻击者是有用的。
- en: Node Pools
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节点池
- en: The pods in a namespace can span multiple nodes, as [Figure 7-1](#multitenancy-shared-namespace)
    shows. If an attacker can escape from a container onto the underlying node, they
    may be able to jump between namespaces, and possibly even nodes, of a cluster.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间中的Pod可以跨越多个节点，如[图 7-1](#multitenancy-shared-namespace)所示。如果攻击者能够从容器逃逸到底层节点，则可能能够在集群的命名空间甚至节点之间跳转。
- en: '![multitenancy-shared-namespace](Images/haku_0701.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![多租户共享命名空间](Images/haku_0701.png)'
- en: Figure 7-1\. A namespace often spans multiple nodes, however a single instance
    of a pod only ever runs on one node
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-1\. 一个命名空间通常跨越多个节点，但是一个Pod实例只会在一个节点上运行。
- en: Node pools are groups of nodes with the same configuration, and that can scale
    independently of other node pools. They can be used to keep workloads of the same
    risk, or classification, on the same nodes. For example, web-facing applications
    should be separated from internal APIs and middleware workloads that are not accessible
    to internet traffic, and the control plane should be on a dedicated pool. This
    means in the event of container breakout, the attacker can only access resources
    on those nodes, and not more sensitive workloads or Secrets, and traversing between
    node pools is not a simple escalation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 节点池是具有相同配置的节点组，并且可以独立于其他节点池进行扩展。它们可以用于在相同节点上保持相同风险或分类的工作负载。例如，面向Web的应用程序应与对Internet流量不可访问的内部API和中间件工作负载分开，并且控制平面应在专用池中。这意味着在容器越界事件中，攻击者只能访问这些节点上的资源，而不能访问更敏感的工作负载或Secrets，且在节点池之间移动不是一个简单的升级过程。
- en: 'You can assign workloads to node pools with labels and node selectors (output
    edited):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用标签和节点选择器将工作负载分配到节点池（输出已编辑）：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s examine a deployment to see its `NodeSelector`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一个部署，看看它的`NodeSelector`：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](Images/1.png)](#comarker11)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#comarker11)'
- en: See the labels applied to each node.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 查看应用于每个节点的标签。
- en: '[![2](Images/2.png)](#comarker22)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#comarker22)'
- en: Set a node’s class.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 设置节点的类别。
- en: '[![3](Images/3.png)](#comarker33)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#comarker33)'
- en: One or more key-value pairs targeting a Node’s labels, to direct the scheduler.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个或多个针对节点标签的键值对，以指导调度程序。
- en: Warning
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Later in this chapter we look at how to prevent a hostile `kubelet` relabeling
    itself, by using well-known labels from the [`NodeRestriction`](https://oreil.ly/VOjYB)
    admission plug-in.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 本章后面将讨论如何通过使用[`NodeRestriction`](https://oreil.ly/VOjYB)准入插件中的众所周知标签，防止敌对`kubelet`重新标记自身。
- en: 'The [`PodNodeSelector`](https://oreil.ly/TRNUq) admission controller can limit
    which nodes can be targeted by selectors in a namespace, to prevent hostile tenants
    scheduling on other’s namespace-restricted nodes (edited to fit):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[`PodNodeSelector`](https://oreil.ly/TRNUq) 准入控制器可以限制命名空间中选择器可以针对哪些节点进行目标选择，以防止敌对租户在其他的命名空间受限节点上调度（编辑以适应）：'
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'For hard multitenant systems these values should be set by an admission controller
    based upon a property of the workload: its labels, who or where it was deployed
    from, or the image name. Or it may be that only an allowlist of fully qualified
    images with their digests may ever be deployed to high-risk or web-facing nodes.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于硬多租户系统，这些值应该由准入控制器根据工作负载的属性设置：它们的标签、部署来源或镜像名称。或者可能只允许部署到高风险或面向网络的节点的完全合格镜像白名单。
- en: Note
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'A cluster’s security boundary slides based upon its threat model and current
    scope, as [Mark Manning](https://oreil.ly/5YvCA) demonstrates in [“Command and
    KubeCTL: Real-World Kubernetes Security for Pentesters”](https://oreil.ly/viBnl).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一个集群的安全边界根据其威胁模型和当前范围进行调整，正如[Mark Manning](https://oreil.ly/5YvCA)在[“命令和KubeCTL：渗透测试人员的实际Kubernetes安全性”](https://oreil.ly/viBnl)中所示。
- en: A Kubernetes system’s prime directive is to keep pods running. A pod’s tolerance
    to infrastructure failure relies upon an effective distribution of workloads across
    hardware. This availability-centric style rightly prioritises utilization above
    security isolation. Security is more expensive and requires dedicated nodes for
    each isolated workload classification.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes系统的主要指导原则是保持Pod运行。一个Pod对基础设施故障的容忍性依赖于工作负载在硬件上的有效分布。这种以可用性为中心的风格正确地优先考虑了利用率而不是安全隔离。安全性成本更高，需要为每个隔离的工作负载分类专用节点。
- en: Node Taints
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节点污点
- en: 'By default, namespaces share all nodes in a cluster. As illustrated here, a
    taint can be used to prevent the scheduler from placing pods on certain nodes
    in Kubernetes’ default configuration:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，命名空间在集群中共享所有节点。如图所示，可以使用污点来防止调度程序在Kubernetes的默认配置中将Pod放置在某些节点上：
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This works because a self-hosted control plane runs using filesystem-hosted
    static pod manifests in the `kubelet`’s `staticPodPath`, defaulted to */etc/kubernetes/manifests*,
    which ignore these taints.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为自托管的控制平面使用文件系统托管的静态 Pod 清单在 `kubelet` 的 `staticPodPath` 中运行，默认为 */etc/kubernetes/manifests*，它会忽略这些污点。
- en: Pods can be prevented from co-scheduling on the same node with advanced scheduler
    hints, which isolate them on their own compute hardware (a virtual or bare-metal
    machine).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过高级调度提示，可以防止 Pod 在同一节点上共同调度，将它们隔离在自己的计算硬件上（虚拟机或裸金属机器）。
- en: This level of isolation is too expensive for most (it prevents “bin packing”
    workload by reducing the number of possible nodes for each workloads, and the
    under-utilization is likely to lead to unused compute), and so provides a consistent
    mechanism to traverse namespaces on default Kubernetes configurations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，这种隔离级别对于大多数人来说太昂贵了（它通过减少每个工作负载的可能节点数量来阻止“装箱”工作负载，而且未充分利用可能导致未使用的计算资源），因此在默认的
    Kubernetes 配置上提供了一种一致的遍历命名空间的机制。
- en: Note
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: An attacker who can compromise a `kubelet` can remain in-cluster in many ingenious
    ways, as detailed in the talk [“Advanced Persistence Threats”](https://oreil.ly/1GvRP)
    by [Brad Geesaman](https://oreil.ly/gEIBb) and [Ian Coldwater](https://oreil.ly/8nz0p).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个能够妥协 `kubelet` 的攻击者可以以许多巧妙的方式留在集群中，详细信息请参考 [Brad Geesaman](https://oreil.ly/gEIBb)
    和 [Ian Coldwater](https://oreil.ly/8nz0p) 的演讲 [“高级持久性威胁”](https://oreil.ly/1GvRP)。
- en: Admission control prevents wide-open avenues of exploitation such as sharing
    host namespaces. You should mitigate potential container breakout to the host
    with secure pod configuration, image scanning, supply chain verification, admission
    control and policy for incoming pods and operators, and intrusion detection for
    when all else fails.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 准入控制可以防止像共享主机命名空间这样的广泛开放的利用途径。您应该通过安全的 Pod 配置、镜像扫描、供应链验证、入站 Pod 和操作员的准入控制和策略，以及入侵检测来减轻潜在的容器逃逸到主机的风险，当其他方法失败时。
- en: If Captain Hashjack can’t easily break out of the container through vulnerable
    container runtime or kernel versions, they’ll pretty quickly start attacking the
    network. They may choose to attack other tenants on the cluster or other network-accessible
    services like the control plane and API server, compute nodes, cluster-external
    datastores, or anything else accessible on the same network segment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Hashjack 船长无法通过容器运行时或内核版本中的漏洞轻松逃逸出容器，他们很快就会开始攻击网络。他们可能选择攻击集群中的其他租户或其他网络可访问的服务，如控制平面和
    API 服务器、计算节点、集群外部数据存储或同一网络段上可访问的任何其他内容。
- en: Attackers look for the next weak link in the chain, or any overprivileged pod,
    so enforcing secure “hard” multitenancy between tenants hardens the cluster to
    this escalation. To give us a comparison, let’s first look at the goals of “soft”
    multitenancy.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者寻找链条中的下一个薄弱环节，或者任何过度特权的 Pod，因此在租户之间强制执行安全的“硬”多租户模式可以使集群对此类升级变得更加坚固。为了进行比较，让我们首先看一下“软”多租户的目标。
- en: Soft Multitenancy
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软多租户
- en: You should use a soft multitenancy model to prevent avoidable accidents resulting
    from overprivileged tenants. It is much easier to build and run than hard multitenancy,
    which we will come to next, because its threat model doesn’t consider motivated
    threat actors like Dread Pirate Hashjack.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该使用软多租户模型来防止由于过度特权的租户导致的可避免事故。与接下来要介绍的硬多租户相比，软多租户的构建和运行要容易得多，因为其威胁模型不考虑像 Dread
    Pirate Hashjack 这样的有动机的威胁行为者。
- en: Soft multitenancy is often a “tenant per namespace” model. Across the cluster,
    tenants are likely to have the best interests of the cluster or administrators
    at heart. Hostile tenants, however, can probably break out of this type of cluster.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 软多租户通常是“每个命名空间一个租户”的模型。在整个集群中，租户可能会把集群或管理员的最佳利益放在心上。然而，敌对的租户可能会打破这种类型的集群。
- en: Examples of tenants include different projects in a team, or teams in a company,
    that are enforced by RBAC roles and bindings and grouped by namespaces. Resources
    in the namespace are limited, so tenants can’t exhaust a cluster’s resources.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 租户的示例包括团队中的不同项目，或者公司中的团队，这些租户通过 RBAC 角色和绑定进行强制执行，并通过命名空间进行分组。命名空间中的资源是有限的，因此租户无法耗尽集群的资源。
- en: 'Namespaces are tools used to build security boundaries in your cluster, but
    they are not an enforcement point. They scope many security and policy features:
    admission control webhooks, RBAC and access control, network policy, resource
    quotas and LimitRanges, Pod Security Policy, pod anti-affinity, dedicated nodes
    with taints and tolerations, and more. So they are an abstraction grouping of
    other mechanisms and resources: your threat models should consider these trust
    boundaries as walls on the defensive landscape.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间是用于在集群中建立安全边界的工具，但它们不是强制执行点。它们涵盖许多安全和策略功能：准入控制Web钩子、RBAC和访问控制、网络策略、资源配额和限制范围、Pod安全策略、Pod反亲和性、带有污点和容忍度的专用节点，以及更多。因此，它们是其他机制和资源的抽象组合：您的威胁模型应将这些信任边界视为防御景观上的墙壁。
- en: Under the lenient soft multitenancy model, namespace isolation techniques may
    not be strictly enforced, permitting tenants visibility of each other’s DNS records,
    and possibly permitting network routing between them if network policy is absent.
    DNS enumeration and requests for malicious domains should be monitored. For Captain
    Hashjack, quietly scanning a network may be a more effective way to evade detection,
    although CNI and IDS tools should detect this anomalous behavior.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在宽松的软多租户模型下，命名空间隔离技术可能不严格执行，允许租户看到彼此的DNS记录，并且如果没有网络策略，则可能允许网络路由之间的通信。应监控DNS枚举和恶意域名请求。对于Captain
    Hashjack来说，静默扫描网络可能是逃避检测的更有效方式，尽管CNI和IDS工具应该能够检测到这种异常行为。
- en: Network policy is strongly recommended for even soft multitenant deployments.
    Kubernetes nodes require a flat network space between their `kubelet`s, and the
    `kubelet`’s CNI plug-in for pod networking is responsible for enforcing tenant
    namespace separation at OSI layers 2 (ARP), 3/4 (IP addresses and TCP/UDP ports),
    and 7 (application, and TLS/x509). Network traffic is encrypted to off-cluster
    snoopers by network plug-ins like Cilium, Weave, or Calico that route pod traffic
    over virtual overlay networks, or VPN tunnels for all traffic between nodes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是软多租户部署，强烈推荐使用网络策略。Kubernetes节点需要它们的`kubelet`之间的平面网络空间，并且`kubelet`的CNI插件用于在OSI第2层（ARP）、第3/4层（IP地址和TCP/UDP端口）以及第7层（应用程序和TLS/x509）强制执行租户命名空间分离。像Cilium、Weave或Calico这样的网络插件通过虚拟覆盖网络或VPN隧道将Pod流量路由到所有节点之间的所有流量，以对抗集群外窥探者进行加密。
- en: The CNI protects data in transit, but must trust any workload Kubernetes has
    permitted to run. As malicious workloads are inside a CNI’s trust boundary, they
    are served trusted traffic. Your tolerance to the impact of that workload going
    rogue in its surrounding environment should guide your level of security controls.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: CNI保护传输中的数据，但必须信任Kubernetes允许运行的任何工作负载。由于恶意工作负载位于CNI的信任边界内，它们会接收到受信任的流量。您对该工作负载在其周围环境中变得不良的容忍度应指导您的安全控制级别。
- en: Note
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We go into depth on network policies in [Chapter 5](ch05.xhtml#ch-networking).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第5章](ch05.xhtml#ch-networking)中深入讨论网络策略。
- en: Hard Multitenancy
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强制多租户
- en: In this model, cluster tenants don’t trust each other, and namespace configurations
    are “secure by default.” Security guardrails in CI/CD pipelines and admission
    control enforce policy. This level of separation is required by sensitive and
    private workloads across industry and state sectors, public compute services,
    and regulatory and accrediting bodies.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种模型中，集群租户彼此不信任，并且命名空间配置默认“安全”。CI/CD管道中的安全保护栏和准入控制强制执行策略。这种分离水平是跨行业和国家部门、公共计算服务以及监管和认证机构所要求的敏感和私密工作负载。
- en: Hostile Tenants
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 敌对租户
- en: It helps to threat model all workloads in a hard multitenant system as aggressively
    hostile. This explores more branches of an attack tree to inform an optimal balance
    of cluster security controls, which will help limit a workload’s potentially permissive
    cloud or cluster authorizations.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在强制多租户系统中，将所有工作负载视为极具敌意可能会有所帮助。这探索了攻击树的更多分支，以制定最佳的集群安全控制平衡，这将有助于限制工作负载可能存在的宽松云或集群授权。
- en: It also covers unknown potential events, such as a failure in the RBAC subsystem
    CVE-2019-11247 that leaked access to cluster-scoped resource for non–cluster-scoped
    roles, CVE-2018-1002105 and CVE-2019-1002100, which enabled API server DOS, or
    CVE-2018-1002105, a partially exploitable API authentication bypass (covered later
    in the chapter).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 它还涵盖了一些未知的潜在事件，例如RBAC子系统CVE-2019-11247中的失败，该漏洞泄露了非集群范围角色对集群范围资源的访问权限，CVE-2018-1002105和CVE-2019-1002100，它们导致API服务器DOS，或CVE-2018-1002105，部分可利用的API身份验证绕过（在本章后面有详细介绍）。
- en: Note
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In 2019, all Kubernetes API servers were at grave risk of being honked. [Rory
    McCune](https://oreil.ly/Kf8cP) discovered v1.13.7 was vulnerable to the Billion
    Laughs YAML deserialization attack, and [Brad Geesaman](https://oreil.ly/KaOWm)
    weaponized it with [sig-honk](https://oreil.ly/dB7CX). For a malicious tenant
    with API server visibility, this would be trivial to exploit.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2019 年，所有 Kubernetes API 服务器都面临严重的风险，可能受到攻击。[Rory McCune](https://oreil.ly/Kf8cP)
    发现 v1.13.7 存在对 Billion Laughs YAML 反序列化攻击的漏洞，而 [Brad Geesaman](https://oreil.ly/KaOWm)
    利用 [sig-honk](https://oreil.ly/dB7CX) 武器化了该漏洞。对于具有 API 服务器可见性的恶意租户来说，这将是一个简单的利用方式。
- en: Admission controllers are executed by the API server after authentication and
    authorization, and validate the inbound API server request with “deep payload
    inspection.” This additional step is more powerful than traditional RESTful API
    architectures as it inspects the content of the request with specific policies,
    which can catch misconfigurations and malicious YAML.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 入场控制器在认证和授权后由 API 服务器执行，并通过“深度负载检查”验证传入的 API 服务器请求。这一额外步骤比传统的 RESTful API 架构更为强大，因为它使用特定策略检查请求的内容，可以捕获配置错误和恶意
    YAML。
- en: Hard multitenant systems may use advanced sandboxes to isolate pods in a different
    way to `runc` containers and increase their resistance to zero-day attacks.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂的多租户系统可能会使用高级沙箱来以不同方式隔离 Pod，以增强对零日攻击的抵抗力。
- en: Note
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Advanced sandboxing techniques are covered in more depth in [Chapter 3](ch03.xhtml#ch-container-runtime-isolation).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 更深入地涵盖了高级沙箱技术的内容在 [第三章](ch03.xhtml#ch-container-runtime-isolation) 中。
- en: Sandboxing and Policy
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 沙箱和策略
- en: Sandboxes such as gVisor, Firecracker, and Kata Containers ingeniously combine
    KVM with namespaces and LSMs to further abstract workloads from high-risk interfaces
    and trust boundaries like the kernel.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如 gVisor、Firecracker 和 Kata Containers 的沙箱巧妙地将 KVM 与命名空间和 LSM 结合起来，进一步将工作负载从高风险接口和内核等信任边界中抽象出来。
- en: '![captain](Images/haku_0000.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![captain](Images/haku_0000.png)'
- en: These sandboxes are designed to resist vulnerabilities in their system call,
    filesystem, and network subsystems. As with every project, they have had CVEs,
    but they are well maintained and quick to fix. Their threat models are well documented
    and architectures theoretically solid, but every security abstraction comes at
    the cost of system simplicity, workload debuggability, and filesystem and network
    performance.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这些沙箱的设计旨在抵御其系统调用、文件系统和网络子系统中的漏洞。与每个项目一样，它们有 CVE，但它们得到了良好的维护并且迅速修复。它们的威胁模型有着良好的文档记录，理论上的架构也是坚实的，但每一种安全抽象都是以系统简易性、工作负载调试能力、文件系统和网络性能为代价的。
- en: Sandboxing a pod or namespace is weighted against the additional resources required.
    Captain Hashjack’s potential cryptolocking ransom should be valued in the equation,
    against the sandboxing protect from unknown kernel and driver vulnerabilities.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Pod 或命名空间沙箱化权衡加在所需的额外资源上。Hashjack 队长的潜在加密勒索应该被计入方程式，以对抗沙箱保护未知的内核和驱动程序漏洞。
- en: Note
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'No sandbox is inescapable, and sandboxing weighs the likelihood of simultaneous
    exploitable bugs being found in both the sandbox and the underlying Linux kernel.
    This is a reasonable approach and has analogies to browser sandboxing: Chromium
    uses the same namespaces, `cgroups`, and `seccomp` as containers do. Chromium
    breakouts have been demonstrated at Pwn2Own and the Tianfu Cup often, but the
    risk window for exploitation is a few days (very roughly) every 2–5 years.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 沙箱并非万无一失，沙箱化的权衡在于同时在沙箱和底层 Linux 内核中发现可利用漏洞的可能性。这是一个合理的方法，并与浏览器沙箱化类似：Chromium
    使用与容器相同的命名空间、`cgroups` 和 `seccomp`。在 Pwn2Own 和 Tianfu Cup 上经常展示了 Chromium 的突破，但利用漏洞的风险窗口大约是每
    2 到 5 年一次（非常粗略地说）。
- en: Hard multitenant systems should implement tools like OPA for complex and extensible
    admission control. OPA uses the Rego language to define policy and, like any code,
    policies may contain bugs. Security tools rarely “fail open” unless they’re misconfigured.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂和可扩展的入场控制应实现像 OPA 这样的工具。OPA 使用 Rego 语言定义策略，与任何代码一样，策略可能会存在漏洞。安全工具很少会“故障开放”，除非它们配置错误。
- en: Policy risks include permissive regexes and loose comparison of objects or values
    in admission controller policy. Many YAML properties such as image names, tags,
    and metadata are string values prone to comparison mistakes. Like all static analysis,
    policy engines are as robust as you configure them to be.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 策略风险包括入场控制器策略中的宽容正则表达式和对象或值的松散比较。许多 YAML 属性，如镜像名称、标签和元数据，都是容易出错的字符串值比较。与所有静态分析一样，策略引擎的健壮性取决于您的配置。
- en: Multitenancy also involves the monitoring of workloads for potentially hostile
    behavior. Supporting intrusion detection and observability services sometimes
    require potentially dangerous eBPF privileges, and eBPF’s in-kernel execution
    has been a source of container breakouts. The `CAP_BPF` capability (since Linux
    5.8) will reduce the impact of bugs in eBPF systems and require less usage of
    the “overloaded `CAP_SYS_ADMIN` capability” (says the manpage).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 多租户还涉及监视工作负载可能具有敌对行为的行为。支持入侵检测和可观察性服务有时需要潜在危险的 eBPF 权限，而 eBPF 的内核执行已成为容器越狱的源头。`CAP_BPF`
    能力（自 Linux 5.8 起）将减少 eBPF 系统中的错误影响，并减少对“过载的 `CAP_SYS_ADMIN` 能力”的使用（如 manpage 所述）。
- en: Note
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: eBPF is covered further in Chapters [5](ch05.xhtml#ch-networking) and [9](ch09.xhtml#ch-intrusion-detection).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: eBPF 在第 [5](ch05.xhtml#ch-networking) 章和第 [9](ch09.xhtml#ch-intrusion-detection)
    章中进一步讨论。
- en: Despite the runtime risks of running introspection and observability tooling
    with elevated privileges, it is safer to understand cluster risks in real time
    with these permissions, than to be unaware of them.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管以提升的权限运行内省和可观察性工具存在运行时风险，但了解集群风险并实时监控这些权限比不知情更安全。
- en: Public Cloud Multitenancy
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 公共云多租户
- en: Public hard multitenancy services like Google Cloud Run do not trust their workloads.
    They naturally assume the tenant and their activity is malicious and build controls
    to restrict them to the container, pod, and namespace. The threat model considers
    that attackers will try every known attack in an attempt to break out.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Run 等公共硬多租户服务不信任其工作负载。它们自然地假设租户及其活动是恶意的，并构建控件以将其限制在容器、pod 和命名空间中。威胁模型考虑到攻击者将尝试每种已知攻击以试图越狱。
- en: Privately run hard multitenancy pioneers include [*https://contained.af*](https://contained.af)—a
    web page with a terminal, connected to a container secured with kernel primitives
    and LSMs. Adventurers are invited to break their way out of the container if their
    cunning and skill enables them. So far there have been no escapes, which is testament
    to the work Jess Frazelle, the site’s host, contributed to the `runc` runtime
    at Docker.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 私人运行的硬多租户先驱包括 [*https://contained.af*](https://contained.af) ——一个带有终端的网页，连接到一个使用内核原语和
    LSM 安全的容器。冒险家被邀请尝试越狱，如果他们的狡猾和技能使其能够。到目前为止还没有越狱成功，这证明了该网站主持人 Jess Frazelle 在 Docker
    的 `runc` 运行时中做出的贡献。
- en: Although a criminal might be motivated to use or sell a container breakout zero
    day, a prerequisite to most container escapes is absence of LSM and capability
    controls. Containers configured to security best-practice, as enforced by admission
    control, have these controls enabled and are at low risk of breakout.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管犯罪分子可能会有动机使用或出售容器越狱的零日漏洞，但大多数容器逃逸的先决条件是缺乏 LSM 和能力控制。按照准入控制强制执行的安全最佳实践配置的容器已启用这些控制，并且越狱风险较低。
- en: CTF or shared compute platforms such as [*https://ctf.af*](https://ctf.af) should
    be considered compromised and regularly “repaved” (rebuilt from scratch with no
    infrastructure persisting) in the expectation of escalation. This makes an attacker’s
    persistence attacks difficult as they must regularly re-use the same point of
    entry, increasing the likelihood of detection.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: CTF 或共享计算平台，如 [*https://ctf.af*](https://ctf.af)，应被视为受到威胁，并定期“重新铺设”（从头开始重建，不保留任何基础设施），以期望升级。这使得攻击者的持久性攻击变得困难，因为他们必须定期重复使用相同的入口点，增加被发现的可能性。
- en: Control Plane
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制平面
- en: 'Captain Hashjack wants to run code in your pods to poke around the rest of
    the system. Stealing service account authentication information from a pod (at
    */var/run/secrets/kubernetes.io/serviceaccount/token*) enables an attacker to
    spoof your pod’s identity to the API server and any cloud integrations, as in
    the following examples:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Hashjack 船长想要在您的 pod 中运行代码以查看系统的其他部分。从 pod 中窃取服务帐户身份验证信息（位于 */var/run/secrets/kubernetes.io/serviceaccount/token*）使攻击者能够伪装成您的
    pod 身份访问 API 服务器和任何云集成，如以下示例所示：
- en: Tip
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Pod and machine identity credentials are like treasure to a pirate adversary.
    Only the service account token (a JWT) is needed to communicate with the API server
    as server certificate verification can be disabled with `--insecure`, although
    this is not recommended for legitimate use.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 和机器身份凭据对于海盗对手来说就像宝藏。只需服务帐户令牌（JWT）即可与 API 服务器通信，因为服务器证书验证可以通过 `--insecure`
    禁用，尽管这不建议用于合法用途。
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](Images/1.png)](#co_hard_multitenancy_CO1-1)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_hard_multitenancy_CO1-1)'
- en: '`kubernetes.default` is the API server DNS name in the pod network.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubernetes.default`是Pod网络中的API服务器DNS名称。'
- en: '[![2](Images/2.png)](#co_hard_multitenancy_CO1-2)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_hard_multitenancy_CO1-2)'
- en: '`kubectl` defaults to `kubernetes.default` and credentials in */run/secrets/kubernetes.io/serviceaccount*.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl`默认为`kubernetes.default`，凭据位于*/run/secrets/kubernetes.io/serviceaccount*中。'
- en: '[![3](Images/3.png)](#co_hard_multitenancy_CO1-3)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_hard_multitenancy_CO1-3)'
- en: With `kubectl` YOLO (no certificate authority verification of the API server).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`kubectl` YOLO（不验证API服务器的证书颁发机构）。
- en: '[![4](Images/4.png)](#co_hard_multitenancy_CO1-4)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_hard_multitenancy_CO1-4)'
- en: If the workload identity is able to access CRDs for cloud-managed resources,
    stealing a token could unlock access to S3 buckets and another connected infrastructure.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果工作负载标识能够访问云托管资源的CRD，则窃取令牌可以解锁对S3存储桶和其他连接基础设施的访问。
- en: 'Access to the API server can also leak information through its SAN, revealing
    internal and external IP addresses, any other domains DNS records point to, as
    well as the standard internal domains stemming from *kubernetes.default.svc.cluster.local*
    (output edited):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对API服务器的访问还可以通过其SAN泄露信息，显示内部和外部IP地址，DNS记录指向的任何其他域，以及源自*kubernetes.default.svc.cluster.local*的标准内部域（输出已编辑）：
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There are many authentication endpoints in a cluster in addition to the API
    server’s Kubernetes resource-level RBAC, each of which allows an attacker to use
    stolen credentials to attempt privilege escalation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 除API服务器的Kubernetes资源级RBAC之外，集群中还有许多身份验证端点，每个端点允许攻击者使用窃取的凭据尝试特权升级。
- en: Warning
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: 'By default unauthenticated users are placed into the `system:anonymous` group
    and able to read the API server’s `/version` endpoint as seen here, and use any
    roles that have been accidentally bound to the group. Anonymous authentication
    should be disabled if possible for your use case:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，未经身份验证的用户将被放置到`system:anonymous`组中，并且能够读取API服务器的`/version`端点，如下所示，并使用任何意外绑定到该组的角色。如果可能的话，应禁用匿名认证以符合您的用例：
- en: '[PRE7]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Each `kubelet` has its own locally exposed API port, which can allow unauthenticated
    access to read node-local pods. Historically this was due to `cAdvisor` (Container
    Advisor) requesting resource and performance statistics, and some observability
    tools still use this endpoint. If there’s no network policy to restrict pods from
    the node’s network, the `kubelet` can be attacked from a pod.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`kubelet`都有其自己的本地公开API端口，可以允许未经身份验证的访问来读取节点本地的Pod。历史上，这是由于`cAdvisor`（容器顾问）请求资源和性能统计信息，一些可观察性工具仍然使用这个端点。如果没有网络策略来限制Pod与节点网络的访问，`kubelet`可以从Pod中受到攻击。
- en: By the same logic, the API server can be attacked from a pod with no network
    policy restrictions. Any admin interface should be restricted in as many ways
    as is practical.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 凭借同样的逻辑，API服务器可以从没有网络策略限制的Pod攻击。任何管理界面应该在尽可能多的方面进行限制。
- en: API Server and etcd
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: API服务器和etcd
- en: '`etcd` is the robust distributed datastore backing every version of Kubernetes
    and many other cloud native projects. It may be deployed on a dedicated cluster,
    as `systemd` units on Kubernetes control plane nodes, or as self-hosted pods in
    a Kubernetes cluster.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`etcd`是每个版本的Kubernetes和许多其他云原生项目背后的强大分布式数据存储。它可以部署在专用集群上，作为Kubernetes控制平面节点上的`systemd`单元，或作为Kubernetes集群中的自托管Pod。'
- en: 'Hosting `etcd` as pods inside a Kubernetes cluster is the riskiest deployment
    option: it offers an attacker direct access to `etcd` on the CNI. An accidental
    Kubernetes RBAC misconfiguration could expose the whole cluster via `etcd` tampering.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes集群内部部署`etcd`作为Pod是最风险的部署选项：它为攻击者提供了直接访问CNI上的`etcd`。一个意外的Kubernetes
    RBAC配置错误可能会通过`etcd`篡改暴露整个集群。
- en: Note
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '`etcd`’s API has experienced remotely exploitable CVEs. CVE-2020-15115 allows
    remote brute-force of user passwords, CVE-2020-15106 was a remote DoS. Historically
    CVE-2018-1098 also permitted cross-site request forgery, with a resulting elevation
    of privilege.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`etcd`的API曾遭遇远程可利用的CVE。CVE-2020-15115允许对用户密码进行远程暴力破解，CVE-2020-15106是远程DoS。历史上的CVE-2018-1098还允许跨站请求伪造，导致特权提升。'
- en: '`etcd` should be secured by firewalling it to the API server only, enabling
    all encryption methods, and finally integrating the API server with a KMS or Vault
    so sensitive values are encrypted before reaching `etcd`. Guidance is published
    in the [`etcd` Security model](https://oreil.ly/stnc5).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 应通过将其防火墙限制为仅允许API服务器访问，启用所有加密方法，并最终将API服务器与KMS或Vault集成，以便在到达`etcd`之前加密敏感值。指导方针已发布在[`etcd`安全模型](https://oreil.ly/stnc5)中。
- en: The API server handles the system’s core logic and persists its state in `etcd`.
    Only the API server should ever need access, so `etcd` should not be accessible
    over the network in a Kubernetes cluster.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器处理系统的核心逻辑并将其状态持久化在`etcd`中。只有 API 服务器应该需要访问，因此在 Kubernetes 集群中`etcd`不应该通过网络访问。
- en: Tip
  id: totrans-136
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: It’s obvious that every software is vulnerable to bugs, so these sorts of attacks
    can be reduced when `etcd` is not generally available on the network. If Captain
    Hashjack can’t see the socket, they can’t attack it.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，每个软件都容易受到漏洞的影响，因此当`etcd`不在网络上普遍可用时，这些攻击可以得到减少。如果 Hashjack 船长看不到套接字，他们就无法攻击它。
- en: 'There’s a trust boundary encompassing the API server and `etcd`. Root access
    to `etcd` may compromise the API server’s data or allow injection of malicious
    workloads, so the API server holds an encryption key: if the key is compromised,
    `etcd` data can be read by an attacker. This means that if `etcd`’s memory and
    backups are partially encrypted to protect against theft, values of Secrets are
    encrypted with the API server’s symmetric key. That Secret key is passed to the
    API server in a configuration YAML at startup:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器和`etcd`之间存在一个信任边界。对`etcd`的根访问可能会危及 API 服务器的数据或允许注入恶意工作负载，因此 API 服务器保存一个加密密钥：如果密钥被泄露，攻击者可以读取`etcd`数据。这意味着如果为了防止窃取而部分加密`etcd`的内存和备份，Secrets
    的值将使用 API 服务器的对称密钥进行加密。该 Secret 密钥在启动时通过配置 YAML 传递给 API 服务器：
- en: '[PRE8]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This file contains the symmetric keys used to encrypt Secrets in `etcd`:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件包含用于加密`etcd`中 Secrets 的对称密钥：
- en: '[PRE9]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Base64 is encoding to simplify binary data over text links and, in ye olden
    days of Kubernetes yore, was the only way that secrets were “protected.” If Secret
    values are not encrypted at rest, then `etcd`’s memory can be dumped and Secret
    values read by an attacker, and backups can be plundered for Secrets.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Base64 是一种编码方式，用于简化文本链接上的二进制数据，在 Kubernetes 的古老时代，这是保护 Secrets 的唯一方式。如果 Secret
    值在静态时未加密，那么`etcd`的内存可以被转储，攻击者可以读取 Secret 值，并且备份可以被掠夺以获取 Secrets。
- en: 'Containers are just processes, but the root user on the host is omniscient.
    They must be able to see everything in order to debug and maintain the system.
    As you can see, dumping the strings in a process’s memory space is trivial:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 容器只是进程，但主机上的根用户是全知的。他们必须能够查看所有内容以便调试和维护系统。正如你所见，转储进程内存空间中的字符串是微不足道的：
- en: Note
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: See [“Container Forensics”](ch09.xhtml#container-forensics) for a simple example
    of dumping process memory.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 参见[“容器取证”](ch09.xhtml#container-forensics)以了解一个简单的示例，如何转储进程内存。
- en: All memory is readable by the root user, and so unencrypted values in a container’s
    memory are easy to discover. You must detect attackers that attempt this behavior.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 所有内存都可以被根用户读取，因此容器内存中的未加密值很容易被发现。你必须检测那些尝试这种行为的攻击者。
- en: The hardest Secrets for an attacker to steal are those hidden in managed provider-hosted
    Key Management Services (KMS), which can perform cryptographic operations on a
    consumer’s behalf. Dedicated, physical hardware security modules (HSMs) are used
    to minimize risk to the cloud KMS system. Applications such as HashiCorp Vault
    can be configured as a frontend for a KMS, and services must explicitly authenticate
    to retrieve these Secrets. They are not in-memory on the local host, they cannot
    be easily enumerated, and each request is logged for audit. An attacker that compromises
    a node has not yet stolen all the Secrets that node can access.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 对于攻击者来说最难窃取的 Secrets 是隐藏在托管提供商托管的密钥管理服务（KMS）中的那些，它们可以代表消费者执行加密操作。专用的物理硬件安全模块（HSM）用于将云
    KMS 系统的风险降至最低。诸如 HashiCorp Vault 等应用程序可以配置为 KMS 的前端，服务必须明确进行身份验证才能检索这些 Secrets。它们不在本地主机的内存中，不能轻易枚举，每个请求都会被记录以供审计。攻击者如果入侵了一个节点，还没有窃取该节点可以访问的所有
    Secrets。
- en: 'KMS integration makes cloud Secrets much harder to steal from `etcd`. The API
    server uses a local proxy to interact with KMS, by which it decrypts values stored
    in `etcd`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: KMS 集成使得从`etcd`中窃取云 Secrets 变得更加困难。API 服务器使用本地代理与 KMS 交互，通过解密存储在`etcd`中的值：
- en: '[PRE10]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let’s move on to other control plane components.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论其他控制平面组件。
- en: Scheduler and Controller Manager
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度器和控制器管理器
- en: Controller manager and scheduler components are hard to attack as they do not
    have a public network API. They can be manipulated by affecting data in `etcd`
    or tricking the API server, but do not accept network input.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器管理器和调度器组件很难受到攻击，因为它们没有公共网络 API。它们可以通过影响`etcd`中的数据或欺骗 API 服务器来进行操纵，但不接受网络输入。
- en: 'The controller manager service accounts are exemplary implementations of “least
    privilege.” A single controller manager process actually runs many individual
    controllers. In the event of privilege escalation in the controller manager, the
    service accounts used are well segregated in case one of them is leaked:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器管理器的服务账户是“最小权限”的典范实现。一个控制器管理器进程实际上运行多个独立的控制器。如果控制器管理器发生权限升级，使用的服务账户在泄露的情况下会有良好的隔离：
- en: '[PRE11]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'However, that’s not the greatest risk to that service. As with most Linux attacks,
    a malicious user with root privileges can access everything: memory of running
    processes, files on disk, network adapters, and mounted devices.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是该服务面临的最大风险。与大多数 Linux 攻击一样，拥有 root 权限的恶意用户可以访问一切：运行中进程的内存、磁盘上的文件、网络适配器以及挂载的设备。
- en: 'An attacker that compromises the node running the controller manager can impersonate
    that component, as it shares essential key and authentication material with the
    API server, using the master node’s filesystem to share:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者如果攻破运行控制器管理器的节点，可以冒充该组件，因为它与 API 服务器共享关键的身份验证材料和文件系统，使用主节点的文件系统共享：
- en: '[PRE12]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As root on the control plane host, examining the controller manager, we are
    able to dump the container’s filesystem and explore:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 作为控制平面主机上的 root 用户，检查控制器管理器，我们可以转储容器的文件系统并探索：
- en: '[PRE13]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The scheduler has fewer permissions and keys than the controller manager:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器比控制器管理器具有更少的权限和密钥：
- en: '[PRE14]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: These limited permissions give Kubernetes least privilege configuration within
    the cluster and make Dread Pirate Hashjack’s work harder.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这些有限的权限使得 Kubernetes 在集群内部配置了最小权限，并使得 Dread Pirate Hashjack 的工作更加困难。
- en: The RBAC ClusterRole for the cloud controller manager is allowed to create service
    accounts, which can be used by attackers to pivot or persist access. It may also
    access cloud interaction to control computer nodes for autoscaling, cloud storage
    access, network routing (e.g., between nodes), and load balancer config (for routing
    internet or external traffic to the cluster).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 云控制器管理器的 RBAC ClusterRole 允许创建服务账户，攻击者可以利用这些账户进行横向移动或持续访问。它还可以访问云交互以控制计算节点进行自动扩展、云存储访问、网络路由（例如节点之间）、以及负载均衡器配置（用于路由互联网或外部流量到集群）。
- en: Historically, this controller was part of the API server, which means cluster
    compromise may be escalated to cloud account compromise. Segregating permissions
    like this makes an attacker’s life more difficult, and ensuring the control plane
    nodes are not compromised will protect these services.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，此控制器曾是 API 服务器的一部分，这意味着集群遭到攻击可能升级为云账号遭到攻击。像这样分离权限可以增加攻击者的难度，确保控制平面节点不被攻破可以保护这些服务。
- en: Data Plane
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据平面
- en: Kubernetes trusts a worker once it’s joined the cluster. If your worker node
    is hacked, then the `kubelet` it hosts is compromised, as well as the pods and
    data the `kubelet` was running or has access to. All `kubelet` and workload credentials
    fall under the attacker’s control.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 在工作节点加入集群后会信任该节点。如果你的工作节点被黑客攻破，那么它托管的 `kubelet` 也会被攻破，以及 `kubelet`
    运行或具有访问权限的 pod 和数据。所有 `kubelet` 和工作负载凭证都处于攻击者控制之下。
- en: The `kubelet`’s kubeconfig, keys, and service account details are not IP-bound
    by default, and neither are default workload service accounts. These identities
    (service account JWTs) can be exfiltrated and used from anywhere the API server
    is accessible. Post-exploitation, Captain Hashjack can masquerade as the `kubelet`’s
    workloads everywhere that workload’s identity is accepted. API server, other clusters
    and `kubelet`s, cloud and datacenter integrations, and external systems.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`kubelet` 的 kubeconfig、密钥和服务账户详细信息不会受 IP 绑定限制，工作负载服务账户也是如此。这些身份（服务账户 JWTs）可以从
    API 服务器可访问的任何地方泄露并使用。后期利用，Captain Hashjack 可以冒充 `kubelet` 的工作负载，无论这些工作负载的身份在何处被接受：API
    服务器、其他集群和 `kubelet`、云和数据中心集成以及外部系统。
- en: By default, the API server uses the NodeRestriction plug-in and node authorization
    in the admission controller. These restrict a `kubelet`’s service account credentials
    (which must be in the `system:nodes` group) to only the pods that are scheduled
    on that `kubelet`. An attacker may only pull Secrets associated with a workload
    scheduled on the `kubelet`’s node, and those Secrets are already mounted from
    the host’s filesystem into the container, which root can read anyway.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，API 服务器使用 NodeRestriction 插件和准入控制器中的节点授权。这些限制了`kubelet`的服务帐户凭据（必须位于`system:nodes`组中）只能访问安排在该`kubelet`上的
    pod。攻击者只能拉取与安排在`kubelet`节点上的工作负载相关的 Secrets，而这些 Secrets 已经从主机文件系统挂载到容器中，任何 root
    用户都可以读取。
- en: This makes Captain Hashjack’s tyrannical plans more difficult. A compromised
    `kubelet`’s blast radius is limited by this policy. Attackers may work around
    this by attempting to attract sensitive pods to schedule on it.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 Hashjack 船长的专制计划变得更加困难。一个被入侵的`kubelet`的爆炸半径受到此策略的限制。攻击者可能会尝试吸引敏感的 pod 调度到它身上，从而绕过这一限制。
- en: This is not using the API server to reschedule the pods—the stolen `kubelet`
    credentials have no authorization in the `kube-system` namespace—but instead changing
    the `kubelet`’s labels to pretend to be a different host or an isolated workload
    type (frontend, database, etc.).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是使用 API 服务器来重新调度 pod —— 被窃取的`kubelet`凭据在`kube-system`命名空间中没有授权 —— 而是通过更改`kubelet`的标签来假装成不同的主机或隔离的工作负载类型（前端、数据库等）。
- en: 'A compromised `kubelet` is able to relabel itself by updating its command-line
    flags and restarting. This may trick the API server into scheduling sensitive
    pods and Secrets on the node (output edited):'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 一个被入侵的`kubelet`能够通过更新其命令行标志并重新启动来重新标记自己。这可能会欺骗 API 服务器将敏感的 pod 和 Secrets 调度到该节点上（输出已编辑）：
- en: '[PRE15]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[![1](Images/1.png)](#comarker1)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#comarker1)'
- en: Check user by making a failing API call, we’re the `kubelet` node `kube-node-2`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通过进行失败的 API 调用来检查用户，我们是`kubelet`节点`kube-node-2`。
- en: '[![2](Images/2.png)](#comarker2)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#comarker2)'
- en: Modify ourselves with a new label.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新标签修改我们自己。
- en: Admins may use labels to assign specific workloads to certain matching `kubelet`
    nodes and namespaces, grouping workloads with similar data classifications together,
    or increasing performance by keeping network traffic in the same zone or datacenter.
    Attackers should not be able to jump between these sensitive and isolated namespaces
    or nodes.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员可以使用标签将特定工作负载分配给特定的匹配`kubelet`节点和命名空间，将具有相似数据分类的工作负载分组在一起，或通过将网络流量保持在同一区域或数据中心来提高性能。攻击者不应能够在这些敏感且隔离的命名空间或节点之间跳跃。
- en: 'The NodeRestriction admission plug-in defends against nodes relabeling themselves
    as part of these trusted node groups by enforcing an immutable label format. The
    documentation uses regulatory tags as examples (like `example.com.node-restriction.kubernetes.io/fips=true`):'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: NodeRestriction 准入插件通过强制不可变标签格式来防止节点将自己重新标记为这些受信任的节点组的一部分。文档使用监管标签作为示例（如`example.com.node-restriction.kubernetes.io/fips=true`）：
- en: '[PRE16]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Without this added control, a compromised `kubelet` could potentially compromise
    sensitive workloads and possibly even the cluster or cloud account. The plug-in
    still allows modifications to some less-sensitive labels.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 没有这种额外的控制，一个被入侵的`kubelet`可能会危及敏感工作负载，甚至可能危及整个集群或云账户。该插件仍允许对一些不那么敏感的标签进行修改。
- en: Tip
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Any hard-multitenant system should consider the impact of transitive permissions
    for RBAC roles, as tools like [gcploit](https://oreil.ly/DTFz2) show in GCP. It
    chains IAM policies assigned to service accounts, and uses their permissions to
    explore the “transitive permissions” of the original service account.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 任何硬多租户系统都应考虑 RBAC 角色的传递权限的影响，例如像 [gcploit](https://oreil.ly/DTFz2) 在 GCP 中显示的那样。它通过链接分配给服务帐户的
    IAM 策略，并利用它们的权限来探索原始服务帐户的“传递权限”。
- en: Cluster Isolation Architecture
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群隔离架构
- en: When thinking about data classification, it helps to ask yourself, “what’s the
    worst that could happen?” and work backward from there. As [Figure 7-2](#multitenancy-4-cs)
    shows, code will try to escape its container, which might attack a cluster and
    could compromise the account. Don’t put high-value data where it can be accessed
    by breaching a low-value data system.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑数据分类时，有助于问自己，“最坏的情况是什么？”并从那里开始倒推。正如[图 7-2](#multitenancy-4-cs)所示，代码将尝试逃离其容器，这可能会攻击集群并可能会危及账户安全。不要将高价值数据放在可以通过侵入低价值数据系统而访问的地方。
- en: '![The 4C''s of Cloud Native Security](Images/haku_0702.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![云原生安全的四个 C](Images/haku_0702.png)'
- en: 'Figure 7-2\. Kubernetes data flow diagram (source: [cncf/financial-user-group](https://oreil.ly/BI4lj))'
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-2\. Kubernetes数据流图（来源：[cncf/financial-user-group](https://oreil.ly/BI4lj)）
- en: Clusters should be segregated on data classification and impact of breach. Taken
    to the extreme, that’s a cluster per tenant, which is costly and creates management
    overhead for SRE and security teams. The art of delineating clusters is a balance
    of security and maintainability.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 集群应根据数据分类和违规影响进行隔离。在极端情况下，每个租户一个集群是昂贵的，并为SRE和安全团队创建了管理开销。划分集群的艺术在于安全性与可维护性的平衡。
- en: Having many clusters isolated from each other is expensive to run and wastes
    much fallow compute, but this is sometimes necessary for sensitive workloads.
    Each cluster must have consistent policy applied, and the hierarchical namespace
    controller offers a measured path to rolling out similar configurations.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多互相隔离的集群运行是昂贵的并浪费大量空闲计算资源，但对于敏感工作负载有时是必要的。每个集群必须应用一致的策略，并且分层命名空间控制器提供了一个有节制的路径来推广类似配置。
- en: Tip
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Uniform configuration is needed to sync Kubernetes resources to subordinate
    clusters and apply consistent admission control and network policy.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 需要统一配置来将Kubernetes资源同步到从属集群，并应用一致的准入控制和网络策略。
- en: In [Figure 7-3](#multitenancy-hierarchical-ns) we see how policy objects can
    be propagated between namespaces to provide uniform enforcement of security requirements
    like RBAC, network policy, and team-specific Secrets.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图7-3](#multitenancy-hierarchical-ns)中，我们看到策略对象如何在命名空间之间传播，以提供像RBAC、网络策略和团队特定秘密等安全要求的统一执行。
- en: '![haku 0703](Images/haku_0703.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![haku 0703](Images/haku_0703.png)'
- en: 'Figure 7-3\. Kubernetes hierarchical namespace controller (source: [Kubernetes
    Multitenancy Working Group: Deep Dive](https://oreil.ly/7E2e2))'
  id: totrans-193
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-3\. Kubernetes分层命名空间控制器（来源：[Kubernetes多租户工作组：深入探讨](https://oreil.ly/7E2e2)）
- en: Cluster Support Services and Tooling Environments
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群支持服务和工具环境
- en: Shared tooling environments that are connected to clusters of different sensitivities
    can offer a chance for attackers to pivot between environments or harvest leaked
    data.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 连接到不同敏感性集群的共享工具环境可以为攻击者在环境之间转移或收集泄漏数据提供机会。
- en: Warning
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Tooling environments are a prime candidate for attack, especially the supply
    chain of registries and internal packages, and logging and observability systems.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 工具环境是攻击的主要目标，尤其是注册表和内部包的供应链，以及日志记录和可观察性系统。
- en: CVE-2019-11250 is a side-channel information disclosure, leaking HTTP authentication
    headers. This sensitive data is logged by default in Kubernetes components running
    the client-go library. Excess logging of headers and environment variables is
    a frequent issue in any system and highlights the need for separation in sensitive
    systems.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: CVE-2019-11250是一个侧信道信息泄漏，泄漏HTTP身份验证头。这些敏感数据默认在运行client-go库的Kubernetes组件中记录。在任何系统中，过度记录头部和环境变量是一个常见问题，突显了在敏感系统中进行分离的必要性。
- en: Tooling environments that can route traffic back to their client clusters may
    be able to reach administrative interfaces and datastores with credentials from
    CI/CD systems. Or, without direct network access, Captain Hashjack might poison
    container images, compromise source code, pillage monitoring systems, access security
    and scanning services, and drop backdoors.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将流量路由回其客户集群的工具环境可能能够访问具有来自CI/CD系统的凭据的管理界面和数据存储。或者，即使没有直接的网络访问，Hashjack船长也可能会毒害容器镜像、破坏源代码、掠夺监控系统、访问安全和扫描服务，并留下后门。
- en: Security Monitoring and Visibility
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全监控和可见性
- en: Large organizations run Security Operations Centers (SOC) and Security Information
    and Event Management (SIEM) technology to support compliance, threat detection,
    and security management. Your clusters emit events, audit, log, and observability
    data to these systems where they are monitored and reacted to.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 大型组织运行安全运营中心（SOC）和安全信息与事件管理（SIEM）技术，以支持合规性、威胁检测和安全管理。您的集群会向这些系统发出事件、审计、日志和可观察性数据，这些数据会被监控和反应。
- en: Overloading these systems with data, exceeding rate limits, or increased event
    latency (adding a delay to audit, event, or container logs) may overwhelm an SOC
    or SIEM’s capacity to respond.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 过载这些系统的数据、超出速率限制，或增加事件延迟（导致审计、事件或容器日志延迟）可能会超出SOC或SIEM响应的能力。
- en: As stateless applications prefer to store their data in somebody else’s database,
    cloud datastores accessible from Kubernetes are a prime target. The workloads
    that can read or write to these are juicy, and service account credentials and
    workload identities are easy to harvest data with. Your SOC and SIEM should correlate
    cloud events with their calling Kubernetes workload identities to understand how
    your systems are being used, and how they may be attacked.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Stateless 应用程序倾向于将它们的数据存储在其他人的数据库中，可从 Kubernetes 访问的云数据存储是主要目标。可以读取或写入这些数据存储的工作负载非常诱人，使用服务账号凭据和工作负载标识很容易获取数据。你的
    SOC 和 SIEM 应该将云事件与它们调用的 Kubernetes 工作负载标识相关联，以了解系统的使用方式及可能的攻击方式。
- en: We will go into greater detail on this topic in [Chapter 9](ch09.xhtml#ch-intrusion-detection).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第 9 章](ch09.xhtml#ch-intrusion-detection)中更详细地讨论这个话题。
- en: Conclusion
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Segregating workloads is hard and requires you to invest in testing your own
    security. Validate your configuration files with static analysis, and revalidate
    clusters at runtime with tests to ensure they’re still configured correctly.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 隔离工作负载很困难，并需要您投资于测试自己的安全性。使用静态分析验证您的配置文件，并通过测试在运行时重新验证集群，以确保它们仍然正确配置。
- en: The API server and `etcd` are the brains and memory of Kubernetes, and must
    be isolated from hostile tenants. Some multitenancy options run many control planes
    in a larger Kubernetes cluster.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器和 `etcd` 是 Kubernetes 的大脑和记忆，必须与敌对租户隔离开来。一些多租户选项在更大的 Kubernetes 集群中运行许多控制平面。
- en: The hierarchical namespace controller brings distributed management to multicluster
    policy.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 分层命名空间控制器为多集群策略带来了分布式管理。
