- en: Chapter 3\. Node.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Outside browsers, there’s only one JavaScript runtime of note, and that’s *Node.js*.^([1](ch03.xhtml#idm45995923445880))
    Although it started as a platform emphasizing single-threaded concurrency in servers
    with continuation-passing style callbacks, a lot of effort went into making it
    a general-purpose programming platform.
  prefs: []
  type: TYPE_NORMAL
- en: Many tasks performed by Node.js programs don’t fit into its traditional use
    case of serving web requests or handling network connections. Instead, a lot of
    newer Node.js programs are command-line tools acting as build systems, or parts
    of them, for JavaScript. Such programs are typically heavy on I/O operations,
    just like servers are, but they also typically do a lot of data processing.
  prefs: []
  type: TYPE_NORMAL
- en: For example, tools like [Babel](https://babeljs.io) and [TypeScript](https://typescriptlang.org)
    will transform your code from one language (or language version) to another. Tools
    like [Webpack](https://webpack.js.org), [Rollup](https://rollupjs.org), and [Parcel](https://parceljs.org)
    will bundle and minify your code for distribution to your web frontend or to other
    environments where load times are crucial, like serverless environments. In situations
    like these, while there’s a lot of filesystem I/O going on, there’s also a lot
    of data processing, which is generally done synchronously. These are the sorts
    of situations where parallelism is handy and might get the job done quicker.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelism can also be useful in the original Node.js use case, which is servers.
    Data processing may happen a lot, depending on your application. For example,
    *server side rendering (SSR)* involves a lot of string manipulation where the
    source data is already known. This is one of many examples where we might want
    to add parallelism to our solutions. [“When to Use”](ch08.xhtml#ch_benchmarks_sec_usage)
    examines a situation where parallelism improves template rendering time.
  prefs: []
  type: TYPE_NORMAL
- en: Today, we have `worker_threads` for parallelizing our code. This wasn’t always
    the case, but that didn’t mean we were limited to single-threaded concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Before We Had Threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prior to threads being available in Node.js, if you wanted to take advantage
    of CPU cores, you needed to use processes. As discussed in [Chapter 1](ch01.xhtml#ch_intro),
    we don’t get some of the benefits we’d get from threads if we use processes. That
    being said, if shared memory isn’t important (and in many cases it isn’t!) then
    processes are perfectly able to solve these kinds of problems for you.
  prefs: []
  type: TYPE_NORMAL
- en: Consider [Figure 1-1](ch01.xhtml#fig_http_worker_threads_sequence) from [Chapter 1](ch01.xhtml#ch_intro).
    In that scenario, we have threads responding to HTTP requests sent to them from
    a main thread, which is listening on a port. While this concept is great for handling
    traffic from several CPU cores, we can also use processes to achieve a similar
    effect. It might look something like [Figure 3-1](#fig_http_processes_sequence).
  prefs: []
  type: TYPE_NORMAL
- en: '![A web server system might offload work to processes on a round-robin basis.](Images/mtjs_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. Processes as they might be used in an HTTP server
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Although we could do something like this using the `child_process` API in Node.js,
    we’re better off using `cluster`, which was purpose-built for this use case. This
    module’s purpose is to spread network traffic across several worker processes.
    Let’s go ahead and use it in a simple “Hello, World” example.
  prefs: []
  type: TYPE_NORMAL
- en: The code in [Example 3-1](#ex_nodejs_hello_world) is a standard HTTP server
    in Node.js. It simply responds to any request, regardless of path or method, with
    “Hello, World!” followed by a new line character.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-1\. A “Hello, World” server in Node.js
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s add four processes with `cluster`. With the `cluster` module, the
    common approach is to use an `if` block to detect whether we’re in the main listening
    process or one of the worker processes. If we’re in the main process, then we
    have to do the work of spawning the worker processes. Otherwise, we just set up
    an ordinary web server as before in each of the workers. This should look something
    like [Example 3-2](#ex_nodejs_hello_world_cluster).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-2\. A “Hello, World” server in Node.js using `cluster`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_node_js_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Require the `cluster` module.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_node_js_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Change code paths depending on whether we’re in the primary process.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_node_js_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: In the primary process, create four worker processes.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_node_js_CO1-4)'
  prefs: []
  type: TYPE_NORMAL
- en: In the worker processes, create a web server and listen, like in [Example 3-1](#ex_nodejs_hello_world).
  prefs: []
  type: TYPE_NORMAL
- en: You may notice that we’re creating web servers that listen on the same port
    in four difference processes. It seems like a mistake. After all, if we try to
    bind a server to a port that’s already being used, we usually get an error. Don’t
    worry! We’re not actually listening on the same port four times. It turns out
    Node.js does some magic for us in `cluster`.
  prefs: []
  type: TYPE_NORMAL
- en: When worker processes are set up in a cluster, any call to `listen()` will actually
    cause Node.js to listen on the primary process rather than on the worker. Then,
    once a connection is received in the primary process, it’s handed off to a worker
    process via IPC. On most systems, this happens on a round-robin basis. This somewhat
    convoluted system is how each worker can *appear* to be listening on the same
    port, when in fact it’s just the primary process listening on that port and passing
    connections off to all the workers.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Historically, the `isPrimary` property on `cluster` used to be called `isMaster`,
    and for compatibility reasons, it’s still there as an alias at time of writing.
    The change was introduced in Node.js v16.0.0.
  prefs: []
  type: TYPE_NORMAL
- en: This change was made in an effort to reduce the amount of potentially harmful
    language in Node.js. The project aims to be a welcoming community, and words with
    a given usage that are rooted in a history of slavery are antithetical to that
    goal.
  prefs: []
  type: TYPE_NORMAL
- en: Processes incur some extra overhead that threads don’t, and we also don’t get
    shared memory, which helps with faster transfer of data. For that, we need the
    `worker_threads` module.
  prefs: []
  type: TYPE_NORMAL
- en: The worker_threads Module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Node.js’s support for threads is in a built-in module called `worker_threads`.
    It provides an interface to threads that mimics a lot of what you’d find in web
    browsers for web workers. Since Node.js is not a web browser, not all the APIs
    are the same, and the environment inside these worker threads isn’t the same as
    what you’d find inside web workers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, inside Node.js worker threads you’ll find the usual Node.js API available
    via `require`, or `import` if you’re using ESM. There are a few differences in
    the API compared to the main thread though:'
  prefs: []
  type: TYPE_NORMAL
- en: You can’t exit the program with `process.exit()`. Instead this will just exit
    the thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can’t change working directories with `process.chdir()`. In fact, this function
    is not even available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can’t handle signals with `process.on()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another important thing to note is that the `libuv` worker pool is shared across
    worker threads. Recall [“Hidden Threads”](ch01.xhtml#sec_hidden_threads), where
    it was noted that the `libuv` thread pool consists of a default of four threads
    to create nonblocking interfaces to low-level blocking APIs. If you’re finding
    yourself bound by that thread pool’s size (due to, for example, a lot of filesystem
    I/O), you’ll find that adding more threads via `worker_threads` won’t lighten
    the load. Instead, apart from considering various caching solutions and other
    optimizations, consider increasing your `UV_THREADPOOL_SIZE`. Likewise, you might
    find that you have little choice but to increase this when adding JavaScript threads
    via the `worker_threads` module, due to their usage of the `libuv` thread pool.
  prefs: []
  type: TYPE_NORMAL
- en: There are other caveats too, so you’re encouraged to have a look at the [Node.js
    documentation](https://oreil.ly/CYxtz) for a full list of differences for your
    particular version of Node.js.
  prefs: []
  type: TYPE_NORMAL
- en: You can create a new worker thread by using the `Worker` constructor, like in
    [Example 3-3](#ex_nodejs_new_worker).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-3\. Spawning a new worker thread in Node.js
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_node_js_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The filename here is the entrypoint file that we want to run inside the worker
    thread. This is similar to the entrypoint in the main file that we’d specify as
    an argument to `node` on the command line.
  prefs: []
  type: TYPE_NORMAL
- en: workerData
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s not sufficient to just be able to create a worker thread. We need to interact
    with it! The `Worker` constructor takes a second argument, an `options` object,
    that among other things allows us to specify a set of data to be passed immediately
    to the worker thread. The `options` object property is called `workerData`, and
    its contents will be copied into the worker thread via the means described in
    the [Appendix](app01.xhtml#app_sca). Inside the thread, we can access the cloned
    data via the `workerData` property of the `worker_threads` module. You can see
    how this works in [Example 3-4](#ex_nodejs_worker_data).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-4\. Passing data to a worker thread via `workerData`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_node_js_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Rather than using a separate file for the worker thread, we can use the current
    file with `__filename` and switch the behavior based on `isMainThread`.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that the properties of the `workerData` object are *cloned*
    rather than shared between threads. Unlike in C, shared memory in JavaScript threads
    does not mean all the variables are visible. This means any changes you make in
    that object will not be visible in the other thread. They are separate objects.
    That being said, you can have memory that’s shared between threads via `SharedArrayBuffer`.
    These can be shared via `workerData` or by being sent through a `MessagePort`,
    which is covered in the next section. Additionally, `SharedArrayBuffer` is covered
    in depth in [Chapter 4](ch04.xhtml#ch_shared_mem).
  prefs: []
  type: TYPE_NORMAL
- en: MessagePort
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A `MessagePort` is one end of a two-way data stream. By default, one is provided
    to every worker thread to provide a communication channel to and from the main
    thread. It’s available in the worker thread as the `parentPort` property of the
    `worker_threads` module.
  prefs: []
  type: TYPE_NORMAL
- en: To send a message via the port, the `postMesage()` method is called on it. The
    first argument is any object that can be passed, as described in the [Appendix](app01.xhtml#app_sca),
    which will end up being the message data being passed to the other end of the
    port. When a message is received on the port, the `message` event is fired, with
    the message data being the first argument to the event handler function. In the
    main thread, the event and the `postMessage()` method are on the worker instance
    itself, rather than having to get them from a `MessagePort` instance. [Example 3-5](#ex_nodejs_message_port)
    shows a simple example where messages sent to the main thread are echoed back
    to a worker thread.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-5\. Bidirectional communication via the default MessagePorts
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You can also create a pair of `MessagePort` instances connected to each other
    via the `MessageChannel` constructor. You can then pass one of the ports via an
    existing message port (like the default one) or via `workerData`. You might want
    to do this in situations where neither of two threads that need to communicate
    are the main thread, or even just for organizational purposes. [Example 3-6](#ex_nodejs_message_channel)
    is the same as the previous example, except using ports created via `MessageChannel`
    and passed via `workerData`.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-6\. Bidirectional communication via `MessagePort` created with `MessageChannel`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You’ll notice we used the `transferList` option when instantiating the `Worker`.
    This is a way of transferring ownership of objects from one thread to another.
    This is required when sending any `MessagePort`, `ArrayBuffer`, or `FileHandle`
    objects via `workerData` or `postMessage`. Once these objects are transferred,
    they can no longer be used on the sending side.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In more recent versions of Node.js, Web Hypertext Application Technology Working
    Group (WHATWG) `ReadableStream` and `WritableStream` are available. You can learn
    more about them in the [Node.js documentation](https://oreil.ly/TRJf0) and in
    use by some APIs. They can be transferred via `transferList` over `MessagePorts`
    to enable another way of communicating across threads. Under the hood, these are
    implemented using a `MessagePort` to send data across.
  prefs: []
  type: TYPE_NORMAL
- en: 'Happycoin: Revisited'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we’ve seen the basics of spawning threads in Node.js and having them
    communicate with each other, we have enough to rebuild our example from [“Threads
    in C: Get Rich with Happycoin”](ch01.xhtml#ch_intro_sec_happycoin) in Node.js.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that Happycoin is our imaginary cryptocurrency, with a completely ridiculous
    proof-of-work algorithm that goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a random unsigned 64-bit integer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine whether or not the integer is happy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If it’s not happy, it’s not a Happycoin.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If it’s not divisible by 10,000, it’s not a Happycoin.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Otherwise, it’s a Happycoin.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Much like we did in C, we’ll make a single-threaded version first, and then
    adapt the code to run on multiple threads.
  prefs: []
  type: TYPE_NORMAL
- en: With Only the Main Thread
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start with generating random numbers. First, let’s create a file called
    *happycoin.js*, in a directory called *ch3-happycoin/*. Fill it with the contents
    of [Example 3-7](#ex_happycoin_js_1).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-7\. *ch3-happycoin/happycoin.js*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: They `crypto` module in Node.js gives us some handy functions for getting cryptographically
    secure random numbers. We’ll definitely want this since we’re building a cryptocurrency
    after all! Luckily, it’s less of an ordeal than it is in C.
  prefs: []
  type: TYPE_NORMAL
- en: The `randomFillSync` function fills a given `TypedArray` with random data. Since
    we’re looking for only a single 64-bit unsigned integer, we can use a `BigUint64Array`.
    This particular `TypedArray`, along with its cousin `BigInt64Array`, are recent
    additions to JavaScript that were made possible by the new `bigint` type, which
    stores arbitrarily large integers. Returning the first (and only) element of this
    array after we’ve filled it with random data gives us the random 64-bit unsigned
    integer that we’re looking for.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s add our happy number calculation. Add the contents of [Example 3-8](#ex_happycoin_js_2)
    to your file.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-8\. *ch3-happycoin/happycoin.js*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'These three functions, `sumDigitsSquared`, `isHappy`, and `isHappycoin`, are
    direct translations from their C counterparts in [“Threads in C: Get Rich with
    Happycoin”](ch01.xhtml#ch_intro_sec_happycoin). One thing you might notice if
    you’re not familiar with `bigint` is the `n` suffix on all the number literals
    in this code. This suffix tells JavaScript that these numbers are to be treated
    as `bigint` values, rather than values of type `number`. This is important because,
    while both types support mathematical operators like `+`, `-`, `**`, and so on,
    they cannot interoperate without doing an explicit conversion. For example, `1
    + 1n` would be invalid because it’s an attempt to add the `number` 1 to the `bigint`
    1.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s finish off the file by implementing our Happycoin mining loop and outputting
    the count of found Happycoins. Add [Example 3-9](#ex_happycoin_js_3) to your file.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-9\. *ch3-happycoin/happycoin.js*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The code here is very similar to what we did in C. We loop 10,000,000 times,
    getting a random number and checking if it’s a Happycoin. If it is, we print it
    out. Note that we’re not using `console.log()` here because we don’t want to insert
    a newline character after each number found. Instead we want spaces, so we’re
    writing to the output stream directly. When we output the count after the loop,
    we need an additional newline character at the beginning of the output to separate
    it from the numbers above.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this program, use the following command in your *ch3-happycoin* directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Your output should be exactly the same as it was in C. That is, it should look
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This takes quite a bit longer than the C example. On a run-of-the-mill machine,
    this took about 1 minute and 45 seconds with Node.js v16.0.0.
  prefs: []
  type: TYPE_NORMAL
- en: There are a variety of reasons why this takes so much longer. When building
    applications and optimizing for performance, it’s important to figure out what
    the sources of performance overhead are. Yes, in general, JavaScript is often
    “slower than C,” but this enormous difference can’t be explained by that alone.
    Yes, we’ll get better performance in the next section when we split this into
    multiple threads of work, but as you’ll see, it’s not nearly enough to make this
    implementation compelling when compared to the C example.
  prefs: []
  type: TYPE_NORMAL
- en: And on that note, let’s see what this looks like when we use `worker_threads`
    to split out the load.
  prefs: []
  type: TYPE_NORMAL
- en: With Four Worker Threads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To add worker threads, we will start from the code we had. Copy the contents
    of *happycoin.js* to *happycoin-threads.js*. Then insert the contents of [Example 3-10](#ex_happycoin_threads_js_1)
    at the very beginning of the file, before the existing content.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-10\. *ch3-happycoin/happycoin-threads.js*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We’ll need these parts of the `worker_threads` module, so we `require` them
    at the beginning. Now, replace everything from `let count = 0;` to the end of
    the file with [Example 3-11](#ex_happycoin_threads_js_2).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-11\. *ch3-happycoin/happycoin-threads.js*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We’re splitting behavior here with an `if` block. If we’re on the main thread,
    we start four worker threads using the current file. Remember, `__filename` is
    a string containing the path and name of the current file. We then add a message
    handler for that worker. In the message handler, if the message is simply `done`,
    then the worker has completed its work, and if all other workers are done, we’ll
    output the count. If the message is a number, or more correctly, a `bigint`, then
    we assume it’s a Happycoin, and we’ll print it out and add it to the count like
    we did in the single-threaded example.
  prefs: []
  type: TYPE_NORMAL
- en: On the `else` side of the `if` block, we’re running in one of the worker threads.
    In here, we’ll do the same sort of loop as we did in the single-threaded example,
    except we’re only looping 1/4 of the number of times we did before, since we’re
    doing the same work across four threads. Also, rather than writing directly to
    the output stream, we’re sending found Happycoins back to the main thread via
    the `MessagePort` given to us, called `parentPort`. We’ve already set up the handler
    on the main thread for this. When the loop exits, we send a `done` on the `parentPort`
    to indicate to the main thread that we won’t be finding any more Happycoins on
    this thread.
  prefs: []
  type: TYPE_NORMAL
- en: We could have simply printed the Happycoins to the output immediately, but just
    like with the C example, we don’t want the different threads to clobber each other
    in the output, so we need to *synchronize*. Chapters [4](ch04.xhtml#ch_shared_mem)
    and [5](ch05.xhtml#ch_adv_shared_mem) go over more advanced techniques for synchronization,
    but for now it’s enough to just send the data back to the main thread through
    the `parentPort` and let the main thread handle output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’re done adding threads to this example, you can run it with the
    following command in your *ch3-happycoin* directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see output that looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Like with the C example, this code runs quite a bit faster. In a test on the
    same computer and Node.js version as the single-threaded example, it ran in about
    33 seconds. This is a huge improvement over the single-threaded example, so another
    big win for threads!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This is not the only way to split this kind of problem up for thread-based computation.
    For example, other synchronization techniques could be used to avoid passing data
    between threads, or the messages could be batched. Always be sure to test and
    compare to find out whether threads are an ideal solution and which thread techniques
    are most applicable to your problem, and the most efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Worker Pools with Piscina
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many types of workloads will naturally lend themselves to using threads. In
    Node.js, most workloads involve processing an HTTP request. If within that code
    you find yourself doing a lot of math or synchronous data processing, it may make
    sense to offload that work to one or more threads. These types of operations involve
    submitting a single task to a thread and waiting for a result from it. In much
    the same way a threaded web server often works, it makes sense to maintain a pool
    of workers that can be sent various tasks from the main thread.
  prefs: []
  type: TYPE_NORMAL
- en: This section only takes a shallow look at thread pools, adapting the familiar
    Happycoins application and abstracting the pooling mechanism using a package.
    [“Thread Pool”](ch06.xhtml#ch_patterns_sec_threadpool) covers thread pools extensively,
    building out an implementation from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The concept of pooled resources isn’t unique to threads. For example, web browsers
    typically create pools of socket connections to web servers so that they can multiplex
    all the various HTTP requests required to render a web page across those connections.
    Database client libraries often do a similar thing with sockets connected to the
    database server.
  prefs: []
  type: TYPE_NORMAL
- en: There’s a handy module available for Node.js called [*generic-pool*](https://oreil.ly/2a6ua),
    which is a helper module for dealing with arbitrary pooled resources. These resources
    could be anything, like database connections, other sockets, local caches, threads,
    or pretty much anything else that might require having multiple instances of something
    but only accessing one at a time, without caring which one it is.
  prefs: []
  type: TYPE_NORMAL
- en: For the use case of discrete tasks sent to a pool of worker threads, we have
    the [*piscina*](https://oreil.ly/0p8zi) module at our disposal. This module encapsulates
    the work of setting up a bunch of worker threads and allocating tasks to them.
    The name of the module comes from the Italian word for “pool.”
  prefs: []
  type: TYPE_NORMAL
- en: The basic usage is straightforward. You create an instance of the `Piscina`
    class, passing in a `filename`, which will be used in the worker thread. Behind
    the scenes, a pool of worker threads is created, and a queue is set up to handle
    incoming tasks. You can enqueue a task by calling `.run()`, passing in a value
    containing all the data necessary to complete this task, and noting that the values
    will be cloned as they would be with `postMessage()`. This returns a promise that
    resolves once the tasks have been completed by a worker, giving a result value.
    In the file to be run in the worker, a function must be exported that takes in
    whatever is passed to `.run()` and returns the result value. This function can
    also be an `async` function, so that you can do asynchronous tasks in a worker
    thread if you need to. A basic example calculating square roots in worker threads
    is found in [Example 3-12](#ex_piscina_square_roots).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-12\. Computing square roots with `piscina`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_node_js_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Much like `cluster` and `worker_threads`, `piscina` provides a handy boolean
    for determining whether we’re in the main thread or a worker thread.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_node_js_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the same technique for using the same file as we did with the Happycoin
    example.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_node_js_CO4-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Since `.run()` returns a promise, we can just call `.then()` on it.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_node_js_CO4-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The exported function is used in the worker thread to perform the actual work.
    In this case, it’s just calculating a square root.
  prefs: []
  type: TYPE_NORMAL
- en: While it’s all fine and good to run one task on the pool, we need to be able
    to run *many* tasks on the pool. Let’s say we want to calculate the square roots
    of every number less than ten million. Let’s go ahead and loop ten million times.
    We’ll also replace the logging with an assertion that we’ve gotten a numeric result,
    since logging will be quite noisy. Have a look at [Example 3-13](#ex_piscina_10m_square_roots).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-13\. Computing ten million square roots with `piscina`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This seems like it ought to work. We’re submitting ten million numbers to be
    processed by the worker pool. However, if you run this code, you’ll get a nonrecoverable
    JavaScript memory allocation error. On one trial of this with Node.js v16.0.0,
    the following output was observed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: What’s going on here? It turns out the underlying task queue is not infinite.
    By default, the task queue will keep growing and growing until we run into an
    allocation error like this one. To avoid having this happen, we need to set a
    reasonable limit. The `piscina` module lets you set a limit by using a `maxQueue`
    option in its constructor, which can be set to any positive integer. Through experimentation,
    the maintainers of `piscina` have found that an ideal `maxQueue` value is the
    square of the number of worker threads it’s using. Handily, you can use this number
    without even knowing it by setting `maxQueue` to `auto`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we’ve established a bound for the queue size, we need to be able to handle
    it when the queue is full. There are two ways to detect that the queue is full:'
  prefs: []
  type: TYPE_NORMAL
- en: Compare the values of `piscina.queueSize` and `piscina.options.maxQueue`. If
    they’re equal, then the queue is full. This can be done prior to calling `piscina.run()`
    to avoid attempting to enqueue when it’s full. This is the recommended way to
    check.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If `piscina.run()` is called when the queue is full, the returned promise will
    reject with an error indicating that the queue is full. This isn’t ideal because
    by this point we’re already in a further tick of the event loop and many other
    attempts to enqueue may already have happened.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When we know that the queue is full, we need a way of knowing when it’ll be
    ready for new tasks again. Fortunately, `piscina` pools emit a `drain` event once
    the queue is empty, which is certainly an ideal time to start adding new tasks.
    In [Example 3-14](#ex_piscina_better_10m_square_roots), we put this all together
    with an `async` function around the loop that submits the tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-14\. Computing ten million square roots with `piscina`, without crashing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#manual_co_node_js_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The `maxQueue` option is set to `auto`, which limits the queue size to the square
    of the number of threads that `piscina` is using.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#manual_co_node_js_CO5-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The `for` loop is wrapped in an `async` immediately invoked function expression
    (IIFE) in order to use an `await` within it.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#manual_co_node_js_CO5-3)'
  prefs: []
  type: TYPE_NORMAL
- en: When this check is true, the queue is full.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#manual_co_node_js_CO5-4)'
  prefs: []
  type: TYPE_NORMAL
- en: We then wait for the `drain` event before submitting any new tasks to the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Running this code does *not* result in an out-of-memory crash like it did before.
    It takes a fairly long time to complete, but it does finally exit without issue.
  prefs: []
  type: TYPE_NORMAL
- en: As seen here, it’s easy to fall into a trap where using a tool in what seems
    like the most sensible way isn’t the best approach. It’s important to fully understand
    tools like `piscina` when building out your multithreaded applications.
  prefs: []
  type: TYPE_NORMAL
- en: On that note, let’s see what happens when we try to use `piscina` to mine Happycoins.
  prefs: []
  type: TYPE_NORMAL
- en: A Pool Full of Happycoins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use `piscina` to produce Happycoins, we’ll use a slightly different approach
    from what we did in the original `worker_threads` implementation. Instead of getting
    a message back every time we have a Happycoin, we’ll batch them together and send
    them all at once when we’re done. This trade-off saves us the effort of setting
    up a `MessageChannel` to send data back to the main thread with; the side effect
    is that we’ll only get our results in batches, rather than as soon as they’re
    ready. The main thread will still do the job of spawning the appropriate threads
    and retrieving all the results.
  prefs: []
  type: TYPE_NORMAL
- en: To start off, copy your *happycoin-threads.js* file to a new one called *happycoin-piscina.js*.
    We’ll build off our old `worker_threads` example here. Now replace everything
    before the `require('crypto')` line with [Example 3-15](#ex_happycoin_piscina_1).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-15\. *ch3-happycoin/happycoin-piscina.js*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Yep, that’s it! Now we’ll get to the more substantial stuff. Replace everything
    after the `isHappycoin()` function declaration with the contents of [Example 3-16](#ex_happycoin_piscina_2).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-16\. *ch3-happycoin/happycoin-piscina.js*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_node_js_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the `isWorkerThread` property to check that we’re in the main thread.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_node_js_CO5-2)'
  prefs: []
  type: TYPE_NORMAL
- en: We’re using the same technique as earlier to create worker threads using this
    same file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_node_js_CO5-3)'
  prefs: []
  type: TYPE_NORMAL
- en: We want to restrict the number of threads to be exactly four, to match our previous
    examples. We’ll want to time this and see what happens, so sticking with four
    threads reduces the number of variables here.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_node_js_CO5-4)'
  prefs: []
  type: TYPE_NORMAL
- en: We know we have four threads, so we’ll enqueue our task four times. Each one
    will complete once it has checked its chunk of random numbers for Happycoins.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](Images/5.png)](#co_node_js_CO5-5)'
  prefs: []
  type: TYPE_NORMAL
- en: We submit the task to the queue in this `async` IIFE, so that they all get queued
    in the same event loop iteration. Don’t worry, we won’t get out-of-memory errors
    like we did before because we know we have exactly four threads and we’re only
    enqueueing four tasks. As we’ll see later, the task returns both the output string
    and the total count of Happycoins that the thread has found.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](Images/6.png)](#co_node_js_CO5-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Much like we’ve done in previous Happycoin implementations, we’ll check that
    all threads have completed their tasks before outputting the grand total count
    of Happycoins that we’ve found.
  prefs: []
  type: TYPE_NORMAL
- en: Next we’ll add the code from [Example 3-17](#ex_happycoin_piscina_3), which
    adds the exported function that’s used in `piscina`’s worker threads.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-17\. *ch3-happycoin/happycoin-piscina.js*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#manual_co_node_js_CO7-1)'
  prefs: []
  type: TYPE_NORMAL
- en: We’re doing our typical Happycoin-hunting loop here, but as in other parallelism
    examples, we’re dividing our total search space by the number of threads.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#manual_co_node_js_CO7-2)'
  prefs: []
  type: TYPE_NORMAL
- en: We’re passing the string of found Happycoins and the total count of them back
    to the main thread by returning a value from this function.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this, you’ll have to install `piscina` if you haven’t done so yet for
    the earlier examples. You can use the following two commands in your *ch3-happycoin*
    directory to set up a Node.js project and add the `piscina` dependency. The third
    line can then be used to run the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: You should see output the same as earlier examples, with a slight twist. Rather
    than seeing each Happycoin come in one by one, you’ll see them either roughly
    all at once, or in four large groupings of them. This is the trade-off we made
    by returning the whole strings rather than the Happycoins one by one. This code
    should run in roughly the same time as *happycoin-threads.js*, since it uses the
    same principle, but with the abstraction layer that `piscina` provides us.
  prefs: []
  type: TYPE_NORMAL
- en: You can see that we’re not using `piscina` in the typical manner. We’re not
    passing it a multitude of discrete tasks that end up requiring careful queueing.
    The primary reason for this is performance.
  prefs: []
  type: TYPE_NORMAL
- en: If, for example, we had a loop iterating ten million times in the main thread,
    each time adding another task to the queue and `await`-ing its response, it would
    end up being just as slow as running all the code synchronously on the main thread.
    We could *not* await the reply and just add things to the queue as soon as we
    can, but it turns out the overhead of passing messages 20 million times is a lot
    greater than simply passing eight messages.
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with raw data, like numbers or byte streams, there are usually
    faster ways of transferring data between threads using `SharedArrayBuffers`, and
    we’ll see more about those in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch03.xhtml#idm45995923445880-marker)) Yes, other nonbrowser JavaScript
    runtimes exist, like Deno, but Node.js has such a massive amount of popularity
    and market share at time of writing that it’s the only one worth talking about
    here. This may change by the time you’re reading this, and that’s great for the
    world of JavaScript! Hopefully, there’s a newer edition of this book that covers
    your nonbrowser JavaScript runtime of choice.
  prefs: []
  type: TYPE_NORMAL
