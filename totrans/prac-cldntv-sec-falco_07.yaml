- en: Chapter 5\. Data Enrichment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章。数据丰富化
- en: Falco’s architecture allows you to capture events from different data sources,
    as you’ve learned. This process delivers raw data, which can be very rich but
    isn’t very useful for runtime security unless paired with the right context. That’s
    why Falco first extracts and then enriches the raw data with contextual information,
    so that the rule author can comfortably use it. Typically, we refer to this information
    as the event *metadata*. Getting metadata can be a complex task, and getting it
    efficiently is even more complex.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Falco的架构允许您从不同的数据源捕获事件，正如您所了解的那样。此过程提供原始数据，可能非常丰富，但如果不与正确的上下文配对，对运行时安全性并不是非常有用。这就是为什么Falco首先提取，然后用上下文信息丰富原始数据，以便规则作者可以轻松使用。通常，我们将这些信息称为事件**元数据**。获取元数据可能是一个复杂的任务，而有效获取它更加复杂。
- en: You’ve already seen that the system-state collection capabilities in *libscap*
    and the state engine implemented by *libsinsp* (discussed in [Chapter 3](ch03.xhtml#understanding_falcoapostr))
    are central to this activity, but there’s much more to discover. In this chapter,
    we’ll delve into the design aspects of the Falco stack to help you better understand
    how data enrichment works. In particular, we will show you *libsinsp*’s efficient
    layered approach to obtaining system, container, and Kubernetes metadata for system
    call (syscall) events. This is what enables you to access the information you
    need relating to different contexts (depending on your use case), such as a container’s
    ID or the name of a Pod where a suspicious event occurred. Finally, we’ll show
    you how plugins, Falco’s other main data source, can implement their own data
    enrichment mechanisms, opening up infinite possibilities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经看到*libscap*中的系统状态收集功能和*libsinsp*中实现的状态引擎（在[第三章](ch03.xhtml#understanding_falcoapostr)讨论过），这些都是这项活动的核心，但还有更多内容等待探索。在本章中，我们将深入探讨Falco堆栈的设计方面，帮助您更好地理解数据丰富化的工作方式。特别是，我们将展示*libsinsp*用于系统调用事件获取系统、容器和Kubernetes元数据的高效分层方法。这使您能够根据您的用例访问您需要的不同上下文信息，例如容器的ID或发生可疑事件的Pod的名称。最后，我们将展示插件如何实现其自己的数据丰富化机制，为Falco的另一个主要数据源打开无限的可能性。
- en: Understanding Data Enrichment for Syscalls
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Syscalls的数据丰富化
- en: Understanding how data enrichment works will help you to fully understand Falco’s
    mechanics. Moreover, although data enrichment usually works out of the box, each
    context Falco supports has its own implementation and may need a specific configuration.
    Knowing the implementation details will help you troubleshoot and fine-tune Falco.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 理解数据丰富化的工作原理将帮助您充分理解Falco的机制。此外，虽然数据丰富化通常可以即插即用，但Falco支持的每个上下文都有自己的实现，可能需要特定的配置。了解实现细节将有助于您进行故障排除和优化Falco。
- en: '*Data enrichment* in Falco refers to the process of providing the rule engine
    with event metadata obtained by decoding the raw data or collecting it from complementary
    sources. You can then use this metadata as fields in both rule conditions and
    output formatting. Falco organizes the collected metadata in a set of field classes,
    so you can easily recognize which context they belong to. (You can find the complete
    list of supported fields in [Chapter 6](ch06.xhtml#fields_and_filters) or, if
    you have a Falco installation at your fingertips, by typing `**falco --list**`.)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*Falco*中的**数据丰富化**指的是通过解码原始数据或从补充源收集事件元数据，并将其提供给规则引擎的过程。然后，您可以将此元数据用作规则条件和输出格式化的字段。Falco将收集的元数据组织成一组字段类别，因此您可以轻松识别它们所属的上下文。（您可以在[第六章](ch06.xhtml#fields_and_filters)找到支持的字段的完整列表，或者如果您的Falco安装在手边，可以键入`**falco
    --list**`来查找。）'
- en: One of the most significant examples of data enrichment is when using system
    calls as a data source, which you learned about in [Chapter 4](ch04.xhtml#data_source).
    Since syscalls are essential to every application, they occur in just about every
    context. Information directly provided by a syscall would not be useful without
    context, however, so it therefore becomes critical to collect and connect the
    surrounding information.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据丰富化的一个重要例子是使用系统调用作为数据源，您在[第四章](ch04.xhtml#data_source)已经了解过。由于syscalls对每个应用程序都至关重要，它们几乎发生在每个上下文中。然而，直接由syscall提供的信息如果没有上下文是没有用处的，因此收集和连接周围信息变得至关重要。
- en: '[Table 5-1](#contextual_metadata_for_system_calls) shows the different categories
    of metadata that Falco collects for syscalls, and the field classes associated
    with each data enrichment layer.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 5-1](#contextual_metadata_for_system_calls) 显示了Falco为系统调用收集的不同类别的元数据以及每个数据丰富层关联的字段类别。'
- en: Table 5-1\. Contextual metadata for system calls
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-1\. 系统调用的上下文元数据
- en: '| Context | Metadata | Field classes |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 上下文 | 元数据 | 字段类别 |'
- en: '| --- | --- | --- |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Operating system | Processes and threads File descriptors'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '| 操作系统 | 进程和线程 文件描述符'
- en: Users and groups
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 用户和组
- en: Network interfaces | `proc`, `thread`, `fd`, `fdlist`, `user`, `group` |
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 网络接口 | `proc`, `thread`, `fd`, `fdlist`, `user`, `group` |
- en: '| Container | ID and name Type'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '| 容器 | ID和名称 类型'
- en: Image name
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像名称
- en: Privileged
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 特权
- en: Mount points
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 挂载点
- en: Health checks | `container` |
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 健康检查 | `container` |
- en: '| Kubernetes | Namespace Pod'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '| Kubernetes | 命名空间 Pod'
- en: ReplicationController
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 复制控制器
- en: Service
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 服务
- en: ReplicaSet
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 副本集
- en: Deployment | `k8s` |
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 | `k8s` |
- en: The enrichment process happens in user space and involves several components
    of Falco’s stack. Most importantly, the metadata must be immediately available
    every time the rule engine requests it. Collecting it from other complementary
    sources on the fly would thus not be feasible, as attempting to do so would risk
    blocking the rule engine and the entire flow of incoming events.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 数据丰富过程在用户空间中进行，涉及Falco堆栈的多个组件。最重要的是，每次规则引擎请求时必须立即提供元数据。因此，尝试从其他互补来源即时收集元数据是不可行的，因为这样做可能会阻塞规则引擎和传入事件的整个流程。
- en: For that reason, data enrichment involves two distinct phases. The first initializes
    a local state by collecting in bulk the data that is present when Falco starts,
    and the second continuously updates the local state while Falco runs. Having a
    local state allows Falco to extract metadata immediately. This design is shared
    among all implementation layers, as you will discover in the following sections.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据丰富涉及两个不同的阶段。第一个阶段通过大量收集Falco启动时存在的数据来初始化本地状态，第二个阶段则在Falco运行时持续更新本地状态。拥有本地状态允许Falco立即提取元数据。这种设计在所有实现层中都是共享的，你将在以下章节中了解到。
- en: Operating System Metadata
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作系统元数据
- en: 'As you learned in [Chapter 3](ch03.xhtml#understanding_falcoapostr), *libscap*
    and *libsinsp* work together to provide all the necessary infrastructure to create
    and update contextual information in a hierarchical structure composed of several
    state tables (see [Figure 3-4](ch03.xhtml#the_libsinsp_state_hierarchy) if you
    need a refresher). Those tables include information about:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[第三章](ch03.xhtml#understanding_falcoapostr)学到的，*libscap* 和 *libsinsp* 协同工作，提供创建和更新由多个状态表组成的分层结构中的上下文信息所需的所有基础设施（如果需要复习，请参见[图 3-4](ch03.xhtml#the_libsinsp_state_hierarchy)）。这些表包括关于以下信息的信息：
- en: Processes and threads
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程和线程
- en: File descriptors
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件描述符
- en: Users and groups
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户和组
- en: Network interfaces
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络接口
- en: At a high level, the mechanism for collecting system information is relatively
    simple. At start time, one of *libscap*’s tasks is to scan the [*process information
    pseudo-filesystem*](https://oreil.ly/xso1E), or *procfs*, which provides a user-space
    interface to the Linux kernel data structures and contains most of the information
    to initialize the state tables. It also collects system information (not available
    in */proc*) using functions provided by the standard C library, which in turn
    obtains the data from the underlying operating system (for example, `getpwent`
    and `getgrent` for users and groups lists, respectively, and `getifaddrs` for
    the network interfaces list). At this point, the initialization phase is complete.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，收集系统信息的机制相对简单。在启动时，*libscap* 的任务之一是扫描[*进程信息伪文件系统*](https://oreil.ly/xso1E)，或称为*procfs*，它为Linux内核数据结构提供用户空间接口，并包含初始化状态表所需的大部分信息。它还使用标准C库提供的函数来收集系统信息（不在*/proc*中可用），这些函数最终从底层操作系统获取数据（例如，`getpwent`
    和 `getgrent` 分别用于用户和组列表，以及 `getifaddrs` 用于网络接口列表）。此时，初始化阶段完成。
- en: Tip
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: '*libscap* and *libsinsp* rely on the host’s procfs to access the host’s system
    information. That happens by default when Falco runs on the host since it can
    directly access the host’s */proc*. However, when Falco runs in a container, the
    */proc* inside the container refers to a different namespace. In such a situation,
    you can configure *libscap* via the `HOST_ROOT` environment variable to read from
    an alternative path. If you set `HOST_ROOT`, *libscap* will use its value as a
    base path when looking for system paths. For example, when running Falco in a
    container, the usual approach is to mount the host’s */proc* to */host/proc* inside
    the container and set `HOST_ROOT` to */host*. With this setup, *libscap* will
    read from */host/proc*, and thus it will use the information provided by the host’s
    procfs.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*libscap* 和 *libsinsp* 依赖于主机的 procfs 来访问主机的系统信息。这在 Falco 运行在主机上时是默认的，因为它可以直接访问主机的
    */proc*。然而，在容器中运行 Falco 时，容器内的 */proc* 指的是不同的命名空间。在这种情况下，你可以通过 `HOST_ROOT` 环境变量配置
    *libscap* 来从另一路径读取信息。如果设置了 `HOST_ROOT`，*libscap* 将使用其值作为查找系统路径的基路径。例如，在容器中运行 Falco
    时，通常的方法是将主机的 */proc* 挂载到容器内的 */host/proc* 并设置 `HOST_ROOT` 为 */host*。通过这种设置，*libscap*
    将从 */host/proc* 读取信息，因此它将使用主机的 procfs 提供的信息。'
- en: Afterward, *libsinsp* comes into play with its state engine (see [Figure 5-1](#system_state_collection_before_left_par)).
    It updates the tables by inspecting the constantly captured stream of syscalls
    provided by the driver, which runs in kernel space. After the initialization phase,
    Falco will not need to make any syscalls or tap into the system to obtain updates
    from the Linux kernel. This approach has the double benefit of not creating noise
    in the system and having a low impact on performance. Furthermore, this technique
    enables *libsinsp* to discover system changes with low latency, allowing Falco
    to function as a streaming engine (one of its most important design goals).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，*libsinsp* 通过其状态引擎发挥作用（见 [图 5-1](#system_state_collection_before_left_par)）。它通过检查驻留在内核空间的驱动程序提供的持续捕获的系统调用流来更新表格。在初始化阶段之后，Falco
    将不需要进行任何系统调用或从 Linux 内核获取更新。这种方法的双重好处是不会在系统中创建噪音并且对性能影响很低。此外，这种技术使 *libsinsp*
    能够以低延迟发现系统变化，从而使 Falco 能够作为流式引擎（其设计的一个重要目标）运行。
- en: 'The last important thing to note is that *libsinsp* updates the state tables
    before dispatching the event to the rule engine. This ensures that when the conditions
    or output require metadata, it will always be available and consistent. You can
    then find the system metadata grouped in the set of field classes you saw in [Table 5-1](#contextual_metadata_for_system_calls):
    `proc`, `thread`, `fd`, `fdlist`, `user`, and `group`.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 最后需要注意的是，*libsinsp* 在将事件传递给规则引擎之前更新状态表。这确保了当条件或输出需要元数据时，它始终可用且一致。然后，你可以在你在 [表格 5-1](#contextual_metadata_for_system_calls)
    中看到的字段类集合中找到系统元数据：`proc`、`thread`、`fd`、`fdlist`、`user` 和 `group`。
- en: 'This set of information represents the basic metadata that enables a rule author
    to make a syscall event usable. Think about it: how would you use a numeric file
    descriptor in a rule? A filename is much better!'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这组信息表示了使规则作者能够使用系统调用事件的基本元数据。想想看：你如何在规则中使用数值文件描述符？使用文件名要好得多！
- en: '![](Images/pcns_0501.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pcns_0501.png)'
- en: Figure 5-1\. System state collection before (1) and after (2) the initialization
    phase
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-1\. 初始化阶段之前（1）和之后（2）的系统状态收集
- en: The system information (i.e., the state tables) produced by this data enrichment
    layer is also essential for collecting contextual information at the container
    level. We’ll look at that next.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据丰富层产生的系统信息（即状态表）也是收集容器级上下文信息所必需的。接下来我们会详细看一下这些信息。
- en: Container Metadata
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器元数据
- en: Additional fundamental contextual information resides in the container runtime
    layer. A *container runtime* is a software component that can run containers on
    a host operating system. It is commonly responsible for managing container images
    and the lifecycles of containers running on your system. It is also responsible
    for managing a set of information related to each running container and providing
    that information to other applications.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的基本上下文信息存储在容器运行时层中。*容器运行时* 是可以在主机操作系统上运行容器的软件组件。通常负责管理容器映像和在系统上运行的容器的生命周期。它还负责管理与每个运行中容器相关的一组信息，并将该信息提供给其他应用程序。
- en: Because Falco is a cloud native runtime security tool, it needs to be able to
    deal with container information. To achieve this goal, *libsinsp* works with the
    most commonly used container runtime environments, including Docker, Podman, and
    CRI-compatible^([2](ch05.xhtml#ch01fn6)) runtimes like containerd and CRI-O.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 Falco 是一个云原生运行时安全工具，它需要能够处理容器信息。为了实现这一目标，*libsinsp* 与最常用的容器运行时环境合作，包括 Docker、Podman
    和与 CRI 兼容的运行时（如 containerd 和 CRI-O）。
- en: When *libsinsp* finds a running container runtime on the host, the container
    metadata enrichment functionality works out of the box in almost all cases. For
    example, *libsinsp* tries to use Docker’s Unix socket at */var/run/docker.sock*;
    if this exists, *libsinsp* automatically connects to it and starts grabbing container
    metadata. *libsinsp* does the same for Podman and containerd. For other CRI-compatible
    runtimes, you will need to pass the socket path to Falco using the `--cri` command-line
    flag (for CRI-O, for example, you would pass `/var/run/crio/crio.sock`).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *libsinsp* 在主机上找到一个运行的容器运行时时，几乎在所有情况下，容器元数据增强功能都能够立即正常工作。例如，*libsinsp* 尝试使用
    Docker 的 Unix 套接字 */var/run/docker.sock*；如果存在，则 *libsinsp* 将自动连接并开始抓取容器元数据。*libsinsp*
    对 Podman 和 containerd 也是如此。对于其他与 CRI 兼容的运行时，你需要使用 `--cri` 命令行标志将套接字路径传递给 Falco（例如，对于
    CRI-O，你需要传递 `/var/run/crio/crio.sock`）。
- en: Tip
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If the `HOST_ROOT` environment variable is set, *libsinsp* will use its value
    as the base path when looking for those Unix sockets. For example, when running
    Falco in a container, it’s common to set `HOST_ROOT=/host` and mount */var/run/docker.sock*
    to */host/var/run/docker.sock* inside the container.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果设置了环境变量`HOST_ROOT`，*libsinsp* 将使用其值作为查找这些 Unix 套接字时的基本路径。例如，当在容器中运行 Falco
    时，通常会设置 `HOST_ROOT=/host` 并将 */var/run/docker.sock* 挂载到容器内的 */host/var/run/docker.sock*。
- en: Regardless of which container runtime you are using, at initialization *libsinsp*
    requests a list of all running containers, which it uses to initialize an internal
    cache. At the same time, *libsinsp* updates the state table of running processes
    and threads, associating each of them with its respective container ID, if any.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 无论使用哪种容器运行时，在初始化时，*libsinsp* 都会请求所有运行中容器的列表，并用它来初始化内部缓存。同时，*libsinsp* 更新运行进程和线程的状态表，将每个进程和线程与其相应的容器
    ID（如果有）关联起来。
- en: '*libsinsp* handles subsequent updates by using the syscalls stream coming from
    the driver (similar to what it does for system information). Since container information
    is always associated with a process, *libsinsp* tracks all new processes and threads.
    When it detects one, it looks up the corresponding container ID in the internal
    cache. If the container ID is not in the cache, *libsinsp* queries the container
    runtime to gather the missing data.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*libsinsp* 通过使用来自驱动程序的系统调用流来处理后续更新（类似于处理系统信息）。由于容器信息始终与进程关联，*libsinsp* 跟踪所有新的进程和线程。当检测到一个新进程或线程时，它会在内部缓存中查找相应的容器
    ID。如果容器 ID 不在缓存中，*libsinsp* 将查询容器运行时以收集丢失的数据。'
- en: Ultimately, each syscall-generated event that occurs in a container has a process
    or thread ID that maps to a container ID and, consequently, to the container metadata
    (as shown in [Figure 5-2](#container_info_in_the_libsinsp_state_hi)). So, when
    the rule engine requires this metadata, *libsinsp* looks it up from the state
    tables and returns system information along with the container metadata. You will
    find the available container metadata grouped in the field class `container`,
    which can be used in both conditions and output formatting.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，发生在容器中的每个系统调用生成的事件都有一个进程或线程 ID，映射到一个容器 ID，并因此映射到容器元数据（如 [图 5-2](#container_info_in_the_libsinsp_state_hi)
    所示）。因此，当规则引擎需要此元数据时，*libsinsp* 会从状态表中查找并返回系统信息以及容器元数据。你可以在字段类 `container` 中找到可用的容器元数据，这些数据可以用于条件和输出格式化。
- en: '![](Images/pcns_0502.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pcns_0502.png)'
- en: Figure 5-2\. Container info in the libsinsp state hierarchy
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-2\. *libsinsp* 状态层次结构中的容器信息
- en: Note that the field `container.id` can contain either the container ID *or*
    the special value `host`. This special value indicates that the event did not
    happen inside a container. The condition `container.id != host` is a common way
    to express a rule that applies only in the context of a container.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，字段 `container.id` 可以包含容器 ID 或特殊值 `host`。这个特殊值表示事件未发生在容器内。条件 `container.id
    != host` 是表达仅在容器上下文中应用规则的常见方式。
- en: In the final data enrichment layer, Falco collects the Kubernetes metadata associated
    with system calls. We’ll look at how this works next.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在最终的数据增强层中，Falco 收集与系统调用相关联的 Kubernetes 元数据。我们接下来将看看它是如何工作的。
- en: Kubernetes Metadata
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 元数据
- en: Kubernetes, the flagship project of the Cloud Native Computing Foundation, is
    an open source platform for managing workloads and services. It has introduced
    many new concepts that make it easier to manage and scale clusters and is the
    most popular container orchestration system today.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是云原生计算基金会的旗舰项目，是一个用于管理工作负载和服务的开源平台。它引入了许多新概念，使得管理和扩展集群更加容易，并且是当今最流行的容器编排系统。
- en: One of the essential features of Kubernetes is encapsulating your applications
    in objects called *Pods*, which contain one or more containers. Pods are ephemeral
    objects that you can quickly deploy and easily replicate. *Services* in Kubernetes
    are an abstraction that allows you to expose a set of Pods as a single network
    service. Finally, Kubernetes lets you arrange those and many other objects into
    *namespaces*, which are objects that allow partitioning of a single cluster into
    multiple virtual clusters.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的一个关键特性是将您的应用程序封装在称为 *Pods* 的对象中，每个 Pod 包含一个或多个容器。Pods 是短暂的对象，您可以快速部署和轻松复制。Kubernetes
    中的 *Services* 是一种抽象，允许您将一组 Pods 暴露为单个网络服务。最后，Kubernetes 允许您将这些和许多其他对象安排到 *namespaces*
    中，这些对象允许将单个集群分区为多个虚拟集群。
- en: While these concepts greatly facilitate managing and automating clusters, they
    also introduce a set of contextual information about how and where your application
    is running. Awareness of this information is essential, since knowing that something
    has happened in your Kubernetes cluster is of little use if you don’t know where
    it happened (for example, in which namespace or Pod). Falco collects information
    such as the container image name, Pod name, namespace, labels, annotations, and
    exposed service names so it can offer as accurate a view as possible of your deployments
    and applications. This is important for runtime alerting and protection of your
    infrastructure, because you’re typically much more interested in what service
    or deployment is showing a strange behavior than in getting a container ID or
    some other hard-to-link piece of information. As a cloud native tool, Falco can
    readily obtain this metadata and attach it to the event.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些概念极大地便于管理和自动化集群，但它们也引入了关于应用程序在何处以及如何运行的一系列上下文信息。了解这些信息至关重要，因为如果不知道事件发生的地点（例如，在哪个命名空间或
    Pod 中），知道 Kubernetes 集群中发生了某事并没有什么用处。Falco 收集的信息包括容器镜像名称、Pod 名称、命名空间、标签、注释和暴露的服务名称，以尽可能准确地展示您的部署和应用。这对于运行时警报和保护基础设施至关重要，因为您通常更关心显示异常行为的服务或部署，而不是获取容器
    ID 或其他难以关联的信息。作为云原生工具，Falco 可以轻松获取此元数据并将其附加到事件中。
- en: 'Similar to the operating system and container metadata collection mechanisms
    you saw in the previous sections, this feature allows Falco to enrich syscall
    events by adding Kubernetes metadata. For full Kubernetes support, you must opt
    in by passing two command-line options to Falco:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与前几节中看到的操作系统和容器元数据收集机制类似，此功能允许 Falco 通过添加 Kubernetes 元数据来丰富系统调用事件。要完全支持 Kubernetes，您必须通过向
    Falco 传递两个命令行选项来选择加入：
- en: '`--k8s-api` (or just `-k`)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`--k8s-api`（或简写为 `-k`）'
- en: This enables Kubernetes support by connecting to the API server specified as
    an argument (e.g., `http://admin:password@127.0.0.1:8080`).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过连接到指定的 API 服务器（例如，`http://admin:password@127.0.0.1:8080`）来启用 Kubernetes 支持。
- en: '`--k8s-api-cert` (or just `-K`)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`--k8s-api-cert`（或简写为 `-K`）'
- en: This provides certificate materials to authenticate the user and (optionally)
    verify the Kubernetes API server’s identity.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了证书材料来对用户进行身份验证，并（可选地）验证 Kubernetes API 服务器的身份。
- en: Further details are provided in [Chapter 10](ch10.xhtml#configuring_and_running).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 更多详细信息请参阅[第10章](ch10.xhtml#configuring_and_running)。
- en: Tip
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'When Falco is running in a Pod, Kubernetes injects that information in the
    container, so you just need to set:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Falco 在 Pod 中运行时，Kubernetes 会将该信息注入到容器中，因此您只需要设置：
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Most installation methods use this strategy to fetch those values automatically.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数安装方法使用此策略自动获取这些值。
- en: Once Kubernetes support is configured, *libsinsp* will get all the necessary
    data from Kubernetes to create and maintain a local copy of the state of the cluster.
    However, unlike the other enrichment mechanisms that get metadata locally from
    the host, *libsinsp* has to connect to the Kubernetes API server (usually a remote
    endpoint) to get cluster information. Because of this difference, the implementation
    design needs to take performance and scalability concerns into account.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦配置了 Kubernetes 支持，*libsinsp* 将从 Kubernetes 获取所有必要的数据，以创建和维护集群状态的本地副本。但是，与从主机本地获取元数据的其他丰富机制不同，*libsinsp*
    必须连接到 Kubernetes API 服务器（通常是远程端点）以获取集群信息。由于这种差异，实现设计需要考虑性能和可扩展性问题。
- en: A typical Falco deployment (pictured in [Figure 5-3](#a_falco_deployment_using_a_daemonset_to))
    runs one Falco sensor on every node in the cluster. At startup, each sensor connects
    to the API server to collect the cluster data and build the initial state locally.
    From then on, each sensor will use the [Kubernetes watch API](https://oreil.ly/g0hCZ)
    to periodically update the local state.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的 Falco 部署（如 [图 5-3](#a_falco_deployment_using_a_daemonset_to) 所示）在集群中的每个节点上运行一个
    Falco 传感器。在启动时，每个传感器连接到 API 服务器以收集集群数据并在本地构建初始状态。从此以后，每个传感器将使用 [Kubernetes watch
    API](https://oreil.ly/g0hCZ) 定期更新本地状态。
- en: '![](Images/pcns_0503.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pcns_0503.png)'
- en: Figure 5-3\. A Falco deployment using a [DaemonSet](https://oreil.ly/WTTGU)
    to ensure that all nodes run a copy of a Pod
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-3\. 使用 [DaemonSet](https://oreil.ly/WTTGU) 实现的 Falco 部署，以确保所有节点运行一个 Pod
    的副本
- en: Since Falco sensors are distributed in the cluster (one per node) and grab data
    from the API server—and because collecting some resource types from Kubernetes
    may result in huge responses that severely impact both the API server and Falco—*libsinsp*
    has mechanisms to avoid congestion. First, it waits for a short time between downloading
    each chunk. Falco allows you to fine-tune that wait time, along with several other
    parameters, by changing a value in */etc/falco/falco.yaml*.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Falco 传感器在集群中分布（每个节点一个），并从 API 服务器获取数据 —— 因为从 Kubernetes 收集某些资源类型可能导致响应巨大，严重影响
    API 服务器和 Falco —— *libsinsp* 具有避免拥塞的机制。首先，在下载每个数据块之间等待一段时间。Falco 允许您通过更改 */etc/falco/falco.yaml*
    中的一个值来调整该等待时间以及几个其他参数。
- en: More importantly, it’s possible to request *only* the relevant metadata for
    the targeted node from the API server. This is helpful because Falco’s architecture
    is distributed, so each sensor needs data only from the node on which the event
    occurred. This optimization is fundamental if you want to scale Falco on a cluster
    with thousands of nodes. To enable it, add the `--k8s-node` flag to the Falco
    command-line arguments, passing the current node name as the value. You can usually
    obtain this name easily from the Kubernetes [Downward API](https://oreil.ly/F1Dnv).^([3](ch05.xhtml#ch01fn7))
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，可以仅从 API 服务器请求针对目标节点的相关元数据。这非常有用，因为 Falco 的架构是分布式的，所以每个传感器只需从事件发生的节点获取数据。如果您希望在具有数千个节点的集群上扩展
    Falco，则这种优化至关重要。要启用此功能，请在 Falco 命令行参数中添加 `--k8s-node` 标志，并将当前节点名称作为值传递。通常可以通过
    Kubernetes 的 [Downward API](https://oreil.ly/F1Dnv) 轻松获取此名称。^([3](ch05.xhtml#ch01fn7))
- en: If you don’t include the `--k8s-node` flag, *libsinsp* will still be able to
    get the data from Kubernetes, but each Falco sensor will have to request the whole
    cluster’s data. This can introduce a performance penalty on large clusters, so
    we strongly discourage it. (You will learn more about running Falco on a production
    Kubernetes cluster in [Part III](part03.xhtml#iii_running_falco_in_production).)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不包括 `--k8s-node` 标志，*libsinsp* 仍然能够从 Kubernetes 获取数据，但每个 Falco 传感器将不得不请求整个集群的数据。这可能会在大型集群上引入性能损失，因此我们强烈不建议这样做。（您将在
    [第三部分](part03.xhtml#iii_running_falco_in_production) 了解更多关于在生产 Kubernetes 集群上运行
    Falco 的内容。）
- en: 'When Kubernetes metadata is available, you will find it grouped in the `k8s`
    field class. Many of the Falco default rules include `k8s` fields in their conditions.
    Falco, when used with the `-pk` command-line option, automatically appends the
    most crucial Kubernetes metadata to the output of all notifications, as you can
    see in the following example, which we’ve pretty-printed to improve readability
    (more on this in [“Output Settings”](ch10.xhtml#output_settings)):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Kubernetes 元数据可用时，您将在 `k8s` 字段类中找到它们。Falco 的许多默认规则在其条件中包含 `k8s` 字段。当使用 `-pk`
    命令行选项运行 Falco 时，Falco 会自动将最关键的 Kubernetes 元数据附加到所有通知的输出中，如下所示，我们已对其进行了美化以提高可读性（更多信息请参阅
    [“输出设置”](ch10.xhtml#output_settings)）：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This output is the result of the complex mechanism you’ve just learned about
    that allows you to obtain accurate and contextualized information to immediately
    identify what event has just occurred, and where.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出是刚学习到的复杂机制的结果，它允许你获取准确和上下文化的信息，以立即识别刚刚发生的事件及其位置。
- en: So far, we’ve only discussed Falco’s data enrichment process for system calls.
    Although that’s likely to be the most relevant information for most users, you
    should know that Falco also offers custom enrichment mechanisms. We’ll take a
    quick look at how to implement those next.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了Falco对系统调用数据丰富化的过程。尽管这对大多数用户可能是最相关的信息，但你应该知道，Falco还提供了自定义丰富化机制。接下来我们快速看一下如何实现这些机制。
- en: Data Enrichment with Plugins
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用插件进行数据丰富化
- en: Plugins can extend Falco by adding new data sources and defining new fields
    to describe how to use these new events. As you’ll recall from [Chapter 4](ch04.xhtml#data_source),
    a plugin that offers the field extraction capability works on events provided
    by other plugins or core libraries. While it might not seem obvious yet, a plugin
    with this capability has everything it takes to provide a custom data-enrichment
    mechanism. First, it can receive data from any data source. Second, it can define
    new fields. Fundamentally, it allows the plugin author to implement logic to return
    the values of those fields, thus potentially providing additional metadata. This
    opens the door to the possibility of implementing custom data enrichment.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 插件可以通过添加新的数据源和定义新的字段来扩展Falco，以描述如何使用这些新事件。正如你在[第4章](ch04.xhtml#data_source)中所了解到的，一个提供字段提取能力的插件可以处理其他插件或核心库提供的事件。虽然现在可能还不明显，但具有这种能力的插件已具备提供自定义数据丰富化机制的一切条件。首先，它可以从任何数据源接收数据。其次，它可以定义新的字段。基本上，它允许插件作者实现逻辑来返回这些字段的值，从而潜在地提供额外的元数据。这打开了实现自定义数据丰富化的可能性。
- en: When such a plugin runs, *libsinsp* calls the plugin function for field extraction
    for each incoming event. The function receives the raw payload of the event and
    the list of fields the rule engine needs. The plugin API interface does not impose
    any other constraints to make the extraction process work. Although data enrichment
    is possible in the flow just described, the plugin author will still have to consider
    all the implications of the use case; for example, the plugin will need to manage
    the local state and subsequent updates. Extracting fields and enriching the event
    is thus entirely up to the plugin author. The APIs merely provide the essential
    tools.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当这样一个插件运行时，*libsinsp* 会为每个传入的事件调用插件函数进行字段提取。该函数接收事件的原始数据负载和规则引擎所需的字段列表。插件API接口并不对使提取过程工作施加其他限制。尽管数据丰富化在上述流程中是可能的，但插件作者仍需考虑使用情况的所有影响；例如，插件将需要管理本地状态和随后的更新。因此，提取字段和丰富化事件完全取决于插件作者。API仅提供了基本工具。
- en: '[Chapter 14](ch14.xhtml#falco_development) shows you how to implement a plugin.
    If you’re interested in doing that, however, our advice is to read the next chapter
    about fields and filters first, so you have a more complete picture of how extracting
    data works.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[第14章](ch14.xhtml#falco_development) 展示了如何实现一个插件。如果你对此感兴趣，我们建议先阅读下一章关于字段和过滤器，这样你就能更全面地了解数据提取的工作方式。'
- en: Conclusion
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This chapter illustrated how Falco works internally to provide a rich set of
    metadata. Falco makes this metadata available as fields you can use in rules’
    conditions. Read on to discover how to use fields to filter only those events
    that are really pertinent to your needs.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了Falco内部工作的方式，以提供丰富的元数据。Falco将这些元数据作为字段提供，你可以在规则的条件中使用这些字段。继续阅读，了解如何使用字段仅过滤那些真正与你需求相关的事件。
- en: ^([1](ch05.xhtml#ch01fn5-marker)) In older Falco versions, the Kubernetes audit
    log was a built-in data source. From Falco 0.32, this data source has been refactored
    out as a plugin.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch05.xhtml#ch01fn5-marker)) 在较早的Falco版本中，Kubernetes审计日志是一个内置的数据源。从Falco
    0.32开始，这个数据源已被重构为一个插件。
- en: ^([2](ch05.xhtml#ch01fn6-marker)) The [Container Runtime Interface (CRI)](https://oreil.ly/fiCGp)
    is a plugin interface introduced by Kubernetes that enables the kubelet to use
    any container runtimes implementing the CRI.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch05.xhtml#ch01fn6-marker)) [容器运行时接口（CRI）](https://oreil.ly/fiCGp) 是由Kubernetes引入的插件接口，允许kubelet使用任何实现CRI的容器运行时。
- en: ^([3](ch05.xhtml#ch01fn7-marker)) The Downward API allows containers to consume
    information about themselves or the cluster without using the Kubernetes API server.
    Among other things, it allows exposing the current node name through an environment
    variable that can be then used in Falco command-line arguments.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch05.xhtml#ch01fn7-marker)) 下行 API 允许容器在不使用 Kubernetes API 服务器的情况下获取有关自身或集群的信息。它可以通过环境变量暴露当前节点名称，这个名称可以在
    Falco 命令行参数中使用。
