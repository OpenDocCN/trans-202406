["```\n$ linkerd viz -n booksapp routes deploy/books --to svc/authors\n```", "```\n$ kubectl get serviceprofile -n booksapp \\\n    authors.booksapp.svc.cluster.local\n```", "```\napiVersion: linkerd.io/v1alpha2\nkind: ServiceProfile\nmetadata:\n  name: authors.booksapp.svc.cluster.local\n  namespace: booksapp\nspec:\n  routes:\n  - condition:\n      method: GET\n      pathRegex: /authors\\.json\n    name: GET /authors.json\n  - condition:\n      method: POST\n      pathRegex: /authors\\.json\n    name: POST /authors.json\n  - condition:\n      method: DELETE\n      pathRegex: /authors/[^/]*\\.json\n    name: DELETE /authors/{id}.json\n  - condition:\n      method: GET\n      pathRegex: /authors/[^/]*\\.json\n    name: GET /authors/{id}.json\n  - condition:\n      method: HEAD\n      pathRegex: /authors/[^/]*\\.json\n    name: HEAD /authors/{id}.json\n```", "```\n$ kubectl edit serviceprofiles authors.booksapp.svc.cluster.local -n booksapp\n```", "```\napiVersion: linkerd.io/v1alpha2\nkind: ServiceProfile\nmetadata:\n  name: authors.booksapp.svc.cluster.local\n  namespace: booksapp\nspec:\n  routes:\n  - condition:\n      method: GET\n      pathRegex: /authors\\.json\n    name: GET /authors.json\n  - condition:\n      method: POST\n      pathRegex: /authors\\.json\n    name: POST /authors.json\n  - condition:\n      method: DELETE\n      pathRegex: /authors/[^/]*\\.json\n    name: DELETE /authors/{id}.json\n  - condition:\n      method: GET\n      pathRegex: /authors/[^/]*\\.json\n    name: GET /authors/{id}.json\n  - condition:\n      method: HEAD\n      pathRegex: /authors/[^/]*\\.json\n    name: HEAD /authors/{id}.json\n    isRetryable: true\n```", "```\n$ linkerd viz -n booksapp routes deploy/books --to svc/authors -o wide\n```", "```\n$ watch linkerd viz -n booksapp \\\n    routes deploy/books --to svc/authors -o wide\n```", "```\n...\nspec:\n  ...\n  # This retryBudget stanza is AN EXAMPLE ONLY\n  retryBudget:\n    retryRatio: 0.3\n    minRetriesPerSecond: 50\n    ttl: 60s\n  ...\n```", "```\n$ linkerd viz -n booksapp routes deploy/webapp --to svc/books\n```", "```\n$ kubectl get sp/books.booksapp.svc.cluster.local -n booksapp -o yaml\n```", "```\napiVersion: linkerd.io/v1alpha2\nkind: ServiceProfile\nmetadata:\n  name: books.booksapp.svc.cluster.local\n  namespace: booksapp\nspec:\n  routes:\n  - condition:\n      method: GET\n      pathRegex: /books\\.json\n    name: GET /books.json\n  - condition:\n      method: POST\n      pathRegex: /books\\.json\n    name: POST /books.json\n  - condition:\n      method: DELETE\n      pathRegex: /books/[^/]*\\.json\n    name: DELETE /books/{id}.json\n  - condition:\n      method: GET\n      pathRegex: /books/[^/]*\\.json\n    name: GET /books/{id}.json\n  - condition:\n      method: PUT\n      pathRegex: /books/[^/]*\\.json\n    name: PUT /books/{id}.json\n```", "```\n$ kubectl edit serviceprofiles.linkerd.io \\\n  books.booksapp.svc.cluster.local -n booksapp\n```", "```\napiVersion: linkerd.io/v1alpha2\nkind: ServiceProfile\nmetadata:\n  name: books.booksapp.svc.cluster.local\n  namespace: booksapp\nspec:\n  routes:\n  - condition:\n      method: GET\n      pathRegex: /books\\.json\n    name: GET /books.json\n  - condition:\n      method: POST\n      pathRegex: /books\\.json\n    name: POST /books.json\n  - condition:\n      method: DELETE\n      pathRegex: /books/[^/]*\\.json\n    name: DELETE /books/{id}.json\n  - condition:\n      method: GET\n      pathRegex: /books/[^/]*\\.json\n    name: GET /books/{id}.json\n  - condition:\n      method: PUT\n      pathRegex: /books/[^/]*\\.json\n    name: PUT /books/{id}.json\n    timeout: 25ms\n```", "```\n$ linkerd viz -n booksapp routes deploy/webapp --to svc/books\n```", "```\n# Start in a clean working directory, as we will be cloning the\n# linkerd-book/luar Git repository.\n$ git clone https://github.com/linkerd-book/luar.git\n\n# First, we'll create our namespace, podinfo, with the\n# linkerd.io/inject: enabled annotation set on it. This will\n# ensure our Pods get Linkerd proxies attached to them.\n$ kubectl apply -f luar/reliability/ns.yaml\n\n# Next, we'll install the podinfo application using Helm.\n$ helm repo add podinfo https://stefanprodan.github.io/podinfo\n$ helm repo up\n\n# Install 3 versions of podinfo:\n# - podinfo is our \"version 1\" Pod.\n# - podinfo-2 is our \"version 2\" Pod.\n# - frontend is a frontend to the whole thing.\n$ helm install podinfo \\\n     --namespace podinfo \\\n     --set ui.message=\"hello from v1\" \\\n     podinfo/podinfo\n\n```", "```\n$ helm install podinfo-2 \\\n     --namespace podinfo \\\n     --set ui.message=\"hello from v2\" \\\n     podinfo/podinfo\n\n$ helm install frontend \\\n     --namespace podinfo \\\n     --set backend=http://podinfo:9898/env \\\n     podinfo/podinfo\n\n# Create a traffic generator for podinfo.\n$ kubectl apply -f luar/reliability/generator.yaml\n\n# Check that the applications are ready.\n$ linkerd check --proxy -n podinfo\n\n# Verify that both versions of the podinfo workload are running.\n$ kubectl get pods -n podinfo\n\n# Verify that each version of podinfo has its own Service.\n$ kubectl get svc -n podinfo\n```", "```\n# If you have the watch command, it works well for this.\n$ watch linkerd viz stat deploy -n podinfo\n\n# If you don't have watch, it's simple enough to emulate.\n$ while true; do\n  clear\n  date\n  linkerd viz stat deploy -n podinfo\n  sleep 2\ndone\n```", "```\n---\napiVersion: policy.linkerd.io/v1beta2\nkind: HTTPRoute\nmetadata:\n  name: podinfo-route\n  namespace: podinfo\nspec:\n  parentRefs:\n    - name: podinfo\n      namespace: podinfo\n      kind: Service\n      group: core\n      port: 9898\n  rules:\n  - backendRefs:\n    - name: podinfo\n      namespace: podinfo\n      port: 9898\n      weight: 5\n    - name: podinfo-v2\n      namespace: podinfo\n      port: 9898\n      weight: 5\n```", "```\n$ kubectl edit httproute -n podinfo podinfo-route\n```", "```\n$ kubectl delete httproute -n podinfo podinfo-route\n```", "```\napiVersion: policy.linkerd.io/v1beta2\nkind: HTTPRoute\nmetadata:\n  name: podinfo-route\n  namespace: podinfo\nspec:\n  parentRefs:\n    - name: podinfo\n      kind: Service\n      group: core\n      port: 9898\n  rules:\n    - matches:\n      - headers:\n        - name: \"x-request-id\"\n          value: \"alternative\"\n      backendRefs:\n        - name: \"podinfo-v2\"\n          port: 9898\n    - backendRefs:\n      - name: \"podinfo\"\n        port: 9898\n```", "```\n# Start by forwarding traffic to your frontend service.\n$ kubectl port-forward svc/frontend-podinfo 9898:9898 &\n\n# Now send a request to the service and see what message you get back.\n# You should see \"hello from v1\" since this request didn't include the\n# header.\n$ curl -sX POST localhost:9898/echo \\\n  | jq -r \".[]\" | grep MESSAGE\n\n# Now try again, setting the x-request-id header.\n# You should see \"hello from v2\" since this request does include the\n# header.\n$ curl -H 'x-request-id: alternative' -sX POST localhost:9898/echo \\\n  | jq -r \".[]\" | grep MESSAGE\n```", "```\n$ kubectl apply -f luar/reliability/podinfo-v3.yaml\n```", "```\n$ kubectl annotate -n podinfo svc/podinfo \\\n  balancer.linkerd.io/failure-accrual=consecutive\n```", "```\n# First, we'll set the number of failures we need to see to quarantine\n# the endpoints. In this case, we'll change it from the default of 7 to 3.\n$ kubectl annotate -n podinfo svc/podinfo \\\n  balancer.linkerd.io/failure-accrual-consecutive-max-failures=3\n\n# Next, we'll change the minimum quarantine time to 30 seconds from 1 second.\n$ kubectl annotate -n podinfo svc/podinfo \\\n  balancer.linkerd.io/failure-accrual-consecutive-min-penalty=30s\n\n# Finally, we change the max penalty time to 2 minutes.\n$ kubectl annotate -n podinfo svc/podinfo \\\n  balancer.linkerd.io/failure-accrual-consecutive-max-penalty=2m\n```"]