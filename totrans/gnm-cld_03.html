<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. Genomics in a Nutshell: A Primer for Newcomers to the Field"><div class="chapter" id="genomics_in_a_nutshell_a_primer_for_new">
<h1><span class="label">Chapter 2. </span>Genomics in a Nutshell: A Primer for Newcomers to the Field</h1>

<p>Now that we’ve given you the broad context of the book in <a data-type="xref" href="ch01.xhtml#introduction">Chapter 1</a>, it’s time to dive into the more specific scientific context of genomics. In this chapter, we run through a brief primer on key biological concepts and related practical information that you need to know in order to benefit fully from working through the exercises in this book. We review the fundamentals of genetics and build up to a definition of genomics that will frame the scientific scope of this book. With that frame in place, we then review the main types of genomics variation, with a focus on how they manifest in the genome. Finally, we go over the key processes, tools, and file formats involved in generating and processing high-throughput sequencing data for genomic analysis.</p>

<p>Depending on your background, this might serve as a quick refresher, or it might be your first introduction to many of these topics. The first couple of sections are aimed at readers who have not had much formal training in biology, genetics, and related life sciences. If you are a life-sciences student or professional, feel free to skim through until you encounter something that you don’t already know. In later sections, we progressively introduce more genomics-specific concepts and tools that should be useful to all but the most seasoned practitioners.</p>

<section data-type="sect1" data-pdf-bookmark="Introduction to Genomics"><div class="sect1" id="introduction_to_genomics">
<h1>Introduction to Genomics</h1>

<p>So what is genomics? <a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-type="indexterm" id="ix_genintro"/>The short answer, “it’s the science of genomes,” doesn’t really help if you don’t already know what a genome is and why it matters. So before we get into the gory details of “how to do genomics,” let’s take a step back and make sure we all agree on what we mean by genomics. First, let’s go over the fundamental concepts involved, including the basics of what a gene is and how it relates to DNA. Then, we progressively deepen our exploration to cover key types of data and analyses within the specific defined scope. Keep in mind that this will not be an exhaustive compilation of all things that could possibly be grouped under the term of genomics, given that (a) this is not meant to be a scientific textbook, and (b) the field is still evolving very rapidly, with so many exciting new methodologies and technologies being actively developed that it would be premature to attempt to codify them in a book like this one.</p>

<section data-type="sect2" data-pdf-bookmark="The Gene as a Discrete Unit of Inheritance (Sort Of)"><div class="sect2" id="the_gene_as_a_discrete_unit_of_inherita">
<h2>The Gene as a Discrete Unit of Inheritance (Sort Of)</h2>

<p>Let’s start at the historical beginning—the gene.<a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-tertiary="genes" data-type="indexterm" id="ix_genintrogen"/><a contenteditable="false" data-primary="genes" data-type="indexterm" id="ix_gene"/> It’s a term that is almost universally recognized but not necessarily well understood, so it’s worth going into its origins and unrolling its evolution (so to speak).</p>

<p>The earliest mention of a <em>gene</em> was based on concepts formulated by key 19th-century thinkers such as Charles “Origin of Species” Darwin and Gregor “Pea Enthusiast” Mendel, at a time when the advent of molecular biology was still well more than a century away. They needed a way to explain the patterns of partial and combinatorial trait inheritance that they had observed in various organisms, so they postulated the existence of microscopic indivisible particles that are transmitted from parents to progeny and constitute the determinants of physical traits. These hypothetical particles were eventually dubbed <em>genes</em> by Wilhelm Johannsen in the early 20th century.</p>

<p>A fistful <a contenteditable="false" data-primary="DNA" data-secondary="structure and composition of" data-type="indexterm" id="idm45625635616632"/>of decades later, Rosalind Franklin, Francis Crick, and James Watson elucidated the now<a contenteditable="false" data-primary="double-helix structure of DNA" data-type="indexterm" id="idm45625635614696"/> famous <em>double-helix</em> structure of DNA: two complementary strands, each formed by a backbone of repeated units of a molecule called <em>deoxyribose</em> (the D in DNA), which carry the actual information content in the form of another type of molecule called <em>nucleic acids</em> (the NA in DNA). <a contenteditable="false" data-primary="deoxyribose" data-type="indexterm" id="idm45625635611912"/><a contenteditable="false" data-primary="nucleic acids" data-type="indexterm" id="idm45625635610776"/>The four nucleic acids in DNA, more generally called <em>bases</em>, are famously referred to by their initials A, C, G, and T, which stand for <em>adenine</em>, <em>cytosine</em>, <em>guanine</em>, and <em>thymine</em>, respectively. <a contenteditable="false" data-primary="A, C, G, T (adenine, cytosine, guanine, thymine)" data-type="indexterm" id="idm45625635607208"/><a contenteditable="false" data-primary="bases" data-type="indexterm" id="idm45625635605976"/>The reason DNA works as a double helix is that the molecular structure of the bases makes the two strands pair up: if you put an A base across from a T base, their shapes match up, and they attract each other like magnets. The same thing happens with G and C, except they attract each other even more strongly than A and T, because G and C form three bonds, whereas A and T form only two bonds. The implications of this simple biochemical complementarity are enormous; sadly, we don’t have time to go into all of that, but we leave you with Crick and Watson’s classic understatement in their original paper on the structure of DNA:</p>

<blockquote>
<p>It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material.</p>
</blockquote>

<p>Combine the concept of genes and the reality of DNA, and it turns out that the units we call genes correspond to fairly short regions that we delineate within immensely long strings of DNA. Those long strings of DNA are what make up our chromosomes, which most people recognize as the X-shaped squiggles in their high school biology textbooks. As illustrated in <a data-type="xref" href="#the_relationship_between_dnacomma_exons">Figure 2-1</a>, that X shape is a condensed form of the chromosome in which the DNA is tightly wound.</p>

<figure class="width-75"><div id="the_relationship_between_dnacomma_exons" class="figure"><img alt="The relationship between DNA, exons, introns, genes, and chromosomes." src="Images/gitc_0201.png" width="1440" height="868"/>
<h6><span class="label">Figure 2-1. </span>The chromosome (shown here in the form of two sister chromatids, each composed of one incredibly long molecule of double-stranded DNA) on which we delineate genes composed of exons and introns.</h6>
</div></figure>

<p>Like many other<a contenteditable="false" data-primary="diploid" data-type="indexterm" id="idm45625635598680"/> living creatures, human beings are <em>diploid</em>, which means that you have two copies of each chromosome: one inherited from each biological parent. As a result, you have two copies of every gene that is present on both chromosomes, which amounts to most of your genes. In a few cases, some genes might be present on one chromosome and absent from the other, but we won’t go into those here. <a contenteditable="false" data-primary="alleles" data-type="indexterm" id="idm45625635596632"/>For a given gene, your two copies are called <em>alleles</em>, and they’re typically not strictly identical in sequence to each other. If you produce a biological child, you pass on to them one chromosome from each of your 23 pairs and, accordingly, one of your two alleles for every gene. This concept of allele will be very important in the context of variant discovery, in which it will apply to individual variants instead of the overall gene.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Although the X-shaped form is their most common representation in popular media, our chromosomes don’t spend much time looking like that. Most of the time they are in a rod-shaped form called a chromatid.<a contenteditable="false" data-primary="chromatids" data-type="indexterm" id="idm45625635593288"/> When the single <em>chromatid</em> is copied ahead of a cell division event, the two identical chromatids are connected by a central region called the <em>centromere</em>, resulting in the popular X shape.<a contenteditable="false" data-primary="centromere" data-type="indexterm" id="idm45625635590920"/> Be careful not to confuse sister chromatids, which belong to the same chromosome, with the chromosome copies that you inherit from each biological parent.</p>
</div>

<p>If we look more closely at the span of a region of DNA that is defined as a gene, we see that the gene itself is split into smaller<a contenteditable="false" data-primary="exons" data-type="indexterm" id="idm45625635588600"/> regions <a contenteditable="false" data-primary="introns" data-type="indexterm" id="idm45625635587368"/>called <em>exons</em> and <em>introns</em>. When a particular gene is called into action, the exons are the parts that are going to <span class="keep-together">contribute</span> to its functionality, whereas the introns will be ignored. If you have a difficult time not mixing them up, try to remember that <em>ex</em>ons are the <em>ex</em>citing parts, and <em>in</em>trons are the bits <em>in</em> between.</p>

<p>All this suggests that genes are not really like the discrete particles that our forerunners originally envisioned. If anything, chromosomes are closer to being discrete units of inheritance, at least in the physical sense, given that each corresponds to an unbroken molecule of DNA. Indeed, many traits caused by different genes are inherited together because when you inherit one copy of a chromosome, there is a physical linkage between all the genes that it carries. Then again, the reality of chromosomal inheritance is more complex than you might expect. Just before the cell division that produces eggs and sperm cells, the parental chromosome copies pair up and swap segments with each other in a process called <em>chromosomal recombination</em>, which shuffles the combinations of physically linked traits that will be transmitted to the progeny.<a contenteditable="false" data-primary="chromosomal recombination" data-type="indexterm" id="idm45625635580872"/> Heads-up: biology is messy that way.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45625635579480">
<h5>Infinite Diversity in Infinite Combinations</h5>

<p><em>Diploidy</em> (the state of being diploid) might sound like the norm when you’re human (or even an animal in general), but many creatures have more interesting chromosomal lifestyles. For example, microorganisms such <a contenteditable="false" data-primary="haploid" data-type="indexterm" id="idm45625635577608"/>as bacteria are generally <em>haploid</em>, meaning they have only one copy of their chromosome, but they can have an array of <a contenteditable="false" data-primary="plasmids" data-type="indexterm" id="idm45625635575912"/>optional mini-chromosomes called <em>plasmids</em>. Fungi can be haploid or diploid at different stages of their life cycles.</p>

<p>As for plants—well, plants<a contenteditable="false" data-primary="polyploid organisms" data-type="indexterm" id="idm45625635573576"/> are the most open-minded of all, with abundant examples of <em>polyploid</em> plants such as bananas and some apples (<em>triploid</em>, 3 copies), potatoes (<em>tetraploid</em>, 4 copies), bread wheat (<em>hexaploid</em>, 6 copies), strawberries (<em>octaploid</em>, 8 copies), and some hybrids of sugar cane taking top prize (<em>dodecaploid</em>, 12 copies).</p>
</div></aside>

<p>Now that we have a handle on the basic terminology and mechanisms of genetic inheritance, let’s look into what genes actually do.<a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-startref="ix_genintrogen" data-tertiary="genes" data-type="indexterm" id="idm45625635568904"/><a contenteditable="false" data-primary="genes" data-startref="ix_gene" data-type="indexterm" id="idm45625635566984"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="The Central Dogma of Biology: DNA to RNA to Protein"><div class="sect2" id="the_central_dogma_of_biology_dna_to_rna">
<h2>The Central Dogma of Biology: DNA to RNA to Protein</h2>

<p>This central dogma is the next <a contenteditable="false" data-primary="DNA" data-secondary="DNA-to-RNA-to-protein" data-type="indexterm" id="ix_DNAto"/>level in our understanding of <a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-tertiary="DNA-to-RNA-to-protein" data-type="indexterm" id="ix_genintroDNAto"/>what genes are and how they work. The idea is that the “blueprint” information<a contenteditable="false" data-primary="proteins, synthesis of" data-secondary="DNA-to-RNA-to-protein dogma" data-type="indexterm" id="ix_protsyn"/> encoded in genes  in the form of DNA is transcribed into a closely<a contenteditable="false" data-primary="RNA (ribonucleic acid)" data-type="indexterm" id="idm45625635310216"/> related intermediate form called <em>ribonucleic acid</em>, or RNA, which our cells then use as a guide to string together amino acids into proteins. <a contenteditable="false" data-primary="DNA" data-secondary="difference from RNA" data-type="indexterm" id="idm45625635308376"/>The main differences between DNA and RNA are that RNA has one different nucleotide (uracil instead of thymine, but it still sticks to adenine) and it’s a lot less stable biochemically. You can think of DNA as the master blueprint, and RNA as working copies of sections of the master blueprint. Those working copies are what the cell will use to build proteins. These proteins range in function from structural components (e.g., muscle fiber) to metabolic agents (e.g., digestive enzymes) and ultimately act as both the bricks and bricklayers of our bodies.</p>

<p>The<a contenteditable="false" data-primary="gene expression" data-type="indexterm" id="idm45625635305784"/> process as a whole is called <em>gene expression</em> (see <a data-type="xref" href="#the_central_dogma_of_biology_dna_leads">Figure 2-2</a>). It makes a ton of sense and explains a lot—yet this is not the complete picture. As a description of <em>a</em> gene expression process, it would have been true, but for several decades the theory went on to state that this flow of information was strictly unidirectional and comprehensive. Yep, you guessed it: just like the gene concept, this turned out to be somewhat wrong. We have since discovered various ways in which life violates this long-held dogma: for example, through DNA-to-RNA-only as well as RNA-only pathways, which modify gene expression in a variety of fun and baffling ways. <a contenteditable="false" data-primary="nonribosomal protein synthesis" data-type="indexterm" id="idm45625635302088"/>Pathways also exist that lead to protein synthesis without the guidance of an RNA template, called <em>nonribosomal protein synthesis</em>, which some bacteria use to produce small molecules that play various roles such as intercellular signaling and microbial warfare (i.e., antibiotics). Again, keep in mind that reality is more complicated than the cartoon version, though the cartoon version is still useful to convey the most common relationship between the major players: DNA, RNA, amino acids, and proteins.</p>

<figure><div id="the_central_dogma_of_biology_dna_leads" class="figure"><img alt="The central dogma of biology: DNA leads to RNA; RNA leads to amino acids; amino acids lead to protein." src="Images/gitc_0202.png" width="1289" height="338"/>
<h6><span class="label">Figure 2-2. </span>The central dogma of biology: DNA leads to RNA; RNA leads to amino acids; amino acids lead to protein.</h6>
</div></figure>

<p>So how does that relationship work in practice? <a contenteditable="false" data-primary="amino acid chain, synthesis of" data-type="indexterm" id="idm45625635297208"/>How do you go from DNA sequence to the amino acids that make up the proteins? First, the transcription of DNA to RNA uses a neat biochemical trick: as we mentioned earlier, the nucleotides are complementary to one another—A sticks to T/U, and C sticks to G—thus, if you have <a contenteditable="false" data-primary="messenger RNA" data-type="indexterm" id="idm45625635295720"/>a string of DNA that reads <code>TACTTGATC</code>, the cell can generate a “messenger” RNA string by placing the appropriate (i.e., sticky) RNA base opposite each DNA base, to produce <code>AUGAACUAG</code>.<a contenteditable="false" data-primary="codons" data-type="indexterm" id="idm45625635293496"/> Then, it’s time for the genetic code to come into play: each set of three letters constitutes a <em>codon</em> that corresponds to an amino acid, as shown in <a data-type="xref" href="#the_genetic_code_connects_three_letter">Figure 2-3</a>. A cellular tool <a contenteditable="false" data-primary="ribosomes" data-type="indexterm" id="idm45625635290616"/>called a <em>ribosome</em> reads each codon and lines up the corresponding amino acid to add it to the chain, which will eventually become a protein. Our minimalist example sequence therefore codes for a very short amino acid chain: just methionine (AUG) followed by asparagine (AAC). The third codon (UAG) simply signals the ribosome to stop extending the chain.</p>

<figure><div id="the_genetic_code_connects_three_letter" class="figure"><img alt="The genetic code connects three-letter codons in a messenger RNA sequence to specific amino acids." src="Images/gitc_0203.png" width="1440" height="1055"/>
<h6><span class="label">Figure 2-3. </span>The genetic code connects three-letter codons in a messenger RNA sequence to specific amino acids.</h6>
</div></figure>

<p>We could explain a lot more about how all of this works, as it’s really quite fascinating, so we encourage you to look it up to learn more. For now, what we want to emphasize is the dependence of this mechanism on the DNA sequence: changing the sequence of the DNA can lead to changes in the amino acid sequence of the protein, which can affect its function.<a contenteditable="false" data-primary="proteins, synthesis of" data-secondary="DNA-to-RNA-to-protein dogma" data-startref="ix_protsyn" data-type="indexterm" id="idm45625635285896"/><a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-startref="ix_genintroDNAto" data-tertiary="DNA-to-RNA-to-protein" data-type="indexterm" id="idm45625635284232"/> So let’s talk about genetic changes.<a contenteditable="false" data-primary="DNA" data-secondary="DNA-to-RNA-to-protein" data-startref="ix_DNAto" data-type="indexterm" id="idm45625635282184"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="The Origins and Consequences of DNA Mutations"><div class="sect2" id="the_inevitability_of_change_and_its_con">
<h2>The Origins and Consequences of DNA Mutations</h2>

<p>DNA is pretty stable, but sometimes it breaks (e.g., because of exposure to radiation or chemicals) and needs to be repaired.<a contenteditable="false" data-primary="DNA" data-secondary="changes in" data-type="indexterm" id="idm45625635278440"/><a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-tertiary="change and its consequences" data-type="indexterm" id="idm45625635277064"/> The enzymes that are responsible for repairing these breaks occasionally make mistakes and incorporate the wrong nucleic acid (e.g., a T instead of an A). The same applies for the enzymes responsible for making copies of DNA during cell division; they make mistakes, and sometimes those mistakes persist and are transmitted to progeny. <a contenteditable="false" data-primary="genes" data-secondary="mutations in" data-type="indexterm" id="idm45625635274920"/><a contenteditable="false" data-primary="mutations" data-type="indexterm" id="idm45625635273544"/>Between these and other mechanisms of mutation that we won’t go into here, the DNA that each generation inherits from their parents diverges a little more over time. The overwhelming majority of these mutations do not have any functional effects, in part because some redundancy is present in the genetic code: you can change some letters without changing the meaning of the “word” that they spell out.</p>

<p>However, as illustrated in <a data-type="xref" href="#a_mutation_in_the_dna_sequence_can_caus">Figure 2-4</a>, some mutations do have effects that cause an alteration in gene function, gene expression, or related processes.<a contenteditable="false" data-primary="proteins, synthesis of" data-secondary="mutations and" data-type="indexterm" id="idm45625635270280"/> These effects might be positive; for example, improving the efficiency of an enzyme that degrades toxins and thereby protects your body from damage. Others will be negative; for example, reducing that same enzyme’s efficiency. Some changes might have dual effects depending on context; for example, one well-known example of a mutation contributes to sickle-cell disease but protects against malaria. Finally, some changes can have functional effects that are not obviously associated with a direct positive or negative outcome, like hair or eye color.</p>

<figure><div id="a_mutation_in_the_dna_sequence_can_caus" class="figure"><img alt="A mutation in the DNA sequence can cause the gene’s protein product to function abnormally or disable its production entirely." src="Images/gitc_0204.png" width="868" height="509"/>
<h6><span class="label">Figure 2-4. </span>A mutation in the DNA sequence can cause the gene’s protein product to function abnormally or disable its production entirely.</h6>
</div></figure>

<p>Again, this topic is vastly more complex than we show here; our goal is mainly to illustrate why we care so much about determining the exact sequence of people’s genomes.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Genomics as an Inventory of Variation in and Among Genomes"><div class="sect2" id="genomics_as_an_inventory_of_variation_i">
<h2>Genomics as an Inventory of Variation in and Among Genomes</h2>

<p>Now that we’ve gone over the fundamentals, we can step back and take another stab at defining genomics. <a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-tertiary="genomics as inventory of variation in/among genomes" data-type="indexterm" id="idm45625635263160"/>Let’s say the relationship <a contenteditable="false" data-primary="DNA" data-secondary="relationship between genes and" data-type="indexterm" id="idm45625635261352"/>between DNA<a contenteditable="false" data-primary="genes" data-secondary="relationship between DNA and" data-type="indexterm" id="idm45625635259832"/> and genes can be roughly summarized as “genes are made of DNA, but your DNA overall comprises both genes and nongenes.” This is an awkward formulation, so we’re going to use the term <em>genome</em> to refer to “your DNA overall.” But if genome means “all of your DNA including (but not limited to) your genes,” what should <em>genomics</em> encompass as “the science of genomes”?</p>

<p class="pagebreak-before">The<a contenteditable="false" data-primary="National Human Genome Research Institute (NHGRI)" data-type="indexterm" id="idm45625635256536"/> US-based <a href="https://oreil.ly/Fm7Tb">NHGRI website declares</a>:</p>

<blockquote>
<p>Genetics refers to the study of genes and the way that certain traits or conditions are passed down from one generation to another. Genomics describes the study of all of a person’s genes (the genome).</p>
</blockquote>

<p>The problem with that<a contenteditable="false" data-primary="genetics versus genomics" data-type="indexterm" id="idm45625635252920"/> definition (beyond the rather cavalier omission of “all the DNA that is not part of genes”) is that the minute you begin looking for something specific in the genome, it becomes a question of genetics. For example, out of all the human genome, what are the genes involved in the development of type 2 diabetes? Is that genomics or genetics? Technically you need to look at all of the genes first in order to narrow down your search to the genes that will be meaningful to your research. So the “some genes” versus “all the genes” distinction is a rather fuzzy one that is not entirely helpful, at least not in the context of our book. We therefore define genomics more narrowly as the discipline tasked with identifying the contents of genomes, whether at the level of individuals, families, or populations. In this view, the goal of genomics is to produce the information that feeds into the downstream genetic analyses that will ultimately yield biological insights.</p>

<p>This definition includes the process of identifying which genomic contents are specific to individuals, which are shared among individuals and populations, and which are different among individuals and populations. <a contenteditable="false" data-primary="transcriptomics" data-type="indexterm" id="idm45625635250056"/>A few related disciplines complement this subdivision, including <em>transcriptomics</em>, which is the study of gene expression at the genome scale. The term genomics is sometimes used as a catch-all <a contenteditable="false" data-primary="&quot;omics&quot;" data-primary-sortas="omics" data-type="indexterm" id="idm45625635248200"/>for these disciplines, though it has now become more common to use the more generic term <em>omics</em> for that purpose. We won’t go into the details of those either, except to note the points of connection when the opportunity arises.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>We can use <em>genome</em> in the individual sense (as in “my personal genome”) and in the collective sense (as in “the human genome”).</p>
</div>
</div></section>

<section data-type="sect2" data-pdf-bookmark="The Challenge of Genomic Scale, by the Numbers"><div class="sect2" id="the_challenge_of_genomic_scalecomma_by">
<h2>The Challenge of Genomic Scale, by the Numbers</h2>

<p>Approximately three billion base pairs are in a human genome, or three <em>gigabases</em> (GB), representing an enormous amount of biochemically encoded informational content. <a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-tertiary="challenge of genomic scale" data-type="indexterm" id="idm45625635242056"/>The technology we use to decipher this content generates hundreds of millions of very short sequences for a single genome. Specifically, about 40 million sequences of ~200 bases, which amounts to a 100 GB file per genome. If you do the math, you’ll realize that this dataset is redundant by a factor of 30 times! This is intentional, because the data is full of errors—some random, some systematic—so we need the redundancy to have enough confidence in our findings. Within that mass of data that is redundant but full of errors, we need to identify the four to five million small differences that are real (relative to a reference framework, which we discuss in the next section). That information can then be used to perform the genetic analysis that will determine which differences actually matter to a particular research question. Oh, and that’s for just one person; but we might want to apply this to cohorts of hundreds, thousands, tens of thousands of people, or more. (Spoiler alert: definitely more.)</p>

<p>Given the scale involved, we’re going to need some very robust procedures for analyzing this data. But before we begin tackling the computational methods, let’s take a deeper look at the topic of genomic variation to define more precisely what we’re going to be looking for.<a contenteditable="false" data-primary="genomics" data-secondary="introduction to" data-startref="ix_genintro" data-type="indexterm" id="idm45625635238408"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Genomic Variation"><div class="sect1" id="genomic_variation">
<h1>Genomic Variation</h1>

<p><em>Genomic variation</em> can take multiple forms and can arise at different times in the life cycles of organisms and populations. <a contenteditable="false" data-primary="genomic variation" data-type="indexterm" id="ix_genvar"/>In this section, we review the way variants are described and classified. We begin by discussing the concept of a reference genome that is used as a common framework for cataloging variants. Then, we go over the three major classes of variants that are defined on the basis of the physical change that is involved: short sequence variants, copy-number variants, and structural variants. Finally, we discuss the difference between germline variants and somatic alterations, and where <em>de novo</em> mutations fit into the picture.</p>

<section data-type="sect2" data-pdf-bookmark="The Reference Genome as Common Framework"><div class="sect2" id="the_reference_genome_as_common_framewor">
<h2>The Reference Genome as Common Framework</h2>

<p>When it comes to comparing variation<a contenteditable="false" data-primary="genomic variation" data-secondary="reference genome as common framework" data-type="indexterm" id="idm45625635229368"/> between genomes, whether it’s between cells or tissues of the same individual, or between individuals, families, or entire populations, almost all analyses rely on using a common genome reference sequence.</p>

<p>Why? Let’s look at a similar, if simpler problem. We have three modern-day sentences that we know evolved from a common ancestor:</p>

<ol>
	<li>
	<p>The quick brown f<em>a</em>x jumped over the lazy dog<em>e</em>.</p>
	</li>
	<li>
	<p>The quick <em>_</em> fox jumped over the<em>ir</em> lazy dog<em>e</em>.</p>
	</li>
	<li>
	<p>The quick brown fox jump<em>s</em> over the lazy <em>brown</em> dog.</p>
	</li>
</ol>

<p>We’d like to inventory their differences in a way that is not biased toward any single one of them, and is robust to the possibility of adding new mutant sentences as we encounter them. So we create a synthetic hybrid that encapsulates what they have most in common, yielding this:</p>

<blockquote>
<p>The quick brown fox jumped over the lazy doge.</p>
</blockquote>

<p>We can use this as a common reference coordinate system against which we can plot what is different (if not necessarily unique) in each mutant:</p>

<ol>
	<li>
	<p>Fourth word, o → a substitution; ninth word, deleted <em>e</em></p>
	</li>
	<li>
	<p>Third word deleted; seventh word, added <em>ir</em>; ninth word, added <em>e</em></p>
	</li>
	<li>
	<p>Fifth word ed → s substitution; duplication of the third word located after the eighth word</p>
	</li>
</ol>

<p>It’s obviously not a perfect method, and what it gives us is not the true ancestral sentence: we suspect that’s not how <em>dog</em> was originally spelled, and we’re unsure of the original tense (<em>jumps</em> versus <em>jumped</em>). But it enables us to distinguish what is commonly observed in the population we have access to from what is divergent.</p>

<p>The more sentences we can involve in the initial formulation of this reference and the more representative the sampling, the more appropriate it will be for describing the variations we encounter in the future.</p>

<p>Similarly, we use a reference genome<a contenteditable="false" data-primary="reference genome" data-type="indexterm" id="idm45625635211064"/> in order to chart sequence variation in individuals against a common standard rather than attempting to chart differences between genome sequences relative to one another. That enables us to identify what subset of variations in sequence are commonly observed versus unique to particular samples, individuals, or populations.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="reference_genome_format_fasta">
<h5>Reference Genome Format: FASTA</h5>

<p>The <a contenteditable="false" data-primary="FASTA (reference genome format)" data-type="indexterm" id="idm45625635207336"/>standard format currently used for <a contenteditable="false" data-primary="reference genome" data-secondary="FASTA format" data-type="indexterm" id="idm45625635206056"/>reference genome is <a href="https://oreil.ly/RbeV3">FASTA</a>, which is generally pronounced “fast-ay” in English (rather than “fast-ah”). FASTA is a fairly simple text format in which all segments of contiguous sequence in a genome, referred to as <em>contigs</em>, can be contained in a single file. <a contenteditable="false" data-primary="contigs" data-type="indexterm" id="idm45625635203160"/>Each contig record in a FASTA file consists of a description line that starts with an angle bracket and the name of the contig, plus some optional metadata, and one or more lines of sequence, as follows:</p>

<pre data-type="programlisting">
&gt;my_contig some_metadata
ATTCGCGAGGATATAAGGATATAGGATA
GGATATTCGCGCCCTATATAGAGATTCG</pre>

<p>Genome references in FASTA format are generally accompanied by two accessory files: a dictionary file (<em>.dict</em>) and an index file (<em>.fai</em>), which allow analysis tools to access specific positions in the reference sequence without having to load the entire file into memory. Note that FASTA can also be used beyond genome references to store other kinds of DNA, RNA, or protein sequences.</p>
</div></aside>

<p>So whose genome do we use as a common framework? In the simplest case, any individual genome can be used as a reference genome. However, our analysis will produce better results if we can use a reference genome that is representative of the widest group of individuals that we might want to study.</p>

<p>That leads to a complicated problem: for our reference to be representative of many individuals, we need to evaluate the most commonly observed sequence across available individual genomes, which we call a <em>haplotype</em>, for each segment of the genome reference.<a contenteditable="false" data-primary="haplotypes" data-type="indexterm" id="idm45625635197624"/> Then, we can use that information to compose a synthetic hybrid sequence. The result is a sequence that is never actually observed wholesale in any particular individual genome.</p>

<p>Researchers are trying to address these limitations using more advanced representations of genomes, such as graphs for which nodes represent different possible sequences, and edges between them allow you to trace a given genome. <a contenteditable="false" data-primary="Human Genome Project (HGP)" data-type="indexterm" id="idm45625635195544"/>However, for the purposes of our analysis presented in this book, we use a high-quality reference genome derived from the efforts of the scientific community starting with the Human Genome Project (HGP).</p>

<p>It’s important to understand that the effectiveness of the common reference is limited by the diversity of the original samples used in its development.<a contenteditable="false" data-primary="reference genome" data-secondary="published by HGP" data-type="indexterm" id="idm45625635193528"/> When the HGP was declared complete in 2003, the genome sequence that the HGP consortium published was, in fact, a synthetic reference based on a very small number of people, all from European background. This limited its effectiveness as a reference for non-European populations because, as we learned later, some of these populations have substantial enough differences that cannot be adequately mapped back to the original Euro-centric reference.</p>

<p>Successive “versions” of the human genome reference, commonly called <em>assemblies</em> or <em>builds</em>, have been published since then.<a contenteditable="false" data-primary="assemblies or builds (human genome)" data-type="indexterm" id="idm45625635190280"/> In addition to delivering higher quality through purely technological advances, these updates to the common genome reference have also increased its representativeness by including more data from historically underrepresented populations. It is worth emphasizing that these efforts to compensate for historical bias in the selection of participants in genomic studies are very necessary.<a contenteditable="false" data-primary="reference genome" data-secondary="increasing its representativeness" data-type="indexterm" id="idm45625635188584"/> Indeed, lack of representation in research data leads to real inequalities in clinical outcomes because it affects our ability to identify meaningful variation in an individual’s genome sequence if that person belongs to an underrepresented population.</p>

<p>In humans, the most significant improvements to date have been made in the representation of so-called <em>alternate haplotypes</em>, regions that are sometimes dramatically different in different populations. <a contenteditable="false" data-primary="haplotypes" data-secondary="alternate" data-type="indexterm" id="idm45625635185624"/><a contenteditable="false" data-primary="alternate haplotypes" data-type="indexterm" id="idm45625635184248"/>The latest build of the human reference genome, officially named <em>GRCh38</em> (for Genome Research Consortium human build 38) but commonly nicknamed <em>Hg38</em> (for human genome build 38), greatly expanded the repertoire of alternate (ALT) contigs representing the alternate haplotypes. <a contenteditable="false" data-primary="contigs" data-secondary="alternate, representing alternate haplotypes" data-type="indexterm" id="idm45625635181864"/>These have a significant impact on our power to detect and analyze genomic variation that is specific to populations carrying alternate haplotypes.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45625635180104">
<h5>The Reference Genome Version Conundrum</h5>

<p>Although the gradual improvements to the human reference genome are absolutely beneficial and necessary, the existence of these different builds is a common source of confusion and errors for many researchers.<a contenteditable="false" data-primary="reference genome" data-secondary="existence of different builds, problems with" data-type="indexterm" id="idm45625635178584"/> To make matters worse, there existed for some time two parallel streams of reference genome evolution, named <em>hg*</em> versus <em>b*</em>, published by<a contenteditable="false" data-primary="hg* versus b* streams of reference genome" data-type="indexterm" id="idm45625635175960"/> different groups, with different naming conventions, some differences in sequences, and inclusion of different noncanonical contigs. Many bioinformatics tools fail to enforce consistent use of a specific reference, which allows the unwary user to switch reference genomes halfway through a project without realizing that their comparisons suddenly become worthless, because, for example, all the positions are silently shifted by some coordinate index.</p>

<p>In our book, we use the older b37 reference in some exercises, and the newer hg38 reference in others.<a contenteditable="false" data-primary="hg38 reference genome" data-type="indexterm" id="idm45625635150200"/><a contenteditable="false" data-primary="b37 reference genome" data-type="indexterm" id="idm45625635149096"/> This is in part for the convenience of using previously existing materials, but also because the older reference is still widely used; thus we feel it’s important to be aware of their coexistence and practice dealing with different <span class="keep-together">references</span>.</p>
</div></aside>

<p>As a final plot twist, note that all current standard reference genome sequences are <em>haploid</em>, meaning they represent only one copy of each chromosome (or contig). <a contenteditable="false" data-primary="reference genome" data-secondary="haploid sequences" data-type="indexterm" id="idm45625635145544"/>The most immediate consequence is that in <em>diploid</em> organisms such as humans, which have two copies of each <a contenteditable="false" data-primary="autosomes" data-type="indexterm" id="idm45625635143544"/>autosome (i.e., any chromosome that is not a sex chromosome, X or Y), the choice of standard representation of sites that are most often <a contenteditable="false" data-primary="heterozygous state" data-type="indexterm" id="idm45625635142072"/>observed in <em>heterozygous</em> state (manifesting two different alleles; e.g., A/T) is largely arbitrary.<a contenteditable="false" data-primary="polyploid organisms" data-secondary="and haploid reference genome sequences" data-type="indexterm" id="idm45625635140392"/> This is obviously even worse in <em>polyploid</em> organisms, such as many plants including wheat and strawberries, which have higher numbers of chromosome copies. Although it is possible <a contenteditable="false" data-primary="graphs" data-secondary="representations of reference genomes" data-type="indexterm" id="idm45625635138344"/>to represent reference genomes using <a href="https://oreil.ly/5BiFo">graph-based representations</a>, which would address this problem, few genome analysis tools are able to handle such representations at this time, and it will likely take years before graph-based genomes gain traction in the field.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Physical Classification of Variants"><div class="sect2" id="physical_classification_of_variants">
<h2>Physical Classification of Variants</h2>

<p>Now that we have a framework for describing variation, let’s talk about the kinds of variation we’ll be considering.<a contenteditable="false" data-primary="genomic variation" data-secondary="physical classificaion of variants" data-type="indexterm" id="ix_genvarclass"/> We distinguish three major classes of variants based on the physical change they represent, which are illustrated in <a data-type="xref" href="#the_major_types_of_variant_classified_b">Figure 2-5</a>. <em>Short sequence variants</em> (single-base changes and small insertions or deletions) are<a contenteditable="false" data-primary="short sequence variants" data-type="indexterm" id="idm45625635130920"/> small changes in DNA sequence compared to a reference genome; c<em>opy-number variants</em> are relative changes in the amount <a contenteditable="false" data-primary="copy-number variants" data-type="indexterm" id="idm45625635129192"/>of a particular fragment of DNA; and <em>structural variants</em> are changes<a contenteditable="false" data-primary="structural variants" data-type="indexterm" id="idm45625635127496"/> in the location or orientation of a particular fragment of DNA compared to a reference genome.</p>

<figure><div id="the_major_types_of_variant_classified_b" class="figure"><img alt="The major types of variant classified by physical changes to the DNA." src="Images/gitc_0205.png" width="1440" height="627"/>
<h6><span class="label">Figure 2-5. </span>The major types of variant classified by physical changes to the DNA.</h6>
</div></figure>

<section data-type="sect3" data-pdf-bookmark="Single-nucleotide variants"><div class="sect3" id="single_nucleotide_variants">
<h3>Single-nucleotide variants</h3>

<p>Earlier, we<a contenteditable="false" data-primary="short sequence variants" data-secondary="single-nucleotide" data-type="indexterm" id="idm45625635122024"/> examined the<a contenteditable="false" data-primary="single-nucleotide variants (SNVs)" data-type="indexterm" id="idm45625635120488"/> hybrid sentence: “The quick brown fox jumped over the lazy doge.” Within the list of three sentences, the first sentence used <em>fax</em> instead of <em>fox</em>. Here we might say there was a single-letter substitution in the word fox, where the <em>o</em> was substituted with an <em>a</em> because the “reference” says <em>fox</em>.<a contenteditable="false" data-primary="SNVs" data-see="single-nucleotide variants" data-type="indexterm" id="idm45625635116904"/></p>

<p>When we apply this to DNA sequence—for example, when we encounter a G nucleotide instead of the A we expect based on the reference—we’ll call it a <em>single-nucleotide</em> variant (<a data-type="xref" href="#single-nucleotide">Figure 2-6</a>). Some variation exists in the exact terminology used to refer to these variants, and appropriately enough, the difference is a single-letter substitution: depending on <a contenteditable="false" data-primary="single-nucleotide polymorphisms (SNPs)" data-type="indexterm" id="idm45625635113144"/>context, we’ll call them either <em>single-nucleotide polymorphism</em> (SNP; pronounced “snip”), which is most appropriate in population genetics, or <em>single-nucleotide variant</em> (SNV; usually spelled out but sometimes pronounced “sniv”), which is more general in meaning yet is mostly used in cancer genomics.<a contenteditable="false" data-primary="SNPs" data-see="single-nucleotide polymorphism" data-type="indexterm" id="idm45625635110840"/></p>

<figure class="width-50"><div id="single-nucleotide" class="figure"><img alt="Single-nucleotide variants." src="Images/gitc_0206.png" width="1084" height="384"/>
<h6><span class="label">Figure 2-6. </span>A single-nucleotide variant.</h6>
</div></figure>

<p>SNVs are the most common type of variation encountered in nature because the various mechanisms that cause them are fairly commonplace and their consequences are often minimal. Biological functions tend to be robust to such small changes because, as we saw earlier in our overview, the genetic code has multiple codons that code for the same amino acid, so single base changes don’t always lead to changes in the <span class="keep-together">protein.</span></p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Insertions and deletions"><div class="sect3" id="insertions_and_deletions">
<h3>Insertions and deletions</h3>

<p>In the second sentence of <a contenteditable="false" data-primary="short sequence variants" data-secondary="insertions and deletions (indels)" data-type="indexterm" id="idm45625635104008"/>our example, “The quick <em>_</em> fox jump<em>s</em> over the<em>ir</em> lazy dog<em>e</em>,” we see the two primary types of small insertions and deletions: we’ve lost the word <em>brown</em>, and one instance of <em>the</em> has become <em>their</em> through the insertion of two letters. <a contenteditable="false" data-primary="insertions and deletions" data-see="indels" data-type="indexterm" id="idm45625635098872"/>We also have one complex substitution in the replacement of <em>jumped</em> by <em>jumps</em>, which is interesting because without additional information we can’t say whether the change happened in a single event, <em>ed</em> becoming <em>s</em>, or whether the <em>ed</em> was lost first and the <em>s</em> was tacked on later. Or, the original ancestor of both <em>jumped</em> and <em>jumps</em> could have been <em>jump</em>, and both forms evolved later through independent insertions! That latter scenario seems more likely because it involves a simpler chain of events, but we can’t know for sure without seeing more data.</p>

<p>Applied to DNA sequence, <em>indels</em> are insertions or<a contenteditable="false" data-primary="indels" data-type="indexterm" id="idm45625635092328"/> deletions of one or more bases compared to the reference sequence, as shown in <a data-type="xref" href="#indels_can_be_insertions">Figure 2-7</a>. Interestingly, multiple studies have reported that insertions occur more commonly than deletions (at least in humans). <a contenteditable="false" data-primary="deletions (DNA sequences)" data-type="indexterm" id="idm45625635089800"/>This observation has not been fully explained but could be related to naturally occurring mobile genetic elements, a kind of molecular parasite that is fascinating but sadly out of scope for this book.</p>

<figure><div id="indels_can_be_insertions" class="figure"><img alt="Indels can be insertions (left) or deletions (right)." src="Images/gitc_0207.png" width="1440" height="257"/>
<h6><span class="label">Figure 2-7. </span>Indels can be insertions (left) or deletions (right).</h6>
</div></figure>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The term <em>indel</em> is a portmanteau created by combining <em>in</em>sertion and <em>del</em>etion.</p>
</div>

<p>Most indels observed in nature are fairly short, measuring less than 10 bases in length, but there is no maximum length of sequence than can be inserted or deleted. In practice, indels longer than a few hundred bases are generally classified as copy-number or structural variants, which we discuss next. Compared to single-nucleotide changes, indels are more likely to disrupt biological function, because they are more likely to cause phase shifts, where adding or removing bases shifts the three-letter reading frame used by the ribosome to read the codons. This can completely change the meaning of the sequence downstream of the indel. They can also cause protein folding changes when inserted into coding regions, for example.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Copy-number variants"><div class="sect3" id="copy_number_variants">
<h3>Copy-number variants</h3>

<p>With <em>copy-number variation</em> (<a data-type="xref" href="#example_of_copy_number_variant_caused_b">Figure 2-8</a>), we’re moving<a contenteditable="false" data-primary="copy-number variants" data-secondary="about" data-type="indexterm" id="idm45625635079112"/> into a <a contenteditable="false" data-primary="genomic variation" data-secondary="physical classificaion of variants" data-tertiary="copy-number variants" data-type="indexterm" id="idm45625635077608"/>more complex territory because the game is no longer just a matter of playing “spot the difference.” Previously, the question was “What do I see at this location?” Now it shifts to “How many copies do I see of any given region?” For example, the third sentence in our evolved text example, “The quick brown fox jump<em>s</em> over the lazy <em>brown</em> dog” has two copies of the word <em>brown</em>.</p>

<figure><div id="example_of_copy_number_variant_caused_b" class="figure"><img alt="Example of copy-number variant caused by a duplication." src="Images/gitc_0208.png" width="624" height="102"/>
<h6><span class="label">Figure 2-8. </span>Example of copy-number variant caused by a duplication.</h6>
</div></figure>

<p>In the biological context, if you imagine that each word is a gene that produces a protein, this means that we could produce twice as much “Brown” protein from this sentence’s DNA compared to the other two. That could be a good thing if the protein in question has, for instance, a protective effect against exposure to dangerous chemicals. But it could also be a bad thing if the amount of that protein present in the cell affects the production of another protein: increasing one could upset the balance of the other and cause a deleterious chain reaction that disrupts cellular processes.</p>

<p>Another<a contenteditable="false" data-primary="allelic ratio, alteration of" data-type="indexterm" id="idm45625635070936"/> case is the alteration of <em>allelic ratio</em>, the balance between two forms of the same gene. Imagine that you inherited a defective copy of a particular gene, which is supposed to repair damaged DNA, from your father, but it’s OK because you inherited a functional copy from your mother. That single functional copy is sufficient to protect you, because it makes enough protein to repair any damage to your DNA. Great. Now imagine that you have a for-now benign tumor in which one part suffers a copy-number event: it loses the functional copy from your mom, and now all you have is your dad’s broken copy, which is unable to produce the DNA repair protein. Those cells are no longer able to repair any DNA breaks (which can happen randomly) and begin to accumulate mutations. Eventually, that part of the tumor starts proliferating and becomes cancerous. Not so great.</p>

<p>These are called <em>dosage effects</em> and <a contenteditable="false" data-primary="dosage effects" data-type="indexterm" id="idm45625635067528"/>illustrate the biological complexity of genetic pathways that regulate cell metabolism and health. The DNA copy number can affect biological function in other ways, and in all cases the degree of severity of the effects depends on a lot of factors.</p>

<p>As an example, <em>trisomies</em> are genetic disorders in which patients have an extra copy of an entire chromosome. <a contenteditable="false" data-primary="trisomies" data-type="indexterm" id="idm45625635064904"/>The most well-known is Down syndrome, which is caused by an extra copy of chromosome 21.<a contenteditable="false" data-primary="Down’s Syndrome" data-type="indexterm" id="idm45625635063560"/> It is associated with multiple intellectual and <span class="keep-together">physical</span> disabilities, but the people who carry them can live healthy and productive lives if they are supported appropriately.<a contenteditable="false" data-primary="sex chromosomes, trisomies affecting" data-type="indexterm" id="idm45625635061448"/> Trisomies affecting sex chromosomes (X and Y) tend to have fewer negative consequences; for example, most individuals with triple X syndrome experience no medical issues as a result. In contrast, several trisomies affecting other chromosomes are tragically incompatible with life and always result in either miscarriage or early infant death.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Structural variants"><div class="sect3" id="structural_variants">
<h3>Structural variants</h3>

<p>This last class of<a contenteditable="false" data-primary="structural variants" data-secondary="examples of" data-type="indexterm" id="idm45625635058072"/> variants is a superset<a contenteditable="false" data-primary="genomic variation" data-secondary="physical classificaion of variants" data-tertiary="structural variants" data-type="indexterm" id="idm45625635056536"/> that includes copy-number variants and large indels in addition to various copy-neutral structural alterations such as translocations and inversions, as shown in <a data-type="xref" href="#examples_of_structural_variantsdot">Figure 2-9</a>.</p>

<figure><div id="examples_of_structural_variantsdot" class="figure"><img alt="Examples of structural variants." src="Images/gitc_0209.png" width="1220" height="977"/>
<h6><span class="label">Figure 2-9. </span>Examples of structural variants.</h6>
</div></figure>

<p>As you can see from the examples in <a data-type="xref" href="#examples_of_structural_variantsdot">Figure 2-9</a>, <em>structural variants</em> can be rather complex because they cover a range of physical transformations of the genetic material. Some can span large distances, even affecting multiple chromosomes in some cases. We won’t cover structural variation in this book because this is still an area of very active development and the relevant methods are far from settled.<a contenteditable="false" data-primary="genomic variation" data-secondary="physical classificaion of variants" data-startref="ix_genvarclass" data-type="indexterm" id="idm45625635049512"/></p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Germline Variants Versus Somatic Alterations"><div class="sect2" id="germline_variants_versus_somatic_alter">
<h2>Germline Variants Versus Somatic Alterations</h2>

<p>The fundamental biological distinction between germline variants and somatic alterations has major <a contenteditable="false" data-primary="genomic variation" data-secondary="germline variants versus somatic alterations" data-type="indexterm" id="ix_genvargvs"/>consequences for the way we approach variant discovery, depending on the specific purpose of the analysis. Wrapping your head around this can be a bit tricky because it’s tied to concepts of inheritance and embryo development. Let’s start from the definitions of the terms <em>germline</em> and <em>somatic</em>.</p>

<section data-type="sect3" data-pdf-bookmark="Germline"><div class="sect3" id="germline">
<h3>Germline</h3>

<p>The term <em>germline</em> is a combination of two related aspects of biological inheritance. <a contenteditable="false" data-primary="germline variants" data-type="indexterm" id="idm45625635040152"/>The <em>germ</em> part refers to the concept of germination of a seed, and doesn’t have anything to do directly with microbes, although it’s the same idea that causes us to call microbes <em>germs.</em> The <em>line</em> part refers to the fact that all cells that eventually turn into either eggs or sperm cells come from a single <em>cell line</em>, a population of cells with a common ancestor that get differentiated early in the development of the embryo.</p>

<p>In fact, the term <em>germline</em> is often used to refer to that entire population of cells as <em>the germline</em> of an individual. So in principle, your germline variants are variants that were present in your biological parents’ germline cells, <em>typically</em> the egg and/or sperm cell that produced you, before fertilization happened. As a result, your germline variants are expected to be present in every cell in your body. In practice, variants that arise very shortly after fertilization will be difficult or impossible to distinguish from germline variants.</p>

<p>Researchers are interested in germline variants for a variety of reasons: diagnosing diseases with a genetic component, predicting risk of developing disorders, understanding the origin of physical traits, mapping the origins and evolution of human populations—and that’s just on the human side! Germline variation within populations of organisms is also of great interest in agriculture, livestock improvement, ecological research, and even epidemiological monitoring of microbial <span class="keep-together">pathogens</span>.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Somatic"><div class="sect3" id="somatic">
<h3>Somatic</h3>

<p>The term <em>somatic</em> is<a contenteditable="false" data-primary="somatic alterations" data-type="indexterm" id="idm45625635030264"/> derived from the Greek word <em>soma</em>, meaning <em>body.</em> It’s used as an exclusionary term to refer to all cells that are not part of the germline, as illustrated in <a data-type="xref" href="#germline_variants_versus_somatic_altera">Figure 2-10</a>. Somatic alterations are produced by mutation events in individual cells during the course of your life (including during embryo development, prior to birth), and are present only in subsets of cells in your body.</p>

<p>These mutations can be caused by a variety of factors, from genetic predispositions to environmental exposure to mutagens such as radiation, cigarette smoke, and other harmful chemicals. A great many of these mutations arise in your body but stay confined to one or a few cells and cause no noticeable effects. In some cases, the mutations can cause domino effects within the affected cells, damaging their ability to regulate growth and causing the formation of a cell tumor. Many tumors are thankfully benign; however, some become malignant and cause negative chain reactions, fueling the occurrence of many additional somatic mutations and resulting in metabolic diseases, which we ultimately group under the label of <em>cancer</em>.<a contenteditable="false" data-primary="somatic alterations" data-secondary="versus germline variants" data-secondary-sortas="germline" data-type="indexterm" id="idm45625635025448"/><a contenteditable="false" data-primary="germline variants" data-secondary="versus somatic alterations" data-secondary-sortas="somatic" data-type="indexterm" id="idm45625635023800"/></p>

<figure><div id="germline_variants_versus_somatic_altera" class="figure"><img alt="Germline variants versus somatic alterations." src="Images/gitc_0210.png" width="1440" height="1717"/>
<h6><span class="label">Figure 2-10. </span>Germline variants are present in all cells of the body (left) while somatic alterations are present only in a subset of cells (right).</h6>
</div></figure>

<p>That being said, even though cancer research is one of the major applications of somatic variation analysis, the effects of somatic variation are not limited to tumor growth and cancer. They<a contenteditable="false" data-primary="Down’s Syndrome" data-secondary="somatic alterations and" data-type="indexterm" id="idm45625635019448"/> also include various developmental disorders such as Down syndrome, which, as we alluded to earlier, is caused by an erroneous duplication of chromosome 21; in other words, a form of CNV. Although Down syndrome can be inherited through the germline, it is most commonly observed as the result of an abnormal cell division event that occurs early on during the development of the embryo. Most of the time this happens so early that virtually all of the individual’s cells are affected.</p>

<p>This is where the line between germline variation and somatic alteration becomes a bit blurry. As we’ve just discussed, you can have a child born with a variant that arose very early on during their development. As far as its origin is concerned, it’s a somatic alteration; however, in the analysis of your child’s genome, it will manifest as a germline variant because it’s present in all of their cells. Along similar lines, you can get somatic mutations within your germline cells during the course of your life; for example, if something goes wrong during the cell division that produces an egg or sperm cell. The resulting variants are clearly somatic in origin, but if you go on to have a child who develops from one of the affected cells, that child will carry the new variants in all cells in their body. And so those variants will be germline variants as far as the child is concerned; doubly so, given that in this case they’ll have inherited them from you. In both cases, we qualify those variants as <em>de novo variants</em> from the Latin <em>de novo</em> meaning “newly arisen,” because in the child they appear to have come out of nowhere. <a contenteditable="false" data-primary="de novo variants" data-type="indexterm" id="idm45625635015016"/>In this book, we treat early somatic mutations as germline mutations.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="terminology_variant_versus_polymorphism">
<h5>Variant, Polymorphism, Alteration, and Mutation</h5>

<p>The terminology <a contenteditable="false" data-primary="genomic variation" data-secondary="terminology, variant, polymorphism, alteration, and mutation" data-type="indexterm" id="idm45625635011992"/>in the field of variant discovery is not completely <a contenteditable="false" data-primary="variant discovery" data-secondary="terminology differences in" data-type="indexterm" id="idm45625635010344"/>settled (especially on the somatic side of the fence), so you might encounter inconsistencies in the literature. In this book, we apply the usages that we have encountered most frequently and believe to be most established, as summarized here:</p>

<ul>
	<li>
	<p>The term <em>variant</em> is the most generic term that can be substituted for all the <span class="keep-together">others</span>.<a contenteditable="false" data-primary="variants" data-type="indexterm" id="idm45625635006072"/></p>
	</li>
	<li>
	<p>For short variants, we use the well-established SNP for germline single-base variants, and SNV for somatic single-base variants. <a contenteditable="false" data-primary="polymorphism" data-type="indexterm" id="idm45625627878184"/>The term <em>polymorphism</em> refers to a concept from population genetics and relies on the assumption that these are naturally occurring variants that are present in a population.</p>
	</li>
	<li>
	<p>For copy number variation, we use CNV (<em>V</em> for variant) for germline variants and CNA (<em>A</em> for alteration) for somatic variants, for which the term <em>alteration</em> emphasizes that these variants result from recent modification events.</p>
	</li>
	<li>
	<p>For structural variation, we use SV (<em>V</em> for variant) for both germline and somatic variants.</p>
	</li>
	<li>
	<p>So far, we have not encountered any usage of single-nucleotide alteration or <em>structural alteration</em> for somatic single-base and structural variants even though that would be the most logical specialized term to use.<a contenteditable="false" data-primary="alterations" data-type="indexterm" id="idm45625627871096"/></p>
	</li>
	<li>
	<p>Finally, we note that many use the term <em>mutations</em> to refer<a contenteditable="false" data-primary="mutations" data-secondary="use of term in this book" data-type="indexterm" id="idm45625627868648"/> generically to somatic variants, but we restrict our use of that term to refer only to the modification events themselves.<a contenteditable="false" data-primary="genomic variation" data-secondary="germline variants versus somatic alterations" data-startref="ix_genvargvs" data-type="indexterm" id="idm45625627866904"/><a contenteditable="false" data-primary="genomic variation" data-startref="ix_genvar" data-type="indexterm" id="idm45625627865160"/></p>
	</li>
</ul>
</div></aside>
</div></section>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="High-Throughput Sequencing Data Generation"><div class="sect1" id="high_throughput_sequencing_data_generat">
<h1>High-Throughput Sequencing Data Generation</h1>

<p>Now that we know<a contenteditable="false" data-primary="high-throughput sequencing" data-type="indexterm" id="ix_hithse"/> what we’re looking for, let’s talk about how we’re going to generate the data that will allow us to identify and characterize variants: <em>high-throughput sequencing</em>.</p>

<p>The technology we use to sequence DNA has evolved dramatically since the pioneering work of Allan Maxam, Walter Gilbert, and Fred Sanger. A lot of ink, electronic or otherwise, has been spent on classifying the <a href="https://oreil.ly/159S1">successive waves, or generations, of sequencing techniques</a>. The most widely used technology today is <em>short read</em> sequencing-by-synthesis <a contenteditable="false" data-primary="short read sequencing" data-type="indexterm" id="idm45625627857528"/>popularized<a contenteditable="false" data-primary="Illumina short read sequencing" data-type="indexterm" id="idm45625627856296"/> by Illumina, which produces very large numbers of <em>reads</em>; that is strings of DNA sequence (originally approximately 30 bases, now going up to roughly 250 bases).<a contenteditable="false" data-primary="next-generation sequencing (NGS)" data-type="indexterm" id="idm45625627854456"/> This is often called <em>next-generation sequencing</em> (NGS) in contrast to the original <em>Sanger sequencing</em>. <a contenteditable="false" data-primary="Sanger sequencing" data-type="indexterm" id="idm45625627852328"/>However, that term has arguably become obsolete with the development of newer “third-generation” technologies that are based on different biochemical mechanisms and typically generate longer reads.</p>

<p>So far, these new technologies are not a direct replacement for Illumina short read sequencing, which still dominates the field for resequencing applications, but some such as PacBio and Oxford Nanopore have become well established for applications like <em>de novo</em> genome assembly that prioritize read length. <a contenteditable="false" data-primary="PacBio DNA sequencing" data-type="indexterm" id="idm45625627849800"/><a contenteditable="false" data-primary="de novo genome assembly" data-type="indexterm" id="idm45625627848696"/><a contenteditable="false" data-primary="Oxford Nanopore sequencing" data-type="indexterm" id="idm45625627847592"/><a contenteditable="false" data-primary="Nanopore sequencing" data-type="indexterm" id="idm45625627846472"/>Nanopore, in particular, is also increasingly popular for point-of-care and fieldwork applications because of the availability of a pocket-size version, the MinION, which can be used with minimal training and connects to a laptop through a USB port. <a contenteditable="false" data-primary="MinION sequencing" data-type="indexterm" id="idm45625627844968"/>Although the MinION device cannot produce the kind of throughput required for routine analysis of human and other large genomes, it is well suited for applications like microbial detection for which smaller yields are sufficient.</p>

<p>Exciting developments have also occurred in the field of single-cell sequencing, in which microfluidics devices are used to isolate and sequence the contents of individual cells. <a contenteditable="false" data-primary="single-cell sequencing" data-type="indexterm" id="idm45625627842888"/>These are generally focused on RNA with the goal of identifying biological phenomena such as differences in gene expression patterns between tissues. Here, we focus on classic Illumina-style short read DNA sequencing for the sake of simplicity, but we encourage you to check out the latest developments in the field.</p>

<section class="pagebreak-before" data-type="sect2" data-pdf-bookmark="From Biological Sample to Huge Pile of Read Data"><div class="sect2" id="from_biological_sample_to_huge_pile_of">
<h2 class="less_space">From Biological Sample to Huge Pile of Read Data</h2>

<p>So how do we sequence someone’s DNA using short read technology? <a contenteditable="false" data-primary="high-throughput sequencing" data-secondary="library preparation" data-type="indexterm" id="idm45625627838600"/>First we need to collect biological material (most commonly blood or a cheek swab) and extract the DNA. Then, we “prepare a DNA library,” which involves shredding whole DNA into fairly small fragments and then preparing these fragments for the sequencing process.<a contenteditable="false" data-primary="exome sequencing" data-secondary="versus whole genome sequencing" data-secondary-sortas="whole" data-type="indexterm" id="idm45625627836760"/><a contenteditable="false" data-primary="whole genome sequencing" data-secondary="versus exome sequencing" data-secondary-sortas="exome" data-type="indexterm" id="idm45625627835096"/> At this stage, we need to choose whether to sequence the whole genome or just a subset. When we talk, for example, about <em>whole genome sequencing</em> versus <em>exome sequencing</em>, what differs isn’t the <em>sequencing technology</em>, but the <em>library preparation</em>: the way the <a contenteditable="false" data-primary="library preparation" data-see="DNA libraries" data-type="indexterm" id="idm45625627831448"/>DNA is prepared for sequencing. We go over the main types of libraries and their implications for analysis in the next section. For now, let’s assume that we can retrieve all of the DNA fragments that we want to sequence; we then add molecular tags for tracking and adapter sequences that will make the fragments stick in the correct place in the sequencing flowcell, as illustrated in <a data-type="xref" href="#library_preparation_processdot">Figure 2-11</a>.</p>

<figure><div id="library_preparation_processdot" class="figure"><img alt="Library preparation process." src="Images/gitc_0211.png" width="1440" height="453"/>
<h6><span class="label">Figure 2-11. </span>Library preparation process for bulk DNA (top); alternative pathway for bulk RNA (bottom).</h6>
</div></figure>

<p>The <em>flowcell</em> is a sort of glass slide with fluidic channels in which the sequencing chemistry takes place when the appropriate reagents are pumped through it in cycles. During that process, which you can learn more about in Illumina’s <a href="https://www.illumina.com">online documentation</a>, the sequencing machine uses lasers and cameras to detect the light emitted by individual nucleotide binding reactions. Each nucleotide corresponds to a specific wavelength, so by capturing the images produced from each reaction cycle, the machine can read out strings of bases <a contenteditable="false" data-primary="Illumina short read sequencing" data-secondary="overview of" data-type="indexterm" id="idm45625627824392"/>called <em>reads</em> from each fragment of DNA that is stuck to the flowcell, as illustrated in <a data-type="xref" href="#overview_of_illumina_short_read_sequenc">Figure 2-12</a>.</p>

<figure><div id="overview_of_illumina_short_read_sequenc" class="figure"><img alt="Overview of Illumina short read sequencing." src="Images/gitc_0212.png" width="1440" height="288"/>
<h6><span class="label">Figure 2-12. </span>Overview of Illumina short read sequencing.</h6>
</div></figure>

<p>Typically, the reactions are set up to produce one read from each end of each DNA fragment, and the resulting data remains associated as read pairs. As you’ll see later in this chapter, having pairs of reads per fragment rather than single reads gives us information that can be useful in several ways.</p>

<section data-type="sect3" data-pdf-bookmark="High-throughput sequencing data formats"><div class="sect3" id="high_throughput_sequencing_data_formats">
<h3>High-throughput sequencing data formats</h3>

<p>The data generated by the Illumina sequencer <a contenteditable="false" data-primary="high-throughput sequencing" data-secondary="data formats" data-type="indexterm" id="idm45625627816552"/>is initially stored on the machine in a format called Basecall (BCL), but you don’t normally interact with that format directly.<a contenteditable="false" data-primary="Basecall (BCL) data format" data-type="indexterm" id="idm45625627814888"/> Most sequencers<a contenteditable="false" data-primary="FASTQ data format" data-type="indexterm" id="idm45625627813640"/> are configured to output <a href="https://oreil.ly/NbFcD">FASTQ</a>, a straightforward if voluminous text file format that holds the name of each read (often called <em>queryname</em>), its sequence and the corresponding string of base quality scores in Phred-scaled <a contenteditable="false" data-primary="Phred scale data format" data-type="indexterm" id="idm45625627811160"/>form, as illustrated in <a data-type="xref" href="#fastq_and_phred_scaledot">Figure 2-13</a>.</p>

<figure><div id="fastq_and_phred_scaledot" class="figure"><img alt="FASTQ and Phred scale." src="Images/gitc_0213.png" width="1440" height="475"/>
<h6><span class="label">Figure 2-13. </span>FASTQ and Phred scale.</h6>
</div></figure>

<p>The <em>Phred scale</em> is a log-based scale for expressing very small quantities such as probabilities and likelihoods in a form that is more intuitive than the original decimal number; most Phred-scaled values we’ll encounter are between 0 and 1,000 and rounded to the nearest integer.</p>

<p>When the read data is mapped to a reference genome, it is transformed into <a href="https://oreil.ly/1fqR5">Sequence Alignment Map</a> (SAM), the format<a contenteditable="false" data-primary="SAMs (Sequence Alignment Maps)" data-type="indexterm" id="idm45625627804488"/> of choice for <em>mapped</em> read <a contenteditable="false" data-primary="Sequence Alignment Maps" data-see="SAMs" data-type="indexterm" id="idm45625627802808"/>data because it can hold mapping and alignment information, as illustrated in <a data-type="xref" href="#key_elements_of_the_sam_format_file_hea">Figure 2-14</a>. It can additionally hold a variety of other important metadata that <span class="keep-together">analysis</span> programs might need to add on top of the sequence itself.<a contenteditable="false" data-primary="Sequence Alignment Maps" data-see="SAMs" data-type="indexterm" id="idm45625627799384"/> Like FASTQ, SAM is a <a href="https://oreil.ly/QPcIK">structured text file format</a>, and because it holds more information, those files can become very large indeed. You’ll generally<a contenteditable="false" data-primary="compression" data-secondary="FASTQ and SAM data formats" data-type="indexterm" id="idm45625627796968"/> encounter both formats in their compressed forms; FASTQ is typically simply compressed using the gzip utility, whereas SAM can be compressed using specialized utilities into either <a contenteditable="false" data-primary="BAMs (Binary Alignment Maps)" data-secondary="SAM format compressed into" data-type="indexterm" id="idm45625627795240"/>Binary Alignment Map (BAM) or CRAM, which <a contenteditable="false" data-primary="CRAMs" data-secondary="SAM format compressed into" data-type="indexterm" id="idm45625627793640"/>offers additional degrees of lossy compression.</p>

<figure><div id="key_elements_of_the_sam_format_file_hea" class="figure"><img alt="Key elements of the SAM format: file header and read record structure." src="Images/gitc_0214.png" width="1462" height="716"/>
<h6><span class="label">Figure 2-14. </span>Key elements of the SAM format: file header and read record structure.</h6>
</div></figure>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Unlike SAM and BAM, CRAM is not a real acronym; it was so named to follow the SAM/BAM naming pattern and as a play on the verb <em>to cram,</em> but the <em>CR</em> does not spell out to anything <span class="keep-together">meaningful</span>.</p>
</div>

<p>In the SAM/BAM/CRAM format, the read’s local alignment is encoded in the Concise Idiosyncratic Gapped Alignment Report (CIGAR) string. <a contenteditable="false" data-primary="CIGAR (Concise Idiosyncratic Gapped Alignment Report)" data-secondary="strings describing structure of read alignment" data-type="indexterm" id="idm45625627786808"/>Yes, someone really wanted it to spell out <em>CIGAR</em>. Briefly, this system uses single-letter operators to represent the alignment relationship of one or more bases to the reference with a numerical prefix that specifies how many positions the operator describes in such a way that the detailed alignment can be reconstructed based solely on the starting position information, the sequence, and the CIGAR string.</p>

<p>For example, <a data-type="xref" href="#the_cigar_string_describes_the_structur">Figure 2-15</a> shows a read that starts with one soft-clipped (ignored) base (1S), then four matching positions (4M), one deletion gap (1D), another two matches (2M), one insertion gap (1I), and, finally, one last match (1M). Note that this is a purely structural description that is not intended to describe sequence content: in the first stretch of matches (4M), the third base does not match the reference, so all it means is that “there is a base in position 4.”</p>

<figure><div id="the_cigar_string_describes_the_structur" class="figure"><img alt="The CIGAR string describes the structure of the read alignment." src="Images/gitc_0215.png" width="1300" height="821"/>
<h6><span class="label">Figure 2-15. </span>The CIGAR string describes the structure of the read alignment.</h6>
</div></figure>

<p>Let’s come back briefly to that soft clip shown in <a data-type="xref" href="#the_cigar_string_describes_the_structur">Figure 2-15</a>, which we qualified as “ignored.” Soft clips happen at the beginning and/or at the end of a read when the mapper isn’t able to align one or more bases to its satisfaction. <a contenteditable="false" data-primary="high-throughput sequencing" data-secondary="soft clips, read data and" data-type="indexterm" id="idm45625627778696"/><a contenteditable="false" data-primary="soft clips" data-type="indexterm" id="idm45625627777320"/>The mapper basically gives up and uses the soft clip symbol to indicate that those bases do not align to the reference and should be ignored in downstream analysis. As you’ll see in <a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a>, some of the data that ends up in soft clips is recoverable and can be useful.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Technically, it is possible to store read data in BAM format without including mapping information, as we describe in <a data-type="xref" href="ch06.xhtml#best_practices_for_germline_short_varia">Chapter 6</a>.</p>
</div>

<p>Note that the long-term storage of large amounts of sequence data is a problem that preoccupies large sequencing centers and many funding agencies, and has prompted various groups to propose alternative formats to FASTQ and SAM/BAM/CRAM. However, none has so far managed to gain traction with the wider community.</p>

<p>The amount of read data produced for a single experiment varies according to the type of library as well as the target coverage of the experiment.<a contenteditable="false" data-primary="target coverage" data-type="indexterm" id="idm45625627771176"/> <em>Coverage</em> is a metric that summarizes the number of reads overlapping a given position of the reference genome. Roughly, this rolls up to the number of copies of the original DNA <span class="keep-together">represented</span> in the DNA library.<a contenteditable="false" data-primary="DNA libraries" data-secondary="target coverage and" data-type="indexterm" id="idm45625627768616"/> If this confuses you, remember that the library preparation process involves shredding DNA isolated from many cells in a biological sample, and the shredding is done randomly (for most library preparation techniques), so for any given position in the genome, we expect to obtain read pairs from multiple overlapping fragments.</p>

<p>Speaking of libraries, let’s take a closer look at our options on that front.</p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Types of DNA Libraries: Choosing the Right Experimental Design"><div class="sect2" id="types_of_dna_libraries_choosing_the_bes">
<h2>Types of DNA Libraries: Choosing the Right Experimental Design</h2>

<p>There are about as many ways to prepare DNA libraries as there are molecular biology reagents companies.<a contenteditable="false" data-primary="high-throughput sequencing" data-secondary="DNA libraries, choosing right experimental design" data-type="indexterm" id="ix_hithselib"/><a contenteditable="false" data-primary="DNA libraries" data-secondary="choosing the right experimental design" data-type="indexterm" id="ix_DNAlib"/> Generally, though, we can distinguish three main approaches that determine the genomic territory made available to sequencing and the major technical properties of the resulting data: <em>amplicon generation</em>, <em>whole genome preparation</em>, and <em>target enrichment</em>, which is used to produce gene panels and exomes, as depicted in <a data-type="xref" href="#experimental_design_comparisondot">Figure 2-16</a>.</p>

<figure><div id="experimental_design_comparisondot" class="figure"><img alt="Experimental design comparison." src="Images/gitc_0216.png" width="1440" height="1025"/>
<h6><span class="label">Figure 2-16. </span>Experimental design comparison between whole genome (top) and exome (bottom).</h6>
</div></figure>

<p>The whole genome library shown in <a data-type="xref" href="#experimental_design_comparisondot">Figure 2-16</a> will lead to sequence coverage across all regions (exon, intron and intergenic), while the exome library will only lead to coverage across the targeted regions, typically corresponding to exons.</p>

<section data-type="sect3" data-pdf-bookmark="Amplicon preparation"><div class="sect3" id="amplicon_preparation">
<h3>Amplicon preparation</h3>

<p>This family of DNA preparation <a contenteditable="false" data-primary="DNA libraries" data-secondary="choosing the right experimental design" data-tertiary="amplicon preparation" data-type="indexterm" id="idm45625627752968"/>techniques relies on<a contenteditable="false" data-primary="polymerase chain reaction (PCR) amplification" data-type="indexterm" id="idm45625627751032"/> classic polymerase chain reaction (PCR) amplification (either using specifically designed primers or using restriction enzyme sites) to<a contenteditable="false" data-primary="amplicon preparation" data-type="indexterm" id="idm45625627749576"/> produce <em>amplicons</em>, fragments of DNA present in large numbers of copies that start and stop at the same positions. This means that the territory made available for sequencing is typically very small and dependent on the starting and stopping points we predetermine with our primers or restriction enzymes.</p>

<p>This approach is fairly economical for small-scale experiments and does not require a reference genome, making it a popular option for the study of nonmodel organisms. However, it produces data with enormous PCR-related technical biases. As a result, this approach lends itself very poorly to variant discovery analysis when done with the GATK and related tools; thus, we don’t cover it further in this book.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Whole genome preparation"><div class="sect3" id="whole_genome_preparation">
<h3>Whole genome preparation</h3>

<p>As the name implies, the goal of whole genome preparation is to sequence the entire genome. <a contenteditable="false" data-primary="whole genome sequencing" data-secondary="whole genome preparation for variant discovery analysis" data-type="indexterm" id="idm45625627744792"/><a contenteditable="false" data-primary="DNA libraries" data-secondary="choosing the right experimental design" data-tertiary="whole genome preparation" data-type="indexterm" id="idm45625627743384"/>It involves putting the DNA through a mechanical shearing process that rips it into a multitude of small fragments and then “filtering” the fragments based on their size to keep only those within a certain range, typically 200 to 800 base pairs. Because a DNA sample contains many copies of the genome and the shearing process is random, we expect that the resulting fragments will be tiled redundantly across the entire genome. If we sequence each fragment once, we should see every base in the genome multiple times.</p>

<p>In practice, some parts of the genome are still very difficult to make available to the sequencing process. Within our cells, our DNA isn’t simply floating around, loosely unfurled; much of it is tightly rolled up and packaged with protein complexes. We can relax it to a point with biochemical persuasion, but some areas remain quite difficult to “liberate.” In addition, some parts of the chromosomes<a contenteditable="false" data-primary="centromere" data-type="indexterm" id="idm45625627740136"/> such as the centromere (the middle bit) and telomeres (the bits at the ends) contain vast stretches of highly repetitive DNA that is difficult to sequence and assemble faithfully. <a contenteditable="false" data-primary="telomeres" data-type="indexterm" id="idm45625627738712"/>The human genome reference is actually incomplete in those areas, and specialized techniques are necessary to probe them. All this to say, when we talk about whole genome sequencing, we mean all of the parts that we can readily access. Nevertheless, even with those limitations, the amount of territory covered by whole genome sequencing is <span class="keep-together">enormous</span>.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Target enrichment: gene panels and exomes"><div class="sect3" id="target_enrichment_gene_panels_and_exome">
<h3>Target enrichment: gene panels and exomes</h3>

<p>Target enrichment approaches are an attempt at a best-of-both-worlds solution: they allow us to focus on<a contenteditable="false" data-primary="target coverage" data-secondary="target enrichment in DNA sequencing" data-type="indexterm" id="idm45625627733976"/> the subset of the genome<a contenteditable="false" data-primary="DNA libraries" data-secondary="choosing the right experimental design" data-tertiary="target enrichment, gene panels and exomes" data-type="indexterm" id="idm45625627732504"/> that we care about, but in a way that is more efficient than amplicon techniques and, to some extent, less prone to technical issues. Briefly, the first step is the same as for whole genome preparation: the genome is sheared into fragments, but then the fragments are filtered not based on size but on whether they match a location we care about. This involves using <em>bait</em> sequences, which are designed very much like PCR primers but immobilized on a surface to <em>capture</em> targets of interest, typically a subset of genes (for gene panels) or all annotated exons (for exomes). <a contenteditable="false" data-primary="exomes" data-secondary="capturing all annotated exons in DNA sequencing" data-type="indexterm" id="idm45625627729176"/><a contenteditable="false" data-primary="gene panels" data-type="indexterm" id="idm45625627727768"/>The result is that we produce patches of data that can inform us about only those regions that we managed to capture.</p>

<p>One often overlooked downside of this very popular approach is that the manufacturers of commercial kits for generating panel and exome data use different sets of baits, sometimes with important differences in the targeted regions, as illustrated in <a data-type="xref" href="#different_exome_preparation_kits_can_le">Figure 2-17</a>. This causes batch effects and makes it more difficult to compare the results of separate experiments that used different target regions.</p>

<figure><div id="different_exome_preparation_kits_can_le" class="figure"><img alt="Different exome preparation kits can lead to important differences in coverage location and quantity." src="Images/gitc_0217.png" width="1440" height="758"/>
<h6><span class="label">Figure 2-17. </span>Different exome preparation kits can lead to important differences in coverage location and quantity.</h6>
</div></figure>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p><em>Exome sequencing</em> is sometimes referred to as <em>Whole Exome Sequencing</em> (WES) out of a misguided attempt to contrast it with <em>Whole Genome Sequencing</em> (WGS). It’s misguided, because the contrast is already in the name: the point of the exome is that it’s a <em>subset</em> of the whole genome. Calling it the whole exome is simply unnecessary and arguably inaccurate, to boot.</p>
</div>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Whole genome versus exome"><div class="sect3" id="whole_genome_versus_exome">
<h3>Whole genome versus exome</h3>

<p>So which one is better?<a contenteditable="false" data-primary="DNA libraries" data-secondary="choosing the right experimental design" data-tertiary="whole genome versus exome" data-type="indexterm" id="idm45625627095160"/> The most balanced thing we can say is that these approaches yield qualitatively and quantitatively different information, and each comes with specific limitations.<a contenteditable="false" data-primary="exome sequencing" data-secondary="versus whole genome sequencing" data-secondary-sortas="whole" data-type="indexterm" id="idm45625627093128"/><a contenteditable="false" data-primary="whole genome sequencing" data-secondary="versus exome sequencing" data-secondary-sortas="exome" data-type="indexterm" id="idm45625627091464"/> Exome sequencing has proved extremely popular because for a long time it was much cheaper and faster than genomes, and for many common <span class="keep-together">applications</span> such as clinical diagnostics, it was usually sufficient to provide the necessary information. However, this approach suffers from substantial technical issues, including reference bias and unevenness of coverage distribution, which introduce many confounding factors into downstream analyses.<a contenteditable="false" data-primary="WGS" data-see="whole genome sequencing" data-type="indexterm" id="idm45625627088536"/></p>

<p>From a purely technical perspective, the data produced by WGS is superior to targeted datasets. It also empowers us to discover biologically important sequence conformations that lurk in the vast expanses of genomic territory that do not encode genes. Thanks to falling costs, whole genome sequencing is now becoming popular, though the downside is that the much larger amount of data produced is more challenging to manage. For example, a standard human exome sequenced at 50X coverage takes about 5 GB to store in BAM format, whereas the same person’s whole genome sequenced at 30X coverage takes about 120 GB.</p>

<p>If you have not worked with exomes or whole genomes before, the difference between them can seem a bit abstract when we’re talking about amounts of data, file sizes, and coverage distributions. It can be really helpful to look at a few files in a genome browser to see what this means in practice. As shown in <a data-type="xref" href="#visual_appearance_of_whole_genome_seque">Figure 2-18</a>, the whole genome sequencing data is distributed almost uniformly across the genome, whereas the exome sequencing data is concentrated in localized piles. If you look at the coverage track in the genome viewer, you’ll see the coverage profile for the whole genome looks like a distant mountain range, whereas the profile for the exome looks like a volcanic island in the middle of a flat ocean. This is an easy and surprisingly effective way to distinguish the two data types by the naked eye. We show you how to view sequencing data in the Integrated Genome Viewer (IGV) in <a data-type="xref" href="ch04.xhtml#first_steps_in_the_cloud">Chapter 4</a>.</p>

<figure><div id="visual_appearance_of_whole_genome_seque" class="figure"><img alt="Visual appearance of whole genome sequence (WGS, top) and exome sequencing (bottom) in a genome browser." src="Images/gitc_0218.png" width="1440" height="590"/>
<h6><span class="label">Figure 2-18. </span>Visual appearance of whole genome sequence (WGS, top) and exome sequence (bottom) in a genome browser.</h6>
</div></figure>

<p>Most of the exercises in this book use whole genome sequencing data, but we also provide pointers to resources for analyzing exome data, and in <a data-type="xref" href="ch14.xhtml#making_a_fully_reproducible_paper">Chapter 14</a> we go through a case study involving exomes.<a contenteditable="false" data-primary="high-throughput sequencing" data-secondary="DNA libraries, choosing right experimental design" data-startref="ix_hithselib" data-type="indexterm" id="idm45625627079144"/><a contenteditable="false" data-primary="DNA libraries" data-secondary="choosing the right experimental design" data-startref="ix_DNAlib" data-type="indexterm" id="idm45625627077368"/><a contenteditable="false" data-primary="high-throughput sequencing" data-startref="ix_hithse" data-type="indexterm" id="idm45625627075704"/></p>
</div></section>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Data Processing and Analysis"><div class="sect1" id="data_processing_and_analysis">
<h1>Data Processing and Analysis</h1>

<p>Finally, we get to the computational part! <a contenteditable="false" data-primary="data processing and analysis" data-type="indexterm" id="ix_DPan"/>Now, you might think that as soon as we have the sequence data in digital form, the real fun begins. However, there is a twist: the data produced by the sequencers is not directly usable for variant discovery analysis: it’s a huge pile of short reads, and we don’t know where they came from in the original genome. In addition, there are sources of bias and errors that are likely to cause problems in downstream analysis if left untreated. So we’re going to need to apply a few preprocessing steps before we can get to the genomic analysis proper. First, we map the read data to a reference genome and then we apply a couple of data cleanup operations to correct for technical biases and make the data suitable for analysis. Next, we’ll finally be able to apply our variant discovery analysis workflows. In this section, we go over the core concepts involved in genome mapping (aka alignment) and variant calling, but we leave the rest for <a data-type="xref" href="ch06.xhtml#best_practices_for_germline_short_varia">Chapter 6</a>. We also touch briefly on data quality issues that can interfere in variant discovery analysis.</p>

<section data-type="sect2" data-pdf-bookmark="Mapping Reads to the Reference Genome"><div class="sect2" id="mapping_reads_to_the_reference_genome">
<h2>Mapping Reads to the Reference Genome</h2>

<p>Ideally, we’d like to reconstruct<a contenteditable="false" data-primary="data processing and analysis" data-secondary="mapping reads to reference genome" data-type="indexterm" id="ix_DPanmp"/> the entire genome of the individual we’re working on to compare it to the reference, but we don’t<a contenteditable="false" data-primary="reference genome" data-secondary="mapping reads to" data-type="indexterm" id="ix_refgenmp"/> have the sample in one piece—it’s more like a million pieces, as illustrated in <a data-type="xref" href="#concept_of_aright_parenthesis_what_is_t">Figure 2-19</a>!</p>

<p>Well, actually <a contenteditable="false" data-primary="Lander-Waterman equation" data-type="indexterm" id="idm45625627061592"/>360 million for a standard 30X WGS, and 30 million for a standard 50X Exome, according to the <a href="https://oreil.ly/NCMd4">Lander-Waterman equation</a>. It’s quite the jigsaw puzzle. And, by the way, the pieces overlap 30 to 50 times (depending on target depth).</p>

<p>So the goal of the mapping step is to match each read to a specific stretch of the reference genome. The output is a BAM file that has mapping and alignment information encoded in each read record, as described in <a data-type="xref" href="#high_throughput_sequencing_data_generat">“High-Throughput Sequencing Data Generation”</a>.</p>

<figure><div id="concept_of_aright_parenthesis_what_is_t" class="figure"><img alt="Concept of A) what is the information we’re trying to extract from the data versus, B) what we actually have in practice." src="Images/gitc_0219.png" width="1440" height="720"/>
<h6><span class="label">Figure 2-19. </span>Sequence divergence introduces mapping challenges and ambiguity.</h6>
</div></figure>

<p>This is often called <em>alignment</em> because it outputs<a contenteditable="false" data-primary="alignment information for reads" data-type="indexterm" id="idm45625627054568"/> detailed alignment information for each read, but it is arguably more appropriate to call it <em>mapping</em>.<a contenteditable="false" data-primary="mapping information for reads" data-type="indexterm" id="idm45625627052808"/> Genome mapping algorithms are primarily designed to solve that fundamental problem of identifying the best matching location for a very small string of letters (typically ~150 to ~250) against an enormously huge one (about three billion for humans, not counting alternate contigs). Among other neat tricks, this involves using a scoring system that penalizes gaps. However, this has drawbacks when it comes to producing the fine-grained letter-by-letter alignment. The mapper works on one read at a time, so it is not well equipped to deal with naturally occurring sequence features like large insertions and deletions, and it will often prefer to clip sequences off the end of a read rather than introduce a large indel. We look at an example of this in <a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a> when we introduce GATK and its <a contenteditable="false" data-primary="HaplotypeCaller" data-type="indexterm" id="idm45625627049800"/>flagship germline short variant caller, <code>HaplotypeCaller</code>. What is important to understand at this point is that we trust the mapper to place the reads in the appropriate places most of the time, but we can’t always trust the exact sequence alignments it produces.</p>

<p>As noted in <a data-type="xref" href="#concept_of_aright_parenthesis_what_is_t">Figure 2-19</a>, an additional complication is that some genomic regions are copies of ancestral regions that were duplicated. The sequence of copies may be more or less divergent depending on how long ago the duplication happened and how many other mutation events produced variants in the copies. This makes the mapper’s job more difficult because the existence of competing copies introduces <span class="keep-together">ambiguity</span> as to where a particular read might belong. <a contenteditable="false" data-primary="paired-end sequencing" data-type="indexterm" id="idm45625627045144"/>Thankfully, most short read sequencing is now done using paired-end sequencing, which helps resolve ambiguity by providing additional information to the mapper. <a contenteditable="false" data-primary="short read sequencing" data-secondary="using paired-end sequencing" data-type="indexterm" id="idm45625627043736"/>Based on the protocol used for library preparation, we know that we can expect DNA fragments to be within a certain size range, so the mapper can evaluate the likelihood of possible mapping <span class="keep-together">locations</span> based on the distance between the two reads in the pair, as shown in <a data-type="xref" href="#paired_end_sequencing_helps_resolve_map">Figure 2-20</a>. This does not apply for long-read sequencing technologies such as PacBio and Oxford Nanopore, for which the longer length of the reads typically leaves less opportunity for ambiguity by reading all the way through repeat regions.</p>

<figure><div id="paired_end_sequencing_helps_resolve_map" class="figure"><img alt="Paired-end sequencing helps resolve mapping ambiguity." src="Images/gitc_0220.png" width="1440" height="498"/>
<h6><span class="label">Figure 2-20. </span>Paired-end sequencing helps resolve mapping ambiguity.</h6>
</div></figure>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Fragments of DNA generated during library preparation are sometimes called <em>inserts</em> because older <a contenteditable="false" data-primary="plasmids" data-secondary="insertion of DNA fragments into" data-type="indexterm" id="idm45625627036664"/>preparation techniques involved inserting each fragment into a small circular piece of DNA called a <em>plasmid</em>. As a result, the relevant quality-control metric is usually called <em>insert size</em> even though nowadays the library preparation no longer involves insertion into plasmid vectors.<a contenteditable="false" data-primary="insert size metric" data-type="indexterm" id="idm45625627033976"/></p>
</div>

<p>As noted a moment ago, a few other processing steps are needed to clean up the aligned data before we would normally move on to variant calling. We cover them later; for now, it’s time to finally tackle the beast that is going to follow us through just about every chapter in this book.<a contenteditable="false" data-primary="data processing and analysis" data-secondary="mapping reads to reference genome" data-startref="ix_DPanmp" data-type="indexterm" id="idm45625627032024"/><a contenteditable="false" data-primary="reference genome" data-secondary="mapping reads to" data-startref="ix_refgenmp" data-type="indexterm" id="idm45625627030344"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Variant Calling"><div class="sect2" id="variant_calling">
<h2>Variant Calling</h2>

<p>The term <em>variant calling</em> is thrown around a lot and is sometimes used to refer to the entire variant discovery process. <a contenteditable="false" data-primary="variant calling" data-type="indexterm" id="ix_varcall"/><a contenteditable="false" data-primary="data processing and analysis" data-secondary="variant calling" data-type="indexterm" id="ix_DPanVC"/>Here we’re defining it narrowly as the specific step in which we identify potential variants by looking for evidence of a particular type of variation in the available sequence data. The output of this step is a raw callset, or set of calls, in which each call is an individual record for a potential variant, describing its position and various properties. The standard format for this is the VCF, which we describe in the next sidebar.</p>

<aside class="pagebreak-before less_space" data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="variant_data_format_vcf">
<h5>Variant Data Format</h5>

<p>The standard format for variant data is <em>Variant Call Format</em> (VCF), as shown in <a data-type="xref" href="#basic_structure_of_the_vcfdot">Figure 2-21</a>. It’s a tab-separated columnar text format in which each variant is represented on one line, indexed by its genomic location. The first eight columns describe variant-level information, including its positional information as well as a list of reference and alternate alleles observed at that position. The last variant-level column aggregates arbitrary annotations (defined in the header) as a single string of elements separated by semicolons. The most commonly encountered annotations are variant context statistics that describe the quality of the evidence supporting the variant call and functional predictions of variant effect. Sample-specific information is stored in additional columns; one column encoding a sequence of keys for retrieving field values and then one subsequent column per sample, with no upper limit on the number of samples that can theoretically be included.</p>

<figure class="no-frame"><div id="basic_structure_of_the_vcfdot" class="figure"><img alt="Basic structure of the VCF." src="Images/gitc_0221.png" width="1440" height="562"/>
<h6><span class="label">Figure 2-21. </span>Basic structure of a VCF file.</h6>
</div></figure>

<p>You will have ample opportunity throughout the book to work with VCF files and get to know the format, so we won’t go into it further here. For more immediate reading, see the <a href="https://oreil.ly/iKicj">VCF documentation</a> on the GATK website.</p>
</div></aside>

<p>The nature of the evidence we use to identify variants is different depending on the type of variant we’re looking for.</p>

<p>For short sequence variants (SNVs and indels), we’re comparing the specific bases in short stretches of sequence. In principle, it’s quite straightforward: we produce a pileup of reads, compare them to the reference sequence, and identify where there are mismatches. Then we simply count the numbers of reads supporting each allele to determine genotype: if it’s half and half, the sample is heterozygous; if it’s all one or the other, the sample is homozygous reference or homozygous variant. For example, the IGV screenshot in <a data-type="xref" href="#pileup_of_reads_in_igv_showing_several">Figure 2-22</a> shows a probable 10-base deletion (left), a <span class="keep-together">homozygous</span> variant SNP (middle right), and a heterozygous variant SNP (rightmost) in whole genome sequence data.</p>

<figure><div id="pileup_of_reads_in_igv_showing_several" class="figure"><img alt="Pileup of reads in IGV showing several probably short variants." src="Images/gitc_0222.png" width="1440" height="993"/>
<h6><span class="label">Figure 2-22. </span>Pileup of reads in IGV showing several probable short variants.</h6>
</div></figure>

<p>For copy-number variants, we’re looking at the relative number of sequence reads produced across multiple regions. Again, it’s a fairly simple reasoning on the surface: if a region of the genome is duplicated in a sample, when we go to sequence that sample, we’re going to generate twice as many reads that align to that region, as demonstrated in <a data-type="xref" href="Images/#relative_amounts_of_coverage_provide_ev">Figure 2-23</a>.</p>

<p>And for structural variants, we’re looking at a combination of both base-pair resolution sequence comparisons as well as relative amounts of sequence.</p>

<figure><div id="relative_amounts_of_coverage_provide_ev" class="figure"><img alt="Relative amounts of coverage provide evidence for copy number modeling." src="Images/gitc_0223.png" width="1155" height="560"/>
<h6><span class="label">Figure 2-23. </span>Relative amounts of coverage provide evidence for copy-number modeling.</h6>
</div></figure>

<p>In practice, the process for identifying each of the variant types confidently is rather more complicated than the simple logic that we just outlined, largely because of various sources of error and uncertainty that muddy the waters, which we touch on shortly. That’s why we’ll want to apply more robust statistical approaches that take various sources of error into account; some through empirically derived heuristics, and others through modeling processes that do not require prior knowledge of what kinds of errors might be present in the data.</p>

<p>We can rarely say definitively, “this call is correct” or “this call is an error,” so we express results in probabilistic terms. For each variant call output by the program, the caller will assign scores that represent how confident we can be in the result. In the earlier indel example, the variant quality (QUAL) score of 50 means “there is a 0.001% chance that this variant is not real” and the genotype quality (GT) score of 17 for the second sample means “there is a 1.99% chance that this genotype assignment is incorrect.” (We cover the distinction between variant quality and genotype quality in more detail in <a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a>.)</p>

<p>Variant calling tools typically use some internal cutoffs to determine when to emit a variant call or not emit one depending on these scores. This avoids cluttering the output with calls that are grossly unlikely to be real. However, it’s important to understand that those cutoffs are usually designed to be very permissive in order to achieve a high degree of sensitivity. This is good because it minimizes the chance of missing real variants, but it does mean that we should expect the raw output to still contain a number of false positives—and that number can be quite large. For that reason, we need to filter the raw callset before proceeding to further downstream analysis.</p>

<p>Filtering variants is ultimately a classification problem: we’re trying to distinguish variants that are more likely to be real from those that are more likely to be artifacts. The more clearly we can make this distinction, the better chance we have of eliminating most of the artifacts without losing too many real variants. Therefore, we’ll <span class="keep-together">evaluate</span> every filtering method based on how favorable a trade-off it enables us to make, expressed in terms of sensitivity, or recall (percentage of the real variants that we’re able to identify), and specificity, or precision (the percentage of the variants we called that are actually real), as depicted in <a data-type="xref" href="#cheatsheet_of_variant_metricsdot">Figure 2-24</a>.</p>

<figure><div id="cheatsheet_of_variant_metricsdot" class="figure"><img alt="Cheatsheet of variant metrics." src="Images/gitc_0224.png" width="1440" height="1213"/>
<h6><span class="label">Figure 2-24. </span>Cheat sheet of variant metrics.</h6>
</div></figure>

<p>There are many approaches to filtering variants, and the choice of what is appropriate depends not only on the variant class we’re looking at, but also on the type and quality of the prior knowledge we have about genomic variation in the organism we study. For example, in humans we have extensive catalogs of variants that have been previously identified and validated, which we can use as a basis for filtering variant calls in new samples, so we can use modeling approaches that rely on the availability of training data from that same organism. In contrast, if we’re looking at a nonmodel organism that is being studied for the very first time, we do not have that luxury and will need to fall back on other methods.<a contenteditable="false" data-primary="variant calling" data-startref="ix_varcall" data-type="indexterm" id="idm45625626995000"/><a contenteditable="false" data-primary="data processing and analysis" data-secondary="variant calling" data-startref="ix_DPanVC" data-type="indexterm" id="idm45625626993624"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Data Quality and Sources of Error"><div class="sect2" id="data_quality_and_sources_of_error">
<h2>Data Quality and Sources of Error</h2>

<p>A lot of things<a contenteditable="false" data-primary="data processing and analysis" data-secondary="data quality and sources of error" data-type="indexterm" id="ix_DPanDQerr"/> can go wrong (<a data-type="xref" href="#common_sources_of_error_in_variant_disc">Figure 2-25</a>) during the entire process, from initial sample collection all the way to the application of computational algorithms, with multiple sources of error and confounding factors creeping in at each stage. Let’s review the most common, which are important for understanding many of the procedures that we’ll apply in the course of genomic analysis.</p>

<figure><div id="common_sources_of_error_in_variant_disc" class="figure"><img alt="Common sources of error in variant discovery." src="Images/gitc_0225.png" width="1440" height="649"/>
<h6><span class="label">Figure 2-25. </span>Common sources of error in variant discovery.</h6>
</div></figure>

<section data-type="sect3" data-pdf-bookmark="Contamination and sample swaps"><div class="sect3" id="contamination_and_sample_swaps">
<h3>Contamination and sample swaps</h3>

<p>At the earliest stages of sample collection and preparation, we are vulnerable to several types of contamination.<a contenteditable="false" data-primary="contamination in variant discovery" data-type="indexterm" id="idm45625626982920"/> The most difficult to prevent is contamination by foreign material, especially in the case of cheek swabs and saliva samples. Think about what’s going on in your own mouth right now. When is the last time you brushed your teeth? What did you have for lunch? Any chance you have a bit of a cold at the moment, maybe a runny nose? If we were to try to sequence your genome based on a saliva sample or cheek swab, whatever is in your mouth is going to be sequenced along with your own DNA. At the very least, this means some of the resulting sequence data will be useless noise; in worst-case scenarios, it can cause errors in the downstream analysis results.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="sample_contamination_stories">
<h5>Sample Contamination Stories</h5>

<p>A few years ago, the Broad Genomics facility processed a group of samples that failed quality control checks with a very particular failure mode. A substantial proportion of reads were mapped in just a few places, accumulating to huge depths, with only a subset of the read sequence aligning to the genome reference. The QC team investigated and found that the reads came from bacterial DNA, with short stretches of sequence that are highly conserved throughout the tree of life. These sequences match some human sequence well enough to align to the human reference, albeit with some read clipping on either side. Going back to the original samples, the team realized that the cheek swabs were from sick children who had very high bacterial load in their mouths due to heavy nasal congestion. The GATK methods development team addressed the issue by adding a data processing filter that weeds out sequence reads that are clipped at both ends.</p>

<p>The following year, the GATK methods development team received another fun request from the Broad Genomics facility: could it please come up with a way to identify cow, pig, chicken, and fish DNA and remove them from human samples? To make a long story short, people were sometimes eating lunch immediately before providing saliva samples, and leftover food fragments were being sequenced along with the diner’s DNA. Vegetarians could get away with this because plant DNA is different enough that it simply doesn’t map to the human genome, but the animals we eat are close enough to us that some of their DNA does map and aligns well enough to the human reference, which can then introduce errors in the variant-calling process. So members of the team got to work creating human-animal hybrids <em>in silico</em>. They added specific amounts of animal sequence data to human data so that they could determine how much should be filtered out. Then, the team adapted an existing method used for metagenomic analysis to identify the contaminating data and exclude it from the dataset, which successfully addressed the original problem. <a contenteditable="false" data-primary="PathSeq tool" data-type="indexterm" id="idm45625626976200"/>The resulting tool, called PathSeq, can be used to preprocess samples in this way, but it can also be used for identifying foreign DNA from other sources, such as viral DNA in blood or tissue samples.</p>
</div></aside>

<p>Then there’s cross-sample contamination, which people don’t like to talk about because it implies something went wrong either with the quality of equipment or the skill of the person doing the work. But the reality is that cross-contamination between samples happens often enough that it should be addressed in the analysis. It can happen during the initial sample collection, especially when sampling is done in the field in less than ideal conditions, or during library preparation steps. The result in either case is that some genetic material from person A ends up in the tube for sample B. <a contenteditable="false" data-primary="germline variants" data-secondary="analysis of, sample contamination and" data-type="indexterm" id="idm45625626973592"/>When the level of contamination is low, it’s typically not a problem for germline variant analysis, but as you’ll see in <a data-type="xref" href="ch07.xhtml#gatk_best_practices_for_somatic_variant">Chapter 7</a>, it can have major implications for somatic analysis. Also in <a data-type="xref" href="ch07.xhtml#gatk_best_practices_for_somatic_variant">Chapter 7</a>, we discuss how we can detect and handle cross-sample contamination in the somatic short variant pipeline.</p>

<p>Finally, sample swaps generally come down<a contenteditable="false" data-primary="sample swaps" data-type="indexterm" id="idm45625626969208"/> to mislabeling—either the label ending up on the wrong tube, or handwritten labels with ambiguous lettering—or metadata handling errors during processing. To detect any sample swaps that occur during processing, the best practice recommendation is to put inbound samples through a fingerprinting procedure and then check processed data against the original fingerprints to detect any swaps.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Biochemical, physical, and software artifacts"><div class="sect3" id="biochemicalcomma_physicalcomma_and_soft">
<h3>Biochemical, physical, and software artifacts</h3>

<p>Various physical and biochemical effects that occur during sample preparation (such as shearing and oxidation) can cause DNA damage that ultimately translates into having the wrong sequence in the output data. <a contenteditable="false" data-primary="biochemical, physical, and software artifacts" data-type="indexterm" id="idm45625626965432"/>Library preparation protocols that involve a PCR amplification step introduces similar errors because our good friend, the polymerase, is wonderfully productive but prone to incorporating the wrong base. And, of course, sometimes the sequencing machine fails to read the light signals bouncing off the DNA accurately, producing either low-confidence BCLs or outright errors. So the data we have might not always be of the highest quality.</p>

<p>Some biochemical properties of sequence context affect the efficiency of library preparation, flowcell loading, and sequencing processes. This results in producing artificially inflated coverage in some areas and inadequate coverage in others. For example, and as <a data-type="xref" href="#some_biochemical_properties_of_the_dna">Figure 2-26</a> shows, we know that stretches of DNA with high GC content (areas with lots of G and C bases) will generally show less coverage compared to the rest of the genome. Highly repetitive regions are also associated with coverage abnormalities.</p>

<figure><div id="some_biochemical_properties_of_the_dna" class="figure"><img alt="Some biochemical properties of the DNA itself cause biases in certain region." src="Images/gitc_0226.png" width="1264" height="602"/>
<h6><span class="label">Figure 2-26. </span>Some biochemical properties of the DNA itself cause biases in certain regions.</h6>
</div></figure>

<p>Then, after the data has been generated and we go to process it, we run into other sources of error. For example, mapping artifacts caused by the biological complexity of the genome (spoiler: it’s a mess) can lead to reads ending up in the wrong place, supporting apparent variants that are not real. Shortcuts in algorithms made to improve performance can cause small approximations to balloon into errors. And although we’re sad to say this, software bugs are inevitable.</p>

<p>The cherry on the cake, finally, consists of batch effects—because we can deal with a certain amount of error as long as it’s consistent across all the samples we’re comparing, but the minute we begin comparing results from samples that were processed <span class="keep-together">differently</span>, we’re in the danger zone. If we’re not careful, we could end up ascribing biological impact to an artifact that just happens to be present in a subset of our samples because of how they were processed.<a contenteditable="false" data-primary="data processing and analysis" data-secondary="data quality and sources of error" data-startref="ix_DPanDQerr" data-type="indexterm" id="idm45625626957304"/></p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Functional Equivalence Pipeline Specification"><div class="sect2" id="functional_equivalence_pipeline_specifi">
<h2>Functional Equivalence Pipeline Specification</h2>

<p>The data preprocessing phase that takes place before variant calling is probably the part of genomic analysis that has the most heterogeneity in terms of valid alternative implementations.<a contenteditable="false" data-primary="pipeline specification, functional equivalence" data-type="indexterm" id="idm45625626953512"/><a contenteditable="false" data-primary="data processing and analysis" data-secondary="functional equivalence pipeline specification" data-type="indexterm" id="idm45625626952376"/><a contenteditable="false" data-primary="functional equivalence pipeline specification" data-type="indexterm" id="idm45625626951000"/> There are many ways you can “do it right” depending on how you want to handle the logistics side, whether you care more about cost or runtime, and so on. For each step, several alternative software tools (some open source, some proprietary) are available for you to use—especially for mapping. It’s almost a rite of passage for newly minted bioinformatics developers to write a new mapping algorithm.</p>

<p>However, there is a dark side to this abundance of choice. Differences between implementations can cause subtle batch effects in downstream analyses that compare datasets produced by those variant pipelines, sometimes with important consequences for the scientific results. That is why historically the Broad Institute teams have always chosen to redo the preprocessing on genomic data coming in from external sources. They would systematically revert any aligned read data back to an unmapped state and scrub it clean of any tagging or any reversible modifications. Then, they would put the reverted data through their internal preprocessing pipeline.</p>

<p>That strategy is unfortunately no longer sustainable given the huge increase in the amount of data being produced and used in large aggregation projects such as <a href="https://gnomad.broadinstitute.org">gnomAD</a>. To address this issue, the Broad Institute teamed up with several of the other largest genome sequencing and analysis centers in North America (New York Genome Center, Washington University, University of Michigan, Baylor College of Medicine) to define a standard for standardizing pipeline implementations. The idea is that any data processed through a pipeline that conforms with the specification will be compatible, so that any datasets aggregated from multiple conformant sources can be analyzed together without fear of batch effects.</p>

<p>The consortium published the <a href="https://oreil.ly/_yLwF">Functional Equivalence specification</a> and encourages all genome centers as well as anyone else who is producing data, even at a small scale, to adopt the specification in order to promote interoperability and eliminate batch effects from joint studies.<a contenteditable="false" data-primary="data processing and analysis" data-startref="ix_DPan" data-type="indexterm" id="idm45625626944984"/></p>
</div></section>
</div></section>

<section class="pagebreak-before" data-type="sect1" data-pdf-bookmark="Wrap-Up and Next Steps"><div class="sect1" id="wrap_up_and_next_step-id00050">
<h1 class="less_space">Wrap-Up and Next Steps</h1>

<p>This concludes our genomics primer; you now know everything you need on the scientific side to get started with GATK and variant discovery. Next up, we do the equivalent exercise on the computational side with a technology primer that takes you through the key concepts and terminology you need to know to run the tools involved.</p>
</div></section>
</div></section></div>



  </body></html>