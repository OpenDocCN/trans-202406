<html><head></head><body><section data-pdf-bookmark="Chapter 9. Networking, Network Security, and Service Mesh" data-type="chapter" epub:type="chapter"><div class="chapter" id="networking_network_security_and_service_mesh">&#13;
<h1><span class="label">Chapter 9. </span>Networking, Network Security, <span class="keep-together">and Service Mesh</span></h1>&#13;
&#13;
&#13;
<p>Kubernetes is effectively a manager of distributed systems across a&#13;
cluster of connected systems. This immediately puts critical&#13;
importance on how the connected systems communicate with one another, and&#13;
networking is the key to this. Understanding how Kubernetes facilitates&#13;
communication among the distributed services it manages is&#13;
important for the effective application of interservice communication.</p>&#13;
&#13;
<p>This chapter focuses on the principles that Kubernetes places on the&#13;
network and best practices around applying these concepts in different&#13;
situations. With any discussion of networking, security is usually&#13;
brought along for the ride. The traditional models of network security&#13;
boundaries being controlled at the network layer are not absent in this&#13;
new world of distributed systems in Kubernetes, but how they are&#13;
implemented and the capabilities offered change slightly. Kubernetes brings&#13;
along a native API for network security policies that will sound eerily&#13;
similar to firewall rules of old.</p>&#13;
&#13;
<p>The last section of this chapter delves into the new and&#13;
scary world of service meshes. The term “scary” is used in jest, but it is quite the Wild West when it comes to service mesh technology in Kubernetes.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Kubernetes Network Principles" data-type="sect1"><div class="sect1" id="id70">&#13;
<h1>Kubernetes Network Principles</h1>&#13;
&#13;
<p>Understanding how Kubernetes uses the underlying network to facilitate&#13;
communication among services is critical to understanding how to&#13;
effectively plan application architectures. Usually, networking topics&#13;
start to give most people major headaches. We are going to keep this&#13;
rather simple because this is more of a best practice guidance than a lesson&#13;
on container networking. Luckily for us, Kubernetes has laid down some&#13;
rules of the road for networking that give us a start. The rules outline how communication is expected to behave between&#13;
different components. Let’s take a closer look at each of these rules:</p>&#13;
<dl>&#13;
<dt>Container-to-container communication in the same pod</dt>&#13;
<dd>&#13;
<p>All <a data-primary="networking" data-secondary="container-to-container communication" data-type="indexterm" id="id753"/><a data-primary="container-to-container communication" data-type="indexterm" id="id754"/>containers in the same pod share the same network space. This effectively allows localhost communication between the containers. It also means that containers in the same pod need to expose different ports. This is done using the power of Linux namespaces and Docker networking to allow these containers to be on the same local network through the use of a paused container in every pod that does nothing but host the networking for the pod. <a data-type="xref" href="#figure91">Figure 9-1</a> shows how Container A can communicate directly with Container B using localhost and the port number that the container is listening on.</p>&#13;
&#13;
<figure><div class="figure" id="figure91">&#13;
<img alt="kbp2 0901" src="assets/kbp2_0901.png"/>&#13;
<h6><span class="label">Figure 9-1. </span>Intrapod communication between containers</h6>&#13;
</div></figure>&#13;
</dd>&#13;
<dt>Pod-to-pod communication</dt>&#13;
<dd>&#13;
<p>All pods<a data-primary="networking" data-secondary="pod-to-pod communication" data-type="indexterm" id="id755"/><a data-primary="pod-to-pod communication" data-type="indexterm" id="id756"/> need to communicate with one another without any network address translation (NAT). This means that the pod’s IP address that is seen by the receiving pod is the sender’s actual IP address. This is handled in different ways, depending on the network plug-in used, which we discuss in more detail later in the chapter. This rule is true between pods on the same node and pods that are on different nodes in the same cluster. This also extends to the node being able to communicate directly to the pod with no NAT involved. This allows host-based agents or system daemons to communicate to the pods as needed. <a data-type="xref" href="#figure92">Figure 9-2</a> is a representation of the communication processes between pods in the same node and pods in different nodes of the cluster.</p>&#13;
&#13;
<figure><div class="figure" id="figure92">&#13;
<img alt="kbp2 0902" src="assets/kbp2_0902.png"/>&#13;
<h6><span class="label">Figure 9-2. </span>Pod-to-pod communication intra- and internode</h6>&#13;
</div></figure>&#13;
</dd>&#13;
<dt>Service-to-pod communication</dt>&#13;
<dd>&#13;
<p>Services in<a data-primary="networking" data-secondary="service-to-pod communication" data-type="indexterm" id="id757"/> Kubernetes represent a durable IP address and port that is found on each node that will forward all traffic to the endpoints that are mapped to the service. Over the different iterations of Kubernetes, the method in favor of enabling this has changed, but the two main methods are via the use of iptables or the newer IP Virtual Server (IPVS). Some cloud providers and more advanced implementations allow for a new eBPF-based dataplane. Most implementations today use the iptables implementation to enable a pseudo–Layer 4 load balancer on each node. <a data-type="xref" href="#figure93">Figure 9-3</a> is a visual representation of how the service is tied to the pods via label selectors.</p>&#13;
&#13;
<figure><div class="figure" id="figure93">&#13;
<img alt="kbp2 0903" src="assets/kbp2_0903.png"/>&#13;
<h6><span class="label">Figure 9-3. </span>Service-to-pod communication</h6>&#13;
</div></figure>&#13;
</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Network Plug-ins" data-type="sect1"><div class="sect1" id="id71">&#13;
<h1>Network Plug-ins</h1>&#13;
&#13;
<p>Early on, the<a data-primary="networking" data-secondary="plug-ins" data-type="indexterm" id="network-plugin"/><a data-primary="plug-ins for networking" data-type="indexterm" id="plugin-network"/> Special Interest Group (SIG) guided the networking&#13;
standards to more of a pluggable architecture, opening the door for&#13;
numerous third-party networking projects, which in many cases injected value-added capabilities into Kubernetes workloads. These network plug-ins come&#13;
in two flavors. The most basic is called Kubenet and is the default plug-in&#13;
provided by Kubernetes natively. The second type of plug-in follows the&#13;
Container Network Interface (CNI) specification, which is a generic plug-in&#13;
network solution for containers.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Kubenet" data-type="sect2"><div class="sect2" id="id72">&#13;
<h2>Kubenet</h2>&#13;
&#13;
<p>Kubenet is<a data-primary="Kubenet" data-type="indexterm" id="kubenet"/> the most basic network plug-in that comes out of the box in&#13;
Kubernetes. It is the simplest of the plug-ins and provides a Linux&#13;
bridge, <code>cbr0</code>, that’s a virtual Ethernet pair for the pods connected to it. The pod&#13;
then gets an IP address from a Classless Inter-Domain Routing (CIDR) range that is distributed across the&#13;
nodes of the cluster. There is also an IP masquerade flag that should be&#13;
set to allow traffic destined to IPs outside the pod CIDR range to be masqueraded. This obeys the rules of pod-to-pod communication because&#13;
only traffic destined outside the pod CIDR undergoes network address translation (NAT). After the packet&#13;
leaves a node to go to another node, some kind of routing is put in&#13;
place to facilitate the process to forward the traffic to the correct&#13;
node.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Kubenet Best Practices" data-type="sect2"><div class="sect2" id="id214">&#13;
<h2>Kubenet Best Practices</h2>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Kubenet <a data-primary="best practices" data-secondary="Kubenet" data-type="indexterm" id="id758"/>allows for a simple network stack and does not&#13;
consume precious IP addresses on already crowded networks. This is&#13;
especially true of cloud networks that are extended to on-premises datacenters.</p>&#13;
</li>&#13;
<li>&#13;
<p>Ensure that the pod CIDR range is large enough to handle the potential size&#13;
of the cluster and the pods in each cluster. The default pods per node&#13;
set in kubelet is 110, but you can adjust this.</p>&#13;
</li>&#13;
<li>&#13;
<p>Understand and plan accordingly for the route rules to properly allow&#13;
traffic to find pods in the proper nodes. In cloud providers, this is&#13;
usually automated, but on-premises or edge cases will require automation&#13;
and solid network <span class="keep-together">management.</span></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The CNI Plug-in" data-type="sect2"><div class="sect2" id="id73">&#13;
<h2>The CNI Plug-in</h2>&#13;
&#13;
<p>The <a data-primary="CNI (Container Network Interface) plug-in" data-type="indexterm" id="cni-plugin"/>CNI plug-in has basic requirements set aside by the specification. These specifications dictate the interfaces and minimal API actions that the CNI offers and how it will interface with the&#13;
container runtime that is used in the cluster. The network management components are defined by the CNI, but they all must include some type of IP address management and minimally allow for the addition and deletion of a container to a network. The full original specification originally derived from the <code>rkt</code> networking proposal is <a href="https://oreil.ly/wGvF7">available on GitHub</a>.</p>&#13;
&#13;
<p>The Core CNI project provides libraries that you can use to write plug-ins that provide the basic requirements and can call other plug-ins&#13;
to perform various functions. This adaptability led to numerous CNI plug-ins that you can use in container networking from cloud providers,&#13;
like the Microsoft Azure native CNI and the Amazon Web Services (AWS) VPC CNI plug-in, as well as plug-ins from traditional network providers such as Nuage CNI, Juniper Networks Contrail/Tunsten Fabric, and VMware NSX.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="CNI Best Practices" data-type="sect2"><div class="sect2" id="id74">&#13;
<h2>CNI Best Practices</h2>&#13;
&#13;
<p>Networking<a data-primary="best practices" data-secondary="CNI plug-in" data-type="indexterm" id="id759"/> is a critical component of a functioning Kubernetes environment. The interaction between the virtual components within Kubernetes and the physical <span class="keep-together">network</span> environment should be carefully designed to ensure dependable application communication:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Evaluate the feature set needed to accomplish the overall networking&#13;
goals of the infrastructure. Some CNI plug-ins provide native high&#13;
availability, multicloud connectivity, Kubernetes network policy&#13;
support, and various other features.</p>&#13;
</li>&#13;
<li>&#13;
<p>If you are running clusters via public cloud providers, verify that any&#13;
CNI plug-ins that are not native to the cloud provider’s Software-Defined Network (SDN) are actually&#13;
supported.</p>&#13;
</li>&#13;
<li>&#13;
<p>Verify that any network security tools, network observability, and management tools are compatible with the CNI plug-in of choice. If&#13;
not, research which tools can replace the existing ones. It is important to not lose either observability or security capabilities because the needs will be expanded when moving to a large-scale distributed system such as Kubernetes. You can add tools like Weaveworks Weave Scope, Dynatrace, and Sysdig to any Kubernetes environment, and each offers its own benefits. If you’re running in a cloud provider’s managed service, such as Azure AKS, Google&#13;
GCE, or AWS EKS, look for native tools like Azure Container Insights and Network Watcher, Google Logging and Monitoring, and AWS CloudWatch. Whatever tool you use, it should provide insight into the network stack and the Four Golden signals, made popular by the amazing Google SRE team and&#13;
Rob Ewashuck: Latency, Traffic, Errors, and Saturation.</p>&#13;
</li>&#13;
<li>&#13;
<p>If you’re using CNIs that do not provide an overlay network separate from&#13;
the SDN space, ensure that you have proper network address space to&#13;
handle node IPs, pod IPs, internal load balancers, and overhead for&#13;
cluster upgrade and scale out <a data-primary="networking" data-secondary="plug-ins" data-startref="network-plugin" data-type="indexterm" id="id760"/><a data-primary="plug-ins for networking" data-startref="plugin-network" data-type="indexterm" id="id761"/><a data-primary="CNI (Container Network Interface) plug-in" data-startref="cni-plugin" data-type="indexterm" id="id762"/>processes.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Services in Kubernetes" data-type="sect1"><div class="sect1" id="id215">&#13;
<h1>Services in Kubernetes</h1>&#13;
&#13;
<p>When pods <a data-primary="networking" data-secondary="services" data-tertiary="purpose of" data-type="indexterm" id="network-service-purpose"/><a data-primary="services" data-secondary="purpose of" data-type="indexterm" id="service-purpose"/>are deployed into a Kubernetes cluster, because of the basic&#13;
rules of Kubernetes networking and the network plug-in used to facilitate&#13;
these rules, pods can directly communicate only with other pods within the same&#13;
cluster. Some CNI plug-ins give the pods IPs on the same network space as&#13;
the nodes, so technically, after the IP of a pod is known, it can be accessed&#13;
directly from outside the cluster. This, however, is not an efficient way&#13;
to access services being served by a pod, because of the ephemeral nature&#13;
of pods in Kubernetes. Imagine that you have a function or system that needs&#13;
to access an API that is running in a pod in Kubernetes. For a while,&#13;
that might work with no issue, but at some point there might be a voluntary or&#13;
involuntary disruption that will cause that pod to disappear. Kubernetes&#13;
will potentially create a replacement pod with a new name and IP&#13;
address, so naturally there needs to be some mechanism to find the&#13;
replacement pod. This is where the service API comes to the rescue.</p>&#13;
&#13;
<p>The service API allows for a durable IP and port to be assigned within&#13;
the Kubernetes cluster and automatically mapped to the proper pods as&#13;
endpoints to the service. This magic happens through the iptables or IPVS on Linux nodes to create a mapping of the assigned service IP and port to the endpoint’s or pod’s actual IPs. The controller that manages this is called the <code>kube-proxy</code> service, which actually runs&#13;
on each node in the cluster. It is responsible for manipulating the iptables rules on each node.</p>&#13;
&#13;
<p>When a service object is defined, the type of service needs to be&#13;
defined. The service type will dictate whether the endpoints are exposed only&#13;
within the cluster or outside of the cluster. We will briefly discuss four basic service types in the following <a data-primary="networking" data-secondary="services" data-startref="network-service-purpose" data-tertiary="purpose of" data-type="indexterm" id="id763"/><a data-primary="services" data-secondary="purpose of" data-startref="service-purpose" data-type="indexterm" id="id764"/>sections.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Service Type ClusterIP" data-type="sect2"><div class="sect2" id="id75">&#13;
<h2>Service Type ClusterIP</h2>&#13;
&#13;
<p>ClusterIP is<a data-primary="networking" data-secondary="services" data-tertiary="ClusterIP" data-type="indexterm" id="network-service-clusterip"/><a data-primary="services" data-secondary="ClusterIP" data-type="indexterm" id="service-clusterip"/><a data-primary="ClusterIP service type" data-type="indexterm" id="clusterip"/> the default service type if one is not declared in the specification. ClusterIP means that the service is assigned an IP from a&#13;
designated service CIDR range. This IP is as long-lasting as the service object, so it provides an IP and port and protocol mapping to backend&#13;
pods using the selector field; however, as we will see, there are cases for which you can have no selector. The declaration of the service also&#13;
provides for a Domain Name System (DNS) name for the service. This facilitates service&#13;
discovery within the cluster and allows for workloads to easily communicate with other services within the cluster by using DNS lookup&#13;
based on the service name. As an example, if you have the service definition shown in the following example and need to access that service from another pod inside the cluster via an HTTP call, the call can simply use http://web1-svc if the client is in the same namespace as the service:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Service</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">web1-svc</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">selector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">app</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">web1</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">ports</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">port</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">80</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">targetPort</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">8081</code><code class="w"/></pre>&#13;
&#13;
<p>If it is required to find services in other namespaces, the DNS&#13;
pattern would be <code><em>&lt;service_name&gt;.&lt;namespace_name&gt;</em>.svc.cluster.local</code>.</p>&#13;
&#13;
<p>If no selector is given in a service definition, the endpoints can be&#13;
explicitly defined for the service by using an endpoint API definition.&#13;
This will basically add an IP and port as a specific endpoint to a&#13;
service instead of relying on the selector attribute to automatically&#13;
update the endpoints from the pods that are in scope by the selector&#13;
match. This can be useful in a few scenarios in which you have a specific&#13;
database that is not in a cluster that is to be used for testing, but you will&#13;
change the service later to a Kubernetes-deployed database. This is sometimes called a <em>headless&#13;
service</em> because it is not managed by <code>kube-proxy</code> as other services are, but you can directly manage the&#13;
endpoints, <a data-primary="networking" data-secondary="services" data-startref="network-service-clusterip" data-tertiary="ClusterIP" data-type="indexterm" id="id765"/><a data-primary="services" data-secondary="ClusterIP" data-startref="service-clusterip" data-type="indexterm" id="id766"/><a data-primary="ClusterIP service type" data-startref="clusterip" data-type="indexterm" id="id767"/>as shown in <a data-type="xref" href="#figure94">Figure 9-4</a>.</p>&#13;
&#13;
<figure><div class="figure" id="figure94">&#13;
<img alt="kbp2 0904" src="assets/kbp2_0904.png"/>&#13;
<h6><span class="label">Figure 9-4. </span>ClusterIP-pod and service visualization</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Service Type NodePort" data-type="sect2"><div class="sect2" id="id76">&#13;
<h2>Service Type NodePort</h2>&#13;
&#13;
<p>The<a data-primary="networking" data-secondary="services" data-tertiary="NodePort" data-type="indexterm" id="id768"/><a data-primary="services" data-secondary="NodePort" data-type="indexterm" id="id769"/><a data-primary="NodePort service type" data-type="indexterm" id="id770"/> NodePort service type assigns a high-level port on each node of the&#13;
cluster to the service IP and port on each node. The high-level&#13;
NodePorts fall within the 30,000 through 32,767 ranges and can either be&#13;
statically assigned or explicitly defined in the service specification.&#13;
NodePorts are typically used for on-premises clusters or bespoke&#13;
solutions that do not offer automatic load-balancing configuration. To&#13;
directly access the service from outside the cluster, use NodeIP:NodePort, as depicted in <a data-type="xref" href="#figure95">Figure 9-5</a>.</p>&#13;
&#13;
<figure class="width-95"><div class="figure" id="figure95">&#13;
<img alt="kbp2 0905" src="assets/kbp2_0905.png"/>&#13;
<h6><span class="label">Figure 9-5. </span>NodePort–pod, service and host network visualization</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Service Type ExternalName" data-type="sect2"><div class="sect2" id="id77">&#13;
<h2>Service Type ExternalName</h2>&#13;
&#13;
<p>The<a data-primary="networking" data-secondary="services" data-tertiary="ExternalName" data-type="indexterm" id="network-service-externalname"/><a data-primary="services" data-secondary="ExternalName" data-type="indexterm" id="service-externalname"/><a data-primary="ExternalName service type" data-type="indexterm" id="externalname"/> ExternalName service type is seldom used in practice, but it can be helpful for passing cluster-durable DNS names to external DNS named services. A common example is an external database service from a cloud provider that has a unique DNS supplied by the cloud provider, such as&#13;
<code>mymongodb.documents.azure.com</code>. <span class="keep-together">Technically,</span> this can be added very easily to a pod specification using an <code>Environment</code> variable, as discussed in&#13;
<a data-type="xref" href="ch06.html#versioning_releases_and_rollouts">Chapter 6</a>. However, it might be more advantageous to use a more generic&#13;
name in the cluster, such as <code>prod-mongodb</code>, which enables the change of the actual database it points to by just changing the service specification&#13;
instead of having to recycle the pods because the <code>Environment</code> variable has changed:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Service</code><code class="w"/>&#13;
<code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">prod-mongodb</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">namespace</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">prod</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">ExternalName</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">externalName</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">mymongodb.documents.azure.com</code><code class="w"/></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Service Type LoadBalancer" data-type="sect2"><div class="sect2" id="id78">&#13;
<h2>Service Type LoadBalancer</h2>&#13;
&#13;
<p>LoadBalancer is<a data-primary="networking" data-secondary="services" data-tertiary="LoadBalancer" data-type="indexterm" id="id771"/><a data-primary="services" data-secondary="LoadBalancer" data-type="indexterm" id="id772"/><a data-primary="LoadBalancer service type" data-type="indexterm" id="id773"/> a very special service type because it enables automation with cloud providers and other programmable cloud infrastructure services. The <code>LoadBalancer</code> type is a single method to ensure the deployment of the load-balancing mechanism that the infrastructure provider of the Kubernetes cluster supplies. This means that in most cases, <code>LoadBalancer</code> will work roughly the same way in AWS, Azure, GCE, OpenStack, and others. This entry will usually create a public-facing load-balanced service; however, each cloud provider has some specific&#13;
annotations that enable other features, such as internal-only load balancers, AWS ELB configuration parameters, and so on. You can also define the actual load-balancer IP to use and the source ranges to allow within the service specification, as seen in the code sample that follows and the visual representation in <a data-type="xref" href="#figure96">Figure 9-6</a>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Service</code><code class="w"/>&#13;
<code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">web-svc</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">LoadBalancer</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">selector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">app</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">web</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">ports</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">protocol</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">TCP</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">port</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">80</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">targetPort</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">8081</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">loadBalancerIP</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">13.12.21.31</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">loadBalancerSourceRanges</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="s">"142.43.0.0/16"</code><code class="w"/></pre>&#13;
&#13;
<figure><div class="figure" id="figure96">&#13;
<img alt="kbp2 0906" src="assets/kbp2_0906.png"/>&#13;
<h6><span class="label">Figure 9-6. </span>LoadBalancer–pod, service, node, and cloud provider network <span class="keep-together">visualization</span></h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Ingress and Ingress Controllers" data-type="sect2"><div class="sect2" id="id79">&#13;
<h2>Ingress and Ingress Controllers</h2>&#13;
&#13;
<p>Although <a data-primary="networking" data-secondary="services" data-tertiary="Ingress API/ingress controllers" data-type="indexterm" id="network-service-ingress"/><a data-primary="services" data-secondary="Ingress API/ingress controllers" data-type="indexterm" id="service-ingress"/><a data-primary="Ingress API" data-type="indexterm" id="ingress-api"/><a data-primary="ingress controllers" data-type="indexterm" id="ingress-control"/>not technically a service type in Kubernetes, the Ingress&#13;
specification is an important concept for ingress to workloads in&#13;
Kubernetes. Services, as defined by the Service API, allow for a basic&#13;
level of Layer 3/4 load balancing. The reality is that many of the&#13;
stateless services that are deployed in Kubernetes require a high level&#13;
of traffic management and usually require application-level control:&#13;
more specifically, HTTP protocol management.</p>&#13;
&#13;
<p>The Ingress API is basically an HTTP-level router that allows for host-&#13;
and path-based rules to direct to specific backend services. Imagine&#13;
a website hosted on www.evillgenius.com and two different paths that&#13;
are hosted on that site, <em>/registration</em> and <em>/labaccess</em>, that are&#13;
served by two different services hosted in Kubernetes, <code>reg-svc</code> and&#13;
<code>labaccess-svc</code>. You can define an ingress rule to ensure that requests&#13;
to www.evillgenius.com/registration are forwarded to the <code>reg-svc</code>&#13;
service and the correct endpoint pods, and, similarly, that requests to&#13;
www.evillgenius.com/labaccess are forwarded to the correct endpoints of&#13;
the <code>labaccess-svc</code> service. The Ingress API also permits host-based&#13;
routing to allow for different hosts on a single ingress. An additional&#13;
feature is the ability to declare a Kubernetes secret that holds the&#13;
certificate information for Transport Layer Security (TLS) termination on port 443. When a path is&#13;
not specified, there is usually a default backend that can be used to&#13;
give a better user experience than the standard 404 error.</p>&#13;
&#13;
<p>The details around the specific TLS and default backend configuration&#13;
are actually handled by what is known as the Ingress controller. The Ingress&#13;
controller is decoupled from the Ingress API and allows for operators to&#13;
deploy an Ingress controller of choice, such as NGINX, Traefik, HAProxy,&#13;
and others. An Ingress controller, as the name suggests, is a&#13;
controller just like any Kubernetes controller, but it’s not part of the&#13;
system and is instead a third-party controller that understands the Kubernetes&#13;
Ingress API for dynamic configuration. The most common implementation of&#13;
an Ingress controller is NGINX because it is partly maintained by the&#13;
Kubernetes project; however, there are numerous examples of both open&#13;
source and commercial Ingress controllers:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">networking.k8s.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Ingress</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">labs-ingress</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">annotations</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">nginx.ingress.kubernetes.io/rewrite-target</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">/</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">tls</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">hosts</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">www.evillgenius.com</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">secretName</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">secret-tls</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">rules</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">host</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">www.evillgenius.com</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">http</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">paths</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">path</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">/registration</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">pathType</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">ImplementationSpecific</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">backend</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">          </code><code class="nt">service</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">reg-svc</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">port</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">              </code><code class="nt">number</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">8088</code><code class="w"/>&#13;
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">path</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">/labaccess</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">pathType</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">ImplementationSpecific</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">backend</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">          </code><code class="nt">service</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">labaccess-svc</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">port</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">              </code><code class="nt">number</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">8089</code><code class="w"/></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Gateway API" data-type="sect2"><div class="sect2" id="id80">&#13;
<h2>Gateway API</h2>&#13;
&#13;
<p>The<a data-primary="networking" data-secondary="services" data-tertiary="Gateway API" data-type="indexterm" id="network-service-gateway"/><a data-primary="services" data-secondary="Gateway API" data-type="indexterm" id="service-gateway"/><a data-primary="Gateway API for Kubernetes" data-type="indexterm" id="gateway-api"/> Ingress API had some challenges over the years that it was in beta and following its v1 promotion. These challenges have led to other network services offering different abstractions through the use of Custom Resource Definitions and controllers to create their own APIs that fill some of the gaps Ingress has had. Some of the most common challenges with the<a data-primary="Ingress API" data-secondary="challenges with" data-type="indexterm" id="id774"/> Ingress API have been:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The lack of expressiveness in the definition as it represents the lowest common denominator for the capabilities of the particular Ingress implementation.</p>&#13;
</li>&#13;
<li>&#13;
<p>A general lack of extensibility in the architecture. Vendors have used countless annotations to expose specific implementation capabilities; however, this has some limitations.</p>&#13;
</li>&#13;
<li>&#13;
<p>The use of vendor-specific annotations has removed some of the portability promised by the API. An annotation to expose a capability in an NGINX-based Ingress controller may be different or expressed differently from a Kong-based controller implementation.</p>&#13;
</li>&#13;
<li>&#13;
<p>There is no formal way to do multi-tenancy with the current Ingress API, and DevOps teams have to create very tight controls to prevent path conflicts between Ingress definitions that could impact other tenants in the same cluster.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Introduced in 2019, the Gateway API is currently managed as a project by the SIG Network team under the Kubernetes Project. The Gateway API does not intend to replace the Ingress API as it primarily targets exposing HTTP applications with a declarative syntax. This API exposes a more general API for proxying for many types of protocols, and fits a more role-based management process because it models more closely the infrastructure components in the environment.</p>&#13;
&#13;
<p>The role-based paradigm, as shown in <a data-type="xref" href="#figure97">Figure 9-7</a>, is important in answering some of the shortcomings of the existing Ingress API. The separate components allow for infrastructure providers, such as cloud providers and proxy ISVs, to define the infrastructure and platform operators to define through policy what infrastructure can be used. Developers can then worry about how they want to expose their services within the constraints they are given. <a data-type="xref" href="#figure98">Figure 9-8</a> shows a practical example of how Gateway API structure abstracts the infrastructure services and capabilities away from the developer and allows them to focus on their specific service needs.</p>&#13;
&#13;
<figure><div class="figure" id="figure97">&#13;
<img alt="kbp2 0907" src="assets/kbp2_0907.png"/>&#13;
<h6><span class="label">Figure 9-7. </span>Gateway API structure</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="figure98">&#13;
<img alt="kbp2 0908" src="assets/kbp2_0908.png"/>&#13;
<h6><span class="label">Figure 9-8. </span>Gateway API structure, continued</h6>&#13;
</div></figure>&#13;
&#13;
<p>The specification is very promising, and many of the leading providers of proxies and services meshes, as well as cloud providers, have begun to implement the Gateway API into their stack. Google’s GKE, Acnodeal EPIC, Contour, Apache APISIX, and others have begun to offer limited preview or alpha support. As of this writing, the API itself is in beta for the GatewayClass, Gateway, and HTTPRoute resources, and others are in Alpha support. Unlike the Ingress API, this is a custom resource that can be added to any cluster and therefore does not follow the Kubernetes alpha or <a data-primary="networking" data-secondary="services" data-startref="network-service-gateway" data-tertiary="Gateway API" data-type="indexterm" id="id775"/><a data-primary="services" data-secondary="Gateway API" data-startref="service-gateway" data-type="indexterm" id="id776"/><a data-primary="Gateway API for Kubernetes" data-startref="gateway-api" data-type="indexterm" id="id777"/>beta release process.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Services and Ingress Controllers Best Practices" data-type="sect2"><div class="sect2" id="id81">&#13;
<h2>Services and Ingress Controllers Best Practices</h2>&#13;
&#13;
<p>Creating a <a data-primary="best practices" data-secondary="services/ingress controllers" data-type="indexterm" id="id778"/><a data-primary="networking" data-secondary="services" data-tertiary="best practices" data-type="indexterm" id="id779"/><a data-primary="services" data-secondary="best practices" data-type="indexterm" id="id780"/><a data-primary="ingress controllers" data-type="indexterm" id="id781"/>complex virtual network environment with interconnected applications requires careful planning. Effectively managing how the different services of the application communicate with one another and the outside world requires constant attention as the application changes. These best practices will help make management easier:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Limit the number of services that need to be accessed from outside the&#13;
cluster. Ideally, most services will be ClusterIP, and only external-facing services will be exposed externally to the cluster.</p>&#13;
</li>&#13;
<li>&#13;
<p>If the services that need to be exposed are primarily HTTP/HTTPS-based&#13;
services, it is best to use an Ingress API and Ingress controller to&#13;
route traffic to backing services with TLS termination. Depending on the&#13;
type of Ingress controller used, features such as rate limiting, header&#13;
rewrites, OAuth authentication, observability, and other&#13;
services can be made available without having to build them into the&#13;
applications themselves.</p>&#13;
</li>&#13;
<li>&#13;
<p>Choose an Ingress controller that has the needed functionality for secure ingress of your web-based workloads. Standardize on one and use it across the enterprise because many of the specific configuration annotations vary between implementations and prevent the deployment code from being portable across enterprise Kubernetes implementations.</p>&#13;
</li>&#13;
<li>&#13;
<p>Evaluate cloud service provider–specific Ingress controller options to move the infrastructure management and load of the ingress out of the cluster, but still allow for Kubernetes API configuration.</p>&#13;
</li>&#13;
<li>&#13;
<p>When serving mostly APIs externally, evaluate API-specific Ingress controllers, such as Kong or Ambassador, that have more fine-tuning for API-based workloads. Although NGINX, Traefik, and others might offer some API tuning, it will not be as fine-grained as specific API proxy systems.</p>&#13;
</li>&#13;
<li>&#13;
<p>When deploying Ingress controllers as pod-based workloads in Kubernetes, ensure that the deployments are designed for high availability and aggregate performance throughput. Use metrics observability to properly scale the ingress, but include enough cushion to prevent client disruptions while the workload scales.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Network Security Policy" data-type="sect1"><div class="sect1" id="id82">&#13;
<h1>Network Security Policy</h1>&#13;
&#13;
<p>The <a data-primary="networking" data-secondary="security policies" data-type="indexterm" id="network-security-policy"/><a data-primary="security" data-secondary="network policies" data-type="indexterm" id="security-network"/><a data-primary="policy and governance" data-secondary="network security" data-type="indexterm" id="policy-network-security"/><a data-primary="NetworkPolicy API" data-type="indexterm" id="networkpolicyapi"/>NetworkPolicy API built into Kubernetes allows for network-level&#13;
ingress and egress access control defined with your workload. Network&#13;
policies allow you to control how groups of pods are allowed to&#13;
communicate with one another and with other endpoints. If you want to dig&#13;
deeper into the NetworkPolicy specification, it might sound confusing,&#13;
especially given that it is defined as a Kubernetes API, but it requires a&#13;
network plug-in that supports the NetworkPolicy API.</p>&#13;
&#13;
<p>Network policies have a simple YAML structure that can look complicated, but if you think of it as a simple East-West traffic firewall, it might help you to understand it a little better. Each policy specification has <code>podSelector</code>, <code>ingress</code>, <code>egress</code>, and <code>policyType</code> fields. The only required&#13;
field is <code>podSelector</code>, which follows the same convention as any Kubernetes&#13;
selector with a <code>matchLabels</code>. You can create multiple NetworkPolicy&#13;
definitions that can target the same pods, and the effect is additive. Because NetworkPolicy objects are namespaced objects, if no&#13;
selector is given for a <code>podSelector</code>, all pods in the namespace fall&#13;
into the scope of the policy. If any ingress or egress rules are defined, this creates an allow list for what can ingress or egress from the pod. There is an important distinction here: if a pod falls&#13;
into the scope of a policy because of a selector match, all traffic,&#13;
unless explicitly defined in an ingress or egress rule, is blocked. This&#13;
little, nuanced detail means that if a pod does not fall into any policy&#13;
because of a selector match, all ingress and egress is allowed to&#13;
the pod. This was done on purpose to allow for ease of deploying new&#13;
workloads into Kubernetes without any blockers.</p>&#13;
&#13;
<p>The <code>ingress</code> and <code>egress</code> fields are basically a list of rules based on&#13;
source or destination and can be specific CIDR ranges,&#13;
<code>podSelector</code>s, or <code>namespaceSelector</code>s. If you leave the ingress field empty, it is like a deny-all inbound. Similarly, if you leave the egress empty, it is deny-all outbound. Port and protocol lists are also&#13;
supported to further tighten down the type of communications&#13;
allowed.</p>&#13;
&#13;
<p>The <code>policyTypes</code> field specifies to which network policy rule types the&#13;
policy object is associated. If the field is not present, it will just&#13;
look at the <code>ingress</code> and <code>egress</code> lists fields. The difference again is&#13;
that you must explicitly call out egress in <code>policyTypes</code> and also&#13;
have an egress rule list for this policy to work. Ingress is assumed, and&#13;
defining it explicitly is not needed.</p>&#13;
&#13;
<p>Let’s use a prototypical example of a three-tier application deployed to a&#13;
single namespace where the tiers are labeled as <code>tier: "web"</code>,&#13;
<code>tier: "db"</code>, and <code>tier: "api"</code>. If you want to ensure that traffic is properly&#13;
limited to each tier, create a NetworkPolicy manifest&#13;
like the following.</p>&#13;
&#13;
<p>Default deny rule:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">networking.k8s.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">NetworkPolicy</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">default-deny-all</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{}</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">policyTypes</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">Ingress</code><code class="w"/></pre>&#13;
&#13;
<p>Web layer network policy:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">networking.k8s.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">NetworkPolicy</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">webaccess</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">tier</code><code class="p">:</code><code class="w"> </code><code class="s">"web"</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">policyTypes</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">Ingress</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">ingress</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="p-Indicator">{}</code><code class="w"/></pre>&#13;
&#13;
<p>API layer network policy:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">networking.k8s.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">NetworkPolicy</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">allow-api-access</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">tier</code><code class="p">:</code><code class="w"> </code><code class="s">"api"</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">policyTypes</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">Ingress</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">ingress</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">from</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">          </code><code class="nt">tier</code><code class="p">:</code><code class="w"> </code><code class="s">"web"</code><code class="w"/></pre>&#13;
&#13;
<p>Database layer network policy:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">networking.k8s.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">NetworkPolicy</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">allow-db-access</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">tier</code><code class="p">:</code><code class="w"> </code><code class="s">"db"</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">policyTypes</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">Ingress</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">ingress</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">from</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">          </code><code class="nt">tier</code><code class="p">:</code><code class="w"> </code><code class="s">"api"</code><code class="w"/></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Network Policy Best Practices" data-type="sect1"><div class="sect1" id="id83">&#13;
<h1>Network Policy Best Practices</h1>&#13;
&#13;
<p>Securing <a data-primary="best practices" data-secondary="network security policies" data-type="indexterm" id="best-practice-network-security"/>network traffic in an enterprise system was once the domain of physical hardware devices with complex networking rule sets. Now, with Kubernetes network policy, a more application-centric approach can be taken to segment and control the traffic of the applications hosted in Kubernetes. Some common best practices apply no matter which policy plug-in is used:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Start off slow and focus on traffic ingress to pods. Complicating&#13;
matters with ingress and egress rules can make network tracing&#13;
a nightmare. As soon as traffic is flowing as expected, you can begin to look at&#13;
egress rules to further control flow to sensitive workloads. The&#13;
specification also favors ingress because it defaults many options even if&#13;
nothing is entered into the ingress rules list.</p>&#13;
</li>&#13;
<li>&#13;
<p>Ensure that the network plug-in used either has some of its own interface&#13;
to the NetworkPolicy API or supports other well-known plug-ins. Example&#13;
plug-ins include Calico, Cilium, Kube-router, Romana, and Weave Net.</p>&#13;
</li>&#13;
<li>&#13;
<p>If the network team is used to having a “default-deny” policy&#13;
in place, create a network policy such as the following for each namespace in&#13;
the cluster that will contain workloads to be protected. This ensures&#13;
that even if another network policy is deleted, no pods are accidentally&#13;
“exposed”:</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">networking.k8s.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">NetworkPolicy</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">default-deny-all</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{}</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">policyTypes</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">Ingress</code><code class="w"/></pre>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>If pods need to be accessed from the internet, use a label to explicitly apply a network policy that allows ingress. Be aware of the entire flow in case the actual IP that a packet is coming from is not the internet but rather the internal IP of a load balancer, firewall, or other network device. For example, to allow traffic from all&#13;
(including external) sources for pods having the <code>allow-internet=true</code>&#13;
label, do this:</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">networking.k8s.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">NetworkPolicy</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">internet-access</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">allow-internet</code><code class="p">:</code><code class="w"> </code><code class="s">"true"</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">policyTypes</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">Ingress</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">ingress</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="p-Indicator">{}</code><code class="w"/></pre>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Try to align application workloads to single namespaces for ease of&#13;
creating rules because the rules themselves are namespace specific. If cross-namespace communication is needed, try to be as explicit as possible and&#13;
perhaps use specific labels to identify the flow pattern:</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">networking.k8s.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">NetworkPolicy</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">namespace-foo-2-namespace-bar</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">namespace</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">bar</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">app</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">bar-app</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">policyTypes</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">Ingress</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">ingress</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">from</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="p-Indicator">-</code><code class="w">  </code><code class="nt">namespaceSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">          </code><code class="nt">networking/namespace</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">foo</code><code class="w"/>&#13;
<code class="w">       </code><code class="nt">podSelector</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">          </code><code class="nt">app</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">foo-app</code><code class="w"/></pre>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Have a test bed namespace that has fewer restrictive policies, if any at&#13;
all, to allow time to investigate the correct traffic patterns<a data-primary="networking" data-secondary="security policies" data-startref="network-security-policy" data-type="indexterm" id="id782"/><a data-primary="security" data-secondary="network policies" data-startref="security-network" data-type="indexterm" id="id783"/><a data-primary="policy and governance" data-secondary="network security" data-startref="policy-network-security" data-type="indexterm" id="id784"/><a data-primary="NetworkPolicy API" data-startref="networkpolicyapi" data-type="indexterm" id="id785"/><a data-primary="best practices" data-secondary="network security policies" data-startref="best-practice-network-security" data-type="indexterm" id="id786"/> needed.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Service Meshes" data-type="sect1"><div class="sect1" id="id84">&#13;
<h1>Service Meshes</h1>&#13;
&#13;
<p>It is <a data-primary="networking" data-secondary="service meshes" data-type="indexterm" id="network-service-mesh"/><a data-primary="service meshes" data-type="indexterm" id="service-mesh"/>easy to imagine a single cluster hosting hundreds of services that&#13;
load-balance across thousands of endpoints that communicate with one another,&#13;
access external resources, and are potentially being accessed from external&#13;
sources. This can be quite daunting when trying to manage, secure,&#13;
observe, and trace all the connections among these services,&#13;
especially with the dynamic nature of the endpoints coming and going&#13;
from the overall system. The concept of a <em>service mesh</em>, which is not unique to&#13;
Kubernetes, allows for control over how these services are connected and&#13;
secured with a dedicated date plane and control plane. Service meshes&#13;
all have different capabilities, but usually they all offer some of the&#13;
following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Load balancing of traffic with potentially fine-grained traffic-shaping policies that are distributed across the mesh.</p>&#13;
</li>&#13;
<li>&#13;
<p>Service discovery of services that are members of the mesh, which might include services within a cluster or in another cluster, or an outside system that is a member of the mesh.</p>&#13;
</li>&#13;
<li>&#13;
<p>Observability of the traffic and services, including tracing across the distributed services using tracing systems like Jaeger or Zipkin that follow the OpenTracing standards.</p>&#13;
</li>&#13;
<li>&#13;
<p>Security of the traffic in the mesh using mutual authentication. In some cases, not only pod-to-pod or East-West traffic is secured, but an Ingress controller is also provided that offers North-South security and control.</p>&#13;
</li>&#13;
<li>&#13;
<p>Resiliency, health, and failure-prevention capabilities that allow for patterns such as circuit breaker, retries, deadlines, and so on.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The key here is that all these features are integrated into the&#13;
applications that take part in the mesh with little or no application&#13;
changes. How can all these amazing features come for free? <a data-primary="sidecar proxies" data-type="indexterm" id="id787"/>Sidecar&#13;
proxies are usually the way this is done. The majority of service meshes&#13;
available today inject a proxy that is part of the data plane into each&#13;
pod that is a member of the mesh. This allows for policies and security&#13;
to be synchronized across the mesh by the control-plane components. This hides the network details from the container that holds the&#13;
workload and leaves it to the proxy to handle the complexity of the&#13;
distributed network. In the application’s perspective, it only communicates via localhost to&#13;
its proxy. In many cases, the control plane and data plane might be&#13;
different technologies but complementary to each other.</p>&#13;
&#13;
<p>In many cases, the first service mesh that comes to mind is Istio, a project by Google, Lyft, and IBM that uses Envoy as its data-plane proxy&#13;
and uses proprietary control-plane components Mixer, Pilot, Galley, and Citadel. Other service meshes offer varying levels of capabilities, such as Linkerd2, which uses its own data-plane proxy built using Rust. HashiCorp has recently added more Kubernetes-centric service mesh capabilities to Consul, which allows you to choose&#13;
between Consul’s own proxy or Envoy, and offers commercial support for its service mesh.</p>&#13;
&#13;
<p>The topic of service meshes in Kubernetes is a fluid one—if not overly&#13;
emotional in many social media tech circles—so a detailed explanation&#13;
of each mesh has no value here. We would be remiss if we did not mention the promising efforts led by &#13;
<span class="keep-together">Microsoft,</span> Linkerd, HashiCorp, Solo.io, Kinvolk, and Weaveworks around the<a data-primary="Service Mesh Interface (SMI)" data-type="indexterm" id="id788"/><a data-primary="SMI (Service Mesh Interface)" data-type="indexterm" id="id789"/> Service Mesh Interface (SMI). The SMI hopes to set a standard interface for basic feature sets that are expected of all service meshes. The specification as of this writing covers traffic policy such as identity and transport-level encryption, traffic telemetry that captures key metrics between services in the mesh, and traffic management to allow for traffic shifting and weighting between different services. This project hopes to take some of the variability out of the service meshes yet allow for service mesh vendors to extend and build value-added capabilities into their products to differentiate themselves.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Service Mesh Best Practices" data-type="sect1"><div class="sect1" id="id85">&#13;
<h1>Service Mesh Best Practices</h1>&#13;
&#13;
<p>The <a data-primary="best practices" data-secondary="service meshes" data-type="indexterm" id="id790"/>service mesh community continues to grow every day, and as more enterprises help define their needs, the service mesh ecosystem will change dramatically. These best practices are, as of this writing, based on common problems that service meshes try to solve today:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Rate the importance of the key features service meshes offer and&#13;
determine which current offerings provide the most important features with&#13;
the least amount of overhead. Overhead here means both human technical debt&#13;
and infrastructure resource debt. If all that is really required is&#13;
mutual TLS between certain pods, would it be easier to perhaps find a&#13;
CNI that offers that capability integrated into the plug-in?</p>&#13;
</li>&#13;
<li>&#13;
<p>Is the need for a cross-system mesh, such as multicloud or hybrid&#13;
scenarios, a key requirement? Not all service meshes offer this&#13;
capability, and if they do, it is a complicated process that often&#13;
introduces fragility into the environment.</p>&#13;
</li>&#13;
<li>&#13;
<p>Many of the service mesh offerings are open source community-based&#13;
projects, and if the team that will be managing the environment is new to&#13;
service meshes, commercially supported offerings might be a better option.&#13;
Some companies are beginning to offer commercially supported and&#13;
managed service meshes based on Istio, which can be helpful because it is&#13;
almost universally agreed upon that Istio is a complicated system <a data-primary="networking" data-secondary="service meshes" data-startref="network-service-mesh" data-type="indexterm" id="id791"/><a data-primary="service meshes" data-startref="service-mesh" data-type="indexterm" id="id792"/>to&#13;
manage.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id361">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In addition to application management, one of the most important things&#13;
that Kubernetes provides is the ability to link different pieces of your&#13;
application. In this chapter, we looked at the details of how&#13;
Kubernetes works, including how pods get their IP addresses through CNI plug-ins, how those IPs are grouped to form services, and how more application&#13;
or Layer 7 routing can be implemented via Ingress resources (which&#13;
in turn use services). You also saw how to limit traffic and secure your network&#13;
using networking policies, and, finally, how service mesh <span class="keep-together">technologies</span> are&#13;
transforming the ways in which people connect and monitor the connections&#13;
between their services. In addition to setting up your application to&#13;
run and be deployed reliably, setting up the networking for your application&#13;
is a crucial piece of using Kubernetes successfully. Understanding how&#13;
Kubernetes approaches networking and how that intersects optimally with&#13;
your application is critical to its ultimate success.</p>&#13;
</div></section>&#13;
</div></section></body></html>