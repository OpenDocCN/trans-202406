- en: Chapter 11\. Building Platform Services
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章。构建平台服务
- en: Platform services are those components that are installed in order to add features
    to the application platform. They are usually deployed as containerized workloads
    into some `*-system` Namespace and are maintained by the platform engineering
    team. These platform services are distinct from the workloads managed by platform
    tenants, which are maintained by the application development teams.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 平台服务是安装的组件，用于为应用平台添加功能。它们通常作为容器化工作负载部署到某个`*-system`命名空间，并由平台工程团队维护。这些平台服务与应用开发团队维护的工作负载有所区别。
- en: The cloud native ecosystem is rich with projects you can use as part of your
    application platform. Additionally, there are throngs of vendors that will be
    happy to provide platform service solutions. Use these wherever they pass the
    cost benefit analysis. They may even take you all the way to your app platform
    destination. But we have found that it’s common for enterprise users of Kubernetes-based
    platforms to build custom components. You may have to integrate your Kubernetes-based
    platform with some existing in-house system. You may have some unique, sophisticated
    workload requirements to meet. You may have some edge cases to account for that
    are uncommon or specific to your business needs. Whatever the circumstance, this
    chapter addresses the details of extending your application platform with custom
    solutions to fill these gaps.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生生态系统中有许多项目可用作应用平台的一部分。此外，有大量供应商愿意提供平台服务解决方案。请在成本效益分析通过的地方使用它们。它们甚至可能将您带到应用平台的目的地。但我们发现，基于
    Kubernetes 平台的企业用户通常会构建定制组件。您可能需要将基于 Kubernetes 的平台与某些现有的内部系统集成。您可能需要满足一些独特而复杂的工作负载要求。您可能需要考虑到一些罕见或特定于业务需求的边缘情况。无论情况如何，本章将详细讨论如何通过定制解决方案扩展您的应用平台，以填补这些空白。
- en: 'Central to this notion of building custom platform services is the effort to
    remove human toil. There is more to this than just automation. Automation is the
    keystone, but integration of automated components is the mortar. Smooth, reliable
    interaction of systems is both challenging and critical. This concept of API-driven
    software is powerful because it fosters integration of software systems. This
    is part of why Kubernetes has achieved such wide adoption: it enables API-driven
    behavior for your entire platform without the need to build and expose an API
    for every piece of software you add to your platform. This software can leverage
    the Kubernetes API by either managing core resources or adding custom resources
    to represent the state of new objects. If we follow these patterns of integrated
    automation as we build our platform services, we stand to remove tremendous human
    toil. And if we succeed in this effort, we will open up greater opportunities
    for innovation, development, and advancement.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 构建定制平台服务的核心思想是消除人力劳动。这不仅仅是自动化。自动化是基石，但自动化组件的整合是灰泥。系统间的平稳可靠交互既具有挑战性又至关重要。API驱动软件的概念之所以强大，是因为它促进了软件系统的集成。这也是为什么
    Kubernetes 取得了如此广泛的应用：它使您的整个平台都能实现API驱动行为，而无需为每个添加到平台的软件构建和公开API。此类软件可以通过管理核心资源或添加自定义资源来利用
    Kubernetes API，以表示新对象的状态。如果我们在构建平台服务时遵循这些集成自动化的模式，我们就有可能消除巨大的人力劳动。如果我们在这方面取得成功，我们将为创新、发展和进步开辟更大的机会。
- en: 'In this chapter we are addressing how to extend the Kubernetes control plane.
    We are taking the effective engineering patterns used by Kubernetes and using
    those same patterns to build upon those systems. We will spend much of this chapter
    exploring Kubernetes operators, their design pattern and use cases, and how to
    develop them. However, it’s important that we first take a tour of the points
    of extension of Kubernetes so that we can maintain a holistic view of building
    platform services. It’s important that we have a clear context and apply solutions
    that are harmonious with the broader system. Finally, we will examine how we may
    extend possibly the most important Kubernetes controller in the ecosystem: the
    scheduler.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何扩展 Kubernetes 控制平面。我们正在采用 Kubernetes 使用的有效工程模式，并利用这些模式来构建这些系统。在本章的大部分内容中，我们将探讨
    Kubernetes 运算符、它们的设计模式和用例，以及如何开发它们。然而，首先我们需要了解 Kubernetes 的扩展点，以便保持构建平台服务的整体视图。我们需要明确的上下文，并应用与整体系统和谐的解决方案。最后，我们将研究如何扩展可能是生态系统中最重要的
    Kubernetes 控制器：调度器。
- en: Points of Extension
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展点
- en: Kubernetes is a wonderfully extensible system. This is certainly one of its
    most powerful features. A common critical error in software development is attempting
    to add features to meet every imaginable use case. The system can quickly become
    a maze of options with unclear paths to outcomes. Furthermore, it often becomes
    unstable as internal dependencies grow and brittle connections between components
    of the system erode reliability. There is good reason behind the central tenets
    of the Unix philosophy to do one thing well and make it interoperable. Kubernetes
    could never provide for every possible requirement users might encounter while
    orchestrating their containerized workloads. That would be an impossible system
    to build. The core functions it does provide are challenging enough. As it is,
    Kubernetes is a relatively complex distributed software system, even with a pretty
    narrow set of concerns. It could never meet every requirement, and it doesn’t
    need to since it offers points of extension that allow specialized needs to be
    met by specialized solutions that may be readily integrated. It can be extended
    and customized to meet virtually any requirements you may have.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个极具扩展性的系统。这无疑是其最强大的特性之一。在软件开发中的一个常见的关键错误是试图添加功能以满足每一个可能的用例。系统很快就会变成一个选项迷宫，到达结果的路径不清晰。此外，随着内部依赖关系的增长和系统组件之间脆弱的连接，系统往往变得不稳定，可靠性逐渐下降。Unix
    哲学的核心原则之一是做好一件事并使其可互操作。Kubernetes 永远无法满足用户在编排其容器化工作负载时可能遇到的每一个需求。构建这样一个系统是不可能的。它提供的核心功能已经足够具有挑战性了。实际上，即使是具有相对狭窄关注点的
    Kubernetes，也是一个相对复杂的分布式软件系统。它不可能满足每一个需求，也不需要，因为它提供了扩展点，允许专门的解决方案满足专门的需求，这些解决方案可以很容易地集成。它可以被扩展和定制，以满足你可能有的几乎所有需求。
- en: The context of what we are calling plug-in extensions that satisfy defined interfaces
    with Kubernetes are largely covered elsewhere in this book, as are some of the
    popular webhook extension solutions. We present a quick review of these here to
    paint a picture around the operator extension topic, which is where we will spend
    considerable time in this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称之为插件扩展的上下文，这些扩展满足 Kubernetes 定义的接口，在本书的其他部分已广泛涵盖，一些流行的 Webhook 扩展解决方案也是如此。我们在这里简要回顾它们，以围绕运算符扩展主题画一个轮廓，本章将在其中花费大量时间。
- en: Plug-in Extensions
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插件扩展
- en: 'This is a broad class of extensions that generally help integrate Kubernetes
    with adjacent systems that are important, and often essential, to running workloads
    on Kubernetes. They are specifications that third parties can use to implement
    solutions, rather than implementations themselves:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一类广泛的扩展，通常帮助将 Kubernetes 与重要且经常是运行在 Kubernetes 上的工作负载不可或缺的相邻系统集成起来。它们是第三方可以使用来实现解决方案的规范，而不是实现本身：
- en: Network
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 网络
- en: The Container Network Interface (CNI) defines the interface that must be satisfied
    by a plug-in to provide a network for containers to connect to. There are many
    plug-ins that exist to fulfill this requirement but they all must satisfy the
    CNI. This topic is covered in [Chapter 5](ch05.html#chapter5).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 容器网络接口（CNI）定义了插件必须满足的接口，以为容器提供网络连接。存在许多插件来满足这一要求，但它们都必须满足 CNI 的标准。本主题在[第五章](ch05.html#chapter5)中有所涉及。
- en: Storage
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 存储
- en: The Container Storage Interface (CSI) provides a system for exposing storage
    systems to containerized workloads. Again, there are many different volume plug-ins
    that expose storage from different providers. This topic is explored in [Chapter 4](ch04.html#chapter4).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 容器存储接口（CSI）提供了一种系统，用于向容器化工作负载公开存储系统。同样，有许多不同的卷插件从不同提供商公开存储。这个主题在 [第四章](ch04.html#chapter4)
    中进行了探讨。
- en: Container Runtime
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时
- en: The Container Runtime Interface (CRI) defines a standard for the operations
    that need to be exposed by a container runtime such that the kubelet does not
    care what runtime is in use. Docker has historically been the most popular, but
    there are now others with their own strengths that have become popular. We discuss
    this topic in detail in [Chapter 3](ch03.html#container_runtime_chapter).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时接口（CRI）定义了容器运行时需要暴露的操作标准，使得 kubelet 不关心使用的运行时是什么。历史上 Docker 是最流行的，但现在有其他具有自身优势的运行时也变得流行起来。我们在
    [第三章](ch03.html#container_runtime_chapter) 中详细讨论了这个话题。
- en: Devices
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 设备
- en: The Kubernetes device plug-in framework allows workloads to access devices on
    underlying nodes. The most common example of this we have found in the field is
    for graphics processing units (GPUs) used by compute-intensive workloads. Node
    pools are often added to clusters for nodes that have these specialized devices,
    allowing workloads to be assigned to them. See [Chapter 2](ch02.html#deployment_models)
    for more on this topic.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 设备插件框架允许工作负载访问底层节点上的设备。我们在实际应用中发现的最常见的例子是用于计算密集型工作负载的图形处理单元（GPU）。通常为具有这些专用设备的节点集群添加节点池，以便将工作负载分配给它们。关于这个主题，请参阅
    [第二章](ch02.html#deployment_models)。
- en: The development of these plug-ins is usually carried out by vendors that either
    support or sell products that are integrated. It is very rare in our experience
    to find platform developers building custom solutions in this area. Instead, it
    is generally a matter of evaluating the available options and leveraging those
    that meet your requirements.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些插件的开发通常由支持或销售与集成的产品的供应商进行。根据我们的经验，很少有平台开发人员在这个领域构建自定义解决方案。相反，通常是评估可用选项并利用符合您需求的选项。
- en: Webhook Extensions
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Webhook 扩展
- en: Webhook extensions act as a backend server for the Kubernetes API server to
    call to fulfill custom renditions of core API functionality. There are several
    steps that each request goes through when it arrives at the API server. The client
    is authenticated to ensure they are permitted access (AuthN). The API checks to
    ensure the client is authorized to perform the action they are requesting (AuthZ).
    The API server mutates the resource as called for by enabled admission plug-ins.
    The resource schema is validated, and any specialized or custom validation is
    performed by validating admission control. [Figure 11-1](#webhook_extensions_are_back_end_servers)
    illustrates the relationship between the clients, the Kubernetes API, and the
    webhook extensions leveraged by the API.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Webhook 扩展作为 Kubernetes API 服务器的后端服务器，用于满足核心 API 功能的自定义版本。每个请求到达 API 服务器时，都经历了几个步骤。客户端经过身份验证以确保他们被允许访问（AuthN）。API
    检查客户端是否被授权执行他们请求的操作（AuthZ）。API 服务器根据启用的准入插件对资源进行修改。验证资源模式，并通过验证准入控制执行任何专门或自定义的验证。[图 11-1](#webhook_extensions_are_back_end_servers)
    描述了客户端、Kubernetes API 和 API 利用的 webhook 扩展之间的关系。
- en: Authentication extensions
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 认证扩展
- en: Authentication extensions, such as OpenID Connect (OIDC), provide the opportunity
    to offload the task of authenticating requests to the API server. This topic is
    covered in depth in [Chapter 10](ch10.html#chapter10).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 认证扩展，例如 OpenID Connect（OIDC），提供了将请求身份验证任务卸载到 API 服务器的机会。这个主题在 [第十章](ch10.html#chapter10)
    中有详细介绍。
- en: You can also have the API server call out to a webhook to authorize actions
    that can be taken on resources by authenticated users. This is an uncommon implementation
    since Kubernetes has a capable Role-Based Access Control system built in. However,
    if you find this system inadequate for any reason you have this option available
    to you.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以让 API 服务器调用 webhook 来授权经过身份验证的用户对资源可以采取的操作。尽管 Kubernetes 内置了强大的基于角色的访问控制系统，这种实现方式并不常见。但是，如果您发现这种系统因某种原因不足够，您可以选择这种选项。
- en: Admission control
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准入控制
- en: Admission control is a particularly useful and widely used extension point.
    If in use, when a request is sent to the API server to perform an action, the
    API server calls any applicable admission webhooks according to the validating
    and mutating admission webhook configs. This topic is covered in [Chapter 8](ch08.html#chapter8).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Admission 控制是一个特别有用且广泛使用的扩展点。如果启用，当向 API 服务器发送请求执行操作时，API 服务器会根据验证和变更的 admission
    webhook 配置调用任何适用的 admission webhooks。有关此主题的详细信息，请参见 [第 8 章](ch08.html#chapter8)。
- en: '![prku 1101](assets/prku_1101.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![prku 1101](assets/prku_1101.png)'
- en: Figure 11-1\. Webhook extensions are backend servers leveraged by the Kubernetes
    API server.
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-1\. Webhook 扩展是 Kubernetes API 服务器利用的后端服务器。
- en: Operator Extensions
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作符扩展
- en: Operators are clients of, as opposed to backend webhooks for, the API server.
    As shown in [Figure 11-2](#operators_extensions_are_clients_of_the_kubernetes_api_server),
    software operators interact as clients of the Kubernetes API, just like human
    operators. These software operators are often called *Kubernetes Operators* and
    follow the officially documented [operator pattern](https://oreil.ly/HLXtJ). Their
    primary purpose is to relieve toil from human operators and perform operations
    on their behalf. These operator extensions follow the same engineering principles
    as the core Kubernetes control plane components. When developing operator extensions
    as platform services, think of them as custom extensions of the control plane
    for your application platform.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 操作符是 API 服务器的客户端，而不是后端 webhook。如 [图 11-2](#operators_extensions_are_clients_of_the_kubernetes_api_server)
    所示，软件操作符作为 Kubernetes API 的客户端与之交互，就像人工操作员一样。这些软件操作符通常称为 *Kubernetes 操作符*，遵循官方文档中的
    [操作符模式](https://oreil.ly/HLXtJ)。它们的主要目的是减轻人工操作员的工作负担，并代表他们执行操作。这些操作符扩展遵循与核心 Kubernetes
    控制平面组件相同的工程原理。在将操作符扩展作为平台服务开发时，想象它们是你应用平台控制平面的自定义扩展。
- en: '![prku 1102](assets/prku_1102.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![prku 1102](assets/prku_1102.png)'
- en: Figure 11-2\. Operator extensions are clients of the Kubernetes API server.
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-2\. 操作符扩展是 Kubernetes API 服务器的客户端。
- en: The Operator Pattern
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作符模式
- en: 'You could say that the operator pattern boils down to extending Kubernetes
    with Kubernetes. We create new Kubernetes resources and develop Kubernetes controllers
    to reconcile the state defined in them. We use Kubernetes resources called Custom
    Resource Definitions (CRDs) to define our new resources. These CRDs create new
    API types and tell the Kubernetes API how to validate these new objects. Then,
    we take the very same principles and designs that make Kubernetes controllers
    so effective and use those principles to build software extensions to the system.
    These are the two core mechanisms that we employ when building operators: custom
    resources and controllers.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以说操作符模式归根结底就是用 Kubernetes 扩展 Kubernetes。我们创建新的 Kubernetes 资源，并开发 Kubernetes
    控制器来协调其中定义的状态。我们使用称为自定义资源定义（CRD）的 Kubernetes 资源来定义我们的新资源。这些 CRD 创建新的 API 类型，并告诉
    Kubernetes API 如何验证这些新对象。然后，我们采用使 Kubernetes 控制器如此高效的相同原理和设计，并利用这些原则构建系统的软硬件扩展。这两个核心机制是我们在构建操作符时使用的：自定义资源和控制器。
- en: The notion of an operator was introduced in November 2016 by Brandon Phillips,
    one of the founders of CoreOS. This early definition of an operator was that an
    operator was an app-specific controller that managed a complex stateful application.
    This is still a very useful definition but has broadened somewhat over the years
    to where the Kubernetes docs now classify any controller that uses CRDs as an
    operator. This more general definition is the one we will use as it applies to
    building platform services. Your platform services may not be “complex stateful
    applications” but still can benefit from using this powerful operator pattern.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 操作符的概念由 CoreOS 的创始人之一 Brandon Phillips 于 2016 年 11 月引入。早期对操作符的定义是操作符是一个特定于应用的控制器，用于管理复杂的有状态应用程序。这个定义仍然非常有用，但多年来有所扩展，现在
    Kubernetes 文档将使用 CRD 的任何控制器归类为操作符。这个更通用的定义是我们将在构建平台服务时使用的定义。你的平台服务可能不是“复杂的有状态应用程序”，但仍然可以从使用这种强大的操作符模式中受益。
- en: The following section will look at Kubernetes controllers, which provide a model
    for the functionality we will use in our custom controllers. Then we will examine
    the custom resources that store the desired and existing state our controllers
    reconcile for us.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将介绍 Kubernetes 控制器，这些控制器提供了我们将在自定义控制器中使用的功能模型。然后我们将研究存储期望状态和现有状态的自定义资源，这些资源由我们的控制器协调。
- en: Kubernetes Controllers
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 控制器
- en: Kubernetes’ core features and functionality are provided by controllers. They
    watch resource types and respond to creation, mutation, and deletion of resources
    by fulfilling that desired state. For example, there is a controller that comes
    bundled with the kube-controller-manager that watches for ReplicaSet resource
    types. When a ReplicaSet is created, the controller creates a number of identical
    Pods—as many as were defined by the `replicas` field in the ReplicaSet. Then at
    some point later, if you change that value, the controller will create or delete
    Pods to satisfy the new desired state.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器的核心功能和功能由 Kubernetes 提供。它们监视资源类型，并响应资源的创建、变更和删除，以实现期望的状态。例如，kube-controller-manager
    预装的控制器会监视 ReplicaSet 资源类型。当创建 ReplicaSet 时，控制器会创建与 ReplicaSet 中的 `replicas` 字段定义的数量相同的
    Pod。稍后，如果更改该值，控制器将创建或删除 Pod 以满足新的期望状态。
- en: This watch mechanism is central to the functionality of all Kubernetes controllers.
    It is an etcd feature that is exposed by the Kubernetes API server to the controllers
    that need to respond to changes in resources. The controllers hold a connection
    open with the API server, which allows the API server to notify the controller
    when a change has occurred to a resource it cares about or manages.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这种监视机制是所有 Kubernetes 控制器功能的核心。它是由 Kubernetes API 服务器暴露给需要响应资源更改的控制器的 etcd 功能。控制器与
    API 服务器保持连接，这使得 API 服务器能够在关心或管理的资源发生更改时通知控制器。
- en: This enables very powerful behavior. The user can declare the desired state
    of the system by submitting resource manifests. The controllers responsible for
    fulfilling the desired state are notified and begin working to make the existing
    state match the declared, desired state. Furthermore, in addition to users submitting
    manifests, controllers can also do the same which, in turn, triggers operations
    in other controllers. In this way you end up with a system of controllers that
    can provide sophisticated functionality that is stable and reliable.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机制能够提供非常强大的行为。用户可以通过提交资源清单声明系统的期望状态。负责实现期望状态的控制器收到通知后开始工作，以使现有状态与声明的期望状态匹配。此外，除了用户提交清单外，控制器还可以执行相同的操作，从而触发其他控制器的操作。通过这种方式，您可以建立一个控制器系统，提供稳定可靠的复杂功能。
- en: One important feature of these controllers is that if they cannot fulfill the
    desired state due to some impediment, they will continue to try on an infinite
    loop. The duration between attempts to fulfill desired state may increase over
    time so that undue load is not placed on the system, but try it will. This provides
    a self-healing behavior that is incredibly important in complex distributed systems
    such as this.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些控制器的一个重要特点是，如果它们由于某些障碍无法满足期望的状态，它们将继续尝试在无限循环中操作。尝试满足期望状态之间的时间间隔可能随着时间的推移而增加，以便不对系统施加不必要的负荷，但它们依然会尝试。这提供了一种自我修复行为，在复杂的分布式系统中尤为重要。
- en: For example, the scheduler is responsible for assigning Pods to nodes in the
    cluster. The scheduler is just another Kubernetes controller, just with a particularly
    important and involved task. If there are insufficient compute resources available
    for one or more Pods, they will go into a “Pending” state and the scheduler will
    continue to attempt to schedule the Pod at some interval. As such, if compute
    resources free up or are added at any point, the Pod will be scheduled and run.
    So if another batch workload completes and resources free up, or if a cluster
    autoscaler adds some worker nodes, the Pending Pod will be assigned with no further
    action required from a human operator.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，调度器负责将 Pod 分配给集群中的节点。调度器只是另一个 Kubernetes 控制器，但其任务非常重要且复杂。如果没有足够的计算资源可用于一个或多个
    Pod，它们将进入“Pending”状态，调度器将继续尝试以一定的间隔调度 Pod。因此，如果在任何时候释放了计算资源或添加了计算节点，该 Pod 将被调度并运行。例如，如果另一个批处理工作负载完成并释放了资源，或者如果集群自动缩放器添加了一些工作节点，则“Pending”
    Pod 将被分配，无需运营人员进一步操作。
- en: 'In following the operator pattern to build extensions to your application platform,
    it’s essential to use these design principles used by Kubernetes controllers:
    (1) watch resources in the Kubernetes API to get notified when changes to their
    desired state occur, and (2) work to reconcile existing and desired state on a
    nonterminating loop.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在遵循操作者模式来构建应用平台的扩展时，使用 Kubernetes 控制器所采用的设计原则至关重要：（1）监视 Kubernetes API 中的资源，以便在其期望状态发生更改时得到通知；以及（2）在非终止循环中努力协调现有状态与期望状态。
- en: Custom Resources
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义资源
- en: One of the most important features of the Kubernetes API is the ability to extend
    the resource types it will recognize. If you submit a valid CRD you will immediately
    have a new custom API type at your disposal. The CRD contains all the fields that
    you will need in your custom resource both in the `spec` where you will provide
    the desired state for your resource and in the `status` where you can record important
    information about the observed, existing state.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes API 的最重要特性之一是其能够扩展它将识别的资源类型。如果您提交一个有效的 CRD，您将立即拥有一个新的自定义 API 类型可供使用。CRD
    包含了您在自定义资源中所需的所有字段，无论是在`spec`中，您可以在那里提供资源的期望状态，还是在`status`中，您可以记录关于观察到的现有状态的重要信息。
- en: Before diving further into this topic, let’s briefly review Kubernetes resources.
    We are going to be talking a lot about resources in this chapter, so it’s important
    to ensure we’re crystal clear on this topic. When we talk about *resources* in
    Kubernetes, we are referring to the objects that are used to record state. An
    example of a common resource is the Pod resource. When you create a Pod manifest,
    you are defining the attributes of what will become a Pod resource. When you submit
    that to the API server with `kubectl apply -f pod.yaml` or similar, you are creating
    an instance of the Pod API type. On one hand you have the API type, or “kind,”
    which refers to the definition and form of the object as provided in a CRD. On
    the other hand we have the resource that is an instantiation or instance of that
    kind. The Pod is an API type or kind. A Pod you create with the name “my-app”
    is a Kubernetes resource.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步深入这个主题之前，让我们简要回顾一下 Kubernetes 资源。在本章中，我们将大量讨论资源，因此确保我们对此主题非常清楚是很重要的。当我们在
    Kubernetes 中谈论 *资源* 时，我们指的是用于记录状态的对象。一个常见资源的示例是 Pod 资源。当您创建 Pod 清单时，您正在定义将成为 Pod
    资源的属性。当您使用 `kubectl apply -f pod.yaml` 或类似命令将其提交到 API 服务器时，您正在创建 Pod API 类型的实例。一方面，您有
    API 类型或“种类”，它指的是在 CRD 中提供的对象的定义和形式。另一方面，我们有资源，它是该种类的实例或实例化。Pod 是一个 API 类型或种类。您使用名称“my-app”创建的
    Pod 是一个 Kubernetes 资源。
- en: Unlike a relational database where relationships between objects are recorded
    and linked by foreign keys in the database itself, each object in the Kubernetes
    API exists independently. Relationships are established using labels and selectors,
    and it is the job of the controllers to manage relationships defined this way.
    You cannot query etcd for related objects the way you can with structured query
    language (SQL). So when we talk about resources, we’re talking about actual instances
    of Namespaces, Pods, Deployments, Secrets, ConfigMaps, etc. When we talk about
    custom resources, we’re referring to user-defined resources that have been added
    and defined with CRDs. When you create a CRD, you define new API types that allow
    you to create and manage custom resources as you would other core Kubernetes resources.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于关系数据库，其中对象之间的关系由数据库中的外键记录和链接，Kubernetes API 中的每个对象都是独立存在的。关系是使用标签和选择器建立的，控制器的工作是管理以这种方式定义的关系。您无法像使用结构化查询语言（SQL）那样查询
    etcd 中的相关对象。因此，当我们谈论资源时，我们指的是命名空间、Pod、部署、机密、配置映射等的实际实例。当我们谈论自定义资源时，我们指的是使用 CRD
    添加和定义的用户定义资源。当您创建 CRD 时，您定义了新的 API 类型，使您能够像管理其他核心 Kubernetes 资源一样创建和管理自定义资源。
- en: CRDs use the Open API v3 schema specification for defining fields. This allows
    for features like setting fields as optional or required as well as setting default
    values. This will provide validation instructions for the API server when it receives
    a request to create or update one of your custom resources. In addition, you can
    group your APIs for improved logical organization and, very importantly, version
    your API types as well.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: CRD 使用 Open API v3 模式规范来定义字段。这允许特性，如将字段设置为可选或必需，以及设置默认值。这将为 API 服务器提供验证指令，当它收到创建或更新您的自定义资源的请求时。此外，您还可以对
    API 进行分组以改善逻辑组织，并且非常重要的是，也可以对您的 API 类型进行版本控制。
- en: 'To illustrate what a CRD is and what a manifest for the resulting custom resource
    looks like, let’s look at a fictional example of a custom WebApp API type. In
    this example, a WebApp resource includes the desired state for a web application
    that consists of the following six Kubernetes resources:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明 CRD 是什么以及生成的自定义资源清单是什么样子，让我们看一个虚构的 WebApp API 类型的示例。在此示例中，WebApp 资源包括一个由以下六个
    Kubernetes 资源组成的 Web 应用程序的期望状态：
- en: Deployment
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 部署
- en: A stateless application that provides a user interface for clients, processes
    requests, and stores data in a relational database
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为客户提供用户界面、处理请求并将数据存储在关系数据库中的无状态应用
- en: StatefulSet
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet
- en: The relational database that provides the persistent data store for the web
    application
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 提供 Web 应用程序的持久数据存储的关系数据库
- en: ConfigMap
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMap
- en: Contains the config file for the stateless application, which is mounted into
    each Pod of the Deployment
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 包含状态应用的配置文件，该文件被挂载到每个部署的 Pod 中
- en: Secret
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Secret
- en: Contains credentials for the application to connect to its database
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 包含应用程序连接到其数据库所需的凭据
- en: Service
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Service
- en: Routes traffic to the Deployment’s backend Pods
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 路由流量到部署的后端 Pod。
- en: Ingress
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress
- en: Contains routing rules for the Ingress controller to properly route client requests
    into the cluster
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 包含路由规则，使 Ingress 控制器能够正确路由客户端请求到集群中
- en: The creation of a WebApp resource would prompt a WebApp Operator to create these
    various child resources. These created resources would constitute a complete,
    functioning instance of the web application that serves clients that are end users
    and customers of the business.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 WebApp 资源将促使 WebApp 操作员创建这些各种子资源。这些创建的资源将构成一个完整、功能齐全的 Web 应用实例，为企业的最终用户和客户提供服务。
- en: '[Example 11-1](#webapp_custom_resources_definition_manifest) illustrates what
    a CRD might look like to define a new WebApp API type.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-1](#webapp_custom_resources_definition_manifest)展示了定义新 WebApp API 类型的
    CRD 的样例。'
- en: Example 11-1\. WebApp CRD manifest
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-1\. WebApp CRD 清单
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO1-1)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO1-1)'
- en: The name of the custom resource *definition*, as distinct from the name of the
    custom resource itself.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义资源*定义*的名称，与自定义资源本身的名称不同。
- en: '[![2](assets/2.png)](#co_building_platform_services_CO1-2)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_building_platform_services_CO1-2)'
- en: The name of the custom resource, as distinct from the definition. This includes
    the variations of the name such as the plural version.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义资源的名称，与定义不同。这包括名称的变体，如复数形式。
- en: '[![3](assets/3.png)](#co_building_platform_services_CO1-3)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_building_platform_services_CO1-3)'
- en: The `deploymentTier` field must contain one of the values listed under `enum`.
    This validation will be carried out by the API server when it receives requests
    to create or update an instance of this custom resource.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`deploymentTier` 字段必须包含 `enum` 列出的值之一。当 API 服务器接收到创建或更新此自定义资源实例的请求时，将执行此验证。'
- en: '[![4](assets/4.png)](#co_building_platform_services_CO1-4)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_building_platform_services_CO1-4)'
- en: The `webAppReplicas` field includes a default value that will be applied if
    the field is not provided.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`webAppReplicas` 字段包含一个默认值，如果未提供该字段，则会应用该默认值。'
- en: '[![5](assets/5.png)](#co_building_platform_services_CO1-5)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_building_platform_services_CO1-5)'
- en: The required fields are listed here. Note that `webAppReplicas` is not included
    and that it has a default value.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此处列出了必填字段。注意 `webAppReplicas` 未包括在内且具有默认值。
- en: Now let’s examine what a manifest for a WebApp would look like. Before submitting
    the manifest shown in [Example 11-2](#ex_11-2) to the API server, you must first
    create the CRD shown in [Example 11-1](#webapp_custom_resources_definition_manifest)
    so that Kubernetes has an API for it. Otherwise, it will not recognize what you
    are trying to create.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看一个 WebApp 的清单会是什么样子。在将[示例 11-2](#ex_11-2)中显示的清单提交给 API 服务器之前，您必须先创建[示例 11-1](#webapp_custom_resources_definition_manifest)中显示的
    CRD，以便 Kubernetes 有一个针对它的 API。否则，它将无法识别您试图创建的内容。
- en: Example 11-2\. An example of a manifest for a WebApp resource
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-2\. WebApp 资源清单的示例
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO2-1)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO2-1)'
- en: This manifest specifies the default value for an optional field, which is unnecessary
    but fine to do if explicitness is desired.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此清单指定了可选字段的默认值，如果需要显式指定，则是不必要的但可行的。
- en: '[![2](assets/2.png)](#co_building_platform_services_CO2-2)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_building_platform_services_CO2-2)'
- en: One of the permitted values for this field is used. Any value that is not permitted
    would prompt the API server to reject the request with an error.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此字段的允许值之一被使用。任何不被允许的值将促使 API 服务器拒绝带有错误的请求。
- en: When this WebApp manifest is submitted to the Kubernetes API, the WebApp Operator
    will be notified via its watch that a new instance of the WebApp kind has been
    created. It will fulfill the desired state expressed in the manifest by calling
    the API server to create the various child resources needed to spin up an instance
    of the web application.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当此 WebApp 清单提交到 Kubernetes API 时，WebApp 运算符将通过其监视收到通知，表示已创建 WebApp 类型的新实例。它将通过调用
    API 服务器来创建各种需要的子资源，以启动 Web 应用程序的实例，从而实现清单中表达的所需状态。
- en: Warning
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: While the custom resource model is powerful, do not overuse it. Do not use custom
    resources as the primary data store for an end-user application. Kubernetes is
    a container orchestration system. etcd should be storing the state of your software
    deployments, not the internal persistent data for your application. Doing so will
    put significant load on your cluster’s control plane. Stick with relational databases,
    object stores, or whatever data store makes sense for your application. Leave
    the control plane to manage software deployments.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然自定义资源模型功能强大，但不要过度使用它。不要将自定义资源用作最终用户应用程序的主要数据存储。Kubernetes 是一个容器编排系统。etcd 应该存储您的软件部署的状态，而不是应用程序的内部持久数据。这样做会给集群的控制平面带来重大负荷。坚持使用关系数据库、对象存储或适合应用程序的任何数据存储。让控制平面管理软件部署。
- en: Operator Use Cases
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运算符使用案例
- en: When developing a Kubernetes-based platform, operators offer a compelling model
    for adding features to that platform. If you can represent the state of the system
    you need to implement in the fields of a custom resource, and if you can yield
    value from reconciling changes using a Kubernetes controller, an operator is often
    a great option.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发基于 Kubernetes 的平台时，运算符为向该平台添加功能提供了引人注目的模型。如果您可以在自定义资源的字段中表示所需实现的系统状态，并且可以通过使用
    Kubernetes 控制器调和变更以产生价值，那么运算符通常是一个很好的选择。
- en: In addition to platform features, operators may be used to facilitate the management
    of software deployments on your platform. They can provide the convenience of
    a generalized abstraction or can be custom-built for the needs of a particular
    sophisticated application. In either case, using software to manage software deployments
    is very useful.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 除了平台功能之外，运算符还可用于简化在平台上管理软件部署。它们可以提供通用抽象的便利，或者可以根据特定复杂应用程序的需求进行定制构建。无论哪种情况，使用软件来管理软件部署非常有用。
- en: 'In this section we’re going to discuss the three general operator categories
    that you may consider using with your platform:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论您可以考虑在平台上使用的三种一般运算符类别：
- en: Platform utilities
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平台实用工具
- en: General-purpose workload operators
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用工作负载运算符
- en: App-specific operators
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用特定运算符
- en: Platform Utilities
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平台实用工具
- en: 'Operators can be extremely useful in developing your platform. They allow you
    to add features to your cluster and build out functionality on top of Kubernetes
    in a way that leverages and integrates with the control plane seamlessly. There
    is a wealth of open source projects that utilize operators to provide platform
    services atop Kubernetes. These projects are already available and don’t require
    you develop them. The reason we bring them up in a chapter about building them
    is that they help build a good mental model for how they work. Should you find
    yourself having to develop custom platform utilities, looking at existing successful
    projects will be helpful:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 运算符在开发您的平台时可以非常有用。它们允许您向集群添加功能，并在 Kubernetes 的基础上构建功能，以一种与控制平面无缝集成和利用的方式。有大量的开源项目利用运算符在
    Kubernetes 上提供平台服务。这些项目已经可用，无需您开发。我们在讨论构建它们的章节中提到它们的原因是它们帮助建立一个良好的心理模型，以了解它们的工作方式。如果您发现自己不得不开发定制平台实用工具，查看现有成功项目将是有帮助的。
- en: The [Prometheus Operator](https://oreil.ly/ClgDL) allows you to provide metrics
    collection, storage, and alerting platform services on your platform. In [Chapter 9](ch09.html#observability_chapter)
    we delve into the value that can be derived from this project.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Prometheus 运算符](https://oreil.ly/ClgDL) 允许您在平台上提供度量收集、存储和警报服务。在 [第 9 章](ch09.html#observability_chapter)
    中，我们深入探讨了可以从该项目中获得的价值。'
- en: '[cert-manager](https://cert-manager.io) provides certificate management as
    a service functionality. It removes significant toil and potential for downtime
    by offering x509 certificate creation and renewal services.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[cert-manager](https://cert-manager.io) 提供作为服务的证书管理功能。通过提供 x509 证书的创建和更新服务，它消除了显著的重复工作和潜在的停机风险。'
- en: '[Rook](https://rook.io) is storage operator that integrates with providers
    like [Ceph](https://ceph.io) to manage block, object, and filesystem storage as
    a service.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Rook](https://rook.io) 是一种存储操作器，与 [Ceph](https://ceph.io) 等提供者集成，用于管理块、对象和文件系统存储作为服务。'
- en: These open source solutions are examples of what is available in the community.
    There are also countless vendors that can provide and support similar platform
    utilities. However, when a solution is not available or not a good fit, enterprises
    sometimes build their own custom platform utilities.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这些开源解决方案是社区中可用的示例。还有无数供应商可以提供和支持类似的平台工具。然而，当不存在或不适合解决方案时，企业有时会构建自己的定制平台工具。
- en: A common example of a custom platform utility we see in the field is a Namespace
    operator. We have found it quite common for organizations to have a standard set
    of resources that are created with each Namespace, such as ResourceQuotas, LimitRanges,
    and Roles. And it has been a useful pattern to use a controller to take care of
    the routine tedium of creating these resources for each Namespace. In a later
    section, we will use this Namespace operator idea as an example to illustrate
    some implementation details when building operators.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在现场常见的定制平台工具的一个常见示例是命名空间操作器。我们发现组织通常有一套标准资源，每个命名空间都会创建这些资源，例如 ResourceQuotas、LimitRanges
    和 Roles。使用控制器来处理为每个命名空间创建这些资源的例行琐事已经是一种有用的模式。在后面的部分，我们将使用命名空间操作器的概念作为一个例子，以展示构建操作器时的一些实现细节。
- en: General-Purpose Workload Operators
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通用工作负载操作器
- en: Application developers’ core competency and concern is to add stability and
    features to the software they build. It is not writing YAML for deployment to
    Kubernetes. Learning how to properly define resource limits and requests, learning
    how to mount a ConfigMap volume or Secret as an environment variable, learning
    how to use label selectors to associate Services with Pods—none of these things
    add features or stability to their software.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 应用开发人员的核心能力和关注点是为其构建的软件增加稳定性和功能。不是编写用于 Kubernetes 部署的 YAML。学习如何正确定义资源限制和请求，学习如何将
    ConfigMap 卷或 Secret 作为环境变量挂载，学习如何使用标签选择器将服务与 Pod 关联起来——这些事情都不能为他们的软件增加功能或稳定性。
- en: In an organization that has developed common patterns for deployed workloads,
    the model of abstracting the complexity in a general-purpose manner has considerable
    promise. This is especially relevant in organizations that have embraced microservice
    architectures. In these environments there may be a considerable number of distinct
    pieces of software that are deployed with different functionality, but with very
    similar patterns of deployment.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在已经为部署工作负载开发了常见模式的组织中，以通用方式抽象复杂性的模型具有相当大的潜力。这在已经采用微服务架构的组织中尤其相关。在这些环境中，可能会部署大量具有不同功能但部署模式非常相似的软件组件。
- en: For example, if your company has a large number of workloads that consist of
    a Deployment, Service, and Ingress resource, there are likely patterns that can
    be encoded into an operator that can abstract much of the resource manifests for
    these objects. In each case the Service references labels on the Pods of a Deployment.
    In each case the Ingress references the Service name. All these things can easily
    be handled by an operator—getting these details right is the definition of toil.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您的公司有大量由 Deployment、Service 和 Ingress 资源组成的工作负载，可能存在可以将这些对象的大部分资源清单抽象为操作器的模式。在每种情况下，Service
    引用 Deployment 的 Pod 上的标签。在每种情况下，Ingress 引用 Service 名称。所有这些细节都可以由操作器轻松处理——确保这些细节正确无误是琐事的定义。
- en: App-Specific Operators
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用特定操作器
- en: 'This type of operator hits at the core of what a Kubernetes operator is: custom
    resources in conjunction with a custom Kubernetes controller for managing a complex
    stateful application. They are purpose-built to manage a particular application.
    Popular examples of this model are the various database operators in the community.
    We have operators for Cassandra, Elasticsearch, MySQL, MariaDB, PostgreSQL, MongoDB
    and many more. Commonly, they handle initial deployment as well as day 2 management
    concerns such as configuration updates, backups, and upgrades.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的操作器直接触及 Kubernetes 操作员的核心：自定义资源与自定义 Kubernetes 控制器结合，用于管理复杂的有状态应用程序。它们专为管理特定应用程序而构建。社区中此模型的流行示例包括各种数据库操作器。我们有
    Cassandra、Elasticsearch、MySQL、MariaDB、PostgreSQL、MongoDB 等操作器。通常，它们处理初始部署以及配置更新、备份和升级等第二天管理的问题。
- en: Operators for popular community- or vendor-supported projects have gained in
    popularity over the past few years. The area where this is approach is still in
    its infancy is in internal enterprise applications. In cases where your organization
    internally develops and maintains a sophisticated stateful application, an app-specific
    operator may be beneficial. For example, if your company maintains something like
    an ecommerce website, transaction processing app, or inventory management system
    that delivers critical business functionality, you may want to consider this option.
    There is tremendous opportunity for reducing human toil in the deployment and
    day 2 management of these kinds of workloads, especially when they are deployed
    widely and updated frequently.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几年里，为流行的社区或供应商支持的项目开发的操作员已经变得越来越受欢迎。这种方法仍处于内部企业应用的初期阶段。在您的组织内部开发和维护复杂的有状态应用程序的情况下，可能会有利于使用特定于应用的操作员。例如，如果您的公司维护类似电子商务网站、交易处理应用程序或库存管理系统等提供关键业务功能的应用程序，您可能需要考虑这个选项。特别是当这些工作负载被广泛部署并频繁更新时，有很大的机会减少人为工作的投入，尤其是在部署和日常管理方面。
- en: This isn’t to say that these app-specific operators are the universally right
    choice for managing your workloads. For simpler use cases, they are likely to
    be severe overkill. Production-ready operators are not trivial to develop, so
    weigh the trade-offs. How much time do you spend in routine toil managing deployment
    and day 2 concerns for an application? Is the engineering cost of building an
    operator likely to be less than that routine toil over the long term? Could simpler,
    existing tools such as Helm or Kustomize provide enough automation to sufficiently
    alleviate toil?
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说这些特定于应用程序的操作员是管理工作负载的普遍正确选择。对于更简单的用例，它们可能过于复杂了。生产就绪的操作员开发并不是一件轻松的事情，所以需要权衡利弊。您在日常工作中管理应用程序的部署和日常管理工作花费了多少时间？与长期的例行工作相比，构建操作员的工程成本可能更低吗？像
    Helm 或 Kustomize 这样的现有工具是否能提供足够的自动化来有效减少这些例行工作？
- en: Developing Operators
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作员开发
- en: Taking on the task of developing Kubernetes operators is not trivial, especially
    if tackling a full-featured, app-specific operator. The engineering investment
    to get one of these more involved projects into production can be considerable.
    As with other types of software development, if getting started in this area,
    begin with less involved projects while you become familiar with useful patterns
    and successful strategies. In this section we’ll discuss some tools and design
    strategies that will help make developing operators a more efficient and successful
    endeavor.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 开发 Kubernetes 操作员任务并不轻松，特别是当涉及全功能、特定于应用的操作员时。将这类更复杂的项目投入生产的工程投入可能是相当可观的。与其他软件开发类型类似，如果初次涉足这个领域，建议从较简单的项目开始，同时熟悉有用的模式和成功的策略。在本节中，我们将讨论一些工具和设计策略，这些将有助于使操作员开发更高效、更成功。
- en: We will cover some specific projects you can leverage to help in development
    of such tools. And then we’ll break down the process of designing and implementing
    this kind of software in detail. We’ll include some code snippets to illustrate
    the concepts and best practices.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍一些您可以利用的特定项目，来帮助开发这些工具。然后，我们将详细分解设计和实现这类软件的过程。我们将包含一些代码片段来说明相关概念和最佳实践。
- en: Operator Development Tooling
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作员开发工具
- en: If you have a compelling use case for a custom Kubernetes operator, there are
    a couple of community projects that can be very helpful in your endeavor. If you
    are—or have on staff—an experienced Go programmer that is familiar with the Kubernetes
    client-go library and with developing Kubernetes operators, you can certainly
    write your operators from scratch. However, there are common components to every
    operator, and using tools to generate boilerplate source code and utilities are
    expediencies that even seasoned operator developers commonly use. They just save
    time. Software development kits (SDKs) and frameworks can be helpful when they
    fit the pattern of software you’re developing. However, they can be a nuisance
    if they make assumptions that don’t suit your purpose. If your project fits the
    standard model of using one or more custom resources to define configuration,
    and custom controllers to implement behavior associated with these objects, it
    is likely the tools we discuss here will be useful.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个为自定义 Kubernetes 运算符创建强有力使用案例的需求，有几个社区项目可能对你的努力非常有帮助。如果你自己或团队中有经验丰富的 Go
    程序员，熟悉 Kubernetes 的 client-go 库以及开发 Kubernetes 运算符，你完全可以从头开始编写你的运算符。然而，每个运算符都有共同的组件，使用工具来生成样板源代码和实用程序是经验丰富的运算符开发人员普遍使用的便利工具，它们可以节省时间。软件开发工具包（SDK）和框架在符合你正在开发的软件模式时会很有帮助。然而，如果它们做出的假设不适合你的目的，它们可能会成为一种麻烦。如果你的项目符合使用一个或多个自定义资源来定义配置，并使用自定义控制器来实现与这些对象相关联行为的标准模型，那么我们在这里讨论的工具很可能会对你有所帮助。
- en: Kubebuilder
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubebuilder
- en: Kubebuilder can be described as an SDK for building Kubernetes APIs. This is
    an apt description but is not exactly what you might expect. Using kubebuilder
    begins with the command-line tool that you use to generate boilerplate. It stamps
    out the source code, a Dockerfile, a Makefile, sample Kubernetes manifests—all
    the things you need to write for every such project. As such, it saves a ton of
    time in getting a project started.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Kubebuilder 可以被描述为构建 Kubernetes API 的 SDK。这是一个恰当的描述，但不完全符合你可能期望的预期。使用 kubebuilder
    从命令行工具开始，你可以用它来生成样板。它会生成源代码、一个 Dockerfile、一个 Makefile，以及示例 Kubernetes 清单——所有你需要为每个类似项目编写的东西。因此，它在启动项目方面节省了大量时间。
- en: Kubebuilder also leverages a collection of tools in a related project called
    controller-runtime. The required imports and common implementations are included
    in the source code generated by the CLI. These help with much of the routine heavy
    lifting of running a controller and interacting with the Kubernetes API. It helps
    with setting up shared caches and clients to provide efficient interaction with
    the API server. The cache allows your controller to list and get objects without
    new requests to the API server for each query, which eases load on the API server
    and speeds up reconciliation. Controller-runtime also provides mechanisms for
    triggering reconcile requests in response to events such as resource changes.
    These reconciliations will be triggered by default for the parent custom resource.
    They can—and usually should—also be triggered when changes occur to child resources
    created by the controller and functions are available to do so. If running your
    controller in highly available (HA) mode, controller-runtime provides the opportunity
    to enable leader election to ensure just one controller is active at any given
    time. Furthermore, controller-runtime includes a package to implement webhooks,
    which are often used for admission control. Lastly, the library includes facilities
    to write structured logs and expose Prometheus metrics for observability.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Kubebuilder 还利用了一个称为 controller-runtime 的相关项目中的一系列工具。CLI 生成的源代码中包含了所需的导入和常见实现。这些工具有助于处理控制器的日常繁重工作并与
    Kubernetes API 交互。它帮助设置共享缓存和客户端，以便有效地与 API 服务器进行交互。缓存允许你的控制器列出和获取对象，而无需为每个查询向
    API 服务器发送新请求，从而减轻 API 服务器的负载并加快协调速度。Controller-runtime 还提供了在资源更改等事件发生时触发协调请求的机制。这些协调默认会为父自定义资源触发。通常情况下，也应在控制器创建的子资源发生更改时触发它们，函数可用来执行此操作。如果在高可用（HA）模式下运行控制器，controller-runtime
    提供了启用领导选举以确保任何给定时间只有一个控制器处于活动状态的机会。此外，controller-runtime 还包括一个实现 Webhooks 的包，通常用于准入控制。最后，该库包含编写结构化日志和暴露
    Prometheus 指标以进行可观察性的设施。
- en: Kubebuilder is a great choice if you are a Go programmer with Kubernetes experience.
    It is even a good choice if you are an experienced software developer but are
    new to the Go programming language. But it is exclusively for Go—it doesn’t cater
    to other languages.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一个具有 Kubernetes 经验的 Go 程序员，Kubebuilder 是一个很好的选择。即使你是一位有经验的软件开发者但是对 Go 编程语言还不熟悉，Kubebuilder
    也是一个不错的选择。但它只适用于 Go，不支持其他语言。
- en: Tip
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If you are going to be developing tools for Kubernetes, you should strongly
    consider learning Go if you don’t know it already. You can certainly use other
    languages. Kubernetes offers a REST API, after all. And there are officially supported
    client libraries for Python, Java, C#, JavaScript, and Haskell, not to mention
    many other community-supported libraries. If you have important reasons for using
    these, you can certainly be successful. However, Kubernetes itself is written
    in Go, and the ecosystem for that language in the world of Kubernetes is rich
    and well-supported.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算为 Kubernetes 开发工具，如果你还不懂 Go 语言，你应该强烈考虑学习它。当然你也可以使用其他语言。毕竟 Kubernetes 提供了一个
    REST API。并且官方支持的客户端库有 Python、Java、C＃、JavaScript 和 Haskell，更不用说许多其他社区支持的库了。如果你有使用这些语言的重要理由，你肯定可以取得成功。然而，Kubernetes
    本身是用 Go 编写的，在 Kubernetes 的世界里，Go 语言的生态系统非常丰富且得到了良好的支持。
- en: One of the features of Kubebuilder that make it such a time-saver is its generation
    of CRDs. Writing a CRD manifest by hand is no joke. The OpenAPI v3 spec that is
    used to define these custom APIs is pretty detailed and involved. The Kubebuilder
    CLI will generate the files where you will define the fields for your custom API
    types. You add the various fields to the struct definitions and tag them with
    special markers that provide metadata such as default values. Then you can use
    a make target to generate the CRD manifests. It is very handy.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Kubebuilder 的一个特性是它可以生成 CRD，这使得它成为一个节省时间的工具。手动编写 CRD 的清单可不是闹着玩的。用于定义这些自定义 API
    的 OpenAPI v3 规范非常详细和复杂。Kubebuilder CLI 将生成文件，你可以在其中定义自定义 API 类型的字段。你可以向结构定义中添加各种字段，并使用特殊标记来提供元数据，如默认值。然后你可以使用
    make 目标生成 CRD 清单。非常方便。
- en: On the subject of make targets, in addition to generating CRDs, you can generate
    the RBAC and sample custom resource manifests, install the custom resources in
    your development cluster, build and publish images for your operator, and run
    your controller locally against a cluster during development. Having conveniences
    for all these tedious, time-consuming tasks really is a productivity boost, especially
    early in the project.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 make 目标，除了生成 CRD 外，你还可以生成 RBAC 和示例自定义资源清单，在开发集群中安装自定义资源，为你的运算符构建和发布镜像，并在开发过程中对本地集群运行你的控制器。所有这些繁琐、耗时任务的便利确实提高了生产力，尤其是在项目早期。
- en: For these reasons, we prefer and recommend Kubebuilder for building operators.
    It has been adopted and used with success in a variety of projects.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这些原因，我们推荐使用 Kubebuilder 来构建运算符。它已经被成功采用和应用在多种项目中。
- en: Metacontroller
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Metacontroller
- en: 'If your comfort with a particular programming language besides Go compels you
    to stick with it, another useful option to aid in developing operators is Metacontroller.
    This is an entirely different approach to developing and deploying operators,
    but it is one that is worth considering if you want to use a variety of languages
    and expect to deploy a number of custom in-house operators with your platform.
    Engineers experienced in programming Kubernetes will also sometimes use Metacontroller
    for prototyping and then use Kubebuilder for the final project once design and
    implementation details have been established. And this alludes to one of the strengths
    of Metacontroller: once you have the Metacontroller add-on installed in your cluster,
    it is fast to get going.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对除了 Go 之外的某种特定编程语言感到舒适，并且有理由坚持使用它，那么在开发运算符时另一个有用的选择是 Metacontroller。这是一种完全不同的开发和部署运算符的方法，但如果你希望使用各种语言并计划在平台上部署多个自定义内部运算符，那么它值得考虑。有经验的
    Kubernetes 编程工程师有时也会使用 Metacontroller 进行原型设计，然后在设计和实现细节明确之后使用 Kubebuilder 完成最终项目。这也揭示了
    Metacontroller 的一个优点：一旦在集群中安装了 Metacontroller 插件，启动速度很快。
- en: 'That is essentially what Metacontroller is: a cluster add-on that abstracts
    away the interaction with the Kubernetes API. Your job is to write the controller
    webhook that contains your controller’s logic. Metacontroller calls this the *lambda
    controller*. Your lambda controller makes decisions about what to do with the
    resources it cares about. Metacontroller watches the resources under management
    and alerts your controller with an HTTP call when there is a change it needs to
    make a decision about. Metacontroller itself uses custom resources that define
    the characteristics of your webhook, e.g., its URL and the resources it manages.
    As such, once Metacontroller is running in your cluster, adding a controller consists
    of deploying your lambda controller webhook and adding a Metacontroller custom
    resource; e.g., composite controller resource. And all your new controller need
    do is expose an endpoint that will accept requests from Metacontroller, parse
    JSON payloads that contain the Kubernetes resource object in question, and then
    return a response to Metacontroller with any changes to be sent to the Kubernetes
    API. [Figure 11-3](#metacontroller_abstracts_the_kubernetes_api_for_your_lamda_controller)
    illustrates how these components interact when using Metacontroller.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 Metacontroller 的本质：一个集群附加组件，抽象出与 Kubernetes API 的交互。您的工作是编写控制器 webhook，其中包含您的控制器逻辑。Metacontroller
    将其称为*lambda 控制器*。您的 lambda 控制器负责决定如何处理其关心的资源。Metacontroller 监视管理的资源，并在需要做出决策时通过
    HTTP 调用通知您的控制器。Metacontroller 本身使用自定义资源来定义您的 webhook 的特性，例如其 URL 和它所管理的资源。因此，一旦
    Metacontroller 在您的集群中运行，添加控制器就包括部署您的 lambda 控制器 webhook，并添加 Metacontroller 自定义资源；例如，组合控制器资源。而您的新控制器所需做的就是公开一个端点，接受来自
    Metacontroller 的请求，解析包含相关 Kubernetes 资源对象的 JSON 负载，然后返回带有任何要发送到 Kubernetes API
    的更改的响应。[图 11-3](#metacontroller_abstracts_the_kubernetes_api_for_your_lamda_controller)展示了使用
    Metacontroller 时这些组件如何交互。
- en: '![prku 1103](assets/prku_1103.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![prku 1103](assets/prku_1103.png)'
- en: Figure 11-3\. Metacontroller abstracts the Kubernetes API for your lambda controller.
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-3\. Metacontroller 为您的 lambda 控制器抽象了 Kubernetes API。
- en: What Metacontroller does not help with is the creation of any CRDs you may need
    to add to your cluster. You are on your own there. If you are writing a controller
    that responds to changes in core Kubernetes resources, this won’t be an issue.
    But if you’re developing custom resources, this is an area where Kubebuilder has
    a significant advantage.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Metacontroller 不帮助您创建可能需要添加到您的集群中的任何 CRD。在这方面，您是独立的。如果您正在编写一个响应核心 Kubernetes
    资源变化的控制器，这不是问题。但是，如果您正在开发自定义资源，那么 Kubebuilder 在这一领域具有显著优势。
- en: Operator Framework
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运算符框架
- en: 'The Operator Framework is a collection of open source tools that originated
    at Red Hat and are now under the CNCF umbrella as an incubating project. This
    framework facilitates the development of operators. It includes the Operator SDK,
    which offers similar functionality to Kubebuilder when developing operators using
    Go. Like Kubebuilder, it provides a CLI to generate boilerplate for projects.
    Also like Kubebuilder, it uses the controller-runtime tools to help integrate
    with the Kubernetes API. In addition to Go projects, the Operator SDK allows developers
    to use Helm or Ansible to manage operations. The framework also includes the Operator
    Lifecycle Manager, which is what it sounds like: an operator for your operators.
    It provides abstractions for installing and upgrading your operators. The project
    also maintains an operator hub, which offers a way for users to discover operators
    for software they use. We have not encountered platform teams using these tools
    in the field. Being a Red Hat-maintained project, it is likely more common among
    users of OpenShift, a Red Hat Kubernetes-based offering.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 运算符框架是由红帽发起的一套开源工具，现在作为 CNCF 的孵化项目。该框架便于运算符的开发。它包括运算符 SDK，使用 Go 编写运算符时提供类似 Kubebuilder
    的功能。与 Kubebuilder 类似，它提供了一个 CLI 来为项目生成样板。它还使用 controller-runtime 工具来帮助集成 Kubernetes
    API。除了 Go 项目，运算符 SDK 还允许开发人员使用 Helm 或 Ansible 来管理操作。该框架还包括运算符生命周期管理器，它提供了安装和升级运算符的抽象。该项目还维护了一个运算符中心，为用户发现他们使用的软件的运算符提供了一种方式。我们在现场尚未遇到使用这些工具的平台团队。作为由红帽维护的项目，它在基于
    Red Hat 的 Kubernetes 提供方 OpenShift 的用户中可能更为常见。
- en: Data Model Design
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据模型设计
- en: Just as you might begin the design of a web application by defining the database
    schema the app will use to persist data, a great place to start when building
    an operator is the data model for the custom resources your operator will use.
    In fact, you will probably have some idea of what fields your custom resource
    will need in its spec before you get started. As soon as you recognize a problem
    to solve or gap to fill, the attributes of the object that defines desired state
    will begin to take shape.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 就像您可能通过定义 Web 应用程序将使用的数据库模式来开始设计应用程序一样，在构建操作员时，一个很好的起点是操作员将使用的自定义资源的数据模型。事实上，在开始之前，您可能已经对自定义资源规范中需要哪些字段有了一些想法。一旦您意识到需要解决的问题或填补的空白，定义所需状态的对象的属性就会开始成形。
- en: 'In the example from earlier in this chapter, the Namespace operator, it could
    begin as an operator that will create a variety of resources: LimitRange, ResourceQuota,
    Roles, and NetworkPolicies to go along with a new Namespace for an app dev team.
    You may want to bind a team lead to the `namespace-admin` Role right away and
    then hand off management of the Namespace to that person. This would naturally
    lead you to add an `adminUsername` field to the spec of the custom resource. The
    custom resource manifest might look something like [Example 11-3](#ex_11-3).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章早些时候的示例中，Namespace 操作员可以作为一个将创建各种资源的操作员开始：LimitRange、ResourceQuota、Roles
    和 NetworkPolicies，以及一个新的应用开发团队的 Namespace。您可能希望立即将团队负责人绑定到 `namespace-admin` 角色，然后将
    Namespace 的管理工作交给该人。这自然会导致您向自定义资源的规范中添加一个 `adminUsername` 字段。自定义资源清单可能看起来像 [示例 11-3](#ex_11-3)。
- en: Example 11-3\. An example of a manifest for an AcmeNamespace resource
  id: totrans-132
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 11-3\. AcmeNamespace 资源清单的示例
- en: '[PRE2]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO3-1)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO3-1)'
- en: An arbitrary name for the Namespace—in this case it will host a workload, “app-y.”
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Namespace 的一个任意名称——在本例中，它将托管一个工作负载，“app-y”。
- en: '[![2](assets/2.png)](#co_building_platform_services_CO3-2)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_building_platform_services_CO3-2)'
- en: This username would correspond to that which is used by the company’s identity
    provider, usually an Active Directory system or similar.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此用户名应与公司的身份提供程序使用的用户名相对应，通常是 Active Directory 系统或类似系统。
- en: Submitting the manifest in [Example 11-3](#ex_11-3) would result in the username
    `sam` being added to the subjects of a RoleBinding to the `namespace-admin` Role
    in the manner shown in [Example 11-4](#ex_11-4).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 提交[示例 11-3](#ex_11-3) 中的清单将导致用户名 `sam` 被添加到一个角色绑定的主体中，该角色绑定将其绑定到 `namespace-admin`
    角色，具体方式如示例 [11-4](#ex_11-4) 所示。
- en: Example 11-4\. Example of a Role and Rolebinding created for the `team-x` AcmeNamespace
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 11-4\. 为 `team-x` 的 AcmeNamespace 创建角色和角色绑定的示例
- en: '[PRE3]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO4-1)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO4-1)'
- en: The `adminUsername` provided in the AcmeNamespace manifest would get inserted
    here to be bound to the `namespace-admin` Role.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AcmeNamespace 清单中提供的 `adminUsername` 将被插入到此处，以绑定到 `namespace-admin` 角色。
- en: 'When thinking about the behavior you want, having Sam bound to the `namespace-admin`
    Role, the data needed to accomplish this becomes pretty clear: Sam’s username
    and the name of the Namespace. So start with the obvious pieces of data that you
    will need to provide functionality and define fields in the spec for your CRD
    from that. What that would look like as part of a Kubebuilder project would be
    similar to what is shown in [Example 11-5](#ex_11-5).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑所需行为时，将 Sam 绑定到 `namespace-admin` 角色所需的数据变得非常清晰：Sam 的用户名和 Namespace 的名称。因此，从明显的数据片段开始，这些数据片段是为了提供功能而需要的，定义您的
    CRD 规范中的字段。在 Kubebuilder 项目中的示例可能类似于 [示例 11-5](#ex_11-5)。
- en: Example 11-5\. Type definition for the `AcmeNamespaceSpec`
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 11-5\. `AcmeNamespaceSpec` 的类型定义
- en: '[PRE4]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This is the source code from which Kubebuilder will generate your CRD manifest
    and the sample AcmeNamespace manifest to use for testing and demonstration.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Kubebuilder 将用来生成您的 CRD 清单以及用于测试和演示的样例 AcmeNamespace 清单的源代码。
- en: Now that we have a data model that we *think* will allow us to adequately manage
    state for the behavior we want, it’s time to start writing the controller. It’s
    probable we will find our data model inadequate as we develop and find there are
    additional fields that will be necessary to bring about our desired outcomes.
    But this is a useful place to start for now.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个数据模型，我们*认为*可以充分管理我们想要的行为状态，是时候开始编写控制器了。在开发过程中，我们可能会发现我们的数据模型不够用，需要额外的字段来实现我们想要的结果。但这是一个很好的起点。
- en: Logic Implementation
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑实现
- en: 'The logic is implemented in our controller. The primary job of the controller
    is to manage one or more custom resources. The controller will keep a watch on
    those custom resources under management. This part is trivial to implement when
    using tools like Kubebuilder and Metacontroller. It is pretty straightforward
    even if just using the client-go library, the GitHub repo for which has excellent
    code examples to refer to. With a watch on its custom resource/s, your controller
    will be notified of any changes to resources of this type. The job of your controller
    at this point is as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑是在我们的控制器中实现的。控制器的主要工作是管理一个或多个自定义资源。当使用类似 Kubebuilder 和 Metacontroller 这样的工具时，控制器将监视这些受管理的自定义资源。即使只使用
    client-go 库，GitHub 仓库中也有优秀的代码示例可供参考，这部分也非常简单易懂。通过对其自定义资源的监视，控制器将收到关于此类资源的任何更改的通知。在这一点上，控制器的工作如下：
- en: Gather an accurate picture of the existing state of the system
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集系统现有状态的准确图像
- en: Examine the desired state of the system
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查系统的期望状态
- en: Take the required actions to reconcile the existing state with desired state
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采取必要的操作来使现有状态与期望状态协调一致
- en: Existing state
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 现有状态
- en: 'There are essentially three places your controller may gather existing state
    information from:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，控制器可以从三个地方收集现有状态信息：
- en: The `status` of your custom resource
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您自定义资源的 `status`
- en: Other related resources in the cluster
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群中的其他相关资源
- en: Relevant conditions outside the cluster or in other systems
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群外或其他系统中的相关条件
- en: The `status` field provides a place for controllers in Kubernetes to record
    observed, existing state. For example, Kubernetes uses a `status.phase` field
    on some resources, such as Pods and Namespaces, to keep track of whether the resource
    is `Running` (for Pods) or `Active` (for Namespaces).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`status` 字段为 Kubernetes 中的控制器提供了记录观察到的现有状态的位置。例如，Kubernetes 在一些资源（如 Pods 和
    Namespaces）上使用 `status.phase` 字段来跟踪资源是否处于 `Running`（对于 Pods）或 `Active`（对于 Namespaces）状态。'
- en: Let’s go back to the example of a Namespace operator. The controller is notified
    of a new AcmeNamespace resource along with the spec for it. The controller cannot
    assume it is a new resource and just robotically create the child Namespace and
    Role resources. What if it’s a preexisting resource that has simply been updated
    with some change? Attempting to create the child resources again will get an error
    from the Kubernetes API. However, to follow the preceding Kubernetes example,
    if we include a `phase` field in the `status` of our CRD, the controller can check
    it to evaluate existing state. When it is first created, the controller will find
    the `status.phase` field empty. This will tell the controller it is a new resource
    creation, and should go ahead with creating all child resources. Once all children
    are created with successful responses from the API, the controller can populate
    the `status.phase` field with a value of `Created`. Then if the AcmeNamespace
    resource is later changed, when the controller is notified, it can see from this
    field that it has been previously created and move on to other reconciliation
    steps.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到一个命名空间操作符的例子。控制器收到一个新的 AcmeNamespace 资源及其规范的通知。控制器不能假设这是一个新资源，然后机械地创建子命名空间和角色资源。如果这只是一个已存在的资源，只是进行了一些更改呢？尝试再次创建子资源将从
    Kubernetes API 得到错误。然而，按照前面 Kubernetes 的例子，如果我们在 CRD 的 `status` 中包含一个 `phase`
    字段，控制器可以检查它来评估现有状态。当首次创建时，控制器会发现 `status.phase` 字段为空。这将告诉控制器这是一个新资源的创建，应该继续创建所有子资源。一旦所有子资源通过
    API 成功响应创建，控制器可以将 `status.phase` 字段填充为 `Created` 值。然后，如果后来更改了 AcmeNamespace 资源，当控制器收到通知时，它可以从此字段中看到它已经被之前创建过，并继续进行其他协调步骤。
- en: The use of the `status.phase` field to determine existing state as described
    so far has one critical flaw. It assumes the controller itself will never fail.
    What if a problem is encountered while creating the child resources? Say, for
    example, the controller gets notified of a new AcmeNamespace, creates the child
    Namespace, but then goes down before it can create the associated Role resources.
    When the controller comes back up, it will find the AcmeNamespace resource *without*
    `Created` in the `status.phase` field, attempt to create the child Namespace,
    and fail without a satisfactory way to reconcile the situation. In order to prevent
    this, the controller can add a `CreationInProgress` value to the `status.phase`
    as the very first step when it finds a new AcmeNamespace has been created. This
    way, if that failure during creation occurs, when the controller comes back up
    and sees the `CreationInProgress` phase, it will know that existing state cannot
    be accurately determined from the `status` alone. This is where it will need to
    look to other related resources in the cluster to determine existing state.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，使用`status.phase`字段来确定现有状态有一个关键缺陷。它假设控制器本身永远不会失败。如果在创建子资源时遇到问题怎么办？例如，控制器收到新的AcmeNamespace通知，创建了子命名空间，但在创建相关的角色资源之前崩溃了。当控制器重新启动时，它会发现AcmeNamespace资源在`status.phase`字段中没有`Created`，尝试创建子命名空间并在没有令人满意的方式下失败。为了防止这种情况发生，控制器可以在发现新的AcmeNamespace已创建时，作为第一步向`status.phase`添加`CreationInProgress`值。这样，如果在创建过程中发生故障，当控制器重新启动并看到`CreationInProgress`阶段时，它将知道无法仅通过`status`准确确定现有状态。这时它需要查看集群中的其他相关资源来确定现有状态。
- en: When existing state cannot be ascertained from the AcmeNamespace `status`, it
    can query the API server—or preferably the local cache of objects in the API server—for
    conditions it cares about. If it finds the phase of an AcmeNamespace set to `CreationInProgress`
    it can start querying the API server for the existence of child resources it expects
    to be there. In the failure example we’re using, it would query for a child Namespace,
    find it exists, and move on. It would query for the Role resource, find it *doesn’t*
    exist, and proceed with creating those resources. In this manner our controller
    can be tolerant of failure. And we should always assume failure will occur and
    develop controller logic accordingly.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当无法从AcmeNamespace的`status`确定现有状态时，它可以查询API服务器或者更好地查询API服务器中对象的本地缓存，以便获取其关心的条件。如果发现AcmeNamespace的阶段设置为`CreationInProgress`，它可以开始查询API服务器，检查其期望存在的子资源是否存在。在我们使用的故障示例中，它将查询子命名空间是否存在，发现它确实存在，然后继续。它将查询角色资源，发现*不存在*，然后继续创建这些资源。通过这种方式，我们的控制器可以容忍失败。我们应该始终假设会发生故障，并相应地开发控制器逻辑。
- en: Furthermore, sometimes our controller will be interested in existing state outside
    the cluster. Cloud infrastructure controllers are a good example of this. The
    status of infrastructure systems must be queried from cloud provider APIs outside
    the cluster. What this existing state may be will be highly dependent on the purpose
    of the operator in question and will usually be clear.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，有时我们的控制器会对集群外的现有状态感兴趣。云基础设施控制器是一个很好的例子。必须从集群外的云提供商API中查询基础设施系统的状态。现有状态可能会高度依赖于问题操作器的目的，并且通常会很清楚。
- en: Desired state
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 期望状态
- en: The desired state for a system is expressed in the `spec` for the relevant resources.
    In our Namespace operator, the desired state provided by the `namespaceName` informs
    the controller what the `metadata.name` field should be for the resulting Namespace.
    The `adminUsername` field determines what the `namespace-admin` RoleBinding’s
    `subjects[0].name` should be. These are examples of direct mappings of desired
    state to fields in child resources. Often, the implementation is less direct.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的期望状态在相关资源的`spec`中表达。在我们的命名空间操作器中，由`namespaceName`提供的期望状态告诉控制器结果命名空间的`metadata.name`字段应该是什么。`adminUsername`字段确定了`namespace-admin`角色绑定的`subjects[0].name`应该是什么。这些是期望状态直接映射到子资源字段的示例。通常，实现方式不那么直接。
- en: We saw an example of this with the use of the `deploymentTier` field in the
    `AcmeStore` example earlier in this chapter. It allowed a user to specify a single
    variable that informed the controller logic on what default values to use. We
    can apply a very similar idea to the Namespace operator. Our new, modified AcmeNamespace
    manifest could look like [Example 11-6](#ex_11-6).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前在本章中的 `AcmeStore` 示例中使用了 `deploymentTier` 字段的示例。它允许用户指定一个单一变量，用于通知控制器逻辑要使用的默认值。我们可以将类似的想法应用到
    Namespace 操作符上。我们的新修改的 AcmeNamespace 清单可能看起来像 [示例 11-6](#ex_11-6)。
- en: Example 11-6\. The AcmeNamespace manifest with new fields added
  id: totrans-166
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-6\. 添加了新字段的 AcmeNamespace 清单
- en: '[PRE5]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO5-1)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO5-1)'
- en: New addition to the data model for the AcmeNamespace API type.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: AcmeNamespace API 类型的数据模型的新添加。
- en: This will prompt the controller to create a ResourceQuota that could look like
    [Example 11-7](#ex_11-7).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这将促使控制器创建一个类似于 [示例 11-7](#ex_11-7) 的 ResourceQuota。
- en: Example 11-7\. The ResourceQuota created for the `team-x` AcmeNamespace
  id: totrans-171
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-7\. 为 `team-x` 的 AcmeNamespace 创建的 ResourceQuota
- en: '[PRE6]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Whereas the default ResourceQuota for `deploymentTier: prod` may look like
    [Example 11-8](#ex_11-8).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '默认的 `deploymentTier: prod` ResourceQuota 可能看起来像 [示例 11-8](#ex_11-8)。'
- en: Example 11-8\. An alternative ResourceQuota created when `deploymentTier:` `prod`
    is given in the AcmeNamespace
  id: totrans-174
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '示例 11-8\. 当 `deploymentTier: prod` 在 AcmeNamespace 中设置时创建的另一种 ResourceQuota'
- en: '[PRE7]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Reconciliation
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 协调
- en: In Kubernetes, reconciliation is the process of altering the existing state
    to match the desired state. This can be as simple as the kubelet requesting the
    container runtime stop containers associated with a deleted Pod. Or it can be
    more complex, such as an operator creating an array of new resources in response
    to a custom resource that represents a stateful application. These are examples
    of reconciliation triggered by creating or deleting the resources that express
    desired state. But very often the reconciliation involves a response to a mutation.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，协调是将现有状态更改为匹配所需状态的过程。这可以是像 kubelet 请求容器运行时停止与已删除 Pod 关联的容器那样简单。或者它可以更复杂，例如操作员根据表示有状态应用程序的自定义资源创建一系列新资源。这些是通过创建或删除表示所需状态的资源来触发的协调示例。但很多时候，协调涉及对变更的响应。
- en: A simple mutation example is if you update the number of replicas on a Deployment
    resource from 5 to 10\. The existing state is 5 Pods for a workload. The desired
    state is 10 Pods. The reconciliation performed by the Deployment controller in
    this case involves updating the replicas on the relevant ReplicaSet. The ReplicaSet
    controller then reconciles state by creating 5 new Pod resources which are, in
    turn, scheduled by the scheduler, which prompts the applicable kubelets to request
    new containers from the container runtime.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的变更示例是如果你将 Deployment 资源上的副本数从 5 更新为 10。现有状态是工作负载的 5 个 Pod。期望的状态是 10 个 Pod。在这种情况下，Deployment
    控制器执行的协调包括更新相关 ReplicaSet 上的副本数。然后 ReplicaSet 控制器通过创建 5 个新的 Pod 资源来协调状态，这些资源依次由调度程序安排，从而促使适用的
    kubelet 从容器运行时请求新的容器。
- en: Another mutation example that is a little more involved is if you change the
    image in a Deployment spec. This is usually to update the version of a running
    application. By default, the Deployment controller will perform a rolling update
    as it reconciles state. It will create a *new* ReplicaSet for the new version
    of the app, increment the replicas on the new ReplicaSet, and decrement the replicas
    on the old ReplicaSet so that the Pods are replaced one at a time. Once all new
    image versions are running with the desired number of replicas, reconciliation
    is complete.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个稍微复杂的变更示例是如果你在 Deployment 规范中更改镜像。这通常是为了更新正在运行的应用程序的版本。默认情况下，Deployment 控制器将执行滚动更新以协调状态。它将为新版本的应用程序创建一个
    *新* 的 ReplicaSet，增加新 ReplicaSet 上的副本数，并减少旧 ReplicaSet 上的副本数，以便逐个替换 Pod。一旦所有新的镜像版本以所需数量的副本运行，协调工作就完成了。
- en: What reconciliation looks like for a custom controller managing a custom resource
    is going to vary greatly according to what the custom resource represents. But
    one thing that should remain constant is that if reconciliation is not successful
    due to a condition that is beyond the domain of the controller, it should retry
    indefinitely. Generally speaking, the reconciliation loop should implement increasing
    delays between iterations. For example, if it is reasonable to expect other systems
    in the cluster to be actively reconciling state that is preventing a controller
    from completing its operations, you may retry 1 second later. However, for the
    sake of preventing gratuitous resource consumption, it is recommended to exponentially
    increase the delay between each iteration until it reaches some reasonable limit
    of, say, 5 minutes. At that point, the controller will retry reconciliation once
    every 5 minutes. This allows for unattended resolving of systems while limiting
    resource consumption and network traffic in circumstances that aren’t resolving
    quickly.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于管理自定义资源的自定义控制器，协调看起来会因自定义资源代表的内容不同而大不相同。但有一件事情应该保持不变，那就是如果由于超出控制器域的条件导致协调失败，它应该无限重试。一般来说，协调循环应该在迭代之间实现递增延迟。例如，如果可以合理地期望集群中的其他系统正在主动协调阻止控制器完成其操作的状态，那么可能在
    1 秒后重试。但是，为了防止不必要的资源消耗，建议在每次迭代之间按指数增加延迟，直到达到某个合理的限制，比如说，5 分钟。在那时，控制器将每隔 5 分钟重试一次协调。这允许在限制资源消耗和网络流量的情况下无人参与解决系统问题。
- en: Implementation details
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现细节
- en: 'In broad terms, to implement initial controller functionality for the Namespace
    operator, we want to be able to:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 大致而言，为了实现 Namespace 操作员的初始控制器功能，我们希望能够：
- en: Write or generate a concise AcmeNamespace manifest like the earlier example
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写或生成类似之前示例的简明 AcmeNamespace 清单
- en: Submit the manifest to the Kubernetes API
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将清单提交到 Kubernetes API
- en: Have a controller respond by creating a Namespace, ResourceQuota, LimitRange,
    Roles, and a RoleBinding.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过创建一个 Namespace、ResourceQuota、LimitRange、角色和角色绑定来让控制器响应。
- en: In a kubebuilder project, the logic to create these resources will live in a
    `Reconcile` method. The initial implementation of creating a Namespace with the
    controller could look like [Example 11-9](#ex_11-9).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在 kubebuilder 项目中，创建这些资源的逻辑将存在于 `Reconcile` 方法中。创建一个带有控制器的 Namespace 的初始实现可能看起来像是
    [示例 11-9](#ex_11-9)。
- en: Example 11-9\. The `Reconcile` method for the AcmeNamespace controller
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-9\. AcmeNamespace 控制器的 `Reconcile` 方法
- en: '[PRE8]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO6-1)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO6-1)'
- en: The variable that will represent the AcmeNamespace object that has been created,
    updated, or deleted.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 表示已创建、更新或删除的 AcmeNamespace 对象的变量。
- en: '[![2](assets/2.png)](#co_building_platform_services_CO6-2)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_building_platform_services_CO6-2)'
- en: Fetching the content of the AcmeNamespace object from the request. Error catching
    omitted for brevity.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 获取来自请求的 AcmeNamespace 对象的内容。为简洁起见，省略了错误捕获。
- en: '[![3](assets/3.png)](#co_building_platform_services_CO6-3)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_building_platform_services_CO6-3)'
- en: Creating the new Namespace object.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 创建新的 Namespace 对象。
- en: '[![4](assets/4.png)](#co_building_platform_services_CO6-4)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_building_platform_services_CO6-4)'
- en: Creating the new Namespace resource in the Kubernetes API.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes API 中创建新的 Namespace 资源。
- en: This simplified snippet demonstrates the controller creating the new Namespace.
    Adding the Role and RoleBinding for the Namespace admin to the controller would
    look similar, as shown in [Example 11-10](#ex_11-10).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简化的片段演示了控制器创建新的 Namespace。向控制器添加 Namespace 管理员的角色和角色绑定将类似，如 [示例 11-10](#ex_11-10)
    所示。
- en: Example 11-10\. The creation of the Role and RoleBinding by the AcmeNamespace
    controller
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-10\. AcmeNamespace 控制器创建角色和角色绑定
- en: '[PRE9]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: At this point we are able to submit an AcmeNamespace manifest to the API and
    our Namespace operator will create the Namespace, a Role for the Namespace admin,
    and a RoleBinding to the username we provided. As we discussed earlier, this will
    work fine when we create a new AcmeNamespace but will break when it tries to reconcile
    it at any other time in the future. This would occur if the AcmeNamespace was
    changed in any way. It would also happen if the controller restarted for any reason.
    When the controller restarts, it must re-list and reconcile all existing resources
    in case something changed. So at this point, simply restarting our controller
    will break it. Let’s fix that by adding a simple use of the status field. First,
    [Example 11-11](#ex_11-11) shows the addition of the field to `AcmeNamespaceStatus`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在此时，我们能够提交一个AcmeNamespace清单到API，我们的Namespace操作器将创建Namespace，Namespace管理员的角色以及绑定到我们提供的用户名的RoleBinding。正如我们之前讨论的，当我们创建一个新的AcmeNamespace时，这将正常工作，但是在以后的任何时间尝试协调它时会出现问题。如果AcmeNamespace以任何方式被更改，这将发生。如果控制器由于任何原因重新启动，也会发生这种情况。当控制器重新启动时，它必须重新列出和协调所有现有资源，以防发生更改。因此，在这一点上，简单地重启我们的控制器将使其中断。让我们通过添加对状态字段的简单使用来修复这个问题。首先，[示例
    11-11](#ex_11-11)展示了向`AcmeNamespaceStatus`添加字段的过程。
- en: Example 11-11\. Adding a field to the status of the AcmeNamespace
  id: totrans-201
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-11\. 向AcmeNamespace状态添加字段
- en: '[PRE10]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now we can leverage this field in our controller as shown in [Example 11-12](#ex_11-12).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以像在[示例 11-12](#ex_11-12)中展示的那样，在我们的控制器中利用这个领域。
- en: Example 11-12\. Using the new status field in the AcmeNamespace controller
  id: totrans-204
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-12\. 在AcmeNamespace控制器中使用新的状态字段
- en: '[PRE11]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now we have a controller that can restart safely. It also now has the beginnings
    of a system to examine existing state using the custom resource’s status and to
    carry out reconciliation steps based on that existing state.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个可以安全重启的控制器。它现在还具有一个系统的开始，用于检查现有状态，使用自定义资源的状态并执行基于该现有状态的协调步骤。
- en: One other thing we should usually do is set ownership for the child resources.
    If we set the AcmeNamespace resource as the owner of the Namespace, Role, and
    RoleBinding, that allows us to delete all the children by simply deleting the
    owner AcmeNamespace resource. This ownership will be managed by the API server.
    Even if the controller is not running, if the owner AcmeNamespace resource is
    deleted, the children will be deleted, too.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常还应该为子资源设置所有权。如果我们将AcmeNamespace资源设置为Namespace、Role和RoleBinding的所有者，那么我们只需删除所有者AcmeNamespace资源即可删除所有子资源。这种所有权将由API服务器管理。即使控制器没有运行，如果删除所有者AcmeNamespace资源，子资源也会被删除。
- en: This raises the question of scoping for our AcmeNamespace API type. When using
    Kubebuilder, it will default to Namespaced scoping. However, a Namespace-scoped
    API type cannot be an owner of a cluster-scoped resource, such as a Namespace.
    With Kubebuilder we can use convenient markers to generate the CRD manifest with
    the proper scoping for this usage, as shown in [Example 11-13](#updated_api_definition_in_a_kubebuilder_project).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了我们的AcmeNamespace API类型的作用域问题。在使用Kubebuilder时，默认为Namespaced作用域。但是，Namespace作用域的API类型不能成为集群作用域资源（如Namespace）的所有者。通过Kubebuilder，我们可以使用方便的标记来生成带有适当作用域的CRD清单，如[示例
    11-13](#updated_api_definition_in_a_kubebuilder_project)所示。
- en: Example 11-13\. Updated API definition in a Kubebuilder project
  id: totrans-209
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-13\. 在Kubebuilder项目中更新API定义
- en: '[PRE12]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO7-1)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO7-1)'
- en: This marker will set the correct scoping on the CRD when the manifest is generated
    with `make manifests`.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用`make manifests`生成清单时，此标记将设置CRD的正确作用域。
- en: This will generate a CRD that looks like [Example 11-14](#cluster_scoped_crd_for_acmenamespce_api_type).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个看起来像[示例 11-14](#cluster_scoped_crd_for_acmenamespce_api_type)的CRD。
- en: Example 11-14\. Cluster scoped CRD for AcmeNamespace API type
  id: totrans-214
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-14\. 用于AcmeNamespace API类型的集群范围CRD
- en: '[PRE13]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO8-1)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO8-1)'
- en: Resource scoping properly set.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 资源作用域已正确设置。
- en: Now we can set the AcmeNamespace as an owner for all child resources. This will
    introduce an `ownerReferences` field into the `metadata` for each child resource.
    At this point our `Reconcile` method looks like [Example 11-15](#setting_ownership_for_child_resources_of_the_acmenamespace).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将AcmeNamespace设置为所有子资源的所有者。这将在每个子资源的metadata中引入一个`ownerReferences`字段。此时，我们的`Reconcile`方法看起来像[示例
    11-15](#setting_ownership_for_child_resources_of_the_acmenamespace)。
- en: Example 11-15\. Setting ownership for child resources of the AcmeNamespace
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-15\. 设置AcmeNamespace子资源的所有权
- en: '[PRE14]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO9-1)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO9-1)'
- en: Check to see if resource was not found so we don’t try to reconcile when the
    AcmeNamespace has been deleted.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 检查资源是否未找到，因此我们不会尝试在AcmeNamespace已被删除时进行协调。
- en: '[![2](assets/2.png)](#co_building_platform_services_CO9-2)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_building_platform_services_CO9-2)'
- en: Set owner reference on Namespace.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在Namespace上设置所有者引用。
- en: '[![3](assets/3.png)](#co_building_platform_services_CO9-3)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_building_platform_services_CO9-3)'
- en: Set owner reference on Role.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在Role上设置所有者引用。
- en: '[![4](assets/4.png)](#co_building_platform_services_CO9-4)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_building_platform_services_CO9-4)'
- en: Set owner reference on RoleBinding.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在RoleBinding上设置所有者引用。
- en: Notice that we had to add the error checking to see if the AcmeNamespace resource
    was found. This is because when it is deleted, normal reconciliation will fail
    due to there no longer being desired state to reconcile. And, in this case, we
    put an owner reference on the child resources so the API server takes care of
    reconciling state for deletion events.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们不得不添加错误检查以查看是否找到了AcmeNamespace资源。这是因为当它被删除时，由于不再存在所需的状态来协调，正常的协调将失败。在这种情况下，我们在子资源上放置了一个所有者引用，因此API服务器会处理删除事件的协调状态。
- en: 'This illustrates the point that reconciliation must not make assumptions about
    existing state. Reconciliation is triggered when:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这说明了协调必须不对现有状态进行假设的观点。协调在以下情况下触发：
- en: The controller starts or restarts
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器启动或重新启动
- en: A resource is created
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建资源
- en: A change is made to a resource, including changes made by the controller itself
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对资源进行更改，包括控制器自身进行的更改
- en: A resource is deleted
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除资源
- en: A periodic resync with the API is carried out to ensure an accurate view of
    the system
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期与API进行重新同步以确保系统的准确视图
- en: To this end, make sure your reconciliation doesn’t make assumptions about the
    event that triggered reconciliation. Use the `status` field, determine relevant
    conditions in other resources as needed, and reconcile accordingly.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，请确保您的协调不对触发协调的事件做出假设。使用`status`字段，在其他资源中确定相关条件，并据此进行协调。
- en: Admission webhooks
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理入场网络钩子
- en: If you find your custom resource requires defaults or validation that cannot
    be implemented using the OpenAPI v3 spec in the CRD that creates your new API
    type, you can turn to validating and mutating admission webhooks. The Kubebuilder
    CLI has a `create webhook` command that caters specifically to these use cases
    by generating boilerplate to get you going faster.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您发现自定义资源需要默认值或验证，而这些内容无法使用创建新API类型的CRD中的OpenAPI v3规范实现，您可以转向验证和变异入场网络钩子。Kubebuilder
    CLI提供了一个`create webhook`命令，专门用于通过生成样板代码来加快您的启动速度。
- en: An example of where a validating webhook may be useful with our Namespace operator
    example and its AcmeNamespace resource, is in validating the `adminUsername` field.
    As a convenience, your webhook could call out to your corporate identity provider
    to ensure the username provided is valid, preventing mistakes that require human
    intervention to correct.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 验证Webhook的一个示例可能与我们的Namespace操作员示例及其AcmeNamespace资源有关，在验证`adminUsername`字段时尤其有用。作为便利，您的Webhook可以调用公司身份提供程序，以确保提供的用户名有效，从而防止需要人工干预来纠正错误。
- en: A defaulting example could be to default the `deploymentTier` to the most common,
    least expensive `dev` option. This is particularly useful for maintaining backward
    compatibility with existing resource definitions when you make a change that adds
    new fields to a custom resource data model.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 默认示例可以将`deploymentTier`默认为最常见、成本最低的`dev`选项。当您对自定义资源数据模型进行更改以添加新字段时，这尤其有用，用于保持与现有资源定义的向后兼容性。
- en: Admission webhooks are not often included in a prototype or pre-alpha release
    of an operator, but commonly come into play when refining the user experience
    for a stable release of a project. [Chapter 8](ch08.html#chapter8) covers the
    subject of admission control in depth.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 管理入场网络钩子通常不包括在操作员的原型或预阿尔法版本中，但在项目的稳定版本中，通常在优化用户体验时发挥作用。[第8章](ch08.html#chapter8)深入讨论了入场控制的主题。
- en: Finalizers
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终处理器
- en: We have looked at examples of a custom resource being set as the owner of child
    resources to ensure they will be deleted when the parent custom resource is removed.
    However, this mechanism is not always sufficient. If the custom resource has relationships
    with other resources in the cluster where an ownership is *not* appropriate, or
    if conditions outside the cluster need to be updated when your custom resource
    is deleted, finalizers will likely be important to use.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过将自定义资源设置为子资源所有者的示例，以确保在删除父自定义资源时它们将被删除。然而，这种机制并不总是足够的。如果自定义资源与集群中其他资源存在关系，其中所有权不合适，或者在删除自定义资源时需要更新集群外的条件，那么使用终结器可能非常重要。
- en: Finalizers are added to the metadata of a resource as shown [Example 11-16](#ex_11-16).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 终结器被添加到资源的元数据中，如[示例 11-16](#ex_11-16)所示。
- en: Example 11-16\. AcmeNamespace manifest with a finalizer
  id: totrans-245
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-16\. 带有终结器的 AcmeNamespace 清单
- en: '[PRE15]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO10-1)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO10-1)'
- en: String value used as a finalizer.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 作为终结器使用的字符串值。
- en: The string value used as your finalizer is not important to anything else in
    the system besides your controller. Just use a value that will safely be unique
    in case other controllers need to apply finalizers to the same resource.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 作为您的终结器使用的字符串值对系统中除您的控制器之外的任何其他内容都不重要。只需使用一个安全地确保在其他控制器需要向同一资源应用终结器时独特的值即可。
- en: When any finalizers are present on a resource, the API server will not delete
    the resource. If a delete request is received, it will instead update the resource
    to add a `deletionTimestamp` field to its metadata. This update to the resource
    will trigger a reconciliation in your controller. A check for this `deletionTimestamp`
    will need to be added to your controller’s `Reconcile` method so that any pre-delete
    operations can be completed. Once complete, your controller can remove the finalizer.
    This will inform the API server that it may now delete the resource.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 当资源上存在任何终结器时，API 服务器将不会删除该资源。如果收到删除请求，它将更新资源以在其元数据中添加`deletionTimestamp`字段。这对资源的更新将触发控制器中的协调。需要在控制器的`Reconcile`方法中添加对`deletionTimestamp`的检查，以便完成任何预删除操作。完成后，您的控制器可以移除终结器。这将告知
    API 服务器它现在可以删除该资源。
- en: Common examples of pre-delete operations are in systems outside the cluster.
    In the Namespace operator example, if there are corporate chargeback systems that
    track Namespace usage and need to be updated when Namespaces are deleted, a finalizer
    could prompt your operator to update that external system before removing the
    Namespace. Other common examples are when a workload uses managed services, such
    as databases or object storage, as a part of the application stack. When an instance
    of the application is deleted, these managed service instances will likely need
    to be cleaned up as well.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的预删除操作示例发生在集群外的系统中。在命名空间操作器示例中，如果存在跟踪命名空间使用情况并在删除命名空间时需要更新的公司计费系统，那么一个终结器可以提示您的操作器在删除命名空间之前更新外部系统。其他常见的示例包括工作负载使用托管服务，例如数据库或对象存储，作为应用堆栈的一部分。当删除应用程序实例时，这些托管服务实例可能也需要清理。
- en: Extending the Scheduler
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展调度器
- en: The scheduler delivers core functionality in Kubernetes. A huge part of the
    value proposition of Kubernetes is the abstraction of pools of machines on which
    to run workloads. It is the scheduler that makes the determination of where Pods
    will run. It is fair to say that, together with the kubelet, these two controllers
    form the heart of Kubernetes around which all else is built. The scheduler is
    a cornerstone platform service for your application platform. In this section
    we will explore customizing, extending, and replacing the behavior of the scheduler.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器在 Kubernetes 中提供核心功能。Kubernetes 的价值主张的一个重要部分是抽象化用于运行工作负载的机器池。调度器确定 Pod 的运行位置。可以说，与
    kubelet 一起，这两个控制器形成了 Kubernetes 的核心，其它所有内容都围绕它们构建。调度器是应用程序平台的一个基石平台服务。在本节中，我们将探讨定制、扩展和替换调度器的行为。
- en: It’s helpful to keep in mind the parallels between core control plane components,
    like the scheduler, and the custom operators we have examined so far in this chapter.
    In both cases we are dealing with Kubernetes controllers managing Kubernetes resources.
    With our custom operators, we develop entirely new custom controllers, whereas
    the scheduler is a core controller deployed with every Kubernetes cluster. With
    our custom operators, we design and create new custom resources, whereas the scheduler
    manages the core Pod resource.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 记住核心控制平面组件（如调度程序）与本章前面所检查的自定义操作员之间的类比是有帮助的。在这两种情况下，我们都在处理管理 Kubernetes 资源的 Kubernetes
    控制器。对于我们的自定义操作员，我们开发全新的自定义控制器，而调度程序是一个与每个 Kubernetes 集群一起部署的核心控制器。对于我们的自定义操作员，我们设计并创建新的自定义资源，而调度程序管理核心的
    Pod 资源。
- en: 'We have found it uncommon for users of Kubernetes to find a need to extend
    the scheduler or modify its behavior. However, considering how important it is
    to a cluster’s function, it is prudent to both understand how the scheduler reaches
    scheduling decisions it makes and how to modify those decisions if the need arises.
    It bears repeating one more time: a large part of the genius of Kubernetes is
    its extensibility and modularity. If you find the scheduler doesn’t meet your
    needs, you can modify or augment its behavior, or replace it altogether.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现 Kubernetes 用户很少有需要扩展调度程序或修改其行为的情况。然而，考虑到调度程序对集群功能的重要性，了解调度程序如何做出调度决策以及如何在需要时修改这些决策是明智的。值得再次强调的是：Kubernetes
    的一大特点是其可扩展性和模块化性。如果您发现调度程序不能满足您的需求，可以修改或增强其行为，甚至完全替换它。
- en: In exploring this topic, we’re going to examine how the scheduler determines
    where to assign Pods so that we can understand what goes into each scheduling
    decision, and then see how we can influence those decisions with scheduling policies.
    We’re also going to address the option of running multiple schedulers and even
    writing your own custom scheduler.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索这个主题时，我们将研究调度程序如何确定在哪里分配 Pod，以便了解每个调度决策的内部机制，然后看看我们如何通过调度策略影响这些决策。我们还将讨论运行多个调度程序的选项，甚至编写您自己的自定义调度程序。
- en: Predicates and Priorities
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 断言和优先级
- en: Before we look at how to extend or modify the scheduler, we first need to understand
    how the scheduler makes its decisions. The scheduler uses a two-step process to
    determine which Node a Pod will get scheduled to.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨如何扩展或修改调度程序之前，我们首先需要了解调度程序如何做出决策。调度程序使用两步流程来确定将 Pod 调度到哪个节点。
- en: The first is filtering. In this step, the scheduler filters out Nodes that are
    ineligible to host a Pod using a number of predicates. For example, there is a
    predicate that checks to see if the Pod being scheduled tolerates a Node’s taints.
    The control plane nodes commonly use a taint to ensure regular workloads don’t
    get scheduled there. If a Pod has no tolerations, any tainted Nodes will be filtered
    out as ineligible targets for a Pod. Another predicate checks to ensure the Node
    has sufficient CPU and memory resources for any Pod that requests values for these
    resources. As you’d expect, if the Node has insufficient resources to satisfy
    the Pod spec, it is filtered out as an eligible host. When all predicates have
    checked for Node eligibility, the filtering step is complete. At this point if
    there are no eligible Nodes, the Pod will remain in a `Pending` state until conditions
    change, such as a new eligible Node being added to the cluster. If the list of
    Nodes consists of a single Node, scheduling may occur at this point. If there
    are multiple eligible Nodes, the scheduler proceeds to the second step.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是过滤。在这一步中，调度程序使用多个断言来过滤出不适合托管 Pod 的节点。例如，有一个断言检查要调度的 Pod 是否容忍节点的污点。控制平面节点通常使用污点来确保常规工作负载不会在此调度。如果一个
    Pod 没有容忍性，任何带有污点的节点都将被过滤掉，不符合 Pod 的合格目标。另一个断言检查确保节点具有足够的 CPU 和内存资源来满足这些资源的请求。如果节点资源不足以满足
    Pod 规范，预期将其过滤为不合格的主机。当所有断言检查节点的合格性时，过滤步骤完成。此时如果没有合格的节点，Pod 将保持在“Pending”状态，直到条件改变，例如集群中增加了一个新的合格节点。如果节点列表中只有一个节点，可能会在这一点上进行调度。如果有多个合格的节点，调度程序将继续进行第二步。
- en: The second step is scoring. This step uses priorities to determine which Node
    is the *best* fit for a particular Pod. One priority that helps to score a Node
    higher is the presence of a container image that is being used by the Pod. Another
    priority that will score a Node higher is the lack of any Pods that share the
    same Service as the Pod being scheduled. That is to say that the scheduler will
    attempt to distribute the Pods that share a Service across multiple Nodes for
    improved Node failure tolerance. The scoring step is also where `preferred...`
    affinity rules on Pods are implemented. At the end of the scoring step, each eligible
    Node has a score associated. The highest scoring Node is deemed the best fit for
    the Pod and it is scheduled there.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是评分。这一步使用优先级来确定哪个节点最适合特定的 Pod。一个提高节点评分的优先级是，节点上存在 Pod 使用的容器镜像。另一个提高节点评分的优先级是，没有任何与待调度的
    Pod 共享相同服务的 Pod。也就是说，调度器将尝试将共享服务的 Pod 分布在多个节点上，以提高节点故障容忍性。评分步骤也是实现 Pod 上 `preferred...`
    亲和规则的地方。在评分步骤结束时，每个符合条件的节点都有一个相关的评分。评分最高的节点被认为是 Pod 的最佳选择，并将其调度到该节点上。
- en: Scheduling Policies
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度策略
- en: Scheduling policies are used to configure the predicates and priorities the
    scheduler is to use. You can write a config file containing a scheduling policy
    to disk on the control plane nodes and provide the scheduler the `--policy-config-file`
    flag, but the preferred method is to use a ConfigMap. Provide the scheduler the
    `--policy-configmap` flag and thereafter you can update the scheduling policy
    via the API server. Note that if you go with the ConfigMap method, you will likely
    need to update the `system:kube-scheduler` ClusterRole to add a rule for getting
    ConfigMaps.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 调度策略用于配置调度器要使用的谓词和优先级。您可以编写一个包含调度策略的配置文件，并将其保存到控制平面节点上，然后通过提供调度器 `--policy-config-file`
    标志来提供给调度器，但更推荐的方法是使用 ConfigMap。提供调度器 `--policy-configmap` 标志，然后可以通过 API 服务器更新调度策略。请注意，如果选择使用
    ConfigMap 方法，您可能需要更新 `system:kube-scheduler` ClusterRole，以添加获取 ConfigMaps 的规则。
- en: Warning
  id: totrans-263
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: At the time of this writing, both the `--policy-config-file` and `--policy-configmap`
    flags for the scheduler still work, but they are marked as deprecated in the official
    documentation. For this reason, if you are implementing new custom scheduling
    behavior, we recommend using the scheduling profiles discussed in the next section
    rather than the policies discussed here.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，调度器的 `--policy-config-file` 和 `--policy-configmap` 标志仍在使用，但在官方文档中已标记为不推荐使用。因此，如果您正在实施新的自定义调度行为，建议使用下一节讨论的调度配置文件，而不是这里讨论的策略。
- en: 'For example, the policy ConfigMap in [Example 11-17](#ex_11-17) will make a
    Node eligible for selection with a `nodeSelector` by a Pod only if it has a label
    with the key: `selectable`.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，示例 11-17 中的策略 ConfigMap 将使节点仅在具有键为 `selectable` 的标签时才能被 Pod 通过 `nodeSelector`
    选择。
- en: Example 11-17\. An example ConfigMap defining a scheduling policy
  id: totrans-266
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-17\. 定义调度策略的 ConfigMap 示例
- en: '[PRE16]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[![1](assets/1.png)](#co_building_platform_services_CO11-1)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_building_platform_services_CO11-1)'
- en: The filename the scheduler will expect to use for policies.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 调度策略的文件名调度器将预期使用。
- en: '[![2](assets/2.png)](#co_building_platform_services_CO11-2)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_building_platform_services_CO11-2)'
- en: The predicate name that implements `nodeSelectors`.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 实现 `nodeSelectors` 的谓词名称。
- en: '[![3](assets/3.png)](#co_building_platform_services_CO11-3)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_building_platform_services_CO11-3)'
- en: The label key you wish to use for adding a constraint to selection. In this
    example, if a node does not have this label key present, it will not be selectable
    by a Pod.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望用于为选择添加约束的标签键。例如，在此示例中，如果节点没有此标签键存在，则不会被 Pod 选择。
- en: '[![4](assets/4.png)](#co_building_platform_services_CO11-4)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_building_platform_services_CO11-4)'
- en: 'This indicates the provided label must be present. If `false` it would need
    to be absent. If using the example configuration of `presence: true`, a Node without
    the label `selectable: ""` will not be eligible for selection by a Pod.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '这表明提供的标签必须存在。如果设置为 `false`，则必须不存在。如果使用 `presence: true` 的示例配置，则没有标签 `selectable:
    ""` 的节点将无法被 Pod 选择。'
- en: 'With this scheduling policy in place, a Pod defined with the manifest in [Example 11-18](#ex_11-18)
    would be scheduled to an eligible Node only with *both* the `device: gpu` *and*
    the `selectable: ""` labels present.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '使用此调度策略，仅当节点同时具有 `device: gpu` 和 `selectable: ""` 标签时，才会将示例 11-18 中定义的 Pod
    调度到符合条件的节点。'
- en: Example 11-18\. A Pod manifest using the `nodeSelector` field to direct scheduling
  id: totrans-277
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-18\. 使用`nodeSelector`字段来指导调度的Pod清单
- en: '[PRE17]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Scheduling Profiles
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度配置文件
- en: Scheduling profiles allow you to enable or disable plug-ins that are compiled
    into the scheduler. You can specify a profile by passing a filename to the `--config`
    flag when running the scheduler. These plug-ins implement the various extension
    points that include—but are not limited to—the filter and scoring steps we covered
    earlier. In our experience it is rarely necessary to customize the scheduler in
    this way. But should you find a need for it, the Kubernetes documentation provides
    instructions.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 调度配置文件允许您启用或禁用编译到调度器中的插件。您可以通过在运行调度器时将文件名传递给`--config`标志来指定配置文件。这些插件实现了各种扩展点，包括但不限于我们之前介绍的过滤器和评分步骤。根据我们的经验，很少需要以这种方式定制调度器。但是，如果您发现有这样的需要，请查阅Kubernetes文档获取详细说明。
- en: Multiple Schedulers
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多个调度器
- en: It should be noted that you are not limited to one scheduler. You can deploy
    any number of schedulers that are either Kubernetes schedulers with different
    policies and profiles, or even custom-built schedulers. If running multiple schedulers
    you can supply the `schedulerName` in the spec for a Pod, which will determine
    which scheduler carries out the scheduling for that Pod. Given the added complexity
    of following this multischeduler model, consider using dedicated clusters for
    workloads with such specialized scheduling requirements.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，您不限于使用一个调度器。您可以部署任意数量的调度器，这些调度器可以是具有不同策略和配置文件的Kubernetes调度器，甚至是自定义构建的调度器。如果运行多个调度器，您可以在Pod的规格中提供`schedulerName`，以确定哪个调度器为该Pod执行调度。鉴于遵循这种多调度器模型的复杂性增加，请考虑为具有此类专用调度要求的工作负载使用专用集群。
- en: Custom Scheduler
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义调度器
- en: In the unlikely event that you are unable to use the Kubernetes scheduler, even
    with the use of policies and profiles, you have the option to develop and use
    your own scheduler. This would entail developing a controller that watches Pod
    resources and whenever a new Pod is created, determine where the Pod should run
    and update the `nodeName` field for that Pod. While this is a narrow scope, this
    is not a simple exercise. As we have seen in this section, the core scheduler
    is a sophisticated controller that routinely evaluates numerous complex factors
    into account when making scheduling decisions. If your requirements are specialized
    enough to demand a custom scheduler, it’s likely you will have to spend considerable
    engineering effort to refine its behavior. We recommend proceeding with this approach
    only if you have exhausted your options with the existing scheduler and have deep
    Kubernetes expertise to tap into for the project.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在使用策略和配置文件的情况下仍无法使用Kubernetes调度器，您可以开发并使用自己的调度器。这将涉及开发一个控制器，该控制器监视Pod资源，每当创建新的Pod时，确定Pod应该在何处运行，并更新该Pod的`nodeName`字段。尽管这个范围很窄，但这并不是一个简单的练习。正如我们在本节中看到的那样，核心调度器是一个复杂的控制器，定期评估多个复杂因素来做出调度决策。如果您的需求足够特殊以至于需要一个自定义调度器，那么您可能需要花费大量的工程工作来优化其行为。我们建议只有在用现有调度器尝试了所有选项并且在项目中具有深入的Kubernetes专业知识时，才继续采用这种方法。
- en: Summary
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: It’s important to understand the points of extension available with Kubernetes
    and how best to add the platform services required to meet your tenants’ needs.
    Study the operator pattern and the use cases for Kubernetes operators. If you
    find a compelling need to build an operator, decide what development tooling and
    language you will use, design your custom resource’s data model, and then build
    a Kubernetes controller to manage that custom resource. Finally, if the default
    scheduler behavior does not meet your requirements, look into scheduling policies
    and profiles to modify its behavior. In extreme edge cases, you have the option
    to develop your own custom scheduler to replace, or run in conjunction with, the
    default scheduler.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 理解Kubernetes提供的扩展点及如何最佳添加满足租户需求的平台服务至关重要。研究操作员模式及Kubernetes操作员的用例。如果发现有必要构建操作员，请决定使用何种开发工具和语言，设计您的自定义资源数据模型，然后构建一个Kubernetes控制器来管理该自定义资源。最后，如果默认调度器行为不符合您的要求，请查看调度策略和配置文件以修改其行为。在极端情况下，您可以选择开发自己的自定义调度器来替换或与默认调度器并行运行。
- en: Using the principles and practices laid out in this chapter, you are no longer
    constrained by the utilities and software provided by the community or your company’s
    vendors. If you encounter important requirements for which there is no existing
    solution, you have at your disposal the tools and guidelines to add any specialized
    platform services your business needs may require.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本章节中提出的原则和实践，您不再受制于社区或公司供应商提供的工具和软件。如果您遇到重要需求，而现有解决方案尚不存在，您可以利用现有工具和指南添加任何您的业务需要的专门平台服务。
