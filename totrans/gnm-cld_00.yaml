- en: Foreword
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I migrated from mathematics into the field of genomics in 1985—roughly a year
    before the field officially came into existence. The word *genomics* was coined
    in 1986, which also saw the first public debate, at the Cold Spring Harbor Laboratory,
    about the notion of mounting a Human Genome Project.
  prefs: []
  type: TYPE_NORMAL
- en: It’s hard to imagine how much has changed since then. Computers hardly figured
    in biomedicine—the initial design for the Whitehead Institute for Biomedical Research,
    founded in the early 1980s, included no provision for a computer. Large amounts
    of data were seen as a nuisance, not an asset—in a Nature article reporting on
    the Human Genome Project debate, the journal’s biology editor wrote, “If the skill
    and ingenuity of modern biology are already stretched to interpret sequences of
    known importance, such as those of the DMD and CGD genes, what possible use could
    be made of more sequences?”
  prefs: []
  type: TYPE_NORMAL
- en: Despite such doubts, biologists eventually decided to press on—launching the
    Human Genome Project, their first major data gathering effort, in 1990\. One of
    the important motivations was the prospect of deploying systematic methods—rather
    than guesswork—to discover the genes responsible for human diseases. In 1980,
    a brilliant biologist, David Botstein, had conceived how to find the location
    of genes for rare monogenic diseases by tracing their inheritance in families
    relative to a genetic map of DNA variants across the human genome. Realizing the
    full power of the idea, though, would require mapping—and eventually sequencing—the
    entire human genome.
  prefs: []
  type: TYPE_NORMAL
- en: The Human Genome Project was an extraordinary collaboration that spanned six
    countries and twenty institutions, took thirteen years, and cost $3 billion. When
    the dust settled, the world had the three billion nucleotide-long DNA sequence
    of a single human genome.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this project completed, many biologists thought that business would return
    to usual. But what happened next was even more remarkable. Over the next 15 years,
    biology became an information science—in which the generation of massive amounts
    of data reshaped the field. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: Genetic mapping in families revealed the genes responsible for more than 5,000
    serious rare monogenic disorders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New kinds of genetic mapping in populations led to the discovery of ~100,000
    robust associations of specific genetic regions with common diseases and traits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Genetic analysis of thousands of tumors uncovered hundreds of new genes in which
    mutations propelled cancer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remarkably, the cost of sequencing a human genome fell by a factor of five million—from
    $3 billion to $600—and the cost is likely to reach $100 in the coming years. More
    than one million genomes have been sequenced so far. Overall, genomic data of
    all kinds is doubling roughly every eight months.
  prefs: []
  type: TYPE_NORMAL
- en: None of this would have been possible without the development of powerful new
    computational methods and tools to work with the many new types of data that were
    being generated. A good example is the Genome Analysis Toolkit, developed by colleagues
    at the Broad Institute, which you’ll read a lot more about in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Today, life sciences are in the midst of new data explosions. Many countries
    are undertaking systematic efforts to collect genomic and medical data into national
    biobanks, which will give researchers the ability to probe even further into the
    genetics of both common and rare diseases and traits. It will be especially important
    to ensure that the world’s full genetic diversity is represented in these large-scale
    efforts—not just people of European descent.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the amazing technological progress in recent years, we can now read
    out not just the DNA blueprint, but how this blueprint is read out as RNA in individual
    cells. Methods have been developed to read out gene expression at the single-cell
    level, with an initial analysis of 18 cells soon leading to analyses of more than
    18 million cells. This work has given rise to an international Human Cell Atlas
    project, involving more than 60 countries around the world. These datasets are
    beginning to make it possible to use computational methods, including modern machine
    learning, to systematically infer the underlying circuitry of cells.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the biological applications burgeon, though, we are often held back by systemic
    limitations in how we access and share data. Most of the world’s biomedical data
    has traditionally been held in silos—accessible only through servers from which
    each authorized researcher or group must download their own copies to their own
    institution’s computing infrastructure. From a purely technical standpoint, this
    is unsustainable. Instead of bringing data to researchers, we need systems that
    allow researchers to operate on the data where it resides. We also need more transparent
    models for managing custody of the data, as well as efficient ways to assess,
    enforce and audit who can access the data and for what purpose. We should aim
    to abide by these four principles: (1) copying data should not be the default
    mode of sharing data; (2) security and auditing should be baked in and enterprise-grade;
    (3) large-scale analysis should be accessible to all research groups; and (4)
    computational resources should be elastic, so that they can be scaled up or down
    as needed.'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud computing has emerged as the leading solution for the technical aspect
    of these challenges. In practice, though, it creates new obstacles that require
    creative solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the Broad Institute, we started moving to the cloud four years ago, to cope
    with the rising tide of genomic data. We cut our teeth by converting our genomic
    data-processing operation from a traditional on-premises system to one that runs
    on the cloud from the moment the data is generated in our genome sequence platform.
    That move required rethinking every aspect of the process and building entirely
    new systems from scratch to handle the terabytes of data that come streaming off
    sequencing machines every day. But that was just the beginning. Once the data
    was up on the cloud, we hit the next obstacle: the available cloud services, in
    their current state, can be daunting to use for life sciences researchers without
    advanced training. So, we teamed up with partners to develop a software and analysis
    platform, Terra.'
  prefs: []
  type: TYPE_NORMAL
- en: Other such platforms also have emerged as the move to the cloud has picked up
    steam in biomedical research. Today we are working with many other groups to build
    a federated data ecosystem of interconnected components that offer complementary
    services and capabilities. We expect these platforms will help facilitate the
    kind of open collaboration that is needed to bring together data, tools, and expertise
    spanning multiple domains and disciplines. We also want to lower the technical
    thresholds for individual researchers to participate in the cloud-based ecosystem,
    especially those with fewer IT resources at their disposal.
  prefs: []
  type: TYPE_NORMAL
- en: By all accounts, the transition of genomics to the cloud is still in its early
    phases. At the Broad Institute, we’ve learned many hard lessons on our own journey
    to the cloud, and we’re learning more every day. In a time of such disruptive
    change, it’s essential that groups share their experiences with each other.
  prefs: []
  type: TYPE_NORMAL
- en: That’s why I’m so excited that the incomparable Geraldine Van der Auwera, longtime
    advocate for the research community at the Broad Institute, and Brian O’Connor,
    an ardent campaigner for software and data interoperability at UCSC, have written
    this book. The book captures the essence of what we have learned so far, and lays
    out an accessible path for newcomers to join the genomics cloud ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Eric S. Lander, Founding Director, The Broad Institute of MIT and Harvard
  prefs: []
  type: TYPE_NORMAL
