<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 4. Using Azure Arc Enabled Kubernetes"><div class="chapter" id="using_azure_arc_enabled_kubernetes">
      <h1><span class="label">Chapter 4. </span>Using Azure Arc Enabled Kubernetes</h1>
      <p>In this final chapter, let’s begin by exploring the architecture involved with Azure Arc enabled Kubernetes and what it takes to onboard, monitor, and use RBAC with an Azure Arc projected Kubernetes cluster. We’ll also dive into how to deploy an app to an Azure Arc projected Kubernetes cluster using GitOps. </p>
      <section data-type="sect1" data-pdf-bookmark="Azure Arc Enabled Kubernetes Architecture and Agents&#10;        "><div class="sect1" id="azure_arc_enabled_kubernetes_architecture_and_agen">
        <h1>Azure Arc Enabled Kubernetes Architecture and Agents
        </h1>
        <p>Azure Arc enabled Kubernetes is essentially a PaaS running in Azure. The architecture for the service itself is abstracted away. Azure Arc enabled Kubernetes architecture generally consists of some Azure services, resources, tools, and agents and a number of Deployments and Pods running on the projected Kubernetes cluster. Let’s unpack all of this to dive deeper into what the architecture and agent entail. </p>
        <p>First, you’ll need a Kubernetes cluster running either in Azure or outside of Azure. This can be AKS; GKE; EKS; Kubernetes running on VMs in Azure, AWS, GCP, on-premises, etc.; Rancher K3s; or even Kubernetes running on an edge device. This becomes your projected Kubernetes cluster in Azure Arc enabled Kubernetes. </p>
        <p>You’ll need the <em>kubeconfig</em> file to access the cluster and cluster-admin role on the projected Kubernetes cluster. This will give the access needed to deploy the Arc agents. </p>
        <p>You’ll need the Azure command-line interface (Azure CLI) version 2.3 or higher. This is needed to install the Azure Arc enabled Kubernetes interface extensions and used to perform registration tasks of the projected Kubernetes cluster.</p>
        <p>You’ll need to create a service principal name (SPN) in Azure. This must have read and write permissions on the <em>Microsoft.Kubernetes/connectedClusters</em> resource type. This SPN will also be used with the <code>az login</code> and <code>az connectedk8s connect</code> commands.</p>
        <p>You need the following Azure Arc providers enabled in the Azure subscription you’re running Azure Arc enabled Kubernetes in:</p>
        <ul>
          <li>
            <p>
              <code>Microsoft.Kubernetes</code>
            </p>
          </li>
          <li>
            <p>
              <code>Microsoft.KubernetesConfiguration</code>
            </p>
          </li>
        </ul>
        <p>You’ll need to load the <code>connectedk8s</code> extension and the Arc enabled Kubernetes CLI extensions. Also, you need Helm 3, as this is used when onboarding the projected Kubernetes cluster to Arc with the <code>az connectedk8s</code> extension. </p>
        <p>You’ll have Azure Arc enabled Kubernetes agents running on the projected Kubernetes cluster(s). In order for the agent to work, the following network protocols/ports and outbound URLs need to be allowed on the projected Kubernetes cluster network:</p>
        <dl>
          <dt>
            <p>Protocols/ports</p>
          </dt>
          <dd>
            <ul>
              <li>
                <p>TCP on port 443</p>
              </li>
              <li><p>TCP on port 9418</p></li>
            </ul>
          </dd>
          <dt><p>Endpoints (DNS) allowed outbound from projected Kubernetes <span class="keep-together">cluster</span></p></dt>
          <dd>
          <ul>
            <li>
              <p>
                <a href="https://management.azure.com">https://management.azure.com</a>
              </p>
            </li>
            <li>
              <p><a href="https://eastus.dp.kubernetesconfiguration.azure.com">https://eastus.dp.kubernetesconfiguration.azure.com</a></p>
            </li>
            <li>
              <p>
                <a href="https://westeurope.dp.kubernetesconfiguration.azure.com">https://westeurope.dp.kubernetesconfiguration.azure.com</a>
              </p>
            </li>
            <li>
              <p>
                <a href="https://login.microsoftonline.com">https://login.microsoftonline.com</a>
              </p>
            </li>
            <li>
              <p>
                <a href="https://mcr.microsoft.com">https://mcr.microsoft.com</a></p>
              </li>
              <li class="pagebreak-before">
                <p><a href="https://eus.his.arc.azure.com">https://eus.his.arc.azure.com</a></p>
              </li>
              <li>
                <p><a href="https://weu.his.arc.azure.com">https://weu.his.arc.azure.com</a></p>
              </li>
            </ul>
          </dd>
          </dl>
            <p>Once the agent is loaded and the projected cluster is onboarded to Arc, there will be a namespace, <code>azure-arc</code>, running on a projected Kubernetes cluster.</p>
            <p>There will also be operators running on the projected Kubernetes cluster in the <code>azure-arc</code> namespace as Deployments (i.e., <span class="keep-together"><code>deployment.apps</code></span>). These are:</p>
            <dl>
              <dt>
                <code>config-agent </code>
              </dt>
          <dd>
            <p>Monitors the projected Kubernetes cluster to update the compliance state when <code>sourceControlConfiguration</code> resources are applied on the projected cluster. </p>
          </dd>
          <dt>
            <code>controller-manager </code>
          </dt>
          <dd>
            <p>Orchestrates interactions between Azure Arc components. It’s an operator used to operate other operators. </p>
          </dd>
          <dt>
            <code>metrics-agent </code>
          </dt>
          <dd>
            <p>Gathers metrics from other Arc agents to measure performance and ensure it’s optimal. </p>
          </dd>
          <dt>
            <code>cluster-metadata-operator </code>
          </dt>
          <dd>
            <p>Collects versions of clusters and Azure Arc agents, cluster metadata, and node count. </p>
          </dd>
          <dt>
            <code>resource-sync-agent </code>
          </dt>
          <dd>
            <p>Syncs the metadata collected by the cluster-metadata-operator with Azure Arc.</p>
          </dd>
          <dt>
            <code>clusteridentityoperator </code>
          </dt>
          <dd>
            <p>Holds a Managed Service Identity (MSI) certificate that is used by the other operators to communicate with Azure. </p>
          </dd>
          <dt>
            <code>flux-logs-agent </code>
          </dt>
          <dd>
            <p>As a part of the <code>sourceControlConfiguration</code>, flux operators are deployed to the projected Kubernetes cluster(s), and this agent collects the logs from them. </p>
          </dd>
        </dl>
        <p class="pagebreak-before">There will be some Pods running on the projected Kubernetes cluster in the azure-arc namespace:</p>
        <ul>
          <li>
            <p><code>cluster-metadata-operator-b88f6695d-rf998</code></p>
          </li>
          <li>
            <p><code>clusteridentityoperator-6459fd778c-4wx66 </code></p>
          </li>
          <li>
            <p><code>config-agent-6cc967f5-kd8b8</code></p>
          </li>
          <li>
            <p><code>controller-manager-557d758b9f-f69vw</code></p>
          </li>
          <li>
            <p><code>flux-logs-agent-5db8bff9d4-gktl4</code></p>
          </li>
          <li>
            <p><code>metrics-agent-997cf95d5-h96gd </code></p>
          </li>
          <li>
            <p><code>resource-sync-agent-587b999567-4kz64</code></p>
          </li>
        </ul>
        <p>That sums up the components involved with Azure Arc enabled Kubernetes, from the Azure services, resources, tools, agents, and <span class="keep-together">a number</span> of Deployments and Pods involved in the architecture. Next, we’ll explore how to set up and use Azure Arc enabled <span class="keep-together">Kubernetes</span>. </p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Creating a Service Principal Name"><div class="sect1" id="creating_a_service_principal_name">
        <h1>Creating a Service Principal Name</h1>
        <p>As mentioned previously, you’ll need to create a service principal name in your Azure subscription. This SPN will need read and write permissions on the <em>Microsoft.Kubernetes/connectedClusters</em> resource type in the subscription. </p>
        <p>You’re also going to use this SPN with the <code>az login</code>  command as well as the <span class="keep-together"><code>az connectedk8s connect</code></span> command. You can create this SPN with one line of syntax by running it in Azure Cloud Shell. You can use the following syntax to create the SPN with a name and assign it to a specific subscription:</p>
        <div data-type="example">
          <!-- TK I MODIFIED THIS -->
          <pre data-type="programlisting">az ad sp create-for-rbac --name &lt;SPNNAMEHERE&gt; --role contributor \
  --scope /subscriptions/&lt;SUBSCRIPTIONIDHERE&gt;</pre>
        </div>
        <p>You’ll want to copy the output somewhere safe, as you’ll need to use it. It will look something like the following:</p>
        <div data-type="example">
          <pre data-type="programlisting">{
  "appId": "058t8611-j9k3-4f90-80d9-ag6524c823b7",
  "displayName": " SPNNAME ",
  "name": "http:// SPNNAME",
  "password": "1a2c85hc-43qa-61f0-o4c6-rbg2c5av472r",
  "tenant": "1qr3gg34-q032-4f6h-h19r-6o34b22v530l"
}</pre>
        </div>
  
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="&#10;          Connecting Kubernetes Clusters to Azure Arc&#10;        "><div class="sect1" id="connecting_kubernetes_clusters_to_azure_arc">
        <h1>
          Connecting Kubernetes Clusters to Azure Arc
        </h1>
        <p>Now let’s get ready to configure what we need in Azure for Azure Arc enabled Kubernetes and connect it to an existing Kubernetes cluster. This existing Kubernetes cluster can be AKS, GKE, EKS, or a cluster you deploy on your own. You can perform the actions in this section from Azure Cloud Shell or locally using a tool like VS Code. It’s recommended that you perform the following actions from Bash. </p>
        <p>Note that since we’re connecting an existing Kubernetes cluster, we need to ensure that our <code>KUBECONFIG</code> is configured and that we’re working against the proper context of the Kubernetes cluster we plan to connect to Azure Arc. </p>
        <p>First, we need to install the <code>connectedk8s</code> extension by running the following commands:</p>
        <div data-type="example">
          <pre data-type="programlisting">az extension add --name connectedk8s
az extension add --name k8sconfiguration</pre>
        </div>
        <p>Next, we’ll register the Kubernetes providers we need for Azure Arc enabled Kubernetes with the following commands:</p>
        <div data-type="example">
          <pre data-type="programlisting">az provider register --namespace Microsoft.Kubernetes
az provider register --namespace Microsoft.KubernetesConfiguration</pre>
        </div>
        <p>Here is where we can log into the subscription using the SPN so that we’re using the SPN to perform the remaining tasks. Here is the syntax to use the SPN with <code>az login:</code> </p>
        <div data-type="example">
          <!-- TK I MODIFIED -->
          <pre data-type="programlisting">az login --service-principal -u SPNID -p SPNPASSWORD \
  --tenant TENANTID</pre>
        </div>
        <p>Now we’ll create the resource group that will be used for our projected Kubernetes cluster. You should create a new resource group for each projected Kubernetes cluster you plan to onboard. As a reminder, we have to create this resource group in one of the two supported regions for Azure Arc enabled Kubernetes. Use the following syntax to create the resource group:</p>
        <div data-type="example">
          <pre data-type="programlisting">az group create -l EastUS -n PROJECTEDK8SRESOURCEGROUP</pre>
        </div>
        <p class="pagebreak-before">Next, let’s set our Bash environment variables for our SPN with the following: </p>
        <div data-type="example">
          <pre data-type="programlisting">export appId=SPNID
export password=SPNPASSWORD
export tenantId=TENANTID
export resourceGroup=PROJECTEDK8SRESOURCEGROUP
export arcClusterName= PROJECTEDK8SCLUSTERNAME</pre>
        </div>
        <p>Now we can connect our Kubernetes cluster to Azure Arc enabled Kubernetes. This action will deploy the Azure Arc enabled Kubernetes agent and operators: </p>
        <div data-type="example">
          <!-- TK I MODIFIED -->
          <pre data-type="programlisting">az connectedk8s connect -n PROJECTEDK8SCLUSTERNAME \
  -g PROJECTEDK8SRESOURCEGROUP</pre>
        </div>
        <p>Once completed, our Kubernetes cluster will be connected to Azure Arc and will appear as a projected Kubernetes cluster in Azure Arc enabled Kubernetes. <a data-type="xref" href="#fig_1_azure_arc_enabled_kubernetes_clusters_view_in_the">Figure 4-1</a> shows what a projected Kubernetes cluster looks like in Azure Arc in the Azure Portal. </p>
        <figure><div id="fig_1_azure_arc_enabled_kubernetes_clusters_view_in_the" class="figure">
          <img alt="Azure Arc enabled Kubernetes clusters view in the Azure Portal" src="Images/aaek_0401.png" width="1177" height="554"/>
          <h6><span class="label">Figure 4-1. </span>Azure Arc enabled Kubernetes clusters view in the Azure Portal</h6>
        </div></figure>
        <p>Once our Kubernetes cluster is connected to Azure Arc, we can click the projected Kubernetes cluster and assign RBAC to it via Access Control (IAM), assign tags, lock the cluster, see its properties, configure a GitOps configuration to it, and apply Azure Policies to it. </p>
      </div></section>
      <section data-type="sect1" class="pagebreak-before less_space" data-pdf-bookmark="Using Azure Active Directory RBAC with Azure Arc Projected Kubernetes Clusters&#10;        "><div class="sect1" id="using_azure_active_directory_rbac_with_azure_arc_p">
        <h1>Using Azure Active Directory RBAC with Azure Arc Projected Kubernetes Clusters
        </h1>
        <p>Role assignments can be assigned to the projected Kubernetes cluster using the Access Control (IAM) blade of the projected cluster resource in the Azure Arc area of the Azure Portal, as shown in <a data-type="xref" href="#fig_2_azure_arc_enabled_kubernetes_rbac_roles_in_the_azu">Figure 4-2</a>.</p>
        <figure><div id="fig_2_azure_arc_enabled_kubernetes_rbac_roles_in_the_azu" class="figure">
          <img alt="Azure Arc enabled Kubernetes RBAC roles in the Azure Portal" src="Images/aaek_0402.png" width="1259" height="836"/>
          <h6><span class="label">Figure 4-2. </span>Azure Arc enabled Kubernetes RBAC roles in the Azure Portal</h6>
        </div></figure>
        <p>Note that RBAC only applies to accessing the projected cluster via Azure. This does not apply when accessing the cluster directly on its hosted platform (i.e., GCP, AWS, on-premises, etc.). </p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="App Deployment to Azure Arc Projected Kubernetes Clusters with GitOps"><div class="sect1" id="app_deployment_to_azure_arc_projected_kubernetes_c">
        <h1>App Deployment to Azure Arc Projected Kubernetes Clusters with GitOps</h1>
        <p>Now we’re going to walk through how to utilize GitOps to deploy a simple application and other API objects to our projected Kubernetes cluster in Azure Arc enabled Kubernetes. </p>
        <p>The first thing you should do is create your own public GitHub repository. Create a <em>hello-kubernetes-arc-demo.yaml</em> file in the repository with the following contents in the YAML file:</p>
        <div data-type="example">
          <pre data-type="programlisting">apiVersion: v1
kind: Service
metadata:
  name: hello-kubernetes-custom
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 8080
  selector:
    app: hello-kubernetes-custom
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-kubernetes-custom
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hello-kubernetes-custom
  template:
    metadata:
      labels:
        app: hello-kubernetes-custom
    spec:
      containers:
      - name: hello-kubernetes
        image: paulbouwer/hello-kubernetes:1.8
        ports:
        - containerPort: 8080
        env:
        - name: MESSAGE
          value: I just deployed this on Kubernetes!</pre>
        </div>
        <p>This YAML file is from one of <a href="https://oreil.ly/CkzqI">Paul Bouwer’s repositories</a>. It is often used to demo deploying a small workload to a Kubernetes cluster. Note that GitOps in Azure Arc enabled Kubernetes works with both public and private Git repositories. In order to use a GitOps with a Git private repository, you would use SSH and either Flux-created or user-provided keys.</p>
        <p>Next, we need to create the GitOps configuration. This will deploy the Flux operator and Memcached on the projected Kubernetes cluster. We’ll use the <code>az k8sconfiguration</code> command to do this. Here’s the syntax to run: </p>
        <div data-type="example">
          <!-- TK I modified -->
          <pre data-type="programlisting">
az k8sconfiguration create --name gitops-config \
  --cluster-name PROJECTEDK8SCLUSTERNAME \
  --resource-group PROJECTEDK8SRESOURCEGROUP \
  --operator-instance-name gitops-config \
  --operator-namespace gitops-config \
  --repository-url URLOFYOURPUBLICREPOHERE \
  --scope cluster --cluster-type connectedClusters \
  --operator-params="--git-poll-interval 5s --git-readonly"</pre>
        </div>
        <p>After it’s finished, we can verify that the new GitOps configuration was created in “Azure Portal at Azure Arc” &gt; “Azure Arc | Kubernetes clusters” &gt; [projected Kubernetes cluster name] &gt; GitOps <span class="keep-together">(see <a data-type="xref" href="#fig_3_gitops_displayed_in_the_azure_portal">Figure 4-3</a>)</span>.</p>
        <figure><div id="fig_3_gitops_displayed_in_the_azure_portal" class="figure">
          <img alt="GitOps displayed in the Azure Portal" src="Images/aaek_0403.png" width="1259" height="638"/>
          <h6><span class="label">Figure 4-3. </span>GitOps displayed in the Azure Portal</h6>
        </div></figure>
        <p>GitOps has deployed everything needed to run the sample application. It has effectively deployed a service type, <code>LoadBalancer</code>; a deployment with three replicas; and a Pod running the web application in the projected Kubernetes cluster. You can check out the new API objects in your projected Kubernetes cluster using <code>kubectl</code>. </p>
        <p>You’ll be able to see the Pod running in your Kubernetes cluster by running: </p>
        <div data-type="example">
          <pre data-type="programlisting">kubectl get pods</pre>
        </div>
        <p>You can see the services and get the external IP of the load balancer by running: </p>
        <div data-type="example">
          <pre data-type="programlisting">kubectl get services </pre>
        </div>
        <p>When you visit the IP in a web browser, you should see the output shown in <a data-type="xref" href="#fig_4_app_deployed_in_a_web_browser_via_gitops">Figure 4-4</a>.</p>
        <figure><div id="fig_4_app_deployed_in_a_web_browser_via_gitops" class="figure">
          <img alt="App deployed in a web browser via GitOps" src="Images/aaek_0404.png" width="1803" height="947"/>
          <h6><span class="label">Figure 4-4. </span>App deployed in a web browser via GitOps</h6>
        </div></figure>
        <p>Now, if you want to make sure that GitOps will ensure your desired state of the app, go ahead and delete the deployment by running the following:</p>
        <div data-type="example">
          <pre data-type="programlisting">kubectl delete deployment hello-kubernetes-custom</pre>
        </div>
        <p>After about five seconds, Flux will sync and reapply the YAML file, putting the deployment back in place. </p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Monitoring an Azure Arc Projected Kubernetes Cluster with Azure Monitor&#10;        "><div class="sect1" id="monitoring_an_azure_arc_projected_kubernetes_clust">
        <h1>Monitoring an Azure Arc Projected Kubernetes Cluster with Azure Monitor
        </h1>
        <p>Monitoring your Kubernetes cluster and the containers running on it is critical to operating an environment. You can utilize Azure Monitor for containers with projected Kubernetes clusters in Azure Arc enabled Kubernetes. Azure Monitor for containers gives you performance visibility of your Kubernetes cluster and collects the container logs for monitoring of your workloads as well. At the time of this writing, Azure Monitor for Containers does not support LiveData. Before you can enable this monitoring, you need to have the following prerequisites in place. These prerequisites can be set on the SPN account you created: </p>
        <ul>
          <li>
            <p>You need a Log Analytics workspace configured with Azure Monitor for containers.</p>
          </li>
          <li>
            <p>At a minimum, you need to be a member of the Azure Contributor role in the Azure subscription.</p>
          </li>
          <li>
            <p>You need to be a member of the Log Analytics Contributor role of the Log Analytics workspace configured with Azure Monitor for containers.</p>
          </li>
          <li>
            <p>You need to be a member of the Contributor role on the Azure Arc cluster resource.</p>
          </li>
          <li>
            <p>You need to be a member of the Log Analytics reader role <span class="keep-together">permission</span>.</p>
          </li>
          <li>
            <p>You need a HELM client to onboard the Azure Monitor for containers chart for the specified Kubernetes cluster.</p>
          </li>
        </ul>
        <p>Let’s set this up. Note that everything we’ll walk through is still being run in Bash. </p>
        <p>First, let’s download the enable monitoring AKA OMS script using the following command:</p>
        <div data-type="example">
          <pre data-type="programlisting">curl -o enable-monitoring.sh \
  -L https://aka.ms/enable-monitoring-bash-script</pre>
        </div>
        <p>Next, we need to get the Azure Arc Connected Cluster Azure Resource ID using the following command:</p>
        <div data-type="example">
          <!-- TK I modified -->
          <pre data-type="programlisting">
export azureArcClusterResourceId=$(az resource show \
  --resource-group PROJECTEDK8SRESOURCEGROUP \
  --name PROJECTEDK8SCLUSTERNAME \
  --resource-type "Microsoft.Kubernetes/connectedClusters" \
  --query id -o tsv)</pre>
        </div>
        <p>Retrieve the projected Kubernetes cluster credentials from the current <code>KubeContext</code> using the following:</p>
        <div data-type="example">
          <pre data-type="programlisting">export kubeContext="$(kubectl config current-context)"</pre>
        </div>
        <p>Run the <em>enable-monitoring.sh</em> script using the following syntax:</p>
        <div data-type="example">
          <pre data-type="programlisting">
bash enable-monitoring.sh --resource-id $azureArcClusterResourceId \
  --client-id SPNID --client-secret SPNPASSWORD \
  --tenant-id TENANTID --kube-context $kubeContext</pre>
        </div>
        <p>When <em>enable-monitoring.sh</em> is done, you can go into the Azure Portal at “Azure Arc” &gt; “Azure Arc | Kubernetes clusters” &gt;[projected Kubernetes cluster name] &gt; “Monitoring – Insights” to see the monitoring of your projected Kubernetes cluster (see <a data-type="xref" href="#fig_5_view_of_monitored_projected_kubernetes_cluster_in">Figure 4-5</a>). Note that it can take up to 15 minutes for data to start populating. </p>
        <figure><div id="fig_5_view_of_monitored_projected_kubernetes_cluster_in" class="figure">
          <img alt="View of monitored projected Kubernetes cluster in Azure Arc enabled Kubernetes" src="Images/aaek_0405.png" width="1259" height="561"/>
          <h6><span class="label">Figure 4-5. </span>View of monitored projected Kubernetes cluster in Azure Arc enabled Kubernetes</h6>
        </div></figure>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="summary_idylMZ6t">
        <h1>Summary</h1>
        <p>This brings us to the end of our journey together. Let’s recap what we covered. In this report, we started by touching on the market demand for multicloud and how this is driving a need to manage Kubernetes across multiple clouds. We then took a detour into the brief history of Azure Arc along with an overview of the overall service. We rounded out that detour with how Azure Arc is able to fill the “single pane of glass” promise. </p>
        <p>We shifted down another route into Azure Arc enabled Kubernetes, first giving an overview about Azure Kubernetes Service. Then we explained what Azure Arc enabled Kubernetes is and the reach it has. We gained insight into what GitOps is, what it does, and how it’s used, finishing up with how Azure Arc leverages GitOps.</p>
        <p>We then took a journey into Azure Arc’s architecture and components, how to connect Kubernetes clusters to it, and how to use RBAC and Azure Monitor with Azure Arc enabled Kubernetes. We also walked through setting up GitOps and deploying an application and configuration to a projected Kubernetes cluster.</p>
        <p>I hope you learned a lot from this report about Azure Arc and GitOps. If your organization is running multiple Kubernetes clusters across different environments, I recommend looking further into Azure Arc as a way to simplify your management needs of Kubernetes across the multiple environments. </p>
      </div></section>
    </div></section></div>
<div id="sbo-rt-content"><section data-type="colophon" epub:type="colophon" class="abouttheauthor" data-pdf-bookmark="About the Author"><div class="colophon" id="idm45690161148344">
  <h1>About the Author</h1>
        <p><strong>Steve Buchanan</strong> (<a href="https://twitter.com/buchatech" class="orm:hideurl">@buchatech</a>) is a director and Midwest Containers Services Lead on a Cloud Transformation team with a large consulting firm. He is a nine-time Microsoft MVP, Pluralsight author, and the author of six technical books. He is an international speaker, having presented at tech events including Midwest Management Summit (MMS), Microsoft Ignite, BITCon, Experts Live Europe, OSCON, Inside Azure management, and user groups. Steve is currently focused on transforming the position of IT into a strategic partner of the business and driver of digital transformation through ITSM, DevOps, and CloudOps. He stays active in the technical community and enjoys blogging about his adventures in the world of IT at <a href="http://www.buchatech.com" class="orm:hideurl">www.buchatech.com</a>.</p>
</div></section></div></body></html>