- en: Chapter 20\. Policy and Governance for Kubernetes Clusters
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第20章 Kubernetes 集群的政策和治理
- en: Throughout this book we have introduced many different Kubernetes resource types,
    each with a specific purpose. It doesn’t take long before the resources on a Kubernetes
    cluster go from several, for a single microservice application, to hundreds and
    thousands, for a complete distributed application. In the context of a production
    cluster it isn’t hard to imagine the challenges associated with managing thousands
    of resources.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中，我们介绍了许多不同的 Kubernetes 资源类型，每种都有特定的用途。在 Kubernetes 集群中的资源数量从单一微服务应用的几个，迅速增加到完整分布式应用的几百甚至几千个，所需管理的资源数目也随之增加。在生产集群的上下文中，管理成千上万的资源所面临的挑战是显而易见的。
- en: In this chapter, we introduce the concepts of policy and governance. *Policy*
    is a set of constraints and conditions for how Kubernetes resources can be configured.
    *Governance* provides the ability to verify and enforce organizational policies
    for all resources deployed to a Kubernetes cluster, such as ensuring all resources
    use current best practices, comply with security policy, or adhere to company
    conventions. Whatever your case may be, your tooling needs to be flexible and
    scalable so that all resources defined on a cluster comply with your organization’s
    defined policies.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了政策和治理的概念。*政策* 是一组约束和条件，规定 Kubernetes 资源的配置方式。*治理* 提供了验证和执行所有部署到 Kubernetes
    集群的资源的组织政策的能力，例如确保所有资源使用当前最佳实践，符合安全政策，或遵守公司惯例。无论你的情况如何，你的工具都需要灵活和可扩展，以便集群上定义的所有资源都符合你组织定义的政策。
- en: Why Policy and Governance Matter
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么政策和治理很重要
- en: There are many different types of policies in Kubernetes. For example, NetworkPolicy
    allows you to specify what network services and endpoints a Pod can connect to.
    PodSecurityPolicy enables fine-grained control over the security elements of a
    Pod. Both can be used to configure network or container runtimes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中有许多不同类型的政策。例如，NetworkPolicy 允许你指定一个 Pod 可以连接到的网络服务和端点。PodSecurityPolicy
    使你能够对 Pod 的安全元素进行细粒度控制。两者都可以用于配置网络或容器运行时。
- en: However, you might want to enforce a policy before Kubernetes resources are
    even created. This is the problem that policy and governance solve. At this point,
    you might be thinking, “Isn’t this what role-based access control does?” However,
    as you’ll see in this chapter, RBAC isn’t granular enough to restrict specific
    fields within resources from being set.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可能希望在 Kubernetes 资源甚至被创建之前就强制执行一个政策。这就是政策和治理解决的问题。此时，你可能会想到，“这不是基于角色的访问控制（RBAC）所做的事情吗？”然而，正如你将在本章中看到的，RBAC
    的粒度不足以限制资源中特定字段的设置。
- en: 'Here are some common examples of policies that cluster administrators often
    configure:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些集群管理员常常配置的政策的常见例子：
- en: All containers *must* only come from a specific container registry.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有容器 *必须* 只来自特定的容器注册表。
- en: All Pods *must* be labeled with the department name and contact information.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有 Pod *必须* 带有部门名称和联系信息的标签。
- en: All Pods *must* have both CPU and memory resource limits set.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有 Pod *必须* 设置 CPU 和内存资源限制。
- en: All Ingress hostnames *must* be unique across a cluster.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有 Ingress 主机名 *必须* 在集群中唯一。
- en: A certain service *must* not be made available on the internet.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 某个服务 *不得* 对外开放。
- en: Containers *must* not listen on privileged ports.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器 *不得* 监听特权端口。
- en: Cluster administrators may also want to audit existing resources on a cluster,
    perform dry-run policy evaluations, or even mutate a resource based on a set of
    conditions—for example, applying labels to a Pod if they aren’t present.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 群集   集群管理员也可能想要审计集群上的现有资源，进行干运行政策评估，或基于一组条件修改资源——例如，如果不存在的话，对一个 Pod 应用标签。
- en: It’s very important for cluster administrators to be able to define policy and
    perform compliance audits without interfering with the developers’ ability to
    deploy applications to Kubernetes. If developers are creating noncompliant resources,
    you need a system to make sure they get the feedback and remediation they need
    to bring their work into compliance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理员能够定义政策并进行合规性审计，而不干扰开发人员将应用部署到 Kubernetes 的能力，这一点非常重要。如果开发人员创建了不合规的资源，你需要一个系统，确保他们得到反馈和修正，以使他们的工作符合规定。
- en: Let’s take a look at how to achieve policy and governance by leveraging core
    extensibility components of Kubernetes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何利用 Kubernetes 核心的扩展组件实现政策和治理。
- en: Admission Flow
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入驻流程
- en: To understand how policy and governance ensures resources are compliant before
    they are created in your Kubernetes cluster, you must first understand the request
    flow through the Kubernetes API server. [Figure 20-1](#fig1701) depicts the flow
    of an API request through the API server. Here, we’ll focus on mutating admission,
    validating admission, and webhooks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解策略和治理如何确保资源在创建前符合规范，必须首先了解请求通过 Kubernetes API 服务器的流程。[图 20-1](#fig1701) 描绘了
    API 请求通过 API 服务器的流程。在这里，我们将重点介绍变异准入、验证准入和 Webhook。
- en: '![kur3 2001](assets/kur3_2001.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![kur3 2001](assets/kur3_2001.png)'
- en: Figure 20-1\. API request flow through the Kubernetes API server
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-1\. API 请求通过 Kubernetes API 服务器的流程
- en: Admission controllers operate inline as an API request flows through the Kubernetes
    API server and are used to either mutate or validate the API request resource
    before it’s saved to storage. Mutating admission controllers allow the resource
    to be modified; validating admission controllers do not. There are many different
    types of admission controllers; this chapter focuses on admission webhooks, which
    are dynamically configurable. They allow a cluster administrator to configure
    an endpoint to which the API server can send requests for evaluation by creating
    either a MutatingWebhookConfiguration or a ValidatingWebhookConfiguration resource.
    The admission webhook will respond with an “admit” or “deny” directive to let
    the API server know whether to save the resource to storage.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 准入控制器在 API 请求通过 Kubernetes API 服务器时内联操作，并用于在资源保存到存储之前对 API 请求资源进行修改或验证。变异准入控制器允许修改资源；验证准入控制器则不允许。有许多不同类型的准入控制器；本章重点介绍准入
    Webhook，这些 Webhook 是动态配置的。它们允许集群管理员配置一个端点，API 服务器可以向其发送请求进行评估，通过创建 MutatingWebhookConfiguration
    或 ValidatingWebhookConfiguration 资源。准入 Webhook 将以“admit”或“deny”的指令响应，告知 API 服务器是否将资源保存到存储。
- en: Policy and Governance with Gatekeeper
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 策略与治理使用 Gatekeeper
- en: Let’s dive into how to configure policies and ensure that Kubernetes resources
    are compliant. The Kubernetes project doesn’t provide any controllers that enable
    policy and governance, but there are open source solutions. Here, we will focus
    on an open source ecosystem project called [Gatekeeper](https://oreil.ly/u0deR).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解如何配置策略并确保 Kubernetes 资源符合规范。Kubernetes 项目未提供任何启用策略和治理的控制器，但有开源解决方案。在这里，我们将关注一个名为[Gatekeeper](https://oreil.ly/u0deR)的开源生态系统项目。
- en: Gatekeeper is a Kubernetes-native policy controller that evaluates resources
    based on defined policy and determines whether to allow a Kubernetes resource
    to be created or modified. These evaluations happen server-side as the API request
    flows through the Kubernetes API server, which means each cluster has a single
    point of processing. Processing the policy evaluations server-side means that
    you can install Gatekeeper on existing Kubernetes clusters without changing developer
    tooling, workflows, or continuous delivery pipelines.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper 是一个 Kubernetes 本地策略控制器，根据定义的策略评估资源，并决定是否允许创建或修改 Kubernetes 资源。这些评估在
    API 请求通过 Kubernetes API 服务器时在服务器端进行，这意味着每个集群具有单一的处理点。在服务器端处理策略评估意味着您可以在现有的 Kubernetes
    集群上安装 Gatekeeper，而无需更改开发人员的工具、工作流程或持续交付流水线。
- en: Gatekeeper uses *custom resource definitions* (CRDs) to define a new set of
    Kubernetes resources specific to configuring it, which allows cluster administrators
    to use familiar tools like `kubectl` to operate Gatekeeper. In addition, it provides
    real-time, meaningful feedback to the user on why a resource was denied and how
    to remediate the problem. These Gatekeeper-specific custom resources can be stored
    in source control and managed using GitOps workflows.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper 使用*自定义资源定义*（CRDs）定义了一组新的专门用于配置它的 Kubernetes 资源，这使得集群管理员可以使用熟悉的工具如`kubectl`来操作
    Gatekeeper。此外，它为用户提供实时、有意义的反馈，说明为何资源被拒绝以及如何修复问题。这些 Gatekeeper 特定的自定义资源可以存储在源控制中，并使用
    GitOps 工作流进行管理。
- en: Gatekeeper also performs *resource mutation* (resource modification based on
    defined conditions) and auditing. It is highly configurable and offers fine-grained
    control over what resources to evaluate and in which namespaces.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper 还执行*资源变异*（根据定义的条件修改资源）和审计。它高度可配置，并提供对要评估的资源及其命名空间的精细控制。
- en: What Is Open Policy Agent?
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是开放策略代理（Open Policy Agent）？
- en: At the core of Gatekeeper is [Open Policy Agent](https://oreil.ly/nbR5d), a
    cloud native open source policy engine that is extensible and allows policy to
    be portable across different applications. Open Policy Agent (OPA) is responsible
    for performing all policy evaluations and returning either an admit or deny. This
    gives Gatekeeper access to an ecosystem of policy tooling, such as, [Conftest](https://oreil.ly/ElWYE),
    which enables you to write policy tests and implement them in continuous integration
    pipelines before deployment.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper 的核心是 [Open Policy Agent](https://oreil.ly/nbR5d)，一个可扩展的云原生开源策略引擎，允许策略在不同应用程序之间可移植。Open
    Policy Agent (OPA) 负责执行所有策略评估并返回允许或拒绝结果。这使得 Gatekeeper 能够访问一系列策略工具，例如 [Conftest](https://oreil.ly/ElWYE)，它允许您编写策略测试并在部署之前在持续集成流水线中实施它们。
- en: Open Policy Agent exclusively uses a native query language called [Rego](https://oreil.ly/Ar55f)
    for all policies. One of the core tenets of Gatekeeper is to abstract the inner
    workings of Rego from the cluster administrator and present a structured API in
    the form of a Kubernetes CRD to create and apply policy. This lets you share parameterized
    policies across organizations and the community. The Gatekeeper project maintains
    a policy library solely for this purpose (discussed later in this chapter).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Open Policy Agent 专门使用名为 [Rego](https://oreil.ly/Ar55f) 的本机查询语言来管理所有策略。Gatekeeper
    的核心原则之一是将 Rego 的内部工作与集群管理员抽象化，并通过 Kubernetes CRD 提供结构化 API，以创建和应用策略。这使您能够在组织和社区之间共享参数化的策略。Gatekeeper
    项目专门为此目的维护一个策略库（本章后续讨论）。
- en: Installing Gatekeeper
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Gatekeeper
- en: Before you start configuring policies, you’ll need to install Gatekeeper. Gatekeeper
    components run as Pods in the `gatekeeper-system` namespace and configure a webhook
    admission controller.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始配置策略之前，您需要安装 Gatekeeper。Gatekeeper 组件作为 Pod 运行在 `gatekeeper-system` 命名空间中，并配置
    webhook 入场控制器。
- en: Warning
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Do not install Gatekeeper on a Kubernetes cluster without first understanding
    how to safely create and disable policy. You should also review the installation
    YAML before installing Gatekeeper to ensure that you are comfortable with the
    resources it creates.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在不理解如何安全创建和禁用策略之前，请不要在 Kubernetes 集群上安装 Gatekeeper。在安装 Gatekeeper 之前，请查看安装 YAML
    文件，以确保您对其创建的资源感到满意。
- en: 'You can install Gatekeeper using the Helm package manager:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 Helm 软件包管理器安装 Gatekeeper：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Gatekeeper installation requires cluster-admin permissions and is version specific.
    Please refer to the official documentation for the latest release of [Gatekeeper](https://oreil.ly/GvLHc).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper 的安装需要 cluster-admin 权限，并且具体版本。请参阅 [Gatekeeper](https://oreil.ly/GvLHc)
    的官方文档获取最新发布信息。
- en: 'Once the installation is complete, confirm that Gatekeeper is up and running:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，请确认 Gatekeeper 是否已启动：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can also review how the webhook is configured using this command:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用此命令查看 webhook 的配置方式：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Under the `rules` section of the output above, we see that all resources are
    being sent to the webhook admission controller, running as a service named `gatekeeper-webhook-service`
    in the `gatekeeper-system` namespace. Only resources from namespaces that aren’t
    labeled `admission.gatekeeper.sh/ignore` will be considered for policy evaluation.
    Finally, the `failurePolicy` is set to `Ignore`, which means that this is a *fail
    open configuration*: if the Gatekeeper service doesn’t respond within the configured
    timeout of three seconds, the request will be admitted.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述输出的 `rules` 部分下，我们看到所有资源都将发送到名为 `gatekeeper-webhook-service` 的服务，该服务作为 `gatekeeper-system`
    命名空间中的服务运行。仅有标签不是 `admission.gatekeeper.sh/ignore` 的命名空间中的资源将被用于策略评估。最后，`failurePolicy`
    设置为 `Ignore`，这意味着这是一个 *失败开放配置*：如果 Gatekeeper 服务在配置的三秒超时内未响应，则请求将被允许通过。
- en: Configuring Policies
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置策略
- en: Now that you have Gatekeeper installed, you can start configuring policies.
    We will first go through a canonical example and demonstrate how the cluster administrator
    creates policies. Then we’ll look at the developer experience when creating compliant
    and noncompliant resources. We will then expand on each step to gain a deeper
    understanding, and walk you through the process of creating a sample policy stating
    that container images can only come from one specific registry. This example is
    based on the [Gatekeeper policy library](https://oreil.ly/ikfZk).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在Gatekeeper已安装，您可以开始配置策略。我们将首先介绍一个典型的示例，并演示集群管理员创建策略的过程。然后我们将查看开发人员在创建符合和不符合规范的资源时的体验。然后我们将进一步扩展每个步骤以获得更深入的理解，并指导您完成创建样例策略的过程，声明容器镜像只能来自一个特定的注册表。此示例基于[Gatekeeper策略库](https://oreil.ly/ikfZk)。
- en: First, you’ll need to configure the policy we need to create a custom resource
    called a *constraint template*. This is usually done by a cluster administrator.
    The constraint template in [Example 20-1](#example1701) requires you to provide
    a list of container repositories as parameters that Kubernetes resources are allowed
    to use.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要配置我们需要创建自定义资源的策略，称为*约束模板*。这通常由集群管理员完成。在[示例20-1](#example1701)中的约束模板需要您提供容器库列表作为参数，允许Kubernetes资源使用。
- en: Example 20-1\. allowedrepos-constraint-template.yaml
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 20-1\. allowedrepos-constraint-template.yaml
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create the constraint template using the following command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令创建约束模板：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now you can create a constraint resource to put the policy into effect (again,
    playing the role of the cluster administrator). The constraint in [Example 20-2](#example1702)
    allows all containers with the prefix of `gcr.io/kuar-demo/` in the `default`
    namespace. The `enforcementAction` is set to “deny”: any noncompliant resources
    will be denied.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以创建一个约束资源来实施策略（再次扮演集群管理员的角色）。[示例20-2](#example1702)中的约束允许在`default`命名空间中具有`gcr.io/kuar-demo/`前缀的所有容器。`enforcementAction`设置为“deny”：任何不符合规范的资源都将被拒绝。
- en: Example 20-2\. allowedrepos-constraint.yaml
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 20-2\. allowedrepos-constraint.yaml
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The next step is to create some Pods to test that the policy is indeed working.
    [Example 20-3](#example1703) creates a Pod using a container image, `gcr.io/kuar-demo/kuard-amd64:blue`,
    that complies with the constraint we defined in the previous step. Workload resource
    creation is typically performed by the developer responsible for operating the
    service or a continuous delivery pipeline.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一些Pod来测试策略是否有效。[示例20-3](#example1703)创建一个Pod，使用一个符合我们在上一步定义的约束的容器镜像，`gcr.io/kuar-demo/kuard-amd64:blue`。工作负载资源的创建通常由负责操作服务的开发人员或持续交付流水线执行。
- en: Example 20-3\. compliant-pod.yaml
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 20-3\. compliant-pod.yaml
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: What happens if we create a noncompliant Pod? [Example 20-4](#example1704) creates
    a Pod using a container image, `nginx`, that is *not* compliant with the constraint
    we defined in the previous step. Workload resource creation would typically be
    performed by the developer or continuous delivery pipeline responsible for operating
    the service. Note the output in [Example 20-4](#example1704).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们创建一个不符合规范的Pod会发生什么？[示例20-4](#example1704)创建一个Pod，使用一个不符合我们在上一步定义的约束的容器镜像，`nginx`。工作负载资源的创建通常由开发人员或负责操作服务的持续交付流水线执行。请注意[示例20-4](#example1704)中的输出。
- en: Example 20-4\. noncompliant-pod.yaml
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 20-4\. noncompliant-pod.yaml
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[Example 20-4](#example1704) shows that an error is returned to the user with
    details on why the resource was not created and how to remediate the issue. Cluster
    administrators can configure the error message in the constraint template.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例20-4](#example1704)显示向用户返回错误，并详细说明为什么未创建资源以及如何解决问题。集群管理员可以在约束模板中配置错误消息。'
- en: Note
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If your constraint’s scope is Pods and you create a resource that generates
    Pods, such as ReplicaSets, Gatekeeper will return an error. However, it won’t
    be returned to you, the user, but to the controller trying to create the Pod.
    To see these error messages, look in the event log for the relevant resource.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的约束范围是Pod，并且您创建生成Pod的资源（例如ReplicaSets），Gatekeeper将返回一个错误。然而，它不会返回给您，而是返回给尝试创建Pod的控制器。要查看这些错误消息，请查看相关资源的事件日志。
- en: Understanding Constraint Templates
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解约束模板
- en: Now that we have walked through a canoncial example, take a closer look at the
    constraint template in [Example 20-1](#example1701), which takes a list of container
    repositories that are allowed in Kubernetes resources.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经演示了一个经典示例，请仔细查看[示例 20-1](#example1701)中的约束模板，该模板列出了允许在Kubernetes资源中使用的容器存储库列表。
- en: 'This constraint template has an `apiVersion` and `kind` that are part of the
    custom resources used only by Gatekeeper. Under the `spec` section, you’ll see
    the name `K8sAllowedRepos`: remember that name, because you’ll use it as the constraint
    kind when creating constraints. You’ll also see a schema that defines an array
    of strings for the cluster administrator to configure. This is done by providing
    a list of allowed container registries. It also contains the raw Rego policy definition
    (under the `target` section). This policy evaluates containers and initContainers
    to ensure that the container repository name starts with the values provided by
    the constraint. The `msg` section defines the message that is sent back to the
    user if the policy is violated.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此约束模板具有作为Gatekeeper专用自定义资源一部分的“apiVersion”和“kind”。在“spec”部分下，您将看到名称“K8sAllowedRepos”：请记住此名称，因为在创建约束时，您将使用它作为约束类型。您还将看到一个模式，该模式定义了供集群管理员配置的字符串数组。这通过提供允许的容器注册表列表来完成。它还包含原始的Rego策略定义（在“target”部分下）。此策略评估容器和initContainers，以确保容器存储库名称以约束提供的值开头。如果违反策略，则在“msg”部分定义的消息将发送回用户。
- en: Creating Constraints
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建约束
- en: To instantiate a policy, you must create a constraint that provides the template’s
    required parameters. There may be many constraints that match the kind of a specific
    constraint template. Let’s take a closer look at the constraint we used in [Example 20-2](#example1702),
    which allows only container images that originate from *gcr.io/kuar-demo/*.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化策略，您必须创建一个约束，提供模板所需的参数。可能会有许多与特定约束模板种类匹配的约束。让我们仔细查看我们在[示例 20-2](#example1702)中使用的约束，该约束仅允许来源于*gcr.io/kuar-demo/*的容器镜像。
- en: 'You may notice that the constraint is of the `kind` “K8sAllowedRepos,” which
    was defined as part of the constraint template. It also defines an `enforcementAction`
    of “deny,” meaning that noncompliant resources will be denied. `enforcementAction`
    also accepts “dryrun” and “warn”: “dryrun” uses the audit feature to test policies
    and verify their impact; “warn” sends a warning back to the user with the associated
    message, but allows them to create or update. The `match` portion defines the
    scope of this constraint, all Pods in the default namespace. Finally, the `parameters`
    section is required to satisfy the constraint template (an array of strings).
    The following demonstrates the user experience when the `enforcementAction` is
    set to “warn”:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这些限制是基于“K8sAllowedRepos”类型的约束，这是作为约束模板的一部分定义的。它还定义了一个“enforcementAction”为“deny”，意味着不符合规范的资源将被拒绝。
    “enforcementAction”还接受“dryrun”和“warn”： “dryrun”使用审计功能来测试策略并验证其影响； “warn”将警告发送回用户并附带消息，但允许他们创建或更新。
    “match”部分定义了此约束的范围，即默认命名空间中的所有Pod。最后，“parameters”部分是必需的，以满足约束模板（字符串数组）。以下演示了当“enforcementAction”设置为“warn”时用户体验：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Warning
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Constraints are only enforced on resource CREATE and UPDATE events. If you already
    have workloads running on a cluster, Gatekeeper will not reevaluate them until
    a CREATE or UPDATE event takes place.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 约束仅在资源创建和更新事件上执行。如果您已经在集群上运行工作负载，则Gatekeeper不会重新评估它们，直到发生创建或更新事件。
- en: 'Here is a real-world example to demonstrate: say you create a policy that only
    allows containers from a specific registry. All workloads that are already running
    on the cluster will continue to do so. If you scale the workload Deployment from
    1 to 2, the ReplicaSet will attempt to create another Pod. If that Pod doesn’t
    have a container from an allowed repository, then it will be denied. It’s important
    to set the `enforcementAction` to “dryrun” and audit to confirm that any policy
    violations are known before setting the `enforcementAction` to “deny.”'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个现实世界的例子来演示：假设您创建了一个策略，仅允许来自特定仓库的容器。所有在集群上已运行的工作负载将继续运行。如果您将工作负载Deployment从1扩展到2，ReplicaSet将尝试创建另一个Pod。如果该Pod没有来自允许的存储库的容器，则将被拒绝。在将“enforcementAction”设置为“deny”之前，将其设置为“dryrun”并进行审计以确认任何策略违规都是已知的，这一点非常重要。
- en: Audit
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审计
- en: Being able to enforce policy on new resources is only one piece of the policy
    and governance story. Policies often change over time, and you can also use Gatekeeper
    to confirm that everything currently deployed is still compliant. Additionally,
    you may already have a cluster full of services and wish to install Gatekeeper
    to bring these resources into compliance. Gatekeeper’s audit capabilities allow
    cluster administrators to get a list of current, noncompliant resources on a cluster.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 能够对新资源实施策略只是策略和治理故事的一部分。策略经常会随时间变化，您还可以使用Gatekeeper确认当前部署的一切是否仍然符合规定。此外，您可能已经拥有一个充满服务的集群，并希望安装Gatekeeper以使这些资源符合规定。Gatekeeper的审计功能允许集群管理员获取集群中当前非符合规定的资源列表。
- en: To demonstrate how auditing works, let’s look at an example. We’re going to
    update the `repo-is-kuar-demo` constraint to have an `enforcementAction` action
    of “dryrun” (as shown in [Example 20-5](#example1707)). This will allow users
    to create noncompliant resources. We will then determine which resources are noncompliant
    using audit.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要演示审计的工作原理，让我们看一个例子。我们将更新`repo-is-kuar-demo`的约束，使`enforcementAction`动作为“dryrun”（如[示例20-5](#example1707)所示）。这将允许用户创建不符合规定的资源。然后，我们将使用审计确定哪些资源不符合规定。
- en: Example 20-5\. allowedrepos-constraint-dryrun.yaml
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例20-5\. allowedrepos-constraint-dryrun.yaml
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Update the constraint by running the following command:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令更新约束：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create a noncompliant Pod using the following command:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令创建不符合规定的Pod：
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To audit the list of noncompliant resources for a given constraint, run a `kubectl
    get constraint` on that constraint and specify that you want the output in YAML
    format as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要对给定约束的非符合资源列表进行审计，请运行`kubectl get constraint`命令，并指定要将输出格式设置为YAML，如下所示：
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Under the `status` section, you can see the `auditTimestamp`, which is the last
    time the audit was run. `totalViolations` lists the number of resources that violate
    this constraint. The `violations` section lists the violations. We can see that
    the nginx-noncompliant Pod is in violation and the message with the details why.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在`status`部分下，您可以看到`auditTimestamp`，这是上次运行审计的时间。`totalViolations`列出了违反此约束的资源数量。`violations`部分列出了违规情况。我们可以看到nginx-noncompliant
    Pod存在违规，并显示了详细的消息。
- en: Note
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Using a constraint `enforcementAction` of “dryrun” along with audit is a powerful
    way to confirm that your policy is having the desired impact. It also creates
    a workflow to bring resources into compliance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`enforcementAction`约束为“dryrun”与审计是确认您的策略产生预期影响的强大方式。它还创建了一个将资源带入符合规定的工作流程。
- en: Mutation
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mutation
- en: So far we have covered how you can use constraints to validate if a resource
    is compliant. What about modifying resources to make them compliant? This is handled
    via the mutation feature in Gatekeeper. Earlier in this chapter, we discussed
    two different type of admission webhooks, mutating and validating. By default,
    Gatekeeper is only deployed as a validating admission webhook, but it can be configured
    to operate as a mutating admission webhook.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了如何使用约束来验证资源是否符合规定。那么如何修改资源使其符合规定呢？这通过Gatekeeper中的Mutation功能来处理。在本章的前面部分，我们讨论了两种不同类型的入场网钩，即Mutation和Validation。默认情况下，Gatekeeper仅部署为验证入场网钩，但可以配置为操作为Mutation入场网钩。
- en: Note
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Mutation features in Gatekeeper are in beta state and may change. We share them
    to demonstrate Gatekeeper’s upcoming capabilities. The installation steps in this
    chapter do not cover enabling mutation. Please refer to the Gatekeeper project
    for more information on [enabling mutation](https://oreil.ly/DQKhl).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper中的Mutation功能处于beta状态，可能会发生变化。我们分享它们以展示Gatekeeper即将推出的功能。本章中的安装步骤不涵盖启用Mutation。请参考Gatekeeper项目以获取有关[启用Mutation](https://oreil.ly/DQKhl)的更多信息。
- en: Let’s walk through an example to demonstrate the power of mutation. In this
    example, we will set the `imagePullPolicy` to “Always” on all Pods. We will assume
    that Gatekeeper is configured correctly to support mutation. [Example 20-6](#example1708)
    defines a mutation assignment that matches all Pods except those in the “system”
    namespace, and assigns a value of “Always” to `imagePullPolicy`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个示例来展示Mutation的威力。在本示例中，我们将在所有Pod上将`imagePullPolicy`设置为“Always”。我们将假设Gatekeeper已正确配置以支持Mutation。[示例20-6](#example1708)定义了一个Mutation分配，该分配匹配除“system”命名空间之外的所有Pod，并将`imagePullPolicy`的值设置为“Always”。
- en: Example 20-6\. imagepullpolicyalways-mutation.yaml
  id: totrans-93
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例20-6\. imagepullpolicyalways-mutation.yaml
- en: '[PRE16]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create the mutation assignment:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 创建Mutation分配：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now create a Pod. This Pod doesn’t have `imagePullPolicy` explicitly set, so
    by default this field is set to “IfNotPresent.” However, we expect Gatekeeper
    to mutate this field to “Always”:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在创建一个 Pod。此 Pod 未显式设置 `imagePullPolicy`，因此默认情况下此字段设置为“IfNotPresent”。但是，我们期望
    Gatekeeper 将此字段变更为“Always”：
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Validate that the `imagePullPolicy` has been successfully mutated to “Always”
    by running the following:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下内容验证 `imagePullPolicy` 是否已成功变更为“Always”：
- en: '[PRE19]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: Mutating admission happens before validating admission, so create constraints
    that validate the mutations you expect to apply to the specific resource.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 变更准入发生在验证准入之前，因此创建验证所期望的变更的约束，应用于特定资源。
- en: 'Delete the Pod using the following command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令删除 Pod：
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Delete the mutation assignment using the following command:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令删除变更分配：
- en: '[PRE21]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Unlike validation, mutation provides a way to remediate noncompliant resources
    automatically on behalf of the cluster administrator.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 与验证不同，变更提供了一种自动修复非符合资源的方式，代表群集管理员操作。
- en: Data Replication
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据复制
- en: 'When writing constraints you may want to compare the value of one field to
    the value of a field in another resource. A specific example of when you might
    need to do this is making sure that ingress hostnames are unique across a cluster.
    By default, Gatekeeper can only evaluate fields within the current resource: if
    comparisons across resources are required to fulfill a policy, it must be configured.
    Gatekeeper can be configured to cache specific resources into Open Policy Agent
    to allow comparisons across resources. The resource in [Example 20-7](#example1709)
    configures Gatekeeper to cache Namespace and Pod resources.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写约束时，您可能希望比较一个字段的值与另一个资源中字段的值。可能需要执行此操作的具体示例是确保整个群集中入口主机名唯一。默认情况下，Gatekeeper
    只能评估当前资源内的字段：如果需要跨资源比较来满足策略，则必须进行配置。Gatekeeper 可配置为将特定资源缓存到 Open Policy Agent
    中，以允许跨资源比较。[示例 20-7](#example1709) 中的资源配置 Gatekeeper 以缓存 Namespace 和 Pod 资源。
- en: Example 20-7\. config-sync.yaml
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 20-7\. config-sync.yaml
- en: '[PRE22]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: You should only cache the specific resources needed to perform a policy evaluation.
    Having hundreds or thousands of resources cached in OPA will require more memory
    and may also have security implications.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您应仅缓存执行策略评估所需的特定资源。在 OPA 中缓存数百或数千个资源将需要更多内存，并可能具有安全性影响。
- en: The constraint template in [Example 20-8](#example1710) demonstrates how to
    compare something in the Rego section (in this case, unique ingress hostnames).
    Specifically, “data.inventory” refers to the cache resources, as opposed to “input,”
    which is the resource sent for evaluation from the Kubernetes API server as part
    of the admission flow. This example is based on the [Gatekeeper policy library](https://oreil.ly/gGrts).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 20-8](#example1710) 中的约束模板演示了如何在 Rego 部分中比较某些内容（在本例中为唯一的入口主机名）。具体而言，“data.inventory”
    指的是缓存资源，而不是从 Kubernetes API 服务器发送到评估的“input”资源，作为准入流程的一部分。此示例基于[Gatekeeper 策略库](https://oreil.ly/gGrts)。'
- en: Example 20-8\. uniqueingresshost-constraint-template.yaml
  id: totrans-115
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 20-8\. uniqueingresshost-constraint-template.yaml
- en: '[PRE23]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Data replication is a powerful tool that allows you to make comparisons across
    Kubernetes resources. We recommend only configuring it if you have policies that
    require it to function. If you use it, scope it only to the relevant resources.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 数据复制是一个强大的工具，允许您跨 Kubernetes 资源进行比较。我们建议仅在需要此功能的策略下配置它。如果使用它，请仅将其限定于相关资源。
- en: Metrics
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标
- en: Gatekeeper emits metrics in Prometheus format to enable continuous resource
    compliance monitoring. You can view simple metrics regarding Gatekeeper’s overall
    health, such as the numbers of constraints, constraint templates, and requests
    being set to Gatekeeper.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper 以 Prometheus 格式发出指标，以实现持续资源符合性监控。您可以查看有关 Gatekeeper 总体健康状况的简单指标，例如约束数、约束模板数以及发送给
    Gatekeeper 的请求数。
- en: 'In addition, details on policy compliance and governance are also available:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还提供有关策略符合性和治理的详细信息：
- en: The total number of audit violations
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审计违规总数
- en: Number of constraints by `enforcementAction`
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按 `enforcementAction` 分类的约束数
- en: Audit duration
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审计持续时间
- en: Note
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: Completely automating the policy and governance process is the ideal goal, so
    we strongly recommended that you monitor Gatekeeper from an external monitoring
    system and set alerts based on resource compliance.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 完全自动化策略和治理过程是理想目标，因此强烈建议您从外部监控系统监视 Gatekeeper，并根据资源符合性设置警报。
- en: Policy Library
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 策略库
- en: One of the core tenets of the Gatekeeper project is to create reusable policy
    libraries that can be shared between organizations. Being able to share policies
    reduces boilerplate policy work and allows cluster administrators to focus on
    applying policy rather than writing it. The Gatekeeper project has a great [policy
    library](https://oreil.ly/uBY2h). It contains a general library with the most
    common policies as well as a *pod-security-policy* library that models the capabilities
    of the PodSecurityPolicy API as Gatekeeper policy. The great thing about this
    library is that it is always expanding and is open source, so feel free to contribute
    any policies that you write.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper 项目的核心理念之一是创建可在组织之间共享的可重用策略库。能够共享策略可以减少模板化的策略工作，使集群管理员能够专注于应用策略而不是编写它们。Gatekeeper
    项目拥有一个很棒的 [策略库](https://oreil.ly/uBY2h)。它包含一个通用库，其中包含最常见的策略，以及一个 *pod-security-policy*
    库，该库模拟了 PodSecurityPolicy API 作为 Gatekeeper 策略的能力。这个库的好处在于它持续扩展并且是开源的，因此请随意贡献您编写的任何策略。
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you’ve learned about policy and governance and why they are
    important as more and more resources are deployed to Kubernetes. We covered the
    Gatekeeper project, a Kubernetes-native policy controller built on Open Policy
    Agent, and showed you to use it to meet your policy and governance requirements.
    From writing policies to auditing, you are now equipped with the know-how to meet
    your compliance needs.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了策略和治理的重要性，特别是在越来越多的资源部署到 Kubernetes 上时。我们介绍了 Gatekeeper 项目，这是一个基于 Open
    Policy Agent 构建的 Kubernetes 本地策略控制器，并向您展示了如何使用它来满足您的策略和治理需求。从编写策略到审核，您现在具备了满足合规需求的技能。
