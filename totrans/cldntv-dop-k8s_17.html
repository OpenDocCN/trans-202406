<html><head></head><body><section data-pdf-bookmark="Chapter 15. Observability and Monitoring" data-type="chapter" epub:type="chapter"><div class="chapter" id="observability">&#13;
<h1><span class="label">Chapter 15. </span>Observability and Monitoring</h1>&#13;
&#13;
<blockquote class="epigraph">&#13;
<p>Nothing is ever completely right aboard a ship.</p>&#13;
<p data-type="attribution">William Langewiesche, <cite><em>The Outlaw Sea</em></cite></p>&#13;
</blockquote>&#13;
&#13;
<p><a data-primary="Kubernetes" data-secondary="observability and monitoring" data-type="indexterm" id="ix_15-observability-adoc0"/>In this chapter, we’ll consider the question of observability and monitoring for cloud native applications. What is observability? How does it relate to monitoring? How do you do monitoring, logging, metrics, and tracing in Kubernetes?</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What Is Observability?" data-type="sect1"><div class="sect1" id="idm45979374518544">&#13;
<h1>What Is Observability?</h1>&#13;
&#13;
<p><em>Observability</em> may not be a familiar term to you, though it’s becoming increasingly popular as a way to express the larger world beyond traditional monitoring. Let’s tackle <em>monitoring</em> first before we see how observability extends it.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What Is Monitoring?" data-type="sect2"><div class="sect2" id="idm45979374516240">&#13;
<h2>What Is Monitoring?</h2>&#13;
&#13;
<p><a data-primary="monitoring" data-secondary="definition" data-type="indexterm" id="idm45979374515040"/>Is your website working right now? Go check; we’ll wait. The most basic way to know whether all your applications and services are working as they should is to look at them yourself. But when we talk about monitoring in a DevOps context, we mostly mean <em>automated monitoring</em>.</p>&#13;
&#13;
<p>Automated monitoring is checking the availability or behavior of a website or service, in some programmatic way, usually on a regular schedule, and usually with some automated way of alerting human engineers if there’s a problem. But what defines a problem?</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Closed-Box Monitoring" data-type="sect2"><div class="sect2" id="closedbox">&#13;
<h2>Closed-Box Monitoring</h2>&#13;
&#13;
<p><a data-primary="monitoring" data-secondary="closed-box" data-type="indexterm" id="idm45979374510480"/>Let’s take the simple case of a static website. If it’s not working at all, it just won’t respond, or you’ll see an error message in the browser. So the simplest possible monitoring check for this site is to fetch the home page and check the HTTP status code (200 indicates a successful request). You could do this with a command-line HTTP client such as <code>httpie</code> or <code>curl</code>. If the exit status from the client is nonzero, there was a problem fetching the website.</p>&#13;
&#13;
<p>But suppose something went wrong with the web server configuration, and although the server is working and responding with HTTP <code>200 OK</code> status, it is actually serving a blank page (or some sort of default or welcome page, or maybe the wrong site altogether). Our simplistic monitoring check won’t detect any issue because the HTTP request succeeds; however, the site is not working as expected for users.</p>&#13;
&#13;
<p>A more sophisticated monitoring check might look for some specific text on the page that you know should be there, like the name of the organization. This would catch the problem of a misconfigured, but working, web server.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Beyond static pages" data-type="sect3"><div class="sect3" id="idm45979374506144">&#13;
<h3>Beyond static pages</h3>&#13;
&#13;
<p>You can imagine that more complex websites might need more complex monitoring. For example, if the site had a facility for users to log in, the monitoring check might also try to log in with a known test-user account and alert if the login fails. Or if the site had a search function, the check might fill in a text field with some search text, simulate clicking the search button, and verify that the results contain some expected text.</p>&#13;
&#13;
<p>For simple websites, a yes/no answer to the question “Is it working?” may be sufficient. For cloud native applications, which tend to be more complex distributed systems, the question may turn into multiple questions:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Is my application available everywhere in the world? Or only in some regions?</p>&#13;
</li>&#13;
<li>&#13;
<p>How long does it take to load for most of my users?</p>&#13;
</li>&#13;
<li>&#13;
<p>What about users who may have slow download speeds?</p>&#13;
</li>&#13;
<li>&#13;
<p>Are all of the features of my website working as intended?</p>&#13;
</li>&#13;
<li>&#13;
<p>Are certain features working slowly or not at all, and how many users are affected?</p>&#13;
</li>&#13;
<li>&#13;
<p>If it relies on a third-party service, what happens to my application when that external service is faulty or unavailable?</p>&#13;
</li>&#13;
<li>&#13;
<p>What happens when my cloud provider has an outage?</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>It starts to become clear that, in the world of monitoring cloud native distributed systems, not very much is clear at all.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The limits of closed-box monitoring" data-type="sect3"><div class="sect3" id="idm45979374496400">&#13;
<h3>The limits of closed-box monitoring</h3>&#13;
&#13;
<p><a data-primary="monitoring" data-secondary="limitations" data-type="indexterm" id="idm45979374495056"/>However, no matter how complicated these checks get, they all fall into the same category of monitoring: <em>closed-box monitoring</em>. Closed-box checks, as the name suggests, observe only the external behavior of a system, without any attempt to observe what’s going on inside it.</p>&#13;
&#13;
<p>Until a few years ago, closed-box monitoring, as performed by popular tools such as Nagios, Icinga, Zabbix, Sensu, and Check_MK, was pretty much state of the art. To be sure, having <em>any</em> kind of automated monitoring of your systems is a huge improvement on having none. But there are a few limitations of closed-box checks:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>They can only detect predictable failures (for example, a website not responding).</p>&#13;
</li>&#13;
<li>&#13;
<p>They only check the behavior of the parts of the system that are exposed to the outside.</p>&#13;
</li>&#13;
<li>&#13;
<p>They are passive and reactive; they only tell you about a problem <em>after</em> it’s happened.</p>&#13;
</li>&#13;
<li>&#13;
<p>They can answer the question “What’s broken?” but not the more important question “Why?”</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>To answer the “why?” question, we need to move beyond traditional monitoring.</p>&#13;
&#13;
<p>There’s a further issue with this kind of <em>up</em>/<em>down</em> test; what does <em>up</em> even mean?</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What Does “Up” Mean?" data-type="sect2"><div class="sect2" id="idm45979374485184">&#13;
<h2>What Does “Up” Mean?</h2>&#13;
&#13;
<p><a data-primary="uptime" data-type="indexterm" id="idm45979374483840"/>In operations we’re used to measuring the resilience and availability of our applications in <em>uptime</em>, usually measured as a percentage. <a data-primary="nines of uptime" data-type="indexterm" id="idm45979374482512"/>For example, an application with 99% uptime was unavailable for no more than 1% of the relevant time period. 99.9% uptime, referred to as <em>three nines</em>, translates to about nine hours downtime a year, which would be a good figure for the average web application. Four nines (99.99%) is less than an hour’s downtime per year, and five nines (99.999%) is about five minutes.</p>&#13;
&#13;
<p>So, the more nines the better, you might think. But looking at things this way misses an important point:</p>&#13;
<blockquote data-type="quote">&#13;
<p>Nines don’t matter if users aren’t happy.</p>&#13;
<p data-type="attribution"><a href="https://red.ht/2FMZcMZ">Charity Majors</a></p>&#13;
</blockquote>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Nines don’t matter if users aren’t happy" data-type="sect3"><div class="sect3" id="idm45979374477904">&#13;
<h3>Nines don’t matter if users aren’t happy</h3>&#13;
&#13;
<p>As the saying goes, what gets measured gets maximized. So you’d better be very careful what you measure. If your service isn’t working for users, it doesn’t matter what your internal metrics say: <em>the service is down</em>. There are lots of ways a service can be making users unhappy, even if it’s nominally <em>up</em>.</p>&#13;
&#13;
<p>To take an obvious example, what if your website takes 10 seconds to load? It might work fine after that, but if it’s too slow to respond, it might as well be down completely. Users will just go elsewhere.</p>&#13;
&#13;
<p>Traditional closed-box monitoring might attempt to deal with this problem by defining a load time of, say, five seconds as <em>up</em>, and anything over that is considered <em>down</em> and an alert generated. But what if users are experiencing all sorts of different load times, from 2 seconds to 10 seconds? With a hard threshold like this, you could consider the service <em>down</em> for some users, but <em>up</em> for others. What if load times are fine for users in North America, but unusable in Europe or Asia?</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Cloud native applications are never “up”" data-type="sect3"><div class="sect3" id="neverup">&#13;
<h3>Cloud native applications are never “up”</h3>&#13;
&#13;
<p>While you could go on refining more complex rules and thresholds to enable us to give an <em>up</em>/<em>down</em> answer about the status of the service, the truth is that the question is irredeemably flawed. Distributed systems like cloud native applications are <a href="http://red.ht/2hMHwSL">never <em>up</em></a>; they exist in a constant state of partially degraded <span class="keep-together">service.</span></p>&#13;
&#13;
<p><a data-primary="gray failures" data-type="indexterm" id="idm45979374467472"/>This is an example of a class of problems called <a href="https://oreil.ly/4r86k"><em>gray failures</em></a>.<sup><a data-type="noteref" href="ch15.html#idm45979374465760" id="idm45979374465760-marker">1</a></sup> Gray failures are, by definition, hard to detect, especially from a single point of view or with a single observation.</p>&#13;
&#13;
<p>So while closed-box monitoring may be a good place to start your observability journey, it’s important to recognize that you shouldn’t stop there. Let’s see if we can do better.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Logging" data-type="sect2"><div class="sect2" id="idm45979374463856">&#13;
<h2>Logging</h2>&#13;
&#13;
<p><a data-primary="logs" data-secondary="information included in" data-type="indexterm" id="idm45979374462480"/>Most applications produce <em>logs</em> of some kind. Logs are a series of records, usually with some kind of timestamps to indicate when records were written, and in what order. For example, a web server records each request in its logs, including information such as:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The URI requested</p>&#13;
</li>&#13;
<li>&#13;
<p>The IP address of the client</p>&#13;
</li>&#13;
<li>&#13;
<p>The HTTP status of the response</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>If the application encounters an error, it usually logs this fact, along with some information that may or may not be helpful for operators to figure out what caused the problem.</p>&#13;
&#13;
<p>Often, logs from a wide range of applications and services will be <em>aggregated</em> into a central database (Elasticsearch, for example), where they can be queried and graphed to help with troubleshooting. Tools like Logstash and Kibana, or hosted services such as Splunk and Loggly, are designed to help you gather and analyze large volumes of log data.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The limits of logging" data-type="sect3"><div class="sect3" id="idm45979374456016">&#13;
<h3>The limits of logging</h3>&#13;
&#13;
<p><a data-primary="logs" data-secondary="limitations" data-type="indexterm" id="idm45979374454640"/>Logs can be useful, but they have their limitations too. The decision about what to log or not to log is taken by the programmer at the time the application is written. Therefore, like closed-box checks, logs can only answer questions or detect problems that can be predicted in advance.</p>&#13;
&#13;
<p>It can also be hard to extract information from logs, because every application writes logs in a different format, and operators often need to write customized parsers for each type of log record to turn it into usable numerical or event data.</p>&#13;
&#13;
<p>Because logs have to record enough information to diagnose any conceivable kind of problem, they usually have a poor signal-to-noise ratio. If you log everything, it’s difficult and time-consuming to wade through hundreds of pages of logs to find the one error message you need. If you log only occasional errors, it’s hard to know what <em>normal</em> looks like.</p>&#13;
&#13;
<p>Using a standard format for your logs can greatly improve their usefulness. Logging events in something like JSON with a known structure will make it much easier to sift through the noise when trying to make sense of what the logs are saying.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Logs are hard to scale" data-type="sect3"><div class="sect3" id="idm45979374450576">&#13;
<h3>Logs are hard to scale</h3>&#13;
&#13;
<p>Logs also don’t scale very well with traffic. If every user request generates a log line that has to be sent to the aggregator, you can end up using a lot of network bandwidth (which is thus unavailable to serve users), and your log aggregator can become a bottleneck.</p>&#13;
&#13;
<p>Many hosted logging providers also charge by the volume of logs you generate, which is understandable but unfortunate: it incentivizes you financially to log less information, and to have fewer users and serve less traffic!</p>&#13;
&#13;
<p>The same applies to self-hosted logging solutions: the more data you store, the more hardware, storage, and network resources you have to pay for, and the more engineering time goes into merely keeping log aggregation working.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is logging useful in Kubernetes?" data-type="sect3"><div class="sect3" id="idm45979374447392">&#13;
<h3>Is logging useful in Kubernetes?</h3>&#13;
&#13;
<p>We talked a little about how containers generate logs and how you can inspect them directly in Kubernetes, in <a data-type="xref" href="ch07.html#containerlogs">“Viewing a Container’s Logs”</a>. This is a useful debugging technique for individual containers.</p>&#13;
&#13;
<p>If you do use logging, you should use some form of structured data, like JSON, which can be automatically parsed (see <a data-type="xref" href="#o11ypipeline">“The Observability Pipeline”</a>) rather than plain-text records.</p>&#13;
&#13;
<p>Centralized log aggregation with services like <a href="https://oreil.ly/1r4BG">Loki</a> can be useful with Kubernetes applications, but it’s not the whole story. While there are some business use-cases for centralized logging (audit and security requirements, for example, or customer analytics), logs can’t give us all the information we need for true <span class="keep-together">observability</span>.</p>&#13;
&#13;
<p>For that, we need to look beyond logs, to something much more powerful.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Introducing Metrics" data-type="sect2"><div class="sect2" id="metrics-intro">&#13;
<h2>Introducing Metrics</h2>&#13;
&#13;
<p><a data-primary="metrics" data-secondary="introduction" data-type="indexterm" id="idm45979374439072"/>A more sophisticated way of gathering information about your services is to use <em>metrics</em>. As the name suggests, a metric is a numerical measure of something. Depending on the application, relevant metrics might include:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The number of requests currently being processed</p>&#13;
</li>&#13;
<li>&#13;
<p>The number of requests handled per minute (or per second, or per hour)</p>&#13;
</li>&#13;
<li>&#13;
<p>The number of errors encountered when handling requests</p>&#13;
</li>&#13;
<li>&#13;
<p>The average time it took to serve requests (or the peak time, or the 99th <span class="keep-together">percentile)</span></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>It’s also useful to gather metrics about your infrastructure as well as your applications:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The CPU usage of individual processes or containers</p>&#13;
</li>&#13;
<li>&#13;
<p>The disk I/O activity of nodes and servers</p>&#13;
</li>&#13;
<li>&#13;
<p>The inbound and outbound network traffic of machines, clusters, or load <span class="keep-together">balancers</span></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Metrics help answer the “why?” question" data-type="sect3"><div class="sect3" id="idm45979374428000">&#13;
<h3>Metrics help answer the “why?” question</h3>&#13;
&#13;
<p>Metrics open up a new dimension of monitoring beyond simply finding out if something is <em>working</em> or <em>not working</em>. Like the speedometer in your car, or the temperature scale on your thermometer, they give you numerical information about what’s happening. Unlike logs, metrics can easily be processed in all sorts of useful ways: drawing graphs, taking statistics, or alerting on predefined thresholds. For example, your monitoring system might alert you if the error rate for an application exceeds 10% for a given time period.</p>&#13;
&#13;
<p>Metrics can also help answer the “why?” question about problems. For example, suppose users are experiencing long response times (high <em>latency</em>) from your app. You check your metrics, and you see that the spike in the <em>latency</em> metric coincides with a similar spike in the <em>CPU usage</em> metric for a particular machine or component. That immediately gives you a clue about where to start looking for the problem. The component may be wedged, or repeatedly retrying some failed operation, or its host node may have a hardware problem.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Metrics help predict problems" data-type="sect3"><div class="sect3" id="idm45979374422832">&#13;
<h3>Metrics help predict problems</h3>&#13;
&#13;
<p>Also, metrics can be <em>predictive</em>: when things go wrong, it usually doesn’t happen all at once. Before a problem is noticeable to you or your users, an increase in some metric may indicate that trouble is on the way.</p>&#13;
&#13;
<p>For example, the disk usage metric for a server may creep up and up over time, and eventually reach the point where the disk actually runs out of space and things start failing. If you alerted on that metric before it got into failure territory, you could prevent the failure from happening at all.</p>&#13;
&#13;
<p>Some systems even use machine learning techniques to analyze metrics, detect anomalies, and reason about the cause. This can be helpful, especially in complex distributed systems, but for most purposes, simply having a way to gather, graph, and alert on metrics is plenty good enough.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Metrics monitor applications from the inside" data-type="sect3"><div class="sect3" id="idm45979374419696">&#13;
<h3>Metrics monitor applications from the inside</h3>&#13;
&#13;
<p>With closed-box checks, operators have to make guesses about the internal implementation of the app or service, and predict what kind of failures might happen and what effect this would have on external behavior. By contrast, metrics allow application developers to export key information about the hidden aspects of the system, based on their knowledge of how it actually works (and how it fails):</p>&#13;
<blockquote data-type="quote">&#13;
<p>Stop reverse engineering applications and start monitoring from the inside.</p>&#13;
<p data-type="attribution"><a href="https://vimeo.com/173610242">Kelsey Hightower, Monitorama 2016</a></p>&#13;
</blockquote>&#13;
&#13;
<p>Tools like Prometheus, StatsD, and Graphite, or hosted services such as Datadog, New Relic, and Dynatrace, are widely used to gather and manage metrics data.</p>&#13;
&#13;
<p>We’ll talk much more in <a data-type="xref" href="ch16.html#metrics">Chapter 16</a> about metrics in the context of Kubernetes, including what kinds you should focus on, and what you should do with them. For now, let’s complete our survey of observability with a look at tracing.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Tracing" data-type="sect2"><div class="sect2" id="idm45979374413856">&#13;
<h2>Tracing</h2>&#13;
&#13;
<p><a data-primary="tracing" data-type="indexterm" id="idm45979374412544"/>Another useful technique in the monitoring toolbox is <em>tracing</em>. It’s especially important in distributed systems. While metrics and logs tell you what’s going on with each individual component of your system, tracing follows a single user request through its whole life cycle.</p>&#13;
&#13;
<p>Suppose you’re trying to figure out why some users are experiencing very high latency for requests. You check the metrics for each of your system components: load balancer, ingress, web server, application server, database, message bus, and so on; and everything appears normal. So what’s going on?</p>&#13;
&#13;
<p>When you trace an individual (hopefully representative) request from the moment the user’s connection is opened to the moment it’s closed, you’ll get a picture of how that overall latency breaks down for each stage of the request’s journey through the system.</p>&#13;
&#13;
<p>For example, you may find that the time spent handling the request in each stage of the pipeline is normal, except for the database hop, which is one hundred times longer than normal. Although the database is working fine and its metrics show no problems, for some reason the application server is having to wait a very long time for requests to the database to complete.</p>&#13;
&#13;
<p>Eventually you track down the problem to excessive packet loss over one particular network link between the application servers and the database server. Without the <em>request’s eye view</em> provided by distributed tracing, it’s hard to find problems like this.</p>&#13;
&#13;
<p>Some popular distributed tracing tools include <a href="https://zipkin.io">Zipkin</a>, <a href="https://www.jaegertracing.io">Jaeger</a>, and <a href="https://lightstep.com/product">Lightstep</a>. Engineer Masroor Hasan has written a useful blog post, <a href="https://oreil.ly/esVav">“Distributed Tracing Infrastructure with Jaeger on Kubernetes”</a> that describes how to use Jaeger for distributed tracing in Kubernetes.<sup><a data-type="noteref" href="ch15.html#idm45979374404496" id="idm45979374404496-marker">2</a></sup></p>&#13;
&#13;
<p>The <a href="https://opentracing.io">OpenTracing framework</a> (part of the CNCF) aims to provide a standard set of APIs and libraries for distributed tracing.</p>&#13;
&#13;
<p><a href="https://px.dev">Pixie</a> is another interesting project that adds tracing and application profiling for Kubernetes applications, along with a rich query language that allows you to explore what is happening inside of the cluster.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Observability" data-type="sect2"><div class="sect2" id="idm45979374400400">&#13;
<h2>Observability</h2>&#13;
&#13;
<p><a data-primary="observability" data-secondary="definition" data-type="indexterm" id="idm45979374399024"/>Because the term <em>monitoring</em> means different things to different people—from plain old closed-box checks to a combination of metrics, logging, and tracing—it’s becoming common to use <em>observability</em> as a catch-all term that covers all these techniques. The observability of your system is a measure of how well instrumented it is, and how easily you can find out what’s going on inside it. Some people say that observability is a superset of monitoring, others that observability reflects a completely different mindset from traditional monitoring.</p>&#13;
&#13;
<p>Perhaps the most useful way to distinguish these terms is to say that monitoring tells you <em>whether the system is working</em>, while observability prompts you to ask <em>why it’s not working</em>, along with considering <em>how well it is performing</em>.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Observability is about understanding" data-type="sect3"><div class="sect3" id="idm45979374394640">&#13;
<h3>Observability is about understanding</h3>&#13;
&#13;
<p><a data-primary="observability" data-secondary="distinction from monitoring" data-type="indexterm" id="idm45979374393424"/>More generally, observability is about <em>understanding</em>: understanding what your system does and how it does it. For example, if you roll out a code change that is designed to improve the performance of a particular feature by 10%, then observability can tell you whether or not it worked. If performance only went up a tiny bit, or worse, went down slightly, you need to revisit the code.</p>&#13;
&#13;
<p>On the other hand, if performance went up 20%, the change exceeded your expectations, and maybe you need to think about why your predictions fell short. Observability helps you build and refine your mental model of how the different parts of your system interact.</p>&#13;
&#13;
<p>Observability is also about <em>data</em>. We need to know what data to generate, what to collect, how to aggregate it (if appropriate), what results to focus on, and how to query and display them.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Software is opaque" data-type="sect3"><div class="sect3" id="idm45979374389696">&#13;
<h3>Software is opaque</h3>&#13;
&#13;
<p>In traditional monitoring we have lots of data about the <em>machinery</em>: CPU loads, disk activity, network packets, and so on. But it’s hard to reason backward from that about what our <em>software</em> is doing. To do that, we need to instrument the software itself:</p>&#13;
<blockquote data-type="quote">&#13;
<p>Software is opaque by default; it must generate data in order to clue humans in on what it is doing. Observable systems allow humans to answer the question, “Is it working properly?”, and if the answer is no, to diagnose the scope of impact and identify what is going wrong.</p>&#13;
<p data-type="attribution"><a href="https://oreil.ly/iJeFI">Christine Spang</a></p>&#13;
</blockquote>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Building an observability culture" data-type="sect3"><div class="sect3" id="idm45979374384352">&#13;
<h3>Building an observability culture</h3>&#13;
&#13;
<p><a data-primary="observability" data-secondary="culture of" data-type="indexterm" id="idm45979374383136"/>Even more generally, observability is about <em>culture</em>. It’s a key tenet of the DevOps philosophy to close the loop between developing code and running it at scale in production. Observability is the primary tool for closing that loop. Developers and operations staff need to work closely together to instrument services for observability, and then figure out the best way to consume and act on the information it provides.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Observability Pipeline" data-type="sect1"><div class="sect1" id="o11ypipeline">&#13;
<h1>The Observability Pipeline</h1>&#13;
&#13;
<p><a data-primary="observability" data-secondary="pipeline for" data-type="indexterm" id="idm45979374378864"/>How does observability work, from a practical point of view? It’s common to have multiple data sources (logs, metrics, and so on) connected to various different data stores in a fairly ad hoc way.</p>&#13;
&#13;
<p>For example, your logs might go to an ELK server, while metrics go to three or four different managed services, and traditional monitoring checks report to yet another service. This isn’t ideal.</p>&#13;
&#13;
<p>For one thing, it’s hard to scale. The more data sources and stores you have, the more interconnections there are, and the more traffic over those connections. It doesn’t make sense to put engineering time into making all of those different kinds of connections stable and reliable.</p>&#13;
&#13;
<p>Also, the more tightly integrated your systems become with specific solutions or providers, the harder it is to change them or to try out alternatives.</p>&#13;
&#13;
<p>An increasingly popular way to address this problem is the <a href="https://oreil.ly/Vyn5M"><em>observability pipeline</em></a>:</p>&#13;
<blockquote>&#13;
<p>With an observability pipeline, we decouple the data sources from the destinations and provide a buffer. This makes the observability data easily consumable. We no longer have to figure out what data to send from containers, VMs, and infrastructure, where to send it, and how to send it. Rather, all the data is sent to the pipeline, which handles filtering it and getting it to the right places. This also gives us greater flexibility in terms of adding or removing data sinks, and it provides a buffer between data producers and consumers.</p>&#13;
<p data-type="attribution">Tyler Treat</p>&#13;
</blockquote>&#13;
&#13;
<p>An observability pipeline brings great advantages. Now, adding a new data source is just a matter of connecting it to your pipeline. Similarly, a new visualization or alerting service just becomes another consumer of the pipeline.</p>&#13;
&#13;
<p>Because the pipeline buffers data, nothing gets lost. If there’s a sudden surge in traffic and an overload of metrics data, the pipeline will buffer it rather than drop samples.</p>&#13;
&#13;
<p>Using an observability pipeline requires a standard metrics format (see <a data-type="xref" href="ch16.html#prometheus">“Prometheus”</a>) and, ideally, structured logging from applications using JSON or some other sensible serialized data format. Instead of emitting raw text logs, and parsing them later with fragile regular expressions, start with structured data from the very beginning.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Monitoring in Kubernetes" data-type="sect1"><div class="sect1" id="idm45979374380064">&#13;
<h1>Monitoring in Kubernetes</h1>&#13;
&#13;
<p><a data-primary="observability" data-secondary="monitoring in Kubernetes" data-type="indexterm" id="ix_15-observability-adoc1"/>So now that we understand a little more about what closed-box monitoring is and how it relates to observability in general, let’s see how it applies to Kubernetes applications.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="External Closed-Box Checks" data-type="sect2"><div class="sect2" id="idm45979374367664">&#13;
<h2>External Closed-Box Checks</h2>&#13;
&#13;
<p><a data-primary="monitoring" data-secondary="closed-box" data-type="indexterm" id="idm45979374366352"/>As we’ve seen, closed-box monitoring can only tell you that your application is down. But that’s still very useful information. All kinds of things could be wrong with a cloud native application, and it might still be able to serve some requests acceptably. Engineers can work on fixing internal problems like slow queries and elevated error rates, without users really being aware of an issue.</p>&#13;
&#13;
<p>However, a more serious class of problems results in a full-scale <em>outage</em>: the application is unavailable or not working for the majority of users. This is bad for the users, and depending on the application, it may be bad for your business as well. In order to detect an outage, your monitoring needs to consume the service in the same way that a user would.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Monitoring mimics user behavior" data-type="sect3"><div class="sect3" id="idm45979374363936">&#13;
<h3>Monitoring mimics user behavior</h3>&#13;
&#13;
<p>For example, if it’s an HTTP service, the monitoring system needs to make HTTP requests to it, not just TCP connections. If the service just returns static text, monitoring can check the text matches some expected string. Usually, it’s a little bit more complicated than that, but your checks can also be more robust.</p>&#13;
&#13;
<p>In an outage situation, though, it’s quite likely that a simple text match will be sufficient to tell you the application is down. But making these closed-box checks from inside your infrastructure (for example, in Kubernetes) isn’t enough. An outage can result from all sorts of problems and failures between the user and the outside edge of your infrastructure, including:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Bad DNS records</p>&#13;
</li>&#13;
<li>&#13;
<p>Network partitions</p>&#13;
</li>&#13;
<li>&#13;
<p>Packet loss</p>&#13;
</li>&#13;
<li>&#13;
<p>Misconfigured routers</p>&#13;
</li>&#13;
<li>&#13;
<p>Missing or bad firewall rules</p>&#13;
</li>&#13;
<li>&#13;
<p>Cloud provider outage</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>In all these situations, your internal metrics and monitoring might show no problems at all. Therefore, your top-priority observability task should be to monitor the availability of your services from some point external to your own infrastructure. There are many third-party services that can do this kind of monitoring for you, including Uptime Robot, Pingdom, and Wormly.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Don’t build your own monitoring infrastructure" data-type="sect3"><div class="sect3" id="dontbuildyourown">&#13;
<h3>Don’t build your own monitoring infrastructure</h3>&#13;
&#13;
<p>Most of these services have either a free tier, or fairly inexpensive subscriptions—and whatever you pay for them you should regard as an essential operating expense. Don’t bother trying to build your own external monitoring infrastructure; it’s not worth it. The cost of a year’s Pro subscription to Uptime Robot likely would not pay for a single hour of your engineers’ time.</p>&#13;
&#13;
<p>Look for the following critical features in an external monitoring provider:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>HTTP/HTTPS checks</p>&#13;
</li>&#13;
<li>&#13;
<p>Detect if your TLS certificate is invalid or expired</p>&#13;
</li>&#13;
<li>&#13;
<p>Keyword matching (alert when the keyword is missing <em>or</em> when it’s present)</p>&#13;
</li>&#13;
<li>&#13;
<p>Automatically create or update checks via an API</p>&#13;
</li>&#13;
<li>&#13;
<p>Alerts by email, SMS, webhook, or some other straightforward mechanism</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Throughout this book we champion the idea of infrastructure as code, so it should be possible to automate your external monitoring checks with code as well. For example, Uptime Robot has a simple REST API for creating new checks, and you can automate it using a client library or command-line tool like <a href="https://oreil.ly/WP5eG"><code>uptimerobot</code></a>.</p>&#13;
&#13;
<p>It doesn’t matter which external monitoring service you use, so long as you use one. But don’t stop there. In the next section, we’ll see what we can do to monitor the health of applications inside the Kubernetes cluster itself.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Internal Health Checks" data-type="sect2"><div class="sect2" id="idm45979374344800">&#13;
<h2>Internal Health Checks</h2>&#13;
&#13;
<p><a data-primary="monitoring" data-secondary="internal health checks" data-type="indexterm" id="ix_15-observability-adoc2"/>Cloud native applications fail in complex, unpredictable, and hard-to-detect ways. Applications have to be designed to be resilient and degrade gracefully in the face of unexpected failures, but ironically, the more resilient they are, the harder it is to detect these failures by closed-box monitoring.</p>&#13;
&#13;
<p>To solve this problem, applications can, and should, do their own health checking. The developer of a particular feature or service is best placed to know what it needs to be <em>healthy</em>, and they can write code to check this that exposes the results in a way that can be monitored from outside the container (like an HTTP endpoint).</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Are users happy?" data-type="sect3"><div class="sect3" id="idm45979374340672">&#13;
<h3>Are users happy?</h3>&#13;
&#13;
<p><a data-primary="liveness probe" data-type="indexterm" id="idm45979374339296"/><a data-primary="readiness probe" data-type="indexterm" id="idm45979374338592"/>Kubernetes gives us a simple mechanism for applications to advertise their liveness or readiness, as we saw in <a data-type="xref" href="ch05.html#liveness">“Liveness Probes”</a>, so this is a good place to start. Usually, Kubernetes liveness or readiness probes are pretty simple; the application always responds “OK” to any requests. If it doesn’t respond, Kubernetes considers it to be down or unready.</p>&#13;
&#13;
<p>However, as many programmers know from bitter experience, just because a program runs, doesn’t necessarily mean it works correctly. A more sophisticated readiness probe should ask, “What does this application need in order to do its job?”</p>&#13;
&#13;
<p>For example, if it needs to talk to a database, it can check that it has a valid and responsive database connection. If it depends on other services, it can check the <span class="keep-together">services’</span> availability. (If health checks are run frequently, they shouldn’t do anything too expensive that might affect serving requests from real users.)</p>&#13;
&#13;
<p>Note that we’re still giving a binary yes/no response to the readiness probe. It’s just a more informed answer. What we’re trying to do is answer the question “Are users happy?” as accurately as possible.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Services and circuit breakers" data-type="sect3"><div class="sect3" id="idm45979374333808">&#13;
<h3>Services and circuit breakers</h3>&#13;
&#13;
<p><a data-primary="circuit breaker pattern" data-type="indexterm" id="idm45979374332464"/>As you know, if a container’s <em>liveness</em> check fails, Kubernetes will restart it automatically, in an exponential backoff loop. This isn’t really that helpful in the situation where there’s nothing wrong with the container, but one of its dependencies is failing. The semantics of a failed <em>readiness</em> check, on the other hand, is “I’m fine, but I can’t serve user requests at the moment.”</p>&#13;
&#13;
<p>In this situation, the container will be removed from any Services that it’s a backend for, and Kubernetes will stop sending it requests until it becomes ready again. This is a better way to deal with a failed dependency.</p>&#13;
&#13;
<p>Suppose you have a chain of 10 microservices, each of which depends on the next for some critical part of its work. The last service in the chain fails. The next-to-last service will detect this and start failing its readiness probe. Kubernetes will disconnect it, and the next service in line detects this, and so on up the chain. Eventually the frontend service will fail, and (hopefully) a closed-box monitoring alert will be tripped.</p>&#13;
&#13;
<p>Once the problem with the base service is fixed, or maybe cured by an automatic restart, all the other services in the chain will automatically become ready again in turn, without being restarted or losing any state. This is an example of what’s called a <a href="https://oreil.ly/F3lKZ"><em>circuit breaker pattern</em></a>. When an application detects a downstream failure, it takes itself out of service (via the readiness check) to prevent any more requests being sent to it until the problem is fixed.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Graceful degradation" data-type="sect3"><div class="sect3" id="idm45979374327520">&#13;
<h3>Graceful degradation</h3>&#13;
&#13;
<p>While a circuit breaker is useful for surfacing problems as soon as possible, you should design your services to avoid having the whole system fail when one or more component services are unavailable. Instead, try to make your services <em>degrade gracefully</em>: even if they can’t do everything they’re supposed to, maybe they can still do some things.</p>&#13;
&#13;
<p>In distributed systems, we have to assume that services, components, and connections will fail mysteriously and intermittently more or less all the time. A resilient system can handle this without failing completely<a data-startref="ix_15-observability-adoc2" data-type="indexterm" id="idm45979374324832"/>.<a data-startref="ix_15-observability-adoc1" data-type="indexterm" id="idm45979374324032"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45979374322928">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>There’s a lot to say about the topic of monitoring and observability. We hope this chapter has given you some useful information about traditional monitoring <span class="keep-together">techniques,</span> what they can do and what they can’t do, and how things need to adapt in a cloud native environment.</p>&#13;
&#13;
<p>The notion of <em>observability</em> introduces us to a bigger picture than traditional log files and closed-box checks. Metrics form an important part of this picture, and in the next and final chapter, we’ll take you on a deep dive into the world of metrics in Kubernetes.</p>&#13;
&#13;
<p>Before turning the page, though, you might like to recall these key points:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Closed-box monitoring checks observe the external behavior of a system to detect predictable failures.</p>&#13;
</li>&#13;
<li>&#13;
<p>Distributed systems expose the limitations of traditional monitoring because they’re not in either <em>up</em> or <em>down</em> states: they exist in a constant state of partially degraded service. In other words, nothing is ever completely right aboard a ship.</p>&#13;
</li>&#13;
<li>&#13;
<p>Logs can be useful for post-incident troubleshooting, but they’re expensive to scale. Loki and ELK are popular centralized logging tools.</p>&#13;
</li>&#13;
<li>&#13;
<p>Metrics open up a new dimension beyond simply <em>working</em>/<em>not working</em>, and give you continuous numerical time-series data on hundreds or thousands of aspects of your system. Prometheus is a popular option for aggregating application metrics.</p>&#13;
</li>&#13;
<li>&#13;
<p>Metrics can help you answer the “why?” question, as well as identify problematic trends before they lead to outages.</p>&#13;
</li>&#13;
<li>&#13;
<p>Tracing records events with precise timing through the life cycle of an individual request to help you debug performance problems. Jaeger, Zipkin, and Pixie are some examples of tools that offer application tracing.</p>&#13;
</li>&#13;
<li>&#13;
<p>Observability is the union of traditional monitoring, logging, metrics, and tracing, and all the other ways you can understand your system.</p>&#13;
</li>&#13;
<li>&#13;
<p>Observability also represents a shift toward a team culture of engineering based on facts and feedback.</p>&#13;
</li>&#13;
<li>&#13;
<p>It’s still important to check that your user-facing services are up, with external closed-box checks, but don’t try to build your own: use a third-party monitoring service like Uptime Robot.</p>&#13;
</li>&#13;
<li>&#13;
<p>Nines don’t matter if users aren’t happy.<a data-startref="ix_15-observability-adoc0" data-type="indexterm" id="idm45979374306160"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45979374465760"><sup><a href="ch15.html#idm45979374465760-marker">1</a></sup> <a href="https://blog.acolyer.org">“Gray failure: the Achilles’ heel of cloud-scale systems”</a>, by Adrian Colyer, June 2017.</p><p data-type="footnote" id="idm45979374404496"><sup><a href="ch15.html#idm45979374404496-marker">2</a></sup> <a href="https://medium.com/@masroor.hasan">“Distributed Tracing Infrastructure with Jaeger on Kubernetes”</a>, by Masroor Hasan, September 2018.</p></div></div></section></body></html>