- en: Chapter 11\. Security, Backups, and Cluster Health
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you think technology can solve your security problems, then you don’t understand
    the problems and you don’t understand the technology.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bruce Schneier, *Applied Cryptography*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this chapter, we’ll explore the security and access control machinery in
    Kubernetes, including Role-Based Access Control (RBAC), outline some vulnerability
    scanning tools and services, and explain how to back up your Kubernetes data and
    state (and even more importantly, how to restore it). We’ll also look at some
    useful ways to get information about what’s happening in your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Access Control and Permissions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Small tech companies tend to start out with just a few employees, and everyone
    has administrator access on every system.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the organization grows, though, eventually it becomes clear that it is no
    longer a good idea for everyone to have administrator rights: it’s too easy for
    someone to make a mistake and change something they shouldn’t. The same applies
    to Kubernetes.'
  prefs: []
  type: TYPE_NORMAL
- en: Managing Access by Cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the easiest and most effective things you can do to secure your Kubernetes
    cluster is limit who has access to it. There are generally two groups of people
    who need to access Kubernetes clusters: *cluster operators* and *application developers*,
    and they often need different permissions and privileges as part of their job
    function.'
  prefs: []
  type: TYPE_NORMAL
- en: Also, you may well have multiple deployment environments, such as production
    and staging. These separate environments will need different policies, depending
    on your organization. Production may be restricted to only some individuals, whereas
    staging may be open to a broader group of engineers.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in [“Do I need multiple clusters?”](ch06.html#multiclusters), it’s
    often a good idea to have separate clusters for production and staging or testing.
    If someone accidentally deploys something in staging that brings down the cluster
    nodes, it will not impact production.
  prefs: []
  type: TYPE_NORMAL
- en: If one team should not have access to another team’s software and deployment
    process, each team could have their own dedicated cluster and not even have credentials
    on the other team’s clusters.
  prefs: []
  type: TYPE_NORMAL
- en: This is certainly the most secure approach, but additional clusters come with
    tradeoffs. Each needs to be patched and monitored, and many small clusters tend
    to run less efficiently than larger clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Role-Based Access Control (RBAC)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another way you can manage access is by controlling who can perform certain
    operations inside the cluster, using Kubernetes’ Role-Based Access Control (RBAC)
    system.
  prefs: []
  type: TYPE_NORMAL
- en: RBAC is designed to grant specific permissions to specific users (or service
    accounts, which are user accounts associated with automated systems). For example,
    you can grant the ability to list all Pods in the cluster to a particular user
    if they need it.
  prefs: []
  type: TYPE_NORMAL
- en: The first and most important thing to know about RBAC is that it should be turned
    on. RBAC was introduced in Kubernetes 1.6 as an option when setting up clusters.
    However, whether this option is actually enabled in your cluster depends on your
    cloud provider or Kubernetes installer.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re running a self-hosted cluster, try this command to see whether or
    not RBAC is enabled on your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If `--authorization-mode` doesn’t contain `RBAC`, then RBAC is not enabled for
    your cluster. Check the documentation for the installer to see how to rebuild
    the cluster with RBAC enabled.
  prefs: []
  type: TYPE_NORMAL
- en: Without RBAC, anyone with access to the cluster has the power to do anything,
    including running arbitrary code or deleting workloads. This probably isn’t what
    you want.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Roles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, assuming you have RBAC enabled, how does it work? The most important concepts
    to understand are *users*, *roles*, and *role bindings*.
  prefs: []
  type: TYPE_NORMAL
- en: Every time you connect to a Kubernetes cluster, you do so as a specific user.
    Exactly how you authenticate to the cluster depends on your provider; for example,
    in GKE, you use the `gcloud` tool to get an access token to a particular cluster.
    On EKS, you use your AWS IAM credentials. There are also service accounts in the
    cluster; for example, there is a default service account for each namespace. Users
    and service accounts can all have different sets of permissions.
  prefs: []
  type: TYPE_NORMAL
- en: These are governed by Kubernetes *roles*. A role describes a specific set of
    permissions. Kubernetes includes some predefined roles to get you started. For
    example, the `cluster-admin` role, intended for superusers, is permitted access
    to read and change any resource in the cluster. By contrast, the `view` role can
    list and examine most objects in a given namespace, but not modify them.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can define roles on the namespace level (using the `Role` object) or across
    the whole cluster (using the ClusterRole object). Here’s an example of a ClusterRole
    manifest that grants read access to Secrets in any namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Binding Roles to Users
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do you associate a user with a role? You can do that using a role binding.
    Just like with roles, you can create a `RoleBinding` object that applies to a
    specific namespace, or a ClusterRoleBinding that applies at the cluster level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the RoleBinding manifest that gives the `daisy` user the `edit` role
    in the `demo` namespace only:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In Kubernetes, permissions are *additive*; users start with no permissions,
    and you can add them using Roles and RoleBindings. You can’t subtract permissions
    from someone who already has them.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can read more about the details of RBAC, and the available roles and permissions,
    in the Kubernetes [documentation](https://oreil.ly/SOxYN).
  prefs: []
  type: TYPE_NORMAL
- en: What Roles Do I Need?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So what roles and bindings should you set up in your cluster? The predefined
    roles `cluster-admin`, `edit`, and `view` will probably cover most requirements.
    To see what permissions a given role has, use the `kubectl describe` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You could create roles for specific people or jobs within your organization
    (for example, a developer role), or individual teams (for example, QA or security).
  prefs: []
  type: TYPE_NORMAL
- en: Guard Access to cluster-admin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Be very careful about who has access to the `cluster-admin` role. This is the
    cluster superuser, equivalent to the root user on Unix systems. They can do anything
    to anything. Never give this role to users who are not cluster operators, and
    especially not to service accounts for apps that might be exposed to the internet,
    such as the Kubernetes Dashboard (see [“Kubernetes Dashboard”](#dashboard)).
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Don’t fix problems by granting *cluster-admin* unnecessarily. You’ll find some
    bad advice about this on sites like Stack Overflow. When faced with a Kubernetes
    permissions error, a common response is to grant the `cluster-admin` role to the
    application. *Don’t do this*. Yes, it makes the errors go away, but at the expense
    of bypassing all security checks and potentially opening up your cluster to an
    attacker. Instead, grant the application a role with the fewest privileges it
    needs to do its job.
  prefs: []
  type: TYPE_NORMAL
- en: Applications and Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Apps running in Kubernetes usually don’t need any special RBAC permissions.
    Unless you specify otherwise, all Pods will run as the `default` service account
    in their namespace, which has no roles associated with it.
  prefs: []
  type: TYPE_NORMAL
- en: If your app needs access to the Kubernetes API for some reason (for example,
    a monitoring tool that needs to list Pods), create a dedicated service account
    for the app, use a `RoleBinding` to associate it with the necessary role (for
    example, `view`), and limit it to specific namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: What about the permissions required to deploy applications to the cluster? The
    most secure way is to allow only a continuous deployment tool to deploy apps (see
    [Chapter 14](ch14.html#continuous)). It can use a dedicated service account, with
    permission to create and delete Pods in a particular namespace.
  prefs: []
  type: TYPE_NORMAL
- en: The `edit` role is ideal for this. Users with the `edit` role can create and
    destroy resources in the namespace, but can’t create new roles or grant permissions
    to other users.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t have an automated deployment tool, and developers have to deploy
    directly to the cluster, they will need edit rights to the appropriate namespaces
    too. Grant these on an application-by-application basis; don’t give anyone edit
    rights across the whole cluster. People who don’t need to deploy apps should have
    only the `view` role by default.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, you should set up a centralized CI/CD deployment process so that developers
    do not need to directly deploy to Kubernetes. We will cover this more in [Chapter 14](ch14.html#continuous)
    and in [“GitOps”](ch14.html#gitops).
  prefs: []
  type: TYPE_NORMAL
- en: Best Practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Make sure RBAC is enabled in all your clusters. Give `cluster-admin` rights
    only to users who actually need the power to destroy everything in the cluster.
    If your app needs access to cluster resources, create a service account for it
    and bind it to a role with only the permissions it needs, in only the namespaces
    where it needs them.
  prefs: []
  type: TYPE_NORMAL
- en: RBAC Troubleshooting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you’re running an older third-party application that isn’t RBAC-aware, or
    if you’re still working out the required permissions for your own application,
    you may run into RBAC permission errors. What do these look like?
  prefs: []
  type: TYPE_NORMAL
- en: 'If an application makes an API request for something it doesn’t have permission
    to do (for example, list nodes) it will see a *Forbidden* error response (HTTP
    status 403) from the API server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If the application doesn’t log this information, or you’re not sure which application
    is failing, you can check the API server’s log (see [“Viewing a Container’s Logs”](ch07.html#containerlogs)
    for more about this). It will record messages like this, containing the string
    `RBAC DENY` with a description of the error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '(You won’t be able to do this on a GKE cluster, or any other managed Kubernetes
    service that doesn’t give you access to the control plane: see the documentation
    for your Kubernetes provider to find out how to access API server logs.)'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl` also includes a useful command for testing out permissions called
    `auth can-i`. This allows you to try out a Kubernetes operation using your current
    role, or you can test the permisisons of someone else to see if their role allows
    a particular command or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: RBAC has a reputation for being complicated, but it’s really not. Just grant
    users the minimum privileges they need, keep `cluster-admin` safe, and you’ll
    be fine.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster Security Scanning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to check for potential known security issues, there are tools for scanning
    your clusters that will let you know of any issues detected.
  prefs: []
  type: TYPE_NORMAL
- en: Gatekeeper/OPA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In February of 2021, the CNCF graduated the [Open Policy Agent (OPA)](https://www.openpolicyagent.org)
    project, meaning that it meets the standards and maturity required to be included
    alongside the other officially adopted CNCF projects. OPA is a *policy engine*
    tool that allows you to define security policies for any of your cloud native
    tools, including Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: '[Gatekeeper](https://oreil.ly/vosvu) is a related project that takes the OPA
    engine and makes it run inside of Kubernetes as native resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, using Gatekeeper you could add the following constraint to prevent
    containers in a given namespace from running if they are using the `latest` tag
    (see [“The latest Tag”](ch08.html#latesttag) for more info):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: There are many other Kubernetes-specific policies maintained in the [`gatekeeper-library`
    repo](https://oreil.ly/PPDYg). Other examples include ensuring that all Pods have
    a known set of labels, or forcing containers to come from a list of trusted registry
    sources. You can also consider using OPA for auditing and securing your non-Kubernetes
    cloud resources.
  prefs: []
  type: TYPE_NORMAL
- en: kube-bench
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[kube-bench](https://oreil.ly/IFV8p) is a tool for auditing your Kubernetes
    cluster against a set of benchmarks produced by the Center for Internet Security
    (CIS). In effect, it verifies that your cluster is set up according to security
    best practices. Although you probably won’t need to, you can configure the tests
    that kube-bench runs, and even add your own, specified as YAML documents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to [“Conformance Testing with Sonobuoy”](ch06.html#sonobuoy), kube-bench
    runs when you deploy a Job to Kubernetes and inspect the results. Download the
    appropriate Job YAML file for your cluster, based on the [repository docs](https://oreil.ly/8zI5c),
    and install it to your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You can then read through the logs to get the specifics about any warnings or
    failures that kube-bench has found.
  prefs: []
  type: TYPE_NORMAL
- en: Kubescape
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another tool in this space is called [Kubescape](https://oreil.ly/Bt9be), and
    it checks to see if your clusters are secure according to recent standards defined
    in the [CIS Benchmark](https://oreil.ly/vT8Kl). It will let you know about containers
    that are running as root, any potentially insecure exposed ports, check that your
    authentication and audit log settings are configured securely, and other similar
    items defined in the CIS checklist.
  prefs: []
  type: TYPE_NORMAL
- en: Container Security Scanning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you’re running third-party software in your cluster, it’s wise to check it
    for security problems and malware. But even your own containers may have software
    in them that you’re not aware of, and that needs to be checked too.
  prefs: []
  type: TYPE_NORMAL
- en: Clair
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Clair](https://oreil.ly/RDSHS) is an open source container scanner produced
    by the CoreOS project. It statically analyzes container images, before they are
    actually run, to see if they contain any software or versions that are known to
    be insecure.'
  prefs: []
  type: TYPE_NORMAL
- en: You can run Clair manually to check specific images for problems, or integrate
    it into your CD pipeline to test all images before they are deployed (see [Chapter 14](ch14.html#continuous)).
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, Clair can hook into your container registry to scan any images
    that are pushed to it and report problems.
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth mentioning that you shouldn’t automatically trust base images, such
    as `alpine`. Clair is preloaded with security checks for many popular base images,
    and will tell you immediately if you’re using one that has a known vulnerability.
  prefs: []
  type: TYPE_NORMAL
- en: Aqua
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Aqua’s Container Security Platform](https://oreil.ly/rLSPJ) is a full-service
    commercial container security offering, allowing organizations to scan containers
    for vulnerabilities, malware, and suspicious activity, as well as providing policy
    enforcement and regulatory compliance.'
  prefs: []
  type: TYPE_NORMAL
- en: As you’d expect, Aqua’s platform integrates with your container registry, CI/CD
    pipeline, and multiple orchestration systems, including Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Aqua also offers [Trivy](https://oreil.ly/T4bSS), a free-to-use tool that you
    can add to your container images to scan installed packages for known vulnerabilities
    from the same database that the Aqua Security Platform uses.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want Trivy to scan a particular Docker image, install the CLI tool and
    run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also use it to scan for security issues and misconfigurations in your
    Dockerfiles, Terraform files, and even your Kubernetes manifests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Another handy open source tool from Aqua is [kube-hunter](https://kube-hunter.aquasec.com),
    designed to find security issues in your Kubernetes cluster itself. If you run
    it as a container on a machine outside your cluster, as an attacker might, it
    will check for various kinds of problems: exposed email addresses in certificates,
    unsecured dashboards, open ports and endpoints, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Anchore Engine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The [Anchore Engine](https://oreil.ly/O0ik7) is an open source tool for scanning
    container images, not only for known vulnerabilities, but to identify the *bill
    of materials* of everything present in the container, including libraries, configuration
    files, and file permissions. You can use this to verify containers against user-defined
    policies: for example, you can block any images that contain security credentials,
    or application source code.'
  prefs: []
  type: TYPE_NORMAL
- en: Synk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Docker partnered with [Synk](https://snyk.io) to add vulnerability scanning
    directly into the `docker` CLI tool. You can scan any image using the `docker
    scan` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Synk will tell you about known security issues and deprecations found in the
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This can be a quick and easy way to add some basic security scanning into your
    Docker workflow as well as your CI/CD pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Best Practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Don’t run containers from untrusted sources, or when you’re not sure what’s
    in them. Run a scanning tool like Clair or Synk over all containers, especially
    those you build yourself, to make sure there are no known vulnerabilities in any
    of the base images or dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Backups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might be wondering whether you still need backups in cloud native architectures.
    After all, Kubernetes is inherently reliable and can handle the loss of several
    nodes at once, without losing state or even degrading application performance
    too much.
  prefs: []
  type: TYPE_NORMAL
- en: Also, Kubernetes is a declarative IaC system. All Kubernetes resources are described
    by data stored in a reliable database (`etcd`). In the event of some Pods being
    accidentally deleted, their supervising Deployment will re-create them from the
    spec held in the database.
  prefs: []
  type: TYPE_NORMAL
- en: Do I Need to Back Up Kubernetes?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So do you still need backups? Well, yes. The data stored on persistent volumes,
    for example, is vulnerable to failure (see [“Persistent Volumes”](ch08.html#persistent)).
    While your cloud vendor may provide nominally high-availability volumes (replicating
    the data across two different availability zones, for example), that’s not the
    same as backup.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s repeat that point, because it’s not obvious:'
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '*Replication is not backup*. While replication may protect you from the failure
    of the underlying storage volume, it won’t protect you from accidentally deleting
    the volume by mis-clicking in a web console, for example.'
  prefs: []
  type: TYPE_NORMAL
- en: Nor will replication prevent a misconfigured application from overwriting its
    data, or an operator from running a command with the wrong environment variables
    and accidentally dropping the production database instead of the development one.
    ([This has happened](https://oreil.ly/0bxEk), probably more often than anyone’s
    willing to admit.^([1](ch11.html#idm45979378784352)))
  prefs: []
  type: TYPE_NORMAL
- en: Backing Up etcd
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw in [“High Availability”](ch03.html#highavailability), Kubernetes stores
    all its state in the `etcd` database, so any failure or data loss here could be
    catastrophic. That’s one very good reason why we recommend that you use managed
    services that guarantee the availability of `etcd` and the control plane generally
    (see [“Use Managed Kubernetes if You Can”](ch03.html#usemanaged)).
  prefs: []
  type: TYPE_NORMAL
- en: If you run your own control plane nodes, you are responsible for managing `etcd`
    clustering and replication. Even with regular data snapshots, it still takes a
    certain amount of time to retrieve and verify the snapshot, rebuild the cluster,
    and restore the data. During this time, your cluster will likely be unavailable
    or seriously degraded.
  prefs: []
  type: TYPE_NORMAL
- en: This is why it is critical that you keep your Kubernetes manifests and Helm
    charts in source control, and implement efficient deployment processes so that
    you can get your clusters back up and running quickly if you do have an issue
    with `etcd`. We will cover this more in [Chapter 14](ch14.html#continuous).
  prefs: []
  type: TYPE_NORMAL
- en: Best Practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Use a managed or turnkey service provider to run your control plane nodes with
    `etcd` clustering and backups. If you run them yourself, be very sure you know
    what you’re doing. Resilient `etcd` management is a specialist job, and the consequences
    of getting it wrong can be serious.
  prefs: []
  type: TYPE_NORMAL
- en: Backing Up Resource State
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Apart from `etcd` failures, there is also the question of saving the state of
    your individual resources. If you delete the wrong Deployment, for example, how
    would you re-create it?
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book we emphasize the value of the *infrastructure as code*
    paradigm, and recommend that you always manage your Kubernetes resources declaratively,
    by applying YAML manifests or Helm charts stored in version control.
  prefs: []
  type: TYPE_NORMAL
- en: In theory, then, to re-create the total state of your cluster workloads, you
    should be able to check out the relevant version control repos and apply all the
    resources in them. *In theory.*
  prefs: []
  type: TYPE_NORMAL
- en: Backing Up Cluster State
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, not everything you have in version control is running in your cluster
    right now. Some apps may have been taken out of service, or replaced by newer
    versions. Some may not be ready to deploy.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve recommended throughout this book that you should avoid making direct changes
    to resources, and instead apply changes from the updated manifest files (see [“When
    Not to Use Imperative Commands”](ch07.html#dontuseimperative)). However, people
    don’t always follow good advice.
  prefs: []
  type: TYPE_NORMAL
- en: In any case, it’s likely that during initial deployment and testing of apps,
    engineers may be adjusting settings like replica count and node affinities on
    the fly, and only storing them in version control once they’ve arrived at the
    right values.
  prefs: []
  type: TYPE_NORMAL
- en: Supposing your cluster were to be shut down completely, or have all its resources
    deleted (hopefully an unlikely scenario, but a useful thought experiment). How
    quickly could you re-create it?
  prefs: []
  type: TYPE_NORMAL
- en: Even if you have an admirably well-designed and up-to-date cluster automation
    system that can redeploy everything to a fresh cluster, how do you *know* that
    the state of this cluster matches the one that was lost?
  prefs: []
  type: TYPE_NORMAL
- en: One way to help ensure this is to make a snapshot of the running cluster, which
    you can refer to later in case of problems.
  prefs: []
  type: TYPE_NORMAL
- en: Large and Small Disasters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It’s not very likely that you’d lose the whole cluster: thousands of Kubernetes
    contributors have worked hard to make sure that doesn’t happen.'
  prefs: []
  type: TYPE_NORMAL
- en: What’s more likely is that you (or your newest team member) might delete a namespace
    by accident, shut down a Deployment without meaning to, or specify the wrong set
    of labels to a `kubectl delete` command, removing more than you intended.
  prefs: []
  type: TYPE_NORMAL
- en: Whatever the cause, disasters do happen, so let’s look at a backup tool that
    can help you avoid them.
  prefs: []
  type: TYPE_NORMAL
- en: Velero
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Velero](https://velero.io) (formerly known as Ark) is a free and open source
    tool that can back up and restore your cluster state and persistent data.'
  prefs: []
  type: TYPE_NORMAL
- en: Velero runs in your cluster and connects to a cloud storage service of your
    choice (for example, Amazon S3 or Azure Storage).
  prefs: []
  type: TYPE_NORMAL
- en: Go to the [velero.io website](https://velero.io/docs/main) for the instructions
    for setting up Velero on your platform.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Velero
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before you use Velero, you need to create a `BackupStorageLocation` object
    in your Kubernetes cluster, telling it where to store backups (for example, an
    AWS S3 cloud storage bucket). Here’s an example that configures Velero to back
    up to the `demo-backup` bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: You must have at least a storage location called `default`, though you can add
    others with any names you like.
  prefs: []
  type: TYPE_NORMAL
- en: 'Velero can also back up the contents of your persistent volumes. To tell it
    where to store them, you need to create a `VolumeSnapshotLocation` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Creating a Velero backup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you create a backup using the `velero backup` command, the Velero server
    queries the Kubernetes API to retrieve the resources matching the selector you
    provided (by default, it backs up all resources). You can back up a set of namespaces,
    or the whole cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It will then export all these resources to a named file in your cloud storage
    bucket, according to your configured BackupStorageLocation. The metadata and contents
    of your persistent volumes will also be backed up to your configured VolumeSnapshotLocation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, you can back up everything in your cluster *except* specified
    namespaces (for example, `kube-system`). You can also schedule automatic backups:
    for example, you can have Velero back up your cluster nightly, or even hourly.'
  prefs: []
  type: TYPE_NORMAL
- en: Each Velero backup is complete in itself, not an incremental backup. So, to
    restore a backup, you only need the most recent backup file.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can list your available backups using the `velero backup get` command.
    And to see what’s in a particular backup, use `velero backup download`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The downloaded file is a *tar.gz* archive that you can unpack and inspect using
    standard tools. If you only want the manifest for a specific resource, for example,
    you can extract it from the backup file and restore it individually with `kubectl
    apply -f`.
  prefs: []
  type: TYPE_NORMAL
- en: To restore the whole backup, the `velero restore` command will start the process,
    and Velero will re-create all the resources and volumes described in the specified
    snapshot, skipping anything that already exists.
  prefs: []
  type: TYPE_NORMAL
- en: If the resource *does* exist, but is different from the one in the backup, Velero
    will warn you, but not overwrite the existing resource. So, for example, if you
    want to reset the state of a running Deployment to the way it was in the most
    recent snapshot, delete the running Deployment first, then restore it with Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, if you’re restoring a backup of a namespace, you can delete the
    namespace first, and then restore the backup.
  prefs: []
  type: TYPE_NORMAL
- en: Restore procedures and tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You should write a detailed, step-by-step procedure describing how to restore
    data from backups, and make sure all staff know where to find this document. When
    a disaster happens, it’s usually at an inconvenient time, the key people aren’t
    available, everyone’s in a panic, and your procedure should be so clear and precise
    that it can be carried out by someone who isn’t familiar with Velero or even Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Each month, run a restore test by having a different team member execute the
    restore procedure against a temporary cluster. This verifies that your backups
    are good and that the restore procedure is correct, and makes sure everyone is
    familiar with how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling Velero backups
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'All backups should be automated, and Velero is no exception. You can schedule
    a regular backup using the `velero schedule create` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `schedule` argument specifies when to run the backup, in Unix `cron` format
    (see [“CronJobs”](ch09.html#cronjobs)). In the example, `0 1 * * *` runs the backup
    at 01:00 every day.
  prefs: []
  type: TYPE_NORMAL
- en: To see what backups you have scheduled, use `velero schedule get`.
  prefs: []
  type: TYPE_NORMAL
- en: Other uses for Velero
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While Velero is extremely useful for disaster recovery, you can also use it
    to migrate resources and data from one cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Making regular Velero backups can also help you understand how your Kubernetes
    usage is changing over time, comparing the current state to the state a month
    ago, six months ago, and a year ago, for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The snapshots can also be a useful source of audit information: for example,
    finding out what was running in your cluster at a given date or time, and how
    and when the cluster state changed.'
  prefs: []
  type: TYPE_NORMAL
- en: Best Practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use Velero to back up your cluster state and persistent data regularly: at
    least nightly. Run a restore test at least monthly.'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring Cluster Status
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitoring cloud native applications is a big topic, which, as we’ll see in
    [Chapter 15](ch15.html#observability), includes things like observability, metrics,
    logging, tracing, and traditional closed-box monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in this chapter, we’ll be concerned only with monitoring the Kubernetes
    cluster itself: the health of the cluster, the status of individual nodes, and
    the utilization of the cluster and the progress of its workloads.'
  prefs: []
  type: TYPE_NORMAL
- en: kubectl
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We introduced the invaluable `kubectl` command in [Chapter 2](ch02.html#firststeps),
    but we haven’t yet exhausted its possibilities. As well as being a general administration
    tool for Kubernetes resources, `kubectl` can also report useful information about
    the state of the cluster components.
  prefs: []
  type: TYPE_NORMAL
- en: Control plane status
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `kubectl get componentstatuses` command (or `kubectl get cs` for short)
    gives health information for the control plane components—the scheduler, the controller
    manager, and `etcd`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: If there were a serious problem with any of the control plane components, it
    would soon become apparent anyway, but it’s still handy to be able to check and
    report on them, as a sort of top-level health indicator for the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: If any of your control plane components is not in a `Healthy` state, it will
    need to be fixed. This should never be the case with a managed Kubernetes service,
    but for self-hosted clusters, you will have to take care of this yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Node status
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another useful command is `kubectl get nodes`, which will list all the nodes
    in your cluster, and report their status and Kubernetes version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Since Docker Desktop clusters only have one node, this output isn’t particularly
    informative; let’s look at the output from a small GKE cluster for something more
    realistic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Note that in the Docker Desktop `get nodes` output, the node *role* was shown
    as `control-plane`. Naturally enough, since there’s only one node, that must be
    the control plane and the lone worker node, too.
  prefs: []
  type: TYPE_NORMAL
- en: In managed Kubernetes services, you typically don’t have direct access to the
    control plane nodes. Accordingly, `kubectl get nodes` lists the worker nodes only.
  prefs: []
  type: TYPE_NORMAL
- en: If any of the nodes shows a status of `NotReady`, there is a problem. A reboot
    of the node may fix it, but if not, it may need further debugging—or you could
    just delete it and create a new node instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'For detailed troubleshooting of bad nodes, you can use the `kubectl describe
    node` command to get more information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This will show you, for example, the memory and CPU capacity of the node, and
    the resources currently in use by Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Workloads
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You may recall from [“Querying the Cluster with kubectl”](ch04.html#querykubectl)
    that you can also use `kubectl` to list all Pods (or any resources) in your cluster.
    In that example, you listed only the Pods in the default namespace, but the `--all-namespaces`
    flag (or just `-A` for short) will allow you to see all Pods in the entire cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This can give you a helpful overview of what’s running in your cluster, and
    any Pod-level problems. If any Pods are not in `Running` status, like the `permissions-auditor`
    Pod in the example, it may need further investigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `READY` column shows how many containers in the Pod are actually running,
    compared to the number configured. For example, the `metrics-api` Pod shows `3/3`:
    3 out of 3 containers are running, so all is well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, `permissions-auditor` shows `0/1` containers ready: 0 containers
    running, but 1 required. The reason is shown in the `STATUS` column: `CrashLoopBackOff`.
    The container is failing to start properly.'
  prefs: []
  type: TYPE_NORMAL
- en: When a container crashes, Kubernetes will keep trying to restart it at increasing
    intervals, starting at 10 seconds and doubling each time, up to 5 minutes. This
    strategy is called *exponential backoff*, hence the `CrashLoopBackOff` status
    message.
  prefs: []
  type: TYPE_NORMAL
- en: CPU and Memory Utilization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another useful view on your cluster is provided by the `kubectl top` command.
    For nodes, it will show you the CPU and memory capacity of each node, and how
    much of each is currently in use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'For Pods, it will show how much CPU and memory each specified Pod is using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Another useful tool for getting a wide look at the health of the cluster and
    Pods is to use [“Lens”](ch07.html#lens).
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Provider Console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you’re using a managed Kubernetes service that is offered by your cloud provider,
    then you will have access to a web-based console that can show you useful information
    about your cluster, its nodes, and workloads.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also list nodes, services, and configuration details for the cluster.
    This is much the same information as you can get from using the `kubectl` tool,
    but the cloud consoles also allow you to perform administration tasks: create
    clusters, upgrade nodes, and everything you’ll need to manage your cluster on
    a day-to-day basis.'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [Kubernetes Dashboard](https://oreil.ly/3ty9U) is a web-based user interface
    for Kubernetes clusters ([Figure 11-1](#img-dashboard-1)). If you’re running your
    own Kubernetes cluster, rather than using a managed service, you can run the Kubernetes
    Dashboard to get more or less the same information as a managed service console
    would provide.
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the Kubernetes Dashboard](assets/cnd2_1101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-1\. The Kubernetes Dashboard displays useful information about your
    cluster
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you’d expect, the Dashboard lets you see the status of your clusters, nodes,
    and workloads, in much the same way as the `kubectl` tool, but with a graphical
    interface. You can also create and destroy resources using the Dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Because the Dashboard exposes a great deal of information about your cluster
    and workloads, it’s very important to secure it properly, and never expose it
    to the public internet. The Dashboard lets you view the contents of ConfigMaps
    and Secrets, which could contain credentials and crypto keys, so you need to control
    access to the Dashboard as tightly as you would to those secrets themselves.
  prefs: []
  type: TYPE_NORMAL
- en: In 2018, security firm RedLock found [hundreds of Kubernetes Dashboard consoles](https://oreil.ly/3me4L)
    accessible over the internet without any password protection, including one owned
    by Tesla, Inc. From these they were able to extract cloud security credentials
    and use them to access further sensitive information.
  prefs: []
  type: TYPE_NORMAL
- en: Best Practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you don’t have to run the Kubernetes Dashboard (for example, if you already
    have a Kubernetes console provided by a managed service such as GKE), don’t run
    it. If you do run it, make sure it has [minimum privileges](https://oreil.ly/aCZ1e),
    and never expose it to the internet. Instead, access it via `kubectl proxy`.
  prefs: []
  type: TYPE_NORMAL
- en: Weave Scope
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Weave Scope](https://oreil.ly/01cLN) is a great visualization and monitoring
    tool for your cluster, showing you a real-time map of your nodes, containers,
    and processes. You can also see metrics and metadata, and even start or stop containers
    using Scope.'
  prefs: []
  type: TYPE_NORMAL
- en: kube-ops-view
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[kube-ops-view](https://oreil.ly/pmTGh) gives you a visualization of what’s
    happening in your cluster: what nodes there are, the CPU and memory utilization
    on each, how many Pods each one is running, and the status of those Pods. This
    is a great way to get a general overview of your cluster and what it’s doing.'
  prefs: []
  type: TYPE_NORMAL
- en: node-problem-detector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[node-problem-detector](https://oreil.ly/rE7Sl) is a Kubernetes add-on that
    can detect and report several kinds of node-level issues: hardware problems, such
    as CPU or memory errors, filesystem corruption, and wedged container runtimes.'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, node-problem-detector reports problems by sending events to the Kubernetes
    API, and comes with a Go client library that you can use to integrate with your
    own tools.
  prefs: []
  type: TYPE_NORMAL
- en: Although Kubernetes currently does not take any action in response to events
    from node-problem-detector, there may be further integration in the future that
    will allow the scheduler to avoid running Pods on problem nodes, for example.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes security and cluster management is a complex and specialized topic,
    and we’ve only scratched the surface of it here. It really deserves a book of
    its own… and there is one. Security experts Liz Rice and Michael Hausenblas have
    written the excellent [*Kubernetes Security*](https://www.oreilly.com/library/view/kubernetes-security/9781492039075/)
    (O’Reilly), covering secure cluster setup, container security, secrets management,
    and more.
  prefs: []
  type: TYPE_NORMAL
- en: Another great resource is [*Production Kubernetes*](https://www.oreilly.com/library/view/production-kubernetes/9781492092292//)
    (O’Reilly) by Josh Rosso, Rich Lander, Alex Brand, and John Harris. We recommend
    both books highly.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Security is not a product or an end goal, but an ongoing process that requires
    knowledge, thought, and attention. Container security is no different, and the
    machinery to help ensure it is there for you to use. If you’ve read and understood
    the information in this chapter, you know everything you need to know to configure
    your containers securely in Kubernetes—but we’re sure you get the point that this
    should be the start, not the end, of your security process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main things to keep in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: RBAC gives you fine-grained management of permissions in Kubernetes. Make sure
    it’s enabled, and use RBAC roles to grant specific users and apps only the minimum
    privileges they need to do their jobs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers aren’t magically exempt from security and malware problems. Use a
    scanning tool to check any containers that you run in production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Kubernetes does not mean that you don’t need backups. Use Velero to back
    up your data and the state of the cluster. It’s handy for moving things between
    clusters, too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubectl` is a powerful tool for inspecting and reporting on all aspects of
    your cluster and its workloads. Get friendly with `kubectl`. You’ll be spending
    a lot of time together.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use your Kubernetes provider’s web console and `kube-ops-view` for a graphical
    overview of what’s going on. If you use the Kubernetes Dashboard, secure it as
    tightly as you would your cloud credentials and crypto keys.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ^([1](ch11.html#idm45979378784352-marker)) See “The Junior Dev Who Deleted the
    Production Database,” 10 Jun 2017, by David Cassel, on [thenewstack.io blog](https://thenewstack.io).
  prefs: []
  type: TYPE_NORMAL
