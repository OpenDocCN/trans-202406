<html><head></head><body><section data-pdf-bookmark="Chapter 13. Development Workflow" data-type="chapter" epub:type="chapter"><div class="chapter" id="workflow">&#13;
<h1><span class="label">Chapter 13. </span>Development Workflow</h1>&#13;
&#13;
<blockquote class="epigraph">&#13;
<p>Surfing is such an amazing concept. You’re taking on Nature with a little stick and saying, <em>I’m gonna ride you!</em> And a lot of times Nature says, <em>No you’re not!</em> and crashes you to the bottom.</p>&#13;
<p data-type="attribution">Jolene Blalock</p>&#13;
</blockquote>&#13;
&#13;
<p><a data-primary="Kubernetes" data-secondary="development workflow" data-type="indexterm" id="ix_13-workflow-adoc0"/>In this chapter, we’ll expand on the discussion in <a data-type="xref" href="ch12.html#deploying">Chapter 12</a>, turning our attention to the whole application life cycle, from local development to deploying updates to a Kubernetes cluster, including the tricky topic of database migrations. We’ll cover some tools that help you develop, test, and deploy your applications, including Skaffold and Telepresence. We will also introduce Knative and OpenFaaS, two options for running “serverless” architectures on your clusters. We’ll also look at more complex deployments, and ordering application rollouts using Helm hooks.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Development Tools" data-type="sect1"><div class="sect1" id="idm45979376436064">&#13;
<h1>Development Tools</h1>&#13;
&#13;
<p><a data-primary="development workflow" data-secondary="development tools" data-type="indexterm" id="ix_13-workflow-adoc1"/>In <a data-type="xref" href="ch12.html#deploying">Chapter 12</a>, we looked at some tools to help you write, build, and deploy your Kubernetes resource manifests. That’s fine as far as it goes, but often when you’re developing an application that runs in Kubernetes, you want to be able to try things out and see changes instantly, without going through a full build-push-deploy-update loop.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Skaffold" data-type="sect2"><div class="sect2" id="idm45979376432032">&#13;
<h2>Skaffold</h2>&#13;
&#13;
<p><a data-primary="Skaffold" data-type="indexterm" id="idm45979376430528"/><a href="https://oreil.ly/UTaRj">Skaffold</a> is an open source tool from Google designed to provide a fast local development workflow. It automatically rebuilds your containers as you develop locally, and deploys those changes to either a local or remote cluster.</p>&#13;
&#13;
<p>You define your desired workflow in a <em>skaffold.yaml</em> file in your repository and run the <code>skaffold</code> command-line tool to start the pipeline. As you make changes to files in your local directory, Skaffold wakes up, builds a new container with the changes, and then deploys it for you automatically, saving you a round trip to the container.</p>&#13;
&#13;
<p>We have a Skaffold example in the <a href="https://oreil.ly/LAI8f">demo repo</a> to show how it works. Follow the Skaffold <a href="https://oreil.ly/heDih">installation instructions</a> for your operating system, point your <code>kubectl</code> at your local development Kubernetes cluster, and switch to the <em>hello-skaffold</em> directory to see how it works:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><strong><code class="go">cd hello-skaffold</code></strong><code class="go">&#13;
</code><strong><code class="go">skaffold dev</code></strong><code class="go">&#13;
</code><code class="go">Listing files to watch...&#13;
</code><code class="go"> - skaffold-demo&#13;
</code><code class="go">Generating tags...&#13;
</code><code class="go"> - skaffold-demo -&gt; skaffold-demo:e50c9e7-dirty&#13;
</code><code class="go">Checking cache...&#13;
</code><code class="go"> - skaffold-demo: Found Locally&#13;
</code><code class="go">Tags used in deployment:&#13;
</code><code class="go"> - skaffold-demo -&gt; skaffold-demo:39f0eb63b0ced173...&#13;
</code><code class="go">Starting deploy...&#13;
</code><code class="go">Helm release demo not installed. Installing...&#13;
</code><code class="go">NAME: demo&#13;
</code><code class="go">NAMESPACE: demo&#13;
</code><code class="go">STATUS: deployed&#13;
</code><code class="go">REVISION: 1&#13;
</code><code class="go">TEST SUITE: None&#13;
</code><code class="go">Waiting for deployments to stabilize...&#13;
</code><code class="go"> - demo:deployment/demo is ready.&#13;
</code><code class="go">Deployments stabilized in 1.097 second&#13;
</code><code class="go">Press Ctrl+C to exit&#13;
</code><code class="go">Watching for changes...&#13;
</code><code class="go">...</code></pre>&#13;
&#13;
<p>Skaffold automatically built and deployed the demo application using Helm and is now watching for changes to the code or the chart. It uses a randomly generated SHA as a temporary placeholder container tag as you are doing development. If you <code>curl localhost:8888</code> you should see <code>Hello, skaffold!</code>, because that is what is set in the <code>main.go</code> for this example. Leave Skaffold running and go change that <em>main.go</em> file to say something else, like <code>Hola, skaffold!</code>. As soon as you save your changes, Skaffold will automatically rebuild and redeploy the updated copy of the app:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="go">...</code>&#13;
<code class="go">Watching for changes...</code>&#13;
<code class="go">Tags used in deployment:</code>&#13;
<code class="go"> - skaffold-demo -&gt; skaffold-demo:39f0eb63b0ced173...</code>&#13;
<code class="go">Starting deploy...</code>&#13;
<code class="go">Release "demo" has been upgraded. Happy Helming!</code>&#13;
<code class="go">NAME: demo</code>&#13;
<code class="go">NAMESPACE: demo</code>&#13;
<code class="go">STATUS: deployed</code>&#13;
<code class="go">REVISION: 2</code>&#13;
<code class="go">TEST SUITE: None</code>&#13;
<code class="go">Waiting for deployments to stabilize...</code>&#13;
<code class="go"> - demo:deployment/demo is ready.</code>&#13;
<code class="go">Deployments stabilized in 1.066 second</code>&#13;
<code class="go">Watching for changes...</code></pre>&#13;
&#13;
<p>Now if you <code>curl localhost:8888</code>, you’ll see your modified code running. Skaffold built a new copy of the demo container and released a new version to your cluster using Helm. Keep making changes with Skaffold running, and it will continue updating the application automatically. When you’ve had enough fun, you can stop Skaffold with <code>Ctrl+C</code> and it will automatically uninstall the demo app:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="go">Cleaning up...</code>&#13;
<code class="go">release "demo" uninstalled</code></pre>&#13;
&#13;
<p>You can use Skaffold for other types of builds, such as Bazel, or using your own custom-build scripts. It supports using <a href="https://cloud.google.com/build">Google Cloud Build</a> as a remote image builder, rather than using your local machine. You can also incorporate your test suite into the workflow and automatically run through your tests as part of the build and deploy process.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Telepresence" data-type="sect2"><div class="sect2" id="idm45979376431440">&#13;
<h2>Telepresence</h2>&#13;
&#13;
<p><a data-primary="Telepresence" data-type="indexterm" id="idm45979376345536"/><a href="https://www.telepresence.io">Telepresence</a> takes a slightly different approach from Skaffold. You don’t need a local Kubernetes cluster; a Telepresence Pod runs in your real cluster as a placeholder for your application. Traffic for the application Pod is then intercepted and routed to the container running on your local machine.</p>&#13;
&#13;
<p>This enables the developer to make their local machine participate in the remote cluster. As they make changes to application code, they will be reflected in the live cluster, without a new container having to be deployed to it. If your application has a particularly long build time, this may be an appealing tool to try.</p>&#13;
&#13;
<p>One common complaint about developing applications in containers is that a new container needs to be built containing the new code changes, and this can be a frustrating experience if the rebuild is slow. Telepresence aims to ease this frustration and speed up the local development process while still using containers and Kubernetes so that the runtime environment between local development and what is deployed in production does not need to be entirely different.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Waypoint" data-type="sect2"><div class="sect2" id="idm45979376343280">&#13;
<h2>Waypoint</h2>&#13;
&#13;
<p><a data-primary="Waypoint" data-type="indexterm" id="idm45979376342176"/>HashiCorp, the developers behind popular tools like Vault, Terraform, and Consul, have built a new tool focused on simplifying the end-to-end application development experience. <a href="https://www.waypointproject.io">Waypoint</a> introduces a declarative <em>waypoint.hcl</em> file that allows you to define the build, deploy, config, and release steps for your application regardless of the runtime or platform it uses. Using a standard wrapper like Waypoint means that your CI/CD tooling and processes can be standardized, even if your applications use different build and deploy steps. Developers can check out an application repository, run <code>waypoint build</code>—while not having to consider if this particular application uses a Dockerfile or something like a <a href="https://buildpacks.io">CloudNative Buildpack</a>—and expect to end up with the correct artifact for running the application. Similarly, <code>waypoint deploy</code> abstracts away whether this particular application uses Kubernetes, Helm, or maybe it runs as an AWS Lambda function. Having a standard CLI experience for developers and the CI/CD tooling can greatly simplify how the build and deployment process works across different types of applications.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Knative" data-type="sect2"><div class="sect2" id="knative">&#13;
<h2>Knative</h2>&#13;
&#13;
<p><a data-primary="Knative" data-type="indexterm" id="idm45979376336736"/>While the other tools we’ve looked at are focused on speeding up the local development loop, <a href="https://oreil.ly/SXohX">Knative</a> is more ambitious. It aims to provide a standard mechanism for deploying all kinds of workloads to Kubernetes: not just containerized applications, but <em>serverless</em>-style functions too.</p>&#13;
&#13;
<p>Knative integrates with both Kubernetes and Istio (see <a data-type="xref" href="ch09.html#istio">“Istio”</a>) to provide a complete application/function deployment platform, including setting up a build process, automated deployment, and an <em>eventing</em> mechanism that standardizes the way applications use messaging and queueing systems (for example, Pub/Sub, Kafka, or RabbitMQ).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="OpenFaaS" data-type="sect2"><div class="sect2" id="openfaas">&#13;
<h2>OpenFaaS</h2>&#13;
&#13;
<p><a data-primary="OpenFaaS" data-type="indexterm" id="idm45979376287280"/><a href="https://www.openfaas.com">OpenFaas</a> is another project that makes it possible to run serverless functions on Kubernetes. It includes a CLI tool for building and deploying functions to your clusters, and can trigger on HTTP events, a cron schedule, MQTT, Kafka, and RabbitMQ messages, and other popular event-driven systems and message queues. These serverless types of architectures work well with the microservice mindset and can lead to more efficient usage of your servers.</p>&#13;
&#13;
<p><a data-primary="arkade" data-type="indexterm" id="idm45979376285792"/>An interesting side project from the folks working on OpenFaaS is called <a href="https://oreil.ly/XBbiD"><em>arkade</em></a>, which works sort of like an App Store or marketplace for installing popular cloud native tools (like OpenFaaS itself) with one unified tool. With one <code>arkade</code> command you can install OpenFaaS on your Kubernetes cluster and start deploying your serverless workloads.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Crossplane" data-type="sect2"><div class="sect2" id="idm45979376283408">&#13;
<h2>Crossplane</h2>&#13;
&#13;
<p><a data-primary="Crossplane" data-type="indexterm" id="ix_13-workflow-adoc2"/><a href="https://crossplane.io">Crossplane</a> is a tool that aims to bring the standardization of Kubernetes to non-Kubernetes cloud resources. Many applications require pieces of infrastructure that live outside of Kubernetes, such as an AWS S3 bucket, an RDS database instance, or an Azure Cosmos DB instance. Often this means that developers end up using tools like <a href="https://www.terraform.io">Terraform</a> to deploy these external dependencies first, and then switch to deploying the application using Dockerfiles, Kubernetes manifests, and Helm charts.</p>&#13;
&#13;
<p><a data-primary="CRDs (custom resource definitions)" data-type="indexterm" id="idm45979376279280"/><a data-primary="Custom Resource Definitions (CRDs)" data-type="indexterm" id="idm45979376278608"/>Crossplane uses CRDs (see <a data-type="xref" href="ch09.html#crds">“Operators and Custom Resource Definitions (CRDs)”</a>) to define these types of infrastructure that live outside of Kubernetes as if they were native Kubernetes objects. It uses the APIs of the cloud providers to actually create and deploy these cloud resources, much like you would using the Terraform CLI or your cloud provider’s CLI and SDK tools. Imagine that you could declare a PostgreSQL RDS instance that your application requires to run like this:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">apiextensions.crossplane.io/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Composition</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">xpostgresqlinstances.aws.database.example.org</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">labels</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">provider</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">aws</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">vpc</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">default</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">writeConnectionSecretsToNamespace</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">crossplane-system</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">compositeTypeRef</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">database.example.org/v1alpha1</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">XPostgreSQLInstance</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">resources</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">rdsinstance</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">base</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">database.aws.crossplane.io/v1beta1</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">RDSInstance</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">          </code><code class="nt">forProvider</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">region</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">us-east-1</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">dbInstanceClass</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">db.t2.small</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">masterUsername</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">postgres-admin</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">engine</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">postgres</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">engineVersion</code><code class="p">:</code><code class="w"> </code><code class="s">"12"</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">skipFinalSnapshotBeforeDeletion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">true</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">publiclyAccessible</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">false</code><code class="w"/>&#13;
<code class="w">          </code><code class="nt">writeConnectionSecretToRef</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">namespace</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">crossplane-system</code><code class="w"/>&#13;
<code class="nn">...</code><code class="w"/></pre>&#13;
&#13;
<p>Now you can bundle this manifest for your application’s RDS instance alongside of your other Kubernetes manifests and deploy them together. The Kubernetes reconciliation loop will then ensure that this RDS instance is provisioned, just as it does for your application Pods. Another benefit here is when the infrastructure is managed and deployed together with the application, you can easily pass configuration between them. For example, the Crossplane CRD can automatically create a Kubernetes Secret for the password when it creates the database, and pass it to your application to use to connect. We expect that as Kubernetes continues to gain widespread adoption that this sort of extending the use of Kubernetes for managing other types of infrastructure will become popular<a data-startref="ix_13-workflow-adoc2" data-type="indexterm" id="idm45979376225776"/>.<a data-startref="ix_13-workflow-adoc1" data-type="indexterm" id="idm45979376225040"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deployment Strategies" data-type="sect1"><div class="sect1" id="deploymentstrategies">&#13;
<h1>Deployment Strategies</h1>&#13;
&#13;
<p><a data-primary="deployments" data-secondary="strategies for" data-type="indexterm" id="ix_13-workflow-adoc3"/><a data-primary="development workflow" data-secondary="deployment strategies" data-type="indexterm" id="ix_13-workflow-adoc4"/>If you were upgrading a running application by hand, without Kubernetes, one way to do it would be to just shut down the application, install the new version, and restart it. But that means downtime.</p>&#13;
&#13;
<p><a data-primary="deployments" data-secondary="zero-downtime" data-type="indexterm" id="idm45979376096800"/>If you had multiple instances of your application spread across several servers, a better way would be to upgrade each one in turn so that there would be no interruption in service: a so-called <em>zero-downtime deployment</em>.</p>&#13;
&#13;
<p>Not all applications need zero downtime. Internal services that consume message queues, for example, are idempotent, so they can be upgraded all at once. This means the upgrade happens faster, but for user-facing applications, we are usually more concerned with avoiding downtime than achieving quick upgrades.</p>&#13;
&#13;
<p>In Kubernetes, you can choose whichever of these strategies is most appropriate. <code>RollingUpdate</code> is the zero-downtime, Pod-by-Pod option, while <code>Recreate</code> is the fast, all-Pods-at-once option. There are also some fields that you can tweak to get the exact behavior that you need for your application.</p>&#13;
&#13;
<p>In Kubernetes, an application’s deployment strategy is defined in the Deployment manifest. The default is <code>RollingUpdate</code>, so if you don’t specify a strategy, this is what you’ll get. To change the strategy to <code>Recreate</code>, set it like this:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">apps/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Deployment</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">replicas</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">1</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">strategy</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Recreate</code><code class="w"/></pre>&#13;
&#13;
<p>Now let’s look more closely at these deployment strategies and see how they work.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Rolling Updates" data-type="sect2"><div class="sect2" id="rollingupdate">&#13;
<h2>Rolling Updates</h2>&#13;
&#13;
<p><a data-primary="rolling updates" data-type="indexterm" id="idm45979376036368"/>In a rolling update, Pods are upgraded one at a time, until all replicas have been replaced with the new version.</p>&#13;
&#13;
<p>For example, imagine we’re running an application with three replicas, each running <code>v1</code>. The developer starts an upgrade to <code>v2</code> with a <code>kubectl apply...</code> or <code>helm upgrade...</code> command. What happens?</p>&#13;
&#13;
<p>First, one of the three <code>v1</code> Pods will be terminated. Kubernetes will flag it as unready, and stop sending it traffic. A new <code>v2</code> Pod will be spun up to take its place. Meanwhile, the remaining <code>v1</code> Pods continue receiving incoming requests. While we’re waiting for the first <code>v2</code> Pod to become ready, we’re down to two Pods, but we’re still serving users.</p>&#13;
&#13;
<p>When the <code>v2</code> Pod becomes ready, Kubernetes will start sending it user traffic, alongside the other two <code>v1</code> Pods. Now we’re back to our full complement of three Pods.</p>&#13;
&#13;
<p>This process will continue, Pod by Pod, until all of the <code>v1</code> Pods have been replaced with <code>v2</code> Pods. While there are times when fewer Pods than usual are available to handle traffic, the application as a whole is never actually down. That’s zero-downtime deployment.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>During a rolling update, both old and new versions of your application will be in service at the same time. While this usually isn’t a problem, you may need to take steps to ensure that this is safe; if your changes involve a database migration, for example (see <a data-type="xref" href="#helm-db-migrate">“Handling Migrations with Helm”</a>), a normal rolling update won’t be possible.</p>&#13;
</div>&#13;
&#13;
<p>If your Pods can sometimes crash or fail after a short time in a ready state, use the <code>minReadySeconds</code> field to have the rollout wait until each Pod is stable (see <a data-type="xref" href="ch05.html#minreadyseconds">“minReadySeconds”</a>).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Recreate" data-type="sect2"><div class="sect2" id="idm45979376001008">&#13;
<h2>Recreate</h2>&#13;
&#13;
<p><a data-primary="Recreate" data-type="indexterm" id="idm45979376000112"/>In <code>Recreate</code> mode, all running replicas are terminated at once, and then new ones are created.</p>&#13;
&#13;
<p>For applications that do not directly handle requests, this should be acceptable. One advantage of <code>Recreate</code> is that it avoids the situation where two different versions of the application are running simultaneously (see <a data-type="xref" href="#rollingupdate">“Rolling Updates”</a>).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="maxSurge and maxUnavailable" data-type="sect2"><div class="sect2" id="idm45979375996704">&#13;
<h2>maxSurge and maxUnavailable</h2>&#13;
&#13;
<p><a data-primary="maxSurge" data-type="indexterm" id="idm45979375995360"/><a data-primary="maxUnavailable" data-type="indexterm" id="idm45979375994656"/>As a rolling update progresses, sometimes you will have more Pods running than the nominal <code>replicas</code> value, and sometimes less. Two important settings govern this behavior: <code>maxSurge</code> and <code>maxUnavailable</code>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>maxSurge</code> sets the maximum number of excess Pods. For example, if you have 10 replicas and you set <code>maxSurge</code> to 30%, then no more than 13 Pods will be allowed to run at any one time.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>maxUnavailable</code> sets the maximum number of unavailable Pods. With a nominal 10 replicas and <code>maxUnavailable</code> of 20%, Kubernetes will never let the number of available Pods drop below 8.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>These can be set as either a whole number, or as a percentage:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">apps/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Deployment</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">replicas</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">10</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">strategy</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">RollingUpdate</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">rollingUpdate</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">maxSurge</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">20%</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">maxUnavailable</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">3</code><code class="w"/></pre>&#13;
&#13;
<p>Usually, the default value of <code>25%</code> for both settings is fine, and you probably won’t need to adjust these, but depending on your load requirements you may need to tweak them to make sure your application can maintain acceptable capacity during an upgrade. At very large scale, you may find that running at 75% availability during a deployment is not sufficient to handle your incoming traffic, and you’ll need to reduce <code>maxUnavailable</code> slightly.</p>&#13;
&#13;
<p>The bigger the value of <code>maxSurge</code>, the faster your rollout but the more load it places on your cluster’s resources. Large values of <code>maxUnavailable</code> also speed up rollouts, at the expense of your application’s capacity.</p>&#13;
&#13;
<p>On the other hand, small values of <code>maxSurge</code> and <code>maxUnavailable</code> reduce the impact on your cluster and your users, but can make your rollouts take much longer. Only you can decide what the right trade-off is for your application.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Blue/Green Deployments" data-type="sect2"><div class="sect2" id="bluegreen">&#13;
<h2>Blue/Green Deployments</h2>&#13;
&#13;
<p><a data-primary="deployments" data-secondary="blue/green" data-type="indexterm" id="idm45979375947568"/>In a <em>blue/green</em> deployment, rather than killing and replacing Pods one at a time, a whole new Deployment is created, and a new separate stack of Pods running <code>v2</code> is launched beside the existing <code>v1</code> Deployment.</p>&#13;
&#13;
<p>One advantage of this is that you don’t have to deal with both old and new versions of the application processing requests simultaneously. On the other hand, your cluster will need to be big enough to run twice the number of replicas required for your application, which can be expensive, and means a lot of unused capacity sitting around most of the time (unless you scale the cluster up and down as needed).</p>&#13;
&#13;
<p>We learned in <a data-type="xref" href="ch04.html#services">“Service Resources”</a> that Kubernetes uses labels to decide which Pods should receive traffic from a Service. One way to implement a blue/green deployment is to set different labels on your old and new Pods (see <a data-type="xref" href="ch09.html#labels">“Labels”</a>).</p>&#13;
&#13;
<p>With a small tweak to the Service definition for our example application, you can send traffic to only Pods labeled <code>deployment: blue</code>:</p>&#13;
&#13;
<pre class="less_space pagebreak-before" data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w">&#13;
</code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Service</code><code class="w">&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="nt">spec</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">ports</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">port</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">8080</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">protocol</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">TCP</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">targetPort</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">8080</code><code class="w">&#13;
</code><code class="w">  </code><code class="nt">selector</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">    </code><code class="nt">app</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">demo</code><code class="w">&#13;
</code><code class="w">    </code><strong><code class="nt">deployment</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">blue</code></strong><code class="w">&#13;
</code><code class="w">  </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">ClusterIP</code></pre>&#13;
&#13;
<p>When deploying a new version, you can label it <code>deployment: green</code>. It won’t receive any traffic, even when it’s fully up and running, because the Service only sends traffic to <code>blue</code> Pods. You can test it and make sure it’s ready before making the cutover.</p>&#13;
&#13;
<p>To switch over to the new <code>Deployment</code>, edit the <code>Service</code> to change the selector to <code>deployment: green</code>. Now the new <code>green</code> Pods will start receiving traffic, and once all the old <code>blue</code> Pods are idle, you can shut them down.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Rainbow Deployments" data-type="sect2"><div class="sect2" id="idm45979375845744">&#13;
<h2>Rainbow Deployments</h2>&#13;
&#13;
<p><a data-primary="deployments" data-secondary="rainbow" data-type="indexterm" id="idm45979375844656"/>In some rare cases, particularly when Pods have very long-lived connections (websockets, for example), just blue and green may not be enough. You may need to maintain three or more versions of your application in flight at the same time.</p>&#13;
&#13;
<p>This is sometimes referred to as a <em>rainbow deployment</em>. Every time you deploy an update, you get a new color set of Pods. As connections finally drain from your oldest set of Pods, they can be shut down.</p>&#13;
&#13;
<p>Brandon Dimcheff describes a <a href="https://oreil.ly/fuFoi">rainbow deployment example</a> in detail.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Canary Deployments" data-type="sect2"><div class="sect2" id="canary">&#13;
<h2>Canary Deployments</h2>&#13;
&#13;
<p><a data-primary="deployments" data-secondary="canary" data-type="indexterm" id="idm45979375801808"/>The advantage of blue/green (or rainbow) deployments is that if you decide you don’t like the new version, or it isn’t behaving correctly, you can simply switch back to the old version, which is still running. However, it is expensive because you need the cluster capacity to run both versions simultaneously, which means you may need to run more nodes.</p>&#13;
&#13;
<p>One alternative approach that avoids this problem is a <em>canary deployment</em>. Like a canary in a coal mine, a small handful of new Pods are exposed to the dangerous world of production to see what happens to them. If they survive, the rollout can continue to completion. If there <em>is</em> a problem, the blast radius is strictly limited.</p>&#13;
&#13;
<p>Just as with blue/green deployments, you can do this using labels (see <a data-type="xref" href="ch09.html#labels">“Labels”</a>). There is a detailed example of running a canary deployment in the Kubernetes <a href="https://oreil.ly/PqUe0">documentation</a>.</p>&#13;
&#13;
<p>A more sophisticated way to do this is to use a service mesh such as Istio, Linkerd, or one of the other tools we mention in <a data-type="xref" href="ch09.html#service-mesh">“Service Mesh”</a>, which allows you to randomly route a variable proportion of traffic to one or more service versions. This also makes it easy to do things like A/B testing.<a data-startref="ix_13-workflow-adoc4" data-type="indexterm" id="idm45979375796592"/><a data-startref="ix_13-workflow-adoc3" data-type="indexterm" id="idm45979375795920"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Handling Migrations with Helm" data-type="sect1"><div class="sect1" id="helm-db-migrate">&#13;
<h1>Handling Migrations with Helm</h1>&#13;
&#13;
<p><a data-primary="development workflow" data-secondary="handling migrations with Helm" data-type="indexterm" id="ix_13-workflow-adoc5"/><a data-primary="migrations" data-type="indexterm" id="ix_13-workflow-adoc6"/>Stateless applications are easy to deploy and upgrade, but when a database is involved the situation can be more complicated. Changes to the schema of a database usually require a <em>migration</em> task to be run before the new version of the application is running. For example, with Rails apps, you need to run <code>rails db:migrate</code> before starting the new application Pods.</p>&#13;
&#13;
<p>On Kubernetes, you can use a Job resource to do this (see <a data-type="xref" href="ch09.html#jobs">“Jobs”</a>). Another option would be to use an <code>initContainer</code> (see <a data-type="xref" href="ch08.html#init-containers">“Init Containers”</a>). You could also script this using <code>kubectl</code> commands as part of your deploy process, or if you are using Helm, then you can use a built-in feature called <em>hooks</em>.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Helm Hooks" data-type="sect2"><div class="sect2" id="helmhooks">&#13;
<h2>Helm Hooks</h2>&#13;
&#13;
<p><a data-primary="Helm" data-secondary="hooks" data-type="indexterm" id="ix_13-workflow-adoc7"/><a data-primary="hooks" data-type="indexterm" id="ix_13-workflow-adoc8"/>Helm hooks allow you to control the order in which things happen during a deployment. They also let you bail out of an upgrade if things go wrong.</p>&#13;
&#13;
<p>Here is an example of a database migration Job for a Rails application deployed with Helm:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">batch/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Job</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{{</code><code class="w"> </code><code class="nv">.Values.appName</code><code class="w"> </code><code class="p-Indicator">}}</code><code class="l-Scalar-Plain">-db-migrate</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">annotations</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="s">"helm.sh/hook"</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">pre-upgrade</code><code class="w"/>&#13;
<code class="w">    </code><code class="s">"helm.sh/hook-delete-policy"</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">hook-succeeded</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">activeDeadlineSeconds</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">60</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">template</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{{</code><code class="w"> </code><code class="nv">.Values.appName</code><code class="w"> </code><code class="p-Indicator">}}</code><code class="l-Scalar-Plain">-db-migrate</code><code class="w"/>&#13;
<code class="w">  </code><code class="w-Error">  </code><code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">restartPolicy</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Never</code><code class="w"/>&#13;
<code class="w">      </code><code class="nt">containers</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{{</code><code class="w"> </code><code class="nv">.Values.appName</code><code class="w"> </code><code class="p-Indicator">}}</code><code class="l-Scalar-Plain">-migration-job</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{{</code><code class="w"> </code><code class="nv">.Values.image.repository</code><code class="w"> </code><code class="p-Indicator">}}</code><code class="l-Scalar-Plain">:{{ .Values.image.tag }}</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">command</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">          </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">rails</code><code class="w"/>&#13;
<code class="w">          </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">db:migrate</code><code class="w"/></pre>&#13;
&#13;
<p><a data-primary="helm.sh/hook" data-type="indexterm" id="idm45979375729200"/>The <code>helm.sh/hook</code> properties are defined in the <code>annotations</code> section:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">annotations</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="s">"helm.sh/hook"</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">pre-upgrade</code><code class="w"/>&#13;
<code class="w">  </code><code class="s">"helm.sh/hook-delete-policy"</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">hook-succeeded</code><code class="w"/></pre>&#13;
&#13;
<p>The <code>pre-upgrade</code> setting tells Helm to apply this Job manifest before doing an upgrade. The Job will run the standard Rails migration command.</p>&#13;
&#13;
<p><a data-primary="helm.sh/hook-delete-policy" data-type="indexterm" id="idm45979375597648"/>The <code>"helm.sh/hook-delete-policy": hook-succeeded</code> tells Helm to delete the Job if it completes successfully (that is, exits with status 0).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Handling Failed Hooks" data-type="sect2"><div class="sect2" id="idm45979375596256">&#13;
<h2>Handling Failed Hooks</h2>&#13;
&#13;
<p>If the Job returns a nonzero exit code, this is a sign that there was an error and the migration did not complete successfully. Helm will leave the Job in place in its failed state so that you can debug what went wrong.</p>&#13;
&#13;
<p>If this happens, the release process will stop, and the application will not be upgraded. Running <code>kubectl get pods</code> will show you the failed Pod, allowing you to inspect the logs and see what happened.</p>&#13;
&#13;
<p>Once the issue has been resolved, you can delete the failed job (<code>kubectl delete job &lt;job-name&gt;</code>) and then try the upgrade again. Another option for automatically cleaning up a failed job would be to add the <code>ttlSecondsAfterFinished</code> field that we cover in <a data-type="xref" href="ch05.html#job-ttl">“Cleaning up completed Jobs”</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Other Hooks" data-type="sect2"><div class="sect2" id="idm45979375591552">&#13;
<h2>Other Hooks</h2>&#13;
&#13;
<p>Hooks have phases other than just <code>pre-upgrade</code>. You can use a hook at any of the following stages of a release:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>pre-install</code> executes after templates are rendered, but before any resources are created.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>post-install</code> executes after all resources are loaded.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>pre-delete</code> executes on a deletion request before any resources are deleted.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>post-delete</code> executes on a deletion request after all of the release’s resources have been deleted.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>pre-upgrade</code> executes on an upgrade request after templates are rendered, but before any resources are loaded (for example, before a <code>kubectl apply</code> <span class="keep-together">operation).</span></p>&#13;
</li>&#13;
<li>&#13;
<p><code>post-upgrade</code> executes on an upgrade after all resources have been upgraded.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>pre-rollback</code> executes on a rollback request after templates are rendered, but before any resources have been rolled back.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>post-rollback</code> executes on a rollback request after all resources have been <span class="keep-together">modified.</span></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Chaining Hooks" data-type="sect2"><div class="sect2" id="idm45979375562032">&#13;
<h2>Chaining Hooks</h2>&#13;
&#13;
<p><a data-primary="helm.sh/hook-weight" data-type="indexterm" id="idm45979375560784"/><a data-primary="weights" data-secondary="helm.sh/hook-weight property" data-type="indexterm" id="idm45979375559952"/>Helm hooks also come with the ability to chain them together in a specific order, using the <code>helm.sh/hook-weight</code> property. The hooks will be run in order from lowest to highest, so a Job with a <code>hook-weight</code> of 0 will run before one with a <code>hook-weight</code> of <code>1</code>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">batch/v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Job</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="p-Indicator">{{</code><code class="w"> </code><code class="nv">.Values.appName</code><code class="w"> </code><code class="p-Indicator">}}</code><code class="l-Scalar-Plain">-stage-0</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">annotations</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">    </code><code class="s">"helm.sh/hook"</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">pre-upgrade</code><code class="w"/>&#13;
<code class="w">    </code><code class="s">"helm.sh/hook-delete-policy"</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">hook-succeeded</code><code class="w"/>&#13;
<code class="w">    </code><code class="s">"helm.sh/hook-weight"</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">0</code><code class="w"/></pre>&#13;
&#13;
<p>You can find everything you need to know about hooks in the Helm <a href="https://oreil.ly/NHKvD">documentation</a>.</p>&#13;
&#13;
<p>Another way to implement more complex deployment situations is by using Kubernetes <code>Operators</code>. These allow you to build your own custom set of tasks tailored to your use-cases, including any special logic or custom steps that need to happen as part of deploying new versions of your applications. A common example where using an <code>Operator</code> makes good sense is for upgrading databases, which often require additional maintenance or preparation tasks as part of upgrading to a new version<a data-startref="ix_13-workflow-adoc8" data-type="indexterm" id="idm45979375547216"/><a data-startref="ix_13-workflow-adoc7" data-type="indexterm" id="idm45979375535952"/>.<a data-startref="ix_13-workflow-adoc6" data-type="indexterm" id="idm45979375535184"/><a data-startref="ix_13-workflow-adoc5" data-type="indexterm" id="idm45979375534480"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45979375533680">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Developing Kubernetes applications can be tedious if you have to build, push, and deploy a container image to test every little code change. Tools like Skaffold and Telepresence make this loop much faster, speeding up development.</p>&#13;
&#13;
<p>In particular, rolling out changes to production is far easier with Kubernetes than with traditional servers, provided you understand the basic concepts, and how you can customize them to suit your application:</p>&#13;
&#13;
<ul class="less_space pagebreak-before">&#13;
<li>&#13;
<p>The default <code>RollingUpdate</code> deployment strategy in Kubernetes upgrades a few Pods at a time, waiting for each replacement Pod to become ready before shutting down the old one.</p>&#13;
</li>&#13;
<li>&#13;
<p>Rolling updates avoid downtime at the expense of making the rollout take longer. It also means that both old and new versions of your application will be running simultaneously during the rollout period.</p>&#13;
</li>&#13;
<li>&#13;
<p>You can adjust the <code>maxSurge</code> and <code>maxUnavailable</code> fields to fine tune rolling updates. Depending on the versions of the Kubernetes API you are using, the defaults may or may not be appropriate for your situation.</p>&#13;
</li>&#13;
<li>&#13;
<p>The <code>Recreate</code> strategy just blows away all the old Pods and starts up new ones all at once. This is fast, but results in downtime, so it’s not suitable for user-facing applications.</p>&#13;
</li>&#13;
<li>&#13;
<p>In a blue/green deployment, all the new Pods are started up and made ready without receiving any user traffic. Then all traffic is switched over to the new Pods in one go, before retiring the old Pods.</p>&#13;
</li>&#13;
<li>&#13;
<p>Rainbow deployments are similar to blue/green deployments, but with more than two versions in service simultaneously.</p>&#13;
</li>&#13;
<li>&#13;
<p>You can implement blue/green and rainbow deployments in Kubernetes by adjusting the labels on your Pods and changing the selector on the frontend Service to direct traffic to the appropriate set of Pods. Service mesh tools also add the ability to split traffic to different running versions of your application.</p>&#13;
</li>&#13;
<li>&#13;
<p>Helm hooks provide a way to apply certain Kubernetes resources (usually Jobs) at a particular stage of a deployment, for example, to run a database migration. Hooks can define the order in which resources should be applied during a deployment, and cause the deployment to halt if something does not succeed.</p>&#13;
</li>&#13;
<li>&#13;
<p>Knative and OpenFaaS allow you to run “serverless” functions on your clusters, making it easy to deploy event-driven architectures wherever you can run Kubernetes (pretty much anywhere!).<a data-startref="ix_13-workflow-adoc0" data-type="indexterm" id="idm45979375465344"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>