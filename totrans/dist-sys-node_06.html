<html><head></head><body><section data-pdf-bookmark="Chapter 5. Containers" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch_containers">&#13;
<h1><span class="label">Chapter 5. </span>Containers</h1>&#13;
&#13;
&#13;
<p>Programs typically don’t <a data-primary="containers" data-type="indexterm" id="idm46291186737240"/>come bundled with everything they need in a single file. This is true not only for Node.js programs, which consist of at least a single <em>.js</em> file and the <em>node</em> executable, but also for programs compiled using other platforms. There are almost always other requirements involved, such as shared libraries. Even a single-executable binary written in C that statically links its dependencies still technically relies on the system call API offered by the kernel.</p>&#13;
&#13;
<p>There are many different ways that programs are distributed and executed. Each &#13;
<span class="keep-together">of these</span> approaches has trade-offs concerning portability, efficiency, security, and &#13;
<span class="keep-together">brittleness.</span></p>&#13;
&#13;
<p>Sometimes it’s nice to “just ship a binary.” But this means, at the very least, shipping a different binary for different operating systems, and sometimes (as is often the case when a binary depends on OpenSSL) it requires shipping multiple binaries depending on operating system <em>and</em> library versions. This is an issue of portability.</p>&#13;
&#13;
<p>One of the biggest issues is with <a data-primary="libraries, shared" data-type="indexterm" id="idm46291186731656"/><a data-primary="shared libraries" data-type="indexterm" id="idm46291186730952"/>shared libraries. Consider a server running the Linux operating system. This single machine is then expected to run two pieces of software, <em>Resizer Service A</em> and <em>Resizer Service B</em>. However, one version depends on <em>ImageMagick v7</em>, and the other relies on <em>ImageMagick v5</em>. It’s now no longer a straightforward task of installing the ImageMagick shared library; instead, it is a juggling act of isolating the different library versions. This situation is brittle.</p>&#13;
&#13;
<p>Other problems may arise when running multiple programs. Perhaps two programs need to maintain a lock file in the filesystem and the path is hard-coded. Or perhaps the programs want to listen on the same port. Or maybe one of the programs gets compromised and may then be used by an attacker to interfere with the other &#13;
<span class="keep-together">program,</span> which is an issue of security.</p>&#13;
&#13;
<p><em>Virtual machines</em> (VMs) were <a data-primary="VMs (virtual machines)" data-type="indexterm" id="idm46291186709336"/>created to solve many of these problems. A VM is able to emulate computer hardware within a host operating system, having access to an isolated subset of memory and disk space. An operating system installed within this VM is able to run programs completely isolated from the host OS. This is a very powerful concept, one that is still extremely important today. However, it comes with the disadvantage that every running VM needs an entire copy of an OS. It also means that freshly deployed VMs need to take time to boot up the guest OS. This overhead can make it prohibitive to dedicate one VM per program and is a problem of &#13;
<span class="keep-together">efficiency.</span></p>&#13;
&#13;
<p><em>Containers</em> are a way to <a data-primary="containers" data-type="indexterm" id="idm46291186706824"/>describe and bundle the requirements of a program into a distributable package. This includes the contents of a private filesystem and the shared libraries therein, an isolated list of PIDs, and isolated ports that may be listened on without the risk of conflicting with another container, all without allowing access to memory dedicated to other containers. The only thing that isn’t bundled within a container is the operating system itself—instead, the containers rely on the host operating system (or perhaps more specifically, the kernel of the host OS). System calls made within a container go through some light translation before being provided to the host OS.</p>&#13;
&#13;
<p><a data-type="xref" href="#fig_classic_vm_container">Figure 5-1</a> compares three <a data-primary="program isolation" data-type="indexterm" id="idm46291186703976"/><a data-primary="program isolation" data-seealso="containers" data-type="indexterm" id="idm46291186703368"/>approaches to program isolation. The first approach, which I <a data-primary="program isolation" data-secondary="classic approach" data-type="indexterm" id="idm46291186702392"/><a data-primary="classic approach to program isolation" data-type="indexterm" id="idm46291186701544"/>call the <em>classic</em> approach, relies on running programs directly on the OS running on hardware. In this case, a complicated juggling act with shared libraries is likely to happen. A system administrator may be needed when new programs are deployed, or an organization might need to agree to use the same exact dependencies everywhere. However, the overhead is the smallest. The <a data-primary="program isolation" data-secondary="VMs (virtual machines)" data-type="indexterm" id="idm46291186699960"/>second approach, <em>virtual machines</em>, conveys the redundant copies of an OS kernel, possibly for each program (though multiple programs often run within the same VM). VM nomenclature refers to a parent OS as the <em>host OS</em> and <a data-primary="VMs (virtual machines)" data-secondary="host OS" data-type="indexterm" id="idm46291186697832"/><a data-primary="VMs (virtual machines)" data-secondary="guest OS" data-type="indexterm" id="idm46291186696824"/>a child OS as a <em>guest OS</em>. The third approach, <em>containers</em>, shows how the container abstraction can reuse a kernel, but shared libraries will likely be redundant. It also illustrates the need to have smaller containers.</p>&#13;
&#13;
<p>The ideal situation is that a program can very quickly be deployed, regardless of whatever dependencies it has, to some location where it can then consume CPU and RAM and reply to network requests. Once this program is no longer needed, it can be torn down very quickly without leaving behind a mess.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Modern technology stacks should leverage at least two of these approaches. While containers are great for deploying stateless, first-party programs that are updated and deployed frequently and scale up and down, stateful databases will benefit more by running directly on an OS, virtual or otherwise.</p>&#13;
</div>&#13;
&#13;
<figure><div class="figure" id="fig_classic_vm_container">&#13;
<img alt="Architectural comparison between Classic, Virtual Machines, and Containers" src="assets/dsnj_0501.png"/>&#13;
<h6><span class="label">Figure 5-1. </span>Classic versus virtual machines versus containers</h6>&#13;
</div></figure>&#13;
&#13;
<p>Containers have won the battle for program encapsulation. They have become the basic unit of program deployment within modern service-oriented architecture. This layer of abstraction, having redundancy of shared libraries but not of an OS, hits the sweet spot where memory efficiency is traded for portability, all while being robust and secure. There have been several different container formats, but only one format has become ubiquitous.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Introduction to Docker" data-type="sect1"><div class="sect1" id="idm46291186689832">&#13;
<h1>Introduction to Docker</h1>&#13;
&#13;
<p>Docker is a conglomeration <a data-primary="Docker" data-secondary="containers" data-type="indexterm" id="idm46291186688504"/><a data-primary="containers" data-secondary="Docker" data-type="indexterm" id="idm46291186686056"/><a data-primary="Docker" data-type="indexterm" id="dock"/>of related tools. The first tool worth mentioning is the <code>dockerd</code> daemon, <a data-primary="Docker" data-secondary="dockerd daemon" data-type="indexterm" id="idm46291186683656"/>which exposes an HTTP API for receiving commands. The next tool is the <code>docker</code> CLI, which <a data-primary="Docker" data-secondary="Docker CLI" data-type="indexterm" id="idm46291186682136"/>makes calls to the daemon and is how you’ve interacted with Docker so far in this book. A killer feature of Docker is <a class="orm:hideurl" href="https://hub.docker.com/">Docker Hub</a>, which is a <a data-primary="Docker" data-secondary="images" data-tertiary="repository" data-type="indexterm" id="idm46291186679928"/><a data-primary="images, Docker" data-type="indexterm" id="idm46291186678648"/>central repository of Docker images. While there may be competing container formats, none of them has a marketplace as impressive.</p>&#13;
&#13;
<p>A Docker image is an immutable representation of a filesystem that you can run applications within. One Docker image can also extend from another. For example, one might have a base <a data-primary="Docker" data-secondary="images" data-tertiary="Ubuntu" data-type="indexterm" id="idm46291186677032"/><a data-primary="Docker" data-secondary="images" data-tertiary="Node.js" data-type="indexterm" id="idm46291186675784"/>Ubuntu image, followed by a Node.js image, and finally an application image. In this situation, the Ubuntu image provides things like a basic filesystem (<em>/usr/bin</em>, users and permissions, and common libraries). The Node.js image provides the <em>node</em> and <em>npm</em> binaries and shared libraries required by Node.js. Finally, the application image provides the <em>.js</em> application code, the <em>node_modules</em> directory (which might include modules compiled for Linux), and even other application-specific dependencies (such as a compiled ImageMagick binary).</p>&#13;
&#13;
<p>Docker runs Linux <a data-primary="Docker" data-secondary="Linux and" data-type="indexterm" id="idm46291186671400"/><a data-primary="Linux" data-secondary="Docker and" data-type="indexterm" id="idm46291186670392"/>applications. However, the Linux kernel is not actually provided in any of these image layers, not even a base Ubuntu image. Instead, that ultimately comes from a Linux OS running outside of Docker. When the machine running Docker is a Linux machine (which is how production applications running on a server typically work), then there’s likely only a single OS involved. When Docker is running on a non-Linux OS, such as macOS or Windows development machine, then a Linux virtual <a data-primary="VMs (virtual machines)" data-secondary="Linux" data-type="indexterm" id="idm46291186668824"/>machine is required. <em>Docker Desktop</em> is a <a data-primary="Docker Desktop" data-type="indexterm" id="idm46291186667336"/><a data-primary="VMs (virtual machines)" data-secondary="Docker Desktop" data-type="indexterm" id="idm46291186666600"/>tool created by Docker for just this situation. Docker Desktop not only provides a VM, but it also provides other niceties such as an admin UI and Kubernetes (which is covered in more detail in <a data-type="xref" href="ch07.html#ch_kubernetes">Chapter 7</a>).</p>&#13;
&#13;
<p>A Docker container is an <a data-primary="Docker" data-secondary="containers" data-type="indexterm" id="idm46291186664264"/><a data-primary="containers" data-secondary="Docker" data-type="indexterm" id="idm46291186663256"/>instance of a Docker image associated with configuration such as a name, port mappings, and volume mappings—which is how the filesystem within the container can be mapped to the host filesystem. This means that you can run as many containers pointing to the same image on a single machine as you want—assuming you have the computing resources to do so. Containers can be started and stopped and interacted with in many ways.</p>&#13;
&#13;
<p>An important aspect <a data-primary="Docker" data-secondary="Dockerfile" data-type="indexterm" id="idm46291186661128"/>of Docker is the <em>Dockerfile</em>, which is a declarative file describing a Docker image. A Dockerfile can contain many different lines, which describe how the container ends up being built. Directives are listed on different lines, with directives being run from top to bottom. The first directive usually ends up being the <code>FROM</code> directive, which is how an image declares which image to use as a parent. The official Node.js Alpine container, for example, uses <code>FROM alpine:3.11</code> as the first line of the Dockerfile. In this case it’s declaring that the Docker image named <code>alpine</code> tagged with a version of <code>3.11</code> is its base container. An application might then extend from that image by using the <code>FROM node:lts-alpine3.11</code> directive. These directives will be covered in more detail shortly. Note that a Docker image cannot have more than one parent Docker images—no multi-inheritance here! However it can have multiple <code>FROM</code> directives, which is called a multistage Dockerfile. Again, more on this later.</p>&#13;
&#13;
<p>Each new directive in a Dockerfile <a data-primary="Docker" data-secondary="Dockerfile" data-tertiary="layers" data-type="indexterm" id="idm46291186655768"/>creates a new <em>layer</em>. A layer is a partial representation of an image after that particular directive has finished running. Each one of these layers increases the storage size and, potentially, the startup time of an image. <a data-type="xref" href="#fig_Docker_image_layer_fs">Figure 5-2</a> shows the relationship between images and layers and how they can contribute to the resulting filesystem. For these reasons it’s common for applications to combine as many operations into as few lines as possible by chaining <a data-primary="commands" data-secondary="chaining" data-type="indexterm" id="idm46291186652584"/><a data-primary="Docker" data-secondary="chaining commands" data-type="indexterm" id="idm46291186651640"/>commands. Each layer can be represented as a hash of its contents, much like <em>git</em> does when you check out a specific commit hash. For this reason, if a line in a Dockerfile is expected to change frequently, it should be placed later in a Dockerfile. This will allow the previous layers to be reused between multiple versions of an application’s Docker image.</p>&#13;
&#13;
<p>Docker images are often tuned for <a data-primary="Docker" data-secondary="images" data-tertiary="filesystem shrinking" data-type="indexterm" id="idm46291186649544"/><a data-primary="images, Docker" data-secondary="filesystem shrinking" data-type="indexterm" id="idm46291186648264"/>performance by shrinking the filesystem to the smallest version required by the application. The Ubuntu Linux <a data-primary="Ubuntu" data-type="indexterm" id="idm46291186647064"/>distribution is intended for generic use on desktops and servers and can be rather large. Debian is a lighter distribution, but it also contains many tools that are needed by whole server machines but aren’t required within a container. Alpine is an extremely stripped-down Linux distribution and is often the base image of choice for storage-concious developers. Sometimes an application does rely on features that aren’t provided by such a simple base image and may need to instead use a more complex one. The <a class="orm:hideurl" href="https://hub.docker.com/_/node/">official Node.js Docker images</a> contain variants for both Debian and Alpine.</p>&#13;
&#13;
<figure><div class="figure" id="fig_Docker_image_layer_fs">&#13;
<img alt="Images are made up of layers, and layers can provide parts of the overall filesystem" src="assets/dsnj_0502.png"/>&#13;
<h6><span class="label">Figure 5-2. </span>Images contain layers, and layers contribute to the filesystem</h6>&#13;
</div></figure>&#13;
&#13;
<p>When you work with Docker images, such as when you previously ran all of those <code>docker run</code> commands, a <a data-primary="commands" data-secondary="docker run" data-type="indexterm" id="idm46291186641688"/>version of the image is downloaded and cached on your machine. This is very similar to how <code>npm install</code> works. Both npm and Docker cache remote files and can keep track of multiple versions of these files. Docker even tracks each layer of the images.</p>&#13;
&#13;
<p>To see a list of the Docker <a data-primary="Docker" data-secondary="images" data-tertiary="cached, viewing" data-type="indexterm" id="idm46291186639480"/><a data-primary="images, Docker" data-secondary="viewing" data-type="indexterm" id="idm46291186638232"/>images that are currently cached on your machine, run this command:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker images</pre>&#13;
&#13;
<p>You should then see a list of images. The list that I see looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">REPOSITORY                   TAG      IMAGE ID      CREATED       SIZE&#13;
grafana/grafana              6.5.2    7a40c3c56100  8 weeks ago   228MB&#13;
grafana/grafana              latest   7a40c3c56100  8 weeks ago   228MB&#13;
openzipkin/zipkin            latest   12ee1ce53834  2 months ago  157MB&#13;
openzipkin/zipkin-slim       2.19     c9db4427dbdd  2 months ago  124MB&#13;
graphiteapp/graphite-statsd  1.1.6-1  5881ff30f9a5  3 months ago  423MB&#13;
sebp/elk                     latest   99e6d3f782ad  4 months ago  2.06GB</pre>&#13;
&#13;
<p>This list hints at a lot of things—other than how much time it takes to write a book. First, notice how large some of the images can get. In the case of <code>sebp/elk</code>, the image is just over 2GB in size! Also, notice the <em>TAG</em> column. This column references the version. A version is usually one of three values: either a version string, the string <code>latest</code> (which refers to the most recent version of an image <em>when it was last downloaded from the registry</em>), or the value <code>&lt;none&gt;</code>, which usually happens when you build an image for your own software but don’t provide a version string.</p>&#13;
&#13;
<p>Every image has two ways to <a data-primary="Docker" data-secondary="images" data-tertiary="referencing" data-type="indexterm" id="idm46291186632056"/><a data-primary="images, Docker" data-secondary="referencing" data-type="indexterm" id="idm46291186629832"/>refer to it. The permanent way is by using the <em>image ID</em>. This value should always refer to the same exact content. The other way to refer to an image is by its repository and tag name. In my results the <code>grafana/grafana</code> repository with a tag of <code>6.5.2</code> happens to point to the same image as the one with a tag of <code>latest</code> since they have the same image ID. When I download the <code>latest</code> version of Grafana again in a few weeks, it might point to a different image ID.</p>&#13;
&#13;
<p>Next, it’s time to gain some <a data-primary="Docker" data-secondary="images" data-tertiary="layers" data-type="indexterm" id="idm46291186626200"/><a data-primary="images, Docker" data-secondary="layers" data-type="indexterm" id="idm46291186624952"/>insight into the layers used by each of these images by using another command. This time run the following command (or substitute a different version number if your listing is different):</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker <code class="nb">history </code>grafana/grafana:6.5.2</pre>&#13;
&#13;
<p>You will then see a list of the different layers of the image. The results that I get look like this:</p>&#13;
&#13;
<pre data-type="programlisting">IMAGE         CREATED BY                                      SIZE&#13;
7a40c3c56100  /bin/sh -c #(nop)  ENTRYPOINT ["/run.sh"]       0B&#13;
&lt;missing&gt;     /bin/sh -c #(nop)  USER grafana                 0B&#13;
&lt;missing&gt;     /bin/sh -c #(nop) COPY file:3e1dfb34fa628163…   3.35kB&#13;
&lt;missing&gt;     /bin/sh -c #(nop)  EXPOSE 3000                  0B&#13;
&lt;missing&gt;     |2 GF_GID=472 GF_UID=472 /bin/sh -c mkdir -p…   28.5kB&#13;
&lt;missing&gt;     /bin/sh -c #(nop) COPY dir:200fe8c0cffc35297…   177MB&#13;
&lt;missing&gt;     |2 GF_GID=472 GF_UID=472 /bin/sh -c if [ `ar…   18.7MB&#13;
&lt;missing&gt;     |2 GF_GID=472 GF_UID=472 /bin/sh -c if [ `ar…   15.6MB&#13;
&lt;missing&gt;     |2 GF_GID=472 GF_UID=472 /bin/sh -c apk add …   10.6MB&#13;
... &lt;TRUNCATED RESULTS&gt; ...&#13;
&lt;missing&gt;     /bin/sh -c #(nop) ADD file:fe1f09249227e2da2…   5.55MB</pre>&#13;
&#13;
<p>In this case, prior to truncating the list, the <a class="orm:hideurl" href="https://github.com/grafana/grafana/blob/v6.5.2/Dockerfile">Grafana version 6.5.2 image</a> is composed of 15 different layers. The list correlates to the steps in a Dockerfile backwards; the earlier entries in the list are later lines in the Dockerfile. The list displayed as the result of the <code>docker history</code> command <a data-primary="docker history command" data-type="indexterm" id="idm46291186577976"/><a data-primary="commands" data-secondary="docker history" data-type="indexterm" id="idm46291186577240"/>only includes steps for the specific image being queried, not any parent images.</p>&#13;
&#13;
<p>The <code>docker pull</code> command <a data-primary="docker pull command" data-type="indexterm" id="idm46291186617768"/><a data-primary="commands" data-secondary="docker pull" data-type="indexterm" id="idm46291186617032"/>is used to download an image from a remote repository. Run the following command to download such an image:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker pull node:lts-alpine</pre>&#13;
&#13;
<p>This will begin downloading the layers of the Alpine variant of the most recent LTS release. In my case, I’m greeted with the following output:</p>&#13;
&#13;
<pre data-type="programlisting">lts-alpine: Pulling from library/node&#13;
c9b1b535fdd9: Pull complete&#13;
750cdd924064: Downloading [=====&gt;           ]  2.485MB/24.28MB&#13;
2078ab7cf9df: Download complete&#13;
02f523899354: Download complete</pre>&#13;
&#13;
<p>In my case, there are four layers with a file size greater than 0 being downloaded (some of the layers don’t modify the filesystem and won’t be listed as having been &#13;
<span class="keep-together">downloaded).</span></p>&#13;
&#13;
<p>The Debian variant is a lot <a data-primary="Docker" data-secondary="images" data-tertiary="Debian" data-type="indexterm" id="idm46291186589416"/><a data-primary="Docker" data-secondary="images" data-tertiary="Alpine" data-type="indexterm" id="idm46291186588168"/><a data-primary="images, Docker" data-secondary="Debian" data-type="indexterm" id="idm46291186586952"/><a data-primary="images, Docker" data-secondary="Alpine" data-type="indexterm" id="idm46291186586008"/>larger than the Alpine variant. For example, this LTS Alpine image is 85.2MB. If you were to download the Debian variant using the <code><strong>docker pull node:lts</strong></code> command, you would see that it’s a much larger 913MB. One thing to keep in mind is that these layers end up getting cached on the different machines they’re used on. If you were to deploy an application using the Debian variant, the first time it’s deployed, the server would need to download the nearly 800MB Debian base image. However, for subsequent deploys, the Debian layer would already be present and the deploy would be faster.</p>&#13;
&#13;
<p>Storage isn’t the <a data-primary="Docker" data-secondary="images" data-tertiary="storage" data-type="indexterm" id="idm46291186583400"/><a data-primary="images, Docker" data-secondary="storage" data-type="indexterm" id="idm46291186551576"/>only concern with large images. Another thing to consider is security. If a Node.js application running inside of Debian gets hacked, there will be many utilities available in the filesystem that can get executed. However, if an application based on Alpine is compromised, there will be less binaries around. In theory, this will lead to a smaller attack surface area.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>As a rule of thumb, if your application <a data-primary="Alpine" data-type="indexterm" id="idm46291186549144"/>works with Alpine,<sup><a data-type="noteref" href="ch05.html#idm46291186560600" id="idm46291186560600-marker">1</a></sup> use Alpine! If your application needs a few shared libraries, install those libraries in your Alpine image. Only for complex applications should you consider using a heavier base container like Debian or Ubuntu.</p>&#13;
</div>&#13;
&#13;
<p>Now that you’re more familiar with some of the theory behind Docker, it’s time to start running more containers. For this first example, you’ll run a plain Ubuntu container <a data-primary="containers" data-secondary="Ubuntu" data-type="indexterm" id="idm46291186558120"/><a data-primary="Ubuntu" data-secondary="containers" data-type="indexterm" id="idm46291186557144"/>without packaging an application with it. The previous sections in this book have done just this. However, this time, you’ll run the container in an interactive mode. Run the following command to enter an interactive <code>bash</code> session <a data-primary="bash sessions" data-type="indexterm" id="idm46291186555448"/><a data-primary="Ubuntu" data-secondary="bash sessions" data-type="indexterm" id="idm46291186554712"/>within an Ubuntu container:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>docker run -it --rm --name ephemeral ubuntu /bin/bash</pre>&#13;
&#13;
<p>The <code>-i</code> flag means that the session is interactive, and the <code>-t</code> flag means that Docker should use a TTY session (as a convention they’ve been combined into simply <code>-it</code>). Both these flags are set to make the session interactive. The <code>--rm</code> flag tells Docker to remove all traces of the container once it exits. The <code>--name</code> flag sets a name for the container, which will help to identify it in a list. The argument <code>ubuntu</code> is the name of the image being run (which really translates into <code>ubuntu:latest</code>). The final argument of <code>/bin/bash</code> is the binary that Docker will execute inside the container.</p>&#13;
&#13;
<p>Once Docker downloads the necessary layers, you should see your terminal prompt change. At this point, you are able to execute commands within the running container itself. Run the command <code><strong>ps -e</strong></code>. This <a data-primary="Docker" data-secondary="ps -e command" data-type="indexterm" id="idm46291186528520"/>will list all currently running processes inside the container. The output I get when I run the command looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">PID TTY          TIME CMD&#13;
  1 pts/0    00:00:00 bash&#13;
 10 pts/0    00:00:00 ps</pre>&#13;
&#13;
<p>The root process within the container, the one with a PID value of 1, is <code>bash</code>. Only a second process is also being run, namely <code>ps</code>. If this same command were run on a more traditional Linux server, the root process would probably be a more complex <em>service manager</em> such as <code>systemd</code> or <code>init</code>. There would also be dozens if not hundreds of other processes listed. Service managers handle things like reading configuration files, running services and managing their interdependencies, and managing process restarts in a configurable manner when a child fails. In short, they’re complex tools required for managing a complete operating system.</p>&#13;
&#13;
<p>Within a Docker container, such <a data-primary="Docker" data-secondary="containers" data-tertiary="service management" data-type="indexterm" id="idm46291186522632"/><a data-primary="containers" data-secondary="Docker" data-tertiary="service management" data-type="indexterm" id="idm46291186521384"/>service management features are usually overkill, and a simpler program should be used. For an interactive shell, <code>bash</code> will suffice as the root process. However, in more complex situations, you might need to reach for another program. For example, sometimes it’s beneficial <a data-primary="Docker" data-secondary="containers" data-tertiary="sidecars" data-type="indexterm" id="idm46291186519352"/><a data-primary="containers" data-secondary="Docker" data-tertiary="sidecars" data-type="indexterm" id="idm46291186518104"/><a data-primary="sidecars" data-type="indexterm" id="idm46291186516888"/>to run a <em>sidecar process</em> within a Docker container. A sidecar is an external process that performs certain duties, such as providing a proxy to make service discovery easier for an application or providing a health-checking daemon that polls the application for health stats and relays the stats to another service. In those situations, restart policies become very important. For example, if the sidecar crashes, it might simply be restarted, but if the main application crashes, the whole container should then exit. In those cases, you may need to research an alternative service manager, one that allows for granular configuration.</p>&#13;
&#13;
<p>Now switch to a new terminal window and run this command:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker ps</pre>&#13;
&#13;
<p>This Docker subcommand is <a data-primary="commands" data-secondary="ps" data-type="indexterm" id="idm46291186490392"/><a data-primary="ps command" data-type="indexterm" id="idm46291186489544"/><a data-primary="Docker" data-secondary="ps command" data-type="indexterm" id="idm46291186488904"/>different than the <code>ps</code> command that was run within the container, but in spirit, both commands intend to list a snapshot of currently running <em>things</em>. The output I get when I run this command looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">CONTAINER ID  IMAGE   COMMAND      CREATED         PORTS  NAMES&#13;
527847ba22f8  ubuntu  "/bin/bash"  11 minutes ago         ephemeral</pre>&#13;
&#13;
<p>Note that you might see more entries if you still have some other containers running.</p>&#13;
&#13;
<p>It’s even possible to manually <a data-primary="Docker" data-secondary="commands, manual execution" data-type="indexterm" id="idm46291186484728"/>execute a command within a currently running Docker container. This is useful if you need to debug a runaway Node.js application. The subcommand to do this is <code>exec</code>. Switch to a new terminal window and run <strong><code>docker exec ephemeral /bin/ls /var</code></strong> to execute a new command within your running Ubuntu container. You’ve just executed a second command within your container without <a data-primary="Docker" data-secondary="exec subcommand" data-type="indexterm" id="idm46291186482312"/>disrupting the other commands.</p>&#13;
&#13;
<p>You’re now free to exit the container. Switch back to the terminal running the Docker container and type <code><strong>exit</strong></code>. The container will be torn down, and, since it was run with the <code>--rm</code> flag, it will be completely removed from your system. Running <strong><code>docker ps</code></strong> again will prove that it is no longer running. However, to prove that it is no longer on your system, run the <strong><code>docker ps --all</code></strong> command. You will see several entries listed in the results, though the <em>ephemeral</em> container you created earlier will not be listed amongst them.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>At this point, you might <a data-primary="containers" data-secondary="Docker" data-tertiary="pruning" data-type="indexterm" id="idm46291186477064"/><a data-primary="Docker" data-secondary="containers" data-tertiary="pruning" data-type="indexterm" id="idm46291186475816"/>want to prune some of the old containers that you’re no longer using, as they do consume disk space. To remove a container from your machine, you can run the <strong><code>docker rm &lt;name/id&gt;</code></strong> command, using either the hexadecimal container identifier or the human-friendly container name. Similarly, you can run the <strong><code>docker images</code></strong> command to see a list of all the images still available on your computer. You can then run <strong><code>docker rmi &lt;image id&gt;</code></strong> to remove any unused images. Note that you cannot remove an image currently being used by a container; the container will need to be removed first.</p>&#13;
</div>&#13;
&#13;
<p>Containers aren’t that useful if external applications can’t interface with them. Luckily, Docker provides two important methods to do just that. The first method is by sharing part of the filesystem within a running container with part of the filesystem in the host operating system. This is done by using the <code>-v</code> / <code>--volume</code> or the <code>--mount</code> flags (the first two are an alias for each other, and the third flag accepts a more verbose syntax, but they essentially do the same thing). The other method for interfacing with a container is by mapping a port inside the container to the host operating system by using the <code>-p</code> / <code>--publish</code> flag.</p>&#13;
&#13;
<p>Execute the following commands to download an example <em>index.html</em> file and to run a container with nginx configured to read from the directory:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>rm index.html <code class="p">;</code> curl -o index.html http://example.org&#13;
<code class="nv">$ </code>docker run --rm -p 8080:80 <code class="se">\</code>&#13;
  -v <code class="nv">$PWD</code>:/usr/share/nginx/html nginx</pre>&#13;
&#13;
<p>Both the <code>volume</code> and <code>publish</code> flags have a verbose syntax for configuring the way the mapping between the host and the container work. For example, it’s possible to specify if a volume mapping is read only or if a port mapping should be UDP. Both flags support a simple syntax as well, where a resource on the host is mapped with reasonable defaults to a resource on the guest. The command you just ran uses this simple syntax for both volume mapping and port mapping. In this case, port 8080 on the host is mapped to port 80 in the container by using <code>-p 8080:80</code>. The current directory is mapped to the directory used by nginx to read static files with the <code>-v $PWD:/usr/share/nginx/html</code> flag (the <code>-v</code> flag expects absolute directories, which is why the command uses <code>$PWD</code> instead of “<code>.</code>”).</p>&#13;
&#13;
<p>Now that the nginx <a data-primary="Docker" data-secondary="containers" data-tertiary="nginx" data-type="indexterm" id="idm46291186442904"/><a data-primary="containers" data-secondary="Docker" data-tertiary="nginx" data-type="indexterm" id="idm46291186441624"/>container is running, visit <a href="http://localhost:8080/"><em class="hyperlink">http://localhost:8080/</em></a> in your browser to see the rendered <em>index.html</em> page. The <code>volume mount</code> flag is very useful when running database services that need to persist state. However, it’s not that common to mount the host’s filesystem for a Node.js application because such services should be run in a stateless manner. For that reason, you probably won’t need to use the <code>volume</code> flag with your apps.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291186435432">&#13;
<h5>Alternatives to Docker</h5>&#13;
<p>There really aren’t many alternatives to <a data-primary="Docker" data-secondary="containers" data-tertiary="alternatives" data-type="indexterm" id="idm46291186434184"/><a data-primary="containers" data-secondary="Docker" data-tertiary="alternatives" data-type="indexterm" id="idm46291186432936"/>Docker containers, at least none as ubiquitous. <a class="orm:hideurl" href="https://github.com/rkt/rkt">rkt</a> is one such alternative, developed by CoreOS/RedHat, that is even compatible with Kubernetes; however, as of this writing, it hasn’t received updates for several months. The <a class="orm:hideurl" href="https://opencontainers.org/">Open Container Initiative</a> is an attempt to create open standards around container formats.</p>&#13;
&#13;
<p>Virtual machines are an alternative in the sense that they can be used to isolate applications and remove the burden of juggling system libraries. However, as was mentioned earlier, they come with much more overhead than containers and aren’t always a viable <a data-primary="Docker" data-startref="dock" data-type="indexterm" id="idm46291186428824"/>replacement.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Containerizing a Node.js Service" data-type="sect1"><div class="sect1" id="ch_containers_subsec_node">&#13;
<h1>Containerizing a Node.js Service</h1>&#13;
&#13;
<p>In this section, you’ll create a <a data-primary="Docker" data-secondary="containers" data-tertiary="recipe-api service" data-type="indexterm" id="idm46291186426552"/><a data-primary="containers" data-secondary="Docker" data-tertiary="recipe-api service" data-type="indexterm" id="idm46291186425304"/><a data-primary="recipe-api" data-secondary="Docker containers" data-type="indexterm" id="idm46291186403624"/><a data-primary="services" data-secondary="containerizing" data-type="indexterm" id="servcont"/>Docker container for the <em>recipe-api</em> service. This container will be used for two different purposes. The first will be to install packages, and the second will be to set up the environment to run the Node.js application. These two operations sound similar, but as you’ll see, it’s important to keep the two concepts separated.</p>&#13;
&#13;
<p>The fact that Docker will be used <a data-primary="modules" data-secondary="installing" data-type="indexterm" id="idm46291186400232"/>to install the project’s packages might sound a bit odd at first. Right now, on disk, within your <em>recipe-api</em> directory, you <a data-primary="recipe-api" data-secondary="node_modules directory" data-type="indexterm" id="idm46291186398632"/>already have a <em>node_modules</em> directory that contains all the modules required to run the application! Why aren’t those modules good enough?</p>&#13;
&#13;
<p>For the most part, this comes down to the <a data-primary="modules" data-secondary="installing" data-tertiary="package manager" data-type="indexterm" id="idm46291186396536"/><a data-primary="package manager" data-type="indexterm" id="idm46291186395288"/>fact that packages installed via package manager don’t simply download JavaScript files and place them on the filesystem. Instead, the installation of packages from the npm registry is actually a fairly &#13;
<span class="keep-together">nondeterministic</span> operation. For one thing, if an npm package has native code involved, such as C++ files, that code will need to be compiled. There’s no guarantee that the compiled output on your local development machine will be compatible with that of the Linux Docker environment (for example, a local development machine might be &#13;
<span class="keep-together">a macOS</span> or Windows machine, or a Linux machine with different shared library &#13;
<span class="keep-together">versions).</span></p>&#13;
&#13;
<p>If you’ve ever deployed an application and then saw many error logs mentioning the <span class="keep-together"><code>chokidar</code></span> or <code>fsevents</code> packages, it might be due to deploying a macOS <em>node_modules</em> directory to a Linux server. Another reason for this nondeterminism is the <code>postinstall</code> and <code>preinstall</code> scripts of a package, which can run any arbitrary code the package author likes. Sometimes this is used to do things like download a binary from the internet. For these reasons, the package installation must happen in an environment similar to where the code will ultimately run.</p>&#13;
&#13;
<p>As part of both the installation step, as well as preparing the execution environment, some files will need to be copied from the directory where your project files live. Much like git has the concept of a <em>.gitignore</em> file and npm has an <em>.npmignore</em> file, Docker <a data-primary="Docker" data-secondary=".dockerignore file" data-secondary-sortas="dockerignore file" data-tertiary="entries" data-type="indexterm" id="idm46291186386872"/><a data-primary="Docker" data-secondary=".dockerignore file" data-secondary-sortas="dockerignore file" data-type="indexterm" id="idm46291186385320"/><a data-primary=".dockerignore file" data-primary-sortas="dockerignore file" data-type="indexterm" id="idm46291186384104"/>has its own <em>.dockerignore</em> file. This file, similar to the others, specifies patterns of files that should be ignored. In the case of Docker, files matching these patterns won’t be copied into the containers. Ignoring such files is convenient because wild cards can later be used when specifying which files to copy. Create a new file at <em>recipe-api/.dockerignore</em> and add the content from <a data-type="xref" href="#ex_dockerignore">Example 5-1</a> to it.</p>&#13;
<div data-type="example" id="ex_dockerignore">&#13;
<h5><span class="label">Example 5-1. </span><em>recipe-api/.dockerignore</em></h5>&#13;
&#13;
<pre data-type="programlisting">node_modules&#13;
npm-debug.log&#13;
Dockerfile</pre></div>&#13;
&#13;
<p>The entries in this file are pretty similar to the files that you might already have in a <em>.gitignore</em> for other Node.js projects. Much like you wouldn’t want the <em>node_modules</em> directory checked into git, you also don’t want those packages copied into the Docker image.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Dependency Stage" data-type="sect2"><div class="sect2" id="idm46291186377528">&#13;
<h2>Dependency Stage</h2>&#13;
&#13;
<p>Now it’s time to consider <a data-primary="Docker" data-secondary="images" data-tertiary="dependency stage" data-type="indexterm" id="depstage"/><a data-primary="images, Docker" data-secondary="dependency stage" data-type="indexterm" id="depstage1"/><a data-primary="containers" data-secondary="dependencies" data-type="indexterm" id="idm46291186373240"/>the Dockerfile itself. This example will use a multistage Dockerfile. The first stage will build the dependencies and the second will prepare the application container. The build stage will be based on the official Node.js Docker image. This image is built with the intention to satisfy the needs of as many Node.js developers as possible, providing tools that they will likely need. As an example, it includes both the npm and yarn package manager. For this reason it’s a pretty useful base image for the build stage of an application.</p>&#13;
&#13;
<p>Create a new file at <em>recipe-api/Dockerfile</em> and add the content from <a data-type="xref" href="#ex_dockerfile_deps">Example 5-2</a> to it. Keep the file open because you’ll add more content to it in a moment.</p>&#13;
<div data-type="example" id="ex_dockerfile_deps">&#13;
<h5><span class="label">Example 5-2. </span><em>recipe-api/Dockerfile</em> “deps” stage</h5>&#13;
&#13;
<pre data-type="programlisting">FROM node:14.8.0-alpine3.12 AS deps&#13;
&#13;
WORKDIR /srv&#13;
COPY package*.json ./&#13;
RUN npm ci --only=production&#13;
# COPY package.json yarn.lock ./&#13;
# RUN yarn install --production</pre></div>&#13;
&#13;
<p>The first line in this file, beginning with <code>FROM</code>, specifies that the <code>node:14.8.0-alpine3.12</code> image will be used as a base. If this were the only <code>FROM</code> directive in the entire file, it would be the base of the resulting image. However, since you’ll add another one later, it’s only the base image of the first stage. This line also states &#13;
<span class="keep-together">that the</span> first stage of the build is being named <code>deps</code>. This name will be useful in the &#13;
<span class="keep-together">next stage.</span></p>&#13;
&#13;
<p>The <code>WORKDIR /srv</code> line states that the actions that follow will take place within the <em>/srv</em> directory. This is similar to running the <code>cd</code> command in your shell, which changes the current working directory.</p>&#13;
&#13;
<p>Next is the <code>COPY</code> statement. The first argument of the statement represents the filesystem in the host, and the second represents the filesystem within the container. In this case, the <a data-primary="JSON" data-secondary="package.json files" data-type="indexterm" id="idm46291186360552"/><a data-primary="JSON" data-secondary="package-lock.json file" data-type="indexterm" id="idm46291186359544"/>command is stating that files matching <code>package*.json</code> (specifically <em>package.json</em> and <em>package-lock.json</em>) will be copied to <code>./</code> within the container (being the <em>/srv</em> directory). Alternatively, if you prefer to use yarn, you would instead copy the <em>yarn.lock</em> file.</p>&#13;
&#13;
<p>After that is the <code>RUN</code> command. This <a data-primary="RUN directive" data-type="indexterm" id="idm46291186354792"/><a data-primary="Docker" data-secondary="Dockerfile" data-tertiary="RUN directive" data-type="indexterm" id="idm46291186354056"/>command will execute the specified command within the container.&#13;
In this case, it’s executing the <code>npm ci --only=production</code> command.&#13;
This performs a clean installation of all nondevelopment dependencies. In general, the <code>npm ci</code> command <a data-primary="commands" data-secondary="npm ci" data-type="indexterm" id="idm46291186351720"/>is faster than <code>npm install</code> when dealing with a clean environment such as a Docker image. Alternatively, if you were using yarn, you might instead run <code>yarn install --production</code>. Again, both the <code>npm</code> and <code>yarn</code> binaries are provided in the image due to inheriting from the official <code>node</code> base image.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Some people like to create an earlier stage in their build where they install dev dependencies and run their test suite. This can help increase confidence that the resulting image is free of bugs. But, since this likely involves two separate <code>npm install</code> steps (one with dev dependencies and one without), it won’t necessarily find all bugs, like if application <a data-primary="Docker" data-secondary="images" data-startref="depstage" data-tertiary="dependency stage" data-type="indexterm" id="idm46291186346728"/><a data-primary="images, Docker" data-secondary="dependency stage" data-startref="depstage1" data-type="indexterm" id="idm46291186345208"/>code mistakenly requires a dev dependency.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Release Stage" data-type="sect2"><div class="sect2" id="idm46291186343544">&#13;
<h2>Release Stage</h2>&#13;
&#13;
<p>Now you’re ready to work on the second <a data-primary="Docker" data-secondary="images" data-tertiary="release stage" data-type="indexterm" id="relstage"/><a data-primary="images, Docker" data-secondary="release stage" data-type="indexterm" id="relstage1"/>half of the Dockerfile. Add the content from <a data-type="xref" href="#ex_dockerfile_release_1">Example 5-3</a> to the same <em>recipe-api/Dockerfile</em> file that you’ve been working with.</p>&#13;
<div data-type="example" id="ex_dockerfile_release_1">&#13;
<h5><span class="label">Example 5-3. </span><em>recipe-api/Dockerfile</em> “release” stage part one</h5>&#13;
&#13;
<pre data-type="programlisting">FROM alpine:3.12 AS release&#13;
&#13;
ENV V 14.8.0&#13;
ENV FILE node-v$V-linux-x64-musl.tar.xz&#13;
&#13;
RUN apk add --no-cache libstdc++ \&#13;
  &amp;&amp; apk add --no-cache --virtual .deps curl \&#13;
  &amp;&amp; curl -fsSLO --compressed \&#13;
  "https://unofficial-builds.nodejs.org/download/release/v$V/$FILE" \&#13;
  &amp;&amp; tar -xJf $FILE -C /usr/local --strip-components=1 \&#13;
  &amp;&amp; rm -f $FILE /usr/local/bin/npm /usr/local/bin/npx \&#13;
  &amp;&amp; rm -rf /usr/local/lib/node_modules \&#13;
  &amp;&amp; apk del .deps</pre></div>&#13;
&#13;
<p>Unlike the first <em>deps</em> stage of the Dockerfile, this second <em>release</em> stage of the build doesn’t make use of the official Node.js image. Instead, it’s using a rather plain <code>alpine</code> image. The reason for this is that some of the niceties provided by the official Node.js image aren’t needed in a production application. For example, once the dependencies are squared away, it’s uncommon for an application to later invoke the <code>npm</code> or <code>yarn</code> binaries. By using the <code>alpine</code> image directly, the image will be just a little smaller and simpler. It also helps for demonstrating more complex Dockerfile directives.</p>&#13;
&#13;
<p>The next two lines define environment variables that are used by the other directives. This is a convenient way to prevent common strings from being repeated in the file. The first variable is called <code>V</code> and represents the version. In this case, the Dockerfile is working with Node.js <em>v14.8.0</em>. The second variable is called <code>FILE</code> and is the name of the tarball to be downloaded.</p>&#13;
&#13;
<p>After the environment <a data-primary="environment variables" data-type="indexterm" id="idm46291186328968"/><a data-primary="containers" data-secondary="environment variables" data-type="indexterm" id="idm46291186328232"/><a data-primary="variables" data-secondary="environment variables" data-type="indexterm" id="idm46291186327288"/><a data-primary="Docker" data-secondary="Dockerfile" data-tertiary="environment variables" data-type="indexterm" id="idm46291186326344"/>variables is a complex series of commands that will be run inside the container using the <code>RUN</code> directive. The Dockerfile is stating that several commands will be executed, but they’re wrapped up in a single <code>RUN</code> directive to keep the number of intermediate layers small. The backslash at the end of the line states that the next line is still part of the same line, and the ampersands state that a new command is being run (and that if a previous command fails, the following commands should not be run).</p>&#13;
&#13;
<p>The Alpine operating <a data-primary="Alpine" data-secondary="apk package manager" data-type="indexterm" id="idm46291186323240"/>system comes with a package manager called <code>apk</code>, and the first two commands in the <code>RUN</code> directive install packages using it. The packages are installed by running <code>apk add</code>. The <code>--no-cache</code> flag tells <code>apk</code> not to leave behind any package management files tracking the installs, which helps keep the image that much smaller. The first package being installed is <code>libstdc++</code>. This package provides a shared library required by Node.js. The second package is <code>curl</code>. This package is only needed during setup and will later be removed. The <code>--virtual .deps</code> flag tells <code>apk</code> to keep track of the installed package and its dependencies. Then, later, that group of packages can be removed all at once.</p>&#13;
&#13;
<p>The next command executes <code>curl</code> inside of the container and downloads the Node.js release tarball. After that, the <code>tar</code> command tar<a data-primary="tar command" data-type="indexterm" id="idm46291186316056"/><a data-primary="commands" data-secondary="tar" data-type="indexterm" id="idm46291186315320"/>extracts the contents of the tarball into <em>/usr/local</em>. The tarball doesn’t include yarn but it does include npm, so the following <code>rm</code> commands <a data-primary="rm command" data-type="indexterm" id="idm46291186313288"/><a data-primary="commands" data-secondary="rm" data-type="indexterm" id="idm46291186312552"/>remove npm and its dependent files. Finally, the <code>apk del .deps</code> command removes <code>curl</code> and its dependencies.</p>&#13;
&#13;
<p>This was the most complex part of the Dockerfile. Now add the final contents from <a data-type="xref" href="#ex_dockerfile_release_2">Example 5-4</a>, which contains the second half of the directives for the <em>release</em> stage.</p>&#13;
<div data-type="example" id="ex_dockerfile_release_2">&#13;
<h5><span class="label">Example 5-4. </span><em>recipe-api/Dockerfile</em> “release” stage part two</h5>&#13;
&#13;
<pre data-type="programlisting">WORKDIR /srv&#13;
COPY --from=deps /srv/node_modules ./node_modules&#13;
COPY . .&#13;
&#13;
EXPOSE 1337&#13;
ENV HOST 0.0.0.0&#13;
ENV PORT 1337&#13;
CMD [ "node", "producer-http-basic.js" ]</pre></div>&#13;
&#13;
<p>Again, the working directory is set to <code>/srv</code>. This is a common convention on Linux servers, but otherwise, the application code could reside almost anywhere.</p>&#13;
&#13;
<p>The more interesting line, though, is <a data-primary="Docker" data-secondary="Dockerfile" data-tertiary="COPY directive" data-type="indexterm" id="idm46291186304616"/>the following <code>COPY</code> directive. The <code>--from</code> flag instructs the <code>COPY</code> directive to copy files from another stage of the image build process, not from the host operating filesystem like it usually does. This is where the magic of the multistage presents itself. In this case, the <em>/srv/node_modules</em> directory from the <code>deps</code> stage is being copied to the <em>/srv/node_modules</em> directory within &#13;
<span class="keep-together">the <code>release</code></span> container. This ensures that the packages are built for the proper &#13;
<span class="keep-together">architecture.</span></p>&#13;
&#13;
<p>The next <code>COPY</code> directive copies files from the current directory (<em>.</em>) into the <em>/srv</em> directory (<em>.</em> with a <code>WORKDIR</code> of <em>/srv</em>). This is where the <em>.dockerignore</em> file comes into play. Normally, the <em>node_modules</em> would get copied as well, overwriting the <em>node_modules</em> that were just copied from the <code>deps</code> stage. Note that in the case of this example application, every single one of the <em>producer-*.js</em> files will get copied into the image. Technically only one of them is needed for a service to run. But the <code>COPY .</code> approach is more applicable to a real-world application.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>In general, using <code>COPY .</code> is a decent approach to copying application files into a Docker image. One caveat to be aware of is that this copies <em>every</em> file that isn’t ignored, including the <em>Dockerfile</em> itself, a potentially massive <em>.git</em> directory (if run in the project root directory). It will even copy temporary files used by your text editors!</p>&#13;
&#13;
<p>For this reason, you’ll need to be <a data-primary="Docker" data-secondary=".dockerignore file" data-secondary-sortas="dockerignore file" data-tertiary="entries" data-type="indexterm" id="idm46291186289224"/>diligent about adding entries to your <em>.dockerignore</em> file, and you’ll occasionally want to look at the filesystem of the Docker image (such as with <strong><code>docker exec &lt;name&gt; ls -la /srv</code></strong>). You should also consider building Docker images <em>only</em> on a special build server and not on a local development machine.</p>&#13;
&#13;
<p>Having specific <code>COPY</code> directives for every file that should be copied can be risky too. For example, your application might require a JSON file that is read at runtime that isn’t explicitly copied, leading to a buggy image.</p>&#13;
</div>&#13;
&#13;
<p>The <code>EXPOSE</code> directive is a <a data-primary="EXPOSE directive" data-type="indexterm" id="idm46291186283736"/><a data-primary="Docker" data-secondary="Dockerfile" data-tertiary="EXPOSE directive" data-type="indexterm" id="idm46291186283000"/>way of documenting that the image plans on listening using a specific port, in this case 1337. This doesn’t actually open the port to the outside world; instead, that is done later when a container is run from the image.</p>&#13;
&#13;
<p>The two <code>ENV</code> directives set <a data-primary="environment variables" data-secondary="HOST" data-type="indexterm" id="idm46291186280360"/><a data-primary="environment variables" data-secondary="PORT" data-type="indexterm" id="idm46291186279352"/><a data-primary="HOST environment variable" data-type="indexterm" id="idm46291186278408"/><a data-primary="PORT environment variable" data-type="indexterm" id="idm46291186277720"/>environment variables, and this time the variables are going to be used by the application itself. Specifically, the <code>HOST</code> and <code>PORT</code> environment variables are what the services have been using to decide which interface and port to listen on. The application defaults to listening for connections on the <code>127.0.0.1</code> interface. Leaving this as-is would mean that the application only listens for requests originating <em>within the Docker container</em>, not from requests generated from the host, which wouldn’t be very useful.</p>&#13;
&#13;
<p>Finally, the Dockerfile <a data-primary="Docker" data-secondary="Dockerfile" data-tertiary="CMD directive" data-type="indexterm" id="idm46291186274552"/>ends with a <code>CMD</code> directive. This is a way of declaring what command should be executed when a container is run. In this case, the <code>node</code> binary will be executed and it will run the <em>producer-http-basic.js</em> file. This command can be overridden at run time.</p>&#13;
&#13;
<p>This image is far from perfect. The official Node.js containers, while a little heavier, do provide some other niceties. For example, when they download the compiled Node.js tarballs, they also compare them against checksum values to ensure the files haven’t been tampered with. They also create a specialized user and set up filesystem permissions for running the Node.js application. It’s up to you to decide <a data-primary="Docker" data-secondary="images" data-startref="relstage" data-tertiary="release stage" data-type="indexterm" id="idm46291186270824"/><a data-primary="images, Docker" data-secondary="release stage" data-startref="relstage1" data-type="indexterm" id="idm46291186269304"/>which of these features you want for your application.</p>&#13;
<div style="page-break-after: always;"/>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space" data-pdf-bookmark="From Image to Container" data-type="sect2"><div class="sect2" id="idm46291186342952">&#13;
<h2>From Image to Container</h2>&#13;
&#13;
<p>With the Dockerfile complete, it’s <a data-primary="Docker" data-secondary="Dockerfile" data-tertiary="building images" data-type="indexterm" id="idm46291186265432"/><a data-primary="Docker" data-secondary="images" data-tertiary="building images" data-type="indexterm" id="idm46291186264184"/><a data-primary="images, Docker" data-secondary="building" data-type="indexterm" id="idm46291186262968"/>now time to build an image from the Dockerfile. The Dockerfile and its supporting files exist on disk and are usually checked into version control. The images that are generated from them are managed by the Docker daemon.</p>&#13;
&#13;
<p>Run the commands in <a data-type="xref" href="#ex_dockerfile_build">Example 5-5</a> to enter the <em>recipe-api</em> directory and then build a Docker image.</p>&#13;
<div data-type="example" id="ex_dockerfile_build">&#13;
<h5><span class="label">Example 5-5. </span>Building an image from a Dockerfile</h5>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code><code class="nb">cd </code>recipe-api&#13;
<code class="nv">$ </code>docker build -t tlhunter/recipe-api:v0.0.1 .</pre></div>&#13;
&#13;
<p>This <code>docker build</code> command <a data-primary="Docker" data-secondary="docker build command" data-type="indexterm" id="idm46291186256296"/><a data-primary="images, Docker" data-secondary="docker build command" data-type="indexterm" id="idm46291186255416"/>has one flag and one argument. The flag is the <code>-t</code> flag that represents the <em>tag</em> for the image. The tag used in this example has three parts to it, following the pattern <code>repository/name:version</code>. In this case, the repository, which is a way to namespace image names, is <em>tlhunter</em>. The name represents the actual content of the image and in this case is <em>recipe-api</em>. The version, which is used for differentiating different releases of the image, is <code>v0.0.1</code>.</p>&#13;
&#13;
<p>Regarding versions, an <a data-primary="Docker" data-secondary="images" data-tertiary="versions" data-type="indexterm" id="idm46291186249800"/><a data-primary="images, Docker" data-secondary="versions" data-type="indexterm" id="idm46291186248520"/>image doesn’t necessarily need to follow along with a particular pattern. In this case, I chose to use a value that looks like a <em>SemVer</em> version string, a value familiar to many Node.js developers. However, applications don’t usually have a SemVer version assigned to them like packages do. One common approach is to simply use an integer, one that gets incremented with each new container build. If a version isn’t supplied, Docker will supply a default version tag of <code>latest</code>. Generally, you should always supply a version.</p>&#13;
&#13;
<p>While this command runs, you’ll see the output as each of the directives in the Dockerfile builds a new layer. Each one of these layers has its hash printed, as well as the directive for that layer. The output that I get when the command has finished looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">Sending build context to Docker daemon  155.6kB&#13;
Step 1/15 : FROM node:14.8.0-alpine3.12 AS deps&#13;
 ---&gt; 532fd65ecacd&#13;
... TRUNCATED ...&#13;
Step 15/15 : CMD [ "node", "producer-http-basic.js" ]&#13;
 ---&gt; Running in d7bde6cfc4dc&#13;
Removing intermediate container d7bde6cfc4dc&#13;
 ---&gt; a99750d85d81&#13;
Successfully built a99750d85d81&#13;
Successfully tagged tlhunter/recipe-api:v0.0.1</pre>&#13;
&#13;
<p>Once the image has been built, you’re ready <a data-primary="images, Docker" data-secondary="container instances" data-type="indexterm" id="idm46291186243416"/><a data-primary="Docker" data-secondary="images" data-tertiary="container instances" data-type="indexterm" id="idm46291186242440"/>to run a container instance based off of this image. Each container instance has metadata attached to it to differentiate it from other running containers. Run the following command to create a new running container instance from your container:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker run --rm --name recipe-api-1 <code class="se">\</code>&#13;
  -p 8000:1337 tlhunter/recipe-api:v0.0.1</pre>&#13;
&#13;
<p>This command uses the <code>--rm</code> flag, which previous examples have used, to clean up the container once it’s done. The <code>--name</code> flag sets <a data-primary="containers" data-secondary="recipe-api-1" data-type="indexterm" id="idm46291186236552"/><a data-primary="recipe-api-1 container" data-type="indexterm" id="idm46291186214008"/>the name of this container to <code>recipe-api-1</code>. The <code>-p</code> flag maps the 8000 port of the host to the 1337 port within the container that the Node.js application is listening on. The final argument is the tag for the image being run.</p>&#13;
&#13;
<p>Once you’ve run the command, you’ll see some output from the service printed to the screen. The first piece of information logged is the PID of the process within the container. In this case, it prints <code>worker pid=1</code>, meaning it’s the main process within the container. The next piece of information printed is that the service is listening at <em>http://0.0.0.0:1337</em>. This is the interface and port that the Node.js service is available at <em>within the container</em>.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Keep in mind that the address the service thinks it is available at isn’t going to be the same as the address that clients will use to contact it. This can affect a service that needs to report its URL to the client (like an API providing URLs to other resources). In these cases you can provide an environment variable containing the external host and port combination for the service to relay to &#13;
<span class="keep-together">consumers.</span></p>&#13;
</div>&#13;
&#13;
<p>At this point, you’re ready to confirm that the service runs. Since the container is mapping the internal 1337 port to 8000 on the host, you’ll need to use the host’s port when making a request. Run the following command to make a request to your containerized service:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>curl http://localhost:8000/recipes/42</pre>&#13;
&#13;
<p>Once you run the command, you should see the familiar JSON data in response. If you were to change the command to use the port 1337, you would get an error that the connection was refused.</p>&#13;
&#13;
<p>Unfortunately, with the way this container is set up, you won’t be able to type Ctrl + C and have the container stop running. Instead, you’ll need to run the following command in a new terminal window to terminate the service:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker <code class="nb">kill </code>recipe-api-1</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Rebuilding and Versioning an Image" data-type="sect2"><div class="sect2" id="idm46291186266712">&#13;
<h2>Rebuilding and Versioning an Image</h2>&#13;
&#13;
<p>Now that you’ve built <a data-primary="Docker" data-secondary="images" data-tertiary="versioning" data-type="indexterm" id="imaversion"/><a data-primary="Docker" data-secondary="images" data-tertiary="rebuilding" data-type="indexterm" id="imaversion1"/>an application image and run a container, you’re ready to modify the application and produce a second version. Applications change all the time, and it’s important to be able to repackage these different versions of an application and run them. It’s also important to retain old versions of an application so that if a new version is troublesome, an old version can quickly be restored.</p>&#13;
&#13;
<p>Within the <em>recipe-api</em> directory, <a data-primary="Docker" data-secondary="docker build command" data-type="indexterm" id="idm46291186200152"/>run the <code>docker build</code> command shown in <a data-type="xref" href="#ex_dockerfile_build">Example 5-5</a> again. This time, note the layers being created when the command is run. This will serve as a baseline for examining the effects of building an application and how modifications will change the resulting Docker images. In my case, I see the following layers:</p>&#13;
&#13;
<pre data-type="programlisting">532fd65ecacd, bec6e0fc4a96, 58341ced6003, dd6cd3c5a283, e7d92cdc71fe,&#13;
4f2ea97869f7, b5b203367e62, 0dc0f7fddd33, 4c9a03ee9903, a86f6f94fc75,&#13;
cab24763e869, 0efe3d9cd543, 9104495370ba, 04d6b8f0afce, b3babfadde8e</pre>&#13;
&#13;
<p>Next, make a change to the .<em>recipe-api/producer-http-basic.js</em> file (the entrypoint to the application) by replacing the route handler with the code in <a data-type="xref" href="#ex_docker_recipe_route">Example 5-6</a>.</p>&#13;
<div data-type="example" id="ex_docker_recipe_route">&#13;
<h5><span class="label">Example 5-6. </span><em>recipe-api/producer-http-basic.js</em>, truncated</h5>&#13;
&#13;
<pre data-code-language="javascript" data-type="programlisting"><code class="nx">server</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/recipes/:id'</code><code class="p">,</code> <code class="nx">async</code> <code class="p">(</code><code class="nx">req</code><code class="p">,</code> <code class="nx">reply</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>&#13;
  <code class="k">return</code> <code class="s2">"Hello, world!"</code><code class="p">;</code>&#13;
<code class="p">});</code></pre></div>&#13;
&#13;
<p>This time, run the <code>build</code> command from <a data-type="xref" href="#ex_dockerfile_build">Example 5-5</a>. Keep an eye on the output and modify the command to use a version tag of <em>v0.0.2</em>. In my case, I now see the following layers:</p>&#13;
&#13;
<pre data-type="programlisting">532fd65ecacd, bec6e0fc4a96, 58341ced6003, dd6cd3c5a283, e7d92cdc71fe,&#13;
4f2ea97869f7, b5b203367e62, 0dc0f7fddd33, 4c9a03ee9903, a86f6f94fc75,&#13;
7f6f49f5bc16, 4fc6b68804c9, df073bd1c682, f67d0897cb11, 9b6514336e72</pre>&#13;
&#13;
<p>In this case, the final five layers of the image have changed. Specifically, everything from the <code>COPY . .</code> line and below.</p>&#13;
&#13;
<p>Next, revert the changes to the <em>producer-http-basic.js</em> file, restoring the request handler to its previous state. Then, modify the application build process at an earlier stage by running the following command:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>npm install --save-exact left-pad@1.3.0</pre>&#13;
&#13;
<p>By installing a new package, the <a data-primary="Docker" data-secondary="images" data-tertiary="layers" data-type="indexterm" id="idm46291186103928"/><a data-primary="images, Docker" data-secondary="layers" data-type="indexterm" id="idm46291186102952"/>contents of the <em>package.json</em> and <em>package-lock.json</em> files will be different. Because of this, Docker will know not to reuse the existing layer correlating with the early <code>COPY</code> directive, which copies those files to the <code>deps</code> stage. It knows not to reuse the cached layer because the hash of the filesystem represented in the layer will be different. Run the <a data-type="xref" href="#ex_dockerfile_build">Example 5-5</a> command again, this time with a &#13;
<span class="keep-together">version</span> tag of <em>v0.0.3</em>, to see the effects that the changes have had on the image build process. In my case, the layers now look like this:</p>&#13;
&#13;
<pre data-type="programlisting">532fd65ecacd, bec6e0fc4a96, 959c7f2c693b, 6e9065bacad0, e7d92cdc71fe,&#13;
4f2ea97869f7, b5b203367e62, 0dc0f7fddd33, 4c9a03ee9903, b97b002f4734,&#13;
f2c9ac237a1c, f4b64a1c5e64, fee5ff92855c, 638a7ff0c240, 12d0c7e37935</pre>&#13;
&#13;
<p>In this case, the last six layers of the <code>release</code> image have changed. This means that everything from the <code>COPY --from=deps</code> directive and below has changed. Also, the last two layers of the <code>deps</code> stage have also changed. This part isn’t as important since the layers in the <code>deps</code> stage don’t directly contribute to the overall image based on the <code>release</code> stage.</p>&#13;
&#13;
<p>So, what exactly does this difference of five layers versus six layers mean? Well, each layer contributes different filesystem entries to the overall stack of layers representing the Docker image. Run the following command to view the size of each of the layers of the <em>v0.0.1</em> version of your application:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker <code class="nb">history </code>tlhunter/recipe-api:v0.0.1</pre>&#13;
&#13;
<p>Some of the directives don’t contribute to the filesystem size and have a size of 0B. For example, the <code>ENV</code>, <code>CMD</code>, <code>EXPOSE</code>, and <code>WORKDIR</code> directives correlate to layers that don’t have file sizes. Others do contribute. For example, the <code>FROM ... release</code> directive contributes about 5.6MB to the resulting image. The <code>RUN apk add</code> directive adds 80MB. The actual application code, resulting from the <code>COPY . .</code> directive, only contributes about <code>140kB</code> to the image. However, the part that is likely to vary the most between application updates is the <code>COPY --from=deps</code> directive. For this example application, the <em>node_modules</em> directory contains tons of entries not needed by the application, since it contains packages for other project files, such as the GraphQL and gRPC packages. In this case, it weighs in at about 68MB. Most projects written in Node.js consist of around 3% first-party application code and about <a class="orm:hideurl" href="https://slides.com/seldo/npm-and-the-future-of-javascript/#/8">97% third-party code</a>, so this file size ratio isn’t that far-fetched.</p>&#13;
&#13;
<p><a data-type="xref" href="#table_docker_image_layers">Table 5-1</a> contains a summary of the three different application versions that you have created. The <em>Layer</em> column contains the number of the layer and a shorthand reference to the directive being run. The <em>Size</em> column contains the size of that layer. Technically, the layer sizes across the three different versions of the application do vary slightly, like when the <code>left-pad</code> package was installed, but the size difference is mostly negligible so that only the size of the layer in the <em>v0.0.1</em> image is shown. Finally, the columns under the version numbers contain the hash of that layer. The hash is in bold if it has diverged from a previous version.</p>&#13;
&#13;
<p>The effect of changing application code, which is layer 11 in the <em>v0.0.2</em> column, is that an additional 138kB of space is required when deploying image <em>v0.0.2</em> to a server that already has image <em>v0.0.1</em>. By changing the content of a layer, every subsequent layer that depends on it will also change. Since layers 12 through 15 don’t contribute to the overall file size, it results in only a 138kB increase.</p>&#13;
<table id="table_docker_image_layers">&#13;
<caption><span class="label">Table 5-1. </span>Docker image layers comparison</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Layer</th>&#13;
<th>Size</th>&#13;
<th>v0.0.1</th>&#13;
<th>v0.0.2</th>&#13;
<th>v0.0.3</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>1: <code>FROM node AS deps</code></p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p><code>532fd65ecacd</code></p></td>&#13;
<td><p><code>532fd65ecacd</code></p></td>&#13;
<td><p><code>532fd65ecacd</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>2: <code>WORKDIR /srv</code></p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p><code>bec6e0fc4a96</code></p></td>&#13;
<td><p><code>bec6e0fc4a96</code></p></td>&#13;
<td><p><code>bec6e0fc4a96</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>3: <code>COPY package*</code></p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p><code>58341ced6003</code></p></td>&#13;
<td><p><code>58341ced6003</code></p></td>&#13;
<td><p><strong><code>959c7f2c693b</code></strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>4: <code>RUN npm ci</code></p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p><code>dd6cd3c5a283</code></p></td>&#13;
<td><p><code>dd6cd3c5a283</code></p></td>&#13;
<td><p><strong><code>6e9065bacad0</code></strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>5: <code>FROM alpine AS release</code></p></td>&#13;
<td><p>5.6MB</p></td>&#13;
<td><p><code>e7d92cdc71fe</code></p></td>&#13;
<td><p><code>e7d92cdc71fe</code></p></td>&#13;
<td><p><code>e7d92cdc71fe</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>6: <code>ENV V</code></p></td>&#13;
<td><p>0</p></td>&#13;
<td><p><code>4f2ea97869f7</code></p></td>&#13;
<td><p><code>4f2ea97869f7</code></p></td>&#13;
<td><p><code>4f2ea97869f7</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>7: <code>ENV FILE</code></p></td>&#13;
<td><p>0</p></td>&#13;
<td><p><code>b5b203367e62</code></p></td>&#13;
<td><p><code>b5b203367e62</code></p></td>&#13;
<td><p><code>b5b203367e62</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>8: <code>RUN apk ...</code></p></td>&#13;
<td><p>79.4MB</p></td>&#13;
<td><p><code>0dc0f7fddd33</code></p></td>&#13;
<td><p><code>0dc0f7fddd33</code></p></td>&#13;
<td><p><code>0dc0f7fddd33</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>9: <code>WORKDIR /srv</code></p></td>&#13;
<td><p>0</p></td>&#13;
<td><p><code>4c9a03ee9903</code></p></td>&#13;
<td><p><code>4c9a03ee9903</code></p></td>&#13;
<td><p><code>4c9a03ee9903</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>10: <code>COPY node_modules</code></p></td>&#13;
<td><p>67.8MB</p></td>&#13;
<td><p><code>a86f6f94fc75</code></p></td>&#13;
<td><p><code>a86f6f94fc75</code></p></td>&#13;
<td><p><strong><code>b97b002f4734</code></strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>11: <code>COPY . .</code></p></td>&#13;
<td><p>138kB</p></td>&#13;
<td><p><code>cab24763e869</code></p></td>&#13;
<td><p><strong><code>7f6f49f5bc16</code></strong></p></td>&#13;
<td><p><strong><code>f2c9ac237a1c</code></strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>12: <code>EXPOSE</code></p></td>&#13;
<td><p>0</p></td>&#13;
<td><p><code>0efe3d9cd543</code></p></td>&#13;
<td><p><strong><code>4fc6b68804c9</code></strong></p></td>&#13;
<td><p><strong><code>f4b64a1c5e64</code></strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>13: <code>ENV HOST</code></p></td>&#13;
<td><p>0</p></td>&#13;
<td><p><code>9104495370ba</code></p></td>&#13;
<td><p><strong><code>df073bd1c682</code></strong></p></td>&#13;
<td><p><strong><code>fee5ff92855c</code></strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>14: <code>ENV PORT</code></p></td>&#13;
<td><p>0</p></td>&#13;
<td><p><code>04d6b8f0afce</code></p></td>&#13;
<td><p><strong><code>f67d0897cb11</code></strong></p></td>&#13;
<td><p><strong><code>638a7ff0c240</code></strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>15: <code>CMD</code></p></td>&#13;
<td><p>0</p></td>&#13;
<td><p><code>b3babfadde8e</code></p></td>&#13;
<td><p><strong><code>9b6514336e72</code></strong></p></td>&#13;
<td><p><strong><code>12d0c7e37935</code></strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Cost per Deploy</p></td>&#13;
<td/>&#13;
<td><p>N/A</p></td>&#13;
<td><p>138kB</p></td>&#13;
<td><p>68MB</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The effect of changing the installed packages, which is layer 10 of the <em>v0.0.3</em> column, is that an additional 67.8MB of data will need to be sent to a server that already has <em>v0.0.2</em>, or even <em>v0.0.1</em>, of the image installed.</p>&#13;
&#13;
<p>Typically, Node.js application code will change much more frequently than changes to the <em>package.json</em> file (and, therefore, the entries in <em>node_modules</em>). The operating system packages installed by the <code>apk</code> command are even less likely to change. For this reason, you usually want the directive to copy the application files to be later than the directive to copy <em>node_modules</em>, which itself should be later than the directive to install operating system packages.</p>&#13;
&#13;
<p>One final note is that you’ll often see Docker containers tagged with a version of <span class="keep-together"><code>latest</code></span>. If you wanted to <a data-primary="Docker" data-secondary="containers" data-tertiary="tags" data-type="indexterm" id="idm46291185946264"/><a data-primary="containers" data-secondary="Docker" data-tertiary="tags" data-type="indexterm" id="idm46291185945016"/>make such a tag available when building images, you can build each image twice. The first time you build the image, supply a version string for it. Then the second time, don’t supply a version string. When the version is omitted, Docker will fill in <code>latest</code>, but this can get confusing. For example, if you were to tag an image as <code>v0.1.0</code> and also tag it as <code>latest</code>, and then go back and tag an image as <code>v0.0.4</code> and tag that as <code>latest</code>, then the <code>latest</code> tag wouldn’t refer to the highest &#13;
<span class="keep-together">version</span> of the image (<code>v0.1.0</code>); it would instead refer to the most recently generated image (<code>v0.0.4</code>). For that reason, it’s sometimes best to not tag an image as <code>latest</code> and only publish images with exact version <a data-primary="services" data-secondary="containerizing" data-startref="servcont" data-type="indexterm" id="idm46291185938728"/><a data-primary="Docker" data-secondary="images" data-startref="imaversion" data-tertiary="versioning" data-type="indexterm" id="idm46291185937480"/><a data-primary="Docker" data-secondary="images" data-startref="imaversion1" data-tertiary="rebuilding" data-type="indexterm" id="idm46291185935992"/>numbers.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Basic Orchestration with Docker Compose" data-type="sect1"><div class="sect1" id="idm46291186687624">&#13;
<h1>Basic Orchestration with Docker Compose</h1>&#13;
&#13;
<p>Docker is a convenient <a data-primary="Docker Compose" data-type="indexterm" id="dockcomp"/><a data-primary="dependencies" data-secondary="Docker Compose" data-type="indexterm" id="dockcomp1"/>tool for packaging the dependencies of a service, whether it be a stable backing store like Postgres or a highly dynamic Node.js application that changes daily. Often, one of these services will depend on another service to run. In fact, <a data-primary="web-api service" data-secondary="dependencies" data-type="indexterm" id="idm46291185930904"/><a data-primary="recipe-api" data-secondary="dependencies" data-type="indexterm" id="idm46291185929960"/><a data-primary="dependencies" data-secondary="web-api service" data-type="indexterm" id="idm46291185929016"/><a data-primary="dependencies" data-secondary="recipe-api" data-type="indexterm" id="idm46291185928072"/>the <em>web-api</em> and <em>recipe-api</em> services that you’ve been building so far are examples of this very situation.</p>&#13;
&#13;
<p>So far, with these services, you’ve been required to manually copy and paste shell commands to spin up dependent services, but managing such a collection of scripts for a project can become unruly. Each of the <code>docker run</code> commands can require several configuration flags, especially if they rely on volume mounts and complex port assignments.</p>&#13;
&#13;
<p>Sometimes, multiple services are packed into the same container. The <em>sebp/elk</em> image used in <a data-type="xref" href="ch04.html#ch_monitoring_sec_log">“Logging with ELK”</a> does just this, providing Elasticsearch, Logstash, and Kibana all in one place. This approach sometimes makes sense when using closely related services, and it certainly makes instantiating such services easier on a local development machine. But when working with application code, it doesn’t make as much sense to bundle backing services with the main app.</p>&#13;
&#13;
<p>Consider a Node.js service that <a data-primary="Redis" data-type="indexterm" id="idm46291185922424"/>depends on Redis. Bundling Redis with the app would make it easier to run the app locally. But in production, multiple services might need to use the same Redis instance, and this convenience falls apart. You’d then need to either have two Dockerfiles created—one combining Redis for local development and one without it for production—or have a single Dockerfile that optionally starts Redis if a flag is set. The approach with multiple Dockerfiles means two files need to be maintained—files that might accidentally diverge. The approach with a single Dockerfile means you’d be shipping dead weight to production.</p>&#13;
&#13;
<p>Luckily, there’s another tool available for managing these container relationships. In fact, this tool was already used previously in <a data-type="xref" href="ch04.html#ch_monitoring_sec_alert_subsec_cabot">“Running Cabot via Docker”</a>. This tool is <em>Docker Compose</em>. Docker Compose is built into Docker Desktop. If you’re using Docker on Linux, you will need to install it separately. Take a look at <a data-type="xref" href="app02.html#appendix_install_docker">Appendix B</a> for more information.</p>&#13;
&#13;
<p>Docker Compose allows for the configuration of multiple dependant Docker containers by using a single declarative <em>docker-compose.yml</em> file. This file contains the same configuration data that can be represented as <code>docker run</code> flags, as well as other information, like the dependency graph between those containers.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Composing Node.js Services" data-type="sect2"><div class="sect2" id="idm46291185916520">&#13;
<h2>Composing Node.js Services</h2>&#13;
&#13;
<p>Now it’s time to convert that <a data-primary="services" data-secondary="composing" data-type="indexterm" id="idm46291185914312"/>pair of applications you’ve been working on to run with Docker Compose. For this section you’ll work with the Zipkin variant of the services that you created in <a data-type="xref" href="ch04.html#ch_monitoring_sec_trace">“Distributed Request Tracing with Zipkin”</a>. The dependency graph for these services is visualized in <a data-type="xref" href="#fig_docker_compose_zipkin">Figure 5-3</a>. In this case, the <em>web-api</em> service depends on the <em>recipe-api</em> service, and <a data-primary="recipe-api" data-secondary="Zipkin and" data-type="indexterm" id="idm46291185910648"/>both of those services depend on Zipkin.</p>&#13;
&#13;
<figure><div class="figure" id="fig_docker_compose_zipkin">&#13;
<img alt="Consumer depends on Producer, Producer and Consumer depends on Zipkin" src="assets/dsnj_0503.png"/>&#13;
<h6><span class="label">Figure 5-3. </span>Consumer, producer, and Zipkin dependency graph</h6>&#13;
</div></figure>&#13;
&#13;
<p>Once you’re done with this section, you’ll be able to run all three services by executing a single command. Within a larger organization, this approach can be used to ease local development for part of the backend stack.</p>&#13;
&#13;
<p>First, copy the <em>recipe-api/.dockerignore</em> file that you created in <a data-type="xref" href="#ex_dockerignore">Example 5-1</a> to <em>web-api/.dockerignore</em>. This file is rather generic and is useful for both applications.</p>&#13;
&#13;
<p>Next, you’ll create a simpler variant of a Dockerfile. This version doesn’t do all the powerful multistage work to create a slim image like what was covered in <a data-type="xref" href="#ch_containers_subsec_node">“Containerizing a Node.js Service”</a>. But it is simple enough to quickly get two new applications up and running. Create a file at <em>recipe-api/Dockerfile-zipkin</em> containing the content in <a data-type="xref" href="#ex_dockerfile_zipkin">Example 5-7</a>.</p>&#13;
<div data-type="example" id="ex_dockerfile_zipkin">&#13;
<h5><span class="label">Example 5-7. </span><em>recipe-api/Dockerfile-zipkin</em></h5>&#13;
&#13;
<pre data-type="programlisting">FROM node:14.8.0-alpine3.12&#13;
WORKDIR /srv&#13;
COPY package*.json ./&#13;
RUN npm ci --only=production&#13;
COPY . .&#13;
CMD [ "node", "producer-http-zipkin.js" ] # change for web-api</pre></div>&#13;
&#13;
<p>Once you’ve created that file, copy it to <em>web-api/Dockerfile-zipkin</em> then modify the <code>CMD</code> directive on the last line to execute the correct <em>consumer-http-zipkin.js</em> file.</p>&#13;
&#13;
<p>When certain commands like <code>docker build</code> are run, they assume that configuration happens using a file named <em>Dockerfile</em>, but you already have a <em>Dockerfile</em> in <em>recipe-api</em> that runs the <em>producer-http-basic.js</em> service. In cases like this where a project has &#13;
<span class="keep-together">multiple</span> configurations, the convention is to name the files <em>Dockerfile-*</em>. The various <code>docker</code> subcommands accept a flag to specify a different Dockerfile.</p>&#13;
&#13;
<p>With the preliminary work out of the <a data-primary="docker-compose.yml file" data-type="indexterm" id="idm46291185893224"/>way, you’re now ready to start creating the <em>docker-compose.yml</em> file. If you work on a service that depends on other services, you might find yourself checking this file into the source code repository. In this case, create the file in the root of your <em>distributed-node/</em> directory. Then, begin the file by adding the content from <a data-type="xref" href="#ex_docker_compose_1">Example 5-8</a> to it.</p>&#13;
<div data-type="example" id="ex_docker_compose_1">&#13;
<h5><span class="label">Example 5-8. </span><em>docker-compose.yml</em>, part one</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">version</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">3.7</code><code class="s">"</code><code>&#13;
</code><code class="nt">services</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">zipkin</code><code class="p">:</code><code> </code><a class="co" href="#callout_containers_CO1-1" id="co_containers_CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>    </code><code class="nt">image</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">openzipkin/zipkin-slim:2.19</code><code> </code><a class="co" href="#callout_containers_CO1-2" id="co_containers_CO1-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>    </code><code class="nt">ports</code><code class="p">:</code><code> </code><a class="co" href="#callout_containers_CO1-3" id="co_containers_CO1-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>      </code><code class="p-Indicator">-</code><code> </code><code class="s">"</code><code class="s">127.0.0.1:9411:9411</code><code class="s">"</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_containers_CO1-1" id="callout_containers_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This line defines a service named “zipkin.”</p></dd>&#13;
<dt><a class="co" href="#co_containers_CO1-2" id="callout_containers_CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>This is the name of the image.</p></dd>&#13;
<dt><a class="co" href="#co_containers_CO1-3" id="callout_containers_CO1-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Port mapping for this service.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This is just the start of the Docker <a data-primary="Docker Compose" data-secondary="version key" data-type="indexterm" id="idm46291185848472"/>Compose file. The first <code>version</code> key is how the file declares which compose file version it is using. The official Docker website <a class="orm:hideurl" href="https://docs.docker.com/compose/compose-file/">maintains a Compose version to Docker version</a> compatibility matrix. Docker occasionally adds backwards-incompatible features. In this case, the file is using version 3.7, which is compatible with at least Docker version 18.06.0.</p>&#13;
&#13;
<p>After that is the <code>services</code> key, <a data-primary="Docker Compose" data-secondary="services key" data-type="indexterm" id="idm46291185817592"/>which contains a list of services managed by the file. A service basically refers to a container, though a service can technically refer to multiple replicated container instances. In this first part of the Compose file, the <em>zipkin</em> service has been declared. Within each service definition are further key/value pairs, like the two used for the <em>zipkin</em> service.</p>&#13;
&#13;
<p>The <code>image</code> key is one way to refer to <a data-primary="Docker Compose" data-secondary="image key" data-type="indexterm" id="idm46291185814488"/>the image that will be used as a template for the service. In the case of the <em>zipkin</em> service, the <em>openzipkin/zipkin-slim</em> image will be used. This value is equivalent to the argument passed into <code>docker run</code>.</p>&#13;
&#13;
<p>The <code>ports</code> key is used to <a data-primary="Docker Compose" data-secondary="ports key" data-type="indexterm" id="idm46291185811528"/>define port mappings. In this case, port 9411 in the container will map to port 9411 in the host, and it will only be accessible from within the host. This entry correlates with the <code>-p</code> flag for the <code>docker run</code> command.</p>&#13;
&#13;
<p>Now that the first service has been defined, add the content from <a data-type="xref" href="#ex_docker_compose_2">Example 5-9</a> to your <em>docker-compose.yml</em> file for the second service.<sup><a data-type="noteref" href="ch05.html#idm46291185807640" id="idm46291185807640-marker">2</a></sup></p>&#13;
<div data-type="example" id="ex_docker_compose_2">&#13;
<h5><span class="label">Example 5-9. </span><em>docker-compose.yml</em>, part two</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="c1">## note the two space indent</code><code>&#13;
</code><code>  </code><code class="nt">recipe-api</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">build</code><code class="p">:</code><code> </code><a class="co" href="#callout_containers_CO2-1" id="co_containers_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>      </code><code class="nt">context</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">./recipe-api</code><code>&#13;
</code><code>      </code><code class="nt">dockerfile</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Dockerfile-zipkin</code><code>&#13;
</code><code>    </code><code class="nt">ports</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="p-Indicator">-</code><code> </code><code class="s">"</code><code class="s">127.0.0.1:4000:4000</code><code class="s">"</code><code>&#13;
</code><code>    </code><code class="nt">environment</code><code class="p">:</code><code> </code><a class="co" href="#callout_containers_CO2-2" id="co_containers_CO2-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>      </code><code class="nt">HOST</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">0.0.0.0</code><code>&#13;
</code><code>      </code><code class="nt">ZIPKIN</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">zipkin:9411</code><code>&#13;
</code><code>    </code><code class="nt">depends_on</code><code class="p">:</code><code> </code><a class="co" href="#callout_containers_CO2-3" id="co_containers_CO2-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>      </code><code class="p-Indicator">-</code><code> </code><code class="l-Scalar-Plain">zipkin</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_containers_CO2-1" id="callout_containers_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Instead of using a named image, a path to a Dockerfile is provided.</p></dd>&#13;
<dt><a class="co" href="#co_containers_CO2-2" id="callout_containers_CO2-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Environment variable pairs used by the service.</p></dd>&#13;
<dt><a class="co" href="#co_containers_CO2-3" id="callout_containers_CO2-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>The <em>zipkin</em> service should be started before this container.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This service entry represents the <em>recipe-api</em> service and is a bit more complicated than the <em>zipkin</em> service.</p>&#13;
&#13;
<p>First, the <code>image</code> entry has been <a data-primary="Docker Compose" data-secondary="build object" data-type="indexterm" id="idm46291185716552"/>replaced with a more complex <code>build</code> object. <code>image</code> is useful for referring to an image already built somewhere else. However, the <code>build</code> object allows Docker Compose to build a Dockerfile into an image at the time when Docker Compose is invoked. This <code>build</code> object has two keys within it. The first is <code>context</code>, which refers to the directory to build the image in, in this case the <em>recipe-api</em> subdirectory. The <code>dockerfile</code> key is only required when the configuration file has a name other than <em>Dockerfile</em>, and in this case it points to the <em>Dockerfile-zipkin</em> file.</p>&#13;
&#13;
<p>The <code>environment</code> object <a data-primary="Docker Compose" data-secondary="environment object" data-type="indexterm" id="idm46291185711368"/>contains key/value pairs where the key is the name of the environment variable and the value is the environment variable’s value. In this case, the <code>HOST</code> value is overridden to 0.0.0.0 so that the application will accept requests coming from outside the Docker container. The <code>ZIPKIN</code> environment <a data-primary="ZIPKIN environment variable" data-type="indexterm" id="idm46291185709320"/><a data-primary="environment variables" data-secondary="ZIPKIN" data-type="indexterm" id="idm46291185708712"/>variable refers to the host/port combination that the application will communicate with, in this case a hostname of <em>zipkin</em> and a port of 9411.</p>&#13;
&#13;
<p>That hostname might look a little suspicious at first. Where is it coming from? Shouldn’t Docker be using something like <code>localhost</code> instead? By default, any Docker service can reach any other service using the service name. The <code>depends_on</code> directive ensures containers are started in a specific order. There are also directives available to change the name of one container’s host in another container.</p>&#13;
&#13;
<p>You’re now ready to add the final service definition to your <em>docker-compose.yml</em> file. Add the content from <a data-type="xref" href="#ex_docker_compose_3">Example 5-10</a> to describe the <em>web-api</em> service.</p>&#13;
<div data-type="example" id="ex_docker_compose_3">&#13;
<h5><span class="label">Example 5-10. </span><em>docker-compose.yml</em>, part three</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="c1">## note the two space indent</code>&#13;
  <code class="nt">web-api</code><code class="p">:</code>&#13;
    <code class="nt">build</code><code class="p">:</code>&#13;
      <code class="nt">context</code><code class="p">:</code> <code class="l-Scalar-Plain">./web-api</code>&#13;
      <code class="nt">dockerfile</code><code class="p">:</code> <code class="l-Scalar-Plain">Dockerfile-zipkin</code>&#13;
    <code class="nt">ports</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="s">"127.0.0.1:3000:3000"</code>&#13;
    <code class="nt">environment</code><code class="p">:</code>&#13;
      <code class="nt">TARGET</code><code class="p">:</code> <code class="l-Scalar-Plain">recipe-api:4000</code>&#13;
      <code class="nt">ZIPKIN</code><code class="p">:</code> <code class="l-Scalar-Plain">zipkin:9411</code>&#13;
      <code class="nt">HOST</code><code class="p">:</code> <code class="l-Scalar-Plain">0.0.0.0</code>&#13;
    <code class="nt">depends_on</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">zipkin</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">recipe-api</code></pre></div>&#13;
&#13;
<p>With the final piece of the puzzle in place, tell Docker Compose to start your services by running the following command:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker-compose up</pre>&#13;
&#13;
<p>Once you do that, you’ll need to wait a minute until the output stabilizes. During this time, each of the three services will be started. Once things have calmed down, run the <a data-primary="curl command" data-type="indexterm" id="idm46291185666232"/><a data-primary="commands" data-secondary="curl" data-type="indexterm" id="idm46291185665624"/>three <code>curl</code> commands one after another in another terminal window to generate some requests:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>curl http://localhost:3000/&#13;
<code class="nv">$ </code>curl http://localhost:4000/recipes/42&#13;
<code class="nv">$ </code>curl http://localhost:9411/zipkin/</pre>&#13;
&#13;
<p>The first <code>curl</code> command confirms that <a data-primary="web-api service" data-secondary="curl command and" data-type="indexterm" id="idm46291185646488"/>the <em>web-api</em> service is listening for requests. The following command confirms that the <em>recipe-api</em> is also listening for requests. The final command confirms that Zipkin is running and also listening for requests.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Assuming this Docker Compose file was created to <a data-primary="web-api service" data-secondary="bootstrapping" data-type="indexterm" id="idm46291185660152"/>bootstrap the <em>web-api</em> service for local development, you technically do not need to expose the <em>zipkin</em> and <em>recipe-api</em> ports <a data-primary="recipe-api" data-secondary="ports" data-type="indexterm" id="idm46291185656968"/>to the host. In other words, omitting the <code>ports</code> field for <em>recipe-api</em> would still allow <em>web-api</em> to make requests to <em>recipe-api</em>. But in my experience, exposing the ports of the upstream services makes it much easier to debug a faulty service.</p>&#13;
</div>&#13;
&#13;
<p>Docker Compose provides a convenient way to describe the configuration and relationships between multiple containers. However, it describes such relationships in a fairly static manner. It doesn’t help with things like dynamically increasing or decreasing the number of running services, or with deploying updated versions of a service. In short, it’s great for local development but is a bit lacking when it comes to deploying dynamic applications to production. <a data-type="xref" href="ch07.html#ch_kubernetes">Chapter 7</a> describes a more robust approach for deploying applications to production.</p>&#13;
&#13;
<p>At this point, you’re free to remove the services that were created by Docker Compose. Switch to the terminal window where you have it running and press Ctrl + C to kill it. Once that’s done, run the <a data-primary="Docker Compose" data-startref="dockcomp" data-type="indexterm" id="idm46291185651576"/><a data-primary="dependencies" data-secondary="Docker Compose" data-startref="dockcomp1" data-type="indexterm" id="idm46291185650600"/>following command to remove the services:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker rm distributed-node_web-api_1 <code class="se">\</code>&#13;
  distributed-node_recipe-api_1 distributed-node_zipkin_1</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Internal Docker Registry" data-type="sect1"><div class="sect1" id="ch_containers_subsec_registry">&#13;
<h1>Internal Docker Registry</h1>&#13;
&#13;
<p>A <em>Docker registry</em> is a place where <a data-primary="Docker" data-secondary="registry" data-type="indexterm" id="dockreg"/>Docker images and their accompanying layers can be stored. By default, the Docker CLI is configured to make use of <a class="orm:hideurl" href="https://hub.docker.com/">Docker Hub</a>, the official public registry of Docker. Throughout this book you’ve been downloading images hosted on Docker Hub, everything from the ELK stack to the official Node.js images. The convention in Docker-land is that open source projects are expected to have their images available on Docker Hub.</p>&#13;
&#13;
<p>This works great for uploading and downloading public, open source projects. You can even create an account with Docker Hub, and as of this writing, you can use it to host one private repository for free. You can also choose to upgrade to a paid account to host even more private repositories, currently for the cost of about one dollar per repository.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>The <code>repository/name:version</code> convention that you’ve been working with so far is actually shorthand for a longer version of the command, <code>server/repository/name:version</code>. When the <code>server</code> part is missing, the Docker CLI defaults to using the Docker Hub repository of <em>docker.io</em>. The <code>repository</code> part also has a default value. As an example of this, the command <strong><code>docker pull node:14.8.0-alpine3.12</code></strong> can also be represented using the more terse version of <strong><code>docker pull docker.io/library/node:14.8.0-alpine3.12</code></strong>.</p>&#13;
</div>&#13;
&#13;
<p>Many organizations instead choose to host their own internal Docker Registry. Depending on the number of repositories, this might prove to be more or less &#13;
<span class="keep-together">expensive</span> than using Docker Hub. Noncost requirements also come into play. For example, the ability to lock up the service behind a corporate firewall for security/compliance purposes may be important. Many organizations require the ability to deploy applications even when external <a data-primary="Docker" data-secondary="registry" data-startref="dockreg" data-type="indexterm" id="idm46291185563608"/>public services like Docker Hub may be down or &#13;
<span class="keep-together">unreachable.</span></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running the Docker Registry" data-type="sect2"><div class="sect2" id="idm46291185561576">&#13;
<h2>Running the Docker Registry</h2>&#13;
&#13;
<p>Docker provides <a data-primary="Docker" data-secondary="registry" data-tertiary="running" data-type="indexterm" id="dockregrun"/>an official <a class="orm:hideurl" href="https://docs.docker.com/registry/">Docker Registry</a> Docker image that can be used to run a self-hosted service for storing Docker images. In turn, the Docker CLI utilities can be configured to communicate with this registry, allowing you and others in your organization to store and interact with private images.</p>&#13;
&#13;
<p>Docker hasn’t been the best approach for running many of the backing services you’ve worked with so far, assuming they require production traffic. For example, Graphite and StatsD might receive such high load in production—receiving requests from dozens of service instances—that the overhead of running them inside Docker might not let them keep up. The Docker Registry, however, doesn’t receive load based on the amount of traffic your public-facing application receives. Instead, it might only receive hundreds of requests per day as images are built and deployed. For that reason it’s perfectly fine to run the Docker Registry within a Docker container.</p>&#13;
&#13;
<p>Run the following command to start a copy of the Docker Registry:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker run -d <code class="se">\</code>&#13;
  --name distnode-registry <code class="se">\</code>&#13;
  -p 5000:5000 <code class="se">\</code>&#13;
  --restart<code class="o">=</code>always <code class="se">\</code>&#13;
  -v /tmp/registry:/var/lib/registry <code class="se">\</code>&#13;
  registry:2.7.1</pre>&#13;
&#13;
<p>This command is <em>almost</em> suitable for production use, though you would need to mount the volume somewhere more permanent than <em>/mnt/</em>. You would also want to keep it from being publicly accessible, to enable TLS termination, and even to enable authentication before putting anything sensitive on it.</p>&#13;
&#13;
<p>The <code>-d</code> flag forks the service to the background. This is useful in a production setting, though if you have problems getting the registry to start, you might want to omit &#13;
<span class="keep-together">that flag.</span></p>&#13;
&#13;
<p>Now that your registry is up and running, it’s time to publish some of the images you’ve been working on. Previously, in <a data-type="xref" href="#ch_containers_subsec_node">“Containerizing a Node.js Service”</a>, you created three versions of the same <em>recipe-api</em> application. You’ll use those tagged images to supply the registry with some fresh data.</p>&#13;
&#13;
<p>There are two sets of commands that you’ll need to run for each of the tagged images. The first is <code>docker image tag</code>, which is a way to assign a new tag to an already tagged image. This is useful for specifying which server a tagged image should be published to, such as your new Docker Registry service. Run the following command three times, once for each of <a data-primary="Docker" data-secondary="registry" data-startref="dockregrun" data-tertiary="running" data-type="indexterm" id="idm46291185527880"/>the versions of your application that you created earlier:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="c"># run for each of v0.0.1, v0.0.2, v0.0.3</code>&#13;
<code class="nv">$ </code>docker image tag tlhunter/recipe-api:v0.0.1 <code class="se">\</code>&#13;
  localhost:5000/tlhunter/recipe-api:v0.0.1</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pushing and Pulling to the Registry" data-type="sect2"><div class="sect2" id="idm46291185560952">&#13;
<h2>Pushing and Pulling to the Registry</h2>&#13;
&#13;
<p>Once that’s done, you’re <a data-primary="Docker" data-secondary="registry" data-tertiary="pushing/pulling from" data-type="indexterm" id="regpush"/>just about ready to publish the images that you’ve built on your local development machine to the Docker Registry. Technically, you’re running the registry on the same machine on which you’ve built the images, but these commands do work if you’re running the registry on a remote machine. In fact, even when you’re running the registry service locally, it’s still isolated from the Docker &#13;
<span class="keep-together">daemon</span> on your local machine.</p>&#13;
&#13;
<p>Before you run the commands, recall the conclusion regarding image layer sizes that was covered in <a data-type="xref" href="#table_docker_image_layers">Table 5-1</a>. According to that data, the added cost of deploying <em>v0.0.2</em> after <em>v0.0.1</em> is in the hundreds of kilobytes. However, deploying <em>v0.0.3</em> after deploying <em>v0.0.2</em> is in the tens of megabytes. Keep this in mind when you run the next set of commands.</p>&#13;
&#13;
<p>The commands you’ll <a data-primary="Docker" data-secondary="docker push command" data-type="indexterm" id="idm46291185508760"/><a data-primary="commands" data-secondary="docker push" data-type="indexterm" id="idm46291185485864"/>use to send the images to the Docker Registry begin with <code>docker push</code>. This is a lot like running <code>git push</code> or <code>npm publish</code>, and it will send a local copy of the image to the remote server. Run the following command three times, once for each version of your application:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="c"># run for each of v0.0.1, v0.0.2, v0.0.3</code>&#13;
<code class="nv">$ </code><code class="nb">time </code>docker push localhost:5000/tlhunter/recipe-api:v0.0.1</pre>&#13;
&#13;
<p>This command has been prefixed with <a data-primary="time command" data-type="indexterm" id="idm46291185479688"/><a data-primary="commands" data-secondary="time" data-type="indexterm" id="idm46291185479080"/>the <code>time</code> command, which will print how much time it took to copy the images. <a data-type="xref" href="#table_docker_deploy_times">Table 5-2</a> lists the amount of time each image took to deploy on my machine.</p>&#13;
<table id="table_docker_deploy_times">&#13;
<caption><span class="label">Table 5-2. </span>Docker image deployment times</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Version</th>&#13;
<th>Time</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>v0.0.1</p></td>&#13;
<td><p>4.494s</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>v0.0.2</p></td>&#13;
<td><p>0.332s</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>v0.0.3</p></td>&#13;
<td><p>3.035s</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The first deployment takes the longest because all of the base images need to be copied, such as the Alpine image and the first iteration of <em>node_modules</em>. The second is the quickest because it only involves the small application change. The third is slow because it needs a new iteration of <em>node_modules</em>. Overall, the deployment time of a few seconds might not seem that bad, but in production you’ll see larger images being copied, likely weighing in at hundreds of megabytes, and they will probably be copied between separate machines over a network. The real takeaway is that changing the <em>node_modules</em> directory resulted in a tenfold increase in deployment time.</p>&#13;
&#13;
<p>With your application images safely stored inside your Docker Registry, it’s time to simulate a situation where you would need to download the images to a new server. This can be done by removing the copies of the images on your local machine. Run the following commands to first remove the images from your machine and then to try and start a container from the missing image:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker rmi localhost:5000/tlhunter/recipe-api:v0.0.2&#13;
<code class="nv">$ </code>docker rmi tlhunter/recipe-api:v0.0.2&#13;
<code class="nv">$ </code>docker run tlhunter/recipe-api:v0.0.2 <code class="c"># should fail</code></pre>&#13;
&#13;
<p>The tags ultimately point to an image, referenced by the hash of the image. The first <code>docker rmi</code> command <a data-primary="Docker" data-secondary="docker rmi command" data-type="indexterm" id="idm46291185448344"/><a data-primary="commands" data-secondary="docker rmi" data-type="indexterm" id="idm46291185447464"/>deletes a tag that points to the image, but the files for the image still exist on disk somewhere. Once the second command is run, the final reference to the image is removed, and the actual files on disk are removed. The call to <code>docker run</code> will <a data-primary="Docker" data-secondary="docker run command" data-type="indexterm" id="idm46291185445768"/><a data-primary="commands" data-secondary="docker run" data-type="indexterm" id="idm46291185422008"/>fail because the referenced tag is no longer present. The error <a data-primary="errors" data-secondary="images" data-type="indexterm" id="idm46291185420936"/><a data-primary="images, Docker" data-secondary="errors" data-type="indexterm" id="idm46291185419992"/>message for this should look like <em>Unable to find image <em>tlhunter/recipe-api:v0.0.2</em> locally</em>. The Docker CLI will attempt to grab the image from the public repository and, assuming I haven’t accidentally published such an image under my <code>tlhunter</code> account, will also fail.</p>&#13;
&#13;
<p>Your machine now resembles a fresh server, one that doesn’t have the <em>recipe-api:v0.0.2</em> image stored on it (technically, it does have some of the layers, but it doesn’t have the full image). It’s now time to download the image to your machine from the Docker Registry, just like a server you’re deploying an application to might. Run the following commands to simulate this process:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker pull localhost:5000/tlhunter/recipe-api:v0.0.2&#13;
<code class="nv">$ </code>docker image tag localhost:5000/tlhunter/recipe-api:v0.0.2 <code class="se">\</code>&#13;
  tlhunter/recipe-api:v0.0.2&#13;
<code class="nv">$ </code>docker run tlhunter/recipe-api:v0.0.2 <code class="c"># this time it succeeds</code></pre>&#13;
&#13;
<p>The first <code>docker pull</code> command downloads the image to your machine. The name of the image is the fully qualified name containing the <em>localhost:5000</em> server prefix. The next <code>docker image tag</code> command makes the image available using the shorter name. The final <code>docker run</code> command executes a copy of the container using the shorter name alias. Technically, you could have skipped step three and used <code>docker run</code> with the full name, but this way you’re using the same run command <a data-primary="Docker" data-secondary="registry" data-startref="regpush" data-tertiary="pushing/pulling from" data-type="indexterm" id="idm46291185410408"/>from before.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running a Docker Registry UI" data-type="sect2"><div class="sect2" id="idm46291185517624">&#13;
<h2>Running a Docker Registry UI</h2>&#13;
&#13;
<p>So far, you’ve been able to <a data-primary="Docker" data-secondary="registry" data-tertiary="running UI" data-type="indexterm" id="regrunUI"/>interact with the Docker Registry entirely using the Docker CLI tool. This is certainly convenient for doing things programmatically, but sometimes having a UI to browse images is more convenient. The Docker Registry image doesn’t come with a UI. This is probably because Docker would rather you purchase its paid products, which do come with a UI.</p>&#13;
&#13;
<p>There are several different projects out there that provide a Docker Registry UI. Unexpectedly, most of them run within a Docker container. Run the following commands to start a container that provides a UI for your Docker Registry:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker run <code class="se">\</code>&#13;
  --name registry-browser <code class="se">\</code>&#13;
  --link distnode-registry <code class="se">\</code>&#13;
  -it --rm <code class="se">\</code>&#13;
  -p 8080:8080 <code class="se">\</code>&#13;
  -e <code class="nv">DOCKER_REGISTRY_URL</code><code class="o">=</code>http://distnode-registry:5000 <code class="se">\</code>&#13;
  klausmeyer/docker-registry-browser:1.3.2</pre>&#13;
&#13;
<p>This container doesn’t need any persistence and is configured to be removed once it’s done running. The <code>--link</code> and <code>-e DOCKER_REGISTRY_URL</code> flags allow it to connect directly to the Docker Registry that you already have running. This container should start up pretty quickly. Once it’s ready, visit <a href="http://localhost:8080"><em class="hyperlink">http://localhost:8080</em></a> in your browser.</p>&#13;
&#13;
<p>Once the web page has loaded, <a data-primary="Docker" data-secondary="images" data-tertiary="namespaces" data-type="indexterm" id="idm46291185368216"/><a data-primary="images, Docker" data-secondary="namespaces" data-type="indexterm" id="idm46291185366968"/><a data-primary="namespaces" data-secondary="images" data-type="indexterm" id="idm46291185366024"/>you should see a screen containing the namespaces of the images you’ve pushed. In this case, you should see a single workspace named <em>tlhunter</em>. This workspace should list a single image entry, <em>recipe-api</em>, which is the only image pushed so far. Click that entry.</p>&#13;
&#13;
<p>On the next screen, you should see a list of tags associated with this image. Since you already pushed three tags for this image, you should see <em>v0.0.3</em>, <em>v0.0.2</em>, and <em>v0.0.1</em> listed, similar to what is shown in <a data-type="xref" href="#fig_docker_registry_browser">Figure 5-4</a>.</p>&#13;
&#13;
<p>Click whichever tag your heart desires. On the next screen, you’ll see more information about that particular tag, such as when it was created, the hash for the image, the environment variables associated with the image, and even the layers (and their associated file sizes) used by the image. There’s even a section titled History, which contains the same information as if you had run <code>docker history</code>.</p>&#13;
&#13;
<figure><div class="figure" id="fig_docker_registry_browser">&#13;
<img alt="Screenshot of the tlhunter/recipe-api image and its associated tags" src="assets/dsnj_0504.png"/>&#13;
<h6><span class="label">Figure 5-4. </span>Docker Registry browser screenshot</h6>&#13;
</div></figure>&#13;
&#13;
<p>Now that you’re done with this section, it’s time to do some cleanup. The Registry Browser container can be killed by running Ctrl + C in its terminal window. The Docker Registry <a data-primary="Docker" data-secondary="registry" data-tertiary="stopping" data-type="indexterm" id="idm46291185333160"/>itself will take another step since it’s running in the background. Run the following command to stop the container:</p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>docker stop distnode-registry&#13;
<code class="nv">$ </code>docker rm distnode-registry</pre>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291185303720">&#13;
<h5>Alternatives to Docker Registry</h5>&#13;
<p>Perhaps the most obvious <a data-primary="Docker" data-secondary="registry" data-tertiary="alternatives" data-type="indexterm" id="idm46291185302584"/>alternative to running a private Docker Registry is to use the public <a class="orm:hideurl" href="https://hub.docker.com/">Docker Hub</a>. This service comes with one free private repository (a repository is basically an image).</p>&#13;
&#13;
<p>If the infrastructure you’re working with is already hosted on AWS, then it might make sense to use <a class="orm:hideurl" href="https://aws.amazon.com/ecr/">AWS Elastic Container Registry</a>. This is a managed registry containing Docker images and their layers and integrates with other AWS products. And if you’re using GCP, then consider their <a class="orm:hideurl" href="https://cloud.google.com/container-registry/">Container Registry</a> product.</p>&#13;
&#13;
<p>Another tool to consider using is <a class="orm:hideurl" href="https://jfrog.com/artifactory/">JFrog Artifactory</a>, which is a paid self-hosted service for storing all kinds of “artifacts,” such as Docker Containers, npm packages, Git LFS files, and OS <a data-primary="Docker" data-secondary="registry" data-startref="regrunUI" data-tertiary="running UI" data-type="indexterm" id="idm46291185328024"/>packages.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm46291186560600"><sup><a href="ch05.html#idm46291186560600-marker">1</a></sup> Alpine uses <em>musl</em> instead of <em>glibc</em> as its C standard library, which can cause compatibility issues.</p><p data-type="footnote" id="idm46291185807640"><sup><a href="ch05.html#idm46291185807640-marker">2</a></sup> This section of the file starts off with some comment symbols. This is to avoid ambiguity with leading whitespace, which can cause YAML errors.</p></div></div></section></body></html>