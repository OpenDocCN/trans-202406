- en: Chapter 14\. Application Considerations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is rather flexible when it comes to the type of applications it can
    run and manage. Barring operating system and processor type limitations, Kubernetes
    can essentially run anything. Large monoliths, distributed microservices, batch
    workloads, you name it. The only requirement that Kubernetes imposes on workloads
    is that they are distributed as container images. With that said, there are certain
    steps you can take to make your applications better Kubernetes citizens.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will pivot our discussions to focus on the application instead
    of the platform. If you are part of a platform team, don’t skip this chapter.
    While you might think it only applies to developers, it also applies to you. As
    a platform team member, you will most likely get to build applications to provide
    custom services on your platform. Even if you don’t, the discussions in this chapter
    will help you better align with development teams consuming the platform, and
    even educate those teams that might be unfamiliar with container-based platforms.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers various considerations you should make when running applications
    on Kubernetes. Mainly:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying applications onto the platform, and mechanisms to manage deployment
    manifests, such as templating and packaging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaches to configure applications, such as using Kubernetes APIs (ConfigMaps/Secrets),
    and integrating with external systems for config and secret management.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes features that improve the availability of your workloads, such as
    pre-stop container hooks, graceful termination, and scheduling constraints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: State probes, a feature of Kubernetes that enables you to surface application
    health information to the platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource requests and limits, which are critical to ensure your applications
    run properly on the platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logs, metrics, and tracing as mechanisms to debug, troubleshoot, and operate
    your workloads effectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Applications to Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once your application is containerized and available in a container image registry,
    you are ready to deploy it onto Kubernetes. In most cases, deploying the application
    involves writing YAML manifests that describe the Kubernetes resources required
    to run the app, such as Deployments, Services, ConfigMaps, CRDs, etc. Then, you
    send the manifests to the API server, and Kubernetes takes care of the rest. Using
    raw YAML manifests is a great way to get started, but it can quickly become impractical,
    especially when deploying the application onto different clusters or environments.
    You will most likely encounter questions similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How do I provide different credentials when running in staging versus production?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I use a different image registry when deploying in various datacenters?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I set different replica counts in development versus production?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I ensure all port numbers match up across the different manifests?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list goes on and on. And while you could have multiple sets of manifests
    to solve for each of these concerns, the permutations make it rather challenging
    to manage. In this section, we will discuss approaches you can take to address
    the issue of manifest management. Mainly, we will cover templating manifests and
    packaging applications for Kubernetes. We will not, however, discuss the gamut
    of tools available in the community. More often than not, we find that teams get
    stuck in analysis paralysis when considering the different options. Our advice
    is to choose *something* and move on to solving higher-value concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Templating Deployment Manifests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Templating involves introducing placeholders in your deployment manifests. Instead
    of hardcoding values in the manifests, the placeholders provide a mechanism for
    you to inject values as necessary. For example, the following templated manifest
    enables you to set replica counts to different values. Perhaps you need one replica
    in development, but five in production.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Packaging Applications for Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating self-contained software packages is another mechanism you can use to
    deploy your application while addressing the manifest management. Packaging solutions
    usually build upon templating, but they introduce additional functionality that
    can be useful, such as the ability to push the package to OCI-compatible registries,
    life cycle management hooks, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Packages are a great mechanism to consume software maintained by a third party
    or deliver software to third parties. If you’ve used Helm to install software
    into a Kubernetes cluster, you’ve already leveraged the benefits of packaging.
    If you are unfamiliar with Helm, the following snippet gives you an idea of what
    it takes to install a package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, packages can be a great way to deploy and manage software on
    Kubernetes. With that said, packages can fall short when it comes to complex applications
    that require advanced life cycle management. For such applications, we find operators
    to be a better solution. We discuss operators extensively in [Chapter 2](ch02.html#deployment_models).
    Even though the chapter focuses on platform services, the concepts discussed apply
    when building operators for complex applications.
  prefs: []
  type: TYPE_NORMAL
- en: Ingesting Configuration and Secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applications typically have configuration that tells them how to behave at runtime.
    Configuration commonly includes logging levels, hostnames of dependencies (e.g.,
    DNS record for a database), timeouts, and more. Some of these settings can contain
    sensitive information, such as passwords, that we usually call secrets. In this
    section, we will discuss the different methods you can use to configure applications
    on a Kubernetes-based platform. First, we will review the ConfigMap and Secret
    APIs available in core Kubernetes. Then, we will explore an alternative to the
    Kubernetes API, mainly integrating with an external system. Finally, we will provide
    guidance on these approaches based on what we’ve seen work best in the field.
  prefs: []
  type: TYPE_NORMAL
- en: Before digging in, it is worth mentioning that you should avoid bundling configuration
    or secrets inside your application’s container image. The tight coupling between
    the application binary and its configuration defeats the purpose of runtime configuration.
    Furthermore, it poses a security problem in the case of secrets, as the image
    might be accessible to actors that should otherwise not have access to the secrets.
    Instead of including config in the image, you should leverage platform features
    to inject configuration at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes ConfigMaps and Secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ConfigMaps and Secrets are core resources in the Kubernetes API that enable
    you to configure your applications at runtime. As with any other resource in Kubernetes,
    they are created via the API server and are usually declared in YAML, such as
    the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Let’s discuss how you can consume ConfigMaps and Secrets in your applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first method is to mount ConfigMaps and Secrets as files in the Pod’s filesystem.
    When building your Pod specification, you can add volumes that reference ConfigMaps
    or Secrets by name and mount them into containers at specific locations. For example,
    the following snippet defines a Pod that mounts the ConfigMap named `my-config`
    into the container named `my-app` at `/etc/my-app/config.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Leveraging volume mounts is the preferred method when it comes to consuming
    ConfigMaps and Secrets. The reason is that the files in the Pod are dynamically
    updated, which allows you to reconfigure applications without restarting the app
    or re-creating the Pod. With that said, this is something that the application
    must support. The application must watch the configuration files on disk and apply
    new configuration when the files change. Many libraries and frameworks make it
    easy to implement this functionality. When this is not possible, you can introduce
    a sidecar container that watches the config files and signals the main process
    (with a SIGHUP, for example) when new configuration is available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consuming ConfigMaps and Secrets via environment variables is another method
    you can use. If your application expects configuration through environment variables,
    this is the natural approach to follow. Environment variables can also be helpful
    if you need to provide settings via command-line flags. In the following example,
    the Pod sets the `DEBUG` environment variable using a ConfigMap named `my-config`,
    which has a key called `debug` that contains the value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: One of the downsides of using environment variables is that changes to the ConfigMaps
    or Secrets are not reflected in the running Pod until it restarts. This might
    not be a problem for some applications, but you should keep it in mind. Another
    downside, mainly for Secrets, is that some applications or frameworks may dump
    the environment details into logs during startup or when they crash. This poses
    a security risk as secrets can be leaked into logfiles inadvertently.
  prefs: []
  type: TYPE_NORMAL
- en: These first two ConfigMap and Secret consumption methods rely on Kubernetes
    injecting the configuration into the workload. Another option is for the application
    to communicate with the Kubernetes API to get its configuration. Instead of using
    config files or environment variables, the application reads ConfigMaps and Secrets
    straight from the Kubernetes API server. The app can also watch the API so that
    it can act whenever the configuration changes. Developers can use one of the many
    Kubernetes libraries or SDKs to implement this functionality or leverage application
    frameworks that support this capability, such as Spring Cloud Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: While leveraging the Kubernetes API for application configuration can be convenient,
    we find that there are important downsides you should consider. First, the need
    to connect to the API server to get configuration creates a tight coupling between
    the application and the Kubernetes platform. This coupling raises some interesting
    questions. What happens if the API server goes down? Will your application experience
    downtime when your platform team upgrades the API server?
  prefs: []
  type: TYPE_NORMAL
- en: Second, for the application to get its configuration from the API, it needs
    credentials, and it needs to have the right permissions. These requirements increase
    your deployment complexity, as you now have to provide a Service Account and define
    RBAC roles for your workload.
  prefs: []
  type: TYPE_NORMAL
- en: Last, the more applications using this method to get config, the more undue
    load is imposed on the API server. Since the API server is a critical component
    of the cluster’s control plane, this approach to app configuration can be at odds
    with the overall scalability of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, when it comes to consuming ConfigMaps and Secrets, we prefer using
    volume mounts and environment variables over integrating with the Kubernetes API
    directly. In this way, the applications remain decoupled from the underlying platform.
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining Configuration from External Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ConfigMaps and Secrets can be convenient when it comes to configuring applications.
    They are built into the Kubernetes API and are readily available for you to consume.
    With that said, configuration and secrets have been a concern that application
    developers had faced well before Kubernetes existed. While Kubernetes provides
    features to solve this concern, nothing is stopping you from using external systems
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most prevalent examples of an external configuration or secrets management
    system we run into in the field is [HashiCorp Vault](https://www.vaultproject.io).
    Vault provides advanced secret management functionality that is unavailable in
    Kubernetes Secrets. For example, Vault provides dynamic secrets, secret rotation,
    time-based tokens, and more. If your application is already leveraging Vault,
    you can continue to do so when running your application on Kubernetes. Even if
    not yet using Vault, it is worth evaluating as a more robust alternative to Kubernetes
    Secrets. We discussed secret management considerations and the Vault integration
    with Kubernetes extensively in [Chapter 7](ch07.html#chapter7). If you want to
    learn more about secret management in Kubernetes and the lower-level details of
    the Vault integration, we recommend you check out that chapter.
  prefs: []
  type: TYPE_NORMAL
- en: When leveraging an external system for configuration or secrets, we find that
    offloading the integration (as much as possible) to the platform is beneficial.
    Integrations with external systems such as Vault can be offered as a platform
    service to expose Secrets as volumes or environment variables in Pods. The platform
    service abstracts the external system and enables your application to consume
    the Secret without worrying about the implementation details of the integration.
    Overall, leveraging such a platform service reduces the application’s complexity
    and results in standardization across your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Handling Rescheduling Events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is a highly dynamic environment where workloads are moved around
    for different reasons. Cluster nodes can come and go; they can run out of resources
    or even fail. Platform teams can drain, cordon, or remove nodes to perform cluster
    life cycle operations (e.g., upgrades). These are examples of situations in which
    your workload might be killed and rescheduled, and there are many others.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the reason, the dynamic nature of Kubernetes can impact your application’s
    availability and operation. Even though the application’s architecture has the
    highest bearing in determining the impact of disturbances, there are features
    in Kubernetes you can leverage to minimize that impact. We will explore these
    features in this section. First, we will dig into pre-stop container life cycle
    hooks. As indicated by the name, these hooks enable you to act before Kubernetes
    stops your containers. We will then discuss how you can shut down containers gracefully,
    which involves handling signals from within the application in response to shutdown
    events. Finally, we will review Pod anti-affinity rules, a mechanism you can use
    to spread your application across failure domains. As mentioned before, these
    mechanisms can help *minimize* the impact of disturbances but cannot eliminate
    the potential for failure. Keep that in mind as you read through this section.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-stop Container Life Cycle Hook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes can terminate workloads for any number of reasons. If you need to
    perform an action before your container is terminated, you can leverage the pre-stop
    container life cycle hook. Kubernetes provides two types of hooks. The `exec`
    life cycle hook runs a command within the container, while the `HTTP` life cycle
    hook issues an HTTP request against an endpoint you specify (typically the container
    itself). Which hook to use depends on your specific requirements and what you
    are trying to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pre-stop hook in the [Contour](https://projectcontour.io) Ingress controller
    is a great example that showcases the power of pre-stop hooks. To avoid dropping
    in-flight client requests, Contour includes a container pre-stop hook that tells
    Kubernetes to execute a command before stopping the container. The following snippet
    from the Contour Deployment YAML file shows the pre-stop hook configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Container pre-stop hooks enable you to take action before Kubernetes stops your
    container. They allow you to run commands or scripts that exist within the container
    but are otherwise not part of the running process. One key consideration to keep
    in mind is that these hooks are executed only in the face of planned life cycle
    or re-scheduling events. The hooks will not run if a node fails, for example.
    Furthermore, any action performed as part of the pre-stop hook is governed by
    the Pod’s graceful shutdown period, which we will discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Graceful Container Shutdown
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After executing pre-stop hooks (when provided), Kubernetes initiates the container
    shutdown process by sending a SIGTERM signal to the workload. This signal lets
    the container know that it is being stopped. It also starts running down the clock
    of the termination shutdown period, which is 30 seconds by default. You can tune
    this period using the `terminationGracePeriodSeconds` field of the Pod specification.
  prefs: []
  type: TYPE_NORMAL
- en: During the graceful termination period, the application can complete any necessary
    actions before shutting down. Depending on the application, these actions can
    be persisting data, closing open connections, flushing files to disk, etc. Once
    done, the application should exit with a successful exit code. The graceful termination
    is illustrated in [Figure 14-1](#application_termination_in_kubernetes), where
    we can see the kubelet sending the SIGTERM signal and waiting for the container(s)
    to terminate within the grace period.
  prefs: []
  type: TYPE_NORMAL
- en: If the application shuts down within the termination period, Kubernetes completes
    the shutdown process and moves on. Otherwise, it forcefully stops the process
    by sending a SIGKILL signal. [Figure 14-1](#application_termination_in_kubernetes)
    also shows this forceful termination toward the bottom right of the diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '![prku 1401](assets/prku_1401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-1\. Application termination in Kubernetes. The kubelet first sends
    a SIGTERM signal to the workload and waits up to the configured graceful termination
    period. If the process is still running after the period expires, the kubelet
    sends a SIGKILL to terminate the process.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For your application to terminate gracefully, it must handle the SIGTERM signal.
    Each programming language or framework has its own way of configuring signal handlers.
    Some application frameworks might even take care of it for you. The following
    snippet shows a Go application that configures a SIGTERM signal handler, which
    stops the application’s HTTP server upon receipt of the signal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: When running your applications on Kubernetes, we recommend you configure signal
    handlers for the SIGTERM signal. Even if there are no shutdown actions to take,
    handling the signal makes your workload a better Kubernetes citizen, as it reduces
    the time it takes to stop the application and thus free up the resources for other
    workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Satisfying Availability Requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Container pre-stop hooks and graceful termination are concerned with a single
    instance or replica of your application. If your application is horizontally scalable,
    you will most likely have multiple replicas running in the cluster to satisfy
    availability requirements. Running more than one instance of your workload can
    provide increased fault tolerance. For example, if a cluster node fails and takes
    one of the application instances with it, the other replicas can pick up the work.
    With that said, having multiple replicas does not help if they are running in
    the same failure domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to ensure your Pods are spread across failure domains is by using Pod
    anti-affinity rules. With Pod anti-affinity rules, you tell the Kubernetes scheduler
    that you want to schedule your Pods according to constraints you define in the
    Pod definition. More specifically, you ask the scheduler to avoid placing your
    Pod on nodes that are already running a replica of your workload. Consider a web
    server that has three replicas. To ensure the three replicas are not placed in
    the same failure domain, you can use Pod anti-affinity as in the following snippet.
    In this case, the anti-affinity rule tells the scheduler that it should prefer
    placing Pods across zones, as determined by the `zone` label on cluster nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In addition to Pod anti-affinity, Kubernetes provides Pod Topology Spread Constraints,
    which are an improvement to Pod anti-affinity rules when it comes to spreading
    Pods across failure domains. The problem with anti-affinity rules is that there
    is no way to guarantee Pods are spread *evenly* across the domains. You can either
    “prefer” scheduling them based on the topology key, or you can guarantee a single
    replica per failure domain.
  prefs: []
  type: TYPE_NORMAL
- en: The Pod Topology Spread Constraints provide a way for you to tell the scheduler
    to spread your workload. Similar to Pod anti-affinity rules, they are only evaluated
    against new Pods that need scheduling, and thus they are not retroactively enforced.
    The following snippet shows an example Pod Topology Spread Constraint that results
    in Pods spread across zones (based on the `zone` label of nodes). If the constraint
    cannot be satisfied, Pods will not be scheduled.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: When running multiple instances of an application, you should leverage these
    Pod placement features to improve the application’s tolerance of infrastructure
    failure. Otherwise, you risk Kubernetes scheduling your workload in a way that
    does not achieve the failure tolerance you are looking for.
  prefs: []
  type: TYPE_NORMAL
- en: State Probes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes uses many signals to determine the state and health of applications
    running on the platform. When it comes to health, Kubernetes treats workloads
    as opaque boxes. It knows whether the process is up or not. While this information
    is helpful, it is typically not enough to run and manage applications effectively.
    This is where probes come in. Probes provide Kubernetes with increased visibility
    of the application’s condition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes provides three probe types: liveness, readiness, and startup probes.
    Before discussing each type in detail, let’s review the different probing mechanisms
    that are common to all probe types:'
  prefs: []
  type: TYPE_NORMAL
- en: Exec
  prefs: []
  type: TYPE_NORMAL
- en: The kubelet executes a command inside the container. The probe is deemed successful
    if the command returns a zero exit code. Otherwise, the kubelet considers the
    container unhealthy.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP
  prefs: []
  type: TYPE_NORMAL
- en: The kubelet sends an HTTP request to an endpoint in the Pod. As long as the
    HTTP response code is greater than or equal to 200 and less than 400, the probe
    is deemed successful.
  prefs: []
  type: TYPE_NORMAL
- en: TCP
  prefs: []
  type: TYPE_NORMAL
- en: The kubelet establishes a TCP connection with the container on a configurable
    port. The container is deemed healthy if the connection is established successfully.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to sharing the probing mechanisms, all probes have a common set
    of parameters that you can use to tune the probe according to your workload. These
    parameters include success and failure thresholds, timeout periods, and others.
    The Kubernetes documentation describes each setting in detail, so we will not
    dive into them here.
  prefs: []
  type: TYPE_NORMAL
- en: Liveness Probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Liveness probes help Kubernetes understand the health of Pods on the cluster.
    At the node level, the kubelet continuously probes Pods that have the liveness
    probe configured. When the liveness probe exceeds the failure threshold, the kubelet
    deems the Pod unhealthy and restarts it. [Figure 14-2](#flowchart_that_shows_an_http_based_liveness_probe)
    shows a flowchart that depicts an HTTP liveness probe. The kubelet probes the
    container every 10 seconds. If the kubelet finds that the last 10 probes have
    failed, it restarts the container.
  prefs: []
  type: TYPE_NORMAL
- en: '![prku 1402](assets/prku_1402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-2\. Flowchart that shows an HTTP-based liveness probe with a period
    of 10 seconds. If the probe fails 10 times consecutively, the Pod is deemed unhealthy
    and the kubelet restarts it.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Given that liveness probe failures result in container restarts, we typically
    suggest that liveness probe implementations should not check for the workload’s
    external dependencies. By keeping the liveness probe local to your workload and
    not checking external dependencies, you prevent cascading failures that could
    otherwise occur. For example, a service that interacts with a database should
    not perform a “database availability” check as part of its liveness probe, as
    restarting the workload will most likely not fix the problem. If the app detects
    an issue with the database, the app can enter a read-only mode or gracefully disable
    the functionality that depends on the database. Another option is for the app
    to fail its readiness probe, which we discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Readiness Probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The readiness probe is perhaps the most common and most important probe type
    in Kubernetes, especially for services that handle requests. Kubernetes uses readiness
    probes to control whether to route Service traffic to Pods. Thus, readiness probes
    provide a mechanism for the application to tell the platform that they’re ready
    to accept requests.
  prefs: []
  type: TYPE_NORMAL
- en: As with liveness probes, the kubelet is responsible for probing the application
    and updating the Pod’s status according to the probe results. When the probe fails,
    the platform removes the failing Pod from the list of available endpoints, effectively
    diverting traffic to other replicas that are ready. [Figure 14-3](#flowchart_that_shows_an_http_based_readiness)
    shows a flowchart that explains an HTTP-based readiness probe. The probe has a
    5-second initial delay and a probing period of 10 seconds. On startup, the application
    begins receiving traffic only when the readiness probe succeeds. Then, the platform
    stops sending traffic to the Pod if the probe fails twice consecutively.
  prefs: []
  type: TYPE_NORMAL
- en: When deploying service-type workloads, make sure that you configure a readiness
    probe to avoid sending requests to replicas that cannot handle them. The readiness
    probe is not only critical when the Pod is starting up but also important during
    the lifetime of the Pod to prevent routing clients to replicas that have become
    unready.
  prefs: []
  type: TYPE_NORMAL
- en: '![prku 1403](assets/prku_1403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-3\. Flowchart that shows an HTTP-based readiness probe with a period
    of 10 seconds. If the probe fails twice consecutively, the Pod is deemed not ready
    and it is taken out of the set of ready endpoints.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Startup Probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Liveness and readiness probes have been available since the first version of
    Kubernetes. As the system gained popularity, the community identified a need to
    implement an additional probe, the startup probe. The startup probe provides extra
    time for slow-starting applications to initialize. Similar to liveness probes,
    failed startup probes result in the container being restarted. Unlike liveness
    probes, however, startup probes are executed only until they succeed, at which
    point the liveness and readiness probes take over.
  prefs: []
  type: TYPE_NORMAL
- en: If you are wondering why a liveness probe is not enough, let’s consider an application
    that takes, on average, 300 seconds to initialize. You could indeed use a liveness
    probe that waits 300 seconds before stopping the container. During startup, this
    liveness probe would work. But what about later on when the application is running?
    If the application entered an unhealthy state, the platform would wait 300 seconds
    before restarting it! This is the problem that the startup probe solves. It looks
    after the workload during startup but then gets out of the way. [Figure 14-4](#flowchart_that_shows_an_http_based_startup_probe_with_a_period_of_10_seconds)
    shows a flowchart that walks through a startup probe like the one we just discussed.
    It has a failure threshold of 30 times and a probing period of 10 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: '![prku 1404](assets/prku_1404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-4\. Flowchart that shows an HTTP-based startup probe with a period
    of 10 seconds. If the probe returns a successful response, the startup probe is
    disabled and the liveness/readiness probes are enabled. Otherwise, if the probe
    fails 30 times consecutively, the kubelet restarts the Pod.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While startup probes can be useful for certain applications, we usually recommend
    avoiding them unless absolutely necessary. We find liveness and readiness probes
    to be appropriate most of the time.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have covered the different probe types, let’s dive into how you
    should approach them in your application, specifically liveness and readiness
    probes. We know that failed liveness probes result in the platform restarting
    the Pod, while failed readiness probes prevent traffic from being routed to the
    Pod. Given these different outcomes, we find that most applications that leverage
    both liveness and readiness probes should configure different probe endpoints
    or commands.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, the liveness probe fails only when there is a problem that requires
    a restart, such as a deadlock or some other condition that permanently prevents
    the app from making progress. Applications that expose an HTTP server commonly
    implement a liveness endpoint that unconditionally returns a 200 status code.
    As long as the HTTP server is healthy and the app can respond, there’s no need
    to restart it.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to the liveness endpoint, the readiness endpoint can check for different
    conditions within the application. For example, if the application warms internal
    caches on startup, the readiness endpoint can return false unless the caches are
    warm. Another example is service overload, a condition under which the app can
    fail the readiness probe as a mechanism to shed load. As you can probably imagine,
    the checked conditions vary from one application to the next. In general, however,
    they are temporary conditions that resolve with the passing of time.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we typically recommend using readiness probes for workloads that
    handle requests, given that readiness probes are meaningless in other application
    types, such as controllers, jobs, etc. When it comes to liveness probes, we recommend
    considering them only when restarting the application would help fix the problem.
    Lastly, we tend to avoid startup probes unless absolutely necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Pod Resource Requests and Limits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of Kubernetes’ primary functions is to schedule applications across cluster
    nodes. The scheduling process involves, among other things, finding candidate
    nodes that have enough resources to host the workload. To place workloads effectively,
    the Kubernetes scheduler first needs to know the resource needs of your application.
    Typically, these resources encompass CPU and memory, but can also include other
    resource types such as ephemeral storage and even custom or extended resources.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to scheduling your applications, Kubernetes also needs resource
    information to guarantee those resources at runtime. After all, the platform has
    limited resources that are shared across applications. Providing resource requirements
    is critical to your application’s ability to *use* those resources.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will discuss resource requests and resource limits, and
    how they can impact your application. We will not dig into the details of how
    the platform implements resource requests and limits, as we have already discussed
    it in [Chapter 12](ch12.html#multi_tenancy_chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Resource Requests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Resource requests specify the minimum amount of resources your application needs
    to run. In most cases, you should specify resource requests when deploying applications
    to Kubernetes. By doing so, you ensure your workload will have access to the requested
    resources at runtime. If you don’t specify resource requests, you might find your
    application’s performance diminishes significantly when resources on the node
    come under contention. You even risk the possibility of your application being
    terminated if the node needs to reclaim memory for other workloads. [Figure 14-5](#pod_1_and_pod_2_share_the_nodes_memory)
    shows the termination of an application because another workload with memory requests
    starts consuming additional memory.
  prefs: []
  type: TYPE_NORMAL
- en: '![prku 1405](assets/prku_1405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-5\. Pod 1 and Pod 2 share the node’s memory. Each Pod is initially
    consuming 200 MiB out of the total 500 MiB. Pod 2 is terminated when Pod 1 needs
    to consume additional memory, as Pod 2 does not have memory requests in its specification.
    Pod 2 enters a crash loop as it cannot allocate enough memory to start up.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: One of the main challenges with resource requests is finding the right numbers
    to use. If you are deploying an existing application, you might already have data
    you can analyze to determine the app’s resource requests, such as the application’s
    actual utilization over time or perhaps the size of the VMs hosting it. When you
    don’t have historical data, you will have to use an educated guess and gather
    data over time. Another option is to use the Vertical Pod Autoscaler (VPA), which
    can suggest values for CPU and memory requests and even adjust those values over
    time. For more information about the VPA, see [Chapter 13](ch13.html#autoscaling_chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Resource Limits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Resource limits allow you to specify the maximum amount of resources your workload
    can consume. You might be wondering why you would impose an artificial limit.
    After all, the more resources available, the better. While this is true for some
    workloads, having unbound access to resources can result in unpredictable performance,
    as the Pod will have access to extra resources when available but will not when
    other Pods need the resources on the node. It gets even worse with memory. Given
    that memory is an incompressible resource, the platform has no other choice but
    to kill Pods when it needs to reclaim memory that was opportunistically consumed.
  prefs: []
  type: TYPE_NORMAL
- en: An important consideration to make when setting resource limits is whether you
    need to propagate those limits to the workload itself. Java applications are a
    good example. If the application uses an older version of Java (JDK version 8u131
    or earlier), you need to propagate the memory limit down to the Java Virtual Machine
    (JVM). Otherwise, the JVM remains unaware of the limit and attempts to consume
    more memory than allowed. In the case of Java, you can configure the memory settings
    of the JVM using the `JAVA_OPTIONS` environment variable. Another option, although
    not always feasible, is to update the version of the JVM, as more recent versions
    gained the ability to detect the memory limits within containers. If you are deploying
    an application that leverages a runtime, consider whether you need to propagate
    the resource limits for the application to understand them.
  prefs: []
  type: TYPE_NORMAL
- en: Limits are also important if you are trying to run performance tests or benchmarks
    against your workload. As you can imagine, it is likely that each test run will
    execute against Pods scheduled on different nodes at different times. If resource
    limits are not enforced on the workload, the test results can be highly variable
    as the workload under test can burst above its resource requests when the nodes
    have idle resources.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, you should set your resource limits equal to your resource requests,
    which ensures your application will always have the same amount of resources,
    no matter what’s happening with other Pods running beside it.
  prefs: []
  type: TYPE_NORMAL
- en: Application Logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Application logs are critical to troubleshoot and debug applications both during
    development and in production. Applications running on Kubernetes should, as much
    as possible, log to the standard out and standard error streams (STDOUT/STDERR).
    This not only removes complexity in the application but also is the least complex
    solution from the platform’s perspective when it comes to shipping logs to a central
    location. We covered this concern in [Chapter 9](ch09.html#observability_chapter),
    where we also discussed different log processing strategies, systems, and tools.
    In this section, we will touch on some of the considerations to make when thinking
    about application logs. The first thing we’ll talk about is what you should log
    in the first place. Then, we will discuss unstructured versus structured logs.
    Finally, we will touch on improving the usefulness of logs by including contextual
    information in log messages.
  prefs: []
  type: TYPE_NORMAL
- en: What to Log
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the first things to figure out when it comes to application logs is *what*
    to include in the logs. While development teams typically have their own philosophy,
    we have found that they tend to go overboard with logs. If you log too much, you
    run the risk of having too much noise and missing out on important information.
    On the flip side, if you log too little, it can become difficult to troubleshoot
    your application effectively. As with most things, there’s a balance to strike
    here.
  prefs: []
  type: TYPE_NORMAL
- en: While working with application teams, we have found that a good rule of thumb
    that helps determine whether to log something is to ask the question, Is this
    log message actionable? If the answer is yes, this is a good indicator that it
    is worth logging that message. Otherwise, it is an indicator that the log message
    might not be useful.
  prefs: []
  type: TYPE_NORMAL
- en: Unstructured Versus Structured Logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Application logs can be categorized as either unstructured or structured. Unstructured
    logs are, as the name suggests, strings of text that lack a specific format. They
    are arguably the most prevalent, as there is zero upfront planning that teams
    need to make. While the team might have generic guidelines, developers get to
    log messages in whatever format they like.
  prefs: []
  type: TYPE_NORMAL
- en: Structured logs, on the other hand, have predetermined fields that must be provided
    when logging events. They are typically formatted as JSON lines or key-value lines
    (e.g., `time="2015-08-09T03:41:12-03:21" msg="hello world!" thread="13" batchId="5"`).
    The main benefit of structured logs is that they are written in a machine-readable
    format, making them easier to query and analyze. With that said, structured logs
    tend to be harder for humans to read, so you must carefully consider this trade-off
    as you implement logging in your application.
  prefs: []
  type: TYPE_NORMAL
- en: Contextual Information in Logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The primary purpose of logs is to provide insight into what happened within
    your application at a certain point in time. Perhaps you are troubleshooting a
    production issue in a live application, or maybe you are performing a root cause
    analysis to understand why something happened. To be able to complete such tasks,
    you typically need contextual information in log messages, in addition to what
    happened.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider a payment application as an example. When the application request
    serving pipeline encounters an error, in addition to logging the error itself,
    try to include the context surrounding the error as well. For example, if an error
    occurs because the payee was not found, include the payee name or ID, the user
    ID attempting to make the payment, the payment amount, etc. Such contextual information
    will improve your experience troubleshooting issues and will help you prevent
    such problems in the future. Having said that, avoid including sensitive information
    in your logs. You don’t want to leak a user’s password or credit card information.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to logs, metrics provide critical insight about how your application
    is behaving. Once you have application metrics, you can configure alerts to let
    you know when your application needs attention. Furthermore, by aggregating metrics
    over time, you can discover trends, improvements, and regressions as you roll
    out new versions of your software. This section discusses application instrumentation
    and some of the metrics you can capture, including RED (Rate, Errors, Duration),
    USE (Utilization, Saturation, Errors), and app-specific metrics. If you are interested
    in the platform components that enable monitoring and more additional discussions
    on metrics, check out [Chapter 9](ch09.html#observability_chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In most cases, the platform can measure and surface metrics about your application’s
    externally visible behavior. Metrics such as CPU usage, memory usage, disk IOPS,
    and others are readily available from the node that is running your application.
    While these metrics are useful, instrumenting your application to expose key metrics
    from within is worthwhile.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus is one of the most popular monitoring systems for Kubernetes-based
    platforms that we run into in the field. We have extensively covered Prometheus
    and its components in [Chapter 9](ch09.html#observability_chapter). In this section,
    we will focus our discussions on instrumenting apps for Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prometheus pulls metrics from your application using an HTTP request on a configurable
    endpoint (typically `/metrics`). This means that your application must expose
    this endpoint for Prometheus to scrape. More importantly, the endpoint’s response
    must contain Prometheus-formatted metrics. Depending on the type of software you
    want to monitor, there are two approaches you can take to expose metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: Native instrumentation
  prefs: []
  type: TYPE_NORMAL
- en: This option involves instrumenting your application using the Prometheus client
    libraries so that metrics are exposed from within the application process. This
    is an excellent approach when you have control over the source code of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Out-of-process exporter
  prefs: []
  type: TYPE_NORMAL
- en: This is an additional process running beside your workload that transforms preexisting
    metrics and exposes them in a Prometheus-compatible format. This approach is best
    suited for off-the-shelf software that you cannot instrument directly and is typically
    implemented using the sidecar container pattern. Examples include the [NGINX Prometheus
    Exporter](https://oreil.ly/g0ZCt) and the [MySQL Server Exporter](https://oreil.ly/SJOka).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Prometheus instrumentation libraries supports four metric types: Counters,
    Gauges, Histograms, and Summaries. Counters are metrics that can only increase,
    while Gauges are metrics that can go up or down. Histograms and Summaries are
    more advanced metrics than Counters and Gauges. Histograms place observations
    into configurable buckets that you can then use to compute quantiles (e.g., 95th
    percentile) on the Prometheus server. Summaries are similar to Histograms, except
    that they compute quantiles on the client side over a sliding time window. The
    [Prometheus documentation](https://oreil.ly/epvwC) explains the metric types in
    more depth.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three primary things you must do to instrument an application with
    the Prometheus libraries. Let’s work through an example of instrumenting a Go
    service. First, you need to start an HTTP server to expose the metrics for Prometheus
    to scrape. The library provides an HTTP handler that takes care of encoding the
    metrics into the Prometheus format. Adding the handler would look something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you need to create and register metrics. For example, if you wanted to
    expose a Counter metric called `items_handled_total`, you would use code similar
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you need to update the metric according to what’s happening in the
    application. Continuing the Counter example, you would use the `Inc()` method
    of the Counter to increment it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Instrumenting an application using the Prometheus libraries is relatively simple.
    The more complicated task is to determine the metrics that your application should
    expose. In the following sections, we will discuss different methods or philosophies
    you can use as a starting point to select metrics.
  prefs: []
  type: TYPE_NORMAL
- en: USE Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The USE method, proposed by [Brendan Gregg](http://www.brendangregg.com/usemethod.html),
    focuses on system resources. When using this method, you capture Utilization,
    Saturation, and Errors (USE) for each of the resources your application uses.
    These resources typically include CPU, memory, disk, etc. They can also include
    resources that exist within the application software, such as queues, thread pools,
    etc.
  prefs: []
  type: TYPE_NORMAL
- en: RED Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In contrast to the USE method, the RED method focuses more on the services themselves
    instead of the underlying resources. Initially proposed by [Tom Wilkie](https://oreil.ly/sW3al),
    the RED method captures the Rate, Errors, and Durations of requests that the service
    handles. The RED method can be better suited for online services, as the metrics
    provide insight into your users’ experience and how they perceive the service
    from their standpoint.
  prefs: []
  type: TYPE_NORMAL
- en: The Four Golden Signals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another philosophy you can adopt is to measure the four golden signals, as
    proposed by Google in [*Site Reliability Engineering*](https://oreil.ly/iv1bJ)
    (O’Reilly). Google suggests you measure four critical signals for every service:
    Latency, Traffic, Errors, and Saturation. You might notice that these are somewhat
    similar to the metrics captured as part of the RED method, with the addition of
    Saturation.'
  prefs: []
  type: TYPE_NORMAL
- en: App-Specific Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The USE method, RED method, and four golden signals capture generic metrics
    that are applicable across most if not all applications. There is an additional
    class of metrics that surface app-specific information. For example, how long
    does it take to add an item to the shopping cart? Or how much time does it take
    to connect a customer with an agent? Typically, these metrics are correlated with
    business key performance indicators (KPIs).
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the method you choose, exporting metrics from your application
    is critical to its success. Once you have access to those metrics, you can build
    dashboards to visualize the behavior of your system, set up alerts to notify your
    on-call teams when something goes wrong, and perform trend analysis to derive
    business intelligence that can advance your organization.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting Services for Distributed Tracing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Distributed tracing enables you to analyze applications that are composed of
    multiple services. They provide visibility into the execution flow of a request
    as it traverses the different services that make up the application. As discussed
    in [Chapter 9](ch09.html#observability_chapter), Kubernetes-based platforms can
    offer distributed tracing as a platform service using systems such as [Jaeger](https://www.jaegertracing.io)
    or [Zipkin](https://zipkin.io). However, similar to monitoring and metrics, you
    must instrument services to take advantage of distributed tracing. In this section,
    we will explore how to instrument services using Jaeger and [OpenTracing](https://opentracing.io).
    First, we will discuss how to initialize a tracer. Then, we will dive into how
    to create spans within a service. A *span* is a named, timed operation that is
    the building block of a distributed trace. Finally, we will explore how to propagate
    tracing context from one service to another. We will use Go and the Go libraries
    for examples, but the concepts are applicable to other programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the Tracer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before being able to create spans within the service, you must initialize the
    tracer. Part of the initialization involves configuring the tracer according to
    the environment the application is running. The tracer needs to know the service
    name, the URL to send trace information, etc. For these settings, we recommend
    using the Jaeger client library environment variables. For example, you can set
    the service name using the `JAEGER_SERVICE_NAME` environment variable.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to configuring the tracer, you can integrate the tracer with your
    metrics and logging libraries as you initialize the tracer. The tracer uses the
    metrics library to emit metrics about what’s happening with the tracer, such as
    the number of traces and spans sampled, the number of successfully reported spans,
    and others. On the other hand, the tracer leverages the logging libraries to emit
    logs when it encounters errors. You can also configure the tracer to log spans,
    which is rather useful in development.
  prefs: []
  type: TYPE_NORMAL
- en: 'To initialize a Jaeger tracer in a Go service, you would add code to your application
    similar to the following. In this case, we are using Prometheus as the metrics
    library and Go’s standard logging library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_application_considerations_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a Prometheus metrics factory that Jaeger can use to emit metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_application_considerations_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a default Jaeger configuration with no hardcoded configuration (use environment
    variables instead).
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_application_considerations_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new tracer from the configuration, and provide the metrics factory
    and the Go standard library logger.
  prefs: []
  type: TYPE_NORMAL
- en: With the tracer initialized, we can start creating spans in our service.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Spans
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have a tracer, we can start creating spans within our service.
    Assuming the service is somewhere in the middle of the request processing flow,
    the service needs to deserialize the incoming span information from the previous
    service and create a child span. Our example is an HTTP service, so the span context
    is propagated via HTTP headers. The following code extracts the context from the
    headers and creates a new span. Note that the tracer we initialized in the previous
    section must be in scope:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_application_considerations_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Extract the context information from the HTTP headers.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_application_considerations_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new span using the extracted span context.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the service handles the request, it can add child spans to the span we just
    created. As an example, let’s assume the service calls a function to perform a
    SQL query. We can use the following code to create a child span for the function
    and set the operation name to `listPayments`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Propagate Context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Up to this point, we’ve created spans within the same service or process. When
    there are other services involved in processing a request, we need to propagate
    the trace context over the wire for the service on the other end. As discussed
    in the previous section, you can use HTTP headers to propagate the context.
  prefs: []
  type: TYPE_NORMAL
- en: 'The OpenTracing libraries provide helper functions you can use to inject the
    context into HTTP headers. The following code shows an example that uses the Go
    standard library HTTP client to create and send the request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_application_considerations_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Adds a tag to mark the span as the client side of a service call.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_application_considerations_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Injects the span context into the request’s HTTP headers.
  prefs: []
  type: TYPE_NORMAL
- en: As we’ve discussed through these sections, instrumenting an application for
    tracing involves initializing a tracer, creating spans within the service, and
    propagating the span context to other services. There is additional functionality
    that you should explore, including tagging, logging, and baggage. If the platform
    team offers tracing as a platform service, now you have an idea of what it takes
    to take advantage of it.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are multiple things you can do to make your applications run better in
    Kubernetes. While most require investing time and effort to implement, we find
    that they are critical to achieve production-grade outcomes for your applications.
    As you onboard applications to your platform, make sure to consider the guidance
    provided in this chapter, including injecting configuration and secrets at runtime,
    specifying resource requests and limits, exposing application health information
    using probes, and instrumenting applications with logs, metrics, and traces.
  prefs: []
  type: TYPE_NORMAL
