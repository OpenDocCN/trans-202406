<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. GATK Best Practices for Somatic Variant Discovery"><div class="chapter" id="gatk_best_practices_for_somatic_variant">
<h1><span class="label">Chapter 7. </span>GATK Best Practices for Somatic <span class="keep-together">Variant Discovery</span></h1>

<p>In this chapter, we tackle somatic variant discovery, mainly as it applies to cancer research.<a contenteditable="false" data-primary="somatic variant discovery, GATK Best Practices" data-type="indexterm" id="ix_SVD"/><a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic variant discovery" data-type="indexterm" id="ix_GATKBPSVD"/> This is going to introduce new challenges and, correspondingly, new experimental and computational designs. We begin with somatic short variants, which still have a lot in common with germline short variants, with enough new challenges to keep things interesting. Then we expand our horizons to include copy-number variation, which involves a very different approach from what we’ve taken so far.</p>

<section data-type="sect1" data-pdf-bookmark="Challenges in Cancer Genomics"><div class="sect1" id="challenges_in_cancer_genomics">
<h1>Challenges in Cancer Genomics</h1>

<p>Before we get into the weeds, let’s make one thing clear: everything is more difficult with respect to cancer. <a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic variant discovery" data-tertiary="challenges in cancer genomics" data-type="indexterm" id="idm45625632733880"/><a contenteditable="false" data-primary="somatic variant discovery, GATK Best Practices" data-secondary="challenges in cancer genomics" data-type="indexterm" id="idm45625632732184"/><a contenteditable="false" data-primary="cancer genomics, challenges in" data-type="indexterm" id="idm45625632730760"/>Consider what is happening in the body before a tumor even begins to develop. Living cells in our bodies are not static; they are metabolically active, taking in nutrients, doing work, and pumping out waste. Some of them are dividing at various rates. Enzymes are unraveling DNA to transcribe it and/or copy and repackage it. At the scale of a single cell, very few of those molecular transactions ever go wrong, but because this is happening all the time in millions of cells, the numbers add up to a lot of little things going wrong, causing mutations across the board.<a contenteditable="false" data-primary="mutations" data-type="indexterm" id="idm45625632728920"/></p>

<p>Most of the time, these mutations have no discernible effect whatsoever. But from time to time, a mutation arises that destabilizes the affected cell’s metabolism in a way that causes it to begin dividing more rapidly and produce a tumor. That’s still not cancer yet, mind you; most tumors in our bodies remain relatively contained and harmless. However, some then experience other destabilizing mutations that kick off a chain reaction, leading to cancerous development, including aggressive growth and in the worst-case scenario, <em>metastasis</em>: dissemination to other parts of the body. <a contenteditable="false" data-primary="driver mutations" data-type="indexterm" id="idm45625632726424"/><a contenteditable="false" data-primary="passenger mutations" data-type="indexterm" id="idm45625632725320"/>The mutation events that drive this progression are appropriately called <em>driver mutations</em>, in contrast to the others, which are called <em>passenger mutations</em>. Driver mutations are typically the main focus of somatic analysis in cancer research.</p>

<p>The difficulty here is that as the tumor progresses, various metabolic functions begin to break down and the cells lose their ability to repair damaged DNA. <a contenteditable="false" data-primary="sampling of tumor tissue" data-type="indexterm" id="idm45625632722600"/>As a result, the frequency of mutation events increases, and variants accumulate in a variety of divergent cell lineages, producing a highly heterogeneous environment. When a pathologist samples the tumor tissue, they end up extracting a mix of multiple cell lines instead of the well-behaved population of largely clonal cells that you expect from healthy tissue.</p>

<p>This is a huge problem for detecting somatic variation, because depending on the internal state of the tumor tissue at the time we sample it, the variants caused by driver mutations might be represented at only a low fraction of the total genomic material. The most direct consequence is that we can’t allow the variant caller to make any assumptions about the fraction of variant allele that we expect to find. This is a big difference compared to the germline case, in which variant allele fractions should roughly follow the ploidy of the organism. That is why we use different variant callers for somatic versus germline variant discovery analysis, which, under the hood, use different algorithms to model genomic variation in the data.</p>

<p>In addition, the sampling process itself introduces confounding factors. Depending on the skill of the pathologist, the stage of progression of the tumor, and the type of biological tissue affected, we can end up with a tumor sample that is contaminated with healthy “normal” cells. Conversely, if we are able to obtain a <em>matched normal sample</em>, a sample taken from supposed healthy tissue from the same person—that sample can, in fact, be contaminated with low levels of tumor cells, as depicted in <a data-type="xref" href="#aright_parenthesis_tumor_progression_le">Figure 7-1</a>.</p>

<figure><div id="aright_parenthesis_tumor_progression_le" class="figure"><img alt="A) Tumor progression leads to heterogeneity; B) sampling is difficult." src="Images/gitc_0701.png" width="1441" height="547"/>
<h6><span class="label">Figure 7-1. </span>Tumor progression leads to heterogeneity (left); sampling is difficult (right).</h6>
</div></figure>

<p>The practical consequence of all this for somatic variant analysis is that our work will necessarily <a contenteditable="false" data-primary="contamination in variant discovery" data-secondary="somatic variant analysis and" data-type="indexterm" id="idm45625632714904"/>be deeply vulnerable to sources of contamination and error because the signal we are trying to detect is much lower compared to the noise that is present in the data, particularly in the case of advanced cancers.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Somatic Short Variants (SNVs and Indels)"><div class="sect1" id="somatic_short_variants_left_parenthesis">
<h1>Somatic Short Variants (SNVs and Indels)</h1>

<p>Let’s commence our exploration of somatic variant calling with short variants—SNVs and indels. <a contenteditable="false" data-primary="single-nucleotide variants (SNVs)" data-secondary="somatic short variants (SNVs and indels)" data-type="indexterm" id="ix_SNVind"/><a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic variant discovery" data-tertiary="somatic short variants, SNVs and indels" data-type="indexterm" id="ix_GATKBPSVDSNVind"/><a contenteditable="false" data-primary="somatic variant discovery, GATK Best Practices" data-secondary="somatic short variants (SNVs and indels)" data-type="indexterm" id="ix_SVDSNVind"/><a contenteditable="false" data-primary="indels" data-secondary="somatic short variants (SNVs and indels)" data-type="indexterm" id="ix_indSSV"/>Some of the core concepts we cover here should feel familiar if you’ve already worked through <a data-type="xref" href="ch06.xhtml#best_practices_for_germline_short_varia">Chapter 6</a>, and indeed some of the tools and underlying algorithms are the same. As we’ve done previously, we’ll be looking at piles of reads and their exact sequences to identify substitutions and small insertions and deletions.</p>

<p>However, the basic experimental design that we follow is actually very different. In germline variant discovery, we were mainly interested in identifying variants that were present in some people but not in others, which led us to favor the joint calling approach. In somatic variant discovery, we’re primarily looking for differences between samples coming from the same person, so we will shift our focus to a different paradigm: the <em>Tumor-Normal</em> pair analysis.<a contenteditable="false" data-primary="tumor-normal pair analysis" data-type="indexterm" id="idm45625632701016"/></p>

<p>The most useful source of information for identifying somatic short variants in the context of cancer is the comparison of the tumor against a sampling of healthy tissue from the same individual, which, as we said previously, is called a <em>matched normal</em>, or often <em>normal</em> for short. The idea here is that any variation observed in the normal sample is part of the germline genome of the individual and can be discounted as background, whereas any variant observed in the tumor sample that is not present in the normal sample is more likely to be a somatic mutation, as demonstrated in <a data-type="xref" href="#the_fundamental_concept_of_tumor_normal">Figure 7-2</a>.</p>

<p>Unfortunately, <a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="fundamental concept of" data-type="indexterm" id="idm45625632696296"/>some confounding factors muddy the waters. For example, biopsy samples preserved with formalin and paraffin, a widely used laboratory<a contenteditable="false" data-primary="FFPE (formalin-fixed paraffin-embedded)" data-type="indexterm" id="idm45625632694648"/> technique (FFPE, for formalin-fixed paraffin-embedded), are subject to biochemical alterations that happen during <a contenteditable="false" data-primary="biochemical alterations in samples preserved with formalin and paraffin" data-type="indexterm" id="idm45625632693272"/>sample preparation and cause patterns of false-positive variant calls that are specific to the tumor sample. Conversely, the presence of tumor cells in normal tissue (either due to contamination during sampling or metastatic dispersion) can cause real somatic variants to be erroneously discounted as being part of the germline of the individual. <a contenteditable="false" data-primary="contamination in variant discovery" data-secondary="sources of contamination affecting all high-throughput sequencing" data-type="indexterm" id="idm45625632691624"/>Finally, as we discussed earlier, the various sources of technical error and contamination that affect all high-throughput sequencing techniques to some degree will have a proportionately higher impact on somatic calling. So, we will need to apply some robust processing and filtering techniques to mitigate all these problems. (The overall workflow is illustrated in <a data-type="xref" href="#best_practices_for_somatic_short_varian">Figure 7-3</a>.)</p>

<figure class="width-75"><div id="the_fundamental_concept_of_tumor_normal" class="figure"><img alt="The fundamental concept of Tumor-Normal comparison." src="Images/gitc_0702.png" width="1440" height="1129"/>
<h6><span class="label">Figure 7-2. </span>The fundamental concept of Tumor-Normal comparison.</h6>
</div></figure>

<p>Before we get into the details of the Tumor-Normal workflow in the next subsection, it’s important to note that sometimes it’s not possible to apply the full Tumor-Normal pair analysis to a sample or set of samples, usually because we simply don’t have matched normals for them. This is particularly frustrating when that lack comes from an investigator’s failure to collect a matched normal from the participant or patient. Such cases highlight the importance of making sure that researchers map out the full analysis protocol before engaging in data collection. On the other hand, in some cases it’s biologically impossible to obtain a matched normal; for example, blood-borne cancers typically reach every tissue in the body, so we can’t assume that any tissue sample would constitute an appropriate normal.</p>

<p>Whatever the reason for the absence of a matched normal, the workflow that we present in the next subsection can be run on a tumor sample with only a few minor modifications, which are detailed in the online <a href="https://oreil.ly/ZgIrB">GATK documentation</a>. However, you should be aware that the results will necessarily be noisier because you will be relying on the germline population resource to exclude the person’s own germline genome.</p>

<section data-type="sect2" data-pdf-bookmark="Overview of the Tumor-Normal Pair Analysis Workflow"><div class="sect2" id="tumor_normal_pair_analysis_workflow">
<h2>Overview of the Tumor-Normal Pair Analysis Workflow</h2>

<p>This <a contenteditable="false" data-primary="single-nucleotide variants (SNVs)" data-secondary="somatic short variants (SNVs and indels)" data-tertiary="tumor-normal pair analysis" data-type="indexterm" id="ix_SNVindTNP"/>workflow, illustrated in <a data-type="xref" href="#best_practices_for_somatic_short_varian">Figure 7-3</a>, is designed to be applied to a tumor sample and its matched normal. <a contenteditable="false" data-primary="somatic variant discovery, GATK Best Practices" data-secondary="somatic short variants (SNVs and indels)" data-tertiary="tumor-normal pair analysis workflow" data-type="indexterm" id="ix_SVDSNVindTNPA"/><a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="workflow" data-type="indexterm" id="ix_TNPAwk"/>We can apply it equally to whole genome data as well as exome data, but both the tumor and the normal must be of the same data type and have been run through the same preprocessing workflow, as we described for germline variant discovery.</p>

<figure class="width-75"><div id="best_practices_for_somatic_short_varian" class="figure"><img alt="Best Practices for somatic short variant discovery." src="Images/gitc_0703.png" width="1440" height="1768"/>
<h6><span class="label">Figure 7-3. </span>Best Practices for somatic short variant discovery.</h6>
</div></figure>

<p>The main variant calling step, which involves a tool called <code>Mutect2</code>, is applied on both the tumor and the normal sample, with the addition of two important resources: a Panel of Normals (PoN) <a contenteditable="false" data-primary="Panel of Normals (PoN)" data-type="indexterm" id="idm45625632671272"/>and a database of germline population frequencies of all germline variants that have been previously reported. The PoN is a resource that allows us to eliminate common technical artifacts; we dedicate the next subsection to explaining how it works and how to create one, although you won’t run it yourself for practical reasons. We talk about the germline population frequencies resource in <span class="keep-together"><a data-type="xref" href="#filtering_mutect2_calls">“Filtering Mutect2 Calls”</a></span>. The filtering process will take into account read orientation statistics, an estimate of cross-sample contamination, germline <span class="keep-together">background</span>, and concordance with the PoN. Finally, we apply functional annotation to the variant callset to predict the effect of candidate variants.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Creating a Mutect2 PoN"><div class="sect2" id="creating_a_mutect2_pon">
<h2>Creating a Mutect2 PoN</h2>

<p>The PoN is a callset<a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="workflow" data-tertiary="creating a Mutect2 PoN" data-type="indexterm" id="idm45625632665064"/> in VCF format that aims to <a contenteditable="false" data-primary="Panel of Normals (PoN)" data-secondary="creating Mutect2 PoN" data-type="indexterm" id="idm45625632663240"/>capture common recurring artifacts, so we can filter those out if we encounter them in our tumor data. We generate it <a contenteditable="false" data-primary="Mutect2 somatic caller" data-type="indexterm" id="idm45625632661608"/>by running the somatic caller, <code>Mutect2</code>, on a set of normal samples that were produced with the same sequencing and library preparation technologies as our tumor sample. The idea is that we’re asking the caller to show us everything it could consider a somatic variant, excluding obvious germline variants (unless otherwise specified). Because these are normals, not tumor samples, we can reasonably assume that any variant calls that are produced this way are either germline variants or artifacts. For those that are more likely to be artifacts, we can therefore further assume that if we see the same artifacts in multiple normals, they might have been caused by the technological processes involved, so we can expect to see them pop up in some of our tumor samples that were processed the same way. If we do see them, we’ll want to discount their likelihood of being real somatic variants.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The normal samples used for making the PoN usually come from people who are unrelated to the person whose tumor we are analyzing. They can be matched normals from other cancer research participants or germline samples collected from healthy individuals in unrelated research projects, as long as the appropriate consents have been provided. The background genetics of the participants or their population of origin don’t really matter; it’s all about the technical profile of the data. Ideally, we want to include at least 40 samples; most PoNs used for research purposes at the Broad Institute are composed of several hundred samples.</p>
</div>

<p>We won’t run the PoN creation commands in this chapter, because they would take too long to run. <a contenteditable="false" data-primary="Mutect2 somatic caller" data-secondary="creating PoN" data-type="indexterm" id="idm45625632656712"/>Instead, we demonstrate usage with some generic command lines. You can find links to full implementations in the <a href="https://oreil.ly/ZgIrB">GATK Best Practices documentation</a>.</p>

<p>If we were to do this, we would first run <code>Mutect2</code> in tumor-only mode on the normals selected to be in our PoN. We would do this separately on all the normals in our panel. The following command (and subsequent ones in this section) are just examples; we’ll have you execute commands on your VM a little later:</p>

<pre data-type="programlisting">
 gatk Mutect2 \
    -R reference.fasta \
    -I normal_1.bam \
    -O normal_1.vcf.gz \
    --max-mnp-distance 0</pre>

<p>This command applies the somatic variant calling model to the normal tissue sample’s BAM file and produces a <a contenteditable="false" data-primary="VCF (Variant Call Format) files" data-type="indexterm" id="idm45625632651880"/>VCF file of calls <a contenteditable="false" data-primary="Mutect2 somatic caller" data-secondary="--max-mnp-distance 0 setting" data-type="indexterm" id="idm45625632650584"/>that are most likely all either artifacts or germline variants.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The <code>--max-mnp-distance 0</code> setting disables the tool’s ability to combine neighboring SNVs into multinucleotide variants in order to maximize comparability across all the normals in the PoN that we’re putting together.</p>
</div>

<p>Next, we would consolidate<a contenteditable="false" data-primary="VCF (Variant Call Format) files" data-secondary="consolidating per-normal VCFs in tumor-normal pair analysis" data-type="indexterm" id="idm45625632646744"/> all the per-normal VCFs using <code>GenomicsDB</code>, which you might<a contenteditable="false" data-primary="GenomicsDB" data-secondary="consolidating per-normal VCS in tumor-normal pair analysis" data-type="indexterm" id="idm45625632644712"/> recognize from the germline joint calling workflow. At that time, we were consolidating GVCFs, whereas here we’re working with regular VCFs, but it doesn’t make any difference: the <code>GenomicsDB</code> tools are quite happy to work with either type of VCF:</p>

<pre data-type="programlisting">
gatk GenomicsDBImport \
    -R reference.fasta \
    -L intervals.interval_list \
    -V normal_1.vcf.gz \
    -V normal_2.vcf.gz \
    -V normal_3.vcf.gz \
    --genomicsdb-workspace-path pon_db</pre>

<p>Finally, we would extract the calls that are relevant to the goals of the PoN. By default, the<a contenteditable="false" data-primary="CreateSomaticPanelOfNormals" data-type="indexterm" id="idm45625632641016"/> rule is to keep any variant call observed in two or more samples but below a certain frequency threshold in the germline population resource:</p>

<pre data-type="programlisting">
gatk CreateSomaticPanelOfNormals \
    -R reference.fasta \
    -V gendb://pon_db \
    --germline-resource af-only-gnomad.vcf.gz \
    -O pon.vcf.gz</pre>

<p>You might recognize <a href="https://oreil.ly/gNICj">gnomAD</a> as the population resource <a contenteditable="false" data-primary="gnomAD database" data-type="indexterm" id="idm45625632637576"/>we used in <a data-type="xref" href="ch06.xhtml#best_practices_for_germline_short_varia">Chapter 6</a>, in the single-sample filtering protocol. The gnomAD database is a public resource that includes variant calls from more than 100,000 people, and for each, it provides the frequency at which each allele is found in the population of the database. We use that information here to gauge the likelihood that a variant call that shows up in several normals in the panel might in fact be a germline variant rather than a recurring <span class="keep-together">artifact.</span></p>

<p>This generates the final VCF that we will use as a PoN. It does not include any of the sample genotypes; only site-level information is retained. We provide an example PoN that you can examine with good old <code>zcat</code>, <code>grep</code>, and <code>head</code>, as we’ve done previously, if you want to see the structure of the information within the file (execute this command in the <em>/home/book/data/somatic</em> directory inside the GATK container):</p>

<pre data-type="programlisting">
# zcat resources/chr17_m2pon.vcf.gz | grep -v '##' | head -3
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO
chr6    29941027        .       G       A       .       .       .
chr6    29941061        .       G       C       .       .       .</pre>

<p>Note that this example PoN file includes data only in a subset of regions of interest that are located within chromosome 6, chromosome 11, and chromosome 17.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Running Mutect2 on the Tumor-Normal Pair"><div class="sect2" id="running_mutect2_on_the_tumor_normal_pai">
<h2>Running Mutect2 on the Tumor-Normal Pair</h2>

<p>Now that <a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="workflow" data-tertiary="running Mutect2 on tumor-normal pair" data-type="indexterm" id="idm45625632628152"/>you know <a contenteditable="false" data-primary="Mutect2 somatic caller" data-secondary="running on tumor-normal pair" data-type="indexterm" id="idm45625632626360"/>how to create a PoN, let’s move to the main event of this section, which consists of running <code>Mutect2</code> on the Tumor-Normal pair using a PoN that we created for you from 40 publicly available normal samples from the 1000 Genomes Project.<a contenteditable="false" data-primary="1000 Genomes project" data-primary-sortas="One Thousand" data-type="indexterm" id="idm45625632624136"/> Just as in <a data-type="xref" href="ch06.xhtml#best_practices_for_germline_short_varia">Chapter 6</a>, we’re going to do this work within the GATK container on our trusty VM, so turn on your VM if it’s not already running, and spin up the GATK container as we showed you in <a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a>. This time, however, our working directory is <em>/home/book/data/somatic</em>, and we’ll need to make another sandbox:</p>

<pre data-type="programlisting">
# cd /home/book/data/somatic
# mkdir sandbox</pre>

<p>We run <code>Mutect2</code> on the Tumor-Normal pair together, specifying which sample name (as encoded in the <code>SM</code> tag in the BAM file) should be used for the normal with the <span class="keep-together"><code>-normal</code></span> argument. We provide the PoN and the gnomAD germline resource with the <span class="keep-together"><code>-pon</code></span> and <code>--germline-resource</code> arguments, respectively. Plus, we specify intervals (using <code>-L</code> and an interval list file) because we’re running on exome data:</p>

<pre data-type="programlisting">
# gatk Mutect2 \
    -R ref/Homo_sapiens_assembly38.fasta \
    -I bams/tumor.bam \
    -I bams/normal.bam \
    -normal HCC1143_normal \
    -L resources/chr17plus.interval_list \
    -pon resources/chr17_m2pon.vcf.gz \
    --germline-resource resources/chr17_af-only-gnomad_grch38.vcf.gz \
    -bamout sandbox/m2_tumor_normal.bam \
    -O sandbox/m2_somatic_calls.vcf.gz</pre>

<p>This will run for a few minutes, so it’s a good time to take a stretch break. After about five minutes, you should see the completion message from <code>Mutect2</code>:</p>

<pre data-type="programlisting">
15:07:19.715 INFO  ProgressMeter - Traversal complete. Processed 285005 total
regions in 5.0 minutes.</pre>

<p>This <code>Mutect2</code> command produces a VCF file containing possible variant calls as well as a bamout file. <a contenteditable="false" data-primary="HaplotypeCaller" data-secondary="Mutect2 and" data-type="indexterm" id="idm45625632610792"/>You might remember the bamout file from the exercises we ran with <code>HaplotypeCaller</code> in <a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a>; this is the same thing. <code>Mutect2</code> is built on most of the same code as <code>HaplotypeCaller</code>, and pulls the same graph-based realignment trick to improve sensitivity to indels. The big difference between them is the genotyping model. For more information on their respective algorithms, see the <code>Haplotype​Caller</code> and <code>Mutect2</code> documentation on <a href="https://oreil.ly/Bits1">GATK’s website</a>. For now, just keep in mind that <code>Mutect2</code> also realigns the reads, so if we want to look at the read data as part of the variant review process later on, we’ll need the bamout. Because this is something analysts do very frequently for somatic calls (much more, relatively speaking, than for germline calls) we just set the <code>Mutect2</code> command to produce the bamout <span class="keep-together">systematically.</span><a contenteditable="false" data-primary="BAMs (Binary Alignment Maps)" data-secondary="bamout produced by Mutect2 command" data-type="indexterm" id="idm45625632603416"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Estimating Cross-Sample Contamination"><div class="sect2" id="estimating_cross_sample_contamination">
<h2>Estimating Cross-Sample Contamination</h2>

<p>As we outlined earlier, identification of somatic mutations is more heavily affected by sources of low-grade noise than the germline case.<a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="workflow" data-tertiary="estimating cross-sample contamination" data-type="indexterm" id="idm45625632600024"/><a contenteditable="false" data-primary="contamination in variant discovery" data-secondary="estimating cross-sample contamination in tumor-normal pair analysis" data-type="indexterm" id="idm45625632598344"/> Even small amounts of contamination between samples (which happens more often than researchers like to think) can confuse the caller and lead to a lot of FPs. Indeed, we have no direct way to distinguish between an allele that shows up in the data because there is a real mutation in the biological tissue, and one that shows up because our sample is contaminated with DNA from someone else who has that allele in their germline.</p>

<p>We can’t directly correct for such contamination, but we can estimate how much it affects any given sample. From there, we can flag any mutation calls that are observed at an allelic fraction equal to or smaller than the contamination rate. It doesn’t mean we rule out those calls as being necessarily false, but it does mean we’ll be extra skeptical of those calls when we move on to the next phase of analysis.</p>

<p>To estimate the contamination rate in our tumor sample, we first identify homozygous-variant sites <a contenteditable="false" data-primary="homozygous-variant sites, finding in tumor-normal pair analysis" data-type="indexterm" id="idm45625632594952"/>in the Normal to choose what sites to look at in the Tumor and then evaluate how much contamination we might have in the tumor based on the fraction of reads supporting the reference allele at those sites. The idea is that because those sites should be homozygous variant, any reference reads present must have come from someone else through a contamination event.</p>

<p>To select the sites that we use in the calculation, we look at biallelic sites that are found in a catalog of common variation (so that there’s a good chance they will be relevant) but have an alternate allele frequency that is rather low (so there won’t be too much noise from alternate alleles).<a contenteditable="false" data-primary="GetPileupSummaries tool" data-type="indexterm" id="idm45625632592552"/> Then, for every site in that subset, we do a quick pileup-based genotyping run to identify those that are homozygous-variant in that sample. We do this on both the tumor sample and the matched normal:</p>

<pre data-type="programlisting">
# gatk GetPileupSummaries \
    -I bams/normal.bam \
    -V resources/chr17_small_exac_common_3_grch38.vcf.gz \
    -L resources/chr17_small_exac_common_3_grch38.vcf.gz \
    -O sandbox/normal_getpileupsummaries.table

# gatk GetPileupSummaries \
    -I bams/tumor.bam \
    -V resources/chr17_small_exac_common_3_grch38.vcf.gz \
    -L resources/chr17_small_exac_common_3_grch38.vcf.gz \
    -O sandbox/tumor_getpileupsummaries.table</pre>

<p>These two commands should run very quickly. If you see a warning about the <code>GetPileupSummaries</code> tool being in a beta evaluation stage and not yet ready for production, you can ignore it; this is a leftover of the development process and will be removed in the near future.<a contenteditable="false" data-primary="alpha or beta evaluation stage, GATK tools" data-type="indexterm" id="idm45625632588936"/><a contenteditable="false" data-primary="beta evaluation stage, GATK tools" data-type="indexterm" id="idm45625632587800"/></p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>GATK developers tend to be very cautious and label their tools as alpha or beta when they start working on them, to make sure that researchers don’t mistake an experimental tool for something that has been fully vetted. However, they sometimes forget to remove or update those labels when the tools have been fully vetted, so the warnings remain longer than necessary. If you’re ever in doubt about the state of a particular tool, don’t hesitate to ask the support team by posting in the <a href="https://oreil.ly/KmHzX">community support forum</a>.</p>
</div>

<p>Each run produces a table that summarizes the allelic counts at each site that was selected as well as the allele frequency annotated in the population resource:</p>

<pre class="small" data-type="programlisting">
# head -5 sandbox/normal_getpileupsummaries.table
#&lt;METADATA&gt;SAMPLE=HCC1143_normal
contig  position        ref_count       alt_count       other_alt_count allele_frequency
chr6    29942512        7       4       0       0.063
chr6    29942517        12      4       0       0.062
chr6    29942525        13      7       0       0.063

# head -5 sandbox/tumor_getpileupsummaries.table
#&lt;METADATA&gt;SAMPLE=HCC1143_tumor
contig  position        ref_count       alt_count       other_alt_count allele_frequency
chr6    29942512        9       0       0       0.063
chr6    29942517        13      1       0       0.062
chr6    29942525        13      7       0       0.063</pre>

<p>Now we can <a contenteditable="false" data-primary="CalculateContamination tool" data-type="indexterm" id="idm45625632581560"/>do the actual estimation by providing both tables to the calculator tool:</p>

<pre data-type="programlisting">
# gatk CalculateContamination \
    -I sandbox/tumor_getpileupsummaries.table \
    -matched sandbox/normal_getpileupsummaries.table \
    -tumor-segmentation sandbox/segments.table \
    -O sandbox/pair_calculatecontamination.table </pre>

<p>This command produces a final table that tells us the likely rate of cross-sample contamination in the Tumor callset. Viewing the contents of the file shows us that the level of contamination of the tumor is estimated at 1.15%, with an error of 0.19%:</p>

<pre data-type="programlisting">
$ cat sandbox/pair_calculatecontamination.table
sample  contamination   error
HCC1143_tumor   0.011485364960150258    0.0019180421331441303</pre>

<p>This means that one read out of every hundred is likely to come from someone else. This percentage will effectively be our floor for detecting low-frequency somatic events; for any potential variant called at or below that AF, we would have zero power to judge whether they were real or created through contamination. And even a larger AF could be due entirely to contamination. We’ll feed the table into the filtering tool so that it can take the contamination estimate properly into account.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Filtering Mutect2 Calls"><div class="sect2" id="filtering_mutect2_calls">
<h2>Filtering Mutect2 Calls</h2>

<p>Much like <code>HaplotypeCaller</code>, <code>Mutect2</code> is designed to be very sensitive and capture as many true positives as possible. As a result, we know that the raw callset will be rife with false positives of various types. <a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="workflow" data-tertiary="filtering Mutect2 calls" data-type="indexterm" id="idm45625632573592"/><a contenteditable="false" data-primary="Mutect2 somatic caller" data-secondary="filtering calls" data-type="indexterm" id="idm45625632571976"/><a contenteditable="false" data-primary="FilterMutectCalls tool" data-type="indexterm" id="idm45625632570600"/>To filter these calls, we’re going to use a tool called <code>FilterMutectCalls</code>, which filters calls based on a single quantity: the probability that a variant is a somatic mutation. Internally the tool takes into account multiple factors, including the germline population frequencies provided during the variant-calling step, the contamination estimates, and the read orientation statistics computed earlier. After it has calculated that probability for each variant call, the tool then determines the threshold that optimizes the <em>F score,</em> the harmonic mean of sensitivity and precision across the entire callset. As a result, we can simply run this one command to apply default filtering to our callset:</p>

<pre data-type="programlisting">
# gatk FilterMutectCalls \
    -R ref/Homo_sapiens_assembly38.fasta \
    -V sandbox/m2_somatic_calls.vcf.gz \
    --contamination-table sandbox/pair_calculatecontamination.table \
    -O sandbox/m2_somatic_calls.filtered.vcf.gz \
    --stats sandbox/m2_somatic_calls.vcf.gz.stats \
    --tumor-segmentation sandbox/segments.table</pre>

<p>The main output of this operation is the VCF output file containing all variants with filter annotations <a contenteditable="false" data-primary="VCF (Variant Call Format) files" data-secondary="output of filtering Mutect2 calls" data-type="indexterm" id="idm45625632566360"/>applied as appropriate:</p>

<pre data-type="programlisting">
15:25:14.742 INFO  ProgressMeter - Traversal complete. Processed 333 total
variants in 0.0 minutes.</pre>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you want to tweak the balance point one way or the other, you can adjust<a contenteditable="false" data-primary="weight of sensitivity versus precision, adjusting in harmonic mean" data-type="indexterm" id="idm45625632562984"/> the relative weight of sensitivity versus precision in the harmonic mean.<a contenteditable="false" data-primary="-f-score-beta parameter" data-primary-sortas="f-score-beta" data-type="indexterm" id="idm45625632561608"/> Setting the <code>-f-score-beta</code> parameter to a value greater than its default of <code>1</code> increases sensitivity, whereas setting it lower favors greater precision.</p>
</div>

<p>Alright, it’s time to have a look at the calls we produced in IGV. You might have noticed that we’re now working with the hg38 reference build, so we’ll need to adjust the reference setting in IGV before we can try to load any files.<a contenteditable="false" data-primary="IGV (Integrated Genome Viewer)" data-secondary="loading and viewing files from tumor-normal pair analysis" data-type="indexterm" id="idm45625632558344"/></p>

<p>You’re going to load the following files: the original BAM files for the Tumor and the Normal, the bamout generated by <code>Mutect2</code>, and the filtered callset. Identify the files based on the commands you ran a moment ago and then follow the same procedure as in <a data-type="xref" href="ch04.xhtml#first_steps_in_the_cloud">Chapter 4</a> through <a data-type="xref" href="ch06.xhtml#best_practices_for_germline_short_varia">Chapter 6</a> to copy the files to your Google Cloud Storage bucket and then load them in IGV using the File &gt; URL pathway.</p>

<p>In IGV, set the view coordinates to <code><strong>chr17:7,666,402-7,689,550</strong></code> after the files are loaded, as shown in <a data-type="xref" href="#zooming_in_on_tp53_in_igvdot">Figure 7-4</a>, which are centered on the TP53 locus. We care about this gene because it is known as a tumor suppressor; it is activated by DNA damage and produces a protein called p53 that can either repair the damage or trigger killing off the cell. Any mutations to this gene that interfere with this very important function could contribute to allowing unchecked tumor development.</p>

<p>To review this call in detail, zoom into the somatic call in the output BAM track, using coordinates <code><strong>chr17:7,673,333-7,675,077</strong></code>. Hover over or click the gray call in the variant track to view annotations, and try scrolling through the data to evaluate the amount of coverage for each sample. In the sequence tracks, we see a C to T variant light up in red for the Tumor but not the Normal (<a data-type="xref" href="#zooming_in_on_tp53_in_igvdot">Figure 7-4</a>).</p>

<figure class="no-frame"><div id="zooming_in_on_tp53_in_igvdot" class="figure"><img alt="Zooming in on TP53 in IGV." src="Images/gitc_0704.png" width="1206" height="665"/>
<h6><span class="label">Figure 7-4. </span>Zooming in on TP53 in IGV.</h6>
</div></figure>

<p>What do you think of this somatic variant call?</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="tweaking_igv_visualization_settings">
<h5>Tweaking IGV Visualization Settings</h5>

<p>Tweaking some IGV settings to make the review easier can be helpful. <a contenteditable="false" data-primary="IGV (Integrated Genome Viewer)" data-secondary="tweaking visualization settings" data-type="indexterm" id="idm45625632544200"/>First, you can make room to focus on certain tracks by minimizing the space taken up by others or removing them entirely. You can resize each track panel by clicking the gray separator lines and dragging them up or down. You can also switch the data view of a specific track to a more compact display by right-clicking or Ctrl-clicking the track and then, on the menu that opens, selecting the Collapsed or Squished view options. And, of course, you can remove individual tracks by right-clicking or Ctrl-clicking (Shift-clicking several to select them at the same time) and then selecting Remove Track.</p>

<p>Another neat feature set available in the tracks’ contextual menu is the ability to order, group, and/or color the data based on specific properties. For example, we often use the following combination for examining output from both <code>HaplotypeCaller</code> and <code>Mutect2</code>: group by sample, color alignments by tag, using HC as tag, and sort by base.<a contenteditable="false" data-primary="Mutect2 somatic caller" data-secondary="tweaking IGV visualization settings to view output" data-type="indexterm" id="idm45625632540376"/><a contenteditable="false" data-primary="HaplotypeCaller" data-secondary="tweaking IGV visualization settings to view output" data-type="indexterm" id="idm45625632538904"/></p>

<p>It’s also worth exploring the IGV Preferences pane, particularly the Alignments tab, to get a good handle on the options available there. For example, we used it to toggle soft clips for exercises in <a data-type="xref" href="ch05.xhtml#first_steps_with_gatk">Chapter 5</a>; you can also toggle downsampling, the display of duplicates, and other metadata-based display options.</p>
</div></aside>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Annotating Predicted Functional Effects with Funcotator"><div class="sect2" id="annotating_predicted_functional_effects">
<h2>Annotating Predicted Functional Effects with Funcotator</h2>

<p>Filtering somatic mutation calls can be an especially daunting task compared to their germline equivalent.<a contenteditable="false" data-primary="filtering" data-secondary="of somatic mutation cells vs. germline equivalents" data-type="indexterm" id="idm45625632533736"/><a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="workflow" data-tertiary="annotating predicted functional effects with Funcotator" data-type="indexterm" id="idm45625632532328"/><a contenteditable="false" data-primary="annotating predicted functional effects with Funcotator" data-type="indexterm" id="idm45625632530680"/> It can therefore be particularly helpful to annotate the calls with predicted functional effects and their significance. For example, a stop codon in the middle of a protein coding region is likely to be more significant than a mutation in the middle of an intron. Knowing this about your calls can help you prioritize which ones you spend time investigating in depth.</p>

<p>To gauge functional<a contenteditable="false" data-primary="functional annotations, resources for" data-type="indexterm" id="idm45625632528616"/> impact, we need to know which regions of the genome code for protein sequence and which correspond to elements important to gene expression.<a contenteditable="false" data-primary="transcript annotation resources" data-type="indexterm" id="idm45625632526840"/> Transcript annotation resources such as <a href="https://www.gencodegenes.org">GENCODE</a> capture<a contenteditable="false" data-primary="GTF (Gene Transfer Format)" data-type="indexterm" id="idm45625632524888"/> such information in the standardized <a href="https://oreil.ly/SDmFX">Gene Transfer Format</a> (GTF).<a contenteditable="false" data-primary="Gene Transfer Format (GTF)" data-type="indexterm" id="idm45625632522920"/> The GATK team provides a <a href="https://oreil.ly/LDGdM">set of resources</a> containing compiled functional annotation resources, or datasources, that are suitable for many common functional annotation needs as <a contenteditable="false" data-primary="Funcotator tool" data-type="indexterm" id="idm45625632520760"/>well as a tool called <code>Funcotator</code> to annotate your callset with information from these datasources. You can also create your own custom data sources. <a contenteditable="false" data-primary="VCF (Variant Call Format) files" data-secondary="default output of Funcotator" data-type="indexterm" id="idm45625632518952"/>In addition, although <code>Funcotator</code> outputs results in VCF by default, you can make it<a contenteditable="false" data-primary="MAF (Mutation Annotation Format)" data-type="indexterm" id="idm45625632516856"/> output <a contenteditable="false" data-primary="Mutation Annotation Format (MAF)" data-type="indexterm" id="idm45625632515608"/>Mutation Annotation Format (MAF), instead, which the cancer genomics community uses extensively. See the <a href="https://oreil.ly/6qw0X">Funcotator documentation</a> for details on both options.</p>

<p>For now, though, let’s apply <code>Funcotator</code> to our filtered <code>Mutect2</code> callset:</p>

<pre class="small" data-type="programlisting">
# gatk Funcotator \
    --data-sources-path resources/funcotator_dataSources_GATK_Workshop_20181205/ \
    --ref-version hg38 \
    -R ref/Homo_sapiens_assembly38.fasta \
    -V sandbox/m2_somatic_calls.filtered.vcf.gz \
    -O sandbox/m2_somatic_calls.funcotated.vcf.gz \
    --output-file-format VCF</pre>

<p>This runs very quickly and produces a VCF in which our somatic callset has now been lovingly annotated based on the GENCODE functional data. Here’s a sneak peek of what the annotations look like in their natural habitat:</p>

<pre class="small" data-type="programlisting">
# zcat sandbox/m2_somatic_calls.funcotated.vcf.gz | grep -v '##' | head -3
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  HCC1143_normal
HCC1143_tumor
chr17   1677390 .       A       T       .       weak_evidence
CONTQ=19;DP=23;ECNT=1;FUNCOTATION=[PRPF8|hg38|chr17|1677390|1677390|INTRON||SNP|A|A|T|
g.chr17:1677390A&gt;T|ENST00000572621.5|-|||c.e13-
175T&gt;A|||0.4463840399002494|CTGCCTCTCAAGGCCCCAGAA|PRPF8_ENST00000304992.10_INTRON];
GERMQ=32;MBQ=33,31;MFRL=301,311;MMQ=60,60;MPOS=22;NALOD=1.06;NLOD=3.01;POPAF=6.00;SEQQ
=1;STRANDQ=17;TLOD=4.22 GT:AD:AF:DP:F1R2:F2R1:SB       0/0:10,0:0.081:10:6,0:4,0:6,4,0,
0	0/1:9,2:0.229:11:5,1:3,1:6,3,2,0
chr17   2394409 .       G       T       .       PASS
CONTQ=93;DP=106;ECNT=1;FUNCOTATION=[MNT|hg38|chr17|2394409|2394409|INTRON||SNP|G|G|T|
g.chr17:2394409G&gt;T|ENST00000575394.1|-|||c.e1-
6231C&gt;A|||0.6209476309226932|TTCCTGACCAGCGCCGCCACC|MNT_ENST00000174618.4_INTRON];
GERMQ=93;MBQ=32,31;MFRL=148,177;MMQ=60,60;MPOS=14;NALOD=1.56;NLOD=10.52;POPAF=6.00;SEQQ
=93;STRANDQ=93;TLOD=30.05  GT:AD:AF:DP:F1R2:F2R1:SB       0/0:35,0:0.027:35:15,0:19,0:4,
31,0,0	0/1:53,13:0.206:66:23,5:29,8:13,40,4,9
</pre>

<p>Now let’s have a look at the annotations specifically for the TP53 mutation that we viewed earlier in IGV, at chr17:7674220:</p>

<pre class="small" data-type="programlisting">
# zcat sandbox/m2_somatic_calls.funcotated.vcf.gz | grep 7674220
chr17   7674220 .       C       T       .       PASS
CONTQ=93;DP=134;ECNT=1;FUNCOTATION=[TP53|hg38|chr17|7674220|7674220|MISSENSE||SNP|C|C|T|
g.chr17:7674220C&gt;T|ENST00000269305.8|-|7|933|c.743G&gt;A|c.(742-
744)cGg&gt;cAg|p.R248Q|0.5660847880299252|GATGGGCCTCCGGTTCATGCC|TP53_ENST00000445888.6_MISSENSE_
p.R248Q/TP53_ENST
00000420246.6_MISSENSE_p.R248Q/TP53_ENST00000622645.4_MISSENSE_p.R209Q/
TP53_ENST00000610292.4_MISSENSE_p.R209Q/TP53_ENST00000455263.6_MISSENSE_p.R248Q/
TP53_ENST00000610538.4_MISSENSE_p.R209Q/TP53_ENST00000620739.4_MISSENSE_p.R209Q/
TP53_ENST00000619485.4_MISSENSE_p.R209Q/TP53_ENST00000510385.5_MISSENSE_p.R116Q/
TP53_ENST00000618944.4_MISSENSE_p.R89Q/TP53_ENST000005
04290.5_MISSENSE_p.R116Q/TP53_ENST00000610623.4_MISSENSE_p.R89Q/
TP53_ENST00000504937.5_MISSENSE_p.R116Q/TP53_ENST00000619186.4_MISSENSE_p.R89Q/
TP53_ENST00000359597.8_MISSENSE_p.R248Q/TP53_ENST00000413465.6_MISSENSE_p.R248Q/
TP53_ENST00000615910.4_MISSENSE_p.R237Q/TP53_ENST00000617185.4_MISSENSE_p.R248Q];
GERMQ=93;MBQ=31,32;MFRL=146,140;MMQ=60,60;MPOS=21;NALOD=1.73;NLOD=15.33;POPA
F=6.00;SEQQ=93;STRANDQ=93;TLOD=264.54      GT:AD:AF:DP:F1R2:F2R1:SB
0/0:51,0:0.018:51:22,0:29,0:36,15,0,0   0/1:0,76:0.987:76:0,38:0,38:0,0,52,24</pre>

<p>This SNV is a C-to-T substitution that is predicted <a contenteditable="false" data-primary="missense mutations" data-type="indexterm" id="idm45625632505032"/>to cause an arginine-to-glutamine <em>missense mutation</em>. Missense mutations change the protein that is produced from the gene, which can be functionally neutral, but can also have deleterious effects. If we look at the rest of the file, out of our 124 mutation records, 21 were annotated as <code>MISSENSE</code>; and of these, 10 passed all filters. That information should help us prioritize what to investigate in the next stage of our analysis.</p>

<p>With that, we’re done with the Tumor-Normal pair analysis workflow for discovery of somatic SNVs and indels! Next, we’re going to go over the process we apply for investigating somatic copy-number alterations.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you’re taking a break before continuing on with the next section, consider stopping your VM to avoid paying for it while you’re away living your best life.<a contenteditable="false" data-primary="indels" data-secondary="somatic short variants (SNVs and indels)" data-startref="ix_indSSV" data-type="indexterm" id="idm45625632500680"/><a contenteditable="false" data-primary="single-nucleotide variants (SNVs)" data-secondary="somatic short variants (SNVs and indels)" data-startref="ix_SNVindTNP" data-tertiary="tumor-normal pair analysis" data-type="indexterm" id="idm45625632498840"/><a contenteditable="false" data-primary="somatic variant discovery, GATK Best Practices" data-secondary="somatic short variants (SNVs and indels)" data-startref="ix_SVDSNVindTNPA" data-tertiary="tumor-normal pair analysis workflow" data-type="indexterm" id="idm45625632496808"/><a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="workflow" data-startref="ix_TNPAwk" data-type="indexterm" id="idm45625632494808"/><a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic variant discovery" data-startref="ix_GATKBPSVDSNVind" data-tertiary="somatic short variants, SNVs and indels" data-type="indexterm" id="idm45625632493144"/><a contenteditable="false" data-primary="single-nucleotide variants (SNVs)" data-secondary="somatic short variants (SNVs and indels)" data-startref="ix_SNVind" data-type="indexterm" id="idm45625632491160"/><a contenteditable="false" data-primary="somatic variant discovery, GATK Best Practices" data-secondary="somatic short variants (SNVs and indels)" data-startref="ix_SVDSNVind" data-type="indexterm" id="idm45625632489464"/></p>
</div>
</div></section>
</div></section>

<section class="pagebreak-before" data-type="sect1" data-pdf-bookmark="Somatic Copy-Number Alterations"><div class="sect1" id="somatic_copy_number_alterations">
<h1 class="less_space">Somatic Copy-Number Alterations</h1>

<p>So far, we’ve been<a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-type="indexterm" id="ix_SCNA"/> looking exclusively<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic copy-number alterations" data-type="indexterm" id="ix_GATKBPSCNA"/> at small variants, SNVs, and indels that are characterized based on the presence or absence of specific nucleotides compared to the reference sequence. Moving to the copy number involves a big mental (and methodological!) shift given that now we’re going to be looking at the <em>relative amounts of sequence</em> in the sample of interest, measured relative to itself (<a data-type="xref" href="#difference_between_copy_number_and_copy">Figure 7-5</a> and <a data-type="xref" href="#spectral_karyotyping_paints_each_chromo">Figure 7-6</a>). In other words, we’re not actually going to measure the copy number that is physically present in the biological material. What we measure is the copy ratio, which we use as a proxy because it is a <em>consequence</em> of copy-number alterations (CNAs). <a contenteditable="false" data-primary="copy-number alterations (CNAs)" data-seealso="somatic copy-number alterations, GATK Best Practices" data-type="indexterm" id="idm45625632478344"/>As part of that process, we’re going to use the reference genome primarily as a coordinate system for defining segments that display CNAs.</p>

<p>As shown in <a data-type="xref" href="#difference_between_copy_number_and_copy">Figure 7-5</a>, the <em>copy number</em> is the absolute, integer-valued number of copies of each locus (i.e., gene or other meaningful segment of DNA). <a contenteditable="false" data-primary="copy number versus copy ratio" data-type="indexterm" id="idm45625632474664"/>The copy ratio is the relative, real-valued ratio of the number of copies of each locus to the average ploidy.</p>

<figure><div id="difference_between_copy_number_and_copy" class="figure"><img alt="Difference between copy number and copy ratio." src="Images/gitc_0705.png" width="1053" height="566"/>
<h6><span class="label">Figure 7-5. </span>Difference between copy number and copy ratio.</h6>
</div></figure>

<p><a data-type="xref" href="#spectral_karyotyping_paints_each_chromo">Figure 7-6</a> shows the striking contrast in genomic composition between a normal cell line that has the expected copy number for all chromosomes (left) and a cancer cell<a contenteditable="false" data-primary="normal versus cancer cell line, contrast in genomic composition" data-type="indexterm" id="idm45625632469896"/> line that has suffered <a contenteditable="false" data-primary="cancer versus normal cell line, contrast in genomic composition" data-type="indexterm" id="idm45625632468728"/>multiple major CNAs (right), not to mention a variety of structural alterations. For the normal cell line in this figure (and indeed, most healthy human cells), any given chromsome’s copy number is 2 and its copy ratio is 1. Meanwhile, in the cancer cell line, there is a lot of variation between chromosomes; for example, it looks like the copy number for chromosome 7 is 5, whereas for chromosome 12 it is 3, and we can’t really guess their copy ratio because the alterations are so extensive that we don’t have a good sense of the average ploidy of this genome.</p>

<figure><div id="spectral_karyotyping_paints_each_chromo" class="figure"><img alt="Spectral karyotyping paints each chromosome pair with a color, showing various chromosomal segments that are amplified or missing (colors in left and right panels are not expected to match)." src="Images/gitc_0706.png" width="1438" height="405"/>
<h6><span class="label">Figure 7-6. </span>Spectral karyotyping paints each chromosome pair with a color, showing various chromosomal segments that are amplified or missing (colors in left and right panels are not expected to match).</h6>
</div></figure>

<p>The good news is that copy-number analysis is less sensitive than short variant analysis to some of the challenges that we enumerated earlier because we don’t care as much about exact sequence. However, it is more sensitive to technical biases that affect the evenness of sequence coverage distribution. The consequence of these two points for the analysis design is that it is less important to have a matched normal available, whereas it is even more important to have a PoN composed of normals that have a closely matching technical profile. Note, however, that the copy-number PoN is completely different from the PoN used for short variant analysis. We go over the specifics in the next section.</p>

<section data-type="sect2" data-pdf-bookmark="Overview of the Tumor-Only Analysis Workflow"><div class="sect2" id="tumor_only_analysis_workflow">
<h2>Overview of the Tumor-Only Analysis Workflow</h2>

<p>The standard workflow for somatic copy-number analysis involves<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic copy-number alterations" data-tertiary="tumor-only analysis workflow" data-type="indexterm" id="ix_GATKBPSCNAtoa"/> four<a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="tumor-only analysis workflow" data-type="indexterm" id="ix_SCNAtoawk"/> main steps (<a data-type="xref" href="#best_practices_workflow_for_somatic_cop">Figure 7-7</a>). First,<a contenteditable="false" data-primary="tumor-only analysis workflow" data-type="indexterm" id="ix_TOAwk"/> we collect proportional coverage statistics for the case sample as well as any normals that will be used for the PoN. Setting the case sample aside for a moment, we create a copy-number PoN that captures the amount of systematic skew in coverage observed across the exome or genome. Then, we use that information to normalize the coverage data we collected for the case sample, which eliminates technical noise and reveals actual copy ratio differences in the data. Finally, we run a segmentation algorithm that identifies contiguous segments of sequence that presents the same copy ratio, and emit CNA calls for those segments whose copy ratio diverges significantly from the mean. Optionally, we can produce plots to visualize the data at several stages, which is helpful for interpretation.</p>

<figure class="width-60"><div id="best_practices_workflow_for_somatic_cop" class="figure"><img alt="Best Practices workflow for somatic copy-number alteration discovery." src="Images/gitc_0707.png" width="1234" height="2100"/>
<h6><span class="label">Figure 7-7. </span>Best Practices workflow for somatic copy-number alteration discovery.</h6>
</div></figure>

<p>Again, you’re going to do this work from within the GATK container on your VM, so make sure everything is turned on and you’re in the <em>/home/book/data/somatic</em> directory. The exercises in this section use the same reference genome and some of the same resource files as the first section, and we’re going to use the same sandbox for writing outputs.</p>
</div></section>

<section data-type="sect3"><div class="sect3" id="collecting_coverage_counts">
<h2>Collecting Coverage Counts</h2>

<p>We count <em>read depth</em><a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="tumor-only analysis workflow" data-tertiary="collecting coverage counts" data-type="indexterm" id="idm45625632448136"/>, or coverage, <a contenteditable="false" data-primary="tumor-only analysis workflow" data-secondary="collecting coverage counts" data-type="indexterm" id="idm45625632446248"/>over a series of intervals. Here we use exome capture targets because we’re analyzing exomes, but if we were analyzing whole genomes, we would switch to using bins of arbitrary length.<a contenteditable="false" data-primary="PreprocessIntervals tool" data-type="indexterm" id="idm45625632444472"/> For exomes, we take the interval list that corresponds to the capture targets (specific to every manufacturer’s exome prep kit) and first add some padding:</p>

<pre data-type="programlisting">
# gatk PreprocessIntervals \
    -R ref/Homo_sapiens_assembly38.fasta \
    -L resources/targets_chr17.interval_list \
    -O sandbox/targets_chr17.preprocessed.interval_list \
    --padding 250 \
    --bin-length 0 \
    --interval-merging-rule OVERLAPPING_ONLY </pre>

<p>In this command, the <code>--interval-merging-rule</code> argument controls whether the GATK engine should merge adjacent intervals for processing.<a contenteditable="false" data-primary="PreprocessIntervals tool" data-secondary="--interval-merging-rule argument" data-type="indexterm" id="idm45625632441096"/> In some contexts, it makes sense to merge them, but in this context, we prefer to keep them separate in order to have more fine-grained resolution, and we’ll merge only intervals that actually overlap.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If we wanted to generate an intervals list for whole genome data, we would run the same tool but without the targets file, and with the <code>--bin-length</code> argument set to the <a contenteditable="false" data-primary="PreprocessIntervals tool" data-secondary="--bin-length argument" data-type="indexterm" id="idm45625632437752"/>length of bin we want to use (set to 100 bases by default).</p>
</div>

<p>When we have the analysis-ready intervals list, we can run the read count collection tool, which operates by counting how many reads start within each interval. By default, the <a contenteditable="false" data-primary="HDF5 data format" data-type="indexterm" id="idm45625632435384"/>tool writes data in <a href="https://oreil.ly/uP_J4">HDF5 format</a>, which is handled more efficiently by downstream tools, but here we change the output<a contenteditable="false" data-primary="tab-separated values (TSV) format" data-type="indexterm" id="idm45625632433432"/> format to tab-separated values (TSV) because it is easier to peek into:</p>

<pre data-type="programlisting">
# gatk CollectReadCounts \
    -I bams/tumor.bam \
    -L sandbox/targets_chr17.preprocessed.interval_list \
    -R ref/Homo_sapiens_assembly38.fasta \
    -O sandbox/tumor.counts.tsv \
    --format TSV \
    -imr OVERLAPPING_ONLY</pre>

<p>The output file includes a header that recapitulates the sequence dictionary, followed by a table of counts for each target:</p>

<pre data-type="programlisting">
# head -5 sandbox/tumor.counts.tsv
@HD     VN:1.6
@SQ     SN:chr1 LN:248956422
@SQ     SN:chr2 LN:242193529
@SQ     SN:chr3 LN:198295559
@SQ     SN:chr4 LN:190214555</pre>

<p>Annoyingly, the sequence <a contenteditable="false" data-primary="alternative contigs" data-type="indexterm" id="idm45625632429192"/>dictionary for the hg38 reference build is extremely long because of the presence of all the <em>ALT contigs</em> (explained in the genomics primer in <a data-type="xref" href="ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new">Chapter 2</a>). So, to <a contenteditable="false" data-primary="tail utility" data-type="indexterm" id="idm45625632426440"/>peek into our file, it’s better to use <code>tail</code> instead of <code>head</code>:</p>

<pre data-type="programlisting">
# tail -5 sandbox/tumor.counts.tsv
chr17   83051485        83052048        1
chr17   83079564        83080237        0
chr17   83084686        83085575        1010
chr17   83092915        83093478        118
chr17   83094004        83094827        484</pre>

<p>Ah, that’s more helpful, isn’t it?<a contenteditable="false" data-primary="segmented copy ratio" data-type="indexterm" id="idm45625632423000"/> The first column is the chromosome or contig, the second and third are the start and stop of the target region we’re looking at, and the fourth is the count of reads overlapping the target. <a data-type="xref" href="#read_counts_in_each_genomic_target_or_b">Figure 7-8</a> provides an example of what this looks like visualized.</p>

<figure><div id="read_counts_in_each_genomic_target_or_b" class="figure"><img alt="Read counts in each genomic target or bin form the basis for estimating segmented copy ratio." src="Images/gitc_0708.png" width="1440" height="684"/>
<h6><span class="label">Figure 7-8. </span>Read counts in each genomic target or bin form the basis for estimating segmented copy ratio, and each dot is the value for a single target or bin.</h6>
</div></figure>

<p>Each dot in the figure represents one of the intervals for which we collected coverage, arranged in the order of their position on the genome. The gray and white stripes in the background represent alternating chromosomes, and the dotted lines represent the position of their centromeres. Notice how the dots form a wavy smear because of the huge variability in the amount of coverage present from one to the next. At this point, it’s impossible to identify any CNAs with any kind of confidence.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Creating a Somatic CNA PoN"><div class="sect2" id="creating_a_somatic_cna_pon">
<h2>Creating a Somatic CNA PoN</h2>

<p>As we discussed in <a data-type="xref" href="ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new">Chapter 2</a>, a lot of technical variability affects the sequencing <a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="tumor-only analysis workflow" data-tertiary="creating somatic CNA PoN" data-type="indexterm" id="idm45625632414648"/>process, and<a contenteditable="false" data-primary="tumor-only analysis workflow" data-secondary="creating somatic CNA PoN" data-type="indexterm" id="idm45625632412648"/> some <a contenteditable="false" data-primary="Panel of Normals (PoN)" data-secondary="creating somatic CNA PoN" data-type="indexterm" id="idm45625632411080"/>of it is fairly systematic—some regions will produce more sequence data than others, mainly because of chemistry. We can establish a baseline of what normal variability looks like by using an algorithm called singular value decomposition, which is conceptually similar to principal component analysis and aims to capture systematic noise from a panel of normals that were sequenced and processed the same way. The minimum number of samples in a CNA PoN should be at least 10 normal samples for the tools to work properly, but the Best Practices recommendation is to use 40 or more normal samples if possible.</p>

<p>Creating the PoN is a lot of work, so we provide one for you made from 40 samples from the 1000 Genomes Project. Each of the 40 samples <a contenteditable="false" data-primary="CollectedReadCounts tool" data-type="indexterm" id="idm45625632408104"/>was run individually through the <code>CollectReadCounts</code> tool, as described earlier (but leaving the default output format set to HDF5; hence, the <em>.hdf5</em> extension in the command line, shown in the next code snippet). <a contenteditable="false" data-primary="HDF5 data format" data-type="indexterm" id="idm45625632405960"/>Then the panel was created by running the command that follows on all the read count files. To be clear, we’re just showing this as an example, so don’t try to run it; it won’t work with the data we’ve provided for the book.<a contenteditable="false" data-primary="CreateReadCountPanelOfNormals" data-type="indexterm" id="idm45625632404392"/> for the book; we’re just showing it as an example.</p>

<pre data-type="programlisting">
gatk CreateReadCountPanelOfNormals \
    -I file1_clean.counts.hdf5 \
    … 
    -I file40_clean.counts.hdf5 \
    -O cnaponC.pon.hdf5</pre>

<p>The PoN produced by this command is completely different from the one we created for the short variant section earlier in this chapter. For the short variants pipeline, the PoN was just a kind of VCF file with annotated variant calls. In this case, however, the file produced by aggregating the read count data from the 40 normals is not meaningfully readable by the naked eye.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Applying Denoising"><div class="sect2" id="applying_denoising">
<h2>Applying Denoising</h2>

<p>With our sample<a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="tumor-only analysis workflow" data-tertiary="applying denoising" data-type="indexterm" id="idm45625632399432"/> read counts<a contenteditable="false" data-primary="tumor-only analysis workflow" data-secondary="applying denoising" data-type="indexterm" id="idm45625632397624"/> in hand and the PoN ready to go, we have everything<a contenteditable="false" data-primary="denoising" data-secondary="applying to read counts" data-type="indexterm" id="idm45625632396120"/> we need to run the most important step in this workflow: denoising the case sample read counts:</p>

<pre data-type="programlisting">
# gatk DenoiseReadCounts \
    -I cna_inputs/hcc1143_T_clean.counts.hdf5 \
    --count-panel-of-normals cna_inputs/cnaponC.pon.hdf5 \
    --standardized-copy-ratios sandbox/hcc1143_T_clean.standardizedCR.tsv \
    --denoised-copy-ratios sandbox/hcc1143_T_clean.denoisedCR.tsv</pre>

<p>Even though we’re running only a single command, internally the tool is performing two successive data transformations. First, it standardizes the read counts by the median counts recorded in the PoN, which involves a base-2 log transformation and normalization of the distribution to center around one, to produce <em>copy ratios</em>. Then, it applies the denoising algorithm to these standardized copy ratios using the principal components of the PoN.<a contenteditable="false" data-primary="copy ratios" data-secondary="standardized, producing and applying denoising to" data-type="indexterm" id="idm45625632392232"/></p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can tune the denoising tool to be more<a contenteditable="false" data-primary="denoising" data-secondary="adjusting level of" data-type="indexterm" id="idm45625632389752"/> or less aggressive by adjusting the <code>--number-of-eigensamples</code> parameter, which affects the resolution of results; that is, how smooth the resulting segments will be. Using a larger number will produce a higher level of denoising but can reduce the sensitivity of the analysis.</p>
</div>

<p>Again, the output files are not really human readable, so let’s plot their contents to get a sense <a contenteditable="false" data-primary="PlotDenoisedCopyRatios" data-type="indexterm" id="idm45625632386840"/>of what the data shows at this point:</p>

<pre data-type="programlisting">
# gatk PlotDenoisedCopyRatios \
    --sequence-dictionary ref/Homo_sapiens_assembly38.dict \
    --standardized-copy-ratios sandbox/hcc1143_T_clean.standardizedCR.tsv \
    --denoised-copy-ratios sandbox/hcc1143_T_clean.denoisedCR.tsv \
    --minimum-contig-length 46709983 \
    --output sandbox/cna_plots \
    --output-prefix hcc1143_T_clean</pre>

<p>The resulting plot includes both the standardized copy ratios produced by the first internal step and the final denoised copy ratios (<a data-type="xref" href="#copy_number_alteration_analysis_plots_s">Figure 7-9</a>).</p>

<p>You can use <code>gsutil</code> to copy the output plots from your VM to your Google bucket and then view them (or download them) from the GCP console. <a contenteditable="false" data-primary="gsutil" data-secondary="using to copy output plots from VM to Google bucket and view or download from GCP console" data-type="indexterm" id="idm45625632381656"/>If you need a refresher on this, see <a data-type="xref" href="ch04.xhtml#first_steps_in_the_cloud">Chapter 4</a>. The following is done from your VM (which has the <code>gsutil</code> tool installed and configured in <a data-type="xref" href="ch04.xhtml#first_steps_in_the_cloud">Chapter 4</a>) rather than the Docker container you’ve run the <code>gatk</code> commands in, and uploads to the <a contenteditable="false" data-primary="storage buckets" data-secondary="uploading output plots from VM to, using gsutil" data-type="indexterm" id="idm45625632377032"/>bucket that you specify (<code>my-bucket</code>) in this example:</p>

<pre data-type="programlisting">
$ export BUCKET="gs://my-bucket"
$ gsutil -m cp -R sandbox/cna_plots $BUCKET/somatic-sandbox/</pre>

<figure><div id="copy_number_alteration_analysis_plots_s" class="figure"><img alt="Copy-number alteration analysis plots showing the standardized copy ratios after the first step of denoising (top) and the fully denoised copy ratios after the second round (bottom)." src="Images/gitc_0709.png" width="1298" height="831"/>
<h6><span class="label">Figure 7-9. </span>Copy-number alteration analysis plots showing the standardized copy ratios after the first step of denoising (top) and the fully denoised copy ratios after the second round (bottom).</h6>
</div></figure>

<p>It can be difficult to see <a contenteditable="false" data-primary="denoising" data-secondary="copy-number alteration analysis plots showing standardized copy ratios after" data-type="indexterm" id="idm45625632371592"/>very clearly in the book<a contenteditable="false" data-primary="copy ratios" data-secondary="CNA analysis plots showing after applying denoising" data-type="indexterm" id="idm45625632370072"/> version of these images, but if you zoom in on the plots you generated yourself, you should be able to see that the range of values in the second-round image is tighter than in the first round, which shows the improvement from one step to the next. In any case, we can agree that these show much better resolution compared to the raw read counts shown in <a data-type="xref" href="#read_counts_in_each_genomic_target_or_b">Figure 7-8</a>, and we can already discern some probable CNAs.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Performing Segmentation and Call CNAs"><div class="sect2" id="performing_segmentation_and_call_cnas">
<h2>Performing Segmentation and Call CNAs</h2>

<p>Now that we have our lovingly denoised copy ratios, all we need to do is identify exactly which<a contenteditable="false" data-primary="tumor-only analysis workflow" data-secondary="performing segmenation and call CNAs" data-type="indexterm" id="idm45625632365000"/> regions <a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="tumor-only analysis workflow" data-tertiary="performing segmentation and call CNAs" data-type="indexterm" id="idm45625632363416"/>demonstrate evidence of CNA. To do that, we’re going to group neighboring intervals that have similar copy ratios into segments. Then, we should be able to determine which segments have an overall copy ratio that supports the presence of an amplification or deletion relative to the rest.</p>

<p>We do this using the <code>ModelSegments</code> tool, which <a contenteditable="false" data-primary="ModelSegments tool, algorithm details" data-type="indexterm" id="idm45625632360376"/>uses a Gaussian-kernel binary-segmentation algorithm to perform multidimensional kernel <a contenteditable="false" data-primary="Markov-Chain Monte Carlo (MCMC) sampling" data-type="indexterm" id="idm45625632358984"/>segmentation.<a contenteditable="false" data-primary="Gaussian-kernel binary-segmentation algorithm" data-type="indexterm" id="idm45625632357720"/></p>

<pre data-type="programlisting">
# gatk ModelSegments \
    --denoised-copy-ratios sandbox/hcc1143_T_clean.denoisedCR.tsv \
    --output sandbox  \
    --output-prefix hcc1143_T_clean</pre>

<p>As for the previous plots, the easiest way to view these is to transfer them to your Google bucket and open (or download) them from the GCP console. This command produces multiple files, so the output name we provide is simply the name that we want to give to the new directory that will contain them. Again, the outputs are not particularly user friendly, so we’re going to make some plots to visualize the results. We provide the plotting tool with the denoised copy ratios (from <code>DenoiseReadCounts</code>), the segments (from <code>ModelSegments</code>), and the reference sequence dictionary:<a contenteditable="false" data-primary="PlotModeledSegments tool" data-type="indexterm" id="idm45625632353928"/></p>

<pre data-type="programlisting">
# gatk PlotModeledSegments \
    --denoised-copy-ratios sandbox/hcc1143_T_clean.denoisedCR.tsv \
    --segments sandbox/hcc1143_T_clean.modelFinal.seg \
    --sequence-dictionary ref/Homo_sapiens_assembly38.dict \
    --minimum-contig-length 46709983 \
    --output sandbox/cna_plots \
    --output-prefix hcc1143_T_clean</pre>

<p><a data-type="xref" href="#plot_of_segments_modeled_based_on_denoi">Figure 7-10</a> shows the segments identified by the <code>PlotModelSegments</code> tool. The dots representing targets or bins on alternate segments are colored in either blue and orange, whereas segment medians are drawn in black. Most segments have a copy ratio of approximately 1, which constitutes the baseline. Against that backdrop, we can observe multiple amplifications and deletions of different sizes and different copy ratios. You might notice that most of these don’t correspond to the numbers that you would expect if you had, for example, four copies instead of two for a given segment. That is because some of the CNAs occur in subclonal populations, meaning that only part of the sampled tissue is affected. As a result, the effect is diluted and you might see a copy ratio of 1.8 instead of 2.<a contenteditable="false" data-primary="copy ratios" data-secondary="denoised, plot of segments modeled based on" data-type="indexterm" id="idm45625632349304"/></p>

<figure><div id="plot_of_segments_modeled_based_on_denoi" class="figure"><img alt="Plot of segments modeled based on denoised copy ratios." src="Images/gitc_0710.png" width="1295" height="406"/>
<h6><span class="label">Figure 7-10. </span>Plot of segments modeled based on denoised copy ratios.</h6>
</div></figure>

<p>More generally, it seems like a lot is going on in this sample; in fact, we can look in the segmentation file in the output directory and see that we’ve predicted 235 segments for this sample. This isn’t typical of regular tumor samples, although some can be pretty messed up; what’s going on here is that we’re looking at a sample taken from a cell line. Cancer cell lines are convenient for teaching and testing software because the data can easily be made open access, but biologically they tend to have accumulated very high numbers of alterations. So this represents an extreme situation. On the bright side, most samples that you’ll encounter in the real world are likely to be cleaner (and easier to interpret) than this. So you have something to look forward to!</p>

<p>That being said, the software can still help us get a bit more clarity even on a messy sample like this.<a contenteditable="false" data-primary="CallCopyRatioSegments tool" data-type="indexterm" id="idm45625632344168"/> We can get final CNA calls—that is, a determination of which segments we can consider to have<a contenteditable="false" data-primary="amplification and deletion in segments" data-type="indexterm" id="idm45625632342808"/> significant evidence of amplification or deletion—by running the last tool in this workflow, as follows:</p>

<pre data-type="programlisting">
# gatk CallCopyRatioSegments \
    -I sandbox/hcc1143_T_clean.cr.seg \
    -O sandbox/hcc1143_T_clean.called.seg</pre>

<p>This tool adds a column to the segmented copy-ratio <em>.cr.seg</em> file from <code>ModelSegments</code>, marking amplifications (<code>+</code>), deletions (<code>-</code>), and neutral segments (<code>0</code>):</p>

<pre data-type="programlisting">
# tail -5 sandbox/hcc1143_T_clean.called.seg
chrX    118974529       139746109       864     0.475183        +
chrX    139749773       139965748       28      -0.925385       -
chrX    140503468       153058699       277     -0.366860       -
chrX    153182138       153580550       47      0.658197        +
chrX    153588113       156010661       544     0.075279        0</pre>

<p>And there you have it; this shows you the output of the somatic copy-number workflow. If we look at the full progression, you can see that we went from raw coverage counts all the way to having identified specific regions of deletion or amplification, as illustrated in <a data-type="xref" href="#full_progression_from_raw_data_to_resul">Figure 7-11</a> (using different data and only a subset of chromosomes).</p>

<figure><div id="full_progression_from_raw_data_to_resul" class="figure"><img alt="Full progression from raw data to results." src="Images/gitc_0711.png" width="1242" height="653"/>
<h6><span class="label">Figure 7-11. </span>Full progression from raw data to results.</h6>
</div></figure>

<p>Copy ratio counts in <a data-type="xref" href="#full_progression_from_raw_data_to_resul">Figure 7-11</a> are calculated and processed as shown in previous figures, rotated 90° to the right. The leftmost panel shows raw copy ratio counts <span class="keep-together">calculated</span> per target or genomic bin. The second and third panels show standardized and denoised counts, respectively. The fourth panel shows segmentation and calling results, including one whole chromosome amplification (AMP) and one deletion (DEL). The rightmost panel shows a minor allele fraction calculated using the procedure outlines in the next section.</p>

<p>Ironically, these <a contenteditable="false" data-primary="tumor-only analysis workflow" data-secondary="full progression from raw data to results" data-type="indexterm" id="idm45625632329896"/>results don’t include an actual copy number, just the boundaries of each segment, its copy ratio, and the final call. To get the copy number, you will need to do some additional work that is beyond the <a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="tumor-only analysis workflow" data-startref="ix_SCNAtoawk" data-type="indexterm" id="idm45625632328072"/>scope <a contenteditable="false" data-primary="tumor-only analysis workflow" data-startref="ix_TOAwk" data-type="indexterm" id="idm45625632326248"/>of this<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic copy-number alterations" data-startref="ix_GATKBPSCNAtoa" data-tertiary="tumor-only analysis workflow" data-type="indexterm" id="idm45625632324696"/> chapter. See the <a href="https://oreil.ly/NXTuz">documentation</a> for more information and next steps.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Additional Analysis Options"><div class="sect2" id="additional_analysis_options">
<h2>Additional Analysis Options</h2>

<p>We’ve just covered the standard workflow that is most commonly used for performing copy-number analysis with GATK tools. <a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic copy-number alterations" data-tertiary="additional analysis options" data-type="indexterm" id="ix_GATKBPSCNAaao"/><a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="additional analysis options" data-type="indexterm" id="ix_SCNAaaopt"/>This involved collecting coverage counts, using a PoN to apply denoising, and performing segmentation in order to model and finally call copy-number–altered segments on the tumor case sample. However, you can apply two additional options to further beef up the quality of the results.</p>

<section data-type="sect3" data-pdf-bookmark="Tumor-Normal pair analysis"><div class="sect3" id="tumor_normal_pair_analysis">
<h3>Tumor-Normal pair analysis</h3>

<p>The Tumor-only workflow gets you decent, usable results for somatic CNA discovery.<a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="additional analysis options" data-tertiary="tumor-normal pair analysis" data-type="indexterm" id="idm45625632314088"/><a contenteditable="false" data-primary="tumor-normal pair analysis" data-secondary="for somatic copy-number alterations" data-type="indexterm" id="idm45625632312232"/> But if you have a matched normal available, you can gain additional benefits! For one thing, you can run the workflow, as described earlier on the normal sample, which is helpful for understanding the baseline that you’re working with. In many cases, having the matched normal can also help the denoising process.</p>

<p>Feel free to run through the commands on your own. In the final segmentation results, notice the probable CNAs on chromosome 2 and chromosome 6. This matched normal is itself from a cell line, albeit derived from healthy tissue instead of a tumor. It’s not uncommon to see some background alterations occur even in normal tissue when it’s been propagated as a cell line.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This concludes the exercises for this chapter, so once again, remember to stop your VM if you’re taking a break before moving on to the next chapter.</p>
</div>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Allelic copy ratio analysis"><div class="sect3" id="allelic_copy_ratio_analysis">
<h3>Allelic copy ratio analysis</h3>

<p>So far, we’ve used only read coverage as evidence<a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="additional analysis options" data-tertiary="allelic copy ratio analysis" data-type="indexterm" id="idm45625632306200"/> for CNAs, but we can <a contenteditable="false" data-primary="allelic copy ratio analysis" data-type="indexterm" id="idm45625632304296"/>also include <em>allelic copy ratio</em>: the copy ratio for different alleles at sites with heterozygous SNVs.<a contenteditable="false" data-primary="heterozygosity of case samples" data-type="indexterm" id="idm45625632302568"/> This can reveal interesting things about the heterozygosity of our case sample, which can have <a contenteditable="false" data-primary="loss of heterozygosity" data-type="indexterm" id="idm45625632301128"/>important biological consequences—especially when there is a <em>loss of <span class="keep-together">heterozygosity</span></em>.</p>

<p>We can detect imbalances in the heterozygosity of segments by looking at the allelic counts (i.e., the read counts for different alleles at each site) in the case sample at sites that are commonly variant in the population. For a diploid organism, we expect to see any heterozygous SNV manifest as two different alleles present in equal proportions. Suppose that we have an A/T variant; we expect to see approximately 50% A and 50% T in the sequence reads (give or take some technical variability). We can detect those sites on the fly when we’re counting the reads in the first step of the workflow. Then, we can use those sites as markers; if we look at those sites in the tumor and find that their allelic ratios are significantly skewed, that gives us additional information about the degree of CNA that affects the segments of which these sites are part.</p>

<p>If you’re interested<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic copy-number alterations" data-startref="ix_GATKBPSCNAaao" data-tertiary="additional analysis options" data-type="indexterm" id="idm45625632297224"/> in exploring<a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-secondary="additional analysis options" data-startref="ix_SCNAaaopt" data-type="indexterm" id="idm45625632295128"/> this additional analysis mode, have a look at the <a href="https://oreil.ly/NXTuz">somatic copy-number documentation</a> on the GATK website. </p>
</div></section>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrap-Up and Next Steps"><div class="sect1" id="wrap_up_and_next_steps-id00004">
<h1>Wrap-Up and Next Steps</h1>

<p>Well then, between the <a contenteditable="false" data-primary="somatic copy-number alterations, GATK Best Practices" data-startref="ix_SCNA" data-type="indexterm" id="idm45625632291048"/>germline workflow <a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic copy-number alterations" data-startref="ix_GATKBPSCNA" data-type="indexterm" id="idm45625632289320"/>and these two somatic analysis workflows, we’ve already run a lot of genomics commands. So, does that mean we’re ready to run full-scale genomic analyses?</p>

<p>Hah, no. At this point you can run individual tools one by one—which is going to be useful at various stages of your work, especially for initial testing/evaluation as well as troubleshooting failures—but you also know that the variant discovery Best Practices are composed of multiple tasks involving various tools. Trust us, you don’t want to be running each task manually for each sample or set of samples that you need to process. You’re going to want to chain these tasks into scripts that automate the bulk of the work to cut down on the mindless tedium as well as to reduce the chance of human error. So in <a data-type="xref" href="ch08.xhtml#automating_analysis_execution_with_work">Chapter 8</a>, we show you how to write workflow scripts using WDL, which automates calling each step in the overall analysis pipeline. Then, we run them using a workflow management system called Cromwell that is equally comfortable running on your laptop, cluster, or cloud platform.<a contenteditable="false" data-primary="Genome Analysis Toolkit (GATK)" data-secondary="Best Practices for somatic variant discovery" data-startref="ix_GATKBPSVD" data-type="indexterm" id="idm45625632285000"/><a contenteditable="false" data-primary="somatic variant discovery, GATK Best Practices" data-startref="ix_SVD" data-type="indexterm" id="idm45625632283272"/></p>
</div></section>
</div></section></div>



  </body></html>