<html><head></head><body><section data-pdf-bookmark="Chapter 11. Advanced Topics" data-type="chapter" epub:type="chapter"><div class="chapter" id="advanced_topics">&#13;
<h1><span class="label">Chapter 11. </span>Advanced Topics</h1>&#13;
&#13;
&#13;
<p>In this chapter, we’ll do a quick pass through some of the more advanced topics. We’re going to assume that you have a pretty good hold on Docker by now and that you’ve already got it in production or you’re at least a regular user. We’ll talk about how containers work in detail and about some of the aspects of Docker security, Docker networking, Docker plug-ins, swappable runtimes, and other advanced &#13;
<span class="keep-together">configurations</span>.</p>&#13;
&#13;
<p>Some of this chapter covers configurable changes you can make to your Docker installation. These can be useful, but Docker has good defaults, so as with most software, you should stick to the defaults on your operating system unless you have a good reason to change them and have educated yourself on what those changes mean to you. Getting your installation right for your environment will likely involve some trial and error, tuning, and adjustment over time. However, changing settings from their defaults before understanding them well is not recommended.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Containers in Detail" data-type="sect1"><div class="sect1" id="idm46803129289872">&#13;
<h1>Containers in Detail</h1>&#13;
&#13;
<p>Though we usually talk about Linux containers<a data-primary="Linux containers" data-secondary="about" data-tertiary="subsystems working together" data-type="indexterm" id="idm46803129287968"/><a data-primary="cgroups in Linux kernel" data-secondary="containers in detail" data-tertiary="about subsystems working together" data-type="indexterm" id="idm46803129286752"/><a data-primary="Linux containers" data-secondary="namespaces" data-tertiary="about subsystems working together" data-type="indexterm" id="idm46803129285568"/><a data-primary="namespaces" data-secondary="containers in detail" data-tertiary="about subsystems working together" data-type="indexterm" id="idm46803129284384"/><a data-primary="Linux" data-secondary="namespaces" data-see="namespaces" data-type="indexterm" id="idm46803129283200"/> as a single entity, they are actually implemented through several separate mechanisms built into the Linux kernel that all work together: control groups (cgroups), namespaces, Secure Computing Mode (<code>seccomp</code>), and SELinux or AppArmor, all of which serve to <em>contain</em> the process. cgroups provide for resource limits, namespaces allow for processes to use identically named resources and isolate them from one another’s view of the system, <a data-primary="security" data-secondary="system calls" data-type="indexterm" id="idm46803129250528"/><a data-primary="system calls" data-secondary="Secure Computing Mode" data-type="indexterm" id="idm46803129249680"/>Secure Computing Mode limits which system calls a process can use, and SELinux or &#13;
<span class="keep-together">AppArmor</span> provides additional strong security isolation for processes. So, to start, what do cgroups and namespaces do for you?</p>&#13;
&#13;
<p>Before we launch into detail, an analogy might help you understand how each of these subsystems plays into the way that containers work. Imagine that the typical computer is like a large open warehouse, full of workers (processes). The warehouse is full of space and resources, but it is very easy for the workers to get in one another’s way, and most of the resources are simply used by whomever gets them first.</p>&#13;
&#13;
<p>When you are running Docker and using Linux containers for your workloads, it is like that warehouse has been converted into an office building, where each worker now has their own individual office. Each office has all the normal things that the workers need to accomplish their jobs, and in general, they can now work without worrying much about what other people (processes) are doing.</p>&#13;
&#13;
<p>Namespaces make up the walls of the office and ensure that processes cannot interact with neighboring processes in any way that they are not specifically allowed to. Control groups are a bit like paying rent to receive utilities. When the process is first spun up, it is assigned time on the CPU and storage subsystem that it will be allowed each cycle, in addition to the amount of memory that it will be allowed to use at any moment. This helps ensure that the workers (processes) have the resources they need, without allowing them to use resources or space reserved for others. Imagine the worst kind of noisy neighbors, and you can suddenly truly appreciate good, solid barriers between offices. Finally, Secure Computing Mode, SELinux, and AppArmor are a bit like office security, ensuring that even if something unexpected or untoward happens, it is unlikely to cause much more than the headache of filling out paperwork and filing an incident report.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="cgroups" data-type="sect2"><div class="sect2" id="idm46803129246800">&#13;
<h2>cgroups</h2>&#13;
&#13;
<p>Traditional distributed system design<a data-primary="cgroups in Linux kernel" data-secondary="containers in detail" data-tertiary="about cgroups" data-type="indexterm" id="idm46803129245424"/><a data-primary="Linux containers" data-secondary="cgroups" data-seealso="cgroups in Linux kernel" data-type="indexterm" id="idm46803129244240"/> dictates running each intensive task on its own virtual server. So, for example, you don’t run your applications on the database server because they have competing resource demands, and their resource usage could grow unbounded and begin to dominate the server, starving the database of performance.</p>&#13;
&#13;
<p>On real hardware systems, this could be quite expensive, so solutions like virtual servers are very appealing, in part because you can share expensive hardware between competing applications, and the virtualization layer will handle your resource partitioning. But while it saves money, this is still a fairly expensive approach if you don’t need all the other separation provided by virtualization, because running multiple kernels introduces a reasonable overhead on the applications. Maintaining VMs is also not the cheapest solution. All the same, cloud computing has shown that it’s immensely powerful and, with the right tooling, incredibly effective.</p>&#13;
&#13;
<p>But if the only kind of isolation you needed was resource partitioning, wouldn’t it be great if you could get that on the same kernel without running another operating system instance? For many years, you could assign a “niceness” value to a process, and it would give the scheduler hints about how you wanted this process to be treated in relation to the others. But it wasn’t possible to impose hard limits like those that you get with VMs. And niceness is not at all fine-grained: you can’t give something more I/O and less CPU than other processes. This fine-grained control, of course, is one of the promises of Linux containers, and the mechanism that they use to provide that functionality is cgroups, which predate Docker and were invented to solve just this problem.</p>&#13;
&#13;
<p><em>Control groups</em> allow you to set limits on resources for processes and their children. This is the mechanism that the Linux kernel uses to control limits on memory, swap, CPU, storage, and network I/O resources. cgroups are built into the kernel and originally shipped in 2007 in Linux 2.6.24. <a data-primary="cgroups in Linux kernel" data-secondary="documentation" data-type="indexterm" id="idm46803129241392"/><a data-primary="documentation" data-secondary="cgroups" data-type="indexterm" id="idm46803129240416"/><a data-primary="resources online" data-secondary="cgroups documentation" data-type="indexterm" id="idm46803129239472"/>The official <a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt">kernel documentation</a> defines them as “a mechanism to organize processes hierarchically and distribute system resources along the hierarchy in a controlled and configurable manner.” It’s important to note that this setting applies to a process and all of the children that descend from it. That’s exactly how containers are structured.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>It is worth mentioning that there have been<a data-primary="Linux" data-secondary="about containers and Linux versions" data-tertiary="cgroups and Linux versions" data-type="indexterm" id="idm46803129236608"/><a data-primary="cgroups in Linux kernel" data-secondary="Linux versions and" data-type="indexterm" id="idm46803129235424"/> at least two major releases of Linux control groups: <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt">v1</a> and <a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt">v2</a>. Make sure that you know which version is being used in production so that you can leverage all the abilities that it provides.</p>&#13;
</div>&#13;
&#13;
<p>Every Linux container is assigned a cgroup that is unique to that container. All of the processes in the container will be in the same group. This means that it’s easy to control resources for each container as a whole without worrying about what might be running. If a container is redeployed with new processes added, you can have Docker assign the same policy and it will apply to the whole container and all the process containers within it.</p>&#13;
&#13;
<p>We talked previously about the cgroups hooks exposed by Docker via its API. That interface allows you to control memory, swap, and disk usage. But there are lots of other things that you can manage with cgroups, including tagging network packets from a container so that you can use those tags to prioritize traffic. You might find that in your environment you need to use some of these levers to keep your containers under control, and there are a few ways you can go about doing that. By their very nature, cgroups need to do a lot of accounting of resources used by each group. That means that when you’re using them, the kernel has a lot of interesting statistics about how much CPU, RAM, disk I/O, and so on your processes are using. So Docker uses cgroups not just to limit resources but also to report on them. These are many of the metrics you see, for example, in the output of <code>docker</code> &#13;
<span class="keep-together"><code>container stats</code>.</span></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The /sys filesystem" data-type="sect3"><div class="sect3" id="idm46803129230464">&#13;
<h3>The /sys filesystem</h3>&#13;
&#13;
<p>The primary way to control cgroups<a data-primary="filesystem layers of Linux containers" data-secondary="/sys filesystem" data-secondary-sortas="sys filesystem" data-type="indexterm" id="ch11-sys"/><a data-primary="cgroups in Linux kernel" data-secondary="containers in detail" data-tertiary="/sys filesystem" data-tertiary-sortas="sys filesystem" data-type="indexterm" id="ch11-sys2"/> in a fine-grained manner, even if you configured them with Docker, is to manage them yourself. This is the most powerful method because changes don’t just happen at container creation time—they can be done on the fly.</p>&#13;
&#13;
<p>On systems with <code>systemd</code>, there are<a data-primary="Linux" data-secondary="systemd" data-tertiary="cgroup control" data-type="indexterm" id="idm46803129224048"/> command-line tools like <code>systemctl</code> that you can use to do this. But since cgroups are built into the kernel, the method that works everywhere is to talk to the kernel directly via the <em>/sys</em> filesystem. If you’re not familiar with <em>/sys</em>, it’s a filesystem that directly exposes several kernel settings and outputs. You can use it with simple command-line tools to tell the kernel how you would like it to behave.</p>&#13;
&#13;
<p>This method of configuring cgroups controls for containers only works directly on the Docker server, so it is not available remotely via any API. If you use this method, you’ll need to figure out how to script this for your environment.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Changing cgroups values yourself, outside of any Docker configuration, breaks some of the repeatability of a Docker deployment. Unless you implement changes in your deployment process, settings will revert to their defaults when containers are replaced. Some schedulers take care of this for you, so if you run one in production, you might check the documentation to see how to best apply these changes repeatably.</p>&#13;
</div>&#13;
&#13;
<p>Let’s use an example of changing the CPU cgroups settings for a container we have just started up. We need to get the long ID of the container, and then we need to find it in the <em>/sys</em> filesystem. Here’s what that looks like:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-d<code class="w"> </code>spkane/train-os<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code>--timeout<code class="w"> </code>360s<code class="w"/>&#13;
&#13;
<code class="go">dcbb…8e86f1dc0a91e7675d3c93895cb6a6d83371e25b7f0bd62803ed8e86</code></pre>&#13;
&#13;
<p>Here, we’ve had <code>docker container run</code> give us the long ID in the output, and the ID we want is <code>dcbb…8e86f1dc0a91e7675d3c93895cb6a6d83371e25b7f0bd62803ed8e86</code>. You can see why Docker normally truncates this.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>In the examples, we may need to truncate the ID to make it fit into the constraints of a standard page. But remember that you will need to use the long ID!</p>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before">Now that we have the ID, we can find our container’s cgroup in the <em>/sys</em> filesystem. <em>/sys</em> is laid out so that each type of setting is grouped into a module, and that module might be exposed at a different place in the <em>/sys</em> filesystem. So when we look at CPU settings, we won’t see <code>blkio</code> settings, for example. You might take a look around in <em>/sys</em> to see what else is there. But for now we’re interested in the CPU controller, so let’s inspect what that gives us. You need <code>root</code> access on the system to do this because you’re manipulating kernel settings.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Remember our <code>nsenter</code> trick we originally discussed in <a data-type="xref" href="ch03.html#installing_docker">Chapter 3</a>. You can run <code>docker container run --rm -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh</code> to get access to the Docker host, even if you can’t SSH into the server.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>ls<code class="w"> </code>/sys/fs/cgroup/docker/dcbb…8e86<code class="w"/>&#13;
&#13;
<code class="go">cgroup.controllers        cpuset.cpus.partition     memory.high</code>&#13;
<code class="go">cgroup.events             cpuset.mems               memory.low</code>&#13;
<code class="go">cgroup.freeze             cpuset.mems.effective     memory.max</code>&#13;
<code class="go">cgroup.max.depth          hugetlb.2MB.current       memory.min</code>&#13;
<code class="go">cgroup.max.descendants    hugetlb.2MB.events        memory.oom.group</code>&#13;
<code class="go">cgroup.procs              hugetlb.2MB.events.local  memory.stat</code>&#13;
<code class="go">cgroup.stat               hugetlb.2MB.max           memory.swap.current</code>&#13;
<code class="go">cgroup.subtree_control    hugetlb.2MB.rsvd.current  memory.swap.events</code>&#13;
<code class="go">cgroup.threads            hugetlb.2MB.rsvd.max      memory.swap.high</code>&#13;
<code class="go">cgroup.type               io.bfq.weight             memory.swap.max</code>&#13;
<code class="go">cpu.max                   io.latency                pids.current</code>&#13;
<code class="go">cpu.stat                  io.max                    pids.events</code>&#13;
<code class="go">cpu.weight                io.stat                   pids.max</code>&#13;
<code class="go">cpu.weight.nice           memory.current            rdma.current</code>&#13;
<code class="go">cpuset.cpus               memory.events             rdma.max</code>&#13;
<code class="go">cpuset.cpus.effective     memory.events.local</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The exact path here may change a bit depending on the Linux distribution your Docker server is running on and what the hash of your container is.</p>&#13;
</div>&#13;
&#13;
<p>You can see that under cgroups, there is a <em>docker</em> directory that contains all of the Linux containers that are running on this host. You can’t set cgroups for things that aren’t running, because they apply only to running processes. This is an important point that you should consider. Docker takes care of reapplying cgroup settings for you when you start and stop containers. Without that mechanism, you are somewhat on your own.</p>&#13;
&#13;
<p>Let’s go ahead and inspect the <a href="https://docs.kernel.org/admin-guide/cgroup-v2.html#cpu-interface-files">CPU weight</a> for this container. Remember that we explored setting some of these CPU values in <a data-type="xref" href="ch05.html#docker_containers">Chapter 5</a> via the <code>--cpus</code> command-line argument to <code>docker container run</code>. But for a normal container where no settings were passed, this setting is the default:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>cat<code class="w"> </code>/sys/fs/cgroup/docker/dcbb…8e86/cpu.weight<code class="w"/>&#13;
<code class="go">100</code></pre>&#13;
&#13;
<p><code>100</code> CPU weight means we are not limited at all. Let’s tell the kernel that this container should be limited to half that:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">echo</code><code class="w"> </code><code class="m">50</code><code class="w"> </code>&gt;<code class="w"> </code>/sys/fs/cgroup/docker/dcbb…8e86/cpu.weight<code class="w"/>&#13;
<code class="gp">$ </code>cat<code class="w"> </code>/sys/fs/cgroup/docker/dcbb…8e86/cpu.weight<code class="w"/>&#13;
<code class="go">50</code></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>In production, you should not use this method to adjust cgroups on the fly, but we are demonstrating it here so that you understand the underlying mechanics that make all of this work. Take a look at <a href="https://dockr.ly/2PPC4P1"><code>docker container update</code></a> if you’d like to adjust these on a running container. You might also find the <a href="https://dockr.ly/2PTLaKK"><span class="keep-together"><code>--cgroup-parent</code></span></a> option to <code>docker container run</code> interesting.</p>&#13;
</div>&#13;
&#13;
<p>There you have it. We’ve changed the container’s settings on the fly. This method is very powerful because it allows you to set any cgroups setting for the container. But as we mentioned earlier, it’s entirely ephemeral. When the container is stopped and restarted, the setting reverts to the default:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>stop<code class="w"> </code>dcbb…8e86<code class="w"/>&#13;
<code class="go">dcbb…8e86</code>&#13;
&#13;
<code class="gp">$ </code>cat<code class="w"> </code>/sys/fs/cgroup/docker/dcbb…8e86/cpu.weight<code class="w"/>&#13;
<code class="go">cat: /sys/fs/…/cpu.weight: No such file or directory</code></pre>&#13;
&#13;
<p>You can see that the directory path doesn’t even exist anymore now that the container is stopped. And when we start it back up, the directory comes back but the setting is back to <code>100</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>start<code class="w"> </code>dcbb…8e86<code class="w"/>&#13;
<code class="go">dcbb…8e86</code>&#13;
&#13;
<code class="gp">$ </code>cat<code class="w"> </code>/sys/fs/cgroup/docker/dcbb…8e86/cpu.weight<code class="w"/>&#13;
<code class="go">100</code></pre>&#13;
&#13;
<p>If you were to change these kinds of settings in a production system via the <em>/sys</em> filesystem directly, you’d want to manage that directly. A daemon that watches the <code>docker system events</code> stream and changes settings at container startup, for example, is a possibility.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>It is possible to create custom cgroups<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="create" data-tertiary="--cgroup-parent" data-tertiary-sortas="cgroup-parent" data-type="indexterm" id="idm46803128988896"/> outside of Docker and then attach a new container to that cgroup using the <code>--cgroup-parent</code> argument to <code>docker container create</code>. This mechanism is also used by schedulers that run multiple containers inside the same cgroup (e.g., Kubernetes pods).<a data-startref="ch11-sys" data-type="indexterm" id="idm46803128986144"/><a data-startref="ch11-sys2" data-type="indexterm" id="idm46803128985440"/></p>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Namespaces" data-type="sect2"><div class="sect2" id="namespaces">&#13;
<h2>Namespaces</h2>&#13;
&#13;
<p>Inside each container, you see a filesystem,<a data-primary="Linux containers" data-secondary="namespaces" data-type="indexterm" id="ch11-name"/><a data-primary="namespaces" data-secondary="containers in detail" data-type="indexterm" id="ch11-name2"/> network interfaces, disks, and other resources that all appear to be unique to the container despite sharing the kernel with all the other processes on the system. The primary network interface on the actual machine, for example, is a single shared resource. But inside your container, it will look like it has an entire network interface to itself. This is a really useful abstraction: it’s what makes your container feel like a machine all by itself. The way this is implemented in the kernel is with Linux namespaces. Namespaces take a traditionally global resource and present the container with its own unique and unshared version of that resource.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Namespaces cannot be explored on the filesystem quite as easily as cgroups, but most of the details can be found under the <em>/proc/*/ns/*</em> and <em>/proc/*/task/*/ns/*</em> hierarchies. In newer Linux releases, the <code>lsns</code> command can also be quite useful.</p>&#13;
</div>&#13;
&#13;
<p>Rather than just having a single namespace, however, by default containers have a namespace on each of the resources that are currently namespaced in the kernel: mount, UTS, IPC, PID, network, and user namespaces, in addition to the partially implemented time namespace. Essentially, when you talk about a container, you’re talking about several different namespaces that Docker sets up on your behalf. So what do they all do?</p>&#13;
<dl>&#13;
<dt>Mount namespaces</dt>&#13;
<dd>&#13;
<p>Linux uses these primarily<a data-primary="mount command" data-secondary="namespaces" data-type="indexterm" id="idm46803128956512"/><a data-primary="system calls" data-secondary="chroot" data-type="indexterm" id="idm46803128955184"/><a data-primary="chroot Unix system call" data-type="indexterm" id="idm46803128954240"/><a data-primary="system calls" data-secondary="mount" data-tertiary="namespaces" data-type="indexterm" id="idm46803128953568"/><a data-primary="umount command" data-secondary="namespaces" data-type="indexterm" id="idm46803128952352"/><a data-primary="system calls" data-secondary="umount" data-tertiary="namespaces" data-type="indexterm" id="idm46803128951408"/> to make your container look like it has its own entire filesystem. If you’ve ever used a <code>chroot</code> jail, this is its more robust relative. It looks a lot like a <code>chroot</code> jail but goes all the way down to the deepest levels of the kernel so that even <code>mount</code> and <code>unmount</code> system calls are namespaced. If you use <code>docker container exec</code> or <span class="keep-together"><code>nsenter</code></span>, which we will discuss later in this chapter, to get into a container, you’ll see a filesystem rooted on <em>/</em>. But we know that this isn’t the actual root partition of the system. It’s the mount namespace that makes that possible.</p>&#13;
</dd>&#13;
<dt>UTS namespaces</dt>&#13;
<dd>&#13;
<p>Named for the kernel structure<a data-primary="UTS (Unix Time Sharing System) namespaces" data-type="indexterm" id="idm46803128945296"/> they namespace, UTS (Unix Time Sharing System) namespaces give your container its own hostname and domain name. This is also used by older systems like NIS to identify which domain a host belongs to. When you enter a container and see a hostname that is not the same as the machine on which it runs, it’s this namespace that makes that happen.</p>&#13;
</dd>&#13;
</dl>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>To have a container use its host’s UTS namespace,<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--uts=host" data-tertiary-sortas="uts=host" data-type="indexterm" id="idm46803128943232"/> you can specify the <code>--uts=host</code> option when launching the container with <code>docker container run</code>. There are similar commands for sharing the other namespaces as well.</p>&#13;
</div>&#13;
<dl>&#13;
<dt>IPC namespaces</dt>&#13;
<dd>&#13;
<p>These isolate your container’s <a data-primary="IPC namespaces" data-type="indexterm" id="idm46803128938464"/>System V IPC and POSIX message queue systems from those of the host. Some IPC mechanisms use filesystem resources like named pipes, and those are covered by the mount namespace. The IPC namespace covers things like shared memory and semaphores that aren’t filesystem resources but that really should not cross the container wall.</p>&#13;
</dd>&#13;
<dt>PID namespaces</dt>&#13;
<dd>&#13;
<p>We have already shown<a data-primary="PID namespace" data-type="indexterm" id="idm46803128936352"/> that you can see all of the processes in containers in the Linux <code>ps</code> output on the host Linux server. But inside the container, processes have a different PID. This is the PID namespace in action. A process has a unique PID in each namespace to which it belongs. If you look in <em>/proc</em> inside a container, or run <code>ps</code>, you will only see the processes inside the container’s PID namespace.</p>&#13;
</dd>&#13;
<dt>Network namespaces</dt>&#13;
<dd>&#13;
<p>This is what allows your container to have<a data-primary="networking" data-secondary="network namespace" data-type="indexterm" id="idm46803128932896"/> its own network devices, ports, and so on. When you run <code>docker container ls</code> and see the bound ports for your container, you are seeing ports from both namespaces. Inside the container, your <code>nginx</code> might be bound to port 80, but that’s on the namespaced network interface. This namespace makes it possible to have what seems to be a completely separate network stack for your container.</p>&#13;
</dd>&#13;
<dt>User namespaces</dt>&#13;
<dd>&#13;
<p>These provide isolation between<a data-primary="user namespace" data-type="indexterm" id="idm46803128929552"/> the user and group IDs inside a container and those on the Linux host. Earlier, when we looked at <code>ps</code> output outside and then inside the container, we saw different user IDs; this is how that happened. A new user inside a container is not a new user on the Linux host’s main namespace, and vice versa. There are some subtleties here, though. For example, UID 0 (<code>root</code>) in a user namespace is not the same thing as UID 0 on the host, although running as <code>root</code> inside the container does increase the risk of potential security exploits. There are concerns about security leakage, which we’ll talk about in a bit, and this is why things like rootless containers are growing in popularity.</p>&#13;
</dd>&#13;
<dt>Cgroup namespaces</dt>&#13;
<dd>&#13;
<p>This namespace was introduced<a data-primary="cgroups in Linux kernel" data-secondary="cgroup namespaces" data-type="indexterm" id="idm46803128925984"/> in Linux kernel 4.6 in 2016 and is intended to hide the identity of the cgroup of which the process is a member. A process checking which cgroup any process is part of would see a path that is relative to the cgroup set at creation time, hiding its true cgroup position and identity.</p>&#13;
</dd>&#13;
<dt>Time namespaces</dt>&#13;
<dd>&#13;
<p>Time has historically not been namespaced<a data-primary="time namespaces" data-type="indexterm" id="idm46803128923536"/> since it is so integral to the Linux kernel, and providing full namespacing would be very complex. However, with the release of Linux kernel 5.6 in 2020, support was added for a <a href="https://man7.org/linux/man-pages/man7/time_namespaces.7.html">time namespace</a> that allows containers to have their own unique clock offsets.</p>&#13;
</dd>&#13;
</dl>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>At the time of this writing, Docker still does not have direct support for setting the time offset, but like everything else, it can be set directly, if required.</p>&#13;
</div>&#13;
&#13;
<p>So by combining all of these namespaces, Linux can provide the visual and, in many cases, the functional isolation that makes a container look like a VM even though it’s running on the same kernel. Let’s explore what some of the namespacing that we just described looks like in more detail.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>There is a lot of ongoing work trying to make containers more secure. <a data-primary="security" data-secondary="rootless mode security risk" data-tertiary="rootless containers" data-type="indexterm" id="idm46803128919232"/><a data-primary="rootless containers" data-type="indexterm" id="idm46803128918016"/>The community is actively looking into ways to improve support for <a href="https://rootlesscontaine.rs">rootless containers</a>, which enables regular users to create, run, and manage containers locally without needing special privileges. In Docker, this can now be achieved via <a href="https://docs.docker.com/engine/security/rootless">rootless mode</a>. <a data-primary="security" data-secondary="gVisor runtime" data-type="indexterm" id="idm46803128915808"/><a data-primary="runtimes" data-secondary="gVisor runtime" data-type="indexterm" id="idm46803128914800"/><a data-primary="gVisor runtime" data-type="indexterm" id="idm46803128913856"/>New container runtimes like <a href="https://github.com/google/gvisor">Google gVisor</a> are also trying to explore better ways to create much more secure container sandboxes without losing most of the advantages of containerized workflows.<a data-startref="ch11-name" data-type="indexterm" id="idm46803128912384"/><a data-startref="ch11-name2" data-type="indexterm" id="idm46803128911680"/></p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exploring namespaces" data-type="sect3"><div class="sect3" id="idm46803128910752">&#13;
<h3>Exploring namespaces</h3>&#13;
&#13;
<p>One of the easiest namespaces<a data-primary="namespaces" data-secondary="containers in detail" data-tertiary="exploring namespaces" data-type="indexterm" id="ch11-exp"/><a data-primary="Linux containers" data-secondary="namespaces" data-tertiary="exploring" data-type="indexterm" id="ch11-exp2"/><a data-primary="UTS (Unix Time Sharing System) namespaces" data-secondary="exploring" data-type="indexterm" id="ch11-exp3"/> to demonstrate is UTS, so let’s use <code>docker container exec</code> to get a shell in a container and take a look. From within the Docker server, run the following:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>hostname<code class="w"/>&#13;
&#13;
<code class="go">docker-desktop</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Again, remember that you can use the <code>docker container run --rm -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh</code> command that we originally discussed in <a data-type="xref" href="ch03.html#installing_docker">Chapter 3</a> to get access to the Docker host, even if you can’t SSH into the server.</p>&#13;
</div>&#13;
&#13;
<p>And then on your local system, run the following:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>ubuntu<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>bash<code class="w"> </code>-c<code class="w"> </code><code class="s1">'echo "Container hostname: $(hostname)"'</code><code class="w"/>&#13;
&#13;
<code class="go">Container hostname: 4cdb66d4495b</code></pre>&#13;
&#13;
<p>That <code>docker container run</code> command line gets us an interactive session (<code>-ti</code>) and then executes the <code>hostname</code> command via <code>/bin/bash</code> inside the container. Since the <code>hostname</code> command is run inside the container’s namespace, we get back the short container ID, which is used as the hostname by default. This is a pretty simple example, but it should clearly show that we’re not in the same namespace as the host.</p>&#13;
&#13;
<p>Another example that’s easy to understand and demonstrate involves PID namespaces. Let’s create a new container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-d<code class="w"> </code>--rm<code class="w"> </code>--name<code class="w"> </code>pstest<code class="w"> </code>spkane/train-os<code class="w"> </code>sleep<code class="w"> </code><code class="m">240</code><code class="w"/>&#13;
<code class="go">6e005f895e259ed03c4386b5aeb03e0a50368cc173078007b6d1beaa8cd7dded</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code><code class="nb">exec</code><code class="w"> </code>-ti<code class="w"> </code>pstest<code class="w"> </code>ps<code class="w"> </code>-ef<code class="w"/>&#13;
&#13;
<code class="go">UID        PID  PPID  C STIME TTY          TIME CMD</code>&#13;
<code class="go">root         1     0  0 15:33 ?        00:00:00 sleep 240</code>&#13;
<code class="go">root        13     0  0 15:33 pts/0    00:00:00 ps -ef</code></pre>&#13;
&#13;
<p>And now let’s get Docker to show us the process IDs from the host’s perspective:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>top<code class="w"> </code>pstest<code class="w"/>&#13;
&#13;
<code class="go">UID   PID    PPID   C  STIME  TTY  TIME      CMD</code>&#13;
<code class="go">root  31396  31370  0  15:33 ?     00:00:00  sleep 240</code></pre>&#13;
&#13;
<p>What we can see here is that from inside our container, the original command run by Docker is <code>sleep 240</code>, and it has been assigned PID <code>1</code> inside the container. You might recall that this is the PID normally used by the <code>init</code> process on Unix systems. In this case, the <code>sleep 240</code> command that we started the container with is the first process, so it gets PID <code>1</code>. But in the Docker server’s main namespace, we can see that the PID there is not <code>1</code> but <code>31396</code>, and it’s a child of process ID <code>31370</code>.</p>&#13;
&#13;
<p>If you are curious, you can run a command like this to determine what PID <code>31370</code> is:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--pid<code class="o">=</code>host<code class="w"> </code>ubuntu<code class="w"> </code>ps<code class="w"> </code>-p<code class="w"> </code><code class="m">31370</code><code class="w"/>&#13;
<code class="go">PID    TTY  TIME      CMD</code>&#13;
<code class="go">31370  ?    00:00:00  containerd-shim</code></pre>&#13;
&#13;
<p>Now we can go ahead and remove the container we started in the last example by running the following:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp"> $ </code>docker<code class="w"> </code>container<code class="w"> </code>rm<code class="w"> </code>-f<code class="w"> </code>pstest<code class="w"/></pre>&#13;
&#13;
<p>The other namespaces work in essentially the same manner, and you probably get the idea by now. It’s worth pointing out here that when we were first working with <code>nsenter</code> back in <a data-type="xref" href="ch03.html#installing_docker">Chapter 3</a>, we had to pass what appeared to be some pretty arcane arguments to the command when we ran it to enter a container from the Docker server. Let’s go ahead and look at the <code>nsenter</code> portion of the command <code>docker container run --rm -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh</code>.</p>&#13;
&#13;
<p>It turns out that <code>nsenter -t 1 -m -u -n -i sh</code> is exactly the same as <code>nsenter --target 1 --mount --uts --net -ipc sh</code>. So this command really just says, look at PID <code>1</code> and then open up a shell in the same <code>mount</code>, <code>uts</code>, <code>net</code>, and <code>ipc</code> namespaces of that process.</p>&#13;
&#13;
<p>Now that we’ve explained namespaces in detail, this probably makes a lot more sense to you. It can also be educational to use <code>nsenter</code> to try entering different sets of namespaces in a throwaway container to see what you get and simply explore how all of this works in some more detail.</p>&#13;
&#13;
<p>When it comes down to it, namespaces are the primary things that make a container look like a container. Combine them with cgroups, and you have reasonably robust isolation between processes on the same kernel.<a data-startref="ch11-exp" data-type="indexterm" id="idm46803128693888"/><a data-startref="ch11-exp2" data-type="indexterm" id="idm46803128693184"/><a data-startref="ch11-exp3" data-type="indexterm" id="idm46803128692512"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Security" data-type="sect1"><div class="sect1" id="security">&#13;
<h1>Security</h1>&#13;
&#13;
<p>We’ve spent a good bit of space now talking<a data-primary="security" data-secondary="about" data-type="indexterm" id="idm46803128671024"/> about how Docker provides containment for applications, allows you to constrain resource utilization, and uses namespaces to give the container a unique view of the world. We have also briefly mentioned the need for technologies like Secure Computing Mode, SELinux, and AppArmor. One of the advantages of containers is the ability to replace VMs in several use cases. So let’s take a look at what isolation we get by default and what we don’t.</p>&#13;
&#13;
<p>You are undoubtedly aware by now that the isolation you get from a container is not as strong as that from a VM. We’ve been reinforcing the idea from the start of this book that containers are just processes running on the Linux server. Despite the isolation provided by namespaces, containers are not as secure as you might imagine, especially if you are still mentally comparing them to lightweight VMs.</p>&#13;
&#13;
<p>One of the big boosts in performance for containers, and one of the things that makes them lightweight, is that they share the kernel of the Linux server. This is also the source of the greatest security concern around Linux containers. The main reason for this concern is that not everything in the kernel is namespaced. We have talked about all of the namespaces that exist and how the container’s view of the world is constrained by the namespaces it runs in. However, there are still lots of places in the kernel where no real isolation exists, and namespaces constrain the container only if it does not have the power to tell the kernel to give it access to a different namespace.</p>&#13;
&#13;
<p>Containerized applications are more secure than noncontainerized applications because cgroups and standard namespaces provide some important isolation from the host’s core resources. But you should not think of containers as a substitute for good security practices. If you think about how you would run an application on a production system, that is really how you should run all your containers. If your application would traditionally run as a nonprivileged user on a server, then it should be run in the same manner inside the container. It is very easy to tell Docker to run your container processes as a nonprivileged user, and in almost all cases, this is what you should be doing.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>The <code>--userns-remap</code> argument to the <code>dockerd</code> command<a data-primary="production" data-secondary="unprivileged user context" data-type="indexterm" id="idm46803128666768"/><a data-primary="security" data-secondary="unprivileged user context in production" data-type="indexterm" id="idm46803128665792"/><a data-primary="dockerd" data-primary-sortas="docker-z" data-secondary="--userns-remap" data-secondary-sortas="userns-remap for unprivileged context" data-type="indexterm" id="idm46803128664880"/><a data-primary="rootless containers" data-secondary="security risk" data-tertiary="unprivileged context" data-type="indexterm" id="idm46803128663424"/><a data-primary="Linux containers" data-secondary="unprivileged user or group context" data-type="indexterm" id="idm46803128662208"/><a data-primary="unprivileged user or group context" data-type="indexterm" id="idm46803128661296"/><a data-primary="privileged containers" data-secondary="unprivileged user or group context" data-type="indexterm" id="idm46803128660656"/> and rootless mode both make it possible to force all containers to run within a user and group context that is unprivileged on the host system. These approaches help protect the host from many potential security exploits.</p>&#13;
&#13;
<p>For more information about <code>userns-remap</code>, read through the official <a href="https://dockr.ly/2BYfWze">feature</a> and <a href="https://dockr.ly/2LE9gG2">Docker daemon</a> documentation.</p>&#13;
&#13;
<p>You can learn more about rootless mode in the section <a data-type="xref" href="#rootless_mode">“Rootless Mode”</a>.</p>&#13;
</div>&#13;
&#13;
<p>Let’s look at some common security risks and controls.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="UID 0" data-type="sect2"><div class="sect2" id="idm46803128655552">&#13;
<h2>UID 0</h2>&#13;
&#13;
<p>The first and most overarching<a data-primary="security" data-secondary="UID 0 security risk" data-type="indexterm" id="idm46803128653568"/><a data-primary="UID (user ID)" data-secondary="UID 0 security risk" data-type="indexterm" id="idm46803128652240"/> security risk in a container is that, unless you are using rootless mode or the <code>userns-remap</code> functionality in the Docker daemon, the <code>root</code> user in the container is actually the <code>root</code> user on the system. There are extra constraints on <code>root</code> in a container, and namespaces do a good job of isolating <code>root</code> in the container from the most dangerous parts of the <em>/proc</em> and <em>/sys</em> filesystems. But if you are UID 0, you have <code>root</code> access, so if you somehow get access to protected resources on a file mount or outside of your namespace, then the kernel will treat you as <code>root</code> and therefore give you access to the resource. Unless otherwise configured, Docker starts all services in containers as <code>root</code>, which means you are responsible for managing privileges in your applications just like if you are on any standard Linux system. Let’s explore some of the limits on <code>root</code> access and look at some obvious holes. This is not intended to be an exhaustive statement on container security but rather an attempt to give you a healthy understanding of some of the classes of security risks.</p>&#13;
&#13;
<p>First, let’s fire up a container and get a <code>bash</code> shell using the public Ubuntu image shown in the following code. Then we’ll see what kinds of access we have, after installing some tools we want to run:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>ubuntu<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">root@808a2b8426d1:/# </code>apt-get<code class="w"> </code>update<code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="gp">root@808a2b8426d1:/# </code>apt-get<code class="w"> </code>install<code class="w"> </code>-y<code class="w"> </code>kmod<code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="gp">root@808a2b8426d1:/# </code>lsmod<code class="w"/>&#13;
<code class="go">Module                             Size  Used by</code>&#13;
<code class="go">xfrm_user                         36864  1</code>&#13;
<code class="go">xfrm_algo                         16384  1 xfrm_user</code>&#13;
<code class="go">shiftfs                           28672  0</code>&#13;
<code class="go">grpcfuse                          16384  0</code>&#13;
<code class="go">vmw_vsock_virtio_transport        16384  2</code>&#13;
<code class="go">vmw_vsock_virtio_transport_common 28672  1 vmw_vsock_virtio_transport</code>&#13;
<code class="go">vsock                             36864  9 vmw_vsock_virtio_transport_common…</code></pre>&#13;
&#13;
<p>In Docker Desktop, you may only see a few modules in the list, but on a normal Linux system, this list can be very long. Using <code>lsmod</code>, we’ve just asked the kernel to tell us what modules are loaded. It is not that surprising that we get this list from inside our container, since a normal user can always do this. If you run this listing on the Docker server itself, it will be identical, which reinforces the fact that the container is talking to the same Linux kernel that is running on the server. So we can see the kernel modules; what happens if we try to unload the <code>floppy</code> module?</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">root@808a2b8426d1:/# </code>rmmod<code class="w"> </code>shiftfs<code class="w"/>&#13;
&#13;
<code class="go">rmmod: ERROR: ../libkmod/libkmod-module.c:799 kmod_module_remove_module() …</code>&#13;
<code class="go">rmmod: ERROR: could not remove module shiftfs: Operation not permitted</code>&#13;
&#13;
<code class="gp">root@808a2b8426d1:/# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>That’s the same error message we would get if we were a nonprivileged user trying to tell the kernel to remove a module. This should give you a good sense that the kernel is doing its best to prevent us from doing things we shouldn’t. And because we’re in a limited namespace, we can’t get the kernel to give us access to the top-level namespace either. We are essentially relying on the hope that there are no bugs in the kernel that allow us to escalate our privileges inside the container. Because if we do manage to do that, we are <code>root</code>, which means that we will be able to make changes if the kernel allows us to.</p>&#13;
&#13;
<p>We can contrive a simple example of how things can go wrong by starting a <code>bash</code> shell in a container that has had the Docker server’s <em>/etc</em> bind-mounted into the container’s namespace. Keep in mind that anyone who can start a container on your Docker server can do what we’re about to do any time they like because you can’t configure Docker to prevent it, so you must instead rely on external tools like SELinux to avoid exploits like this.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>This example assumes that you are running the <code>docker</code> CLI on a Linux system, which has an <em>/etc/shadow</em> file. This file will not exist on Windows or macOS hosts running something like Docker Desktop.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>-v<code class="w"> </code>/etc:/host_etc<code class="w"> </code>ubuntu<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">root@e674eb96bb74:/# </code>more<code class="w"> </code>/host_etc/shadow<code class="w"/>&#13;
<code class="go">root:!:16230:0:99999:7:::</code>&#13;
<code class="go">daemon:*:16230:0:99999:7:::</code>&#13;
<code class="go">bin:*:16230:0:99999:7:::</code>&#13;
<code class="go">sys:*:16230:0:99999:7:::</code>&#13;
<code class="go">…</code>&#13;
<code class="go">irc:*:16230:0:99999:7:::</code>&#13;
<code class="go">nobody:*:16230:0:99999:7:::</code>&#13;
<code class="go">libuuid:!:16230:0:99999:7:::</code>&#13;
<code class="go">syslog:*:16230:0:99999:7:::</code>&#13;
<code class="go">messagebus:*:16230:0:99999:7:::</code>&#13;
<code class="gp">kmatthias:$1$aTAYQT.j$</code>3xamPL3dHGow4ITBdRh1:16230:0:99999:7:::<code class="w"/>&#13;
<code class="go">sshd:*:16230:0:99999:7:::</code>&#13;
<code class="go">lxc-dnsmasq:!:16458:0:99999:7:::</code>&#13;
&#13;
<code class="gp">root@e674eb96bb74:/# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>Here we’ve used the <code>-v</code> switch to tell Docker to mount a host path into the container. The one we’ve chosen is <em>/etc</em>, which is a very dangerous thing to do. But it serves to prove a point: we are <code>root</code> in the container, and <code>root</code> has file permissions in this path. So we can look at the <em>/etc/shadow</em> file on the Linux server, which contains the encrypted passwords for all the users. There are plenty of other things you could do here, but the point is that by default you’re only partly constrained.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>It is a bad idea to run your container processes with UID 0. This is because any exploit that allows the process to somehow escape its namespaces will expose your host system to a fully privileged process. You should always run your standard containers with a nonprivileged UID.</p>&#13;
</div>&#13;
&#13;
<p>The easiest way to deal with the potential problems surrounding the use of UID 0 inside containers is to always tell Docker to use a different UID for your container.</p>&#13;
&#13;
<p>You can do this by passing the <code>-u</code> argument to <code>docker container run</code>. In the next example, we run the <code>whoami</code> command to show that we are <code>root</code> by default and that we can read the <em>/etc/shadow</em> file that is inside this container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>spkane/train-os:latest<code class="w"> </code>whoami<code class="w"/>&#13;
<code class="go">root</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>spkane/train-os:latest<code class="w"> </code>cat<code class="w"> </code>/etc/shadow<code class="w"/>&#13;
<code class="go">root:!locked::0:99999:7:::</code>&#13;
<code class="go">bin:*:18656:0:99999:7:::</code>&#13;
<code class="go">daemon:*:18656:0:99999:7:::</code>&#13;
<code class="go">adm:*:18656:0:99999:7:::</code>&#13;
<code class="go">lp:*:18656:0:99999:7:::</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>In this example, when you add <code>-u 500</code>, you will see that we become a new, unprivileged user and can no longer read the same <em>/etc/shadow</em> file:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-u<code class="w"> </code><code class="m">500</code><code class="w"> </code>spkane/train-os:latest<code class="w"> </code>whoami<code class="w"/>&#13;
<code class="go">user500</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-u<code class="w"> </code><code class="m">500</code><code class="w"> </code>spkane/train-os:latest<code class="w"> </code>cat<code class="w"> </code>/etc/shadow<code class="w"/>&#13;
<code class="go">cat: /etc/shadow: Permission denied</code></pre>&#13;
&#13;
<p>Another highly recommended approach is to add the <code>USER</code> directive to your <em>Dockerfile</em>s so that containers created from them will launch using a nonprivileged user by default:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">fedora:34</code><code class="w"/>&#13;
<code class="k">RUN</code><code class="w"> </code>useradd<code class="w"> </code>-u<code class="w"> </code><code class="m">500</code><code class="w"> </code>-m<code class="w"> </code>myuser<code class="w"/>&#13;
<code class="k">USER</code><code class="w"> </code><code class="s">500:500</code><code class="w"/>&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"whoami"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>If you create this <em>Dockerfile</em>, and then build and run it, you will see that <code>whoami</code> returns <code>myuser</code> instead of <code>root</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>build<code class="w"> </code>-t<code class="w"> </code>user-test<code class="w"> </code>.<code class="w"/>&#13;
&#13;
<code class="go">[+] Building 0.5s (6/6) FINISHED</code>&#13;
<code class="go"> =&gt; [internal] load build definition from Dockerfile                      0.0s</code>&#13;
<code class="go"> =&gt; =&gt; transferring dockerfile: 36B                                       0.0s</code>&#13;
<code class="go"> =&gt; [internal] load .dockerignore                                         0.0s</code>&#13;
<code class="go"> =&gt; =&gt; transferring context: 2B                                           0.0s</code>&#13;
<code class="go"> =&gt; [internal] load metadata for docker.io/library/fedora:34              0.4s</code>&#13;
<code class="go"> =&gt; [1/2] FROM docker.io/library/fedora:34@sha256:321d…2697               0.0s</code>&#13;
<code class="go"> =&gt; CACHED [2/2] RUN useradd -u 500 -m myuser                             0.0s</code>&#13;
<code class="go"> =&gt; exporting to image                                                    0.0s</code>&#13;
<code class="go"> =&gt; =&gt; exporting layers                                                   0.0s</code>&#13;
<code class="go"> =&gt; =&gt; writing image sha256:4727…30d5                                     0.0s</code>&#13;
<code class="go"> =&gt; =&gt; naming to docker.io/library/user-test                              0.0s</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>user-test<code class="w"/>&#13;
<code class="go">myuser</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Rootless Mode" data-type="sect2"><div class="sect2" id="rootless_mode">&#13;
<h2>Rootless Mode</h2>&#13;
&#13;
<p>One of the primary security challenges<a data-primary="security" data-secondary="rootless mode security risk" data-type="indexterm" id="ch11-sec"/><a data-primary="rootless containers" data-secondary="security risk" data-type="indexterm" id="ch11-sec2"/> with containers is that they often require some root-privileged processes to launch and manage them. Even when you use the <code>--userns-remap</code> feature of the Docker daemon, the daemon itself still runs as a privileged process, even though the containers that it launches will not.</p>&#13;
&#13;
<p>With <a href="https://docs.docker.com/engine/security/rootless">rootless mode</a>, it is possible to run the daemon and all containers without root privileges, which can do a great deal to improve the security of the underlying system.</p>&#13;
&#13;
<p>Rootless mode requires a Linux system, and Docker recommends Ubuntu, so let’s run through an example using a new Ubuntu 22.04 system.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>These steps assume that you are logging in a regular unprivileged user and that you already have <a href="https://docs.docker.com/engine/install/ubuntu">Docker Engine installed</a>.</p>&#13;
</div>&#13;
&#13;
<p>The first thing we need to do is make sure that <code>dbus-user-session</code> and <code>uidmap</code> are installed. If <code>dbus-user-session</code> isn’t already installed, then we need to log out and log back in after running the following command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>sudo<code class="w"> </code>apt-get<code class="w"> </code>install<code class="w"> </code>-y<code class="w"> </code>dbus-user-session<code class="w"> </code>uidmap<code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="go">dbus-user-session is already the newest version (1.12.20-2ubuntu4).</code>&#13;
<code class="go">…</code>&#13;
<code class="go">Setting up uidmap (1:4.8.1-2ubuntu2) …</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>Although, it is not strictly required, if the system-wide Docker daemon is set up to run, it is a very good idea to disable it and then reboot:<a data-primary="Linux" data-secondary="systemd" data-tertiary="rootless mode" data-type="indexterm" id="ch11-rootl"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>sudo<code class="w"> </code>systemctl<code class="w"> </code>disable<code class="w"> </code>--now<code class="w"> </code>docker.service<code class="w"> </code>docker.socket<code class="w"/>&#13;
&#13;
<code class="go">Synchronizing state of docker.service with SysV service script with</code>&#13;
<code class="go">  /lib/systemd/systemd-sysv-install.</code>&#13;
<code class="go">Executing: /lib/systemd/systemd-sysv-install disable docker</code>&#13;
<code class="go">Removed /etc/systemd/system/sockets.target.wants/docker.socket.</code>&#13;
<code class="go">Removed /etc/systemd/system/multi-user.target.wants/docker.service.</code>&#13;
&#13;
<code class="gp">$ </code>sudo<code class="w"> </code>shutdown<code class="w"> </code>-r<code class="w"> </code>now<code class="w"/></pre>&#13;
&#13;
<p>Once the system is back up, you can SSH back into the server as a regular user and confirm that <em>/var/run/docker.sock</em> is no longer on the system:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>ls<code class="w"> </code>/var/run/docker.sock<code class="w"/>&#13;
<code class="go">ls: cannot access '/var/run/docker.sock': No such file or directory</code></pre>&#13;
&#13;
<p>The next step is to run the rootless mode installation script, which is installed in <em>/usr/bin</em> by the Docker installer:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>dockerd-rootless-setuptool.sh<code class="w"> </code>install<code class="w"/>&#13;
&#13;
<code class="go">[INFO] Creating /home/me/.config/systemd/user/docker.service</code>&#13;
<code class="go">[INFO] starting systemd service docker.service</code>&#13;
<code class="go">+ systemctl --user start docker.service</code>&#13;
<code class="go">+ sleep 3</code>&#13;
<code class="go">+ systemctl --user --no-pager --full status docker.service</code>&#13;
<code class="go">● docker.service - Docker Application Container Engine (Rootless)</code>&#13;
<code class="go">     Loaded: loaded (/home/me/.config/systemd/user/docker.service; …)</code>&#13;
<code class="go">…</code>&#13;
<code class="go">+ DOCKER_HOST=unix:///run/user/1000/docker.sock /usr/bin/docker version</code>&#13;
<code class="go">Client: Docker Engine - Community</code>&#13;
<code class="go"> Version:           20.10.18</code>&#13;
<code class="go">…</code>&#13;
<code class="go">Server: Docker Engine - Community</code>&#13;
<code class="go"> Engine:</code>&#13;
<code class="go">  Version:          20.10.18</code>&#13;
<code class="go">…</code>&#13;
<code class="go">+ systemctl --user enable docker.service</code>&#13;
<code class="go">Created symlink /home/me/.config/systemd/user/default.target.wants/</code>&#13;
<code class="go">  docker.service → /home/me/.config/systemd/user/docker.service.</code>&#13;
<code class="go">[INFO] Installed docker.service successfully.</code>&#13;
&#13;
<code class="go">[INFO] To control docker.service, run:</code>&#13;
<code class="go">         `systemctl --user (start|stop|restart) docker.service`</code>&#13;
<code class="go">[INFO] To run docker.service on system startup, run:</code>&#13;
<code class="go">         `sudo loginctl enable-linger me`</code>&#13;
&#13;
<code class="go">[INFO] Creating CLI context "rootless"</code>&#13;
<code class="go">Successfully created context "rootless"</code>&#13;
&#13;
<code class="go">[INFO] Make sure the following environment variables are set</code>&#13;
<code class="go">       (or add them to ~/.bashrc):</code>&#13;
<code class="go">export PATH=/usr/bin:$PATH</code>&#13;
<code class="go">export DOCKER_HOST=unix:///run/user/1000/docker.sock</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The <code>UID`</code> in the <code>DOCKER_HOST`</code> variable here should match the UID of the user who ran the script. In this case, the <code>UID</code> is <code>1000</code>.</p>&#13;
</div>&#13;
&#13;
<p>This script ran a few checks to ensure that our system was ready and then installed and started a user-scoped <code>systemd</code> service file into <code>${HOME}/.config/systemd/user/docker.service</code>. Each and every user on the system could do the same thing, &#13;
<span class="keep-together">if desired.</span></p>&#13;
&#13;
<p>The user Docker daemon can be controlled, like most <code>systemd</code> services. A few basic examples are shown here:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>systemctl<code class="w"> </code>--user<code class="w"> </code>restart<code class="w"> </code>docker.service<code class="w"/>&#13;
<code class="gp">$ </code>systemctl<code class="w"> </code>--user<code class="w"> </code>stop<code class="w"> </code>docker.service<code class="w"/>&#13;
<code class="gp">$ </code>systemctl<code class="w"> </code>--user<code class="w"> </code>start<code class="w"> </code>docker.service<code class="w"/></pre>&#13;
&#13;
<p>To allow the user Docker daemon to run when the user is not logged in, the user needs to use <code>sudo</code> to enable a <code>systemd</code> feature called <code>linger</code>, and then you can also enable the Docker daemon to start whenever the system boots up:<a data-primary="Linux" data-secondary="systemd" data-tertiary="linger feature" data-type="indexterm" id="idm46803128135664"/><a data-startref="ch11-rootl" data-type="indexterm" id="idm46803128051392"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>sudo<code class="w"> </code>loginctl<code class="w"> </code>enable-linger<code class="w"> </code><code class="k">$(</code>whoami<code class="k">)</code><code class="w"/>&#13;
<code class="gp">$ </code>systemctl<code class="w"> </code>--user<code class="w"> </code><code class="nb">enable</code><code class="w"> </code>docker<code class="w"/></pre>&#13;
&#13;
<p>This would be a good time to go ahead and add those environment variables to our shell startup files, but at a minimum we need to make sure both of these environment variables are set in our current terminal:<a data-primary="environment variables" data-secondary="PATH" data-type="indexterm" id="idm46803128016816"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">export</code><code class="w"> </code><code class="nv">PATH</code><code class="o">=</code>/usr/bin:<code class="nv">$PATH</code><code class="w"/>&#13;
<code class="gp">$ </code><code class="nb">export</code><code class="w"> </code><code class="nv">DOCKER_HOST</code><code class="o">=</code>unix:///run/user/1000/docker.sock<code class="w"/></pre>&#13;
&#13;
<p>We can easily run a standard container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>hello-world<code class="w"/>&#13;
&#13;
<code class="go">Hello from Docker!</code>&#13;
<code class="go">This message shows that your installation appears to be working correctly.</code>&#13;
<code class="go">…</code>&#13;
<code class="go">For more examples and ideas, visit:</code>&#13;
<code class="go"> https://docs.docker.com/get-started/</code></pre>&#13;
&#13;
<p>However, you will notice that some of the more privileged containers that we have used in earlier sections will not work in this environment:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>--privileged<code class="w"> </code>--pid<code class="o">=</code>host<code class="w"> </code>debian<code class="w"> </code>nsenter<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>-t<code class="w"> </code><code class="m">1</code><code class="w"> </code>-m<code class="w"> </code>-u<code class="w"> </code>-n<code class="w"> </code>-i<code class="w"> </code>sh<code class="w"/>&#13;
&#13;
<code class="go">docker: Error response from daemon: failed to create shim task: OCI runtime</code>&#13;
<code class="go">create failed: runc create failed: unable to start container process: error</code>&#13;
<code class="go">during container init: error mounting "proc" to rootfs at "/proc":</code>&#13;
<code class="go">mount proc:/proc (via /proc/self/fd/7), flags: 0xe:</code>&#13;
<code class="go">operation not permitted: unknown.</code></pre>&#13;
&#13;
<p>And this is because, in rootless mode, the container cannot have more privileges than the user who is running the container, even though, on the surface, the container appears to still have full <code>root</code> privileges:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>spkane/train-os:latest<code class="w"> </code>whoami<code class="w"/>&#13;
<code class="go">root</code></pre>&#13;
&#13;
<p class="pagebreak-before">Let’s explore this just a little bit more by launching a small container that is running <code>sleep 480s</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-d<code class="w"> </code>--rm<code class="w"> </code>--name<code class="w"> </code>sleep<code class="w"> </code>spkane/train-os:latest<code class="w"> </code>sleep<code class="w"> </code>480s<code class="w"/>&#13;
<code class="go">1f8ccec0a834537da20c6e07423f9217efe34c0eac94f0b0e178fb97612341ef</code></pre>&#13;
&#13;
<p>If we look at the processes inside the container, we see that they all appear to be running with the user <code>root</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code><code class="nb">exec</code><code class="w"> </code>sleep<code class="w"> </code>ps<code class="w"> </code>auxwww<code class="w"/>&#13;
<code class="go">USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</code>&#13;
<code class="go">root           1  0.1  0.0   2400   824 ?        Ss   17:51   0:00 sleep 480s</code>&#13;
<code class="go">root           7  0.0  0.0   7780  3316 ?        Rs   17:51   0:00 ps auxwww</code></pre>&#13;
&#13;
<p>However, if we look at the processes on the Linux system, we see that the <code>sleep</code> command is actually being run by the local user, named <code>me</code>, and not by <code>root</code> at all:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>ps<code class="w"> </code>auxwww<code class="w"> </code><code class="p">|</code><code class="w"> </code>grep<code class="w"> </code>sleep<code class="w"/>&#13;
<code class="go">me   3509 0.0 0.0  2400  824 ?     Ss 10:51 0:00 sleep 480s</code>&#13;
<code class="go">me   3569 0.0 0.0 17732 2360 pts/0 S+ 10:51 0:00 grep --color=auto sleep</code></pre>&#13;
&#13;
<p>The <code>root</code> user inside a rootless container is actually mapped to the user themself. The container processes cannot use any privileges that the user running the daemon does not already have, and because of this, they are a very safe way to allow users on a multiuser system to run containers without granting any of them elevated privileges on the system.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>There are directions to <a href="https://docs.docker.com/engine/security/rootless/#uninstall">uninstall rootless mode</a> on the Docker website.<a data-primary="security" data-secondary="rootless mode security risk" data-tertiary="uninstalling rootless mode" data-type="indexterm" id="idm46803127755792"/><a data-primary="rootless containers" data-secondary="security risk" data-tertiary="uninstalling rootless mode" data-type="indexterm" id="idm46803127754576"/><a data-primary="documentation" data-secondary="Docker" data-tertiary="rootless mode uninstall" data-type="indexterm" id="idm46803127753392"/><a data-primary="resources online" data-secondary="Docker documentation" data-tertiary="rootless mode uninstall" data-type="indexterm" id="idm46803127752176"/><a data-startref="ch11-sec" data-type="indexterm" id="idm46803127750960"/><a data-startref="ch11-sec2" data-type="indexterm" id="idm46803127750288"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Privileged Containers" data-type="sect2"><div class="sect2" id="idm46803128296592">&#13;
<h2>Privileged Containers</h2>&#13;
&#13;
<p>There are times when you need your container to have special<a data-primary="security" data-secondary="privileged containers" data-type="indexterm" id="idm46803127728320"/><a data-primary="Linux containers" data-secondary="privileged" data-tertiary="security" data-type="indexterm" id="idm46803127727472"/><a data-primary="privileged containers" data-secondary="security" data-type="indexterm" id="idm46803127726352"/> <a href="https://man7.org/linux/man-pages/man7/capabilities.7.html">kernel capabilities</a> that would normally be denied to the container. These could include mounting a USB drive, modifying the network configuration, or creating a new Unix device.</p>&#13;
&#13;
<p>In the following code, we try to change the MAC address of our container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>spkane/train-os<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">[root@280d4dc16407 /]# </code>ip<code class="w"> </code>link<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode …</code>&#13;
<code class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</code>&#13;
<code class="go">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN mode DEFAULT …</code>&#13;
<code class="go">    link/ipip 0.0.0.0 brd 0.0.0.0</code>&#13;
<code class="go">3: ip6tnl0@NONE: &lt;NOARP&gt; mtu 1452 qdisc noop state DOWN mode DEFAULT …</code>&#13;
<code class="go">    link/tunnel6 :: brd :: permaddr 12b5:6f1b:a7e9::</code>&#13;
<code class="go">22: eth0@if23: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue …</code>&#13;
<code class="go">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</code>&#13;
&#13;
<code class="gp">[root@fc4589fb8778 /]# </code>ip<code class="w"> </code>link<code class="w"> </code><code class="nb">set</code><code class="w"> </code>eth0<code class="w"> </code>address<code class="w"> </code><code class="m">02</code>:0a:03:0b:04:0c<code class="w"/>&#13;
<code class="go">RTNETLINK answers: Operation not permitted</code>&#13;
&#13;
<code class="gp">[root@280d4dc16407 /]# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>As you can see, it doesn’t work. This is because the underlying Linux kernel blocks the nonprivileged container from doing this, which is exactly what we’d normally want. However, assuming that we need this functionality for our container to work as intended, the easiest way to significantly expand a container’s privileges is by launching it with the <code>--privileged=true</code> argument.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>We don’t recommend running the <code>ip link set eth0 address</code> command in the next example, since this will change the MAC address on the container’s network interface. We show it to help you understand the mechanism. Try it at your own risk.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--privileged<code class="o">=</code><code class="nb">true</code><code class="w"> </code>spkane/train-os<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">[root@853e0ef5dd63 /]# </code>ip<code class="w"> </code>link<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode …</code>&#13;
<code class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</code>&#13;
<code class="go">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN mode DEFAULT …</code>&#13;
<code class="go">    link/ipip 0.0.0.0 brd 0.0.0.0</code>&#13;
<code class="go">3: ip6tnl0@NONE: &lt;NOARP&gt; mtu 1452 qdisc noop state DOWN mode DEFAULT …</code>&#13;
<code class="go">    link/tunnel6 :: brd :: permaddr 12b5:6f1b:a7e9::</code>&#13;
<code class="go">22: eth0@if23: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue …</code>&#13;
<code class="go">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</code>&#13;
&#13;
<code class="gp">[root@853e0ef5dd63 /]# </code>ip<code class="w"> </code>link<code class="w"> </code><code class="nb">set</code><code class="w"> </code>eth0<code class="w"> </code>address<code class="w"> </code><code class="m">02</code>:0a:03:0b:04:0c<code class="w"/>&#13;
&#13;
<code class="gp">[root@853e0ef5dd63 /]#  </code>ip<code class="w"> </code>link<code class="w"> </code>show<code class="w"> </code>eth0<code class="w"/>&#13;
<code class="go">26: eth0@if27: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue …</code>&#13;
<code class="go">    link/ether 02:0a:03:0b:04:0c brd ff:ff:ff:ff:ff:ff link-netnsid 0</code>&#13;
&#13;
<code class="gp">[root@853e0ef5dd63 /]# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>In the preceding output, you will notice that we no longer get the error, and the <code>link/ether</code> entry for <code>eth0</code> has been changed.</p>&#13;
&#13;
<p>The problem with using the <code>--privileged=true</code> argument is that you are giving your container very broad privileges, and in most cases, you likely need only one or two kernel capabilities to get the job done.</p>&#13;
&#13;
<p>If we explore our privileged container some more, we will discover that we have capabilities that have nothing to do with changing the MAC address. We can even do things that could cause issues with both Docker and the host system. In the following code, we are going to mount a disk partition from the underlying host system, list all of the underlying Docker-based Linux containers on the system, and explore some of their critical files:<a data-primary="mount command" data-secondary="privileged containers" data-type="indexterm" id="idm46803127598336"/><a data-primary="system calls" data-secondary="mount" data-tertiary="privileged containers" data-type="indexterm" id="idm46803127597360"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--privileged<code class="o">=</code><code class="nb">true</code><code class="w"> </code>spkane/train-os<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">[root@664a896983d7 /]# </code>mount<code class="w"> </code>/dev/vda1<code class="w"> </code>/mnt<code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">                         </code>ls<code class="w"> </code>-F<code class="w"> </code>/mnt/docker/containers<code class="w"> </code><code class="p">|</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">                         </code>head<code class="w"> </code>-n<code class="w"> </code><code class="m">10</code><code class="w"/>&#13;
&#13;
<code class="go">047df420f6d1f227a26667f83e477f608298c25b0cdad2e149a781587aae5e11/</code>&#13;
<code class="go">0888b9f97b1ecc4261f637404e0adcc8ef0c8df291b87c9160426e42dc9b5dea/</code>&#13;
<code class="go">174ea3ec35cd3a576bed6f475b477b1a474d897ece15acfc46e61685abb3101d/</code>&#13;
<code class="go">1eddad26ee64c4b29eb164b71d56d680739922b3538dc8aa6c6966fce61125b0/</code>&#13;
<code class="go">22b2aa38a687f423522dd174fdd85d578eb21c9c8ec154a0f9b8411d08f6fd4b/</code>&#13;
<code class="go">23879e3b9cd6a42a1e09dc8e96912ad66e80ec09949c744d1177a911322e7462/</code>&#13;
<code class="go">266fe7da627d2e8ec5429140487e984c8d5d36a26bb3cc36a88295e38216e8a7/</code>&#13;
<code class="go">2cb6223e115c12ae729d968db0d2f29a934b4724f0c9536e377e0dbd566f1102/</code>&#13;
<code class="go">306f00e86122b69eeba9323415532a12f88360a1661f445fc7d64c07249eb0ce/</code>&#13;
<code class="go">333b85236409f873d07cd47f62ec1a987df59f688a201df744f40f98b7e4ef2c/</code>&#13;
&#13;
<code class="gp">[root@664a896983d7 /]# </code>ls<code class="w"> </code>-F<code class="w"> </code>/mnt/docker/containers/047d…5e11/<code class="w"/>&#13;
&#13;
<code class="go">047df420f6d1f227a26667f83e477f608298c25b0cdad2e149a781587aae5e11-json.log</code>&#13;
<code class="go">checkpoints/</code>&#13;
<code class="go">config.v2.json</code>&#13;
<code class="go">hostconfig.json</code>&#13;
<code class="go">hostname</code>&#13;
<code class="go">hosts</code>&#13;
<code class="go">mounts/</code>&#13;
<code class="go">resolv.conf</code>&#13;
<code class="go">resolv.conf.hash</code>&#13;
&#13;
<code class="gp">[root@664a896983d7 /]# </code>cat<code class="w"> </code>/mnt/docker/containers/047d…5e11/047…e11-json.log<code class="w"/></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="json" data-type="programlisting"><code class="p">{</code><code class="nt">"log"</code><code class="p">:</code><code class="s2">"047df420f6d1\r\n"</code><code class="p">,</code><code class="nt">"stream"</code><code class="p">:</code><code class="s2">"stdout"</code><code class="p">,</code><code class="nt">"time"</code><code class="p">:</code><code class="s2">"2022-09-14T15:18:29.…"</code><code class="p">}</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="console" data-type="programlisting"><code class="gp">[root@664a896983d7 /]# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Do not change or delete any of these files. It could have an unpredictable impact on the containers or the underlying Linux system.</p>&#13;
</div>&#13;
&#13;
<p>So, as we’ve seen, people can run commands and get access to things that they shouldn’t from a fully privileged container.</p>&#13;
&#13;
<p class="pagebreak-before">To change the MAC address,<a data-primary="Linux" data-secondary="capabilities" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="idm46803127444480"/><a data-primary="Linux" data-secondary="capabilities" data-tertiary="NET_ADMIN" data-type="indexterm" id="idm46803127496032"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="idm46803127494816"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="idm46803127493056"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="NET_ADMIN" data-type="indexterm" id="idm46803127491568"/> the only kernel capability we need is <code>CAP_NET_ADMIN</code>. Instead of giving our container the full set of privileges, we can give it this one privilege by launching our Linux container with the <code>--cap-add</code> argument, as shown here:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--cap-add<code class="o">=</code>NET_ADMIN<code class="w"> </code>spkane/train-os<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">[root@087c02a3c6e7 /]# </code>ip<code class="w"> </code>link<code class="w"> </code>show<code class="w"> </code>eth0<code class="w"/>&#13;
<code class="go">36: eth0@if37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue …</code>&#13;
<code class="go">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</code>&#13;
&#13;
<code class="gp">[root@087c02a3c6e7 /]# </code>ip<code class="w"> </code>link<code class="w"> </code><code class="nb">set</code><code class="w"> </code>eth0<code class="w"> </code>address<code class="w"> </code><code class="m">02</code>:0a:03:0b:04:0c<code class="w"/>&#13;
&#13;
<code class="gp">[root@087c02a3c6e7 /]# </code>ip<code class="w"> </code>link<code class="w"> </code>show<code class="w"> </code>eth0<code class="w"/>&#13;
<code class="go">36: eth0@if37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue …</code>&#13;
<code class="go">    link/ether 02:0a:03:0b:04:0c brd ff:ff:ff:ff:ff:ff link-netnsid 0</code>&#13;
&#13;
<code class="gp">[root@087c02a3c6e7 /]# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>You should also notice that although we can change the MAC address, we can no longer use the <code>mount</code> command inside our container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--cap-add<code class="o">=</code>NET_ADMIN<code class="w"> </code>spkane/train-os<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">[root@b84a06ddaa0d /]# </code>mount<code class="w"> </code>/dev/vda1<code class="w"> </code>/mnt<code class="w"/>&#13;
<code class="go">mount: /mnt: permission denied.</code>&#13;
&#13;
<code class="gp">[root@b84a06ddaa0d /]# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>It is also possible to remove specific capabilities from a container. Imagine for a moment that your security team requires that <code>tcpdump</code> be disabled in all containers, and when you test some of your containers, you find that <code>tcpdump</code> is installed and can easily be run:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>spkane/train-os:latest<code class="w"> </code>tcpdump<code class="w"> </code>-i<code class="w"> </code>eth0<code class="w"/>&#13;
&#13;
<code class="go">dropped privs to tcpdump</code>&#13;
<code class="go">tcpdump: verbose output suppressed, use -v[v]… for full protocol decode</code>&#13;
<code class="go">listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes</code>&#13;
<code class="go">15:40:49.847446 IP6 fe80::23:6cff:fed6:424f &gt; ff02::16: HBH ICMP6, …</code>&#13;
<code class="go">15:40:49.913977 ARP, Request who-has _gateway tell 5614703ffee2, length 28</code>&#13;
<code class="go">15:40:49.914048 ARP, Request who-has _gateway tell 5614703ffee2, length 28</code>&#13;
<code class="go">15:40:49.914051 ARP, Reply _gateway is-at 02:49:9b:d9:49:4e (oui Unknown), …</code>&#13;
<code class="go">15:40:49.914053 IP 5642703bbff2.45432 &gt; 192.168.75.8.domain: 44649+ PTR? …</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>You could remove <code>tcpdump</code> from your images, but there is very little preventing someone from reinstalling it. The most effective way to solve this problem is to determine what capability <code>tcpdump</code> needs to operate and remove that from the container. In this case, you can do so by adding <code>--cap-drop=NET_RAW</code> to your <code>docker container run</code> command:<a data-primary="Linux" data-secondary="capabilities" data-tertiary="--cap-drop" data-tertiary-sortas="cap-drop" data-type="indexterm" id="idm46803127266880"/><a data-primary="Linux" data-secondary="capabilities" data-tertiary="NET_RAW" data-type="indexterm" id="idm46803127265328"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--cap-drop" data-tertiary-sortas="cap-drop" data-type="indexterm" id="idm46803127264112"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="--cap-drop" data-tertiary-sortas="cap-drop" data-type="indexterm" id="idm46803127262352"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="NET_RAW" data-type="indexterm" id="idm46803127260864"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--cap-drop<code class="o">=</code>NET_RAW<code class="w"> </code>spkane/train-os:latest<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>tcpdump<code class="w"> </code>-i<code class="w"> </code>eth0<code class="w"/>&#13;
&#13;
<code class="go">tcpdump: eth0: You don't have permission to capture on that device</code>&#13;
<code class="gp-VirtualEnv">(socket: Operation not permitted)</code></pre>&#13;
&#13;
<p>By using both the <code>--cap-add</code> and <code>--cap-drop</code> arguments to <code>docker container run</code>, you can finely control your container’s&#13;
<a href="https://man7.org/linux/man-pages/man7/capabilities.7.html">Linux kernel capabilities</a>.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Be aware that in addition to providing access to system calls, there are actually some other things that enabling a specific Linux capability can provide. This might include visibility of all the devices on the system or the ability to change the time on the system.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Secure Computing Mode" data-type="sect2"><div class="sect2" id="seccomp">&#13;
<h2>Secure Computing Mode</h2>&#13;
&#13;
<p>When Linux kernel version 2.6.12 was<a data-primary="security" data-secondary="Secure Computing Mode" data-type="indexterm" id="ch11-scm"/><a data-primary="Secure Computing Mode" data-type="indexterm" id="ch11-scm2"/><a data-primary="Linux" data-secondary="Secure Computing Mode" data-type="indexterm" id="ch11-scm3"/><a data-primary="security" data-secondary="system calls" data-type="indexterm" id="ch11-scm4"/><a data-primary="system calls" data-secondary="Secure Computing Mode" data-type="indexterm" id="ch11-scm5"/> released in 2005, it included a new security feature called Secure Computing Mode, or <code>seccomp</code> for short. <a data-primary="system calls" data-secondary="sigreturn" data-type="indexterm" id="idm46803127178368"/><a data-primary="system calls" data-secondary="read" data-type="indexterm" id="idm46803127177360"/><a data-primary="system calls" data-secondary="write" data-type="indexterm" id="idm46803127176416"/>This feature enables a process to make a one-way transition into a special state, where it will only be allowed to make the system calls <code>exit()</code>, <code>sigreturn()</code>, and <code>read()</code> or <code>write()</code> to already-open file descriptors.</p>&#13;
&#13;
<p>An extension to <code>seccomp</code>, called <code>seccomp-bpf</code>, utilizes the Linux version of <a href="https://www.kernel.org/doc/Documentation/networking/filter.txt">Berkeley Packet Filter (BPF)</a> rules to allow you to create a policy that will provide an explicit list of system calls that a process can utilize while running under Secure Computing Mode. The Docker support for Secure Computing Mode utilizes <code>seccomp-bpf</code> so that users can create profiles that give them very fine-grained control of which kernel system calls their containerized processes are allowed to make.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>By default, all containers use Secure Computing Mode and have the default profile attached to them. You can <a href="https://docs.docker.com/engine/security/seccomp">read more about Secure Computing Mode</a> and which system calls the default profile blocks in the documentation. You can also examine the <a href="https://github.com/moby/moby/blob/master/profiles/seccomp/default.json">default policy’s JSON file</a> to see what a policy looks like and understand exactly what it defines.</p>&#13;
</div>&#13;
&#13;
<p>To see how you could use this,<a data-primary="umount command" data-secondary="secure computing mode" data-type="indexterm" id="idm46803127168416"/><a data-primary="system calls" data-secondary="umount" data-type="indexterm" id="idm46803127167440"/> let’s use the program <code>strace</code> to trace the system calls that a process is making when we try to unmount a filesystem with the &#13;
<span class="keep-together"><code>umount</code> command.</span></p>&#13;
<div class="less_space pagebreak-before" data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>These examples are here to prove a point, but you obviously shouldn’t be unmounting filesystems out of your container without knowing exactly what is going to happen.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>spkane/train-os:latest<code class="w"> </code>umount<code class="w"> </code>/sys/fs/cgroup<code class="w"/>&#13;
<code class="go">umount: /sys/fs/cgroup: must be superuser to unmount.</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>spkane/train-os:latest<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>strace<code class="w"> </code>umount<code class="w"> </code>/sys/fs/cgroup<code class="w"/>&#13;
&#13;
<code class="go">execve("/usr/bin/umount", ["umount", "/sys/fs/cgroup"], 0x7fff902ddbe8 …</code>&#13;
<code class="go">…</code>&#13;
<code class="go">umount2("/sys/fs/cgroup", 0)            = -1 EPERM (Operation not permitted)</code>&#13;
<code class="go">write(2, "umount: ", 8umount: )                 = 8</code>&#13;
<code class="go">write(2, "/sys/fs/cgroup: must be superuse"…,</code>&#13;
<code class="go">      45/sys/fs/cgroup: must be superuser to unmount.) = 45</code>&#13;
<code class="go">write(2, "\n", 1</code>&#13;
<code class="go">)                       = 1</code>&#13;
<code class="go">dup(1)                                  = 3</code>&#13;
<code class="go">close(3)                                = 0</code>&#13;
<code class="go">dup(2)                                  = 3</code>&#13;
<code class="go">close(3)                                = 0</code>&#13;
<code class="go">exit_group(32)                          = ?</code>&#13;
<code class="go">+++ exited with 32 +++</code></pre>&#13;
&#13;
<p>We already know that mount-related commands<a data-primary="mount command" data-secondary="Secure Computing Mode" data-type="indexterm" id="idm46803127162400"/><a data-primary="system calls" data-secondary="mount" data-tertiary="Secure Computing Mode" data-type="indexterm" id="idm46803127142880"/> do not work in a container with standard permissions, and <code>strace</code> makes it clear that the system returns an “Operation not permitted” error message when the <code>umount</code> command tries to use the <code>umount2</code> system call.</p>&#13;
&#13;
<p>You could potentially fix this by giving your container the <code>SYS_ADMIN</code> capability, like this:<a data-primary="Linux" data-secondary="capabilities" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="ch11-capa"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="ch11-capa2"/><a data-primary="Linux" data-secondary="capabilities" data-tertiary="SYS_ADMIN" data-type="indexterm" id="ch11-capa3"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="ch11-capa4"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="SYS_ADMIN" data-type="indexterm" id="ch11-capa5"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--cap-add<code class="o">=</code>SYS_ADMIN<code class="w"> </code>spkane/train-os:latest<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>strace<code class="w"> </code>umount<code class="w"> </code>/sys/fs/cgroup<code class="w"/>&#13;
&#13;
<code class="go">execve("/usr/bin/umount", ["umount", "/sys/fs/cgroup"], 0x7ffd3e4452b8 …</code>&#13;
<code class="go">…</code>&#13;
<code class="go">umount2("/sys/fs/cgroup", 0)            = 0</code>&#13;
<code class="go">dup(1)                                  = 3</code>&#13;
<code class="go">close(3)                                = 0</code>&#13;
<code class="go">dup(2)                                  = 3</code>&#13;
<code class="go">close(3)                                = 0</code>&#13;
<code class="go">exit_group(0)                           = ?</code>&#13;
<code class="go">+++ exited with 0 +++</code></pre>&#13;
&#13;
<p class="pagebreak-before">However, remember that using <code>--cap-add=SYS_ADMIN</code> will make it possible for us to do many other things, including mounting system partitions using a command like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--cap-add<code class="o">=</code>SYS_ADMIN<code class="w"> </code>spkane/train-os:latest<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>mount<code class="w"> </code>/dev/vda1<code class="w"> </code>/mnt<code class="w"/></pre>&#13;
&#13;
<p>You can solve this problem with a more focused approach by using a <code>seccomp</code> profile. Unlike <code>seccomp</code>, <code>--cap-add</code> will enable a whole set of system calls and some additional privileges, and you almost certainly don’t need them all. <code>CAP_SYS_ADMIN</code>  is particularly powerful and provides way more privileges than any one capability should. With a <code>seccomp</code> profile, however, you can be very specific about exactly what system calls you want to be enabled or disabled.</p>&#13;
&#13;
<p>If we take a look at the default <code>seccomp</code> profile, we’ll see something like this:</p>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="p">{</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">"defaultAction"</code><code class="p">:</code><code class="w"> </code><code class="s2">"SCMP_ACT_ERRNO"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">"defaultErrnoRet"</code><code class="p">:</code><code class="w"> </code><code class="mi">1</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">"archMap"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"architecture"</code><code class="p">:</code><code class="w"> </code><code class="s2">"SCMP_ARCH_X86_64"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"subArchitectures"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"SCMP_ARCH_X86"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"SCMP_ARCH_X32"</code><code class="w"/>&#13;
<code class="w">            </code><code class="p">]</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">},</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">],</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">"syscalls"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"names"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"accept"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"accept4"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"access"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"adjtimex"</code><code class="p">,</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"waitid"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"waitpid"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"write"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"writev"</code><code class="w"/>&#13;
<code class="w">            </code><code class="p">],</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"action"</code><code class="p">:</code><code class="w"> </code><code class="s2">"SCMP_ACT_ALLOW"</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">},</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"names"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"bpf"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"clone"</code><code class="p">,</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"umount2"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                </code><code class="s2">"unshare"</code><code class="w"/>&#13;
<code class="w">            </code><code class="p">],</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"action"</code><code class="p">:</code><code class="w"> </code><code class="s2">"SCMP_ACT_ALLOW"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"includes"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"caps"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">                    </code><code class="s2">"CAP_SYS_ADMIN"</code><code class="w"/>&#13;
<code class="w">                </code><code class="p">]</code><code class="w"/>&#13;
<code class="w">            </code><code class="p">}</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">},</code><code class="w"/>&#13;
<code class="err">…</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">]</code><code class="w"/>&#13;
<code class="p">}</code><code class="w"/></pre>&#13;
&#13;
<p>This JSON file provides a list of supported architectures, a default ruleset, and groups of system calls that fall within the scope of each capability. In this case, the default action is <code>SCMP_ACT_ERRNO</code> and will generate an error if an unspecified call is attempted.</p>&#13;
&#13;
<p>If you examine the default profile in detail, you’ll notice that <code>CAP_SYS_ADMIN</code> controls access to 37 system calls, a huge number that is even larger than the 4-6 system calls included in most other capabilities.</p>&#13;
&#13;
<p>In the current use case, we actually need some of the special functionality provided by <code>CAP_SYS_ADMIN</code>, but we do not need all of those system calls. To ensure that we are adding only the one additional system call that we need, we can create our own Secure Computing Mode policy, based on the default policy that Docker provides.</p>&#13;
&#13;
<p>First, pull down the default policy and make a copy of it:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>wget<code class="w"> </code>https://raw.githubusercontent.com/moby/moby/master/<code class="se">\</code>&#13;
profiles/seccomp/default.json<code class="w"/>&#13;
&#13;
<code class="gp">$ </code>cp<code class="w"> </code>default.json<code class="w"> </code>umount2.json<code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The URL has been continued on the following line so that it fits in the margins. You may find that you need to reassemble the URL and remove the backslashes for the command to work properly in your environment.</p>&#13;
</div>&#13;
&#13;
<p>Then edit the file and remove a bunch of the system calls that <code>CAP_SYS_ADMIN</code> normally provides. In this case, we actually need to retain two system calls to ensure that both <code>strace</code> and <code>umount</code> work correctly.</p>&#13;
&#13;
<p>The section of the file that we are targeting ends with this JSON block:</p>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="w">            </code><code class="nt">"includes"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">                </code><code class="nt">"caps"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">                    </code><code class="s2">"CAP_SYS_ADMIN"</code><code class="w"/>&#13;
<code class="w">                </code><code class="p">]</code><code class="w"/>&#13;
<code class="w">            </code><code class="p">}</code><code class="w"/></pre>&#13;
&#13;
<p>This <code>diff</code>  shows the exact changes that need to be made in this use case:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>diff<code class="w"> </code>-u<code class="w"> </code>-U5<code class="w"> </code>default.json<code class="w"> </code>umount2.json<code class="w"/></pre>&#13;
&#13;
<pre data-code-language="diff" data-type="programlisting"><code class="gh">diff -u -U5 default.json umount2.json</code><code class="w"/>&#13;
<code class="gd">--- default.json        2022-09-25 13:23:57.000000000 -0700</code><code class="w"/>&#13;
<code class="gi">+++ umount2.json        2022-09-25 13:38:31.000000000 -0700</code><code class="w"/>&#13;
<code class="gu">@@ -575,34 +575,12 @@</code><code class="w"/>&#13;
<code class="w"> </code>                               ]<code class="w"/>&#13;
<code class="w"> </code>                       }<code class="w"/>&#13;
<code class="w"> </code>               },<code class="w"/>&#13;
<code class="w"> </code>               {<code class="w"/>&#13;
<code class="w"> </code>                       "names": [<code class="w"/>&#13;
<code class="gd">-                               "bpf",</code><code class="w"/>&#13;
<code class="w"> </code>                               "clone",<code class="w"/>&#13;
<code class="gd">-                               "clone3",</code><code class="w"/>&#13;
<code class="gd">-                               "fanotify_init",</code><code class="w"/>&#13;
<code class="gd">-                               "fsconfig",</code><code class="w"/>&#13;
<code class="gd">-                               "fsmount",</code><code class="w"/>&#13;
<code class="gd">-                               "fsopen",</code><code class="w"/>&#13;
<code class="gd">-                               "fspick",</code><code class="w"/>&#13;
<code class="gd">-                               "lookup_dcookie",</code><code class="w"/>&#13;
<code class="gd">-                               "mount",</code><code class="w"/>&#13;
<code class="gd">-                               "mount_setattr",</code><code class="w"/>&#13;
<code class="gd">-                               "move_mount",</code><code class="w"/>&#13;
<code class="gd">-                               "name_to_handle_at",</code><code class="w"/>&#13;
<code class="gd">-                               "open_tree",</code><code class="w"/>&#13;
<code class="gd">-                               "perf_event_open",</code><code class="w"/>&#13;
<code class="gd">-                               "quotactl",</code><code class="w"/>&#13;
<code class="gd">-                               "quotactl_fd",</code><code class="w"/>&#13;
<code class="gd">-                               "setdomainname",</code><code class="w"/>&#13;
<code class="gd">-                               "sethostname",</code><code class="w"/>&#13;
<code class="gd">-                               "setns",</code><code class="w"/>&#13;
<code class="gd">-                               "syslog",</code><code class="w"/>&#13;
<code class="gd">-                               "umount",</code><code class="w"/>&#13;
<code class="gd">-                               "umount2",</code><code class="w"/>&#13;
<code class="gd">-                               "unshare"</code><code class="w"/>&#13;
<code class="gi">+                               "umount2"</code><code class="w"/>&#13;
<code class="w"> </code>                       ],<code class="w"/>&#13;
<code class="w"> </code>                       "action": "SCMP_ACT_ALLOW",<code class="w"/>&#13;
<code class="w"> </code>                       "includes": {<code class="w"/>&#13;
<code class="w"> </code>                               "caps": [<code class="w"/>&#13;
<code class="w"> </code>                                       "CAP_SYS_ADMIN"<code class="w"/></pre>&#13;
&#13;
<p>You are now ready to test your new finely tuned <code>seccomp</code> profile to ensure that it can run <code>umount</code> but cannot run <code>mount</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--security-opt<code class="w"> </code><code class="nv">seccomp</code><code class="o">=</code>umount2.json<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--cap-add<code class="o">=</code>SYS_ADMIN<code class="w"> </code>spkane/train-os:latest<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">[root@15b8a26b6cfe /]# </code>strace<code class="w"> </code>umount<code class="w"> </code>/sys/fs/cgroup<code class="w"/>&#13;
<code class="go">execve("/usr/bin/umount", ["umount", "/sys/fs/cgroup"], 0x7ffece9ebc38 …</code>&#13;
<code class="go">close(3)                                = 0</code>&#13;
<code class="go">exit_group(0)                           = ?</code>&#13;
<code class="go">+++ exited with 0 +++</code>&#13;
&#13;
<code class="gp">[root@15b8a26b6cfe /]# </code>mount<code class="w"> </code>/dev/vda1<code class="w"> </code>/mnt<code class="w"/>&#13;
<code class="go">mount: /mnt: permission denied.</code>&#13;
&#13;
<code class="gp">[root@15b8a26b6cfe /]# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>If everything went according to plan, your <code>strace</code> of the <code>umount</code> program should have run perfectly and the <code>mount</code> command should have been blocked. In the real world, it would be much safer to consider redesigning your applications so that they do not need these special privileges, but when it cannot be avoided, you should be able to use these tools to help ensure that your containers remain as secure as possible while still doing their jobs.<a data-startref="ch11-capa" data-type="indexterm" id="idm46803126483632"/><a data-startref="ch11-capa2" data-type="indexterm" id="idm46803126482960"/><a data-startref="ch11-capa3" data-type="indexterm" id="idm46803126482288"/><a data-startref="ch11-capa4" data-type="indexterm" id="idm46803126481616"/><a data-startref="ch11-capa5" data-type="indexterm" id="idm46803126480944"/></p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>You could completely disable the default Secure Computing Mode profile by setting <code>--security-opt seccomp=unconfined</code>; however, running a container unconfined is a very bad idea in general and is probably only useful when you are trying to figure out exactly what system calls you may need to define in your profile.</p>&#13;
</div>&#13;
&#13;
<p>The strength of Secure Computing Mode is that it allows users to be much more selective about what a container can and can’t do with the underlying Linux kernel. Custom profiles are not required for most containers, but they are an incredibly handy tool when you need to carefully craft a powerful container and ensure that you maintain the overall security of the system.<a data-startref="ch11-scm" data-type="indexterm" id="idm46803126478496"/><a data-startref="ch11-scm2" data-type="indexterm" id="idm46803126477792"/><a data-startref="ch11-scm3" data-type="indexterm" id="idm46803126477120"/><a data-startref="ch11-scm4" data-type="indexterm" id="idm46803126476448"/><a data-startref="ch11-scm5" data-type="indexterm" id="idm46803126497344"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="SELinux and AppArmor" data-type="sect2"><div class="sect2" id="idm46803127214496">&#13;
<h2>SELinux and AppArmor</h2>&#13;
&#13;
<p>Earlier, we talked about how containers<a data-primary="security" data-secondary="SELinux" data-type="indexterm" id="idm46803126495264"/><a data-primary="SELinux security" data-type="indexterm" id="idm46803126494288"/><a data-primary="security" data-secondary="AppArmor" data-type="indexterm" id="idm46803126493616"/><a data-primary="AppArmor" data-type="indexterm" id="idm46803126492672"/><a data-primary="Linux" data-secondary="AppArmor" data-type="indexterm" id="idm46803126492000"/> primarily leverage cgroups and namespaces for their functionality. <a href="https://www.redhat.com/en/topics/linux/what-is-selinux">SELinux</a> and <a href="https://apparmor.net">AppArmor</a> are security layers in the Linux ecosystem that can be used to increase the security of containers even further. In this section, we are going to discuss these two systems a bit. SELinux and AppArmor allow you to apply security controls that extend beyond those normally supported by Unix systems. SELinux originated in the US National Security Agency, was strongly adopted by Red Hat, and supports very fine-grained control. AppArmor is an effort to achieve many of the same goals while being a bit more user-friendly than SELinux.</p>&#13;
&#13;
<p>By default, Docker ships with reasonable profiles enabled on platforms that support either of these systems. You can further configure these profiles to enable or prevent all sorts of features, and if you’re running Docker in production, you should do a risk analysis to determine if there are additional considerations that you should be aware of. We’ll give a quick outline of the benefits you are getting from these systems.</p>&#13;
&#13;
<p>Both systems provide <em>mandatory access control</em>, a <a data-primary="mandatory access control" data-type="indexterm" id="idm46803126488144"/><a data-primary="security" data-secondary="mandatory access control" data-type="indexterm" id="idm46803126487472"/>class of security system where a systemwide security policy grants users (or “initiators”) access to a resource (or “target”). This allows you to prevent anyone, including <code>root</code>, from accessing a part of the system that they should not have access to. You can apply the policy to a whole container so that all processes are constrained. Many chapters would be required to provide a clear and detailed overview of how to configure these systems. The default profiles are performing tasks like blocking access to parts of the <em>/proc</em> and <em>/sys</em> filesystems that would be dangerous to expose in the container, even though they show up in the container’s namespace. The default profiles also provide more narrowly scoped mount access to prevent containers from getting hold of mount points they should not see.</p>&#13;
&#13;
<p>If you are considering using Linux containers in production, it is worth seriously considering going through the effort to enable AppArmor or SELinux on these systems. For the most part, both systems are reasonably equivalent. But in the Docker context, one notable limitation of SELinux is that it only works fully on systems that support filesystem metadata, which means that it won’t work with all Docker storage drivers. AppArmor, on the other hand, does not use filesystem metadata and therefore works on all of the Docker backends. Which one you use is somewhat distribution-centric, so you may be forced to choose a filesystem backend that also supports the security system that you use.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Docker Daemon" data-type="sect2"><div class="sect2" id="idm46803126434528">&#13;
<h2>The Docker Daemon</h2>&#13;
&#13;
<p>From a security standpoint, the<a data-primary="security" data-secondary="Docker daemon" data-type="indexterm" id="idm46803126433152"/><a data-primary="Docker daemon" data-primary-sortas="docker-a" data-secondary="security" data-type="indexterm" id="idm46803126432240"/><a data-primary="dockerd" data-primary-sortas="docker-z" data-secondary="security" data-type="indexterm" id="idm46803126431024"/> Docker daemon and its components are the only completely new risk you are introducing to your infrastructure. Your containerized applications are not any less secure and are, at least, a little more secure than they would be if deployed outside of containers. But without the containers, you would not be running <code>dockerd</code>, the Docker daemon. You can run Docker such that it doesn’t expose any ports on the network. This is highly recommended and the default for most Docker installations.</p>&#13;
&#13;
<p>The default configuration for Docker, on most distributions, leaves Docker isolated from the network with only a local Unix socket exposed. Since you cannot remotely administer Docker when it is set up this way, it is not uncommon to see people simply add the nonencrypted port 2375 to the configuration. This may be great for getting started with Docker, but it is not what you should do in any environment where you care about the security of your systems. You should not open Docker up to the outside world at all unless you have a very good reason to. If you do, you should also commit to properly securing it. Most scheduler systems run their services on each node and expect to talk to Docker over the Unix domain socket instead of over a network port.</p>&#13;
&#13;
<p>If you do need to expose the daemon to the network, you can do a few things to tighten Docker down in a way that makes sense in most production environments. But no matter what you do, you are relying on the Docker daemon itself to be resilient against threats like buffer overflows and race conditions, two of the more common classes of security vulnerabilities. This is true of any network service. The risk is a lot higher with the Docker daemon because it is normally run as <code>root</code>, it can run anything on your system, and it has no integrated role-based access controls.</p>&#13;
&#13;
<p>The basics of locking Docker down are common with many other network daemons: encrypt your traffic and authenticate users. The first is reasonably easy to set up on Docker; the second is not as easy. If you have SSL certificates you can use for protecting HTTP traffic to your hosts, such as a wildcard certificate for your domain, you can turn on TLS support to encrypt all of the traffic to your Docker servers, using port 2376. This is a good first step. <a data-primary="security" data-secondary="Docker daemon" data-tertiary="documentation" data-type="indexterm" id="idm46803126427520"/><a data-primary="documentation" data-secondary="Docker" data-tertiary="security" data-type="indexterm" id="idm46803126426272"/><a data-primary="resources online" data-secondary="Docker documentation" data-tertiary="security" data-type="indexterm" id="idm46803126425056"/>The <a href="https://docs.docker.com/engine/security/protect-access">Docker documentation</a> will walk you through doing this.</p>&#13;
&#13;
<p>Authenticating users is more complicated. Docker does not provide any kind of fine-grained authorization: you either have access or you don’t. But the authentication control it does provide—signed certificates—is reasonably strong. Unfortunately, this also means that you don’t get a cheap step from no authentication to some authentication without also having to set up a certificate authority in most cases. If your organization already has one, then you are in luck. Certificate management needs to be implemented carefully in any organization, both to keep certificates secure and to distribute them efficiently. So, given that, here are the basic steps:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Set up a method of generating and signing certificates.</p>&#13;
</li>&#13;
<li>&#13;
<p>Generate certificates for the server and clients.</p>&#13;
</li>&#13;
<li>&#13;
<p>Configure Docker to require certificates with <code>--tlsverify</code>.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Detailed instructions on getting a server and client set up, as well as a simple certificate authority, are included in the <a href="https://docs.docker.com/engine/security/protect-access">Docker documentation</a>.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Because it’s a daemon that almost always runs with privilege, and because it has direct control of your applications, it is a bad idea to expose Docker directly on the internet. If you need to talk to your Docker hosts from outside your network, consider something like a VPN or an SSH tunnel to a secure jump host.</p>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Advanced Configuration" data-type="sect1"><div class="sect1" id="idm46803126416336">&#13;
<h1>Advanced Configuration</h1>&#13;
&#13;
<p>Docker has a very clean external interface,<a data-primary="configuration" data-secondary="advanced configuration" data-type="indexterm" id="idm46803126414768"/> and on the surface, it looks pretty monolithic. But there are actually a lot of things going on behind the scenes that are configurable, and the logging backends we described in <a data-type="xref" href="ch06.html#docker_logs">“Logging”</a> are a good example. You can also do things like change out the storage backend for container images for the whole daemon, use a completely different runtime, or configure individual containers to run on a different network configuration. Those are powerful switches, and you’ll want to know what they do before turning them on. First, we’ll talk about the network configuration, then we’ll cover the storage backends, and finally, we’ll try out a completely different container runtime to replace the default <code>runc</code> supplied with Docker.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Networking" data-type="sect2"><div class="sect2" id="docker_net">&#13;
<h2>Networking</h2>&#13;
&#13;
<p>Early on, we described the layers<a data-primary="configuration" data-secondary="advanced configuration" data-tertiary="networking" data-type="indexterm" id="ch11-advnet"/><a data-primary="networking" data-secondary="advanced configuration" data-type="indexterm" id="ch11-advnet2"/> of networking between a Linux container and the real, live network. Let’s take a closer look at how that works. Docker supports a rich set of network configurations, but let’s start with the default setup. <a data-type="xref" href="#figure11-1">Figure 11-1</a> shows a drawing of a typical Docker server, where three containers are running on their private network, shown on the right. One of them has a public port (TCP port 10520) that is exposed on the Docker server. We’ll track how an inbound request gets to the Linux container and also how a Linux container can make an outbound connection to the external network.</p>&#13;
&#13;
<figure><div class="figure" id="figure11-1">&#13;
<img alt="The network on a typical Docker server" src="assets/dur3_1101.png"/>&#13;
<h6><span class="label">Figure 11-1. </span>The network on a typical Docker server</h6>&#13;
</div></figure>&#13;
&#13;
<p>If we have a client somewhere on the network that wants to talk to the <code>nginx</code> server running on TCP port 80 inside Container 1, the request will come into the <code>eth0</code> interface on the Docker server. Because Docker knows this is a public port, it has spun up an instance of <code>docker-proxy</code> to listen on port 10520. So our request is passed to the <code>docker-proxy</code> process, which then forwards the request to the correct container address and port on the private network. Return traffic from the request flows through the same route.</p>&#13;
&#13;
<p>Outbound traffic from the container follows a different route in which the <code>docker-proxy</code> is not involved at all. In this case, Container 3 wants to contact a server on the public internet. It has an address on the private network of 172.16.23.1, and its default route is the <code>docker0</code> interface 172.16.23.7. So it sends the traffic there. The Docker server now sees that this traffic is outbound and that it has traffic forwarding enabled. And since the virtual network is private, it wants to send the traffic from its public address instead. So the request is passed through the kernel’s network address translation (NAT) layer and put onto the external network via the <code>eth0</code> interface on the server. Return traffic passes through the same route. The NAT is one-way, so containers on the virtual network will see real network addresses in response packets.</p>&#13;
&#13;
<p>You’ve probably noticed that it’s not a simple configuration. It’s a fair amount of complexity, but it makes Docker seem pretty transparent. It also contributes to the security posture of the Docker stack because the containers are namespaced into individual network namespaces, are on individual private networks, and don’t have access to things like the main system’s DBus (Desktop Bus) or iptables.</p>&#13;
&#13;
<p>Let’s examine what’s happening at a more detailed level. The interfaces that show up in <code>ifconfig</code> or <code>ip addr show</code> in the Linux container are actually virtual Ethernet interfaces on the Docker server’s kernel. They are then mapped into the container’s network namespace and given the names that you see inside the container. Let’s take a look at what we might see when running <code>ip addr show</code> on a Docker server. We’ll shorten the output a little for clarity and spaces, as shown here:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>ip<code class="w"> </code>addr<code class="w"> </code>show<code class="w"/>&#13;
&#13;
<code class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group …</code>&#13;
<code class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</code>&#13;
<code class="go">    inet 127.0.0.1/8 brd 127.255.255.255 scope host lo</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">    inet6 ::1/128 scope host</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state …</code>&#13;
<code class="go">    link/ether 02:50:00:00:00:01 brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 172.16.168.178/24 brd 192.168.65.255 scope global dynamic …</code>&#13;
<code class="go">       valid_lft 4908sec preferred_lft 3468sec</code>&#13;
<code class="go">    inet6 fe80::50:ff:fe00:1/64 scope link</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">…</code>&#13;
<code class="go">7: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue …</code>&#13;
<code class="go">    link/ether 02:42:9c:d2:89:4f brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 172.17.42.1/16brd 172.17.255.255 scope global docker0</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">    inet6 fe80::42:9cff:fed2:894f/64 scope link</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">…</code>&#13;
<code class="go">185: veth772de2a@if184: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc …</code>&#13;
<code class="go">    link/ether 9a:a9:24:b7:5a:31 brd ff:ff:ff:ff:ff:ff link-netnsid 1</code>&#13;
<code class="go">    inet6 fe80::98a9:24ff:feb7:5a31/64 scope link</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code></pre>&#13;
&#13;
<p>What this tells us is that we have the normal loopback interface, our real Ethernet interface <code>eth0</code>, and then the Docker bridge interface, <code>docker0</code>, that we described earlier. This is where all the traffic from the Linux containers is picked up to be routed outside the virtual network. The surprising thing in this output is the <code>veth772de2a</code> interface. When Docker creates a container, it creates two virtual interfaces, one of which sits on the server side and is attached to the <code>docker0</code> bridge, and one that is attached to the container’s namespace. What we’re seeing here is the server-side interface. Did you notice how it doesn’t show up as having an IP address assigned to it? That’s because this interface is just joined to the bridge. This interface will have a different name in the container’s namespace as well.</p>&#13;
&#13;
<p>As with so many pieces of Docker, you can replace the proxy with a different implementation. To do so, you would use the <code>--userland-proxy-path=&lt;path&gt;</code> setting, but there are probably not that many good reasons to do this unless you have a very specialized network. However, the <code>--userland-proxy=false</code> flag to <code>dockerd</code> will completely disable the <code>userland-proxy</code> and instead rely on hairpin <a href="https://www.geeksforgeeks.org/network-address-translation-nat">NAT</a> functionality to route traffic between local containers. If you need higher-throughput services, this might be right for you.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>A hairpin NAT is typically used to describe services inside a NATed network that address one another with their public IP addresses. This causes traffic from the source service to route out to the internet, hit the external interface for the NAT router, and then get routed back into the original network to the destination service. The traffic is shaped like the letter U or a standard hairpin.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Host networking" data-type="sect3"><div class="sect3" id="host_networking">&#13;
<h3>Host networking</h3>&#13;
&#13;
<p>As we’ve noted, there is a lot of complexity<a data-primary="host networking" data-type="indexterm" id="ch11-host"/><a data-primary="networking" data-secondary="advanced configuration" data-tertiary="host networking" data-type="indexterm" id="ch11-host2"/> involved in the default implementation. You can, however, run a container without the whole networking configuration that Docker puts in place for you. And the <code>docker-proxy</code> can also limit the throughput for very high-volume data services by requiring all the network traffic to pass through the <code>docker-proxy</code> process before being received by the container. So what does it look like if we turn off the Docker network layer? Since the beginning, Docker has let you do this on a per-container basis with the <code>--net=host</code> command-line switch. There are times, like when you want to run high-throughput applications, when you might want to do this. But you lose some of Docker’s flexibility when you do. Let’s examine how this mechanism works.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Like others we discuss in this chapter, this is not a setting you should take lightly. It has operational and security implications that might be outside your tolerance level. It can be the right thing to do, but you should understand the consequences.</p>&#13;
</div>&#13;
&#13;
<p>Let’s start a container with <code>--net=host</code> and see what happens:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>--net<code class="o">=</code>host<code class="w"> </code>spkane/train-os<code class="w"> </code>bash<code class="w"/>&#13;
&#13;
<code class="gp">[root@docker-desktop /]# </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>--net<code class="o">=</code>host<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">                         </code>spkane/train-os<code class="w"> </code>ip<code class="w"> </code>addr<code class="w"> </code>show<code class="w"/>&#13;
&#13;
<code class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group</code>&#13;
<code class="go">                              default qlen 1000</code>&#13;
<code class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</code>&#13;
<code class="go">    inet 127.0.0.1/8 brd 127.255.255.255 scope host lo</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">    inet6 ::1/128 scope host</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast</code>&#13;
<code class="go">                                           state UP group default qlen 1000</code>&#13;
<code class="go">    link/ether 02:50:00:00:00:01 brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 192.168.65.3/24 brd 192.168.65.255 scope global dynamic</code>&#13;
<code class="go">                                            noprefixroute eth0</code>&#13;
<code class="go">       valid_lft 4282sec preferred_lft 2842sec</code>&#13;
<code class="go">    inet6 fe80::50:ff:fe00:1/64 scope link</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">…</code>&#13;
<code class="go">7: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue</code>&#13;
<code class="go">                                                state DOWN group default</code>&#13;
<code class="go">    link/ether 02:42:9c:d2:89:4f brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">    inet6 fe80::42:9cff:fed2:894f/64 scope link</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">8: br-340323d07310: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc</code>&#13;
<code class="go">                                          noqueue state DOWN group default</code>&#13;
<code class="go">    link/ether 02:42:56:24:42:b8 brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 172.22.0.1/16 brd 172.22.255.255 scope global br-340323d07310</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">11: br-01f7537b9475: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc</code>&#13;
<code class="go">                                           noqueue state DOWN group default</code>&#13;
<code class="go">    link/ether 02:42:ed:14:67:61 brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-01f7537b9475</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">    inet6 fc00:f853:ccd:e793::1/64 scope global</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">    inet6 fe80::42:edff:fe14:6761/64 scope link</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">    inet6 fe80::1/64 scope link</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code></pre>&#13;
&#13;
<p>That should look pretty familiar. That’s because when we run a container with the host networking option, the container is running in both the host server’s network and UTS namespaces. Our server’s hostname is <code>docker-desktop</code>, and from the shell prompt, we can tell that our container has the same hostname:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">[root@docker-desktop /]# </code>hostname<code class="w"/>&#13;
<code class="go">docker-desktop</code></pre>&#13;
&#13;
<p>If we run the <code>mount</code> command to see what’s mounted, though,<a data-primary="mount command" data-secondary="networking" data-type="indexterm" id="idm46803126218416"/><a data-primary="system calls" data-secondary="mount" data-tertiary="networking" data-type="indexterm" id="idm46803126217568"/> we see that Docker is still maintaining our <em>/etc/resolv.conf</em>, <em>/etc/hosts</em>, and <em>/etc/hostname</em> directories. And as expected, the <em>/etc/hostname</em> directory simply contains the server’s hostname:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">[root@docker-desktop /]# </code>mount<code class="w"/>&#13;
&#13;
<code class="go">overlay on / type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/…)</code>&#13;
<code class="go">…</code>&#13;
<code class="go">/dev/vda1 on /etc/resolv.conf type ext4 (rw,relatime)</code>&#13;
<code class="go">/dev/vda1 on /etc/hostname type ext4 (rw,relatime)</code>&#13;
<code class="go">/dev/vda1 on /etc/hosts type ext4 (rw,relatime)</code>&#13;
<code class="go">…</code>&#13;
&#13;
<code class="gp">[root@docker-desktop /]# </code>cat<code class="w"> </code>/etc/hostname<code class="w"/>&#13;
<code class="go">docker-desktop</code></pre>&#13;
&#13;
<p>Just to prove that we can see all the normal networking on the Docker server, let’s look at the output from <code>ss</code> to see if we can see the sockets that Docker is utilizing:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">root@852d18f5c38d:/# </code>ss<code class="w"> </code><code class="p">|</code><code class="w"> </code>grep<code class="w"> </code>docker<code class="w"/>&#13;
&#13;
<code class="go">u_str  ESTAB  0  0  /run/guest-services/docker.sock  18086  * 16860</code>&#13;
<code class="go">…</code>&#13;
<code class="go">u_str  ESTAB  0  0  /var/run/docker.sock             21430  * 21942</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If the Docker daemon was listening on a TCP port, like 2375, you could have looked for that as well. Feel free to look for another TCP port on your server port that you know is in use.</p>&#13;
</div>&#13;
&#13;
<p>If you search for <code>docker</code> in the output of a normal container within its own namespace, you will notice that you get no results:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>spkane/train-os<code class="w"> </code>bash<code class="w"> </code>-c<code class="w"> </code><code class="s2">"ss | grep docker"</code><code class="w"/></pre>&#13;
&#13;
<p>So we are indeed in the server’s network namespace. What all of this means is that if we were to launch a high-throughput network service, we could expect network performance from it that is essentially native. But it also means we could try to bind to ports that would collide with those on the server, so if you do this, you should be careful about how you allocate port assignments.<a data-startref="ch11-host" data-type="indexterm" id="idm46803126081824"/><a data-startref="ch11-host2" data-type="indexterm" id="idm46803126081216"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Configuring networks" data-type="sect3"><div class="sect3" id="idm46803126351664">&#13;
<h3>Configuring networks</h3>&#13;
&#13;
<p>There is more to networking<a data-primary="networking" data-secondary="advanced configuration" data-tertiary="docker network command" data-type="indexterm" id="ch11-docnet"/> than just the default network or host networking, however. The <code>docker network</code> command lets you create multiple networks backed by different drivers. It also allows you to view and manipulate the Docker network layers and how they are attached to containers that are running on the system.</p>&#13;
&#13;
<p>Listing the networks available from Docker’s perspective is easily accomplished with the following command:<a data-primary="docker network" data-primary-sortas="docker-z" data-secondary="ls" data-type="indexterm" id="idm46803126076336"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>network<code class="w"> </code>ls<code class="w"/>&#13;
&#13;
<code class="go">NETWORK ID      NAME      DRIVER    SCOPE</code>&#13;
<code class="go">5840a6c23373    bridge    bridge    local</code>&#13;
<code class="go">1c22b4582189    host      host      local</code>&#13;
<code class="go">c128bfdbe003    none      null      local</code></pre>&#13;
&#13;
<p>You can then find out more details about any individual network by using the <code>docker network inspect</code> command along with the network ID:<a data-primary="docker network" data-primary-sortas="docker-z" data-secondary="inspect" data-type="indexterm" id="idm46803126045600"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>network<code class="w"> </code>inspect<code class="w"> </code>5840a6c23373<code class="w"/></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="json" data-type="programlisting"><code class="p">[</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Name"</code><code class="p">:</code><code class="w"> </code><code class="s2">"bridge"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Id"</code><code class="p">:</code><code class="w"> </code><code class="s2">"5840…fc94"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Created"</code><code class="p">:</code><code class="w"> </code><code class="s2">"2022-09-23T01:21:55.697907958Z"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Scope"</code><code class="p">:</code><code class="w"> </code><code class="s2">"local"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Driver"</code><code class="p">:</code><code class="w"> </code><code class="s2">"bridge"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"EnableIPv6"</code><code class="p">:</code><code class="w"> </code><code class="kc">false</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"IPAM"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"Driver"</code><code class="p">:</code><code class="w"> </code><code class="s2">"default"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"Options"</code><code class="p">:</code><code class="w"> </code><code class="kc">null</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"Config"</code><code class="p">:</code><code class="w"> </code><code class="p">[</code><code class="w"/>&#13;
<code class="w">                </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">                    </code><code class="nt">"Subnet"</code><code class="p">:</code><code class="w"> </code><code class="s2">"172.17.0.0/16"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">                    </code><code class="nt">"Gateway"</code><code class="p">:</code><code class="w"> </code><code class="s2">"172.17.0.1"</code><code class="w"/>&#13;
<code class="w">                </code><code class="p">}</code><code class="w"/>&#13;
<code class="w">            </code><code class="p">]</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">},</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Internal"</code><code class="p">:</code><code class="w"> </code><code class="kc">false</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Attachable"</code><code class="p">:</code><code class="w"> </code><code class="kc">false</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Ingress"</code><code class="p">:</code><code class="w"> </code><code class="kc">false</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"ConfigFrom"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"Network"</code><code class="p">:</code><code class="w"> </code><code class="s2">""</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">},</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"ConfigOnly"</code><code class="p">:</code><code class="w"> </code><code class="kc">false</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Containers"</code><code class="p">:</code><code class="w"> </code><code class="p">{},</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Options"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"com.docker.network.bridge.default_bridge"</code><code class="p">:</code><code class="w"> </code><code class="s2">"true"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"com.docker.network.bridge.enable_icc"</code><code class="p">:</code><code class="w"> </code><code class="s2">"true"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"com.docker.network.bridge.enable_ip_masquerade"</code><code class="p">:</code><code class="w"> </code><code class="s2">"true"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"com.docker.network.bridge.host_binding_ipv4"</code><code class="p">:</code><code class="w"> </code><code class="s2">"0.0.0.0"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"com.docker.network.bridge.name"</code><code class="p">:</code><code class="w"> </code><code class="s2">"docker0"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"com.docker.network.driver.mtu"</code><code class="p">:</code><code class="w"> </code><code class="s2">"1500"</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">},</code><code class="w"/>&#13;
<code class="w">        </code><code class="nt">"Labels"</code><code class="p">:</code><code class="w"> </code><code class="p">{}</code><code class="w"/>&#13;
<code class="w">    </code><code class="p">}</code><code class="w"/>&#13;
<code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>Docker networks can be created and removed, as well as attached and detached from individual containers, with the <code>network</code> subcommand.</p>&#13;
&#13;
<p>So far, we’ve set up a bridged network, no Docker network, and a bridged network with hairpin NAT. There are a few other drivers that you can use to create different topologies using Docker as well, with the <code>overlay</code> and <code>macvlan</code> drivers being the most common. Let’s take a brief look at what these can do for you:</p>&#13;
<dl>&#13;
<dt><code>overlay</code></dt>&#13;
<dd>&#13;
<p>This driver is used in Swarm mode<a data-primary="networking" data-secondary="overlay driver" data-type="indexterm" id="idm46803125775280"/><a data-primary="Docker Swarm mode" data-primary-sortas="docker-a" data-secondary="overlay network driver" data-type="indexterm" id="idm46803125774304"/><a data-primary="scaling" data-secondary="Docker Swarm mode" data-tertiary="overlay network driver" data-type="indexterm" id="idm46803125773088"/> to generate a network overlay between the Docker hosts, creating a private network between all the containers that run on top of the real network. This is useful for Swarm but not in scope for general use with non-Swarm containers.</p>&#13;
</dd>&#13;
<dt><code>macvlan</code></dt>&#13;
<dd>&#13;
<p>This driver creates a real MAC address<a data-primary="networking" data-secondary="macvlan driver" data-type="indexterm" id="idm46803125770336"/> for each of your containers and then exposes them on the network via the interface of your choice. This requires that you switch gears to support more than one MAC address per physical port on the switch. The result is that all the containers appear directly on the underlying network. When you’re moving from a legacy system to a container-native one, this can be a really useful step. There are drawbacks here, such as making it harder when debugging to identify which host the traffic is really coming from, overflowing the MAC tables in your network switches, excessive ARPing by container hosts, and other underlying network issues. For this reason, the <code>macvlan</code> driver is not recommended unless you have a good understanding of your underlying network and can manage it effectively.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>There are a few sets of configurations that are possible here, but the basic setup is easy to configure:<a data-primary="docker network" data-primary-sortas="docker-z" data-secondary="create" data-tertiary="macvlan" data-type="indexterm" id="idm46803125768048"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>network<code class="w"> </code>create<code class="w"> </code>-d<code class="w"> </code>macvlan<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--subnet<code class="o">=</code><code class="m">172</code>.16.16.0/24<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--gateway<code class="o">=</code><code class="m">172</code>.16.16.1<code class="w">  </code><code class="se">\</code>&#13;
<code class="w">    </code>-o<code class="w"> </code><code class="nv">parent</code><code class="o">=</code>eth0<code class="w"> </code>ourvlan<code class="w"/>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>network<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">NETWORK ID     NAME            DRIVER    SCOPE</code>&#13;
<code class="go">5840a6c23373   bridge          bridge    local</code>&#13;
<code class="go">1c22b4582189   host            host      local</code>&#13;
<code class="go">c128bfdbe003   none            null      local</code>&#13;
<code class="go">8218c0ecc9e2   ourvlan         macvlan   local</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>network<code class="w"> </code>rm<code class="w"> </code>8218c0ecc9e2<code class="w"/></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>You can prevent Docker from allocating<a data-primary="docker network" data-primary-sortas="docker-z" data-secondary="--aux-address" data-secondary-sortas="aux-address" data-type="indexterm" id="idm46803125832800"/> specific addresses by specifying them as named auxiliary addresses, <code>--aux-address="my-router=172.16.16.129"</code>.</p>&#13;
</div>&#13;
&#13;
<p>There is a lot more you can configure with the Docker network layer. However, the defaults, host networking, and userland proxyless mode are the ones that you’re most likely to use or encounter in the wild. Some of the other options you can configure include the container’s DNS nameservers, resolver options, and default gateways, among other things. The networking section of the <a href="https://docs.docker.com/network">Docker documentation</a> gives an overview of how to do some of this configuration.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For advanced network configuration of Docker, check out <a href="https://github.com/weaveworks/weave">Weave</a>—a well-supported overlay network tool for spanning containers across multiple Docker hosts, similar to the <code>overlay</code> driver but much more configurable and without the Swarm requirement. Another offering is <a href="https://www.tigera.io/project-calico">Project Calico</a>. If you’re running Kubernetes, which has its own networking configuration, you might also want to familiarize yourself with the <a href="https://www.cni.dev">Container Network Interface (CNI)</a> and then look at <a href="https://cilium.io">Cilium</a>, which provides robust eBPF-based networking for containers.<a data-startref="ch11-advnet" data-type="indexterm" id="idm46803125825088"/><a data-startref="ch11-advnet2" data-type="indexterm" id="idm46803125824384"/><a data-startref="ch11-docnet" data-type="indexterm" id="idm46803125823712"/></p>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Storage" data-type="sect1"><div class="sect1" id="idm46803126411696">&#13;
<h1>Storage</h1>&#13;
&#13;
<p>Backing all of the images and containers<a data-primary="filesystem layers of Linux containers" data-secondary="storage backend for" data-type="indexterm" id="ch11-sb2"/><a data-primary="OCI images" data-secondary="filesystem layers" data-tertiary="storage backend for" data-type="indexterm" id="ch11-sb3"/><a data-primary="Linux containers" data-secondary="filesystem layers" data-tertiary="storage backend for" data-type="indexterm" id="ch11-sb4"/><a data-primary="storage backends for filesystem layers" data-type="indexterm" id="idm46803125652736"/> on your Docker server is a storage backend that handles reading and writing all of that data. Docker has some strenuous requirements on its storage backend: it has to support layering, the mechanism by which Docker tracks changes and reduces both how much disk a container occupies and how much is shipped over the wire to deploy new images. Using a copy-on-write strategy, Docker can start up a new container from an existing image without having to copy the whole image. The storage backend supports that. The storage backend is what makes it possible to export images as groups of changes in layers and also lets you save the state of a running container. In most cases, you need the kernel’s help in doing this efficiently. That’s because the filesystem view in your container is generally a union of all of the layers below it, which are not actually copied into your container. Instead, they are made visible to your container, and only when you make changes does anything get written to your container’s filesystem. One place this layering mechanism is exposed to you is when you upload or download a new image from a registry like Docker Hub. The Docker daemon will push or pull each layer separately, and if some of the layers are the same as others it has already stored, it will use the cached layer instead. In the case of a push to a registry, it will sometimes even tell you which image they are mounted from.</p>&#13;
&#13;
<p>Docker relies on an array of possible kernel drivers to handle the layering. The Docker codebase contains code that can handle interacting with many of these backends, and you can configure the decision about which to use on daemon restart. So let’s look at what is available and some of the pluses and minuses of each.</p>&#13;
&#13;
<p>Various backends have different limitations that may or may not make them your best option. In some cases, your choices of which backend to use are limited by what your distribution of Linux supports. Using the drivers that are built into the kernel shipped with your distribution will always be the easiest approach. It’s generally best to stay close to the well-tested path. We’ve seen all manner of oddities from various backends since Docker’s release. And, as usual, the common case is always the best-supported one. Different backends also report different statistics through the Docker Remote API (<em>/info</em> endpoint). This can be very useful for monitoring your Docker systems. However, not all backends are created equal, so let’s see how they differ:<a data-primary="filesystem layers of Linux containers" data-secondary="storage backend for" data-tertiary="comparing storage backends" data-type="indexterm" id="ch11-storb"/><a data-primary="storage backends for filesystem layers" data-secondary="comparing storage backends" data-type="indexterm" id="ch11-storb2"/></p>&#13;
<dl>&#13;
<dt><em>Overlay</em></dt>&#13;
<dd>&#13;
<p><a href="https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html">Overlay</a> (formerly OverlayFS) is a union<a data-primary="Overlay" data-type="indexterm" id="idm46803125644816"/> filesystem where multiple layers are mounted together so that they appear as a single filesystem. The Overlay filesystem is the most recommended choice for Docker storage these days and works on most major distributions. If you are running on a Linux kernel older than 4.0 (or 3.10.0-693 for RHEL), then you won’t be able to take advantage of this backend. The reliability and performance are good enough that it might be worth updating your OS for Docker hosts to support it, even if your company standard is an older distribution. The Overlay filesystem is part of the mainline Linux kernel and has become increasingly stable over time. Being in the mainline means that long-term support is virtually guaranteed, which is another nice advantage. Docker supports two versions of the Overlay backend, <code>overlay</code> and <code>overlay2</code>. As you might expect, you are strongly advised to use <code>overlay2</code> as it is faster, more efficient with inode usage, and more robust.</p>&#13;
</dd>&#13;
</dl>&#13;
<div class="less_space pagebreak-before" data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The Docker community is frequently improving support for a variety of filesystem backends.<a data-primary="Docker" data-primary-sortas="docker-a" data-secondary="documentation" data-tertiary="filesystem backends" data-type="indexterm" id="idm46803125640944"/><a data-primary="documentation" data-secondary="Docker" data-tertiary="filesystem backends" data-type="indexterm" id="idm46803125639424"/><a data-primary="resources online" data-secondary="Docker documentation" data-tertiary="filesystem backends" data-type="indexterm" id="idm46803125638208"/> For more details about the supported filesystems, take a look at the <a href="https://docs.docker.com/storage/storagedriver">official documentation</a>.</p>&#13;
</div>&#13;
<dl>&#13;
<dt><em>AuFS</em></dt>&#13;
<dd>&#13;
<p>Although at the time of this writing<a data-primary="AuFS" data-type="indexterm" id="idm46803125634016"/> it is no longer recommended, <code>aufs</code> is the original backend for Docker. <a href="https://aufs.sourceforge.net">AuFS (Advanced multilayered unification filesystem)</a> is a union filesystem driver with reasonable support on various popular Linux distributions. It was never accepted into the mainline kernel, however, and this has limited its availability on various distributions. It is not supported on recent versions of Red Hat or Fedora, for example. It is not shipped in the standard Ubuntu distribution but is in the Ubuntu <code>linux-image-extra</code> package.</p>&#13;
&#13;
<p>Its status as a second-class citizen in the kernel has led to the development of many of the other backends now available. If you are running an older distribution that supports AuFS, you might consider it, but you should upgrade to a kernel version that natively supports Overlay or Btrfs, which is discussed next.</p>&#13;
</dd>&#13;
<dt><em>Btrfs</em></dt>&#13;
<dd>&#13;
<p><a href="https://btrfs.wiki.kernel.org/index.php/Main_Page">B-Tree File System (Btrfs)</a> is fundamentally<a data-primary="Btrfs" data-type="indexterm" id="idm46803125628880"/> a copy-on-write filesystem, which means it’s a pretty good fit for the Docker image model. Like <code>aufs</code> and unlike <code>devicemapper</code>, Docker is using the backend in the way it was intended. That means it’s both pretty stable in production and also a good performer. It scales reasonably to thousands of containers on the same system. A drawback for Red Hat–based systems is that Btrfs does not support SELinux. If you can use the <code>btrfs</code> backend, it is worth exploring another option, after the <code>overlay2</code> driver. <a data-primary="mount command" data-secondary="Btrfs backend with loopback-mount" data-type="indexterm" id="idm46803125626160"/><a data-primary="system calls" data-secondary="mount" data-tertiary="Btrfs backend with loopback-mount" data-type="indexterm" id="idm46803125625136"/>One popular way to run <code>btrfs</code> backends for Linux containers without having to give over a whole volume to this filesystem is to make a Btrfs filesystem in a file and loopback-mount it with something like <code>mount -o loop file.btrs /mnt</code>. Using this method, you could build a 50 GB Linux container storage filesystem even on cloud-based systems without having to give over all your precious local storage to Btrfs.</p>&#13;
</dd>&#13;
<dt><em>Device Mapper</em></dt>&#13;
<dd>&#13;
<p>Originally written by Red Hat to support their distributions,<a data-primary="Device Mapper" data-type="indexterm" id="idm46803125621440"/> which lacked AuFS in Docker’s early days, Device Mapper became the default backend on all Red Hat–based distributions of Linux. Depending on the version of Red Hat Linux that you are using, this may be your only option. Device Mapper itself has been built into the Linux kernel for ages and is very stable. The way the Docker daemon uses it is a bit unconventional, though, and in the past, this backend was not that stable. This checkered past means that we recommend picking a different backend when possible. If your distribution supports only the <code>devicemapper</code> driver, then you will likely be fine. But it’s worth considering using <code>overlay2</code> or <code>btrfs</code>. By default, <code>devicemapper</code> utilizes the <code>loop-lvm</code> mode, which has zero configuration and is very slow and generally only useful for development. If you decide to use the <code>devicemapper</code> driver, you must make sure it is configured to use <code>direct-lvm</code> mode for all nondevelopment environments.</p>&#13;
</dd>&#13;
</dl>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>You can find out more about using the various <code>devicemapper</code> modes with Docker in the <a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver">official documentation</a>.&#13;
A 2014 <a href="https://developers.redhat.com/blog/2014/09/30/overview-storage-scalability-docker">blog article</a> also provides some interesting history about the various Docker storage backends.</p>&#13;
</div>&#13;
<dl>&#13;
<dt><em>VFS</em></dt>&#13;
<dd>&#13;
<p>Of the supported drivers,<a data-primary="VFS (Virtual File System)" data-type="indexterm" id="idm46803125612624"/> the Virtual File System (<code>vfs</code>) driver is the simplest, and slowest, to start up. It doesn’t actually support copy-on-write. Instead, it makes a new directory and copies over all of the existing data. It was originally intended for use in tests and for mounting host volumes. The <code>vfs</code> driver is very slow to create new containers, but runtime performance is native, which is a real benefit. Its mechanism is very simple, which means there is less to go wrong. Docker, Inc., does not recommend it for production use, so proceed with caution if you think it’s the right solution for your production environment.</p>&#13;
</dd>&#13;
<dt><em>ZFS</em></dt>&#13;
<dd>&#13;
<p>ZFS, which was created<a data-primary="ZFS" data-type="indexterm" id="idm46803125609488"/> by Sun Microsystems, is the most advanced open source filesystem available on Linux. Due to licensing restrictions, it does not ship in mainline Linux. However, the <a href="https://zfsonlinux.org">ZFS on Linux project</a> has made it pretty easy to install. Docker can then run on top of the ZFS filesystem and use its advanced copy-on-write facilities to implement layering. Given that ZFS is not in the mainline kernel and not available off the shelf in the major commercial distributions, going this route requires some extended effort. However, if you are already running ZFS in production, this may be your very best option.</p>&#13;
</dd>&#13;
</dl>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Storage backends can have a big impact on the performance of your containers. And if you swap the backend on your Docker server, all of your existing images will disappear. They are not gone, but they will not be visible until you switch the driver back. Caution is advised.<a data-startref="ch11-storb" data-type="indexterm" id="idm46803125606704"/><a data-startref="ch11-storb2" data-type="indexterm" id="idm46803125606000"/><a data-startref="ch11-sb2" data-type="indexterm" id="idm46803125605328"/><a data-startref="ch11-sb3" data-type="indexterm" id="idm46803125604656"/><a data-startref="ch11-sb4" data-type="indexterm" id="idm46803125603984"/></p>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before">You can use <code>docker system info</code> to see which storage backend your system is running:<a data-primary="docker system" data-primary-sortas="docker-z" data-secondary="info" data-tertiary="storage backend system" data-type="indexterm" id="idm46803125602016"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>system<code class="w"> </code>info<code class="w"/></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">…</code><code class="w"/>&#13;
<code class="w"> </code><code class="l-Scalar-Plain">Storage Driver</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">overlay2</code><code class="w"/>&#13;
<code class="w">  </code><code class="l-Scalar-Plain">Backing Filesystem</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">extfs</code><code class="w"/>&#13;
<code class="w">  </code><code class="l-Scalar-Plain">Supports d_type</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">true</code><code class="w"/>&#13;
<code class="w">  </code><code class="l-Scalar-Plain">Native Overlay Diff</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">true</code><code class="w"/>&#13;
<code class="w">  </code><code class="l-Scalar-Plain">userxattr</code><code class="p-Indicator">:</code><code class="w"> </code><code class="l-Scalar-Plain">false</code><code class="w"/>&#13;
<code class="l-Scalar-Plain">…</code><code class="w"/></pre>&#13;
&#13;
<p>As you can see, Docker will also tell you what the underlying or “backing” filesystem is if there is one. Since we’re running <code>overlay2</code> here, we can see it’s backed by an <code>ext</code> filesystem. In some cases, like with <code>devicemapper</code> on raw partitions or with <code>btrfs</code>, there won’t be a different underlying filesystem.</p>&#13;
&#13;
<p>Storage backends can be swapped via the <code>daemon-json</code> configuration file or via command-line arguments to <code>dockerd</code> on startup. If we wanted to switch our Ubuntu system from <code>aufs</code> to <code>devicemapper</code>, we could do so like this:<a data-primary="dockerd" data-primary-sortas="docker-z" data-secondary="--storage-driver" data-secondary-sortas="storage-driver" data-type="indexterm" id="idm46803125499616"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>dockerd<code class="w"> </code>--storage-driver<code class="o">=</code>devicemapper<code class="w"/></pre>&#13;
&#13;
<p>That will work on pretty much any Linux system that can support Docker because <code>devicemapper</code> is almost always present. The same is true for <code>overlay2</code> on modern Linux kernels. However, you will need to have the actual underlying dependencies in place for the other drivers. For example, without <code>aufs</code> in the kernel—​usually via a kernel module—​Docker will not start up with <code>aufs</code> set as the storage driver, and the same is true for Btrfs or ZFS.</p>&#13;
&#13;
<p>Getting the appropriate storage driver for your systems and deployment needs is one of the more important technical points to get right when you’re taking Docker to production. Be conservative: make sure the path you choose is well supported in your kernel and distribution. Historically, this was a pain point, but most of the drivers have reached reasonable maturity. Remain cautious for any newly appearing backends, however, as this space continues to change. Getting new backend drivers to work reliably for production systems takes quite some time, in our experience.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="nsenter" data-type="sect1"><div class="sect1" id="nsenter">&#13;
<h1>nsenter</h1>&#13;
&#13;
<p><code>nsenter</code>, which is short<a data-primary="nsenter for Docker server access" data-type="indexterm" id="idm46803125554112"/> for “namespace enter,” allows you to enter any Linux namespace and is part of the core <code>util-linux</code> package from <a href="https://mirrors.edge.kernel.org/pub/linux/utils/util-linux">kernel.org</a>. Using <code>nsenter</code>, we can get into a Linux container from the server itself, even in situations where the <code>dockerd</code> server is not responding and we can’t use <code>docker container exec</code>. It can also be used to manipulate things in a container as <code>root</code> on the server that would otherwise be prevented by <code>docker container exec</code>. This can be truly useful when you are debugging. Most of the time, <code>docker container exec</code> is all you need, but you should have <code>nsenter</code> in your tool belt.</p>&#13;
&#13;
<p>Most Linux distributions ship with a new-enough <code>util-linux</code> package that it will contain <code>nsenter</code>. If you are on a distribution that does not have it, the easiest way to get hold of <code>nsenter</code> is to install it via the third-party <a href="https://github.com/jpetazzo/nsenter">Linux container</a>.</p>&#13;
&#13;
<p>This container works by pulling a Docker image from the Docker Hub registry and then running a Linux container that will install the <code>nsenter</code> command-line tool into <em>/usr/local/bin</em>. This might seem strange at first, but it’s a clever way to allow you to install <code>nsenter</code> to any Docker server remotely using nothing more than the <code>docker</code> command.</p>&#13;
&#13;
<p>Unlike <code>docker container exec</code>, which can be run remotely, <code>nsenter</code> requires that you run it on the server itself, directly or via a container. For our purposes, we’ll use a specially crafted container to run <code>nsenter</code>. As with the <code>docker container exec</code> example, we need to have a container running:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-d<code class="w"> </code>--rm<code class="w">  </code>ubuntu:22.04<code class="w"> </code>sleep<code class="w"> </code><code class="m">600</code><code class="w"/>&#13;
<code class="go">fd521174d66dc32650d165e0ce7dd97255c7b3624c34cb1d119d955284382ddf</code></pre>&#13;
&#13;
<p><code>docker container exec</code> is pretty simple, but <code>nsenter</code> is a little inconvenient to use. It needs to have the PID of the actual top-level process in your container, which is not obvious to find. Let’s go ahead and run <code>nsenter</code> by hand so you can see what’s going on.</p>&#13;
&#13;
<p>First, we need to find out the ID of the running container, because <code>nsenter</code> needs to know that to access it. We can easily get this using <code>docker container ls</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
&#13;
<code class="go">CONTAINER ID  IMAGE          COMMAND      …  NAMES</code>&#13;
<code class="go">fd521174d66d   ubuntu:22.04  "sleep 1000" …  angry_albattani</code></pre>&#13;
&#13;
<p>The ID we want is that first field, <code>fd521174d66d</code>. With that, we can now find the PID we need, like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>inspect<code class="w"> </code>--format<code class="w"> </code><code class="se">\{</code><code class="o">{</code>.State.Pid<code class="se">\}</code><code class="o">}</code><code class="w"> </code>fd521174d66d<code class="w"/>&#13;
<code class="go">2721</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>You can also get the real PIDs of the processes in your container by running the command <code>docker container top</code>, followed by the container ID. In our example, this would look like the following:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>top<code class="w"> </code>fd521174d66d<code class="w"/>&#13;
&#13;
<code class="go">UID   PID   PPID  C  STIME  TTY  TIME      CMD</code>&#13;
<code class="go">root  2721  2696  0  20:37  ?    00:00:00  sleep 600</code></pre>&#13;
</div>&#13;
&#13;
<p>Make sure to update the <code>--target</code> argument in the following command with the process ID that you got from the previous command, then go ahead and invoke <code>nsenter</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>--privileged<code class="w"> </code>--pid<code class="o">=</code>host<code class="w"> </code>debian<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>nsenter<code class="w"> </code>--target<code class="w"> </code><code class="m">2721</code><code class="w"> </code>--all<code class="w"/>&#13;
&#13;
<code class="gp"># </code>ps<code class="w"> </code>-ef<code class="w"/>&#13;
&#13;
<code class="go">UID        PID  PPID  C STIME TTY          TIME CMD</code>&#13;
<code class="go">root         1     0  0 20:37 ?        00:00:00 sleep 600</code>&#13;
<code class="go">root        11     0  0 20:51 ?        00:00:00 -sh</code>&#13;
<code class="go">root        15    11  0 20:51 ?        00:00:00 ps -ef</code>&#13;
<code class="gp"># </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>If the result looks a lot like <code>docker container exec</code>, that’s because it does almost the same thing under the hood!</p>&#13;
&#13;
<p>The command-line argument <code>--all</code> is telling <code>nsenter</code> that we want to enter all of the namespaces used by the process specified with <code>--target</code>.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Debugging Shell-less Containers" data-type="sect2"><div class="sect2" id="shellless">&#13;
<h2>Debugging Shell-less Containers</h2>&#13;
&#13;
<p>If you want to troubleshoot a container<a data-primary="debugging" data-secondary="shell-less containers" data-type="indexterm" id="ch11-less"/><a data-primary="Linux containers" data-secondary="shell-less" data-type="indexterm" id="ch11-less2"/><a data-primary="shell-less containers" data-type="indexterm" id="ch11-less3"/> that does not have a Unix shell, then things get a little trickier, but it is still possible. For this example, we can run a container that has a single executable in it:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code>--name<code class="w"> </code>outyet-small<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--publish<code class="w"> </code><code class="nv">mode</code><code class="o">=</code>ingress,published<code class="o">=</code><code class="m">8090</code>,target<code class="o">=</code><code class="m">8080</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>spkane/outyet:1.9.4-small<code class="w"/>&#13;
<code class="go">4f6de24d4c9c794c884afa758ef5b33ea38c01f8ec9314dcddd9fadc25c1a443</code></pre>&#13;
&#13;
<p>Let’s take a quick look at the processes that are running in this container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>top<code class="w"> </code>outyet-small<code class="w"/>&#13;
&#13;
<code class="go">UID  PID   PPID  C STIME TTY TIME     CMD</code>&#13;
<code class="go">root 61033 61008 0 22:43 ?   00:00:00 /outyet -version 1.9.4 -poll 600s …</code></pre>&#13;
&#13;
<p>If you try to launch a Unix shell in the container, you will get an error:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code><code class="nb">exec</code><code class="w"> </code>-it<code class="w"> </code>outyet-small<code class="w"> </code>/bin/sh<code class="w"/>&#13;
&#13;
<code class="go">OCI runtime exec failed: exec failed: unable to start container process: exec:</code>&#13;
<code class="go">  "/bin/sh": stat /bin/sh: no such file or directory: unknown</code></pre>&#13;
&#13;
<p>We can then launch a second container that includes a shell and some other useful tools in a way that the new container can see the processes in the first container, is using the same network stack as the first container, and has some extra privileges which will be helpful for our debugging:<a data-primary="Linux" data-secondary="capabilities" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="idm46803125178496"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="idm46803125177136"/><a data-primary="Linux" data-secondary="capabilities" data-tertiary="SYS_PTRACE" data-type="indexterm" id="idm46803125175376"/><a data-primary="Linux" data-secondary="capabilities" data-tertiary="SYS_ADMIN" data-type="indexterm" id="idm46803125174160"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="--cap-add" data-tertiary-sortas="cap-add" data-type="indexterm" id="idm46803125172944"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="SYS_ADMIN" data-type="indexterm" id="idm46803125171456"/><a data-primary="security" data-secondary="Linux capabilities" data-tertiary="SYS_PTRACE" data-type="indexterm" id="idm46803125149984"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>--pid<code class="o">=</code>container:outyet-small<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--net<code class="o">=</code>container:outyet-small<code class="w"> </code>--cap-add<code class="w"> </code>sys_ptrace<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--cap-add<code class="w"> </code>sys_admin<code class="w"> </code>spkane/train-os<code class="w"> </code>/bin/sh<code class="w"/>&#13;
&#13;
<code class="gp">sh-5.1#</code></pre>&#13;
&#13;
<p>If you type <code>ls</code> in this container, you will see in the filesystem the <code>spkane/train-os</code> image, which contains <code>/bin/sh</code> and all of our debugging tools, but it does not contain any of the files from our <code>outyet-small</code> container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">sh-5.1# </code>ls<code class="w"/>&#13;
&#13;
<code class="go">bin   dev  home  lib64       media  opt   root  sbin  sys  usr</code>&#13;
<code class="go">boot  etc  lib   lost+found  mnt    proc  run   srv   tmp  var</code></pre>&#13;
&#13;
<p>However, if you type <code>ps -ef</code>, you will notice that you see all of the processes from the original container. This is because we told Docker to attach to use the namespace from the <code>outyet-small</code> container by passing in <code>--pid=container:outyet-small</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">sh-5.1# </code>ps<code class="w"> </code>-ef<code class="w"/>&#13;
&#13;
<code class="go">UID  PID PPID C STIME TTY   TIME     CMD</code>&#13;
<code class="go">root   1    0 0 22:43 ?     00:00:00 /outyet -version 1.9.4 -poll 600s …</code>&#13;
<code class="go">root  29    0 0 22:47 pts/0 00:00:00 /bin/sh</code>&#13;
<code class="go">root  36   29 0 22:49 pts/0 00:00:00 ps -ef</code></pre>&#13;
&#13;
<p>And because we are using the same network stack, you can even <code>curl</code> the port that the <code>outyet</code> service from the first container is bound to:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">sh-5.1# </code>curl<code class="w"> </code>localhost:8080<code class="w"/></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="html" data-type="programlisting"><code class="cp">&lt;!DOCTYPE html&gt;</code><code class="p">&lt;</code><code class="nt">html</code><code class="p">&gt;&lt;</code><code class="nt">body</code><code class="p">&gt;&lt;</code><code class="nt">center</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">h2</code><code class="p">&gt;</code>Is Go 1.9.4 out yet?<code class="p">&lt;/</code><code class="nt">h2</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">h1</code><code class="p">&gt;</code>&#13;
&#13;
    <code class="p">&lt;</code><code class="nt">a</code> <code class="na">href</code><code class="o">=</code><code class="s">"https://go.googlesource.com/go/&amp;#43;/go1.9.4"</code><code class="p">&gt;</code>YES!<code class="p">&lt;/</code><code class="nt">a</code><code class="p">&gt;</code>&#13;
&#13;
  <code class="p">&lt;/</code><code class="nt">h1</code><code class="p">&gt;</code>&#13;
  <code class="p">&lt;</code><code class="nt">p</code><code class="p">&gt;</code>Hostname: 155914f7c6cd<code class="p">&lt;/</code><code class="nt">p</code><code class="p">&gt;</code>&#13;
<code class="p">&lt;/</code><code class="nt">center</code><code class="p">&gt;&lt;/</code><code class="nt">body</code><code class="p">&gt;&lt;/</code><code class="nt">html</code><code class="p">&gt;</code></pre>&#13;
&#13;
<p>At this point, you could use <code>strace</code> or whatever else you wanted to debug your application, and then finally <code>exit</code> the new debug container, leaving your original container still running on the server.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>If you run <code>strace</code>, you will need to type Ctrl-C to exit the <code>strace</code> process.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">sh-5.1# </code>strace<code class="w"> </code>-p<code class="w"> </code><code class="m">1</code><code class="w"/>&#13;
&#13;
<code class="go">strace: Process 1 attached</code>&#13;
<code class="go">futex(0x963698, FUTEX_WAIT, 0, NULL^Cstrace: Process 1 detached</code>&#13;
<code class="go"> &lt;detached …&gt;</code>&#13;
&#13;
<code class="gp">sh-5.1# </code><code class="nb">exit</code><code class="w"/>&#13;
<code class="go">exit</code></pre>&#13;
&#13;
<p>You’ll notice that we could not see the filesystem in this use case. If you need to view or copy files from the container, you can make use of the <code>docker container export</code> command to retrieve a tarball of the container’s filesystem:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code><code class="nb">export</code><code class="w"> </code>outyet-small<code class="w"> </code>-o<code class="w"> </code>export.tar<code class="w"/></pre>&#13;
&#13;
<p>You can then use <code>tar</code> to view or extract the files:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>tar<code class="w"> </code>-tvf<code class="w"> </code>export.tar<code class="w"/>&#13;
&#13;
<code class="go">-rwxr-xr-x  0 0   0         0 Jul 17 16:04 .dockerenv</code>&#13;
<code class="go">drwxr-xr-x  0 0   0         0 Jul 17 16:04 dev/</code>&#13;
<code class="go">-rwxr-xr-x  0 0   0         0 Jul 17 16:04 dev/console</code>&#13;
<code class="go">drwxr-xr-x  0 0   0         0 Jul 17 16:04 dev/pts/</code>&#13;
<code class="go">drwxr-xr-x  0 0   0         0 Jul 17 16:04 dev/shm/</code>&#13;
<code class="go">drwxr-xr-x  0 0   0         0 Jul 17 16:04 etc/</code>&#13;
<code class="go">-rwxr-xr-x  0 0   0         0 Jul 17 16:04 etc/hostname</code>&#13;
<code class="go">-rwxr-xr-x  0 0   0         0 Jul 17 16:04 etc/hosts</code>&#13;
<code class="go">lrwxrwxrwx  0 0   0         0 Jul 17 16:04 etc/mtab -&gt; /proc/mounts</code>&#13;
<code class="go">-rwxr-xr-x  0 0   0         0 Jul 17 16:04 etc/resolv.conf</code>&#13;
<code class="go">drwxr-xr-x  0 0   0         0 Apr 24  2021 etc/ssl/</code>&#13;
<code class="go">drwxr-xr-x  0 0   0         0 Apr 24  2021 etc/ssl/certs/</code>&#13;
<code class="go">-rw-r--r--  0 0   0    261407 Mar 13  2018 etc/ssl/certs/ca-certificates.crt</code>&#13;
<code class="go">-rwxr-xr-x  0 0   0   5640640 Apr 24  2021 outyet</code>&#13;
<code class="go">drwxr-xr-x  0 0   0         0 Jul 17 16:04 proc/</code>&#13;
<code class="go">drwxr-xr-x  0 0   0         0 Jul 17 16:04 sys/</code></pre>&#13;
&#13;
<p>When you are finished, go ahead and delete <code>export.tar</code>, and then stop the <code>outyet-small</code> container with <code>docker container stop outyet-small</code>.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>You can explore the container’s filesystem from the Docker server by navigating directly to where the filesystem resides on the server’s storage system. This will typically look something like <em>/var/lib/docker/overlay/fd5…</em> but will vary based on the Docker setup, storage backend, and container hash. You can determine your Docker root directory by running <code>docker system info</code>.</p>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="The Structure of Docker" data-type="sect1"><div class="sect1" id="idm46803125558960">&#13;
<h1>The Structure of Docker</h1>&#13;
&#13;
<p>What we think of as Docker is made<a data-primary="Docker" data-primary-sortas="docker-a" data-secondary="structure of Docker" data-type="indexterm" id="ch11-stru"/><a data-primary="architecture of Docker" data-secondary="structure of Docker" data-type="indexterm" id="ch11-stru2"/> of five major server-side components that present a common front via the API. These parts are <code>dockerd</code>, <code>containerd</code>, <code>runc</code>, <code>containerd-shim-runc-v2</code>, and the <code>docker-proxy</code> we described in <a data-type="xref" href="#docker_net">“Networking”</a>. We’ve spent a lot of time interacting with <code>dockerd</code> and the API it presents. It is, in fact, responsible for orchestrating the whole set of components that make up Docker. But when it starts a container, Docker relies on <code>containerd</code> to handle instantiating the container. All of this used to be handled in the <code>dockerd</code> process itself, but there were several shortcomings to that design:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><code>dockerd</code> had a huge number of jobs.</p>&#13;
</li>&#13;
<li>&#13;
<p>A monolithic runtime prevented any of the components from being swapped out easily.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>dockerd</code> had to supervise the lifecycle of the containers themselves, and it couldn’t be restarted or upgraded without losing all the running containers.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Another major motivation for <code>containerd</code> was that, as we’ve just shown, containers are not just a single abstraction. On the Linux platform, they are processes involving namespaces, cgroups, and security rules in AppArmor or SELinux. But Docker also runs on Windows and may even work on other platforms in the future. <a data-primary="system calls" data-secondary="structure of Docker" data-type="indexterm" id="idm46803124836448"/>The idea of <code>containerd</code> is to present a standard layer to the outside world where, regardless of implementation, developers can think about the higher-level concepts of containers, tasks, and snapshots rather than worry about specific Linux system calls. This simplifies the Docker daemon a lot and enables platforms like Kubernetes to integrate directly into <code>containerd</code> rather than using the Docker API. Kubernetes relied on a Docker shim for many years, but nowadays it uses <code>containerd</code> directly.</p>&#13;
&#13;
<p>Let’s take a look at the components (shown in <a data-type="xref" href="#figure11-2">Figure 11-2</a>) and see what each of them does:</p>&#13;
<dl>&#13;
<dt><code>dockerd</code></dt>&#13;
<dd>&#13;
<p>One per server. Serves the API, builds container images, and does high-level network management, including volumes, logging, statistics reporting, and more.</p>&#13;
</dd>&#13;
<dt><code>docker-proxy</code></dt>&#13;
<dd>&#13;
<p>One per port forwarding rule. Each instance handles the forwarding of the defined protocol traffic (TCP/UDP) from the defined host IP and port to the defined container IP and port.</p>&#13;
</dd>&#13;
<dt><code>containerd</code></dt>&#13;
<dd>&#13;
<p>One per server. Manages the lifecycle, execution, copy-on-write filesystem, and low-level networking drivers.</p>&#13;
</dd>&#13;
<dt><code>containerd-shim-runc-v2</code></dt>&#13;
<dd>&#13;
<p>One per container. Handles file descriptors passed to the container (e.g., <code>stdin</code>/<code>out</code>) and reports exit status.</p>&#13;
</dd>&#13;
<dt><code>runc</code></dt>&#13;
<dd>&#13;
<p>Constructs the container and executes it, gathers statistics, and reports events on the lifecycle.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="figure11-2">&#13;
<img alt="Structure of Docker" src="assets/dur3_1102.png"/>&#13;
<h6><span class="label">Figure 11-2. </span>Structure of Docker</h6>&#13;
</div></figure>&#13;
&#13;
<p><code>dockerd</code> and <code>containerd</code> speak to each other over a socket, usually a Unix socket, using a <a href="https://grpc.io">gRPC API</a>. <code>dockerd</code> is the client in this case, and <code>containerd</code> is the server! <code>runc</code> is a CLI tool that reads configuration from JSON on disk and is executed by <code>containerd</code>.</p>&#13;
&#13;
<p>When we start a new container, <code>dockerd</code> will handle making sure that the image is present or will pull it from the repository specified in the image name. (In the future, this responsibility may shift to <code>containerd</code>, which already supports image pulls.) The Docker daemon also does most of the rest of the setup around the container, like launching <code>docker-proxy</code> to set up port forwarding. It then talks to <code>containerd</code> and asks it to run the container. <code>containerd</code> will take the image and apply the container configuration passed in from <code>dockerd</code> to generate an <a href="https://www.opencontainers.org">OCI bundle</a> that <code>runc</code> can execute.<sup><a data-type="noteref" href="ch11.html#idm46803124791184" id="idm46803124791184-marker">1</a></sup> It will then execute <code>containerd-shim-runc-v2</code> to start the container. This will in turn execute <code>runc</code> to construct and start the container. However, <code>runc</code> will not stay running, and the <code>containerd-shim-runc-v2</code> will be the actual parent process of the new container process.</p>&#13;
&#13;
<p>If we launch a container and then look at the output of <code>ps axlf</code> on the Docker server, we can see the parent/child relationship between the various processes. PID 1 is <code>/sbin/init</code> and is the parent process for <code>containerd</code>, <code>dockerd</code>, and the <code>containerd-shim-runc-v2</code>.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Docker Desktop’s VM contains minimal versions of most Linux tools, and some of these commands may not produce the same output that you will get if you use a standard Linux server as the Docker daemon host.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--publish<code class="w"> </code><code class="nv">mode</code><code class="o">=</code>ingress,published<code class="o">=</code><code class="m">8080</code>,target<code class="o">=</code><code class="m">80</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--name<code class="w"> </code>nginx-test<code class="w"> </code>--rm<code class="w"> </code>nginx:latest<code class="w"/>&#13;
<code class="go">08b5cffed7baaf32b3af50498f7e5c5fa7ed35e094fa6045c205a88746fe53dd</code>&#13;
&#13;
<code class="gp">$ </code>ps<code class="w"> </code>axlf<code class="w"/>&#13;
<code class="go">… PID  PPID COMMAND</code>&#13;
<code class="go">…</code>&#13;
<code class="go">… 5171 1    /usr/bin/containerd</code>&#13;
<code class="go">… 5288 1    /usr/bin/dockerd -H fd:// --containerd=/run/cont…/containerd.…</code>&#13;
<code class="go">… 5784 5288 \_ /usr/bin/docker-proxy -proto tcp -host-ip … -host-port 8080</code>&#13;
<code class="go">… 5791 5288 \_ /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port …</code>&#13;
<code class="go">… 5807 1    /usr/bin/containerd-shim-runc-v2 -namespace moby -id …</code>&#13;
<code class="go">… 5829 5807  \_ nginx: master process nginx -g daemon off;</code>&#13;
<code class="go">… 5880 5829      \_ nginx: worker process</code>&#13;
<code class="go">… 5881 5829      \_ nginx: worker process</code>&#13;
<code class="go">… 5882 5829      \_ nginx: worker process</code>&#13;
<code class="go">… 5883 5829      \_ nginx: worker process</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>So what happened to <code>runc</code>? Its job is to construct the container and start it running, then it leaves and its children are inherited by its parent, the <code>containerd-shim-runc-v2</code>. This leaves the minimal amount of code in memory necessary to manage the file descriptors and exit status for <code>containerd</code>.</p>&#13;
&#13;
<p>To help you understand what’s going on here, let’s take a deeper look at what happens when we start a container. We’ll just reuse the <code>nginx</code> container that we already have running for this since it’s very lightweight and the container stays running when backgrounded:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
&#13;
<code class="go">CONTAINER ID IMAGE        COMMAND        … PORTS                  NAMES</code>&#13;
<code class="go">08b5cffed7ba nginx:latest "/docker-ent…" … 0.0.0.0:8080-&gt;80/tcp … nginx-test</code></pre>&#13;
&#13;
<p>Let’s use the <code>runc</code> runtime CLI tool to take a look at its view of the system. We could see a similar view from <code>ctr</code>, the CLI client for <code>containerd</code>, but <code>runc</code> is nicer to work with, and it’s at the lowest level:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>sudo<code class="w"> </code>runc<code class="w"> </code>--root<code class="w"> </code>/run/docker/runtime-runc/moby<code class="w"> </code>list<code class="w"/>&#13;
&#13;
<code class="go">ID         PID   …  BUNDLE                                          … OWNER</code>&#13;
<code class="go">08b5…53dd  5829  …  …/io.containerd.runtime.v2.task/moby/08b5…53dd  … root</code></pre>&#13;
&#13;
<p>We normally need root privileges to run this command. Unlike with the Docker CLI, we can’t rely on the Docker daemon’s permissions to let us access lower-level functionality. With <code>runc</code> we need direct access to these privileges. What we can see in the output from <code>runc</code> is our container! This is the actual OCI runtime bundle that represents our container, with which it shares an ID. Notice that it also gives us the PID of the container; that’s the PID on the host of the application running inside the container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>ps<code class="w"> </code>-edaf<code class="w"> </code><code class="p">|</code><code class="w"> </code>grep<code class="w"> </code><code class="m">5829</code><code class="w"/>&#13;
&#13;
<code class="go">root      5829  5807  …  nginx: master process nginx -g daemon off;</code>&#13;
<code class="go">systemd+  5880  5829  …  nginx: worker process</code>&#13;
<code class="go">systemd+  5881  5829  …  nginx: worker process</code>&#13;
<code class="go">systemd+  5882  5829  …  nginx: worker process</code>&#13;
<code class="go">systemd+  5883  5829  …  nginx: worker process</code></pre>&#13;
&#13;
<p>If we look in the bundle, we’ll see a set of named pipes for our container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>sudo<code class="w"> </code>ls<code class="w"> </code>-la<code class="w"> </code>/run/docker/containerd/08b5…53dd<code class="w"/>&#13;
&#13;
<code class="go">total 0</code>&#13;
<code class="go">drwxr-xr-x 2 root root 80 Oct  1 08:49 .</code>&#13;
<code class="go">drwxr-xr-x 3 root root 60 Oct  1 08:49 ..</code>&#13;
<code class="go">prwx------ 1 root root  0 Oct  1 08:49 init-stderr</code>&#13;
<code class="go">prwx------ 1 root root  0 Oct  1 08:49 init-stdout</code></pre>&#13;
&#13;
<p>You can find a lot of additional files related to your container underneath <em>/run/containerd/io.containerd.runtime.v2.task/moby</em>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>sudo<code class="w"> </code>ls<code class="w"> </code>-la<code class="w"> </code>/run/containerd/io.containerd.runtime.v2.task/moby/08b5…53dd/<code class="w"/>&#13;
&#13;
<code class="go">total 32</code>&#13;
<code class="go">drwx------ 3 root root  240 Oct  1 08:49 .</code>&#13;
<code class="go">drwx--x--x 3 root root   60 Oct  1 08:49 ..</code>&#13;
<code class="go">-rw-r--r-- 1 root root   89 Oct  1 08:49 address</code>&#13;
<code class="go">-rw-r--r-- 1 root root 9198 Oct  1 08:49 config.json</code>&#13;
<code class="go">-rw-r--r-- 1 root root    4 Oct  1 08:49 init.pid</code>&#13;
<code class="go">prwx------ 1 root root    0 Oct  1 08:49 log</code>&#13;
<code class="go">-rw-r--r-- 1 root root    0 Oct  1 08:49 log.json</code>&#13;
<code class="go">-rw------- 1 root root   82 Oct  1 08:49 options.json</code>&#13;
<code class="go">drwx--x--x 2 root root   40 Oct  1 08:49 rootfs</code>&#13;
<code class="go">-rw------- 1 root root    4 Oct  1 08:49 runtime</code>&#13;
<code class="go">-rw------- 1 root root   32 Oct  1 08:49 shim-binary-path</code>&#13;
<code class="go">lrwxrwxrwx 1 root root  119 Oct  1 08:49 work -&gt; /var/lib/containerd/io…</code></pre>&#13;
&#13;
<p>The <em>config.json</em> file is a very verbose equivalent of what Docker shows in <code>docker container inspect</code>. We are not going to reproduce it here due to size, but we encourage you to dig around and see what’s in the config. You may, for example, note all the entries for the <a data-type="xref" href="#seccomp">“Secure Computing Mode”</a> that are present in it.</p>&#13;
&#13;
<p>If you want to explore <code>runc</code> some more, you can experiment with the CLI tool. Most of this is already available in Docker, usually on a higher and more useful level than the one available in <code>runc</code>. But it can be useful to explore so that you can better understand how containers and the Docker stack are put together. It’s also interesting to watch the events that <code>runc</code> reports about a running container. We can hook into those with the <code>runc events</code> command. During the normal operations of a running container, there is not a lot of activity in the events stream. But <code>runc</code> regularly reports runtime statistics, which we can see in JSON format:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>sudo<code class="w"> </code>runc<code class="w"> </code>--root<code class="w"> </code>/run/docker/runtime-runc/moby<code class="w"> </code>events<code class="w"> </code>08b5…53dd<code class="w"/></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="json" data-type="programlisting"><code class="p">{</code><code class="nt">"type"</code><code class="p">:</code><code class="s2">"stats"</code><code class="p">,</code><code class="nt">"id"</code><code class="p">:</code><code class="s2">"08b5…53dd"</code><code class="p">,</code><code class="nt">"data"</code><code class="p">:{</code><code class="nt">"cpu"</code><code class="p">:{</code><code class="nt">"usage"</code><code class="p">:{</code><code class="s2">"…"</code><code class="p">}}}}</code><code class="w"/></pre>&#13;
&#13;
<p>To conserve space, we have removed much of the output from the previous command, but this might look familiar to you now that we’ve spent some time looking at <code>docker container stats</code>. Guess where Docker gets those statistics by default. That’s right, <code>runc</code>.</p>&#13;
&#13;
<p>At this point, you can go ahead and stop the example container by running <code>docker container stop nginx-test</code>.<a data-startref="ch11-stru" data-type="indexterm" id="idm46803124440960"/><a data-startref="ch11-stru2" data-type="indexterm" id="idm46803124440288"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Swapping Runtimes" data-type="sect1"><div class="sect1" id="swapping_runtimes">&#13;
<h1>Swapping Runtimes</h1>&#13;
&#13;
<p>As we mentioned in <a data-type="xref" href="ch02.html#docker_glance">Chapter 2</a>, there are a few other native<a data-primary="runtimes" data-secondary="swapping" data-type="indexterm" id="ch11-rtsw"/> OCI-compliant runtimes that can be substituted in place of <code>runc</code>. As an example, there is <a href="https://github.com/containers/crun">crun</a>, which describes itself as “a fast and low-memory footprint OCI Container Runtime fully written in C.” Some other alternative native runtimes, like <code>railcar</code> and <code>rkt</code>, have been deprecated and largely abandoned. In the next section, we’ll talk about a sandboxed runtime from Google, called <a href="https://gvisor.dev">gVisor</a>, which provides a user space runtime for untrusted code.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p><a href="https://github.com/kata-containers">Kata Containers</a> is a very interesting open source project that provides a runtime capable of using VMs as an isolation layer for containers. At the time of this writing, version 3 of Kata works with Kubernetes but does not work with Docker. The Kata developers <a href="https://github.com/kata-containers/kata-containers/issues/5321">are working with the Docker developers</a> to try and improve this situation and create better documentation. This may be resolved when Docker 22.06 is publicly released.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="gVisor" data-type="sect2"><div class="sect2" id="idm46803124459728">&#13;
<h2>gVisor</h2>&#13;
&#13;
<p>In mid-2018, Google released gVisor, which<a data-primary="runtimes" data-secondary="gVisor runtime" data-type="indexterm" id="ch11-gv"/><a data-primary="gVisor runtime" data-type="indexterm" id="ch11-gv2"/><a data-primary="system calls" data-secondary="gVisor" data-type="indexterm" id="idm46803124455840"/> is a completely new take on a runtime. It’s OCI compliant and can therefore also be used with Docker. However, gVisor also runs in user space and isolates the application by implementing system calls there rather than relying on Kernel isolation mechanisms. It doesn’t redirect the calls to the kernel; rather, it implements them itself using kernel calls. The most obvious win from this approach is security isolation since gVisor itself is running in user space and thus is isolated from the kernel. Any security issues are still trapped in user space, and all of the kernel security controls we’ve mentioned still apply. The downside is that it typically performs worse than Kernel or VM-based solutions.</p>&#13;
&#13;
<p>If you have processes that do not require massive scaling but do require highly secure isolation, gVisor may be an ideal solution for you. A common use case for gVisor is when your containers will be running code provided by your end users and you cannot guarantee that the code is benign. Let’s run a quick demo so you can see how gVisor works.</p>&#13;
&#13;
<p>Installation is covered in the <a href="https://gvisor.dev/docs/user_guide/quick_start/docker">gVisor documentation</a>. It is written in Go and is delivered as a single executable with no packages required. Once it’s installed, you can start containers with the <code>runsc</code> runtime. To demonstrate the different isolation levels offered by gVisor, we’ll run a shell using it and compare that to one using a standard container.</p>&#13;
&#13;
<p>First, let’s start a shell on gVisor and look around a bit:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>--runtime<code class="o">=</code>runsc<code class="w"> </code>-it<code class="w"> </code>alpine<code class="w"> </code>/bin/sh<code class="w"/></pre>&#13;
&#13;
<p>That will drop us into a shell running in an Alpine Linux container. One very revealing difference is apparent when you look at the output of the <code>mount</code> command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>--runtime<code class="o">=</code>runsc<code class="w"> </code>-it<code class="w"> </code>alpine<code class="w"> </code>/bin/sh<code class="w"> </code>-c<code class="w"> </code><code class="s2">"mount"</code><code class="w"/>&#13;
&#13;
<code class="go">none on / type 9p (rw,trans=fd,rfdno=4,wfdno=4,aname=/,…)</code>&#13;
<code class="go">none on /dev type tmpfs (rw,mode=0755)</code>&#13;
<code class="go">none on /sys type sysfs (ro,noexec,dentry_cache_limit=1000)</code>&#13;
<code class="go">none on /proc type proc (rw,noexec,dentry_cache_limit=1000)</code>&#13;
<code class="go">none on /dev/pts type devpts (rw,noexec)</code>&#13;
<code class="go">none on /dev/shm type tmpfs (rw,noexec,mode=1777,size=67108864)</code>&#13;
<code class="go">none on /etc/hosts type 9p (rw,trans=fd,rfdno=7,wfdno=7,…)</code>&#13;
<code class="go">none on /etc/hostname type 9p (rw,trans=fd,rfdno=6,wfdno=6,…)</code>&#13;
<code class="go">none on /etc/resolv.conf type 9p (rw,trans=fd,rfdno=5,wfdno=5,…)</code>&#13;
<code class="go">none on /tmp type tmpfs (rw,mode=01777)</code></pre>&#13;
&#13;
<p>There is not very much in there! Compare that with the output from a traditional container launched with <code>runc</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>alpine<code class="w"> </code>/bin/sh<code class="w"> </code>-c<code class="w"> </code><code class="s2">"mount"</code><code class="w"/>&#13;
&#13;
<code class="go">overlay on / type overlay (rw,relatime,…)</code>&#13;
<code class="go">proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">tmpfs on /dev type tmpfs (rw,nosuid,size=65536k,mode=755,inode64)</code>&#13;
<code class="go">devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,…)</code>&#13;
<code class="go">sysfs on /sys type sysfs (ro,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">cgroup on /sys/fs/cgroup type cgroup2 (ro,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">mqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">shm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,…)</code>&#13;
<code class="go">/dev/sda3 on /etc/resolv.conf type ext4 (rw,relatime,errors=remount-ro)</code>&#13;
<code class="go">…</code>&#13;
<code class="go">devpts on /dev/console type devpts (rw,nosuid,noexec,relatime,gid=5,…)</code>&#13;
<code class="go">proc on /proc/bus type proc (ro,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">…</code>&#13;
<code class="go">tmpfs on /proc/asound type tmpfs (ro,relatime,inode64)</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>This output was 24 lines long, so we truncated it a lot. It should be pretty clear that there is a lot of system detail here. That detail represents the kernel footprint exposed to the container in one way or another. The contrast with the very short output from gVisor should give you an idea of the differing level of isolation. We won’t spend a lot more time on it, but it’s also worth looking at the output of <code>ip addr show</code> as well. On gVisor:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>--runtime<code class="o">=</code>runsc<code class="w"> </code>alpine<code class="w"> </code>ip<code class="w"> </code>addr<code class="w"> </code>show<code class="w"/>&#13;
&#13;
<code class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65522</code>&#13;
<code class="go">    link/loopback 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 127.0.0.1/8 scope global dynamic</code>&#13;
<code class="go">2: eth0: &lt;UP,LOWER_UP&gt; mtu 1500</code>&#13;
<code class="go">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 172.17.0.2/16 scope global dynamic</code></pre>&#13;
&#13;
<p>And in a normal Linux container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>alpine<code class="w"> </code>ip<code class="w"> </code>addr<code class="w"> </code>show<code class="w"/>&#13;
&#13;
<code class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000</code>&#13;
<code class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</code>&#13;
<code class="go">    inet 127.0.0.1/8 scope host lo</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code>&#13;
<code class="go">44: eth0@if45: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc</code>&#13;
<code class="go">                                                        noqueue state UP</code>&#13;
<code class="go">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff</code>&#13;
<code class="go">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</code>&#13;
<code class="go">       valid_lft forever preferred_lft forever</code></pre>&#13;
&#13;
<p>Even the Linux <em>/proc</em> filesystem exposes a lot less in the gVisor container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>--runtime<code class="o">=</code>runsc<code class="w"> </code>alpine<code class="w"> </code>ls<code class="w"> </code>-C<code class="w"> </code>/proc<code class="w"/>&#13;
&#13;
<code class="go">1               filesystems     net             sys</code>&#13;
<code class="go">cgroups         loadavg         self            thread-self</code>&#13;
<code class="go">cmdline         meminfo         sentry-meminfo  uptime</code>&#13;
<code class="go">cpuinfo         mounts          stat            version</code></pre>&#13;
&#13;
<p>Once more comparing this to a normal Linux container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>alpine<code class="w"> </code>ls<code class="w"> </code>-C<code class="w"> </code>/proc<code class="w"/>&#13;
&#13;
<code class="go">1                  fb                 mdstat             stat</code>&#13;
<code class="go">acpi               filesystems        meminfo            swaps</code>&#13;
<code class="go">asound             fs                 misc               sys</code>&#13;
<code class="go">bootconfig         interrupts         modules            sysrq-trigger</code>&#13;
<code class="go">buddyinfo          iomem              mounts             sysvipc</code>&#13;
<code class="go">bus                ioports            mpt                thread-self</code>&#13;
<code class="go">cgroups            irq                mtd                timer_list</code>&#13;
<code class="go">cmdline            kallsyms           mtrr               tty</code>&#13;
<code class="go">consoles           kcore              net                uptime</code>&#13;
<code class="go">cpuinfo            key-users          pagetypeinfo       version</code>&#13;
<code class="go">crypto             keys               partitions         version_signature</code>&#13;
<code class="go">devices            kmsg               pressure           vmallocinfo</code>&#13;
<code class="go">diskstats          kpagecgroup        schedstat          vmstat</code>&#13;
<code class="go">dma                kpagecount         scsi               zoneinfo</code>&#13;
<code class="go">driver             kpageflags         self</code>&#13;
<code class="go">dynamic_debug      loadavg            slabinfo</code>&#13;
<code class="go">execdomains        locks              softirqs</code></pre>&#13;
&#13;
<p>Aside from being more isolated, the experience inside the gVisor container is interesting because it looks a lot more like what you might expect to see in an isolated environment. Sandboxed runtimes like gVisor provide a lot of potential for securely running untrusted workloads by providing a much stronger barrier between the application and the underlying kernel.<a data-startref="ch11-rtsw" data-type="indexterm" id="idm46803124172576"/><a data-startref="ch11-gv" data-type="indexterm" id="idm46803124103600"/><a data-startref="ch11-gv2" data-type="indexterm" id="idm46803124102992"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Wrap-Up" data-type="sect1"><div class="sect1" id="idm46803124459136">&#13;
<h1>Wrap-Up</h1>&#13;
&#13;
<p>That’s a quick tour of some of the more advanced concepts of Docker. Hopefully, it has expanded your knowledge of what is happening behind the scenes and has opened up some avenues for you to continue your exploration. As you build and maintain a production platform, this background should provide you with a broad enough perspective of Docker to know where to start when you need to customize the system.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm46803124791184"><sup><a href="ch11.html#idm46803124791184-marker">1</a></sup> To quote the OCI website: “The Open Container Initiative (OCI) is a lightweight, open governance structure (project), formed under the auspices of the Linux Foundation, for the express purpose of creating open industry standards around container formats and runtime. The OCI was launched on June 22nd, 2015 by Docker, CoreOS and other leaders in the container industry.”</p></div></div></section></body></html>