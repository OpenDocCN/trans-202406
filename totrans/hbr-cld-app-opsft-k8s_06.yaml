- en: Chapter 5\. Continuous Delivery Across Clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cloud native applications have the potential to disrupt entire industries.
    A key reason for this is their ability to support continuous delivery. When the
    market environment changes and applications need to be updated to address real-world
    constraints that pop up quickly, continuous delivery enables applications to quickly
    adapt to meet these newly encountered issues. Here is a brief overview of how
    container images, Kubernetes, and OpenShift support DevOps principles to facilitate
    continuous delivery:'
  prefs: []
  type: TYPE_NORMAL
- en: Small batch changes
  prefs: []
  type: TYPE_NORMAL
- en: All changes should be incremental and finite. When failures occur, small batch
    changes are typically easier to recover than large, disruptive changes.
  prefs: []
  type: TYPE_NORMAL
- en: Source control all the things
  prefs: []
  type: TYPE_NORMAL
- en: A history of all changes is helpful to understand the changes that have been
    made and to identify the causes of regressions in the code base or configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Production-like environments
  prefs: []
  type: TYPE_NORMAL
- en: Developers should have access to environments and tools that are representative
    of production. Production environments typically operate at larger scales than
    development or quality assurance (QA) and with more complex configuration. The
    variance can mean that features that work fine in the early stages do not work
    correctly in production, which is the only place they matter.
  prefs: []
  type: TYPE_NORMAL
- en: Shift-left of operational practices
  prefs: []
  type: TYPE_NORMAL
- en: We should expose behaviors for health management, log collection, change management,
    and so on earlier in the development process.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous integration of changes
  prefs: []
  type: TYPE_NORMAL
- en: All changes should be built and deployed together on an ongoing basis to identify
    when the intermingling of various changes lead to an unforeseen issue or API incompatibility.
  prefs: []
  type: TYPE_NORMAL
- en: Highly automated testing with continuous feedback
  prefs: []
  type: TYPE_NORMAL
- en: To manage velocity, we have to automate our testing and validation work so that
    we can always be testing (ABT).
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we provide an overview of a variety of tools and methodologies
    for supporting continuous delivery in production across clusters. We begin with
    a discussion of Helm, which is a popular packaging tool for Kubernetes applications.
    Next we introduce Kustomize, which provides the ability to repurpose your existing
    Kubernetes YAML files for multiple purposes and configurations while avoiding
    the use of templates. We then describe several popular approaches for supporting
    continuous delivery pipelines, including GitOps, Razee, and Tekton. Finally, we
    conclude this chapter with an extensive discussion of OpenShift pipelines and
    the Open Cluster Management project for deploying applications across multiple
    clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Helm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Helm is the Kubernetes package manager. It enables you to create a package containing
    multiple templates for all of the resources that make up your application. Common
    Kubernetes resources you would expect to find included in a Helm package are `ConfigMaps`,
    deployments, `PersistentVolumeClaims`, services, and many others.
  prefs: []
  type: TYPE_NORMAL
- en: Helm provides its own [CLI](https://oreil.ly/9S6Ne) that will generate a collection
    of template files, and it also supports passing variable values into these template
    files. The collection of template files that Helm generates is called a *Helm
    chart*. The CLI will then create complete YAML files from the template files,
    package up all the related files, and deploy the chart.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `helm create` command is used to create a new package by passing in the
    name of the chart. So to create a new chart called `firstchart` we do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This command creates the following files and subfolders:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chart.yaml*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*charts/*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*templates/*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*values.yaml*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The *templates* folder contains some generated templates for representing key
    Kubernetes abstractions like deployments and service accounts. These template
    files are:'
  prefs: []
  type: TYPE_NORMAL
- en: '*NOTES.txt*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*_helpers.tpl*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*deployment.yaml*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*hpa.yaml*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ingress.yaml*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Service.yaml*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*serviceaccount.yaml*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*tests/*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *_helpers.tpl* file contains partial templates that are used to generate
    values such as Kubernetes selector labels and the name to use for the service
    account. Template files such as *deployment.yaml* and *serviceaccount.yaml* then
    use the partial templates to obtain these values. The template files also pull
    values from the *values.yaml* file. This file contains values such as `replicaCount`
    that are variables the user can change. These variables are also passed into template
    files such as *deployment.yaml* and *serviceaccount.yaml* and used to set desired
    values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have the proper set of template files and proper variables set for
    your application, it’s time to package up all the contents associated with this
    Helm chart. This is accomplished by using the `helm package` command. In our example,
    we would call the `helm package` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in the example, running the `helm package` command generates an archive
    file containing all the content associated with the Helm chart. Now, if we want
    to install the Helm chart, we just need to run the `helm install` command as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `helm install` command in its most basic form takes two arguments, the name
    of the release and the archive file. The `helm install` command is quite flexible
    and can install a Helm chart and its content in a variety of different ways. In
    addition, the Helm release that has been installed can be easily updated using
    the `helm update` command. For more information on the use of Helm and its capabilities,
    please see the [Helm documentation](https://helm.sh/docs).
  prefs: []
  type: TYPE_NORMAL
- en: Kustomize
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When running Kubernetes in production, you will invariably have lots of YAML
    files used for deploying and configuring applications. Moreover, you would typically
    store these configuration files in some form of source control to enable continuous
    delivery. Experience with running in production has shown that in many cases the
    configuration YAML files will need customizations for a variety of reasons. For
    example, there may be configuration changes for differences between development
    and production environments. Or custom prefix names may be needed to distinguish
    similar applications. To address these needs, the Kubernetes `kubectl` CLI has
    incorporated a recently developed tool called [Kustomize](https://kustomize.io).
    The Kustomize tool provides a template-free approach to customizing Kubernetes
    configurations.^([1](ch05.html#ch01fn33)) The Kustomize tool has several key features
    that both reduce the complexity of managing a large number of Kubernetes configurations
    for production deployments and facilitate the use of continuous deployment methodologies.
    The primary capabilities provided by Kustomize include generators, composition,
    patches, and overlays.
  prefs: []
  type: TYPE_NORMAL
- en: Generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Best practices for Kubernetes deployment recommend that configuration and secret
    data should not be hardcoded into an application. Instead, this information should
    be stored in Kubernetes resources like `ConfigMaps` and secrets. Kustomize provides
    the notion of *generators* that can create `ConfigMaps` and secrets to simplify
    this aspect of deployment. Kustomize uses YAML files to describe what should be
    generated. The following Kustomize YAML is used to generate a Kubernetes secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the previous example, save the file as *kustomization.yaml* in a new
    folder called *generateSecret*. You can now run it by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'After you run the above command, Kustomize will generate a Kubernetes secret
    resource as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As an alternative, Kustomize can generate a secret where the username and password
    are stored in a separate file. For example, create a file called *password.txt*
    and store the following key value pairs in the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'With these values now in *password.txt*, you can create a Kustomization file
    that generates a secret and pulls the username and password from *password.txt*
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the previous example, save the file as *kustomization.yaml* in a new
    folder called *generateSecret2*. You can now run Kustomize using this file by
    doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After you run this command, Kustomize will generate a Kubernetes secret resource
    similar to the one shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next section, we discuss another key feature of Kustomize: the ability
    to aggregate individual Kubernetes resource files into a single deployment YAML
    file.'
  prefs: []
  type: TYPE_NORMAL
- en: Composition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes deployments are typically created from a large set of YAML files.
    The YAML files themselves may be shared for multiple purposes. Kustomize supports
    the notion of *composition*, which enables individual YAML files to be selected
    and aggregated into a single deployment YAML file. The composition functionality
    also reduces the need to copy YAML files and then make slight modifications to
    those duplicate files for different purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate the capabilities of Kustomize composition, let’s create some
    Kubernetes YAML resource files that we want to aggregate. First, create a new
    folder called *composition* and store the following content in a file called *deploymentset.yaml*
    in the *composition* folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, store the following service resource YAML in a file called *service.yaml*
    in the *composition* folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now create a customization file that is capable of composing *deploymentset.yaml*
    and *service.yaml* by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To run this example, save the file as *kustomization.yaml* in the *composition*
    folder you previously created. You can now run Kustomize using this file by doing
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After you run this command, Kustomize will generate the aggregated deployment
    YAML as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we cover Kustomize’s patch capability, which enables us
    to avoid duplicating a full Kubernetes YAML file when all we need is a small change
    to an existing YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: Patches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many cases, the YAML file needed for a deployment may be very similar to
    an existing YAML file and only needs a small change to one of the resources. As
    an example, perhaps the only thing in a YAML file that needs to be changed is
    the number of replicas to create. For this type of situation, Kustomize provides
    the notion of *patches*, which are capable of making small modifications to resources
    described in YAML files. This is a much better approach than having to make a
    copy of the complete YAML file and then making the small modification to the duplicate
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate the capabilities of patches, let’s create a Kubernetes YAML
    resource file that is close to what we want but needs small changes. First, create
    a new folder called *patch* and store the following content in a file called *deploymentset.yaml*
    in the *patch* folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The deployment YAML file shown above is close to what we desire, but we now
    need a new version of this file that needs to provide six replicas instead of
    three. Rather than duplicating the whole *deploymentset.yaml* resource file and
    then changing the value of the `replicas` field, we can create a patch file that
    is much smaller and easier to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple patch file that can be used to create a duplicate *deploymentset.yaml*
    with a modified `replicas` field value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note that this small file identifies the kind of resource, the name of the resource,
    and the attribute field we wish to modify. This small file gives Kustomize enough
    information to identify the field that needs to be patched. To use this patch
    file, save it in a new file called *update_replicas.yaml* in the *patch* folder
    you just created.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the patch file created, we can now create a *kustomization.yaml* file
    that identifies the *deploymentset.yaml* file we wish to modify and also identifies
    the *update_replicas.yaml* file as the file that contains information on which
    fields to modify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the previous example, save the file as *kustomization.yaml* in the *patch*
    folder you previously created. You can now run Kustomize using this file by doing
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'After you run this command, Kustomize will generate the patched deployment
    YAML as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we describe the overlays capability, which is one of the
    most powerful features available in Kustomize.
  prefs: []
  type: TYPE_NORMAL
- en: Overlays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Building on the features described in the previous sections, the *overlays*
    functionality is where users see the most significant capabilities available from
    Kustomize. Overlays provide an approach where the user starts with a base folder
    that contains a set of Kubernetes deployment YAML files and builds on the base
    folder using overlay folders that enhance and customize the deployment YAML files
    contained in the base folder. In this section, we demonstrate how Kustomize overlays
    can be used to manage the differences that occur in deployment YAML files that
    exist when using the deployment YAML files across development, staging, and production
    Kubernetes environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate how Kustomize can be used in this fashion, let’s first create
    a new folder called *base* and copy into this folder the *deploymentset.yaml*
    and *service.yaml* files that we created in [“Composition”](#composition). With
    these files in the *base* folder, we can now create a *kustomization.yaml* in
    the *base* folder that references the deployment YAML files as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are going to create an overlay folder that tailors the base deployment
    files for a development environment. We begin by creating a new folder called
    *development*. Inside this folder, we create a new *kustomization.yaml* as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in *kustomization.yaml*, the Kustomization file starts by defining
    a new label called `env` that contains the value `development`. Since this label
    is defined as part of the `commonLabels` field, the effect is that this label
    will be set on all resources that are included in *kustomization.yaml*. The Kustomization
    then declares that its base will be the deployment YAML files that are located
    in the *base* folder. Next, the Kustomization defines a `namePrefix` with the
    value `dev-`*.* The effect of this declaration is to add a prefix to all resource
    names and references. In the final portion of *kustomization.yaml*, a patch is
    declared that will contain modifications to the deployment YAML files found in
    the *base* directory. The patch is contained in the file *update_replicas.yaml*.
    The contents of *update_replicas.yaml* are shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The *update_replicas.yaml* file contains a patch that modifies the number of
    replicas to now be `2` for a development environment. To run this example, make
    sure to save the patch in the *development* folder with the name *update_replicas.yaml*.
    You can now run Kustomize using the *kustomization.yaml* and *update_replicas.yaml*
    files by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'After you run this command, Kustomize will generate the patched deployment
    YAML as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Upon reviewing the deployment file that was generated, we see several changes
    that resulted from the use of *kustomization.yaml* and *update_replicas.yaml*
    files. First, notice that a new `env` label with the value of `development` now
    exists in both the service and deployment resources, as well as in the `template`
    section used to create the container replicas. Also note that all names listed
    in the deployment YAML have a prefix of `dev-`*.* Finally, the number of replicas
    for the development deployment YAML has been modified to denote that only two
    replicas should be created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are going to create *kustomize.yaml* and *update_replicas.yaml* files
    that are used to tailor the base deployment YAMLs for a staging environment. In
    our situation, the staging environment should have a label of `env` with the value
    of `staging` on all resources, the names of all resources should have a prefix
    of `staging-`*,* and the number of replicas that should be used for the staging
    environment is five. Similar to the previous example for the development environment
    customizations, we begin by creating a new folder called *staging*. Inside this
    folder, we create a new *kustomization.yaml* as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we defined `env` as a `commonLabel` and gave it the value
    of `staging`. We created a new `namePrefix` with the value of `staging-`*.* We
    also are once again creating an *update_replicas.yaml* that will be used as a
    patch file to modify the number of replicas when the base deployments YAML files
    are used in a staging environment. The contents of *update_replicas.yaml* are
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, the *update_replicas.yaml* file contains a patch that modifies
    the number of replicas. For staging, we have chosen to use five replicas. To run
    this example, make sure to save the patch in the *staging* folder with the name
    *update_replicas.yaml*. You can now run Kustomize using the *kustomization.yaml*
    and *update_replicas.yaml* files by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'After you run this command, Kustomize will generate the patched deployment
    YAML as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Once more, we see several changes that resulted from the use of our *kustomization.yaml*
    and *update_replicas.yaml* files. First, notice that a new `env` label with the
    value of `staging` now exists in both the service and deployment resources, as
    well as in the `template` section used to create the container replicas. Also
    note that all names listed in the deployment YAML have a prefix of `staging-`*.*
    Finally, the number of replicas for the development deployment YAML has been modified
    to denote that five replicas should be created.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our final example, we will use the same techniques to modify the base deployment
    YAML files for a production environment. In our production environment, we should
    have a label of `env` with the value of `production` on all resources, the names
    of all resources should have a prefix of `prod-`*,* and the number of replicas
    that should be used for the production environment is 20\. We begin by creating
    a new folder called *production*. Inside this folder, we create a new *kustomization.yaml*
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We again create an *update_replicas.yaml* file that will be used as a patch
    file to modify the number of replicas when the base deployments YAML files are
    used in the production environment. The contents of *update_replicas.yaml* are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'To run this example, make sure to save the patch in the *production* folder
    with the name *update_replicas.yaml*. You can now run Kustomize using the *kustomization.yaml*
    and *update_replicas.yaml* files by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'After you run this command, Kustomize will generate the patched deployment
    YAML with the proper labels, prefixes, and replica count value as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: As we have demonstrated with this comprehensive example, Kustomize was able
    to manage deployment YAML files for a development environment, a staging environment,
    and a production environment, and it reduced the number of deployment YAML files
    we needed to maintain for all of these environments. We avoided a large amount
    of copy and paste of files and ended up with a much more manageable solution.
    In the next section, we show how Kustomize can be used to directly deploy its
    generated deployment files.
  prefs: []
  type: TYPE_NORMAL
- en: Direct Deploy of Kustomize-Generated Resource Files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In all of the previous Kustomize examples, we generated the modified deployment
    YAMLs and outputted them to make it clear what Kustomize was generating. Kustomize
    provides another option in which the generated deployment YAML files can be automatically
    submitted to Kubernetes for processing. This avoids the step of first generating
    all the deployment YAML files and instead enables us to use Kustomize to directly
    deploy what it generates. To use Kustomize to directly deploy to Kubernetes, we
    use the `kubectl apply -k` option and pass in the desired customization directory.
    For example, if we wanted to directly deploy the production example we just covered,
    we would do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In addition, Kustomize provides commands for viewing and deleting the Kubernetes
    resources objects that it generates and deploys. More details on these capabilities
    can be found in the [Kustomization documentation](https://oreil.ly/4kCu4). In
    the next section, we introduce the concept of GitOps, which is a popular cloud
    native methodology for automated continuous delivery that is driven directly from
    Git repositories.
  prefs: []
  type: TYPE_NORMAL
- en: GitOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*GitOps* is the idea of using Git to manage your infrastructure as code. The
    idea was first popularized by Weaveworks,^([2](ch05.html#ch01fn34)) and with the
    proliferation of more containerized approaches to software delivery, GitOps has
    become a popular topic in the industry. The basic GitOps flow is always the same:
    an update to your source code triggers automation and ultimately validates a potential
    new change or delivers a new change into a running environment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying GitOps involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Containerized applications are represented with declarative infrastructure (easily
    done with Kubernetes API represented as YAML) and stored in Git.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All changes originate from your source control revision system, typically Git-based
    systems like GitHub, GitLab, Bitbucket, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code-review techniques like pull requests or merge requests allow you to apply
    a review process and even automated validation to ensure that changes work correctly
    before wide rollouts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes (or more generally a software agent) is then used to apply and reconcile
    the desired state whenever changes are merged into the appropriate branch in your
    repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first half of this flow is really about your team and organizational culture.
    Is your organization disciplined enough with the appropriate skill set to make
    all changes indirectly via Git rather than directly manipulating the target infrastructure?
    Are you at a scale in terms of the number of applications, number of delivery
    stages, and number of actual clusters that you can manage the proliferation of
    repositories and branches? As with any cultural change, look for teams in your
    organization that adapt well to new ideas and can become good representative examples
    for the broader organization. Focus on a specific application or set of related
    applications applying this approach from end to end before attempting a broader
    reorganization of your team’s delivery practices.
  prefs: []
  type: TYPE_NORMAL
- en: The second half of the flow is where you have various tools that have evolved
    to simplify the management of adopting changes out of Git, applying the changes
    to your running environments, and validating the changes. We will review a few
    projects that can help you adopt your changes from Git and apply them to your
    Kubernetes environment in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Pull requests/merge requests (PR/MR) allow you to leverage feature branches
    to complete enhancements and fixes against your code base and validate those changes
    before integration with the main delivery branches. These PR/MR branches generally
    apply automated validation to virtually all dimensions of code quality, including
    security scans, linting or best practices required by your team or organization,
    automated unit testing, automated functional testing, automated integration testing,
    and review by other humans on your team to ensure that the change is consistent
    with the rest of the system’s goals and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: GitOps can work well in systems with fewer independent applications and fewer
    active environments under management (e.g., software as a service, or SaaS). When
    your delivery output includes software that must be packaged and versioned, GitOps
    can still add value but likely becomes part of a larger story.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a single application managed with source under management in a Git
    repository. For each stage of your release process, you will create a distinct
    Git branch. In the most basic version, you keep a single “main” branch deployed
    continuously within your end-user accessible production applications. In other
    cases, your release process may require additional lower environments and thus
    additional corresponding branches like “main” (for code under active development),
    “candidate” (for code undergoing user acceptance testing), and “stable” (for code
    running in production). For example, you might have branches “main” and “stable”
    where the “main” branch accumulates changes for development and “stable” tracks
    the version of code and configuration deployed in production. Many organizations
    likely have additional layers of validation, including quality engineering, user
    acceptance testing, performance and scale testing, and so on. Each distinct phase
    that you want control over means potentially another branch in your Git repository.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we introduce Razee, which is the first of several production-quality
    continuous delivery systems for Kubernetes that we survey in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Razee
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Razee](https://razee.io) is an open source continuous deployment system originally
    developed by IBM to address issues that arise when supporting extreme-scale environments
    with tens of thousands of Kubernetes clusters that need to be managed. Razee automates
    the deployment of Kubernetes resources across a large number of clusters and environments
    and provides several key features to address issues that arise when managing a
    large number of clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to other deployment systems, Razee has a pull-based deployment approach
    that enables Kubernetes clusters to be self-updating. Also, Razee has a dynamic
    inventory-creation feature that allows it to ascertain what is running in all
    the Kubernetes clusters that it manages. With this feature, operators can gain
    insights into what applications and versions run in their clusters. Razee keeps
    a history of this inventory data and provides alerts to help troubleshoot issues
    in clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Razee provides a lot of rule-based support for the grouping of clusters that
    helps to simplify managing large groups of clusters. Razee also uses a rule-based
    approach to orchestrate its pull-based update deployment model. The combination
    of all of these features enables Razee to support automated deployment and management
    of tens of thousands of clusters across multiple availability zones without manual
    intervention. For more details on Razee’s approach to scalability and the key
    features it provides, see the [Razee documentation](https://oreil.ly/1N0ql).
  prefs: []
  type: TYPE_NORMAL
- en: Argo CD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Argo CD](https://oreil.ly/H2UiL) is a declarative continuous delivery system
    that will continuously reconcile the contents of a Git repository with a Kubernetes
    cluster. Argo CD has a number of flexible access control models ranging from a
    deployment per namespace to per cluster, or you can provide credentials for multiple
    clusters via Kubernetes secrets to manage multiple clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: Argo CD adapts well to Kubernetes applications using Helm charts, [Kustomize](https://oreil.ly/TOE56),
    or [ksonnet](https://oreil.ly/9apwT) for templating changes to your resources
    for different clusters. Once deployed and configured, Argo CD will respond to
    postcommit hooks or ongoing polling of changes to the repository and apply those
    changes to the cluster. In many ways, it resembles a Puppet- or Chef-style convergence
    model. If changes are made out of band to the cluster, the desired state will
    eventually be restored.
  prefs: []
  type: TYPE_NORMAL
- en: As of the time of this writing, Argo CD has begun looking at additional API
    kinds, including [ApplicationSet](https://oreil.ly/5nbsB), that allow the deployment
    of resources to more than one cluster. One proposed path would enable Argo CD
    to leverage the inventory of clusters available from Open Cluster Management to
    automatically configure GitOps for members of the fleet.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on Argo CD, we recommend the [Getting Started](https://oreil.ly/VJQk5)
    materials from the project website.
  prefs: []
  type: TYPE_NORMAL
- en: Tekton
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tekton is a *continuous integration and continuous delivery* (CI/CD) system
    that runs as a Kubernetes-based cloud native application. Since Tekton runs as
    a Kubernetes-based application, it is built to run as a scalable cloud native
    application. This is a significant advantage over more legacy CI/CD systems, which
    are not cloud native based and thus are more susceptible to failures or performance
    bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: Tekton was originally the build system for the Knative serverless workload platform.
    Because it provided value as a general-purpose CI/CD platform, it was converted
    to a standalone project and donated to the Continuous Delivery Foundation in March
    2019.^([3](ch05.html#ch01fn35))
  prefs: []
  type: TYPE_NORMAL
- en: 'Tekton provides a CLI and a dashboard user interface for managing its CI/CD
    workloads. It also has event trigger and webhooks support. There are several great
    tutorials for getting started with Tekton available at the [Tekton Pipeline GitHub
    site](https://oreil.ly/0yZDx) and the [IBM Developer Tekton Tutorial page](https://oreil.ly/FSE9g).
    In the next few sections, we introduce the fundamental concepts of Tekton: tasks
    and pipelines.'
  prefs: []
  type: TYPE_NORMAL
- en: Tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A *task* represents a collection of commands or tools that should be executed
    in a specific order. Each command or tool is represented as a *step,* which defines
    the command or tool to be executed and the container image that contains the command
    or tool. The following example illustrates a simple task with two discrete steps
    that each run an echo command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To run this task, first save the previous example in a file called *simpleexample.yaml*.
    Next, you need to create a `TaskRun` resource that will be used to run the task
    in a standalone fashion on a Kubernetes cluster. Here is the YAML for the `TaskRun`
    resource that we will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: As shown in our sample `TaskRun` YAML, we create a `TaskRun` resource and give
    it a name. Then in the `taskRef` field, we provide the name of the task that we
    want to run on a Kubernetes cluster. To deploy the `TaskRun` resource, save the
    previous example as *simpleexamplerun.yaml*.
  prefs: []
  type: TYPE_NORMAL
- en: 'On a Kubernetes cluster that has Tekton installed, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'After running these commands, you should see output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'To confirm that the task ran properly, we can use the `tkn taskrun logs --last
    -f` Tekton command to view the logs from the `simple-task-example` that we just
    ran:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'If you need more details on the execution of your task, you can use the `tkn
    taskrun describe` command to get a much larger list of information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: While not shown in the previous example, Tekton has a large number of built-in
    capabilities for common integration steps like pulling in content from Git repositories
    and building container images. In addition, Tekton gives tasks a new feature called
    *workspaces,* which is a shared persistent volume. The workspace provides an area
    of shared storage that tasks can use to share files with other tasks that are
    working with it cooperatively. For more details on workspaces, see the [Tekton
    Workspaces Documentation](https://oreil.ly/XUZdv).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we describe pipelines, which is Tekton’s construct for
    enabling multiple tasks to work together on common build integration and deployment
    activities.
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Tekton provides the notion of *pipelines* as its mechanism for creating a collection
    of tasks and ordering the execution of the group of tasks. In some cases, tasks
    have dependencies on other tasks and must declare that they execute after the
    tasks they are dependent on. In other cases, tasks may not have dependencies on
    one another, and those tasks can run concurrently. The pipelines construct manages
    its collection of tasks and the order in which they execute, as well as the common
    shared workspaces that each task is entitled to use. To better understand how
    pipelines work, we need at least two tasks. In the previous section, we defined
    and deployed the `simple-task-example` task. We will now create a second task
    called `simple-task-example2`. This task is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'To deploy this task, save the previous example in a file called *simpleexample2.yaml*.
    Deploy this task by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: You may notice that with our second task example, we did not provide a corresponding
    `TaskRun` for running it. The reason we don’t have a second `TaskRun` is because
    we are going to group both tasks into a pipeline, and the pipeline will be responsible
    for creating any `TaskRun` objects it needs to run its tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline that we are using for this example is named `simple-pipeline`,
    and it declares that it manages two tasks, which it references as `simple-task-example`
    and `simple-task-example2` respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'To run this pipeline, first save the previous example in a file called *simplepipeline.yaml*.
    Deploy this pipeline using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will create a `PipelineRun` object that is responsible for running
    this pipeline on a Kubernetes cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the previous file as *simplepipelinerun.yaml*. You can then run the `simple-pipeline`
    example on the cluster by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'To confirm that the pipeline ran properly, use the `tkn pipelinerun logs --last
    -f` Tekton command and view the logs from the `simple-pipeline` example that you
    just ran:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon reviewing the log output, we notice that the two tasks ran concurrently.
    This is consistent with how we defined our tasks. If the two tasks had a dependency
    and we needed the second task to defer execution until after the first task completed,
    the Tekton pipeline supports this by adding a `runAfter` declaration to the second
    task that states it should be run after the first task completes. This is shown
    in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Note that the `runAfter` field explicitly references the task named `simple-task`
    as the task that must be completed before `simple-task2` is permitted to execute.
  prefs: []
  type: TYPE_NORMAL
- en: Tekton has a large number of useful features that are beyond the scope of this
    book. For more information on Tekton and its capabilities, see the [Tekton Pipeline
    documentation](https://oreil.ly/nw5yD). In addition, Tekton pipelines serve as
    the foundation for OpenShift Pipelines, an offering available from Red Hat.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift Pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[OpenShift Pipelines](https://oreil.ly/VU8Gr) is a fully supported software
    offering from Red Hat based on Tekton. Using the operator paradigm simplifies
    the configuration of Tekton and helps you get to value from the ecosystem faster.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at an end-to-end example using OpenShift Pipelines, which is available
    from the [GitHub organization associated with this book](https://oreil.ly/X749O).
    In this example, you’ll see the Tekton concepts of tasks and pipelines put to
    work to build a simple app that lets you play PAC-MAN in your browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure OpenShift Pipelines by installing the operator from the OperatorHub
    catalog available within your OpenShift Container Platform web console (4.4 or
    greater):'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to Operators > OperatorHub and search for “OpenShift Pipelines,” as
    shown in [Figure 5-1](#operatorhub_catalog_filtered_by_the_quer).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/hcok_0501.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 5-1\. OperatorHub catalog filtered by the query “OpenShift Pipelines”
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Click on the tile to display information about the operator. Scroll to the bottom
    of the page to download the appropriate command-line version for your platform
    (see [Figure 5-2](#download_the_cli_for_tekton_left_parenth)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/hcok_0502.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 5-2\. Download the CLI for Tekton (`tkn`) for your platform
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Click Install.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the appropriate update channel for your version of OpenShift. For example,
    if you’re running OCP 4.4.x, use ocp-4.4.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click Subscribe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can confirm that the installation was successful by navigating to Operators
    > Installed Operator and filtering the project to “openshift-operators,” as shown
    in [Figure 5-3](#confirm_successful_installation_of_the_o).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0503.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-3\. Confirm successful installation of the OpenShift Pipelines Operator
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When assembling your continuous delivery solution with Tekton Tasks, you have
    access to a broad community library of existing tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Tekton task catalog](https://oreil.ly/INXgA)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenShift Pipelines task catalog](https://oreil.ly/z3KwI)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s reuse some of the tasks in the public catalogs to put together our working
    example. You will also have a set of tasks available after installing the operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now create a pipeline to build our image and publish to the in-cluster
    registry. First, create a project in your OpenShift cluster to hold the resources
    we are about to create:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'All of the following examples assume that you are working in this same namespace,
    `pipelines-tutorial`. If for some reason your `KUBECONFIG` is referencing a different
    namespace, then you can use the `oc project` command to update your context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can add the `-n pipelines-tutorial` flag to the example
    commands after `oc apply`, `oc create`, `oc get`, and so on. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: To build and publish an image, the default service account `pipeline` must have
    the authorization to push an image into your destination registry. For this example,
    the [Quay.io](https://quay.io) registry is used, but any registry will work fine.
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable the authorization for the `pipeline` service account, you must create
    a `docker-registry` secret and update the `pipeline` service account. These steps
    are not related to Tekton specifically but are relevant to our example:'
  prefs: []
  type: TYPE_NORMAL
- en: Create the Quay.io image repository named `quay.io/*<username>*/pacman` for
    your username by following the [Quay.io documentation](https://oreil.ly/N3Ng3).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download the Kubernetes secret from Quay.io. You can access the secret from
    the Settings page under “Generate Encrypted Password.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Apply the secret (and be sure to update the default name of `*<username>*-pull-secret
    to quay-registry-secret`) or use the `kubectl` or `oc` command line to create
    the secret:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Patch the `quay-registry-secret` into the `pipeline` service account. The OpenShift
    pipelines operator automatically creates the `pipeline` service account in every
    namespace of your cluster. By updating the service account in the `pipelines-tutorial`
    namespace, you will allow any Tekton `TaskRun`s to leverage this authorization
    for pushing images:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will start creating a pipeline that will build an image and push it into
    the image repository that you just defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The `build-pacman` Pipeline defines a single task that uses the `buildah ClusterTask`.
    The input requires a Git repository with the `Dockerfile` and associated source
    files that are required and the details of the image to build.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create the pipeline using the `oc` command-line tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'After applying the pipeline definition, we can verify it exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The `tkn` command-line tool offers a specific set of actions for Tekton resources.
    In addition to equivalents for commands like `get` or `describe`, there are direct
    commands to view task logs and other Tekton-specific behaviors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Tekton pipelines define parameters that drive their behavior. To simplify the
    management of parameters, Tekton also defines `PipelineResource`s that represent
    different kinds of objects that occur frequently in desired pipeline behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the defined [`PipelineResource` types](https://oreil.ly/KrZlb):'
  prefs: []
  type: TYPE_NORMAL
- en: '`git`'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub repository
  prefs: []
  type: TYPE_NORMAL
- en: '`storage`'
  prefs: []
  type: TYPE_NORMAL
- en: Storage blob
  prefs: []
  type: TYPE_NORMAL
- en: '`image`'
  prefs: []
  type: TYPE_NORMAL
- en: Container image metadata
  prefs: []
  type: TYPE_NORMAL
- en: '`cluster`'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes cluster description with access credentials
  prefs: []
  type: TYPE_NORMAL
- en: '`pullRequest`'
  prefs: []
  type: TYPE_NORMAL
- en: A GitHub pull request
  prefs: []
  type: TYPE_NORMAL
- en: '`cloudEvent`'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Event
  prefs: []
  type: TYPE_NORMAL
- en: '`gcs`'
  prefs: []
  type: TYPE_NORMAL
- en: GCSResource backed by a GCS blob/directory
  prefs: []
  type: TYPE_NORMAL
- en: '`build-gcs`'
  prefs: []
  type: TYPE_NORMAL
- en: BuildGCSResources added to be compatible with Knative build
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create `PipelineResource`s that will become inputs to the pipeline
    and fulfill the required values for the input parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We will apply these resources and then reference them in our `PipelineRun`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have a pipeline and we have inputs (our Git repo and our desired image
    to build). Let’s trigger the pipeline by creating a `PipelineRun`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The `PipelineRun` will carry out two actions with a single `buildah` task:
    clone the Git repository, and then build the image and publish it to the Quay.io
    registry that you previously created.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the pipeline, use `oc create`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We are using `oc create` here instead of `oc apply` because the `PipelineRun`
    uses a `generateName` instead of a `name` attribute. The `oc apply` command requires
    the `name` attribute, whereas `oc create` supports additional behavior to generate
    a suffix for the name automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see the running pipelines with the `tkn` command-line tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'You can follow along with the `PipelineRun` using the `tkn` command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we built the container image. Let’s take it further and apply
    the change to the cluster. In this step, we will create a pipeline with three
    distinct stages:'
  prefs: []
  type: TYPE_NORMAL
- en: Build the application image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fetch the Git repository that contains our deployment manifests (using Kustomize).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply Kustomization deployment manifests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The first step works exactly the same way as before. The additional steps introduce
    a few new ideas:'
  prefs: []
  type: TYPE_NORMAL
- en: We will create a `PersistentVolumeClaim` to provide available storage to host
    the contents of our Git repository. Otherwise, the files retrieved from Git in
    Step 2 will not be available for use in Step 3.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will require additional permissions for our `pipeline` service account to
    allow the deployment manifests to be applied to the application namespace on this
    cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s create the `PersistentVolumeClaim`. The `PersistentVolumeClaim` should
    request enough capacity for all persistent file system storage required by all
    tasks in the pipeline. If the `PersistentVolume` is reclaimed or recycled in between
    tasks, you may lose important state and the pipeline run will likely fail. On
    the other hand, if the same `PersistentVolume` is reused across many pipeline
    runs, it may eventually exhaust all available space. If the same `PersistentVolume`
    is expected to support multiple pipeline runs in parallel, be sure to set the
    `accessMode` to `ReadWriteMany`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: State management of workspaces could become an issue over time. Tekton 0.12
    introduces a `volumeClaimTemplate` that offers to simplify this process. Otherwise,
    you may always be creating `PersistentVolumeClaim`s and `PersistentVolume`s for
    each `PipelineRun`. For any resource that you are creating via automation, be
    sure to define your reclamation strategy to destroy or allow any unnecessary resources
    to age out as appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our first pipeline, we updated the `system:serviceaccounts:pipelines-tutorial:pipeline`
    service account to allow the use of an additional secret that authorized our service
    account to push images into our Quay.io image registry. In our second pipeline,
    our service account will apply deployment manifests to the same cluster running
    the pipeline and will require authorization to the application namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: With the `edit ClusterRoleBinding` to the `pacman` namespace, the service account
    will be able to create, modify, and view most of the Kubernetes API objects, including
    deployments, services, and OpenShift routes. Our chosen example application creates
    each of these as part of its deployment manifests.
  prefs: []
  type: TYPE_NORMAL
- en: 'To verify that you have applied the permission correctly, you can use the `can-i`
    command, which will print a simple “yes” or “no” answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will create our new pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: We do not need any additional `PipelineResource`s to run this pipeline. In fact,
    you may notice that the details about the two related Git repositories are managed
    differently in this pipeline. As you consume different tasks or define your own,
    you may find slight inconsistencies in how you assemble tasks to accomplish your
    goals. Specifically, the community `git-clone` task does not use the `git` type
    `Pipeline​Res⁠ource` but rather accepts the component parts needed to identify
    the repository URL and revision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as before, we will create a `PipelineRun` and monitor its progress:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, you can use the `tkn` command-line tool to view all `PipelineRun`s:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'You can review or follow the logs as well. Note that if you run this after
    the `PipelineRun` has completed, the log order will be reversed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Defining and troubleshooting tasks can be a little error prone at first. Use
    the API reference and don’t be afraid to delete or recreate the initial pipelines
    and pipeline runs to resolve reference issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can confirm whether `pacman` was successfully deployed by opening the
    route with the web browser ([Figure 5-4](#successful_deployment_of_the_pac_man_app)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/hcok_0504.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-4\. Successful deployment of the PAC-MAN application
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Open Cluster Management Apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The [Open Cluster Management](https://oreil.ly/QbBRN) project is a new approach
    to managing applications across one or more OpenShift clusters. The approach applies
    a native GitOps approach to attaching a Kubernetes object to a Git repository.
    Let’s take a simple example based on the open source PAC-MAN app.
  prefs: []
  type: TYPE_NORMAL
- en: The Open Cluster Management project is focused on several aspects of managing
    Kubernetes clusters, including creating and upgrading clusters, distributed delivery
    and management of applications, syndicating cluster configuration, and maintaining
    visibility on the compliance and governance of managed clusters. The *hub* cluster
    runs the multicluster control plane, and a lightweight agent that runs as a set
    of pods on the *managed clusters* applies the desired state to all clusters under
    management and provides a feedback loop for health, search index, and compliance.
    We will focus only on the application management concepts for the next example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Open Cluster Management app model relies on the following concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Application`'
  prefs: []
  type: TYPE_NORMAL
- en: A grouping of related resources required to provide a logical service to a consumer.
  prefs: []
  type: TYPE_NORMAL
- en: '`Channel`'
  prefs: []
  type: TYPE_NORMAL
- en: A source of application parts required for deployment. Current supported channels
    include Git repositories, object store buckets, and Helm repositories.
  prefs: []
  type: TYPE_NORMAL
- en: '`Subscription`'
  prefs: []
  type: TYPE_NORMAL
- en: Connects parts of an application from a channel to one or more clusters. Subscriptions
    consume a range of versions from a release branch (e.g., “latest,” “stable,” “production,”
    etc.).
  prefs: []
  type: TYPE_NORMAL
- en: '`PlacementRule`'
  prefs: []
  type: TYPE_NORMAL
- en: Links a subscription to one or more clusters.
  prefs: []
  type: TYPE_NORMAL
- en: '[*Red Hat Advanced Cluster Management* (RHACM)](https://oreil.ly/6x2Ba) is
    a fully supported software offering that is based on the Open Cluster Management
    project. Similar to how OpenShift Pipelines simplifies the setup and life cycle
    of adopting Tekton and other projects, RHACM for Kubernetes simplifies the adoption
    of the Open Cluster Management project ([Figure 5-5](#installation_of_advanced_cluster_managem)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0505.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-5\. Installation of Advanced Cluster Management for Kubernetes in OpenShift
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To install RHACM for Kubernetes, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Search for the operator by name and click Install.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the operator is installed, create an instance of the `MultiClusterHub`
    API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: From the Applications list in the OpenShift Container Platform web console,
    click the new item to open the RHACM web console, as shown in [Figure 5-6](#opening_the_rhacm_web_console_in_openshi).
    You may need to refresh your web browser for this new link to appear.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/hcok_0506.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 5-6\. Opening the RHACM web console in OpenShift
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The example assumes that you have created or imported two clusters in Advanced
    Cluster Management with the following labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'For reference, we will assume the following two managed clusters: “cluster1-aws-east”
    and “cluster3-gcp-europe-west3.” Notice that one cluster (“cluster1-aws-east”)
    is provisioned on Amazon in North America, while the second (“cluster3-gcp-europe-west3”)
    is provisioned on Google in Europe (see [Figure 5-7](#using_the_rhacm_web_console_to_manage_bo)).
    So for this example, we’re deploying our app to a multicluster and multicloud
    platform backed by OpenShift!'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0507.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-7\. Using the RHACM web console to manage both Amazon- and Google-provisioned
    clusters
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can display these managed clusters from the command line as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'We start by defining our application and referencing the `Subscription` kind
    that will make up the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: The application provides a way to group a set of related parts into a logical
    unit for management. As of the current project readiness, the application is used
    to understand the delivery of parts to different managed clusters. Work is underway
    to also use the application to aggregate health information and summarize the
    readiness of the complete application for all supporting clusters where the application
    or its parts are deployed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s define the channel and subscription to attach our application to
    one or more clusters. The channel simply references the Git repository for our
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The subscription then references the channel, includes details about the requested
    branch for application changes, and isolates the relevant directory structure
    within the Git repository. Subscriptions can further restrict when deployments
    are allowed by specifying `timeWindows` that either explicitly allow or block
    changes to the cluster that are recognized in the source repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we see the subscription for the `pacman-app` with references to the channel
    defined previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: The subscription also provides the ability to supply information to the deployment
    via `packageOverrides` for Kustomization projects or Helm charts.
  prefs: []
  type: TYPE_NORMAL
- en: The subscription is then matched to a managed cluster by a `PlacementRule`.
    The `PlacementRule` uses match selectors to identify target clusters that are
    under management that should host the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, a `PlacementRule` defines a selection clause to select
    at most two clusters that have a region value of `us-east`, `us-west`, or `europe-west3`
    and include the labels `environment=dev` and `apps/pacman=deployed`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'We can apply all of these API resources from our example project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s see what this would look like if we had two clusters under management.
    Our first cluster is an OpenShift cluster running on Amazon Elastic Compute Cloud
    (EC2) in the us-east region. Our second cluster is an OpenShift cluster running
    on Google Compute Platform in the europe-west3 region. We can inspect any managed
    clusters in RHACM with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `PlacementRule` will have identified these two eligible clusters based
    on the `matchLabels` and `matchExpressions` that we defined previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: We can view our application in the Advanced Cluster Management topology view
    and its relevant parts (described by the subscription) that were deployed to our
    two managed clusters (identified by the `PlacementRule`) that originated from
    our Git repository (identified by the channel). In [Figure 5-8](#visualization_of_the_application_in_the),
    we can see the application has exactly one subscription (it could have multiple)
    that is placed on two clusters.
  prefs: []
  type: TYPE_NORMAL
- en: We can select elements in the topology to view more information, as shown in
    [Figure 5-9](#displaying_the_details_of_multiple_clust).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0508.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-8\. Visualization of the application in the RHACM topology view
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![](assets/hcok_0509.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-9\. Displaying the details of multiple clusters in the RHACM topology
    view
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The cluster icon depicted in [Figure 5-10](#displaying_the_details_of_a_selected_clu)
    shows us the clusters that were selected.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0510.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-10\. Displaying the details of a selected cluster in the RHACM topology
    view
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The deployment icons show us how our deployment is doing and whether it was
    successfully deployed and is currently healthy on our managed clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Clicking “Launch resource in Search” will show us details about the `pacman`
    deployment across all managed clusters (see [Figure 5-11](#display_of_the_pacman_deployment_in_the)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we can see our `pacman` deployment is running on two clusters: cluster3-gcp-europe-west3
    and cluster1-aws-east. From here we could further inspect related objects, including
    the related pods, services, and secrets used by the deployment.'
  prefs: []
  type: TYPE_NORMAL
- en: The powerful search capability allows you to understand your application with
    a holistic view. At a minimum, you are able to validate that parts of the application
    are deployed as expected. If a problem arises, these views help you isolate what
    may be the root cause of an observed failure. Making the information available
    in a more consumable form helps SREs and developers be more effective in dealing
    with the complexity of a multicluster or multicloud architecture.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0511.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-11\. Display of the `pacman` deployment in the RHACM web console
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided an overview of several popular tools and methodologies
    for supporting continuous delivery in production across traditional Kubernetes
    and OpenShift clusters. We first introduced Helm, which is a popular packaging
    tool for Kubernetes applications. Next, we described Kustomize, which provides
    the ability to use your existing Kubernetes YAML files for multiple purposes and
    configurations while avoiding the use of templates. We then described several
    popular approaches for supporting continuous delivery pipelines, including GitOps,
    Razee, Tekton, and Argo CD. Finally, we concluded with an extensive discussion
    of OpenShift Pipelines and Open Cluster Management tools for deploying and managing
    OpenShift applications across multiple clusters. With the techniques learned in
    this chapter, you now have a solid understanding of the most popular and proven
    continuous delivery options available to you and some hands-on experience managing
    applications across multiple clusters. In the next chapter, we provide an in-depth
    examination of the crucial operations of provisioning and upgrading in multicluster
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch05.html#ch01fn33-marker)) Jeff Regan and Phil Wittrock, “Introducing
    Kustomize; Template-free Configuration Customization for Kubernetes,” Kubernetes
    Blog (May 29, 2018), [*https://oreil.ly/fli5E*](https://oreil.ly/fli5E).
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch05.html#ch01fn34-marker)) Weaveworks, “Guide to GitOps,” [*https://oreil.ly/QIQ24*](https://oreil.ly/QIQ24).
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch05.html#ch01fn35-marker)) “Introducing the Continuous Delivery Foundation,
    the New Home for Tekton, Jenkins, Jenkins X, and Spinnaker,” Google Open Source
    Blog (March 12, 2019), [*https://oreil.ly/FvwF1*](https://oreil.ly/FvwF1).
  prefs: []
  type: TYPE_NORMAL
