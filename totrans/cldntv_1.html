<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" class="pagenumrestart" data-pdf-bookmark="Chapter 1. Introduction to Cloud Native"><div class="chapter" id="introduction_to_cloud_native">
<h1><span class="label">Chapter 1. </span>Introduction to Cloud Native</h1>


<p>What are cloud native applications? What makes them so appealing that the cloud native model is now considered not only for the cloud, but also for the edge? And, finally, how do you design and develop cloud native applications? These are all questions that will be answered throughout this book. But before we dive into the details on the what, why, and how, we want to provide a brief introduction to the cloud native world and some of the fundamental concepts and assumptions that are building the foundation for modern cloud native applications and environments.</p>






<section data-type="sect1" data-pdf-bookmark="Distributed Systems"><div class="sect1" id="distributed_systems">
<h1>Distributed Systems</h1>

<p>One of the biggest hurdles that developers face when they build cloud native applications for the first time is that they must deal with services that are not on the same machine, and they need to deal with patterns that consider a network between the machines.<a data-type="indexterm" data-primary="distributed systems" id="idm45987080871272"/> Without even knowing it, they have entered the world of distributed systems. A <em>distributed system</em> is a system in which individual computers are connected through a network and appear as a single computer. Being able to distribute computing power across a bunch of machines is a great way to accomplish scalability, reliability, and better economics.<a data-type="indexterm" data-primary="scalability" id="idm45987080870056"/> For example, most cloud providers are using cheaper commodity hardware and solving common problems such as high availability and reliability through software-based solutions.</p>








<section data-type="sect2" data-pdf-bookmark="Fallacies of Distributed Systems"><div class="sect2" id="fallacies_of_distributed_systems">
<h2>Fallacies of Distributed Systems</h2>

<p>There are couple of incorrect or unfounded assumptions most developers and architects make when they enter the world of distributed systems.<a data-type="indexterm" data-primary="distributed systems" data-secondary="fallacies of" id="idm45987080868216"/> Peter Deutsch, a Fellow at Sun Microsystems, was identifying fallacies of distributed computing back in 1994, at a time when nobody thought about cloud computing. Because cloud native applications are, at their core, distributed systems, these fallacies still have validity today. Following is the list of the fallacies that Deutsch described, with their meanings applied to cloud native applications:</p>
<dl>
<dt>The network is reliable</dt>
<dd>
<p>Even in the cloud you cannot assume that the network is reliable.<a data-type="indexterm" data-primary="reliability" data-secondary="network, fallacy of in distributed systems" id="idm45987080865784"/><a data-type="indexterm" data-primary="networks" data-secondary="reliability in distributed systems" id="idm45987080864936"/> Because services are typically placed on different machines, you need to develop your software in a way that it accounts for potential network failures, which we discuss later in this book.</p>
</dd>
<dt>Latency is zero</dt>
<dd>
<p>Latency and bandwidth are often confused, but it is important to understand the difference.<a data-type="indexterm" data-primary="latency" data-secondary="in distributed systems" id="idm45987080861464"/> Latency is how much time goes by until data is received, whereas bandwidth indicates how much data can be transferred in a given window of time.<a data-type="indexterm" data-primary="bandwidth" data-secondary="latency versus" id="idm45987080862152"/> Because latency has a big impact on user experience and performance, you should take care to do the following:</p>

<ul>
<li>
<p>Avoid frequent network calls and introducing chattiness to the network.</p>
</li>
<li>
<p>Design your cloud native application in a way that the data is closest to your client by using caching, content delivery networks (CDNs), and multiregion deployments.<a data-type="indexterm" data-primary="caching" id="idm45987080858872"/><a data-type="indexterm" data-primary="content delivery networks (CDNs)" id="idm45987080857032"/><a data-type="indexterm" data-primary="mutiregion deployments" id="idm45987080856360"/><a data-type="indexterm" data-primary="CDNs" data-see="content delivery networks" id="idm45987080855656"/></p>
</li>
<li>
<p>Use publication/subscription (pub/sub) mechanisms to be notified that there is new data and store it locally to be immediately available. <a data-type="xref" href="ch03.xhtml#designing_cloud-native_applications">Chapter 3</a> covers messaging patterns such as pub/sub in more detail.<a data-type="indexterm" data-primary="publish/subscribe (pub/sub)" id="idm45987080851832"/></p>
</li>
</ul>
</dd>
<dt>There is infinite bandwidth</dt>
<dd>
<p>Nowadays, network bandwidth does not seem to be a big issue, but new technologies and areas such as edge computing open up new scenarios that demand far more bandwidth. <a data-type="indexterm" data-primary="bandwidth" data-secondary="infinite, fallacy of in distributed systems" id="idm45987080850296"/>For example, it is predicted that a self-driving car will produce around 50 terabytes (TB) of data per day. This volume of data requires you to design your cloudnative application with bandwidth usage in mind.<a data-type="indexterm" data-primary="domain driven design (DDD)" id="idm45987080846904"/> Domain-Driven Design (DDD) and data patterns such as Command Query Responsibility Segregation (CQRS) are very useful under such bandwidth-demanding circumstances. <a data-type="xref" href="ch04.xhtml#working_with_data">Chapter 4</a> and <a data-type="xref" href="ch06.xhtml#best_practices">Chapter 6</a> cover how to work with data in cloud native applications in more detail.<a data-type="indexterm" data-primary="Command Query Responsibility Segregation (CQRS)" id="idm45987080848056"/></p>
</dd>
<dt>The network is secure</dt>
<dd>
<p>Two things are often an afterthought for developers: diagnostics and security.<a data-type="indexterm" data-primary="networks" data-secondary="fallacies of, in distributed systems" id="idm45987080842904"/> The assumption that networks are secure can be fatal. As a developer or architect, you need to make security a priority of your design; for example, by embracing a defense-in-depth approach.</p>
</dd>
<dt>The topology does not change</dt>
<dd>
<p>Pets versus cattle is a meme that gained popularity with the advent of containers.<a data-type="indexterm" data-primary="pets versus cattle" id="idm45987080840648"/><a data-type="indexterm" data-primary="topology (network) in distributed systems" id="idm45987080840040"/> It means that you do not treat any machine as a known entity (pet) with its own set of properties, such as static IPs and so on. Instead, you treat machines as a member of a herd that has no special attributes. This concept is very important with cloud native applications. Because cloud environments are meant to provide elasticity, machines can be added and removed based on criteria such as resource consumption or requests per second.</p>
</dd>
<dt>There is one administrator</dt>
<dd>
<p>In traditional software development, it was quite common to have one person responsible for the environment, installing and upgrading the application, and so forth.<a data-type="indexterm" data-primary="administration" data-secondary="of distributed systems" id="idm45987080841496"/> Modern cloud architectures and DevOps methods have shifted the way software is built.<a data-type="indexterm" data-primary="DevOps" id="idm45987080836360"/> A modern cloud native application is a composite of many services that need to work together in concert and that are developed by different teams. This makes it practically impossible for a single person to know and understand the application in its entirety, not to mention trying to fix a problem. Thus, you need to ensure that you have governance in place that makes it easy to troubleshoot issues. Throughout this book, we introduce you to important concepts such as <em>release management</em>, <em>decoupling</em>, and <em>logging and monitoring</em>. <a data-type="xref" href="ch05.xhtml#devops">Chapter 5</a> provides a detailed look at common DevOps practices for cloud native applications.</p>
</dd>
<dt>Transport cost is zero</dt>
<dd>
<p>From a cloud native perspective, there are two ways to look at this one. First, transport happens over a network and network costs are not free with most cloud providers.<a data-type="indexterm" data-primary="transport costs in distributed systems" id="idm45987080833432"/> Most cloud providers, for example, do not charge for data ingress, but do charge for data egress. The second way to look at this fallacy is that the cost for translating any payload into objects is not free. For example, serialization and deserialization are usually fairly expensive operations that you need to consider in addition to the latency of network calls.</p>
</dd>
<dt>The network is homogeneous</dt>
<dd>
<p>This is almost not worth listing given that pretty much every developer and architect understands that there are different protocols that they must consider when building their applications.<a data-type="indexterm" data-primary="homogeneous networks in distributed systems, fallacy of" id="idm45987080829304"/></p>
</dd>
</dl>

<p>As mentioned before, although these fallacies were documented a long time ago, they are still a good reminder of the incorrect assumptions people make when entering the cloud native world. Throughout this book, we teach you patterns and best practices that take all of the fallacies of distributed computing into account.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="CAP Theorem"><div class="sect2" id="cap_theorem">
<h2>CAP Theorem</h2>

<p>The CAP theorem is often mentioned in combination with distributed systems.<a data-type="indexterm" data-primary="CAP theorem" id="idm45987080825432"/><a data-type="indexterm" data-primary="consistency, availability, partitions" data-see="CAP theorem" id="idm45987080824936"/> The CAP theorem states that any networked shared-data system can have at most two of the<a data-type="indexterm" data-primary="availability" data-seealso="CAP theorem" id="idm45987080822296"/> following three desirable properties:</p>

<ul>
<li>
<p>Consistency (C) equivalent to having a single up-to-date copy of the data</p>
</li>
<li>
<p>High availability (A) of that data (for updates)</p>
</li>
<li>
<p>Tolerance to network partitions (P)</p>
</li>
</ul>

<p>The reality is that you will always have network partitions (remember, “the network is reliable” is one of the fallacies of distributed computing). <a data-type="indexterm" data-primary="partitions (network), tolerance for, in CAP theorem" id="idm45987080819016"/>That leaves you with only two choices—you can optimize either for consistency or high availability. Many NoSQL databases such as Cassandra optimize for availability, whereas SQL-based systems that adhere to the principles of ACID (atomicity, consistency, isolation, and durability) optimize for consistency.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="The Twelve-Factor App"><div class="sect1" id="the_twelve-factor_app">
<h1>The Twelve-Factor App</h1>

<p>In the early days of Infrastructure as a Service (IaaS) and Platform as a Service (PaaS), it quickly became obvious that the cloud required a new way of developing applications.<a data-type="indexterm" data-primary="Platform as a Service (PaaS)" id="idm45987080816840"/><a data-type="indexterm" data-primary="Infrastructure as a Service (IaaS)" id="idm45987080813080"/> For example, on-premises scaling was often done by scaling vertically, meaning adding more resources to a machine. Scaling in the cloud, on the other hand, is usually done horizontally, meaning adding more machines to distribute the load.<a data-type="indexterm" data-primary="Twelve-Factor App methodology" id="idm45987080812472"/> This type of scaling requires stateless applications, and this is one of the factors described by the <em>Twelve-Factor App manifesto</em>. The Twelve-Factor App methodology can be considered the foundation for cloud native applications and was first introduced by engineers at Heroku, derived from best practices for application development in the cloud. Cloud development has evolved since the introduction of the Twelve-Factor manifesto, but the principles still apply. Following <a data-type="indexterm" data-primary="cloud native applications" data-secondary="Twelve-Factor App methodology" id="idm45987080811384"/>are the 12 factors and their meaning for cloud native applications:</p>
<ol>
<li>
<p>Codebase</p>

<p><em>One codebase tracked in revision control; many deploys</em>.</p>

<p>There is only one codebase per application, but it can be deployed into many environments such as Dev, Test, and Prod.<a data-type="indexterm" data-primary="code" data-secondary="codebase in Twelve-Factor apps" id="idm45987080809016"/> In cloud native architecture, this translates directly into one codebase per service or function, each having its own Continuous Integration/Continuous Deployment (CI/CD) flow.</p>
</li>
<li>
<p>Dependencies</p>

<p><em>Explicitly declare and isolate dependencies</em>.</p>

<p>Declaring and isolating dependencies is an important aspect of cloud native development.<a data-type="indexterm" data-primary="isolation" data-secondary="of dependencies" data-secondary-sortas="dependencies" id="idm45987080802888"/><a data-type="indexterm" data-primary="dependencies" data-secondary="in Twelve-Factor apps" data-secondary-sortas="Twelve-Factor" id="idm45987080802248"/> Many issues arise due to missing dependencies or version mismatch of dependencies, which stem from environmental differences between the on-premises and cloud environments. In general, you should always use dependency managers for languages such as Maven or npm. Containers have drastically reduced dependency-based issues because all dependencies are packaged inside a container, and as such should be declared in the Dockerfile. Chef, Puppet, Ansible, and Terraform are great tools to manage and install system dependencies.</p>
</li>
<li>
<p>Configuration</p>

<p><em>Store configuration in the environment</em>.</p>

<p>Configuration should be strictly separated from code. This allows you to easily apply configurations per environment.<a data-type="indexterm" data-primary="configuration" data-secondary="in Twelve-Factor apps" data-secondary-sortas="Twelve-Factor" id="idm45987080800296"/> For example, you can have a test configuration file that stores all the connection strings and other information used in a test environment. If you want to deploy the same application to a production environment, you need only to replace the configuration. Many modern platforms support external configuration, whether it is configuration maps with Kubernetes or managed configuration services in cloud environments.</p>
</li>
<li>
<p>Backing Services</p>

<p><em>Treat backing services as attached resources</em>.</p>

<p>A backing service is defined as “any service the app consumed over the network as part of its normal operation.” In the case of cloud native applications, this might be a managed caching service or a Database as a Service (DbaaS) implementation.<a data-type="indexterm" data-primary="backing services" id="idm45987080798600"/> The recommendation here is to access those services through configuration settings stored in external configuration systems, which allows loose coupling, one of the principles that is also valid for cloud native applications.</p>
</li>
<li>
<p>Build, Release, Run</p>

<p><em>Strictly separate build and run stages</em>.</p>

<p>As you will see in <a data-type="xref" href="ch05.xhtml#devops">Chapter 5</a> on DevOps, it is recommended<a data-type="indexterm" data-primary="build, release, run" id="idm45987080794824"/> to aim for fully automated build and release stages using CI/CD practices.</p>
</li>
<li>
<p>Processes</p>

<p><em>Execute the app in one or more stateless processes</em>.</p>

<p>As mentioned earlier, compute in the cloud should be stateless, meaning that data should only be saved outside the processes.<a data-type="indexterm" data-primary="processes (in Twelve-Factor apps)" id="idm45987080788616"/><a data-type="indexterm" data-primary="state" data-secondary="stateless processes in Twelve-Factor apps" id="idm45987080787752"/> This enables elasticity, which is one of the promises of cloud computing.</p>
</li>
<li>
<p>Data Isolation</p>

<p><em>Each service manages its own data</em>.</p>

<p>This is one of the key tenets of &lt;em&gt;microservices architectures&lt;/em&gt;, which is a common pattern in cloud native applications.<a data-type="indexterm" data-primary="isolation" data-secondary="of data" data-secondary-sortas="data" id="idm45987080784344"/><a data-type="indexterm" data-primary="data isolation" id="idm45987080783256"/><a data-type="indexterm" data-primary="microservices" data-secondary="data isolation in" id="idm45987080782552"/> Each service manages its own data, which can be accessed only through APIs, meaning that other services that are part of the application are not allowed to directly access the data of another service.</p>
</li>
<li>
<p>Concurrency</p>

<p><em>Scale out via the process model</em>.</p>

<p>Improved scale and resource usage are two of the key benefits of cloud native applications, meaning that you can scale each service or function independently and horizontally; thus, you’ll achieve better resource usage.<a data-type="indexterm" data-primary="concurrency" id="idm45987080617544"/></p>
</li>
<li>
<p>Disposability</p>

<p><em>Maximize robustness with fast startup and graceful shutdown</em>.</p>

<p>Containers and functions already satisfy this factor given that both provide fast startup times.<a data-type="indexterm" data-primary="disposability" id="idm45987080615960"/> One thing that is often neglected is to design for a crash or scale in scenario, meaning that the instance count of a function or a container is decreased, which is also captured in this factor.</p>
</li>
<li>
<p>Dev/Prod Parity</p>

<p><em>Keep development, staging, and production as similar as possible</em>.</p>

<p>Containers allow you to package all of the dependencies of your service, which limits the issues with environment inconsistencies.<a data-type="indexterm" data-primary="environments" data-secondary="keeping similar as possible" id="idm45987080614120"/><a data-type="indexterm" data-primary="production" data-secondary="dev/prod parity" id="idm45987080614968"/><a data-type="indexterm" data-primary="dev/prod parity" id="idm45987080613000"/> There are scenarios that are a bit trickier, especially when you use managed services that are not available on-premises in your Dev environment. <a data-type="xref" href="ch05.xhtml#devops">Chapter 5</a> looks at methods and techniques to keep your environments as consistent as possible.</p>
</li>
<li>
<p>Logs</p>

<p><em>Treat logs as event streams</em>.</p>

<p>Logging is one of the most important tasks in a distributed system. There are so many moving parts<a data-type="indexterm" data-primary="logging" data-secondary="logs, treating as event streams" id="idm45987080606872"/><a data-type="indexterm" data-primary="events" data-secondary="logs as event streams" id="idm45987080606360"/> and without a good logging strategy, you would be “flying blind” when the application is not behaving as expected. The Twelve-Factor manifesto states that you should treat logs as streams, routed to external systems.</p>
</li>
<li>
<p>Admin Processes</p>

<p><em>Run admin and management tasks as one-off processes</em>.</p>

<p>This basically means that you should execute administrative and management tasks as short-lived processes.<a data-type="indexterm" data-primary="administration" data-secondary="admin processes, short-lived" id="idm45987080605048"/> Both functions and containers are great tools for that.</p>
</li>

</ol>

<p>Throughout the book you will recognize many of these factors because they are still very relevant for cloud native applications.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Availability and Service-Level Agreements"><div class="sect1" id="availability_and_service-level_agreement">
<h1>Availability and Service-Level Agreements</h1>

<p>Most of the time, cloud native applications are composite applications that use compute, such as containers and functions, but also managed cloud services such as DbaaS, caching services, and/or identity services.<a data-type="indexterm" data-primary="availability" data-secondary="and service-level agreements" id="idm45987080601192"/><a data-type="indexterm" data-primary="SLAs (service-level agreements), availability and" id="idm45987080599640"/><a data-type="indexterm" data-primary="service-level agreements (SLAs), availability and" id="idm45987080599032"/> What is not obvious is that your compound Service-Level Agreement (SLA) will never be as high as the highest availability of an individual service. SLAs are typically measured in uptime in a year, more commonly referred to as “number of nines.” <a data-type="xref" href="#uptime_percentages_and_service_downtime">Table 1-1</a> shows a list of common availability percentages for cloud services and their corresponding downtimes.</p>
<table id="uptime_percentages_and_service_downtime">
<caption><span class="label">Table 1-1. </span>Uptime percentages and service downtime</caption>
<thead>
<tr>
<th>Availability %</th>
<th>Downtime per year</th>
<th>Downtime per month</th>
<th>Downtime per week</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>99%</p></td>
<td><p>3.65 days</p></td>
<td><p>7.20 hours</p></td>
<td><p>1.68 hours</p></td>
</tr>
<tr>
<td><p>99.9%</p></td>
<td><p>8.76 hours</p></td>
<td><p>43.2 minutes</p></td>
<td><p>10.1 minutes</p></td>
</tr>
<tr>
<td><p>99.99%</p></td>
<td><p>52.56 minutes</p></td>
<td><p>4.32 minutes</p></td>
<td><p>1.01 minutes</p></td>
</tr>
<tr>
<td><p>99.999%</p></td>
<td><p>5.26 minutes</p></td>
<td><p>25.9 seconds</p></td>
<td><p>6.05 seconds</p></td>
</tr>
<tr>
<td><p>99.9999%</p></td>
<td><p>31.5 seconds</p></td>
<td><p>2.59 seconds</p></td>
<td><p>0.605 seconds</p></td>
</tr>
</tbody>
</table>

<p>Following is an example of a compound SLA:</p>

<ul class="simplelist">
<li>
<p>Service 1 (99.95%) + Service 2 (99.90%): 0.9995 × 0.9990 = 0.9985005</p>
</li>
</ul>

<p>The compound SLA is 99.85%.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="summary">
<h1>Summary</h1>

<p>Many developers struggle when starting to develop for the cloud. In a nutshell, developers are facing three major challenges: first, they need to understand distributed systems; second, they need to understand new technologies such as containers and functions; and third, they need to understand what patterns to use when building cloud native applications. Having some familiarity with the fundamentals, such as the fallacies of distributed systems, the Twelve-Factor manifesto, and compound SLAs, will make the transition easier. This chapter introduced some of the fundamental concepts of cloud native, which enables you to better understand some of the architectural considerations and patterns discussed throughout the book.</p>
</div></section>







</div></section></div>



  </body></html>