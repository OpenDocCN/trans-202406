<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. Intrusion Detection"><div class="chapter" id="ch-intrusion-detection">
<h1><span class="label">Chapter 9. </span>Intrusion Detection</h1>


<p>In this chapter we will see how container intrusion detection operates
with the new low-level eBPF interface, what forensics looks like for a container,
and how to catch attackers who have evaded all other controls.</p>

<p>Defense in depth <a data-type="indexterm" data-primary="defense in depth" id="idm45302808200976"/>means limiting the trust you place in each security control you deploy. No solution is infallible,
but you can use intrusion detection systems (IDS)<a data-type="indexterm" data-primary="intrusion detection systems (IDSs)" data-see="IDSs (intrusion detection systems)" id="idm45302808199952"/><a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" id="idm45302808199072"/> to detect unexpected activity in much the same way that motion sensors detect movement. Your adversary has already accessed your system and
may even have viewed confidential information already, so an IDS reviews your system in real time for unexpected behavior and
observes or blocks it. Alerts can trigger further defensive actions from an IDS, like dumping compromised memory or recording
network activity.</p>

<p>Intrusion detection can inspect file, network, and kernel reads and writes to verify or block them with an allowlist or a denylist (as <code>seccomp-bpf</code> configuration does). If Captain Hashjack’s Hard Hat Hacking Collective has remote access to your servers, an IDS might be triggered by their use of malware with known behavioral signatures, scan of networks or files for further targets, or any other program access that deviates from the expected “stable” baseline the IDS has learned about the process.</p>

<p>Some attackers’ campaigns are only discovered after the adversary has been on the system for weeks or months and finally inadvertently tripped the IDS detection.</p>






<section data-type="sect1" data-pdf-bookmark="Defaults"><div class="sect1" id="idm45302808195776">
<h1>Defaults</h1>

<p>Stable behavior <a data-type="indexterm" data-primary="intrusion detection" data-secondary="default behavior" id="idm45302808194448"/>is what we’d expect our container process to do normally,
when running as intended, and not compromised. We can apply the same thing to any data we collect: access and audit
logs, metrics and telemetry, and system calls and network activity.</p>

<p>Intrusion detection to identify deviance from this behavior requires installation, maintenance, and monitoring.
By default most systems do not have any intrusion detection unless configured to do so.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Threat Model"><div class="sect1" id="idm45302808192208">
<h1>Threat Model</h1>

<p>Intrusion detection<a data-type="indexterm" data-primary="intrusion detection" data-secondary="threat models" id="idm45302808190704"/><a data-type="indexterm" data-primary="threat models" data-secondary="intrusion detection" id="idm45302808189696"/> can detect threats to BCTL’s systems. If an attacker gets remote code execution<a data-type="indexterm" data-primary="RCE (remote code execution)" data-secondary="Intrusion detection and" id="idm45302808188624"/> (RCE) into a
container they may be able to control the process, changing its behavior. Potentially nonstable behaviors that could
indicate compromise might include:</p>

<ul>
<li>
<p>New or disallowed system calls (perhaps fork or exec system calls to create a shell like Bash or sh)</p>
</li>
<li>
<p>Any unexpected network, filesystem, file metadata, or device access</p>
</li>
<li>
<p>Application usage and order</p>
</li>
<li>
<p>Unexplained processes or files</p>
</li>
<li>
<p>Changes to users or identity settings</p>
</li>
<li>
<p>System and kernel configuration events</p>
</li>
</ul>

<p>Any of a process’s properties and behaviors when interacting with the wider system may also be subject to scrutiny.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Attack tools like <a href="https://oreil.ly/pKyt0">ccat</a> and <a href="https://oreil.ly/bchJw">dockerscan</a>
can poison images in registries and <a data-type="indexterm" data-primary="dockerscan" id="idm45302808178288"/><a data-type="indexterm" data-primary="ccat" id="idm45302808177584"/><a data-type="indexterm" data-primary="backdoors" data-secondary="attack tools" id="idm45302808176912"/>install backdoors in container images that an attacker may use to gain entry to
your pods at runtime. This sort of unexpected behavior should be noticed and alerted on by your IDS.</p>
</div>

<p>Of course, you don’t want to be alerted to legitimate activity, so you authorize expected behavior. It’s either
preconfigured with rules and signatures or learned while the process is under observation in a nonproduction
environment.</p>

<p>These threats should be identified and configured to alert your IDS system. We’ll see how in this chapter.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Traditional IDS"><div class="sect1" id="idm45302808174208">
<h1>Traditional IDS</h1>

<p>Before we get <a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="traditional" id="IDS_trad"/>into cloud native IDS, let’s have a look at a few of the other intrustion detection applications
that have been prominent over the years.</p>

<p>Traditional intrusion detection systems are classed as<a data-type="indexterm" data-primary="NIDSs (network intrusion detection systems)" id="idm45302808170512"/><a data-type="indexterm" data-primary="network intrusion detection systems (NIDSs)" id="idm45302808169712"/><a data-type="indexterm" data-primary="HIDSs (host-based intrusion detection systems)" id="idm45302808169008"/><a data-type="indexterm" data-primary="host-based intrusion detection systems (HIDSs)" id="idm45302808168304"/> Network- or Host-based IDS (NIDS or HIDS), and some tools offer
both. Historically these used signals from the host kernel or network adapter, and were not aware of the Linux
namespaces that containers use.</p>

<p>Linux has <a href="https://oreil.ly/N5BSs"><code>auditd</code></a> built in for <a data-type="indexterm" data-primary="Linux" data-secondary="intrusion detection" id="idm45302808165984"/><a data-type="indexterm" data-primary="intrusion detection" data-secondary="Linux" id="idm45302808165008"/><a data-type="indexterm" data-primary="auditd" id="idm45302808164064"/>system call events, but this
doesn’t correlate activity nicely across nodes in a distributed system. It’s also considered heavyweight (it generates a
great volume of logs) and can’t distinguish by namespace due to  “complex and incomplete” ID tracking of namespaced
processes.</p>

<p>Tools like <a href="https://suricata.io">Suricata</a>, <a href="https://www.snort.org">Snort</a>, and <a href="https://zeek.org">Zeek</a> inspect <a data-type="indexterm" data-primary="Suricata" id="idm45302808160192"/><a data-type="indexterm" data-primary="Snort" id="idm45302808159456"/><a data-type="indexterm" data-primary="Zeek" id="idm45302808158784"/>network
traffic against a rule and scripting engine, and may be run on the same host or (as they tend to be  resource intensive)
on dedicated hardware attached to the network under observation. Encrypted or steganographic payloads may escape such
NIDS undetected. To further guard against these slippery assailants, the old-but-effective
<a href="https://oreil.ly/3ewaE">Tripwire</a> tool watches <a data-type="indexterm" data-primary="Tripwire" id="idm45302808156976"/>files on the host for unauthorized changes.</p>

<p>An IDS detects <a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="principles of operation" id="IDS_poOps"/>threats by either using preknown information about them or detecting deviance from an expected baseline.
Information known in advance can be considered a “signature,” and signatures can relate to network traffic and scans,
malware binaries, or memory. Any suspicious patterns in packets, “fingerprints” of application code or memory usage, and
process activities are verified against an expected ruleset derived from the application’s “known good” behavior.</p>

<p>Once a signature pattern is identified (for example, the SUNBURST traffic back to command and control servers), the IDS
creates a relevant alert.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>FireEye released <a data-type="indexterm" data-primary="FireEye" id="idm45302808152448"/>IDS configurations <a href="https://oreil.ly/kgkNH">to detect SUNBURST</a>. These
configurations support various IDS tools including Snort, Yara, IOC, and ClamAV.</p>
</div>

<p>Signatures <a data-type="indexterm" data-primary="signatures, IDSs and" id="idm45302808150240"/><a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="signatures and" id="idm45302808149504"/>are distributed and update files, so you must regularly update them to ensure new and recent threats are
detected. A signature-based approach is usually less resource intensive and less prone to false positives, but it may not
detect zero-days and novel attacks. Attackers have access to defensive tooling and can determine how to circumvent
controls in their own test systems.</p>

<p>Without predefined signatures to trip the IDS, anomalous behavior may be detected. This relies on a “known good state”
of the application.</p>

<p>The derivation of a normal application behavior state defines “secure,” which puts the onus on defenders to ensure
application correctness, rather than on the tool to enforce a generic ruleset.</p>

<p>This observational approach is more powerful than signatures as it can act autonomously against new threats. The price
for this more general protection is greater resource utilization, which may impact the performance of the system being

<span class="keep-together">protected.</span></p>

<p>Signature and anomaly detection can be fooled, circumvented, and potentially disabled by a skilled adversary, so never rely entirely upon one<a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="traditional" data-startref="IDS_trad" id="idm45302808145088"/><a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="principles of operation" data-startref="IDS_poOps" id="idm45302808143824"/> control.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a href="https://oreil.ly/Zpw8C">VirusTotal</a> is a <a data-type="indexterm" data-primary="VirusTotal" id="idm45302808140896"/>library of malicious files. When a defender discovers an attack, they upload the files retrieved by
forensics (for example, malware, implants, and C2 binaries or encrypted files), allowing researchers to correlate
techniques across targets and helping defenders to understand their adversary, the attacks being used, and (with any
luck) how they can best defend themselves. Antivirus vendors ensure their products have signatures for every malicious
file on VirusTotal, and new submissions are scanned by existing virus detection engines for matches.</p>

<p>Attackers use these same tools to ensure their payloads will bypass antivirus and malware signature
scanners. Red Teams have been retrospectively discovered leaking tooling and signatures onto VirusTotal once their
attacking campaigns have been decloaked.</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="eBPF-Based IDS"><div class="sect1" id="idm45302808173616">
<h1>eBPF-Based IDS</h1>

<p>Running IDS for <a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="eBPF-based" id="IDS_eBPF"/><a data-type="indexterm" data-primary="eBPF" data-secondary="Intrusion detection and" id="eBPF_intdet"/>every packet or system call can incur overhead and slow down the system.</p>

<p>We introduced eBPF in <a data-type="xref" href="ch05.xhtml#workload-networking-bpf">“eBPF”</a> as a mechanism to safely and efficiently extend
the Linux kernel. eBPF avoids some of these issues by being very fast indeed: it was designed for fast packet handling, and now
kernel developers use it to observe runtime behavior for everything in the kernel. Because it runs inside the kernel
as trusted code it is less restricted than other IDS and tracing technologies.</p>

<p>However, running in the kernel poses its own set of possible risks, and the eBPF subsystem and JIT compiler have had a number of
breakouts, but these are considered less dangerous than slow, incomplete kernel developer tracing solutions or more
fallible IDS.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a href="https://oreil.ly/BPYwJ">Jeff Dileo’s</a> <a href="https://oreil.ly/sllD3">“Evil eBPF In-Depth Practical Abuses of an In-Kernel Bytecode Runtime”</a>
is a good primer on BPF and its attacks, and <a href="https://oreil.ly/KzOg0">“Kernel Pwning with eBPF: A Love Story”</a> by  <a href="https://oreil.ly/NjjEf">Valentina Palmiotti</a> is a
walkthrough of the various components of eBPF.</p>
</div>

<p class="pagebreak-before">Since eBPF’s powers have been extended and integrated more deeply into the kernel, a number of CNIs and security
products now use eBPF for detection and networking including <a href="https://cilium.io">Cilium</a>, <a href="https://pixielabs.ai">Pixie</a>,
and <a href="https://falco.org">Falco</a> (which we detail in the following section).</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>As with all container software, bugs can lead to <a data-type="indexterm" data-primary="container breakouts" data-secondary="CVEs" id="idm45302808123872"/><a data-type="indexterm" data-primary="CVEs (Common Vulnerabilities and Exposures)" data-secondary="container breakouts" id="idm45302808122896"/><a data-type="indexterm" data-primary="security" data-secondary="CVEs" data-tertiary="container breakouts" id="idm45302808121856"/><a data-type="indexterm" data-primary="intrusion detection" data-secondary="CVEs" id="idm45302808120640"/>container breakout, as in
<a href="https://oreil.ly/82xbU">CVE-2021-31440</a>, where
an incorrect bounds calculation in the Linux kernel eBPF verifier allowed an exploitable verifier bypass.</p>
</div>

<p>Let’s move on to some applications of eBPF in <a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="eBPF-based" data-startref="IDS_eBPF" id="idm45302808118240"/><a data-type="indexterm" data-primary="eBPF" data-secondary="Intrusion detection and" data-startref="eBPF_intdet" id="idm45302808116928"/>Kubernetes.</p>








<section data-type="sect2" data-pdf-bookmark="Kubernetes and Container Intrusion Detection"><div class="sect2" id="idm45302808115456">
<h2>Kubernetes and Container Intrusion Detection</h2>

<p>There are <a data-type="indexterm" data-primary="containers" data-secondary="IDSs and" id="idm45302808114096"/><a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="containers and" id="idm45302808113088"/>signature and anomaly detection systems available for Kubernetes workloads at runtime. Kubernetes and
container IDS systems support namespaced workload, host, and network IDS.</p>

<p>By splitting processes into namespaces, you can use more well-defined metadata to help an IDS make decisions. This
more granular data can give greater insight into an attack, which is vital when the decision to kill a running container
may affect your production workloads.</p>

<p>This gives container IDS an advantage: the behavior it is monitoring is just a single container, not a whole machine.
The definition of allowed behavior is much smaller in a single-purpose container, so the IDS has a far greater fidelity
of policy to block unwanted behavior. With this in mind, let’s now have a look at a few container-specific IDS.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Falco"><div class="sect2" id="idm45302808110096">
<h2>Falco</h2>

<p>Falco <a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="Falco" id="IDS_falco"/><a data-type="indexterm" data-primary="Falco" id="falco"/>is an open source, cloud native IDS that can run in a container or on a host. Traditionally, Falco required a
dedicated kernel module to run (with its code loaded into the kernel) so that it could interact with system calls. Since
2019, Falco has also supported eBPF. The eBPF interface allows general-purpose code to be loaded by Falco, from
userspace, into the kernel’s memory. This means less custom code, fewer kernel modules, and the ability to use the
kernel monitoring and enforcement techniques through a well-known interface.</p>

<p>When run in a container, it requires privileged access to the host or use of the <code>CAP_BPF</code> capability with host PID
namespace access.</p>

<p class="pagebreak-before">In eBPF mode, when a process interacts with a file using a system call such as <code>open()</code>, the eBPF program is triggered,
which can run arbitrary code in a kernel VM to make its decision. Depending on the inputs, the action will be accepted
or blocked:</p>

<pre data-type="programlisting" data-code-language="bash">user@host:~ <code class="o">[</code>0<code class="o">]</code><code class="nv">$ </code>docker run --rm -i -t <code class="se">\</code>
  -e <code class="nv">HOST_ROOT</code><code class="o">=</code>/ <code class="se">\</code>
  --cap-add BPF <code class="se">\</code>
  --cap-add SYS_PTRACE <code class="se">\</code>
  --pid<code class="o">=</code>host <code class="se">\</code>
  <code class="k">$(</code>ls /dev/falco* <code class="p">|</code> xargs -I <code class="o">{}</code> <code class="nb">echo</code> --device <code class="o">{}</code><code class="k">)</code> <code class="se">\</code>
  -v /var/run/docker.sock:/var/run/docker.sock <code class="se">\</code>
  falcosecurity/falco-no-driver:latest</pre>
<pre data-type="programlisting" data-code-language="bash" class="small no-indent">
DEMO    13:07:48.722501295: Notice A shell was spawned in a container with an attached terminal
  <code class="o">(</code><code class="nv">user</code><code class="o">=</code>root <code class="nv">user_loginuid</code><code class="o">=</code>-1 &lt;NA&gt; <code class="o">(</code><code class="nv">id</code><code class="o">=</code>52af6056d922<code class="o">)</code> <code class="nv">shell</code><code class="o">=</code>sh <code class="nv">parent</code><code class="o">=</code>&lt;NA&gt;
  <code class="nv">cmdline</code><code class="o">=</code>sh -c <code class="nb">unset</code> <code class="k">$(</code>env <code class="p">|</code> grep -Eo <code class="s1">'.*VERSION[^\=]*'</code><code class="k">)</code> <code class="o">&amp;&amp;</code> <code class="nb">exec </code>bash <code class="nv">terminal</code><code class="o">=</code>34816
  <code class="nv">container_id</code><code class="o">=</code>52af6056d922 <code class="nv">image</code><code class="o">=</code>&lt;NA&gt;<code class="o">)</code>
</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Falco is based on Sysdig, a system introspection tool. Sysdig Cloud offers workload and Kubernetes performance monitoring,
and <a href="https://oreil.ly/S6q1e">Sysdig Secure</a> is the commercial product built around Falco.</p>
</div>

<p>Falco comes with a collection of <a href="https://oreil.ly/T43NW">community contributed and maintained rules</a>, including dedicated
rules to manage Kubernetes clusters:</p>

<ul>
<li>
<p>Unexpected inbound TCP connections:</p>

<ul>
<li>
<p>Detects inbound TCP traffic to Kubernetes components from a port outside of an expected set</p>
</li>
<li>
<p>Allowed inbound ports:</p>

<ul>
<li>
<p><code>6443</code> (<code>kube-apiserver</code> container)</p>
</li>
<li>
<p><code>10252</code> (<code>kube-controller</code> container)</p>
</li>
<li>
<p><code>8443</code> (<code>kube-dashboard</code> container)</p>
</li>
<li>
<p><code>10053</code>, <code>10055</code>, <code>8081</code> (<code>kube-dns</code> container)</p>
</li>
<li>
<p><code>10251</code> (<code>kube-scheduler</code> container)</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Unexpected spawned processes:</p>

<ul>
<li>
<p>Detects a process started in a Kubernetes cluster outside of an expected set</p>
</li>
<li>
<p>Allowed processes:</p>

<ul>
<li>
<p><code>kube-apiserver</code> (for <code>kube-apiserver</code> container)</p>
</li>
<li>
<p><code>kube-controller-manager</code> (for <code>kube-controller</code> container)</p>
</li>
<li>
<p><code>/dashboard</code> (<code>kube-dashboard</code> container)</p>
</li>
<li>
<p><code>/kube-dns</code> (<code>kube-dns</code> container)</p>
</li>
<li>
<p><code>kube-scheduler</code> (<code>kube-scheduler</code> container)</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Unexpected file access readonly:</p>

<ul>
<li>
<p>Detects an attempt to access a file in readonly mode, other than those in an expected list of directories</p>
</li>
<li>
<p>Allowed file prefixes for readonly:</p>

<ul>
<li>
<p><code>/public</code></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>

<p>These rules form a useful base set to extend with custom rules for your own cluster’s specific security<a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="Falco" data-startref="IDS_falco" id="idm45302807965344"/><a data-type="indexterm" data-primary="Falco" data-startref="falco" id="idm45302807964032"/> needs.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>While it’s almost always better to consume community contributed rules, no software is free of bugs. For example, Darkbit found
a <a href="https://oreil.ly/wgZy7">Falco rule bypass</a> that exploited a loose regex rule to deploy a custom
privileged agent container—<code>docker.io/my-org-name-that-ends-with-sysdig/agent</code>:</p>
<pre data-type="programlisting" data-code-language="bash" class="small">
- macro: falco_privileged_containers
  condition: <code class="o">(</code>openshift_image or
              user_trusted_containers or
              container.image.repository in <code class="o">(</code>trusted_images<code class="o">)</code> or
              container.image.repository in <code class="o">(</code>falco_privileged_images<code class="o">)</code> or
              container.image.repository startswith istio/proxy_ or
              container.image.repository startswith quay.io/sysdig<code class="o">)</code>
</pre>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Machine Learning Approaches to IDS"><div class="sect1" id="idm45302808138224">
<h1>Machine Learning Approaches to IDS</h1>

<p>Machine learning (ML) replays <a data-type="indexterm" data-primary="machine learning (ML), intrusion detection" id="idm45302807955776"/><a data-type="indexterm" data-primary="ML (machine learning), intrusion detection" id="idm45302807955008"/><a data-type="indexterm" data-primary="IDSs (intrusion detection systems)" data-secondary="machine learning and" id="idm45302807954304"/>the same signals used in other IDS systems through a model, which then predicts whether the
container is compromised.</p>

<p>There are many examples of machine learning IDS available:</p>

<ul>
<li>
<p><a href="https://oreil.ly/gfl98">Aqua Security</a> uses ML-based <a data-type="indexterm" data-primary="Aqua Security" id="idm45302807951040"/>behavioral profiling to analyze and react to behaviors in containers, the network, and hosts.</p>
</li>
<li>
<p><a href="https://oreil.ly/AoLCX">Prisma Cloud</a>’s layer 3 <a data-type="indexterm" data-primary="Prisma Cloud" id="idm45302807948672"/>inter-container firewall learns valid traffic flows between app components with ML.</p>
</li>
<li>
<p><a href="https://oreil.ly/6pooI">Lacework</a> uses unsupervised<a data-type="indexterm" data-primary="Lacework" id="idm45302807946416"/> machine learning for cross-cloud observability and
response to runtime threats.</p>
</li>
<li>
<p><a href="https://accuknox.com">Accuknox</a> uses <a data-type="indexterm" data-primary="Accuknox" id="idm45302807944160"/>unsupervised machine learning to detect instability and discern potential attacks, and “Identity as a Perimeter” for zero-trust network, application, and data protection.</p>
</li>
</ul>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Container Forensics"><div class="sect1" id="container-forensics">
<h1>Container Forensics</h1>

<p>Forensics is <a data-type="indexterm" data-primary="forensics, principles" id="for_princ"/><a data-type="indexterm" data-primary="intrusion detection" data-secondary="forensics, principles" id="ID_for"/><a data-type="indexterm" data-primary="container forensics" id="contfor"/>the art of reconstructing data from incomplete or historical sources. In Linux this involves capturing
process, memory, and filesystem contents to interrogate them offline, find the source or impact of a breach, and
inspect adversarial 
<span class="keep-together">techniques.</span></p>

<p>More advanced systems gather more information, like network connection information they were already logging. In the
event of a serious break, the entire cluster or account may be cut off from the network so that the attacker cannot
continue their assault, and the entire system can be imaged and explored.</p>

<p>Tools like <a href="https://oreil.ly/s4xup">kube-forensics</a> “create checkpoint <a data-type="indexterm" data-primary="kube-forensics" id="idm45302807909792"/>snapshots of the state of running pods for
later off-line analysis,” so malicious workloads can be dumped and killed, and the system returned to use. It runs a
<code>forensics-controller-manager</code> with a <code>PodCheckpoint</code> custom resource definition (CRD) to effectively <code>docker inspect</code>,
<code>docker diff</code>, and finally <code>docker export</code>. Notably, this does not capture the process’s memory, which may have
implants or attacker tools that were not saved to disk or were deleted once the process started.</p>

<p>To capture a <a data-type="indexterm" data-primary="process memory, capturing" id="idm45302807906160"/><a data-type="indexterm" data-primary="intrusion detection" data-secondary="process memory, capturing" id="idm45302807905456"/>process’ memory, you can use standard tools like GDB. Using these tools from inside a container is difficult as symbols may be required. From outside a container, dumping memory and searching it for interesting data is trivial, as this <a href="https://oreil.ly/6eDzc">simple Bash script</a> mashing together <a href="https://oreil.ly/U2ibi">Trufflehog</a> and GDB process dumping demonstrates:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="c">#!/bin/bash</code>
<code class="c">#</code>
<code class="c"># truffleproc — hunt secrets in process memory // 2021 @controlplaneio</code>

<code class="nb">set</code> -Eeuo pipefail

<code class="nv">PID</code><code class="o">=</code><code class="s2">"</code><code class="si">${</code><code class="nv">1</code><code class="k">:-</code><code class="nv">1</code><code class="si">}</code><code class="s2">"</code>
<code class="nv">TMP_DIR</code><code class="o">=</code><code class="s2">"</code><code class="k">$(</code>mktemp -d<code class="k">)</code><code class="s2">"</code>
<code class="nv">STRINGS_FILE</code><code class="o">=</code><code class="s2">"</code><code class="si">${</code><code class="nv">TMP_DIR</code><code class="si">}</code><code class="s2">/strings.txt"</code>
<code class="nv">RESULTS_FILE</code><code class="o">=</code><code class="s2">"</code><code class="si">${</code><code class="nv">TMP_DIR</code><code class="si">}</code><code class="s2">/results.txt"</code>

<code class="nv">CONTAINER_IMAGE</code><code class="o">=</code><code class="s2">"controlplane/build-step-git-secrets"</code>
<code class="nv">CONTAINER_SHA</code><code class="o">=</code><code class="s2">"51cfc58382387b164240501a482e30391f46fa0bed317199b08610a456078fe7"</code>
<code class="nv">CONTAINER</code><code class="o">=</code><code class="s2">"</code><code class="si">${</code><code class="nv">CONTAINER_IMAGE</code><code class="si">}</code><code class="s2">@sha256:</code><code class="si">${</code><code class="nv">CONTAINER_SHA</code><code class="si">}</code><code class="s2">"</code>

main<code class="o">()</code> <code class="o">{</code>
  ensure_sudo

  <code class="nb">echo</code> <code class="s2">"# coredumping pid </code><code class="si">${</code><code class="nv">PID</code><code class="si">}</code><code class="s2">"</code>

  coredump_pid

  <code class="nb">echo</code> <code class="s2">"# extracting strings to </code><code class="si">${</code><code class="nv">TMP_DIR</code><code class="si">}</code><code class="s2">"</code>

  extract_strings_from_coredump

  <code class="nb">echo</code> <code class="s2">"# finding secrets"</code>

  find_secrets_in_strings <code class="o">||</code> <code class="nb">true</code>

<code class="nb">  echo</code> <code class="s2">"# results in </code><code class="si">${</code><code class="nv">RESULTS_FILE</code><code class="si">}</code><code class="s2">"</code>

  less -N -R <code class="s2">"</code><code class="si">${</code><code class="nv">RESULTS_FILE</code><code class="si">}</code><code class="s2">"</code>
<code class="o">}</code>

ensure_sudo<code class="o">()</code> <code class="o">{</code>
  sudo touch /dev/null
<code class="o">}</code>

coredump_pid<code class="o">()</code> <code class="o">{</code>
  <code class="nb">cd</code> <code class="s2">"</code><code class="si">${</code><code class="nv">TMP_DIR</code><code class="si">}</code><code class="s2">"</code>

  sudo grep -Fv <code class="s2">".so"</code> <code class="s2">"/proc/</code><code class="si">${</code><code class="nv">PID</code><code class="si">}</code><code class="s2">/maps"</code> <code class="p">|</code> awk <code class="s1">'/ 0 /{print $1}'</code> <code class="p">|</code> <code class="o">(</code>
    <code class="nv">IFS</code><code class="o">=</code><code class="s2">"-"</code>
    <code class="k">while</code> <code class="nb">read</code> -r START END<code class="p">;</code> <code class="k">do</code>
      <code class="nv">START_ADDR</code><code class="o">=</code><code class="k">$(</code><code class="nb">printf</code> <code class="s2">"%llu"</code> <code class="s2">"0x</code><code class="si">${</code><code class="nv">START</code><code class="si">}</code><code class="s2">"</code><code class="k">)</code>
      <code class="nv">END_ADDR</code><code class="o">=</code><code class="k">$(</code><code class="nb">printf</code> <code class="s2">"%llu"</code> <code class="s2">"0x</code><code class="si">${</code><code class="nv">END</code><code class="si">}</code><code class="s2">"</code><code class="k">)</code>
      sudo gdb <code class="se">\</code>
        --quiet <code class="se">\</code>
        --readnow <code class="se">\</code>
        --pid <code class="s2">"</code><code class="si">${</code><code class="nv">PID</code><code class="si">}</code><code class="s2">"</code> <code class="se">\</code>
        -ex <code class="s2">"dump memory </code><code class="si">${</code><code class="nv">PID</code><code class="si">}</code><code class="s2">_mem_</code><code class="si">${</code><code class="nv">START</code><code class="si">}</code><code class="s2">.bin </code><code class="si">${</code><code class="nv">START_ADDR</code><code class="si">}</code><code class="s2"> </code><code class="si">${</code><code class="nv">END_ADDR</code><code class="si">}</code><code class="s2">"</code> <code class="se">\</code>
        -ex <code class="s2">"set confirm off"</code> <code class="se">\</code>
        -ex <code class="s2">"set exec-file-mismatch off"</code> <code class="se">\</code>
        -ex quit od <code class="p">|&amp;</code> grep -E <code class="s2">"^Reading symbols from"</code>
    <code class="k">done</code> <code class="p">|</code> awk-unique
  <code class="o">)</code>
<code class="o">}</code>

extract_strings_from_coredump<code class="o">()</code> <code class="o">{</code>
  strings <code class="s2">"</code><code class="si">${</code><code class="nv">TMP_DIR</code><code class="si">}</code><code class="s2">"</code>/*.bin &gt;<code class="s2">"</code><code class="si">${</code><code class="nv">STRINGS_FILE</code><code class="si">}</code><code class="s2">"</code>
<code class="o">}</code>

find_secrets_in_strings<code class="o">()</code> <code class="o">{</code>
  <code class="nb">local </code>DATE MESSAGE
  <code class="nv">DATE</code><code class="o">=</code><code class="s2">"(</code><code class="k">$(</code>date --utc +%FT%T.%3NZ<code class="k">)</code><code class="s2">)"</code>
  <code class="nv">MESSAGE</code><code class="o">=</code><code class="s2">"for pid </code><code class="si">${</code><code class="nv">PID</code><code class="si">}</code><code class="s2">"</code>

  <code class="nb">cd</code> <code class="s2">"</code><code class="si">${</code><code class="nv">TMP_DIR</code><code class="si">}</code><code class="s2">"</code>
  git init --quiet
  git add <code class="s2">"</code><code class="si">${</code><code class="nv">STRINGS_FILE</code><code class="si">}</code><code class="s2">"</code>
  git -c commit.gpgsign<code class="o">=</code><code class="nb">false </code>commit <code class="se">\</code>
    -m <code class="s2">"Coredump of strings </code><code class="si">${</code><code class="nv">MESSAGE</code><code class="si">}</code><code class="s2">"</code> <code class="se">\</code>
    -m <code class="s2">"https://github.com/controlplaneio/truffleproc"</code> <code class="se">\</code>
    --quiet

  <code class="nb">echo</code> <code class="s2">"# </code><code class="si">${</code><code class="nv">0</code><code class="si">}</code><code class="s2"> results </code><code class="si">${</code><code class="nv">MESSAGE</code><code class="si">}</code><code class="s2"> </code><code class="si">${</code><code class="nv">DATE</code><code class="si">}</code><code class="s2"> | @controlplaneio"</code> &gt;&gt;<code class="s2">"</code><code class="si">${</code><code class="nv">RESULTS_FILE</code><code class="si">}</code><code class="s2">"</code>

  docker run -i -e <code class="nv">IS_IN_AUTOMATION</code><code class="o">=</code> <code class="se">\</code>
    -v <code class="s2">"</code><code class="k">$(</code>git rev-parse --show-toplevel<code class="k">)</code><code class="s2">:/workdir:ro"</code> <code class="se">\</code>
    -w /workdir <code class="se">\</code>
    <code class="s2">"</code><code class="si">${</code><code class="nv">CONTAINER</code><code class="si">}</code><code class="s2">"</code> <code class="se">\</code>
    bash <code class="p">|&amp;</code> <code class="nb">command </code>grep -P <code class="s1">'\e\['</code> <code class="p">|</code> awk-unique &gt;&gt; <code class="s2">"</code><code class="si">${</code><code class="nv">RESULTS_FILE</code><code class="si">}</code><code class="s2">"</code>
<code class="o">}</code>

awk-unique<code class="o">()</code> <code class="o">{</code>
  awk <code class="s1">'!x[$0]++'</code>
<code class="o">}</code>

main <code class="s2">"</code><code class="si">${</code><code class="p">@</code><code class="k">:-</code><code class="si">}</code><code class="s2">"</code></pre>

<p>Put this script into <em>procdump.sh</em> and run it against a local shell:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>procdump.sh <code class="k">$(</code>pgrep -f bash<code class="k">)</code></pre>

<p>You will see any high entropy strings or suspected secrets that were loaded into the shell:</p>

<pre data-type="programlisting"> 1 # procdump.sh results for pid 5598 (2021-02-23 08:58:54.972Z) | @controlplaneio
 2 Reason: High Entropy
 3 Date: 2021-02-23 08:58:54
 4 Hash: 699776ae32d13685afca891b0e9ae2f1156d2473
 5 Filepath: strings.txt
 6 Branch: origin/master
 7 Commit: WIP
 8
 9 +SECRET_KEY=c0dd1e1eaf1e757e55e118fea7caba55e7105e51eaf1e55c0caa1d05efa57e57
10 +GH_API_TOKEN=1abb1ebab1e5e1ec7ed5c07f1abe118b0071e551005edf1a710c8c10aca5ca1d</pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>An attacker as<a data-type="indexterm" data-primary="namespaces" data-secondary="dumping memory" id="idm45302807671680"/><a data-type="indexterm" data-primary="memory" data-secondary="dumping" id="idm45302807636720"/> root in a process namespace can dump the memory of any other process in the namespace. The root
user in the host process namespace can dump any process memory on the node (including child namespaces).</p>
</div>

<p>Avoid this type of attack in a <a data-type="indexterm" data-primary="cloud" data-secondary="native applications" data-tertiary="attacks on secrets" id="idm45302807634912"/>cloud native application by retrieving secrets at time of use from a filesystem or key
management system. If you can discard the Secrets from memory when not in use, you’ll be more resilient to this attack.
You can also encrypt Secrets in memory, although the decryption keys suffer the same risk of being dumped and so should
also be discarded when not <a data-type="indexterm" data-primary="forensics, principles" data-startref="for_princ" id="idm45302807633168"/><a data-type="indexterm" data-primary="intrusion detection" data-secondary="forensics, principles" data-startref="ID_for" id="idm45302807632224"/><a data-type="indexterm" data-primary="container forensics" data-startref="contfor" id="idm45302807631008"/>in<a data-type="indexterm" data-primary="honeypots, attack defense" id="honey_atakdef"/><a data-type="indexterm" data-primary="attacks" data-secondary="honeypots and" id="atak_honey"/> use.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Honeypots"><div class="sect1" id="idm45302807942000">
<h1>Honeypots</h1>
<div class="clear">
<figure class="informal no-frame width-35"><div id="captain7" class="figure">
<img src="Images/haku_0000.png" alt="captain" width="1086" height="1103"/>
<h6/>
</div></figure>
<p>Although IDS can detect and prevent almost all abuses of your systems, we cannot emphasize enough that there is no such
thing as a silver bullet. It should be assumed that rogue sea dogs like Captain Hashjack will still be able to bypass
any careful security configuration. A complex system offers asymmetrical advantage for an attacker: a defender only
has to make one mistake to get compromised.</p>
</div>

<p>Attackers may still be able to escape from a container or traverse onto the host. Or, if they’re in a container
governed by IDS and manipulates the expected behavior of the application (for example, by invoking the same application
with different flags), they may be able to read sensitive data without triggering IDS alarms.</p>

<p>So the last line of defense is the humble honeypot, a simple server or file that legitimate applications never use. It
innocuously nestles in a tempting or secured location and triggers an alert when an attacker accesses it. Honeypots
might be triggered by a network scan, or HTTP requests that the system would never usually make.</p>

<p><a data-type="xref" href="#ids-honeypot-architecture">Figure 9-1</a> shows BCTL’s honeypot entrapping Dread Pirate Hashjack. A honeypot such as this one is as simple as using tools like <a href="https://oreil.ly/L1bSu">ElastAlert</a> to monitor, audit, and access logs for pods that should never be accessed.</p>

<figure><div id="ids-honeypot-architecture" class="figure">
<img src="Images/haku_0901.png" alt="Catching an attacker in a Honeypot" width="1453" height="962"/>
<h6><span class="label">Figure 9-1. </span>Catching an attacker in a honeypot</h6>
</div></figure>

<p>You are looking to catch an attacker operating inside the pod network. They may scan local IP ranges for open TCP and UDP
ports. Remember that each  Kubernetes workload must be identical, so we can’t run “custom” pods to deploy a single
honeypot. Instead, deploy a dedicated DaemonSet so each node is defended by a honeypot pod.</p>

<p>If the attacker or internal actor has cluster DNS access, can read a pod’s environment variables, or has read access to
the Kubernetes API, they can see the names of the Kubernetes services in the DNS and pod names. They may be looking for
a specifically named target. You can name your honeypot service with an appealingly similar name (such as “myapp-data”
or “myapp-support”) to entice an attacker. Deploying honeypots as a DaemonSet will ensure one is lying in wait on any
node Captain Hashjack might<a data-type="indexterm" data-primary="honeypots, attack defense" data-startref="honey_atakdef" id="idm45302807662496"/><a data-type="indexterm" data-primary="attacks" data-secondary="honeypots and" data-startref="atak_honey" id="idm45302807661456"/> plunder.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a href="https://oreil.ly/1E7Eo">Canary tokens</a> are<a data-type="indexterm" data-primary="canary tokens" id="idm45302807658544"/> honeypots for protocols like AWS and Slack keys, URLs, DNS records,
QR codes, email addresses, documents, and binaries. They are “tiny tripwires” that you can drop in production systems
and developer devices to detect compromise.</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Auditing"><div class="sect1" id="idm45302807657168">
<h1>Auditing</h1>

<p>As discussed in <a data-type="xref" href="ch08.xhtml#ch-policy">Chapter 8</a>, Kubernetes<a data-type="indexterm" data-primary="auditing" data-secondary="CVEs" id="aud_CVE"/><a data-type="indexterm" data-primary="CVEs (Common Vulnerabilities and Exposures)" data-secondary="audit logs" id="CVE_aud"/><a data-type="indexterm" data-primary="security" data-secondary="CVEs" data-tertiary="audit logs" id="sec_CVE_aud"/> generates audit logs for every API request it
receives, and IDS tools can ingest and monitor that stream of information for unexpected requests. This could include
requests from outside known IP ranges or expected working hours, honeytoken credentials, or attempts to use unauthorized
APIs (e.g., a default service account token attempting to get all Secrets in its namespace or a privileged namespace).</p>

<p>Audit log level and depth is configurable, but as CVE-2020-8563 for Kubernetes v1.19.2 (and CVE-2020-8564, CVE-2020-8565,
CVE-2020-8566) shows, defaults were not historically tight enough. Some sensitive request payload information was

<span class="keep-together">persisted to</span> logs that could have been read from outside the cluster and then used to attack it.</p>

<p>Unintended data leakage into logs is being mitigated in
<a href="https://oreil.ly/5iuMK">KEP 1753</a>:</p>
<blockquote>
<p>This KEP proposes the introduction of a logging filter which could be applied to all Kubernetes system components logs
to prevent various types of sensitive information from leaking via logs…Ensure that sensitive data cannot be trivially
stored in logs. Prevent dangerous logging actions with improved code review policies. Redact sensitive information with
logging filters. Together, these actions can help to prevent sensitive data from being exposed in the logs.</p></blockquote>

<p>It can be used with the <code>kubelet</code> flag <code>--experimental-logging-sanitization</code> in v1.20+.</p>

<p>Leaking Secrets into logs and audit streams is common in all technology organizations, and is another reason to avoid
environment variables for sensitive information. Developers need introspection and useful output from running programs,
but sanitizing debug during development is a rare practice. These debug strings invariably make their way into
production, and so searching logs for Secrets is perhaps the only practical way to detect <a data-type="indexterm" data-primary="auditing" data-secondary="CVEs" data-startref="aud_CVE" id="idm45302807466560"/><a data-type="indexterm" data-primary="CVEs (Common Vulnerabilities and Exposures)" data-secondary="audit logs" data-startref="CVE_aud" id="idm45302807465312"/><a data-type="indexterm" data-primary="security" data-secondary="CVEs" data-tertiary="audit logs" data-startref="sec_CVE_aud" id="idm45302807464064"/>this.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The bugs that gave momentum to the log sanitization focus include:</p>
<dl>
<dt>CVE-2020-8563</dt>
<dd>
<p>Secret leaks in logs for vSphere Provider kube-controller-manager</p>
</dd>
<dt>CVE-2020-8564</dt>
<dd>
<p>Docker config Secrets leaked when file is malformed and <code>logLevel</code> &gt;= 4</p>
</dd>
<dt>CVE-2020-8565</dt>
<dd>
<p>Incomplete fix for CVE-2019-11250 allows for token leak in logs when <code>logLevel</code> &gt;= 9</p>
</dd>
<dt>CVE-2020-8566</dt>
<dd>
<p>Ceph RBD adminSecrets exposed in logs when <code>logLevel</code> &gt;= 4</p>
</dd>
</dl>

<p>You can read the disclosure on the
<a href="https://oreil.ly/yBvQu">Kubernetes Forums</a>.</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Detection Evasion"><div class="sect1" id="idm45302807452944">
<h1>Detection Evasion</h1>

<p>Bypassing Kubernetes audit logs was <a data-type="indexterm" data-primary="auditing" data-secondary="evading detection" id="idm45302807451392"/><a data-type="indexterm" data-primary="intrusion detection" data-secondary="audit logs, evading" id="idm45302807450416"/>demonstrated by <a href="https://oreil.ly/KaOWm">Brad Geesaman</a> and
<a href="https://oreil.ly/KMK0u">Ian Coldwater</a> at <a href="https://oreil.ly/LfzS0">RSA 2020</a>.
As <a data-type="xref" href="#ids-oversized-logs">Figure 9-2</a> shows, the <code>etcd</code> datastore in the Kubernetes control plane is highly efficient and resillient,
however it does not support large data sizes. That means request payloads in the audit logs that exceed 256 KB will not
get stored, enabling stealthy behavior with oversized log entries.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>An attacker with access to the API server can blackhole, redirect, or tamper with any audit logs that are stored locally.
As a post-mortem exercise it’s useful to explore an attacker’s path, so shipping the API server’s audit logs directly to a remote
 webhook backend safeguards against this. Configure the API server to use the flag 
<span class="keep-together"><code>--audit-webhook-config-file</code></span> to ship logs remotely, or use a managed service that configures this for you.</p>
</div>

<figure><div id="ids-oversized-logs" class="figure">
<img src="Images/haku_0902.png" alt="haku 0902" width="1431" height="1465"/>
<h6><span class="label">Figure 9-2. </span>Oversize <code>etcd</code> logs (<a href="https://oreil.ly/LfzS0">RSA 2020</a>)</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Security Operations Centers"><div class="sect1" id="idm45302807439984">
<h1>Security Operations Centers</h1>

<p>Larger organizations may have a Security Operations Center (SOC)<a data-type="indexterm" data-primary="Security Operations Center (SOC)" data-secondary="audit logs and" id="idm45302807438656"/><a data-type="indexterm" data-primary="SOC (Security Operations Center)" data-secondary="audit logs and" id="idm45302807437664"/><a data-type="indexterm" data-primary="auditing" data-secondary="SOCs and" id="idm45302807436704"/> that manages security information and events (SIEM).</p>

<p>Configuring enterprise applications for alerting on your audit and pod logs requires fine-tuning to avoid false
positives and needless alerts. You can use a local cluster to build out automated tests and capture the audit log
events, then use that data to configure your SIEM. Finally, rerun your automated tests to ensure alerts are raised
correctly in production systems.</p>

<p>You should run Red Team security tests against production systems to validate the Blue Team controls work as expected.
This provides a real-world test for the attack trees and threat models that the system is configured upon.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="idm45302807433888">
<h1>Conclusion</h1>

<p>Intrusion detection is the last line of defense for a cloud native system. eBPF approaches offer greater speed on
modern kernels, and the performance overhead is slight. Sensitive or web-facing workloads should always be guarded by IDS
as they have the greatest risk of compromise.</p>

<p>With this we’re switching gears and will turn our attention to the weakest link
and its natural habitat: organizations.</p>
</div></section>







</div></section></div></body></html>