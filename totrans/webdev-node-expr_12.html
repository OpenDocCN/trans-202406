<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 12. Production Concerns"><div class="chapter" id="ch_production_concerns">
<h1><span class="label">Chapter 12. </span>Production Concerns</h1>


<p><a data-type="indexterm" data-primary="production concerns" id="ix_ch-12-production_concerns-asciidoc0"/>While it may feel premature to start discussing production concerns at this
point, you can save yourself a lot of time and suffering down the line if
you start thinking about production early on. Launch day will be here
before you know it.</p>

<p>In this chapter, you’ll learn about Express’s support for different
execution environments, methods to scale your website, and how to monitor
your website’s health. You’ll see how you can simulate a production
environment for testing and development and also how to perform stress
testing so you can identify production problems before they happen.</p>






<section data-type="sect1" data-pdf-bookmark="Execution Environments"><div class="sect1" id="idm45053587404104">
<h1>Execution Environments</h1>

<p><a data-type="indexterm" data-primary="execution environments" id="idm45053587461624"/><a data-type="indexterm" data-primary="production concerns" data-secondary="execution environments" id="idm45053587460888"/>Express supports the concept of <em>execution environments</em>: a way to run your
application in production, development, or test mode. You
could actually have as many different environments as you want. For
example, you could have a staging environment, or a training environment.
However, keep in mind that development, production, and test are “standard”
environments, and both Express and third-party middleware often make decisions
based on those environments. In other words, if you have a “staging”
environment, there’s no way to make it automatically inherit the properties
of a production environment. For this reason, I recommend you stick with
the standards of production, development, and test.</p>

<p>While it is possible to specify the execution environment by
calling <code>app.set('env', \'production')</code>, it is inadvisable to do so; it
means your app will always run in that environment, no matter what the
situation. Worse, it may start running in one environment and then switch
to another.</p>

<p>It’s preferable to specify the execution environment by
using the environment variable <code>NODE_ENV</code>. Let’s modify
our app to report on the mode it’s running in by calling <code>app.get('env’)</code>:</p>

<pre data-type="programlisting" data-code-language="js"><code class="kr">const</code> <code class="nx">port</code> <code class="o">=</code> <code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code> <code class="o">||</code> <code class="mi">3000</code>
<code class="nx">app</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="nx">port</code><code class="p">,</code> <code class="p">()</code> <code class="o">=&gt;</code> <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`Express started in `</code> <code class="o">+</code>
  <code class="sb">`</code><code class="si">${</code><code class="nx">app</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'env'</code><code class="p">)</code><code class="si">}</code><code class="sb"> mode at http://localhost:</code><code class="si">${</code><code class="nx">port</code><code class="si">}</code><code class="sb">`</code> <code class="o">+</code>
  <code class="sb">`; press Ctrl-C to terminate.`</code><code class="p">))</code></pre>

<p>If you start your server now, you’ll see you’re running in development
mode; it’s the default if you don’t specify otherwise. Let’s try
putting it in production mode:</p>

<pre data-type="programlisting">$ export NODE_ENV=production
$ node meadowlark.js</pre>

<p>If you’re using Unix/BSD, there’s a handy syntax that allows you to
modify the environment only for the duration of that command:</p>

<pre data-type="programlisting">$ NODE_ENV=production node meadowlark.js</pre>

<p>This will run the server in production mode, but once the server
terminates, the <code>NODE_ENV</code> environment variable won’t be modified. I’m
particularly fond of this shortcut, and it reduces the chance that I
accidentally leave environment variables set to values that I don’t
necessarily want for everything.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you start Express in production mode, you may notice warnings about
components that are not suitable for use in production mode. If you’ve
been following along with the examples in this book, you’ll see that
<code>connect.session</code> is using a memory store, which is not suitable for a
production environment. Once we switch to a database store in
<a data-type="xref" href="ch13.xhtml#ch_persistence">Chapter 13</a>, this warning will <span class="keep-together">disappear</span>.</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Environment-Specific Configuration"><div class="sect1" id="idm45053587403480">
<h1>Environment-Specific Configuration</h1>

<p><a data-type="indexterm" data-primary="environment-specific configuration" id="ix_ch-12-production_concerns-asciidoc1"/><a data-type="indexterm" data-primary="execution environments" id="ix_ch-12-production_concerns-asciidoc2"/><a data-type="indexterm" data-primary="production concerns" data-secondary="environment-specific configuration" id="ix_ch-12-production_concerns-asciidoc3"/>Just changing the execution environment won’t do much, though Express will
log more warnings to the console in production mode (for example, informing
you of modules that are deprecated and will be removed in the
future).
Also, in production mode, view caching is enabled by default (see
<a data-type="xref" href="ch07.xhtml#ch_templating">Chapter 7</a>).</p>

<p>Mainly, the execution environment is a tool for you to leverage, allowing
you to easily make decisions about how your application should behave in
the different environments. As a word of caution, you should try to
minimize the differences between your development, test, and production
environments. That is, you should use this feature sparingly. If your
development or test environments differ wildly from production, you are
increasing your chances of different behavior in production, which is a
recipe for more defects (or harder-to-find ones). Some differences are
inevitable; for example, if your app is highly database driven, you
probably don’t want to be messing with the production database during
development, and that would be a good candidate for environment-specific
configuration. Another low-impact area is more verbose logging. There are
a lot of things you might want to log in development that are unnecessary
to record in production.</p>

<p><a data-type="indexterm" data-primary="logging" id="idm45053587167768"/>Let’s add some logging to our server. The twist is that we want different
behavior for production and development. For development, we can leave the
defaults, but for production, we want to log to a file. <a data-type="indexterm" data-primary="morgan middleware" id="idm45053587166712"/>We’ll use
<code>morgan</code> (don’t forget <code>npm install morgan</code>), which is the most common
logging middleware (<em>ch12/00-logging.js</em> in the companion repo):</p>

<pre data-type="programlisting" data-code-language="js"><code class="kr">const</code> <code class="nx">morgan</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'morgan'</code><code class="p">)</code>
<code class="kr">const</code> <code class="nx">fs</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'fs'</code><code class="p">)</code>

<code class="k">switch</code><code class="p">(</code><code class="nx">app</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'env'</code><code class="p">))</code> <code class="p">{</code>
  <code class="k">case</code> <code class="s1">'development'</code><code class="o">:</code>
    <code class="nx">app</code><code class="p">.</code><code class="nx">use</code><code class="p">(</code><code class="nx">morgan</code><code class="p">(</code><code class="s1">'dev'</code><code class="p">))</code>
    <code class="k">break</code>
  <code class="k">case</code> <code class="s1">'production'</code><code class="o">:</code>
    <code class="kr">const</code> <code class="nx">stream</code> <code class="o">=</code> <code class="nx">fs</code><code class="p">.</code><code class="nx">createWriteStream</code><code class="p">(</code><code class="nx">__dirname</code> <code class="o">+</code> <code class="s1">'/access.log'</code><code class="p">,</code>
      <code class="p">{</code> <code class="nx">flags</code><code class="o">:</code> <code class="s1">'a'</code> <code class="p">})</code>
    <code class="nx">app</code><code class="p">.</code><code class="nx">use</code><code class="p">(</code><code class="nx">morgan</code><code class="p">(</code><code class="s1">'combined'</code><code class="p">,</code> <code class="p">{</code> <code class="nx">stream</code> <code class="p">}))</code>
    <code class="k">break</code>
<code class="p">}</code></pre>

<p>If you start the server as you normally would (<code>node meadowlark.js</code>) and
visit the site, you’ll see the activity logged to the console. To see how
the application behaves in production mode, run it with
<code>NODE_ENV=production</code> instead. Now if you visit the application, you won’t
see any activity on the terminal (probably what we want for a production
server), but all of the activity is logged in
<a href="http://bit.ly/2NGC592">Apache’s Combined
Log Format</a>, which is a staple for many server tools.</p>

<p>We accomplished this by creating an appendable (<code>{ flags: <em>a</em> }</code>) write
stream and passing it to the morgan configuration. Morgan has many
options; to see them all, check out the
<a href="http://bit.ly/32H5wMr">morgan documentation</a>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In the previous example, we’re using <code>__dirname</code> to store the request log in a subdirectory of the project itself. If you take this approach, you
will want to add <code>log</code> to your <em>.gitignore</em> file. Alternatively, you
could take a more Unix-like approach and save the logs in a subdirectory
of <em>/var/log</em>, as Apache does by default.</p>
</div>

<p>I will stress again that you should use your best judgment when making
environment-specific configuration choices. Always keep in mind that
when your site is live, your production instances will be running in
<code>production</code> mode (or they should be). Whenever you’re tempted to make a
development-specific modification, you should always think first about how
that might have QA consequences in production. We’ll see a more robust
example of environment-specific configuration in <a data-type="xref" href="ch13.xhtml#ch_persistence">Chapter 13</a>.<a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc3" id="idm45053587041784"/><a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc2" id="idm45053587041112"/><a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc1" id="idm45053587040424"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Running Your Node Process"><div class="sect1" id="idm45053587039608">
<h1>Running Your Node Process</h1>

<p><a data-type="indexterm" data-primary="production concerns" data-secondary="running your Node process" id="idm45053587038072"/>So far, we’ve been running our application by invoking it directly with
<code>node</code> (for example, <code>node meadowlark.js</code>). This is fine for development
and testing, but it has disadvantages for production. Notably, there are
no protections if your app crashes or gets terminated. <a data-type="indexterm" data-primary="process managers" id="idm45053587035944"/>A robust <em>process
manager</em> can address this problem.</p>

<p>Depending on your hosting solution, you may not need a process manager if
one is provided by the hosting solution itself. That is, the hosting
provider will give you a configuration option to point to your application
file, and it will handle the process management.</p>

<p>But if you need to manage the process yourself, there are two popular
options for process managers:<a data-type="indexterm" data-primary="Forever" id="idm45053587033464"/><a data-type="indexterm" data-primary="PM2" id="idm45053587032760"/></p>

<ul>
<li>
<p><a href="https://github.com/foreversd/forever">Forever</a></p>
</li>
<li>
<p><a href="https://github.com/Unitech/pm2">PM2</a></p>
</li>
</ul>

<p>Since production environments can vary widely, we won’t go into the
specifics of setting up and configuring a process manager. Both Forever
and PM2 have excellent documentation, and you can install and use them on
your development machine to learn how to configure them.</p>

<p>I have used them both, and I don’t have a strong preference. Forever is a
little more straightforward and easy to get started, and PM2 offers more
features.</p>

<p>If you want to experiment with a process manager without investing a lot of
time, I recommend giving Forever a try. You can try it in two steps.
First, install Forever:</p>

<pre data-type="programlisting">npm install -g forever</pre>

<p>Then, start your application with Forever (run this from your application
root):</p>

<pre data-type="programlisting">forever start meadowlark.js</pre>

<p>Your application is now running…and it will stay running even if you
close your terminal window! You can restart the process with <code>forever
restart meadowlark.js</code> and stop it with <code>forever stop meadowlark.js</code>.</p>

<p>Getting started with PM2 is a little more involved but is worth looking
into if you need to use your own process manager for production.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Scaling Your Website"><div class="sect1" id="idm45053587039080">
<h1>Scaling Your Website</h1>

<p><a data-type="indexterm" data-primary="production concerns" data-secondary="scaling your website" id="ix_ch-12-production_concerns-asciidoc4"/><a data-type="indexterm" data-primary="scaling out" data-secondary="website" id="ix_ch-12-production_concerns-asciidoc5"/><a data-type="indexterm" data-primary="websites" data-secondary="scaling" id="ix_ch-12-production_concerns-asciidoc6"/>These days, scaling usually means one of two things: scaling up or scaling
out. <a data-type="indexterm" data-primary="scaling out" data-secondary="scaling up versus" id="idm45053587018056"/><em>Scaling up</em> refers to making servers more
powerful: faster CPUs, better architecture, more cores, more memory, etc.
 <em>Scaling out</em>, on the other hand, simply means more
servers. With the increased popularity of cloud computing and the ubiquity
of virtualization, server computational power is becoming less relevant,
and scaling out is usually the most cost-effective method for scaling
websites according to your needs.</p>

<p>When developing websites for Node, you should always consider the
possibility of scaling out. Even if
your application is tiny (maybe it’s even an intranet application that will
always have a limited audience) and will never conceivably need to be
scaled out, it’s a good habit to get into. After all, maybe your next Node
project will be the next Twitter, and scaling out will be essential.
Fortunately, Node’s support for scaling out is very good, and writing your
application with this in mind is painless.</p>

<p><a data-type="indexterm" data-primary="persistence" data-secondary="scaling out and" id="idm45053587014648"/>The most important thing to remember when building a
website designed to
be scaled out is persistence. If you’re used to relying on file-based
storage for persistence, <em>stop right there</em>. That way lies madness.</p>

<p>My first experience with this
problem was nearly disastrous. One of our clients was running a web-based
contest, and the web application was designed to inform the first 50
winners that they would receive a prize. With that particular client, we
were unable to easily use a database because of some corporate IT restrictions,
so most persistence was achieved by writing flat files. I proceeded just
as I always had, saving each entry to a file. Once the file had recorded
50 winners, no more people would be notified that they had won. The
problem is that the server was load-balanced, so half the requests were served
by one server, and the other half by another. One server notified 50
people that they had won…and so did the other server. Fortunately, the
prizes were small (fleece blankets) and not something expensive like iPads,
and the client took their lumps and handed out 100 prizes instead of 50 (I
offered to pay for the extra 50 blankets out of pocket for my mistake, but
they generously refused to take me up on my offer).</p>

<p>The moral of this
story is that unless you have a filesystem that’s accessible to <em>all</em> of
your servers, you should not rely on the local filesystem for persistence.
The exceptions are read-only data, like logging, and backups. For example,
I have commonly backed up form submission data to a local flat file in case
the database connection failed. In the case of a database outage, it is a
hassle to go to each server and collect the files, but at least no damage
has been done.</p>








<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Scaling Out with App Clusters"><div class="sect2" id="idm45053587010088">
<h2>Scaling Out with App Clusters</h2>

<p><a data-type="indexterm" data-primary="app clusters, scaling out with" id="ix_ch-12-production_concerns-asciidoc7"/><a data-type="indexterm" data-primary="scaling out" data-secondary="with app clusters" id="ix_ch-12-production_concerns-asciidoc8"/><a data-type="indexterm" data-primary="websites" data-secondary="scaling out with app clusters" id="ix_ch-12-production_concerns-asciidoc9"/>Node itself supports <em>app clusters</em>, a simple, single-server form of
scaling out. With app clusters, you can create an
independent server for each core (CPU) on the system (having more servers
than the number of cores will not improve the performance of your app).
App clusters are good for two reasons: first, they can help maximize the
performance of a given server (the hardware or virtual machine), and
second, it’s a low-overhead way to test your app under parallel conditions.</p>

<p>Let’s go ahead and add cluster support to our website. While it’s quite common to do
all of this work in your main application file, we are going to create a
second application file that will run the app in a cluster, using the
nonclustered application file we’ve been using all along. To enable that,
we have to make a slight modification to <em>meadowlark.js</em> first (see
<em>ch12/01-server.js</em> in the companion repo for a simplified example):</p>

<pre data-type="programlisting" data-code-language="js"><code class="kd">function</code> <code class="nx">startServer</code><code class="p">(</code><code class="nx">port</code><code class="p">)</code> <code class="p">{</code>
  <code class="nx">app</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="nx">port</code><code class="p">,</code> <code class="kd">function</code><code class="p">()</code> <code class="p">{</code>
    <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`Express started in </code><code class="si">${</code><code class="nx">app</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'env'</code><code class="p">)</code><code class="si">}</code><code class="sb"> `</code> <code class="o">+</code>
      <code class="sb">`mode on http://localhost:</code><code class="si">${</code><code class="nx">port</code><code class="si">}</code><code class="sb">`</code> <code class="o">+</code>
      <code class="sb">`; press Ctrl-C to terminate.`</code><code class="p">)</code>
  <code class="p">})</code>
<code class="p">}</code>

<code class="k">if</code><code class="p">(</code><code class="nx">require</code><code class="p">.</code><code class="nx">main</code> <code class="o">===</code> <code class="nx">module</code><code class="p">)</code> <code class="p">{</code>
  <code class="c1">// application run directly; start app server</code>
  <code class="nx">startServer</code><code class="p">(</code><code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code> <code class="o">||</code> <code class="mi">3000</code><code class="p">)</code>
<code class="p">}</code> <code class="k">else</code> <code class="p">{</code>
  <code class="c1">// application imported as a module via "require": export</code>
  <code class="c1">// function to create server</code>
  <code class="nx">module</code><code class="p">.</code><code class="nx">exports</code> <code class="o">=</code> <code class="nx">startServer</code>
<code class="p">}</code></pre>

<p>If you recall from <a data-type="xref" href="ch05.xhtml#ch_qa">Chapter 5</a>, if <code>require.main === module</code>, it means the
script has been run directly; otherwise, it has been called with <code>require</code>
from another script.</p>

<p>Then, we create a new script, <em>meadowlark-cluster.js</em> (see
<em>ch12/01-cluster</em> in the companion repo for a simplified example):</p>

<pre data-type="programlisting" data-code-language="js"><code class="kr">const</code> <code class="nx">cluster</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'cluster'</code><code class="p">)</code>

<code class="kd">function</code> <code class="nx">startWorker</code><code class="p">()</code> <code class="p">{</code>
  <code class="kr">const</code> <code class="nx">worker</code> <code class="o">=</code> <code class="nx">cluster</code><code class="p">.</code><code class="nx">fork</code><code class="p">()</code>
  <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`CLUSTER: Worker </code><code class="si">${</code><code class="nx">worker</code><code class="p">.</code><code class="nx">id</code><code class="si">}</code><code class="sb"> started`</code><code class="p">)</code>
<code class="p">}</code>

<code class="k">if</code><code class="p">(</code><code class="nx">cluster</code><code class="p">.</code><code class="nx">isMaster</code><code class="p">){</code>

  <code class="nx">require</code><code class="p">(</code><code class="s1">'os'</code><code class="p">).</code><code class="nx">cpus</code><code class="p">().</code><code class="nx">forEach</code><code class="p">(</code><code class="nx">startWorker</code><code class="p">)</code>

  <code class="c1">// log any workers that disconnect; if a worker disconnects, it</code>
  <code class="c1">// should then exit, so we'll wait for the exit event to spawn</code>
  <code class="c1">// a new worker to replace it</code>
  <code class="nx">cluster</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'disconnect'</code><code class="p">,</code> <code class="nx">worker</code> <code class="o">=&gt;</code> <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code>
    <code class="sb">`CLUSTER: Worker </code><code class="si">${</code><code class="nx">worker</code><code class="p">.</code><code class="nx">id</code><code class="si">}</code><code class="sb"> disconnected from the cluster.`</code>
  <code class="p">))</code>

  <code class="c1">// when a worker dies (exits), create a worker to replace it</code>
  <code class="nx">cluster</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'exit'</code><code class="p">,</code> <code class="p">(</code><code class="nx">worker</code><code class="p">,</code> <code class="nx">code</code><code class="p">,</code> <code class="nx">signal</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>
    <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code>
      <code class="sb">`CLUSTER: Worker </code><code class="si">${</code><code class="nx">worker</code><code class="p">.</code><code class="nx">id</code><code class="si">}</code><code class="sb"> died with exit `</code> <code class="o">+</code>
      <code class="sb">`code </code><code class="si">${</code><code class="nx">code</code><code class="si">}</code><code class="sb"> (</code><code class="si">${</code><code class="nx">signal</code><code class="si">}</code><code class="sb">)`</code>
    <code class="p">)</code>
    <code class="nx">startWorker</code><code class="p">()</code>
  <code class="p">})</code>

<code class="p">}</code> <code class="k">else</code> <code class="p">{</code>

    <code class="kr">const</code> <code class="nx">port</code> <code class="o">=</code> <code class="nx">process</code><code class="p">.</code><code class="nx">env</code><code class="p">.</code><code class="nx">PORT</code> <code class="o">||</code> <code class="mi">3000</code>
    <code class="c1">// start our app on worker; see meadowlark.js</code>
    <code class="nx">require</code><code class="p">(</code><code class="s1">'./meadowlark.js'</code><code class="p">)(</code><code class="nx">port</code><code class="p">)</code>

<code class="p">}</code></pre>

<p>When this JavaScript is executed, it will be either in the context of
master (when it is run directly, with <code>node meadowlark-cluster.js</code>) or in
the context of a worker, when Node’s cluster system executes it. <a data-type="indexterm" data-primary="cluster.isMaster property" id="idm45053586884360"/><a data-type="indexterm" data-primary="cluster.isWorker property" id="idm45053586883656"/>The
properties <code>cluster.isMaster</code> and <code>cluster.isWorker</code> determine which
context you’re running in. When we run this script, it’s executing in master mode, and
we start a worker using <code>cluster.fork</code> for each CPU in
the system. Also, we respawn any dead workers by listening for <code>exit</code>
events from workers.</p>

<p>Finally, in the <code>else</code> clause, we handle the worker case. Since we
configured <em>meadowlark.js</em> to be used as a module, we simply import it
and immediately invoke it (remember, we exported it as a function that
starts the server).</p>

<p>Now start up your new clustered server:</p>

<pre data-type="programlisting" data-code-language="js"><code class="nx">node</code> <code class="nx">meadowlark</code><code class="o">-</code><code class="nx">cluster</code><code class="p">.</code><code class="nx">js</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you are using virtualization (like Oracle’s VirtualBox), you may have to
configure your VM to have multiple CPUs. By default, virtual machines
often have a single CPU.</p>
</div>

<p>Assuming you’re on a multicore system, you should see some number of
workers started. If you want to see evidence of different workers handling
different requests, add the following middleware before your routes:</p>

<pre data-type="programlisting" data-code-language="js"><code class="kr">const</code> <code class="nx">cluster</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'cluster'</code><code class="p">)</code>

<code class="nx">app</code><code class="p">.</code><code class="nx">use</code><code class="p">((</code><code class="nx">req</code><code class="p">,</code> <code class="nx">res</code><code class="p">,</code> <code class="nx">next</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>
  <code class="k">if</code><code class="p">(</code><code class="nx">cluster</code><code class="p">.</code><code class="nx">isWorker</code><code class="p">)</code>
    <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="sb">`Worker </code><code class="si">${</code><code class="nx">cluster</code><code class="p">.</code><code class="nx">worker</code><code class="p">.</code><code class="nx">id</code><code class="si">}</code><code class="sb"> received request`</code><code class="p">)</code>
  <code class="nx">next</code><code class="p">()</code>
<code class="p">})</code></pre>

<p>Now you can connect to your application with a browser. Reload a few
times and see how you can get a different worker out of the pool on each
request. (You may not be able to; Node is designed to handle large numbers
of connections, and you may not be able to stress it sufficiently simply by
reloading your browser; later we’ll explore stress testing, and you’ll be
able to better see the cluster in action.)<a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc9" id="idm45053586645000"/><a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc8" id="idm45053586644504"/><a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc7" id="idm45053586643896"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Handling Uncaught Exceptions"><div class="sect2" id="idm45053587009464">
<h2>Handling Uncaught Exceptions</h2>

<p><a data-type="indexterm" data-primary="error handling/reporting" data-secondary="uncaught exceptions" id="idm45053586642088"/><a data-type="indexterm" data-primary="exceptions, uncaught" id="idm45053586641048"/><a data-type="indexterm" data-primary="scaling out" data-secondary="handling uncaught exceptions" id="idm45053586640376"/><a data-type="indexterm" data-primary="uncaught exceptions" id="idm45053586639416"/>In the asynchronous world of Node, uncaught exceptions are of particular
concern. Let’s start with a simple example that doesn’t
cause too much trouble (I encourage you to follow along with these
examples):</p>

<pre data-type="programlisting" data-code-language="js"><code class="nx">app</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/fail'</code><code class="p">,</code> <code class="p">(</code><code class="nx">req</code><code class="p">,</code> <code class="nx">res</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>
  <code class="k">throw</code> <code class="k">new</code> <code class="nb">Error</code><code class="p">(</code><code class="s1">'Nope!'</code><code class="p">)</code>
<code class="p">})</code></pre>

<p><a data-type="indexterm" data-primary="route handlers" data-secondary="uncaught exceptions and" id="idm45053586610280"/>When Express executes route handlers, it wraps them in a try/catch block,
so this isn’t actually an uncaught exception. This won’t cause too much of a
problem: Express will log the exception on the server side, and the visitor
will get an ugly stack dump. However, your server is stable, and other
requests will continue to be served correctly. If we want to provide a “nice” error page, create a
file <em>views/500.handlebars</em> and add an error handler after all of your
routes:</p>

<pre data-type="programlisting" data-code-language="js"><code class="nx">app</code><code class="p">.</code><code class="nx">use</code><code class="p">((</code><code class="nx">err</code><code class="p">,</code> <code class="nx">req</code><code class="p">,</code> <code class="nx">res</code><code class="p">,</code> <code class="nx">next</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>
  <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="nx">err</code><code class="p">.</code><code class="nx">message</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">stack</code><code class="p">)</code>
  <code class="nx">app</code><code class="p">.</code><code class="nx">status</code><code class="p">(</code><code class="mi">500</code><code class="p">).</code><code class="nx">render</code><code class="p">(</code><code class="s1">'500'</code><code class="p">)</code>
<code class="p">})</code></pre>

<p>It’s always a good practice to provide a custom error page; it not only looks more professional to your users when errors do occur, but also allows
you to take action when errors occur. For example, this error handler
would be a good place to notify your dev team that an error occurred.
Unfortunately, this helps only for exceptions that Express can catch.
Let’s try something worse:</p>

<pre data-type="programlisting" data-code-language="js"><code class="nx">app</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/epic-fail'</code><code class="p">,</code> <code class="p">(</code><code class="nx">req</code><code class="p">,</code> <code class="nx">res</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>
  <code class="nx">process</code><code class="p">.</code><code class="nx">nextTick</code><code class="p">(()</code> <code class="o">=&gt;</code>
    <code class="k">throw</code> <code class="k">new</code> <code class="nb">Error</code><code class="p">(</code><code class="s1">'Kaboom!'</code><code class="p">)</code>
  <code class="p">)</code>
<code class="p">})</code></pre>

<p>Go ahead and try it. The result is considerably more catastrophic: it
brings your whole server down! In addition to not displaying a friendly
error message to your user, now your server is down, and <em>no</em> requests are
being served. This is because <code>setTimeout</code> is executing
<em>asynchronously</em>; execution of the function with the exception is being
deferred until Node is idle. The problem is, when Node is idle and gets
around to executing the function, it no longer has context about the
request it was being served from, so it has no recourse but to
unceremoniously shut down the whole server, because now it’s in an
undefined state. (Node can’t know the purpose of the function or its
caller, so it can no longer assume that any further functions will work
correctly.)</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a data-type="indexterm" data-primary="process.nextTick" id="idm45053586471432"/><code>process.nextTick</code> is similar to calling <code>setTimeout</code> with an
<span class="keep-together">argument</span> of 0, but it’s more
efficient. We’re using it here for demonstration
purposes; it’s not something you would generally use in server-side code.
However, in coming chapters, we will be dealing with many things that
execute asynchronously, such as database access, filesystem access, and network
access, to name a few, and they are all subject to this problem.</p>
</div>

<p>There is action that we can take to handle uncaught exceptions, but <em>if
Node can’t determine the stability of your application, neither can you</em>.
In other words, if there is an uncaught exception, the only recourse is to
shut down the server. The best we can do in this circumstance is to shut
down as gracefully as possible and have a failover mechanism. The easiest
failover mechanism is to use a cluster. If your application is operating in clustered mode and
one worker dies, the master will spawn another worker to take its place.
(You don’t even need multiple workers; a cluster with one worker
will suffice, though the failover may be slightly slower.)</p>

<p>So with that in mind, how can we shut down as gracefully as possible when
confronted with an unhandled exception? <a data-type="indexterm" data-primary="uncaughtException event" id="idm45053586466792"/>Node’s mechanism for dealing with
this is the <code>uncaughtException</code> event. (Node also has a mechanism called
<em>domains</em>, but this module has been deprecated, and its use is no longer
recommended.)</p>

<pre data-type="programlisting" data-code-language="js"><code class="nx">process</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'uncaughtException'</code><code class="p">,</code> <code class="nx">err</code> <code class="o">=&gt;</code> <code class="p">{</code>
  <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="s1">'UNCAUGHT EXCEPTION\n'</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">stack</code><code class="p">);</code>
  <code class="c1">// do any cleanup you need to do here...close</code>
  <code class="c1">// database connections, etc.</code>
  <code class="nx">process</code><code class="p">.</code><code class="nx">exit</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>
<code class="p">})</code></pre>

<p>It’s unrealistic to expect that your application will never experience
uncaught exceptions, but you should have a mechanism in place to record the
exception and notify you when it happens, and you should take it seriously.
Try to determine why it happened so you can fix it. Services like
<a href="https://sentry.io">Sentry</a>, <a href="https://rollbar.com">Rollbar</a>,
<a href="https://airbrake.io/">Airbrake</a>, and <a href="https://newrelic.com">New Relic</a> are a
great way to record these kinds of errors for analysis. <a data-type="indexterm" data-primary="Sentry" id="idm45053586351896"/>For example, to use
Sentry, first you have to register for a free account, at which point you
will receive a data source name (DSN), and then you can modify your
exception handler:</p>

<pre data-type="programlisting" data-code-language="js"><code class="kr">const</code> <code class="nx">Sentry</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'@sentry/node'</code><code class="p">)</code>
<code class="nx">Sentry</code><code class="p">.</code><code class="nx">init</code><code class="p">({</code> <code class="nx">dsn</code><code class="o">:</code> <code class="s1">'** YOUR DSN GOES HERE **'</code> <code class="p">})</code>

<code class="nx">process</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s1">'uncaughtException'</code><code class="p">,</code> <code class="nx">err</code> <code class="o">=&gt;</code> <code class="p">{</code>
  <code class="c1">// do any cleanup you need to do here...close</code>
  <code class="c1">// database connections, etc.</code>
  <code class="nx">Sentry</code><code class="p">.</code><code class="nx">captureException</code><code class="p">(</code><code class="nx">err</code><code class="p">)</code>
  <code class="nx">process</code><code class="p">.</code><code class="nx">exit</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>
<code class="p">})</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Scaling Out with Multiple Servers"><div class="sect2" id="idm45053586643032">
<h2>Scaling Out with Multiple Servers</h2>

<p><a data-type="indexterm" data-primary="scaling out" data-secondary="with multiple servers" id="idm45053586294408"/>Although scaling out using clustering can maximize the performance of an
individual server, what happens when you need more than one
server? That’s where things get a little more complicated. <a data-type="indexterm" data-primary="forward-facing proxy" id="idm45053586292904"/><a data-type="indexterm" data-primary="proxies" id="idm45053586292232"/><a data-type="indexterm" data-primary="reverse proxy" id="idm45053586291560"/>To achieve
this kind of parallelism, you need a <em>proxy</em> server. (It’s often
called a <em>reverse proxy</em> or <em>forward-facing proxy</em> to distinguish it from
proxies commonly used to access external networks, but I find this language
to be confusing and unnecessary, so I will simply refer to it as a proxy.)</p>

<p><a data-type="indexterm" data-primary="HAProxy" id="idm45053586289160"/><a data-type="indexterm" data-primary="NGINX" id="idm45053586288456"/>Two very popular options are <a href="https://www.nginx.com">NGINX</a> (pronounced
“engine X”) and <a href="http://www.haproxy.org">HAProxy</a>. NGINX servers in
particular are springing up like weeds. I recently did a competitive
analysis for my company and found upward of 80% of our competitors were
using NGINX. NGINX and HAProxy are both robust, high-performance proxy
servers and are capable of the most demanding applications. (If you need
proof, consider that Netflix, which accounts for as much as 15% of <em>all
internet traffic</em>, uses NGINX.)</p>

<p>There are also some smaller Node-based proxy servers, such as
<a href="http://bit.ly/34RWyNN">node-http-proxy</a>. This is a great option if your needs are modest, or for
development. For production, I recommend using NGINX or HAProxy
(both are free, though they offer support for a fee).</p>

<p>Installing and configuring a proxy is beyond the scope of this book, but it
is not as hard as you might think (especially if you use node-http-proxy or another lightweight proxy). For now, using clusters gives us some assurance that our
website is ready for scaling out.</p>

<p>If you do configure a proxy server, make sure you tell Express that you are using a proxy and that it
should be trusted:</p>

<pre data-type="programlisting" data-code-language="js"><code class="nx">app</code><code class="p">.</code><code class="nx">enable</code><code class="p">(</code><code class="s1">'trust proxy'</code><code class="p">)</code></pre>

<p><a data-type="indexterm" data-primary="req.ip parameter" id="idm45053586252456"/><a data-type="indexterm" data-primary="req.protocol property" id="idm45053586281384"/><a data-type="indexterm" data-primary="req.secure property" id="idm45053586280888"/>Doing this will ensure that <code>req.ip</code>, <code>req.protocol</code>, and <code>req.secure</code> will
reflect the details about the connection between the <em>client and the
proxy</em>, not between the client and your app. <a data-type="indexterm" data-primary="req.ips array" id="idm45053586276712"/>Also, <code>req.ips</code> will be an
array that indicates the original client IP and the names or IP addresses
of any intermediate proxies.<a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc6" id="idm45053586275336"/><a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc5" id="idm45053586274664"/><a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc4" id="idm45053586274024"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Monitoring Your Website"><div class="sect1" id="idm45053586273336">
<h1>Monitoring Your Website</h1>

<p><a data-type="indexterm" data-primary="production concerns" data-secondary="monitoring your website" id="idm45053586272168"/><a data-type="indexterm" data-primary="websites" data-secondary="monitoring" id="idm45053586271192"/>Monitoring your website is one of the most important—and most often
overlooked—QA measures you can take. The only
thing worse than being up at 3 a.m. fixing a broken website
is being woken up at 3 a.m. by your boss because the website is down (or,
worse still, arriving in the morning to realize that your client just lost
$10,000 in sales because the website had been down all night
and no one <span class="keep-together">noticed).</span></p>

<p>There’s nothing you can do about failures: they are as inevitable as death
and taxes. However, if there is one thing you can do to convince your boss
and your clients that you are great at your job, it’s to <em>always</em> know
about failures before they do.</p>








<section data-type="sect2" data-pdf-bookmark="Third-Party Uptime Monitors"><div class="sect2" id="idm45053586264920">
<h2>Third-Party Uptime Monitors</h2>

<p><a data-type="indexterm" data-primary="uptime monitors" id="idm45053586263752"/><a data-type="indexterm" data-primary="websites" data-secondary="uptime monitors" id="idm45053586263048"/>Having an uptime monitor running on your website’s server is as effective
as having a smoke alarm in a house that nobody lives in.
It might be able to catch errors if a certain page goes down, but if the
whole <em>server</em> goes down, it may go down without even sending out an SOS.
That’s why your first line of defense should be third-party uptime
monitors. <a data-type="indexterm" data-primary="UptimeRobot" id="idm45053586261208"/><a href="http://uptimerobot.com">UptimeRobot</a> is free
for up to 50 monitors and is simple to configure. Alerts can go to email,
SMS (text message), Twitter, or Slack (among others). You can monitor for
the return code from a single page (anything other than a 200 is considered
an error) or to check for the presence or absence of a keyword on the
page. Keep in mind that if you use a keyword
monitor, it may affect your analytics (you can exclude traffic from uptime
monitors in most analytics services).</p>

<p>If your needs are more sophisticated, there are other, more expensive
services out there such as <a href="http://pingdom.com">Pingdom</a> and
<a href="http://www.site24x7.com">Site24x7</a>.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Stress Testing"><div class="sect1" id="idm45053586257048">
<h1>Stress Testing</h1>

<p><a data-type="indexterm" data-primary="load testing (stress testing)" id="idm45053586207192"/><a data-type="indexterm" data-primary="production concerns" data-secondary="stress testing" id="idm45053586206584"/><a data-type="indexterm" data-primary="stress testing" id="idm45053586205736"/><em>Stress testing</em> (or <em>load testing</em>) is designed to give you some confidence
that your server will function under the load of hundreds or thousands of
simultaneous requests. This is another deep area that could be
the subject for a whole book: stress testing can be arbitrarily
sophisticated, and how complicated you want to get depends largely on the
nature of your project. If you have reason to believe that your site could
be massively popular, you might want to invest more time in stress testing.</p>

<p><a data-type="indexterm" data-primary="Artillery" id="idm45053586203464"/>Let’s add a simple stress test using <a href="https://artillery.io/">Artillery</a>.
First, install Artillery by running <code>npm install -g artillery</code>; then edit
your <em>package.json</em> file and add the following to the <code>scripts</code> section:</p>

<pre data-type="programlisting" data-code-language="json">  <code class="s2">"scripts"</code><code class="err">:</code> <code class="p">{</code>
    <code class="nt">"stress"</code><code class="p">:</code> <code class="s2">"artillery quick --count 10 -n 20 http://localhost:3000/"</code>
  <code class="p">}</code></pre>

<p>This will simulate 10 “virtual users” (<code>--count 10</code>), each of whom will
send 20 requests (<code>-n 20</code>) to your server.</p>

<p>Make sure your application is running (in a separate terminal window, for
example) and then run <code>npm run stress</code>. You’ll see statistics like this:</p>

<pre data-type="programlisting">Started phase 0, duration: 1s @ 16:43:37(-0700) 2019-04-14
Report @ 16:43:38(-0700) 2019-04-14
Elapsed time: 1 second
  Scenarios launched:  10
  Scenarios completed: 10
  Requests completed:  200
  RPS sent: 147.06
  Request latency:
    min: 1.8
    max: 10.3
    median: 2.5
    p95: 4.2
    p99: 5.4
  Codes:
    200: 200

All virtual users finished
Summary report @ 16:43:38(-0700) 2019-04-14
  Scenarios launched:  10
  Scenarios completed: 10
  Requests completed:  200
  RPS sent: 145.99
  Request latency:
    min: 1.8
    max: 10.3
    median: 2.5
    p95: 4.2
    p99: 5.4
  Scenario counts:
    0: 10 (100%)
  Codes:
    200: 200</pre>

<p>This test was run on my development laptop. You can see Express didn’t
take more than 10.3 milliseconds to serve any requests, and 99% of them
were served in under 5.4 milliseconds. I can’t offer concrete guidance
about what kind of numbers you should be looking for, but to ensure a
snappy application, you should be looking for total connection times under
50 milliseconds. (Don’t forget that this is just the time it takes the
server to deliver the data to the client; the client still has to render
it, which takes time, so the less time you spend transmitting the data,
the better.)</p>

<p>If you stress test your application regularly and benchmark it, you’ll be
able to recognize problems. If you just finished a feature and you find
that your connection times have tripled, you might want to do some
performance tuning on your new feature!</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="idm45053586256680">
<h1>Conclusion</h1>

<p>I hope this chapter has given you some insight into the things you’ll
want to think about as you approach the launch of your application. There
is a lot of detail that goes into a production application, and while you can’t
anticipate everything that might happen when you launch, the more you can
anticipate, the better off you’ll be. To paraphrase Louis Pasteur, fortune
favors the prepared.<a data-type="indexterm" data-startref="ix_ch-12-production_concerns-asciidoc0" id="idm45053586192872"/></p>
</div></section>







</div></section></div>



  </body></html>