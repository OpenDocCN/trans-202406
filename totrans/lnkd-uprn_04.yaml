- en: Chapter 4\. Adding Workloads to the Mesh
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Getting Linkerd running in your cluster is a great first step. But it’s pointless
    to run Linkerd with nothing else: to get actual value out of your Linkerd cluster,
    you’ll need to get workloads running in your service mesh. In this chapter, we’ll
    show you how to do exactly that.'
  prefs: []
  type: TYPE_NORMAL
- en: Workloads Versus Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ll talk about “workloads” a lot in this chapter—but sometimes we’ll also
    talk about “services,” and sometimes “Services.” Unfortunately, these three things
    all have slightly different meanings:'
  prefs: []
  type: TYPE_NORMAL
- en: Service
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes resource that is widely used to control how Kubernetes allocates
    DNS names and IP addresses for services (see [Figure 4-1](#workloads-vs-services)).
  prefs: []
  type: TYPE_NORMAL
- en: Workload
  prefs: []
  type: TYPE_NORMAL
- en: A thing that actually does work on your behalf. A workload receives requests
    over the network and executes code to take actions. In Kubernetes, it’s usually
    one or more Pods (to provide the computation), often managed by a Deployment or
    DaemonSet resource, plus one or more Services (to manage the names and IP addresses),
    as illustrated in [Figure 4-1](#workloads-vs-services).
  prefs: []
  type: TYPE_NORMAL
- en: service
  prefs: []
  type: TYPE_NORMAL
- en: A less formal term that could refer to either a Service or a workload, depending
    on context. This lack of precision shows just one of many cases where Kubernetes
    terminology is very much more confusing than we would like it to be.
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0401](assets/luar_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. The workload as distinct from the Service
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As an application developer, you can usually just say “service” and trust that
    people will be fine with the ambiguity. Unfortunately, we often need to be more
    precise when talking about service meshes—hence the discussion of *workloads*
    here rather than *services*.
  prefs: []
  type: TYPE_NORMAL
- en: What Does It Mean to Add a Workload to the Mesh?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “Adding a workload to the mesh” really means “adding the Linkerd sidecar to
    each of your workload’s Pods,” as shown in [Figure 4-2](#meshing-a-workload).
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, this means changing the Pod’s definition to include the sidecar
    container. While you *could* do this by manually editing the YAML that defines
    the Pod, it’s much easier and safer to let Linkerd do the heavy lifting instead.
  prefs: []
  type: TYPE_NORMAL
- en: Linkerd includes a Kubernetes admission controller called the `linkerd-proxy-injector`.
    Its job, unsurprisingly, is to inject Linkerd proxies into workload Pods. Of course,
    it doesn’t do this blindly; instead, it looks for Kubernetes annotations that
    tell it which Pods need to be injected, as shown in [Figure 4-3](#proxy-injector).
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0402](assets/luar_0402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. Adding a workload to the mesh
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![luar 0403](assets/luar_0403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. The proxy injector
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Injecting Individual Workloads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most common way to handle injection is to add the `linkerd.io/inject: enabled`
    annotation directly to the Pod itself, typically by adding the annotation to the
    Pod template in a Deployment, DaemonSet, etc. Whenever `linkerd-proxy-injector`
    sees a new Pod with this annotation, it will inject the proxy sidecar into the
    Pod for you.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s worth pointing out that the value of the annotation is important: `enabled`
    means to do a normal sidecar injection. We’ll look at other values shortly.'
  prefs: []
  type: TYPE_NORMAL
- en: All Pods Are Created Equal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It doesn’t matter what kind of resource is being used to create the Pod. Deployments,
    DaemonSets, hand-tooled ReplicaSets, Argo Rollouts resources—all of them create
    their Pods exactly the same way. What the Linkerd injector notices is that a new
    Pod exists, not what caused it to be created.
  prefs: []
  type: TYPE_NORMAL
- en: Injecting All Workloads in a Namespace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can add the `linkerd.io/inject` annotation to a Namespace, rather than to
    a Pod. Once that’s done, every new Pod created in that namespace will be injected
    (and, again, it *does not matter* what causes the new Pod to be created).
  prefs: []
  type: TYPE_NORMAL
- en: This can be very useful for situations where automation is creating Pods, but
    it’s difficult or error-prone to modify the annotations on the Pods themselves.
    For example, some ingress controllers will re-create Deployments every time you
    change a resource; rather than mess about with laboriously modifying the Pod template
    used by the ingress controller (if it’s even possible), you can just annotate
    the Namespace in which the Deployments will be created.
  prefs: []
  type: TYPE_NORMAL
- en: linkerd.io/inject Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The value of the `linkerd.io/inject` annotation does matter—it’s not just a
    matter of having a non-empty string there. There are three specific values that
    are meaningful:'
  prefs: []
  type: TYPE_NORMAL
- en: '`linkerd.io/inject: enabled`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common case: `linkerd-proxy-injector` will add a proxy container to
    the Pod and tell the proxy to run in its “normal” mode.'
  prefs: []
  type: TYPE_NORMAL
- en: '`linkerd.io/inject: ingress`'
  prefs: []
  type: TYPE_NORMAL
- en: '`linkerd-proxy-injector` will add a proxy container to the Pod, but the proxy
    will run in “ingress” mode (which we’ll discuss in [Chapter 5](ch05.html#LUAR_ingress_and_linkerd)).'
  prefs: []
  type: TYPE_NORMAL
- en: '`linkerd.io/inject: disabled`'
  prefs: []
  type: TYPE_NORMAL
- en: This explicitly tells `linkerd-proxy-injector` to *not* add the proxy sidecar,
    even if there’s a Namespace annotation that would otherwise say to add the sidecar.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll discuss ingress mode more in [Chapter 5](ch05.html#LUAR_ingress_and_linkerd):
    it’s a workaround for ingress controllers that only know how to route requests
    directly to workload endpoints. In most cases, you should use `linkerd.io/inject:
    enabled` to get “normal” mode.'
  prefs: []
  type: TYPE_NORMAL
- en: Why Might You Decide Not to Add a Workload to the Mesh?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In general:'
  prefs: []
  type: TYPE_NORMAL
- en: You always want to add your application workloads to the mesh.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You never want to add cluster infrastructure to the mesh.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, for example, things in the `kube-system` namespace are never injected. All
    of these Pods are designed to protect themselves no matter what else is going
    on, and some of them need to be sure that nothing is between them and the network
    layer, so you shouldn’t inject them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Likewise, a Kubernetes conversion webhook (as shown in the `application-code`
    namespace in [Figure 4-3](#proxy-injector)) generally shouldn’t be in the mesh.
    The webhook mechanism itself already makes specific demands around TLS, and the
    mesh won’t help with that. (It probably won’t hurt, but there’s really no point.)
    Another good example here is CNI implementations: these need direct access to
    the network layer and shouldn’t be injected.'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the workloads that are part of your application running in
    the cluster should always be injected into the mesh. All of these guidelines are
    shown in [Figure 4-4](#inject-app-not-infrastructure).
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0404](assets/luar_0404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-4\. Inject the application, not the infrastructure
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Other Proxy Configuration Options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the basic `linkerd.io/inject` annotation is the only proxy configuration
    option you *must* provide, there are actually quite a few other things you can
    configure about the proxy. The full list can be found in the [Linkerd Proxy Configuration
    documentation](https://oreil.ly/9FiJF), but two areas very much worth learning
    about from the start are *protocol detection* and *Kubernetes resource limits*.
  prefs: []
  type: TYPE_NORMAL
- en: Protocol Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in [Chapter 1](ch01.html#LUAR_service_mesh_101), Linkerd puts
    a lot of effort into operational simplicity; whenever possible, Linkerd tries
    to make sure things just work when you bring your application into the mesh. Protocol
    detection is a critical part of this, because Linkerd has to know the protocol
    being used over a connection to correctly manage the connection, as shown in [Figure 4-5](#protocol-detection-overview).
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0405](assets/luar_0405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-5\. Protocol detection
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'There are several reasons that Linkerd (or any other mesh) needs to know the
    protocol in use over the wire. We’ll touch on just a few of them:'
  prefs: []
  type: TYPE_NORMAL
- en: Observability
  prefs: []
  type: TYPE_NORMAL
- en: Linkerd can’t provide proper metrics without understanding the flow of the protocol.
    Identifying the beginning and end of a request is crucial to measuring request
    rate and latency. Reading the status of a request is critical to measuring the
    success rate.
  prefs: []
  type: TYPE_NORMAL
- en: Reliability
  prefs: []
  type: TYPE_NORMAL
- en: 'Any reliability feature beyond the most basic requires understanding the protocol
    in flight. Consider load balancing, for example: if Linkerd doesn’t know the protocol,
    it can only do connection-based load balancing, where an incoming TCP connection
    is assigned to a specific workload Pod.'
  prefs: []
  type: TYPE_NORMAL
- en: However, connection-based load balancing doesn’t work very well for protocols
    like HTTP/2 and gRPC. In these protocols, a single long-lived connection can carry
    many requests, with multiple requests active at the same time. Linkerd can dramatically
    improve reliability and performance by assigning individual requests to workload
    Pods, rather than fixing an entire connection to a Pod. (It’s a fun Linkerd fact
    that it does this automatically, with zero configuration; just install Linkerd,
    and you get this for free.)
  prefs: []
  type: TYPE_NORMAL
- en: Security
  prefs: []
  type: TYPE_NORMAL
- en: 'If a workload makes a TLS connection to another workload, Linkerd shouldn’t
    try to reencrypt it. It also shouldn’t try to do anything fancy with load balancing,
    since it won’t be able to see anything inside the connection. (This implies that
    you’ll get the best results with Linkerd by having your workloads *not* use TLS
    when connecting to each other: let Linkerd do mTLS for you!)'
  prefs: []
  type: TYPE_NORMAL
- en: When Protocol Detection Goes Wrong
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Automatic protocol detection has one major limitation: it can only work for
    protocols where the entity that makes the connection is also the first one to
    send data (*client-speaks-first* protocols). It will fail for protocols where
    the entity that *receives* the connection is the first to send data (*server-speaks-first*
    protocols).'
  prefs: []
  type: TYPE_NORMAL
- en: The reason for this limitation is that until Linkerd knows the protocol, it
    can’t make reasonable decisions about how to do load balancing, so it can’t decide
    what server to connect to, so it can’t find out what the server will say! Every
    proxy has this frustratingly circular issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the cloud native world, many—perhaps most?—common protocols are, happily,
    client-speaks-first protocols; for example, HTTP, gRPC, and TLS itself are all
    client-speaks-first. Unfortunately, there are some important server-speaks-first
    protocols out there: SMTP, MySQL, and Redis are all examples.'
  prefs: []
  type: TYPE_NORMAL
- en: If Linkerd cannot detect the protocol, it will assume it’s a raw TCP connection,
    simply because that’s the least common denominator that will always function.
    The problem is that for server-speaks-first protocols, Linkerd will wait 10 seconds
    before assuming that it won’t be able to detect the protocol, and that 10-second
    delay is obviously not what you want. To prevent that, you need to tell Linkerd
    that it should either skip the connection entirely or treat it as opaque.
  prefs: []
  type: TYPE_NORMAL
- en: Opaque Ports Versus Skip Ports
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you tell Linkerd to *skip* a connection, you’re telling it to have absolutely
    nothing to do with that connection. In fact, the Linkerd proxies don’t touch the
    connection at all: the packets flow straight from workload to workload.'
  prefs: []
  type: TYPE_NORMAL
- en: This means that Linkerd can’t do mTLS, load balancing, metrics collection, or
    *anything*. The connection effectively happens outside the mesh entirely.
  prefs: []
  type: TYPE_NORMAL
- en: An *opaque* connection, on the other hand, does pass through the Linkerd proxies,
    which means that it is carried over mTLS. It’s still encrypted and Linkerd still
    enforces any policy that has been configured, but you’ll only get per-connection
    metrics and load balancing (because Linkerd knows that it can’t see into the stream
    to look at individual requests).
  prefs: []
  type: TYPE_NORMAL
- en: This distinction is shown in [Figure 4-6](#opaque-vs-skip).
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0406](assets/luar_0406.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-6\. Opaque ports versus skip ports
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This all implies that if you need to use server-speaks-first protocols, it’s
    better to mark them as opaque, rather than skipping them entirely. Skipping should
    only be necessary when the destination of the traffic isn’t part of your mesh.
    Since opaque connections still rely on a Linkerd proxy to do mTLS, they can’t
    work if there’s no proxy there to receive the connection!
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Protocol Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two ways to tell Linkerd about protocols. You can use a Server resource,
    which we’ll cover when we talk policy in [Chapter 8](ch08.html#LUAR_server_policy),
    or you can use the following annotations to mark specific ports as opaque or skipped:'
  prefs: []
  type: TYPE_NORMAL
- en: '`config.linkerd.io/opaque-ports`'
  prefs: []
  type: TYPE_NORMAL
- en: Connections to or from these ports will always be treated as opaque.
  prefs: []
  type: TYPE_NORMAL
- en: '`config.linkerd.io/skip-inbound-ports`'
  prefs: []
  type: TYPE_NORMAL
- en: Connections coming into this workload on these ports will always be skipped.
  prefs: []
  type: TYPE_NORMAL
- en: '`config.linkerd.io/skip-outbound-ports`'
  prefs: []
  type: TYPE_NORMAL
- en: Connections leaving this workload on these ports will always be skipped.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of these take comma-separated lists of port numbers or port ranges, so
    all of the following are legal:'
  prefs: []
  type: TYPE_NORMAL
- en: '`config.linkerd.io/opaque-ports: 25`'
  prefs: []
  type: TYPE_NORMAL
- en: This will treat only port 25 as opaque.
  prefs: []
  type: TYPE_NORMAL
- en: '`config.linkerd.io/skip-inbound-ports: 3300,9900`'
  prefs: []
  type: TYPE_NORMAL
- en: This will skip connections coming in on port 3300 or 9900.
  prefs: []
  type: TYPE_NORMAL
- en: '`config.linkerd.io/skip-inbound-ports: 8000-9000`'
  prefs: []
  type: TYPE_NORMAL
- en: This will skip connections coming in on any port between 8000 and 9000, inclusive.
  prefs: []
  type: TYPE_NORMAL
- en: '`config.linkerd.io/skip-outbound-ports: 25,587,8000-9000`'
  prefs: []
  type: TYPE_NORMAL
- en: This will skip connections going out on port 25, port 587, or any port between
    8000 and 9000, inclusive.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s also a `config.linkerd.io/skip-subnets` option, which skips any connection
    to or from any listed subnets. Its argument is a comma-separated list of [Classless
    Inter-Domain Routing (CIDR)](https://oreil.ly/soiAU) ranges—for example, `config.linkerd.io/skip-subnets:
    10.0.0.0/8,192.168.1.0/24`.'
  prefs: []
  type: TYPE_NORMAL
- en: Default Opaque Ports
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As of Linkerd 2.12, several ports are marked as opaque by default (see the list
    in [“Default Opaque Ports”](ch03.html#default-opaque-ports) for details).
  prefs: []
  type: TYPE_NORMAL
- en: The default ports are meant to allow various server-speaks-first protocols,
    such as MySQL and SMTP, to work seamlessly with Linkerd. If you’re using these
    ports for client-speaks-first protocols, you’ll need to use a Server resource
    to override the port default (or—better—just choose a different port for your
    client-speaks-first protocol!).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Resource Limits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Compared to protocol detection, Kubernetes resource limits are much more straightforward.
    There’s a simple set of annotations to set that will allow you to specify resource
    requests and limits, as shown in [Table 4-1](#linkerd_annotations_table_ch04).
  prefs: []
  type: TYPE_NORMAL
- en: Table 4-1\. Linkerd annotations for resource requests and limits
  prefs: []
  type: TYPE_NORMAL
- en: '| Annotation | Effect |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `config.linkerd.io/proxy-cpu-limit` | Maximum amount of CPU units that the
    proxy sidecar can use |'
  prefs: []
  type: TYPE_TB
- en: '| `config.linkerd.io/proxy-cpu-request` | Amount of CPU units that the proxy
    sidecar requests |'
  prefs: []
  type: TYPE_TB
- en: '| `config.linkerd.io/proxy-ephemeral-storage-limit` | Used to override the
    `limitEphemeralStorage` config |'
  prefs: []
  type: TYPE_TB
- en: '| `config.linkerd.io/proxy-ephemeral-storage-request` | Used to override the
    `requestEphemeralStorage` config |'
  prefs: []
  type: TYPE_TB
- en: '| `config.linkerd.io/proxy-memory-limit` | Maximum amount of memory that the
    proxy sidecar can use |'
  prefs: []
  type: TYPE_TB
- en: '| `config.linkerd.io/proxy-memory-request` | Amount of memory that the proxy
    sidecar requests |'
  prefs: []
  type: TYPE_TB
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So there you have it: the start-to-finish guide for getting your workloads
    to be an effective part of the Linkerd mesh. Hopefully you now have a good understanding
    of how to make everything work, and of the gotchas along the way (like server-speaks-first
    protocols). Next up is getting Linkerd and ingress controllers to play nicely
    together.'
  prefs: []
  type: TYPE_NORMAL
