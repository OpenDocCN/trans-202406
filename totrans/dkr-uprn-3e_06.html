<html><head></head><body><section data-pdf-bookmark="Chapter 5. Working with Containers" data-type="chapter" epub:type="chapter"><div class="chapter" id="docker_containers">&#13;
<h1><span class="label">Chapter 5. </span>Working with Containers</h1>&#13;
&#13;
&#13;
<p>In the previous chapter, we learned how to build a Docker image and the very basic steps required for running the resulting image within a container. In this chapter, we’ll first take a look at the history of container technology and then dive deeper into running containers and exploring the Docker commands that control the overall configuration, resources, and privileges that your container receives.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What Are Containers?" data-type="sect1"><div class="sect1" id="what-are-containers">&#13;
<h1>What Are Containers?</h1>&#13;
&#13;
<p>You might be familiar with virtualization<a data-primary="Linux containers" data-secondary="about" data-tertiary="explanation of containers" data-type="indexterm" id="idm46803149142064"/><a data-primary="Hypervisor framework (Apple)" data-secondary="virtualization system hypervisors" data-type="indexterm" id="idm46803149140848"/><a data-primary="virtual machines (VM)" data-secondary="hypervisor virtualized layer" data-type="indexterm" id="idm46803149139968"/><a data-primary="Linux" data-secondary="kernel" data-tertiary="virtual machine providing" data-type="indexterm" id="idm46803149139056"/> systems like VMware or KVM that allow you to run a complete Linux kernel and operating system on top of a virtualized layer, commonly known as a <em>hypervisor</em>. This approach provides very strong isolation between workloads because each VM hosts its own operating system kernel that sits in a separate memory space on top of a hardware virtualization layer.</p>&#13;
&#13;
<p>Containers are fundamentally different<a data-primary="Linux containers" data-secondary="about" data-tertiary="operating system virtualization" data-type="indexterm" id="idm46803149136944"/><a data-primary="operating system virtualization" data-type="indexterm" id="idm46803149135680"/><a data-primary="virtual machines (VM)" data-secondary="containers versus" data-tertiary="operating system virtualization" data-type="indexterm" id="idm46803149134992"/><a data-primary="Linux" data-secondary="kernel" data-tertiary="operating system virtualization" data-type="indexterm" id="idm46803149133760"/> since they all share a single kernel, and isolation between workloads is implemented entirely within that one kernel. This is called <em>operating system virtualization</em>.</p>&#13;
&#13;
<p>The <a href="https://github.com/opencontainers/runc/blob/main/libcontainer/README.md"><code>libcontainer</code> README</a> provides a good, short definition of a container:<a data-primary="Linux containers" data-secondary="about" data-tertiary="definition" data-type="indexterm" id="idm46803149130624"/></p>&#13;
<blockquote>A container is a self-contained execution environment that shares the kernel of the host system and is (optionally) isolated from other containers in the system.</blockquote>&#13;
&#13;
<p>One of the major advantages of containers is resource efficiency, because you don’t need a whole operating system instance for each isolated workload. Since you are sharing a kernel, there is one fewer layer of indirection between the isolated task and the real hardware underneath. When a process is running inside a container, there is only a little bit of code that sits inside the kernel managing the container. Contrast this with a VM, where a second layer would be running. In a VM, calls by the process to the hardware or hypervisor would require bouncing in and out of privileged mode on the processor twice, thereby noticeably slowing down many calls.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p><a href="https://github.com/opencontainers/runc/tree/main/libcontainer">libcontainer</a> is a Go library<a data-primary="libcontainer Go library" data-type="indexterm" id="idm46803149127040"/><a data-primary="Go language" data-secondary="libcontainer library" data-type="indexterm" id="idm46803149126304"/><a data-primary="Linux containers" data-secondary="Go library for managing from applications" data-type="indexterm" id="idm46803149125360"/> that is designed to provide a standard interface for managing Linux containers from applications.</p>&#13;
</div>&#13;
&#13;
<p>But the container approach does mean that you can only run processes that are compatible with the underlying kernel. For example, unlike hardware virtualization provided by technologies like VMware or KVM, Windows applications cannot run natively inside a Linux container on a Linux host. Windows applications can, however, run inside Windows containers on a Windows host. <a data-primary="Linux containers" data-secondary="about" data-tertiary="OS-specific technology" data-type="indexterm" id="idm46803149123696"/>So containers are best thought of as an OS-specific technology where you can run any of your favorite applications or daemons that are compatible with the container server’s kernel. <a data-primary="Docker" data-primary-sortas="docker-a" data-secondary="characteristics" data-tertiary="containers as ephemeral wrappers" data-type="indexterm" id="idm46803149122320"/><a data-primary="Linux containers" data-secondary="characteristics" data-tertiary="ephemeral wrappers" data-type="indexterm" id="idm46803149120768"/><a data-primary="virtual machines (VM)" data-secondary="containers versus" data-type="indexterm" id="idm46803149119552"/>When thinking of containers, you should try very hard to throw out what you might already know about VMs and instead conceptualize a container as a wrapper around a normal process that runs on the server.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>In addition to being able to run containers inside VMs, it is completely feasible to run a VM inside a container. If you do this, then it is indeed possible to run a Windows application inside a Windows VM that is running inside a Linux container.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="History of Containers" data-type="sect2"><div class="sect2" id="history">&#13;
<h2>History of Containers</h2>&#13;
&#13;
<p>It is often the case that a revolutionary<a data-primary="Docker" data-primary-sortas="docker-a" data-secondary="history of development" data-tertiary="container history" data-type="indexterm" id="ch05-hist"/><a data-primary="Linux containers" data-secondary="history of development" data-type="indexterm" id="ch05-hist2"/><a data-primary="processes" data-secondary="container history of development" data-type="indexterm" id="ch05-hist3"/><a data-primary="Linux" data-secondary="system calls" data-see="system calls" data-type="indexterm" id="idm46803149111008"/><a data-primary="system calls" data-secondary="history of container development" data-type="indexterm" id="idm46803149109792"/> technology is an older technology that has finally arrived in the spotlight. Technology goes in waves, and some of the ideas from the 1960s are back in vogue. Similarly, Docker is a newer technology, and it has an ease of use that has made it an instant hit, but it doesn’t exist in a vacuum. Much of what underpins Docker comes from work done over the last 30 years in a few different areas. We can easily trace the conceptual evolution of containers from a simple system call that was added to the Unix kernel in the late 1970s to the modern container tooling that powers many huge internet firms, like Google, Twitter, and Meta. It’s worth taking some time for a quick tour through how the technology evolved and led to the creation of Docker, because understanding this helps you place it within the context of other things that you might be familiar with.</p>&#13;
&#13;
<p>Containers are not a new idea. They are a way to isolate and encapsulate a part of the running system. The oldest technology in this area includes the very first batch processing systems. When using these early computers, the system would only run one program at a time, switching to run another program once the previous program had finished or a predefined time span had elapsed. With this design there was enforced isolation: you could make sure your program didn’t step on anyone else’s program because it was only possible to run one thing at a time. Although modern computers still switch tasks constantly, it is incredibly fast and completely unnoticeable to most users.</p>&#13;
&#13;
<p>We would argue that the seeds<a data-primary="chroot Unix system call" data-type="indexterm" id="idm46803149107904"/><a data-primary="system calls" data-secondary="chroot" data-type="indexterm" id="idm46803149107200"/> for today’s containers were planted in 1979 with the addition of the <code>chroot</code> system call to Version 7 Unix. <code>chroot</code> restricts a process’s view of the underlying filesystem to a single subtree. The <code>chroot</code> system call is commonly used to protect the operating system from untrusted server processes like FTP, BIND, and Sendmail, which are publicly exposed and susceptible to compromise.</p>&#13;
&#13;
<p>In the 1980s and 1990s, various Unix variants<a data-primary="Linux" data-secondary="kernel" data-tertiary="development history" data-type="indexterm" id="idm46803149033792"/> were created with mandatory access controls for security reasons.<sup><a data-type="noteref" href="ch05.html#idm46803149032576" id="idm46803149032576-marker">1</a></sup> This meant you had tightly controlled domains running on the same Unix kernel. Processes in each domain had an extremely limited view of the system that precluded them from interacting across domains. A popular commercial version of Unix that implemented this idea was the Sidewinder firewall built on top of BSDI Unix, but this was not possible with most mainstream Unix implementations.</p>&#13;
&#13;
<p>That changed in 2000 when FreeBSD 4.0 was released with a new command,<a data-primary="jail command" data-type="indexterm" id="idm46803149031568"/> called <code>jail</code>, which was designed to allow shared-environment hosting providers to easily and securely create a separation between their processes and those that belonged to each of their customers. FreeBSD <code>jail</code> expanded <code>chroot</code>’s capabilities and also restricted everything a process could do with the underlying system and other jailed processes.</p>&#13;
&#13;
<p>In 2004, Sun released an early build of Solaris 10, which included Solaris containers, which later evolved into Solaris Zones. This was the first major commercial implementation of container technology and is still used today to support many commercial container implementations. In 2005, OpenVZ for Linux was released by the company Virtuozzo, followed in 2007 by HP’s Secure Resource Partitions for HP-UX, which was later renamed HP-UX Containers.</p>&#13;
&#13;
<p>Companies like Google, which had to deal with scaling applications for broad internet consumption and/or hosting untrusted user code, started pushing container technology in the early 2000s to facilitate reliably and securely distributing their applications across global data centers. A few companies maintained their own patched Linux kernels with container support for internal use, but as the need for these features became more evident within the Linux community, Google contributed some of its work supporting containers into the mainline Linux kernel,<a data-primary="LXC (Linux Containers)" data-type="indexterm" id="idm46803149028720"/><a data-primary="Linux Containers (LXC)" data-type="indexterm" id="idm46803149028016"/><a data-primary="Linux" data-secondary="Linux Containers (LXC)" data-type="indexterm" id="idm46803149027344"/> and in 2008, Linux Containers (LXC) were released in version 2.6.24 of the Linux kernel. The phenomenal growth of Linux Containers across the community did not truly start to grow until 2013, with the inclusion of user namespaces in version 3.8 of the Linux kernel and the release of Docker one month later.</p>&#13;
&#13;
<p>Nowadays, containers are used almost everywhere. Docker and OCI images provide the packaging format for a significant and growing amount of software that is delivered into production environments, and provide the basis for many production systems, including, but not limited to, Kubernetes and most “serverless” cloud technologies.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>So-called serverless technologies<a data-primary="serverless technologies" data-type="indexterm" id="idm46803149024832"/> are not actually serverless; they simply rely on other people’s servers to get work done so that the application owner does not have to worry about managing the hardware and operating system.<a data-startref="ch05-hist" data-type="indexterm" id="idm46803149024000"/><a data-startref="ch05-hist2" data-type="indexterm" id="idm46803149023328"/><a data-startref="ch05-hist3" data-type="indexterm" id="idm46803149022656"/></p>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Creating a Container" data-type="sect1"><div class="sect1" id="creating-a-container">&#13;
<h1>Creating a Container</h1>&#13;
&#13;
<p>So far we’ve started containers<a data-primary="Linux containers" data-secondary="creating a container" data-type="indexterm" id="ch05-creat"/><a data-primary="Linux containers" data-secondary="creating a container" data-tertiary="about" data-type="indexterm" id="idm46803149018704"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="creating and executing the container" data-type="indexterm" id="idm46803149017488"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="create" data-tertiary="docker container run doing" data-type="indexterm" id="idm46803149015984"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="start" data-tertiary="docker container run executing container" data-type="indexterm" id="idm46803149014480"/> using the handy <code>docker container run</code> command. But <code>docker container run</code> is really a convenience command that wraps two separate steps into one. The first thing it does is create a container from the underlying image. We can accomplish this separately using the <code>docker container create</code> command. The second thing <code>docker container run</code> does is execute the container, which we can also do separately with the <code>docker container start</code> command.</p>&#13;
&#13;
<p>The <code>docker container create</code> and <code>docker container start</code> commands both contain all the options that pertain to how a container is initially set up. In <a data-type="xref" href="ch04.html#docker_images">Chapter 4</a>, we demonstrated that with the <code>docker container run</code> command you could map network ports in the underlying container to the host using the <code>-p/--publish</code> argument, and that <code>-e/--env</code> could be used to pass environment variables into the container.</p>&#13;
&#13;
<p>This only just begins to touch on the array of things that you can configure when you first create a container. So let’s take a look at some of the options that <code>docker</code> supports.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Basic Configuration" data-type="sect2"><div class="sect2" id="idm46803149006096">&#13;
<h2>Basic Configuration</h2>&#13;
&#13;
<p>Let’s start by exploring some of the ways we can tell Docker to configure our &#13;
<span class="keep-together">container</span> when we create it.<a data-primary="Linux containers" data-secondary="creating a container" data-tertiary="basic configuration" data-type="indexterm" id="ch05-bascon"/></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Container name" data-type="sect3"><div class="sect3" id="idm46803149001920">&#13;
<h3>Container name</h3>&#13;
&#13;
<p>When you create a container,<a data-primary="Linux containers" data-secondary="configuring" data-tertiary="container name" data-type="indexterm" id="idm46803149000208"/> it is built from the underlying image, but various command-line arguments can affect the final settings. Settings specified in the &#13;
<span class="keep-together"><em>Dockerfile</em></span> are always used as defaults, but you can override many of them at creation time.</p>&#13;
&#13;
<p>By default, <a href="https://github.com/moby/moby/blob/master/pkg/namesgenerator/names-generator.go">Docker randomly names your container</a> by combining an adjective with the name of a famous person. This results in names like <em>ecstatic-babbage</em> and <em>serene-albattani</em>. If you want to give your container a specific name, you can use the <code>--name</code> argument:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="create" data-tertiary="--name" data-tertiary-sortas="name" data-type="indexterm" id="idm46803148995344"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>create<code class="w"> </code>--name<code class="o">=</code><code class="s2">"awesome-service"</code><code class="w"> </code>ubuntu:latest<code class="w"> </code>sleep<code class="w"> </code><code class="m">120</code><code class="w"/></pre>&#13;
&#13;
<p>After creating this container, you can then<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="start" data-tertiary="exit after 120 seconds" data-type="indexterm" id="idm46803148988336"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="stop" data-tertiary="stop running container" data-type="indexterm" id="idm46803148986976"/> start it by using the <code>docker container start awesome-service</code>. It will automatically exit after 120 seconds, but you can stop it before then by running <code>docker container stop awesome-service</code>. We will dive a bit more into each of these commands a little later in the chapter.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>You can only have one container with<a data-primary="Linux containers" data-secondary="configuring" data-tertiary="container name unique" data-type="indexterm" id="idm46803148965568"/> any given name on a Docker host. If you run the preceding command twice in a row, you will get an error. You must either delete the previous container using <code>docker container rm</code> or change the name of the new container.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Labels" data-type="sect3"><div class="sect3" id="idm46803148963424">&#13;
<h3>Labels</h3>&#13;
&#13;
<p>As mentioned in <a data-type="xref" href="ch04.html#docker_images">Chapter 4</a>, labels<a data-primary="Linux containers" data-secondary="configuring" data-tertiary="labels" data-type="indexterm" id="idm46803148960832"/><a data-primary="metadata of Linux containers" data-secondary="labels" data-type="indexterm" id="idm46803148959584"/><a data-primary="Linux containers" data-secondary="metadata" data-tertiary="labels" data-type="indexterm" id="idm46803148958672"/><a data-primary="labels" data-type="indexterm" id="idm46803148957456"/> are key/value pairs that can be applied to Docker images and containers as metadata. When new Linux containers are created, they automatically inherit all the labels from their parent image.</p>&#13;
&#13;
<p>It is also possible to add new labels to the containers so that you can apply metadata that might be specific to that single container:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-l for labels" data-tertiary-sortas="l" data-type="indexterm" id="idm46803148956272"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code>--name<code class="w"> </code>has-some-labels<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>-l<code class="w"> </code><code class="nv">deployer</code><code class="o">=</code>Ahmed<code class="w"> </code>-l<code class="w"> </code><code class="nv">tester</code><code class="o">=</code>Asako<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>ubuntu:latest<code class="w"> </code>sleep<code class="w"> </code><code class="m">1000</code><code class="w"/></pre>&#13;
&#13;
<p>You can then search for and filter containers based on this metadata, using commands like <code>docker container ls</code>:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="filtering on labels" data-type="indexterm" id="idm46803148930752"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"> </code>-a<code class="w"> </code>-f<code class="w"> </code><code class="nv">label</code><code class="o">=</code><code class="nv">deployer</code><code class="o">=</code>Ahmed<code class="w"/>&#13;
<code class="go">CONTAINER ID  IMAGE         COMMAND       … NAMES</code>&#13;
<code class="go">845731631ba4  ubuntu:latest "sleep 1000"  … has-some-labels</code></pre>&#13;
&#13;
<p class="pagebreak-before">You can use the <code>docker container inspect</code> command to see all the labels that a container has:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="inspect" data-tertiary="displaying labels" data-type="indexterm" id="idm46803148901856"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>inspect<code class="w"> </code>has-some-labels<code class="w"/>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="json" data-type="programlisting"><code class="w">        </code><code class="nt">"Labels"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"deployer"</code><code class="p">:</code><code class="w"> </code><code class="s2">"Ahmed"</code><code class="p">,</code><code class="w"/>&#13;
<code class="w">            </code><code class="nt">"tester"</code><code class="p">:</code><code class="w"> </code><code class="s2">"Asako"</code><code class="w"/>&#13;
<code class="w">        </code><code class="p">},</code><code class="w"/></pre>&#13;
&#13;
<pre class="nomargin" data-code-language="text" data-type="programlisting">…</pre>&#13;
&#13;
<p>This container runs the command <code>sleep 1000</code>, so after 1,000 seconds it will stop running.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Hostname" data-type="sect3"><div class="sect3" id="idm46803148962800">&#13;
<h3>Hostname</h3>&#13;
&#13;
<p>By default, when you start a container,<a data-primary="Linux containers" data-secondary="configuring" data-tertiary="hostname" data-type="indexterm" id="ch05-host"/><a data-primary="hostname" data-type="indexterm" id="ch05-host2"/><a data-primary="bind mounts" data-secondary="hostname" data-type="indexterm" id="idm46803148783776"/> Docker copies certain system files on the host, including <em>/etc/hostname</em>, into the container’s configuration directory on the host,<sup><a data-type="noteref" href="ch05.html#idm46803148782320" id="idm46803148782320-marker">2</a></sup> and then uses a bind mount to link that copy of the file into the container. We can launch a default container with no special configuration, like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>ubuntu:latest<code class="w"> </code>/bin/bash<code class="w"/></pre>&#13;
&#13;
<p>This command uses the <code>docker container run</code> command, which runs <code>docker &#13;
<span class="keep-together">container</span> create</code> and <code>docker container start</code> in the background. Since we want to be able to interact with the container that we are going to create for demonstration purposes, we pass in a few useful arguments. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--rm to remove container on exit" data-tertiary-sortas="rm0" data-type="indexterm" id="idm46803148732096"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-ti for interactive terminal" data-tertiary-sortas="ti" data-type="indexterm" id="idm46803148730336"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-it for interactive terminal" data-tertiary-sortas="it" data-type="indexterm" id="idm46803148728608"/><a data-primary="STDIN open with -i argument" data-type="indexterm" id="idm46803148726880"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="ENTRYPOINT" data-type="indexterm" id="idm46803148726240"/>The <code>--rm</code> argument tells Docker to delete the container when it exits, the <code>-t</code> argument tells Docker to allocate a pseudo-TTY, and the <code>-i</code> argument tells Docker that this is going to be an interactive session and that we want to keep STDIN open. <a data-primary="ENTRYPOINT in Dockerfiles" data-type="indexterm" id="idm46803148704688"/>If there is no <code>ENTRYPOINT</code> defined in the image, then the final argument in the command is the executable and command-line arguments that we want to run within the container, which in this case is the ever-useful <code>/bin/bash</code>. If there is an <code>ENTRYPOINT</code> defined in the image, then the final argument is passed to the <code>ENTRYPOINT</code> process as a list of command-line arguments to that command.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>You might have noticed that the preceding paragraph talks about <code>-i</code> and <code>-t</code>, but the command is using the argument <code>-ti</code>. There is a lot of Unix history that explains why this is, but a <a href="https://nullprogram.com/blog/2020/08/01">quick overview</a> can be found online if you are curious.</p>&#13;
</div>&#13;
&#13;
<p>If we now run the <code>mount</code> command from within the resulting container, we’ll see something similar to this:<a data-primary="mount command" data-secondary="run within container" data-type="indexterm" id="idm46803148698576"/><a data-primary="Linux containers" data-secondary="mount command" data-type="indexterm" id="idm46803148697600"/><a data-primary="system calls" data-secondary="mount" data-tertiary="run within container" data-type="indexterm" id="idm46803148696656"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">root@ebc8cf2d8523:/# </code>mount<code class="w"/>&#13;
<code class="go">overlay on / type overlay (rw,relatime,lowerdir=…,upperdir=…,workdir…)</code>&#13;
<code class="go">proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">tmpfs on /dev type tmpfs (rw,nosuid,mode=755)</code>&#13;
<code class="go">shm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)</code>&#13;
<code class="go">mqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,…,ptmxmode=666)</code>&#13;
<code class="go">sysfs on /sys type sysfs (ro,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">/dev/sda9 on /etc/resolv.conf type ext4 (rw,relatime,data=ordered)</code>&#13;
<code class="go">/dev/sda9 on /etc/hostname type ext4 (rw,relatime,data=ordered)</code>&#13;
<code class="go">/dev/sda9 on /etc/hosts type ext4 (rw,relatime,data=ordered)</code>&#13;
<code class="go">devpts on /dev/console type devpts (rw,nosuid,noexec,relatime,…,ptmxmode=000)</code>&#13;
<code class="go">proc on /proc/sys type proc (ro,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">proc on /proc/sysrq-trigger type proc (ro,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">proc on /proc/irq type proc (ro,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">proc on /proc/bus type proc (ro,nosuid,nodev,noexec,relatime)</code>&#13;
<code class="go">tmpfs on /proc/kcore type tmpfs (rw,nosuid,mode=755)</code>&#13;
<code class="gp">root@ebc8cf2d8523:/#</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>When you see any examples<a data-primary="docker commands" data-primary-sortas="docker-z" data-secondary="shell prompt for interactive containers" data-type="indexterm" id="idm46803148678752"/><a data-primary="root shell prompt for interactive containers" data-type="indexterm" id="idm46803148672896"/><a data-primary="hashes" data-secondary="container ID hash" data-type="indexterm" id="idm46803148672256"/> with a prompt that looks something like <em>root@hashID</em>, it means that you are running a command within the container instead of on the local host.</p>&#13;
&#13;
<p>There are occasions when a container will have been configured with a different hostname instead (e.g., using <code>--name</code> on the CLI), but in the default case, it’s the container ID hash.</p>&#13;
&#13;
<p>It is also possible to change the user that is used inside the container with <code>--user</code>, but by default, it will be <em>root</em>.</p>&#13;
</div>&#13;
&#13;
<p>There are quite a few bind mounts in a container, but in this case, we are interested in this one:<a data-primary="bind mounts" data-secondary="hostname" data-type="indexterm" id="idm46803148667792"/></p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">/dev/sda9 on /etc/hostname type ext4 (rw,relatime,data=ordered)</pre>&#13;
&#13;
<p>While the device number will be different for each container, the part we care about is that the mount point is <em>/etc/hostname</em>. This links the container’s <em>/etc/hostname</em> to the hostname file that Docker has prepared for the container, which by default contains the container’s ID and is not fully qualified with a domain name.</p>&#13;
&#13;
<p>We can check this in the container by running the following:<a data-primary="hostname" data-secondary="hostname command" data-type="indexterm" id="idm46803148657840"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">root@ebc8cf2d8523:/# </code>hostname<code class="w"> </code>-f<code class="w"/>&#13;
<code class="go">ebc8cf2d8523</code>&#13;
<code class="gp">root@ebc8cf2d8523:/# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Don’t forget to <code>exit</code> the container shell to return to the local host when finished.<a data-primary="exit command for exiting container shell" data-type="indexterm" id="idm46803148661440"/><a data-primary="docker commands" data-primary-sortas="docker-z" data-secondary="shell prompt for interactive containers" data-tertiary="exit command for exiting container shell" data-type="indexterm" id="idm46803148660768"/></p>&#13;
</div>&#13;
&#13;
<p>To set the hostname specifically, we can use the <code>--hostname</code> argument to pass in a more specific value:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--hostname" data-tertiary-sortas="hostname" data-type="indexterm" id="idm46803148597520"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--hostname<code class="o">=</code><code class="s2">"mycontainer.example.com"</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>ubuntu:latest<code class="w"> </code>/bin/bash<code class="w"/></pre>&#13;
&#13;
<p>Then, from within the container, we’ll see that the fully qualified hostname is defined as requested:<a data-startref="ch05-host" data-type="indexterm" id="idm46803148559488"/><a data-startref="ch05-host2" data-type="indexterm" id="idm46803148558880"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">root@mycontainer:/# </code>hostname<code class="w"> </code>-f<code class="w"/>&#13;
<code class="go">mycontainer.example.com</code>&#13;
<code class="gp">root@mycontainer:/# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Domain Name Service" data-type="sect3"><div class="sect3" id="idm46803148775664">&#13;
<h3>Domain Name Service</h3>&#13;
&#13;
<p>Just like <em>/etc/hostname</em>, the <em>resolv.conf</em> file that configures Domain Name Service (DNS) resolution is managed via a bind mount between the host and container:<a data-primary="Linux containers" data-secondary="configuring" data-tertiary="Domain Name Service" data-type="indexterm" id="idm46803148554752"/><a data-primary="DNS (Domain Name Service)" data-secondary="configuring Linux containers" data-type="indexterm" id="idm46803148553504"/><a data-primary="Domain Name Service" data-see="DNS" data-type="indexterm" id="idm46803148552624"/></p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">/dev/sda9 on /etc/resolv.conf type ext4 (rw,relatime,data=ordered)</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Details about the <em>resolve.conf</em> file can be found <a href="https://sslhow.com/understanding-etc-resolv-conf-file-in-linux">online</a>.</p>&#13;
</div>&#13;
&#13;
<p>By default, this is an exact copy of the Docker host’s <em>resolv.conf</em> file. If you didn’t want this, you could use a combination of the <code>--dns</code> and <code>--dns-search</code> arguments to override this behavior in the container:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--dns" data-tertiary-sortas="dns" data-type="indexterm" id="idm46803148523872"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--dns-search" data-tertiary-sortas="dns-search" data-type="indexterm" id="idm46803148522192"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--dns<code class="o">=</code><code class="m">8</code>.8.8.8<code class="w"> </code>--dns<code class="o">=</code><code class="m">8</code>.8.4.4<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--dns-search<code class="o">=</code>example1.com<code class="w"> </code>--dns-search<code class="o">=</code>example2.com<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>ubuntu:latest<code class="w"> </code>/bin/bash<code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If you want to leave the search domain completely unset, then use <code>--dns-search=.</code></p>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before">Within the container, you would still see a bind mount, but the file contents would no longer reflect the host’s <em>resolv.conf</em>; instead, it would now look like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">root@0f887071000a:/# </code>more<code class="w"> </code>/etc/resolv.conf<code class="w"/>&#13;
<code class="go">nameserver 8.8.8.8</code>&#13;
<code class="go">nameserver 8.8.4.4</code>&#13;
<code class="go">search example1.com example2.com</code>&#13;
<code class="gp">root@0f887071000a:/# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="MAC address" data-type="sect3"><div class="sect3" id="idm46803148544640">&#13;
<h3>MAC address</h3>&#13;
&#13;
<p>Another important piece of information that you can configure is the media access control (MAC) address for the container.<a data-primary="Linux containers" data-secondary="configuring" data-tertiary="MAC address" data-type="indexterm" id="idm46803148424880"/><a data-primary="MAC (media access control) address" data-secondary="configuring Linux containers" data-type="indexterm" id="idm46803148455776"/></p>&#13;
&#13;
<p>Without any configuration, a container will receive a calculated MAC address that starts with the <em>02:42:ac:11</em> prefix.</p>&#13;
&#13;
<p>If you need to specifically set this to a value, you can do so by running something similar to this:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--mac-address" data-tertiary-sortas="mac-address" data-type="indexterm" id="idm46803148453424"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--mac-address<code class="o">=</code><code class="s2">"a2:11:aa:22:bb:33"</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>ubuntu:latest<code class="w"> </code>/bin/bash<code class="w"/></pre>&#13;
&#13;
<p>Normally, you will not need to do that. But sometimes you want to reserve a particular set of MAC addresses for your containers to avoid conflicting with other virtualization layers that use the same private block as Docker.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Be very careful when customizing<a data-primary="MAC (media access control) address" data-secondary="warning about customizing" data-type="indexterm" id="idm46803148374896"/> the MAC address settings. It is possible to cause ARP contention on your network if two systems advertise the same MAC address. If you have a strong need to do this, try to keep your locally administered address ranges within some of the official ranges, like <em>x2-xx-xx-xx-xx-xx</em>, <em>x6-xx-xx-xx-xx-xx</em>, <em>xA-xx-xx-xx-xx-xx</em>, and <em>xE-xx-xx-xx-xx-xx</em> (with <em>x</em> being any valid hexadecimal character).<a data-startref="ch05-bascon" data-type="indexterm" id="idm46803148371712"/></p>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Storage Volumes" data-type="sect2"><div class="sect2" id="idm46803148370880">&#13;
<h2>Storage Volumes</h2>&#13;
&#13;
<p>There are times when the default disk space<a data-primary="Linux containers" data-secondary="creating a container" data-tertiary="storage volumes" data-type="indexterm" id="ch05-stor"/><a data-primary="storage volumes for Linux containers" data-type="indexterm" id="ch05-stor2"/><a data-primary="persistent storage" data-see="storage volumes for Linux containers" data-type="indexterm" id="idm46803148366752"/> allocated to a container, or the container’s ephemeral nature, is not appropriate for the job at hand, so you’ll need storage that can persist between container deployments.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Mounting storage from the Docker host is not generally advisable because it ties your container to a particular Docker host for its persistent state. But for cases like temporary cache files or other semi-ephemeral states, it can make sense.</p>&#13;
</div>&#13;
&#13;
<p>For times like this, you can leverage the <code>--mount/-v</code> command to mount directories and individual files from the host server into the container. It is important that you use fully qualified paths in the <code>--mount/-v</code> argument. The following example mounts <em>/mnt/session_data</em> to <em>/data</em> within the container:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--mount storage volume" data-tertiary-sortas="mount" data-type="indexterm" id="idm46803148362496"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--mount<code class="w"> </code><code class="nv">type</code><code class="o">=</code>bind,target<code class="o">=</code>/mnt/session_data,source<code class="o">=</code>/data<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>ubuntu:latest<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">root@0f887071000a:/# </code>mount<code class="w"> </code><code class="p">|</code><code class="w"> </code>grep<code class="w"> </code>data<code class="w"/>&#13;
<code class="go">/dev/sda9 on /data type ext4 (rw,relatime,data=ordered)</code>&#13;
<code class="gp">root@0f887071000a:/# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>For bind mounts specifically,<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="-v for bind mounts" data-tertiary-sortas="v" data-type="indexterm" id="idm46803148292560"/><a data-primary="bind mounts" data-secondary="docker container run -v command" data-type="indexterm" id="idm46803148290864"/> you can use the <code>-v</code> argument to shorten the command. When using the <code>-v</code> argument, you will notice here that the source and target files/directories are separated by a colon(:).</p>&#13;
&#13;
<p>It is also important to note that volumes are mounted read-write by default. You can easily make <code>docker</code> mount the file or directory read-only by adding <code>,readonly</code> to end the of the <code>--mount</code> arguments, or by adding <code>:ro</code> to the end of the <code>-v</code> arguments.</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>-v<code class="w"> </code>/mnt/session_data:/data:ro<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>ubuntu:latest<code class="w"> </code>/bin/bash<code class="w"/></pre>&#13;
</div>&#13;
&#13;
<p>Neither the host mount point nor the mount point in the container needs to preexist for this command to work properly. If the host mount point does not exist already, then it will be created as a directory. This could cause you some issues if you were trying to point to a file instead of a directory.</p>&#13;
&#13;
<p>In the mount options, you can see that the filesystem was mounted read-write on <span class="keep-together"><em>/data</em></span> as expected.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46803148275568">&#13;
<h1>SELinux and Volume Mounts</h1>&#13;
<p>If you have SELinux enabled on<a data-primary="storage volumes for Linux containers" data-secondary="SELinux" data-type="indexterm" id="idm46803148260208"/><a data-primary="SELinux security" data-secondary="volume mounts" data-type="indexterm" id="idm46803148259264"/><a data-primary="Linux" data-secondary="SELinux and volume mounts" data-type="indexterm" id="idm46803148258320"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="z and Z options for volume mounts" data-type="indexterm" id="idm46803148257408"/><a data-primary="bind mounts" data-secondary="docker container run -v command" data-tertiary="z and Z options (SELinux)" data-type="indexterm" id="idm46803148255952"/> your Docker host, you may get a “Permission Denied” error when trying to mount a volume into your container. You can handle this by using one of the <code>z</code> options to the Docker command for mounting volumes:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The lowercase <code>z</code> option indicates that the bind-mount content is shared among multiple containers.</p>&#13;
</li>&#13;
<li>&#13;
<p>The uppercase <code>Z</code> option indicates that the bind-mount content is private and unshared.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p class="pagebreak-before">If you are going to share a volume between containers, you can use the <code>z</code> option to the volume mount:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-v<code class="w"> </code>/app/dhcpd/etc:/etc/dhcpd:z<code class="w"> </code>dhcpd<code class="w"/></pre>&#13;
&#13;
<p>However, the best option is actually the <code>Z</code> option to the volume mount command, which will set the directory with the exact MCS label (e.g., <code>chcon … -l s0:c1,c2</code>) that the container will be using. This provides for the best security and will allow only a single container to mount the volume:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-v<code class="w"> </code>/app/dhcpd/etc:/etc/dhcpd:Z<code class="w"> </code>dhcpd<code class="w"/></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Use extreme caution with the <code>z</code> options. Bind-mounting a system directory such as <em>/etc</em> or <em>/var</em> with the <code>Z</code> option will very likely render your system inoperable and require you to use SELinux tools to <a href="https://www.thegeekdiary.com/understanding-selinux-file-labelling-and-selinux-context">relabel the host machine manually</a>.</p>&#13;
</div>&#13;
</div></aside>&#13;
&#13;
<p>If the container application is designed to write into <em>/data</em>, then this data will be visible on the host filesystem in <em>/mnt/session_data</em> and will remain available when this container stops and a new container starts with the same volume mounted.</p>&#13;
&#13;
<p>It is possible to tell Docker that the root volume of your container should be mounted read-only<a data-primary="read-only" data-secondary="mount option" data-type="indexterm" id="idm46803148184320"/><a data-primary="system calls" data-secondary="mount" data-tertiary="root volume as read-only" data-type="indexterm" id="idm46803148183344"/><a data-primary="mount command" data-secondary="root volume as read-only" data-type="indexterm" id="idm46803148182160"/> so that processes within the container cannot write anything to the root filesystem. This prevents things like logfiles, which a developer may be unaware of, from filling up the container’s allocated disk in production. When it’s used in conjunction with a mounted volume, you can ensure that data is written only into expected locations.</p>&#13;
&#13;
<p>In the previous example, we could accomplish this simply by adding &#13;
<span class="keep-together"><code>--read-only=true</code></span> to the command:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--read-only" data-tertiary-sortas="read-only" data-type="indexterm" id="idm46803148179888"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--read-only<code class="o">=</code><code class="nb">true</code><code class="w"> </code>-v<code class="w"> </code>/mnt/session_data:/data<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>ubuntu:latest<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">root@df542767bc17:/# </code>mount<code class="w"> </code><code class="p">|</code><code class="w"> </code>grep<code class="w"> </code><code class="s2">" / "</code><code class="w"/>&#13;
<code class="go">overlay on / type overlay (ro,relatime,lowerdir=…,upperdir=…,workdir=…)</code>&#13;
<code class="gp">root@df542767bc17:/# </code>mount<code class="w"> </code><code class="p">|</code><code class="w"> </code>grep<code class="w"> </code>data<code class="w"/>&#13;
<code class="go">/dev/sda9 on /data type ext4 (rw,relatime,data=ordered)</code>&#13;
<code class="gp">root@df542767bc17:/# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
&#13;
<p>If you look closely at the mount options for the root directory, you’ll notice that they are mounted with the <code>ro</code> option, which makes it read-only. However, the <span class="keep-together"><em>/session_data</em></span> mount is still mounted with the <code>rw</code> option so that our application can successfully write to the one volume to which it’s designed to write.</p>&#13;
&#13;
<p>Sometimes it is necessary to make a directory like <em>/tmp</em> writable,<a data-primary="filesystem layers of Linux containers" data-secondary="tmpfs for writable within read-only" data-type="indexterm" id="idm46803148074688"/><a data-primary="tmpfs for writable within read-only" data-type="indexterm" id="idm46803148089120"/> even when the rest of the container is read-only. For this use case, you can use the <code>--mount type=tmpfs</code> argument with <code>docker container run</code> so that you can mount a <em>tmpfs</em> filesystem into the container. The <em>tmpfs</em> filesystems are completely in-memory. They will be very fast, but they are also ephemeral and will utilize additional system memory. Any data in these <em>tmpfs</em> directories will be lost when the container is stopped. The following example shows a container being launched with a 256 MB <em>tmpfs</em> filesystem mounted at <em>/tmp</em>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--read-only<code class="o">=</code><code class="nb">true</code><code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--mount<code class="w"> </code><code class="nv">type</code><code class="o">=</code>tmpfs,destination<code class="o">=</code>/tmp,tmpfs-size<code class="o">=</code>256M<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>ubuntu:latest<code class="w"> </code>/bin/bash<code class="w"/>&#13;
&#13;
<code class="gp">root@25b4f3632bbc:/# </code>df<code class="w"> </code>-h<code class="w"> </code>/tmp<code class="w"/>&#13;
<code class="go">Filesystem      Size  Used Avail Use% Mounted on</code>&#13;
<code class="go">tmpfs           256M     0  256M   0% /tmp</code>&#13;
<code class="gp">root@25b4f3632bbc:/# </code>grep<code class="w"> </code>/tmp<code class="w"> </code>/etc/mtab<code class="w"/>&#13;
<code class="go">tmpfs /tmp tmpfs rw,nosuid,nodev,noexec,relatime,size=262144k 0 0</code>&#13;
<code class="gp">root@25b4f3632bbc:/# </code><code class="nb">exit</code><code class="w"/></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Containers should be designed<a data-primary="stateless containers" data-type="indexterm" id="idm46803148047760"/><a data-primary="dependencies" data-secondary="persistent storage" data-type="indexterm" id="idm46803148047152"/> to be stateless whenever possible. Managing storage creates undesirable dependencies and can easily make deployment scenarios much more complicated.<a data-startref="ch05-stor" data-type="indexterm" id="idm46803148046080"/><a data-startref="ch05-stor2" data-type="indexterm" id="idm46803148045408"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Resource Quotas" data-type="sect2"><div class="sect2" id="idm46803148370288">&#13;
<h2>Resource Quotas</h2>&#13;
&#13;
<p>When people discuss the types<a data-primary="Linux containers" data-secondary="creating a container" data-tertiary="resource quotas" data-type="indexterm" id="ch05-resou"/><a data-primary="resource quotas" data-secondary="about" data-type="indexterm" id="idm46803148041392"/> of problems they must often cope with when working in the cloud, the “noisy neighbor” is often near the top of the list. The basic problem this term refers to is that other applications running on the same physical system as yours can have a noticeable impact on your performance and resource availability.</p>&#13;
&#13;
<p>VMs have the advantage that you can easily and very tightly control how much memory and CPU, among other resources, are allocated to the VM. <a data-primary="cgroups in Linux kernel" data-secondary="resource quotas" data-type="indexterm" id="idm46803148039712"/><a data-primary="virtual machines (VM)" data-secondary="containers versus" data-tertiary="resource quotas" data-type="indexterm" id="idm46803148038736"/><a data-primary="Linux" data-secondary="kernel" data-tertiary="resource quotas" data-type="indexterm" id="idm46803148007920"/><a data-primary="control groups" data-see="cgroups in Linux kernel" data-type="indexterm" id="idm46803148006832"/><a data-primary="Linux" data-secondary="control groups" data-see="cgroups in Linux kernel" data-type="indexterm" id="idm46803148005984"/><a data-primary="Linux" data-secondary="kernel" data-see="cgroups in Linux kernel" data-tertiary="control groups" data-type="indexterm" id="idm46803148004896"/>When using Docker, you must instead leverage the cgroup functionality in the Linux kernel to control the resources that are available to a Linux container. The <code>docker container create</code> and <code>docker container run</code> commands directly support configuring CPU, memory, swap, and storage I/O restrictions when you create a container.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Constraints are normally applied<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="update to adjust resource quotas" data-type="indexterm" id="idm46803148001376"/> at the time of container creation. If you need to change them, you can use the <code>docker container update</code> command or deploy a new container with the adjustments.</p>&#13;
</div>&#13;
&#13;
<p>There is an important caveat here. While Docker supports various resource limits, you must have these capabilities enabled in your kernel for Docker to take advantage of them. You might need to add these as command-line parameters to your kernel on startup. <a data-primary="docker system" data-primary-sortas="docker-z" data-secondary="info" data-tertiary="kernel information" data-type="indexterm" id="idm46803147999104"/>To figure out if your kernel supports these limits, run <code>docker system info</code>. If you are missing any support, you will get warning messages at the bottom, like this:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">WARNING: No swap limit support</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The details regarding getting cgroup support configured for your kernel are distribution specific, so you should consult the <a href="https://oreil.ly/Z70ZO">Docker documentation</a><sup><a data-type="noteref" href="ch05.html#idm46803147988272" id="idm46803147988272-marker">3</a></sup> if you need help configuring things.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="CPU shares" data-type="sect3"><div class="sect3" id="idm46803149235376">&#13;
<h3>CPU shares</h3>&#13;
&#13;
<p>Docker has several ways to limit<a data-primary="resource quotas" data-secondary="CPU shares" data-type="indexterm" id="ch05-shar"/><a data-primary="CPU shares" data-type="indexterm" id="ch05-shar2"/> CPU usage by applications in containers. The original method, still commonly used, is the concept of <em>CPU shares</em>. We’ll present other options as well.</p>&#13;
&#13;
<p>The computing power of all the CPU cores in a system is considered to be the full pool of shares. Docker assigns the number 1,024 to represent the full pool. By configuring a container’s CPU shares, you can dictate how much time the container gets to use the CPU. If you want the container to be able to use at most half of the computing power of the system, then you would allocate it 512 shares. These are not exclusive shares, meaning that assigning all 1,024 shares to a container does not prevent all other containers from running. Rather, it’s a hint to the scheduler about how long each container should be able to run each time it’s scheduled. If we have one container that is allocated 1,024 shares (the default) and two that are allocated 512, they will all get scheduled the same number of times. But if the normal amount of CPU time for each process is 100 microseconds, the containers with 512 shares will run for 50 microseconds each time, whereas the container with 1,024 shares will run for 100 microseconds.</p>&#13;
&#13;
<p>Let’s explore a little bit how this works in practice. <a data-primary="stress command" data-type="indexterm" id="idm46803147983920"/>For the following examples, we’ll use a new Docker image that contains the <a href="https://linux.die.net/man/1/stress"><code>stress</code> command</a> for pushing a system to its limits.</p>&#13;
&#13;
<p class="pagebreak-before">When we run <code>stress</code> without any cgroup constraints, it will use as many resources as we tell it to. The following command creates a load average of around five by creating two CPU-bound processes, one I/O-bound process, and two memory allocation processes. For all of the following examples, we are running on a system with two CPUs.</p>&#13;
&#13;
<p>Note that in the following command, everything following the container image name is related to the <code>stress</code> command, not the <code>docker</code> command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>spkane/train-os<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code>--timeout<code class="w"> </code>120s<code class="w"/></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>This should be a reasonable command to run on any modern computer system, but be aware that it is going to stress the host system. So don’t do this in a location that can’t take the additional load, or even a possible failure, due to resource starvation.</p>&#13;
</div>&#13;
&#13;
<p>If you run the <code>top</code> or <code>htop</code> command<a data-primary="top command after stress command" data-type="indexterm" id="idm46803147911712"/><a data-primary="htop command after stress command" data-type="indexterm" id="idm46803147911008"/> on the Docker host, near the end of the two-minute run, you can see how the system is affected by the load created by the <code>stress</code> program:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>top<code class="w"> </code>-bn1<code class="w"> </code><code class="p">|</code><code class="w"> </code>head<code class="w"> </code>-n<code class="w"> </code><code class="m">15</code><code class="w"/>&#13;
<code class="go">top - 20:56:36 up 3 min,  2 users,  load average: 5.03, 2.02, 0.75</code>&#13;
<code class="go">Tasks:  88 total,   5 running,  83 sleeping,   0 stopped,   0 zombie</code>&#13;
<code class="gp">%</code>Cpu<code class="o">(</code>s<code class="o">)</code>:<code class="w"> </code><code class="m">29</code>.8<code class="w"> </code>us,<code class="w"> </code><code class="m">35</code>.2<code class="w"> </code>sy,<code class="w"> </code><code class="m">0</code>.0<code class="w"> </code>ni,<code class="w"> </code><code class="m">32</code>.0<code class="w"> </code>id,<code class="w"> </code><code class="m">0</code>.8<code class="w"> </code>wa,<code class="w"> </code><code class="m">1</code>.6<code class="w"> </code>hi,<code class="w"> </code><code class="m">0</code>.6<code class="w"> </code>si,<code class="w"> </code><code class="m">0</code>.0<code class="w"> </code>st<code class="w"/>&#13;
<code class="go">KiB Mem:   1021856 total,   270148 used,   751708 free,    42716 buffers</code>&#13;
<code class="go">KiB Swap:        0 total,        0 used,        0 free.    83764 cached Mem</code>&#13;
&#13;
<code class="go">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</code>&#13;
<code class="go">  810 root      20   0    7316     96      0 R  44.3  0.0   0:49.63 stress</code>&#13;
<code class="go">  813 root      20   0    7316     96      0 R  44.3  0.0   0:49.18 stress</code>&#13;
<code class="go">  812 root      20   0  138392  46936    996 R  31.7  4.6   0:46.42 stress</code>&#13;
<code class="go">  814 root      20   0  138392  22360    996 R  31.7  2.2   0:46.89 stress</code>&#13;
<code class="go">  811 root      20   0    7316     96      0 D  25.3  0.0   0:21.34 stress</code>&#13;
<code class="go">    1 root      20   0  110024   4916   3632 S   0.0  0.5   0:07.32 systemd</code>&#13;
<code class="go">    2 root      20   0       0      0      0 S   0.0  0.0   0:00.04 kthreadd</code>&#13;
<code class="go">    3 root      20   0       0      0      0 S   0.0  0.0   0:00.11 ksoftir…</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Docker Desktop users on non-Linux systems<a data-primary="monitoring" data-secondary="Docker Desktop VM filesystem read-only" data-type="indexterm" id="idm46803147904480"/><a data-primary="Docker Desktop" data-primary-sortas="docker-a" data-secondary="VM filesystem read-only" data-type="indexterm" id="idm46803147849808"/> may discover that Docker has made the VM filesystem read-only, and it does not contain many useful tools for monitoring the VM. For these demos where you want to be able to monitor the resource usage of various processes, you can work around this by doing something like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-it<code class="w"> </code>--pid<code class="o">=</code>host<code class="w"> </code>alpine<code class="w"> </code>sh<code class="w"/>&#13;
<code class="go">/ # apk update</code>&#13;
<code class="go">/ # apk add htop</code>&#13;
<code class="go">/ # htop -p $(pgrep stress | tr '\n' ',')</code>&#13;
<code class="go">/ # exit</code></pre>&#13;
&#13;
<p>Be aware that the preceding <code>htop</code> command will give you an error unless <code>stress</code> is actively running when you launch <code>htop</code>, since no processes will be returned by the <code>pgrep</code> command.</p>&#13;
&#13;
<p>You will also want to exit and rerun <code>htop</code> each time you run a new <code>stress</code> instance.</p>&#13;
</div>&#13;
&#13;
<p>If you want to run the same <code>stress</code> command again, with only half the amount of available CPU time, you can do so like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--cpu-shares<code class="w"> </code><code class="m">512</code><code class="w"> </code>spkane/train-os<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code>--timeout<code class="w"> </code>120s<code class="w"/></pre>&#13;
&#13;
<p>The <code>--cpu-shares 512</code> is the flag<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--cpu-shares" data-tertiary-sortas="cpu-shares" data-type="indexterm" id="idm46803147719984"/> that does the magic, allocating 512 CPU shares to this container. The effect of this argument might not be noticeable on a system that is not very busy. That’s because the container will continue to be scheduled for the same time-slice length whenever it has work to do unless the system is constrained for resources. So in our case, the results of a <code>top</code> command on the host system will likely look the same, unless you run a few more containers to give the CPU something else to do.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Unlike VMs, Docker’s <a data-primary="cgroups in Linux kernel" data-secondary="resource quotas" data-type="indexterm" id="idm46803147716736"/>cgroup-based constraints on CPU shares can have unexpected consequences. They are not hard limits; they are relative limits, similar to the <code>nice</code> command. An example is a container that is constrained to half the CPU shares but is on a system that is not very busy. Since the CPU is not busy, the limit on the CPU shares would have only a limited effect because there is no competition in the scheduler pool. When a second container that uses a lot of CPU is deployed to the same system, suddenly the effect of the constraint on the first container will be noticeable. Consider this carefully when constraining containers and allocating resources.<a data-startref="ch05-shar" data-type="indexterm" id="idm46803147715216"/><a data-startref="ch05-shar2" data-type="indexterm" id="idm46803147714512"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="CPU pinning" data-type="sect3"><div class="sect3" id="idm46803147992176">&#13;
<h3>CPU pinning</h3>&#13;
&#13;
<p>It is also possible to pin a container<a data-primary="resource quotas" data-secondary="CPU pinning" data-type="indexterm" id="idm46803147707472"/><a data-primary="CPU pinning of a container" data-type="indexterm" id="idm46803147706624"/> to one or more CPU cores. This means that work for this container will be scheduled only on the cores that have been assigned to this container. That is useful if you want to hard-shard CPUs between applications or if you have applications that need to be pinned to a particular CPU for things like cache efficiency.</p>&#13;
&#13;
<p>In the following example, we are running a stress container pinned to the first of two CPUs, with 512 CPU shares:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--cpuset-cpus" data-tertiary-sortas="cpuset-cpus" data-type="indexterm" id="idm46803147705376"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--cpu-shares<code class="w"> </code><code class="m">512</code><code class="w"> </code>--cpuset-cpus<code class="o">=</code><code class="m">0</code><code class="w"> </code>spkane/train-os<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code>--timeout<code class="w"> </code>120s<code class="w"/></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>The <code>--cpuset-cpus</code> argument is zero-indexed, so your first CPU core is 0. If you tell Docker to use a CPU core that does not exist on the host system, you will get a <code>Cannot start container</code> error. On a two-CPU example host, you could test this by using <code>--cpuset-cpus=0-2</code>.</p>&#13;
</div>&#13;
&#13;
<p>If you run <code>top</code> again, you should notice that the percentage of CPU time spent in user space (<code>us</code>) is lower than it previously was, since we have restricted two CPU-bound processes to a single CPU:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">%Cpu(s): 18.5 us, 22.0 sy, 0.0 ni, 57.6 id, 0.5 wa, 1.0 hi, 0.3 si, 0.0 st</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>When you use CPU pinning, additional CPU sharing restrictions on the container only take into account other containers running on the same set of cores.</p>&#13;
</div>&#13;
&#13;
<p>Using the CPU Completely Fair Scheduler (CFS) within the Linux kernel, you can alter the CPU quota for a given container by setting the <code>--cpu-quota</code> flag to a valid value when launching the container with <code>docker container run</code>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Simplifying CPU quotas" data-type="sect3"><div class="sect3" id="idm46803147632496">&#13;
<h3>Simplifying CPU quotas</h3>&#13;
&#13;
<p>While CPU shares were the original<a data-primary="resource quotas" data-secondary="CPU quotas simplified" data-type="indexterm" id="idm46803147631728"/><a data-primary="CPU quotas simplified" data-type="indexterm" id="idm46803147630976"/> mechanism in Docker for managing CPU limits, Docker has evolved a great deal since, and one of the ways that it now makes users’ lives easier is by greatly simplifying how CPU quotas can be set. Instead of trying to set correct CPU shares and quotas yourself, you can now simply tell Docker how much CPU you would like to be available to your container, and it will do the math required to set the underlying cgroups correctly.</p>&#13;
&#13;
<p>The <code>--cpus</code> command can be set to a floating-point number between 0.01 and the number of CPU cores on the Docker server:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--cpus" data-tertiary-sortas="cpus" data-type="indexterm" id="idm46803147628352"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--cpus<code class="o">=</code><code class="s2">".25"</code><code class="w"> </code>spkane/train-os<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code>--timeout<code class="w"> </code>60s<code class="w"/></pre>&#13;
&#13;
<p>If you try to set the value too high, you’ll get an error message from Docker (not the <code>stress</code> application) that will give you the correct range of CPU cores that you have to work with:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--cpus<code class="o">=</code><code class="s2">"40.25"</code><code class="w"> </code>spkane/train-os<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code>--timeout<code class="w"> </code>60s<code class="w"/>&#13;
<code class="go">docker: Error response from daemon: Range of CPUs is from</code>&#13;
<code class="go">    0.01 to 4.00, as there are only 4 CPUs available.</code>&#13;
<code class="go">See 'docker container run --help'.</code></pre>&#13;
&#13;
<p>The <code>docker container update</code> command<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="update to adjust resource quotas" data-type="indexterm" id="idm46803147519904"/> can be used to dynamically adjust the resource limits of one or more containers. You could adjust the CPU allocation on two containers simultaneously, for example, like so:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>update<code class="w"> </code>--cpus<code class="o">=</code><code class="s2">"1.5"</code><code class="w"> </code>092c5dc85044<code class="w"> </code>92b797f12af1<code class="w"/></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Docker sees CPUs the same way that Linux sees them. Hyper-threading and cores are interpreted by Linux and exposed via the special file <em>/proc/cpuinfo</em>. When you use the <code>--cpus</code> command in Docker, you are referring to how many of the entries in this file you want the container to have access to, whether they refer to a standard core or a hyper-threaded core.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Memory" data-type="sect3"><div class="sect3" id="idm46803147478960">&#13;
<h3>Memory</h3>&#13;
&#13;
<p>We can control how much memory<a data-primary="resource quotas" data-secondary="memory" data-type="indexterm" id="ch05-mem"/><a data-primary="memory resources for container" data-type="indexterm" id="ch05-mem2"/> a container can access in a manner similar to constraining the CPU. There is, however, one fundamental difference: while constraining the CPU only impacts the application’s priority for CPU time, the<a data-primary="memory resources for container" data-secondary="hard limit" data-type="indexterm" id="idm46803147455520"/> memory limit is a <em>hard</em> limit. Even on an unconstrained system with 96 GB of free memory, if we tell a container that it may have access only to 24 GB, then it will only ever get to use 24 GB regardless of the free memory on the system. Because of the way the virtual memory system works on Linux, it’s possible to allocate more memory to a container than the system has actual RAM. In this case, the container will resort to using swap, just like a normal Linux process.</p>&#13;
&#13;
<p>Let’s start a container with a memory constraint by passing the <code>--memory</code> option to the <code>docker container run</code> command:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--memory" data-tertiary-sortas="memory" data-type="indexterm" id="idm46803147453008"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--memory<code class="w"> </code>512m<code class="w"> </code>spkane/train-os<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code>--timeout<code class="w"> </code>10s<code class="w"/></pre>&#13;
&#13;
<p>When you use the <code>--memory</code> option alone, you are setting both the amount of RAM and the amount of swap that the container will have access to. So by using <code>--memory 512m</code> here, we’ve constrained the container to 512 MB of RAM and 512 MB of additional swap space. Docker supports <code>b</code>, <code>k</code>, <code>m</code>, or <code>g</code>, representing bytes, kilobytes, megabytes, or gigabytes, respectively. If your system somehow runs Linux and Docker and has multiple terabytes of memory, then unfortunately you’re going to have to specify it in gigabytes.</p>&#13;
&#13;
<p>If you would like to set the swap separately<a data-primary="memory resources for container" data-secondary="memory swap option" data-type="indexterm" id="idm46803147419232"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--memory-swap" data-tertiary-sortas="memory-swap" data-type="indexterm" id="idm46803147418288"/> or disable it altogether, you need to also use the <code>--memory-swap</code> option. This defines the total amount of memory and swap available to the container. If we rerun our previous command, like so:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--memory<code class="w"> </code>512m<code class="w"> </code>--memory-swap<code class="o">=</code>768m<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>spkane/train-os<code class="w"> </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>--timeout<code class="w"> </code>10s<code class="w"/></pre>&#13;
&#13;
<p>then we’re telling the kernel that this container can have access to 512 MB of memory and 256 MB of additional swap space. Setting the <code>--memory-swap</code> option to <code>-1</code> will allow the container to use as much swap as is available on the underlying system and if <code>--memory-swap</code> and <code>--memory</code> are set to the same positive value, then the container will not have any access to swap.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Again, unlike CPU shares, <a data-primary="memory resources for container" data-secondary="hard limit" data-type="indexterm" id="idm46803147356944"/>memory is a hard limit! This is good because the constraint doesn’t suddenly have a noticeable effect on the container when another container is deployed to the system. But it means you need to be careful that the limit closely matches your container’s needs because there is no wiggle room. <a data-primary="processes" data-secondary="killed when out of memory" data-type="indexterm" id="idm46803147355872"/>An out-of-memory container causes the kernel to behave just like it would if the system were out of memory. It will try to find a process to kill so that it can free up space. This is a common failure case where containers have their memory limits set too low. <a data-primary="exit codes" data-secondary="137 out of memory error" data-type="indexterm" id="idm46803147324400"/><a data-primary="out of memory (OOM)" data-type="indexterm" id="idm46803147323664"/><a data-primary="Linux" data-secondary="kernel" data-tertiary="out of memory (OOM)" data-type="indexterm" id="idm46803147323024"/><a data-primary="memory resources for container" data-secondary="out of memory" data-type="indexterm" id="idm46803147321808"/>The telltale sign of this issue is a container exit code of 137 and kernel out-of-memory (OOM) messages in the Docker server’s <code>dmesg</code> output.</p>&#13;
</div>&#13;
&#13;
<p>So, what happens if a container reaches its memory limit? Well, let’s give it a try by modifying one of our previous commands and lowering the memory significantly:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>--memory<code class="w"> </code>100m<code class="w"> </code>spkane/train-os<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code>--timeout<code class="w"> </code>10s<code class="w"/></pre>&#13;
&#13;
<p>While all of our other runs of the <code>stress</code> container ended with a line like this:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">stress: info: [17] successful run completed in 10s</pre>&#13;
&#13;
<p>we see that this run quickly fails with a line similar to this:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">stress: FAIL: [1] (451) failed run completed in 0s</pre>&#13;
&#13;
<p>This is because the container tries to allocate more memory than it is allowed, and the Linux OOM killer is invoked and starts killing processes within the cgroup to reclaim memory. In this case, our container has a single-parent process that has spawned a few children processes, and when the OOM killer kills one of the children processes, the parent process cleans everything up and exits with an error.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Docker has features that allow<a data-primary="out of memory (OOM)" data-secondary="tuning and disabling" data-type="indexterm" id="idm46803147265712"/><a data-primary="memory resources for container" data-secondary="out of memory" data-tertiary="tuning and disabling" data-type="indexterm" id="idm46803147265088"/> you to tune and disable the Linux OOM killer by using the <code>--oom-kill-disable</code> and the &#13;
<span class="keep-together"><code>--oom-score-adj</code></span> arguments to <code>docker container run</code>, but they are not recommended for almost any use cases.</p>&#13;
</div>&#13;
&#13;
<p>If you access your Docker server, you can see the kernel message related to this event by running <code>dmesg</code>. The output will look something like this:<a data-primary="dmesg" data-type="indexterm" id="idm46803147253136"/></p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">[ 4210.403984] stress invoked oom-killer: gfp_mask=0x24000c0 …&#13;
[ 4210.404899] stress cpuset=5bfa65084931efabda59d9a70fa8e88 …&#13;
[ 4210.405951] CPU: 3 PID: 3429 Comm: stress Not tainted 4.9 …&#13;
[ 4210.406624] Hardware name:   BHYVE, BIOS 1.00 03/14/2014&#13;
…&#13;
[ 4210.408978] Call Trace:&#13;
[ 4210.409182]  [&lt;ffffffff94438115&gt;] ? dump_stack+0x5a/0x6f&#13;
….&#13;
[ 4210.414139]  [&lt;ffffffff947f9cf8&gt;] ? page_fault+0x28/0x30&#13;
[ 4210.414619] Task in /docker-ce/docker/5…3&#13;
killed as a result of limit of /docker-ce/docker/5…3&#13;
[ 4210.416640] memory: usage 102380kB, limit 102400kB, failc …&#13;
[ 4210.417236] memory+swap: usage 204800kB, limit 204800kB,  …&#13;
[ 4210.417855] kmem: usage 1180kB, limit 9007199254740988kB, …&#13;
[ 4210.418485] Memory cgroup stats for /docker-ce/docker/5…3:&#13;
cache:0KB rss:101200KB rss_huge:0KB mapped_file:0KB dirty:0KB&#13;
writeback:11472KB swap:102420KB inactive_anon:50728KB&#13;
active_anon:50472KB inactive_file:0KB active_file:0KB unevictable:0KB&#13;
…&#13;
[ 4210.426783] Memory cgroup out of memory: Kill process 3429…&#13;
[ 4210.427544] Killed process 3429 (stress) total-vm:138388kB,&#13;
anon-rss:44028kB, file-rss:900kB, shmem-rss:0kB&#13;
[ 4210.442492] oom_reaper: reaped process 3429 (stress), now&#13;
anon-rss:0kB, file-rss:0kB, shmem-rss:0kB</pre>&#13;
&#13;
<p>This OOM event will also be recorded by Docker and viewable via <code>docker system events</code>:<a data-primary="docker system" data-primary-sortas="docker-z" data-secondary="events" data-tertiary="out of memory event" data-type="indexterm" id="idm46803147247392"/><a data-startref="ch05-mem" data-type="indexterm" id="idm46803147248336"/><a data-startref="ch05-mem2" data-type="indexterm" id="idm46803147203280"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>system<code class="w"> </code>events<code class="w"/>&#13;
<code class="go">2018-01-28T15:56:19.972142371-08:00 container oom \</code>&#13;
<code class="go">    d0d803ce32c4e86d0aa6453512a9084a156e96860e916ffc2856fc63ad9cf88b \</code>&#13;
<code class="go">    (image=spkane/train-os, name=loving_franklin)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Block I/O" data-type="sect3"><div class="sect3" id="idm46803147478144">&#13;
<h3>Block I/O</h3>&#13;
&#13;
<p>Many containers are just stateless<a data-primary="resource quotas" data-secondary="block I/O" data-type="indexterm" id="idm46803147227872"/><a data-primary="block I/O for Linux containers" data-type="indexterm" id="idm46803147226896"/> applications and won’t need block I/O restrictions. But Docker also supports limiting block I/O in a few different ways via the &#13;
<span class="keep-together">cgroups mechanism.</span></p>&#13;
&#13;
<p>The first way is applying some prioritization to a container’s use of block device I/O. <a data-primary="cgroups in Linux kernel" data-secondary="block I/O" data-type="indexterm" id="idm46803147197360"/>You enable this by manipulating the default setting of the <code>blkio.weight</code> cgroup attribute. This attribute can have a value of 0 (disabled) or a number between 10 and 1,000, the default being 500. This limit acts a bit like CPU shares, in that the system will divide all of the available I/O between every process within a cgroup slice by 1,000, with the assigned weights impacting how much available I/O is available to each process.</p>&#13;
&#13;
<p>To set this weight on a container,<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--blkio-weight" data-tertiary-sortas="blkio-weight" data-type="indexterm" id="idm46803147195456"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--blkio-weight-device" data-tertiary-sortas="blkio-weight-device" data-type="indexterm" id="idm46803147193664"/> you need to pass the <code>--blkio-weight</code> to your <code>docker container run</code> command with a valid value. You can also target a specific device using the <code>--blkio-weight-device</code> option.</p>&#13;
&#13;
<p>As with CPU shares, tuning the weights is hard to get right in practice, but we can make it vastly simpler by limiting the maximum number of bytes or operations per second that are available to a container via its cgroup. The following settings let us control that:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">--device-read-bps     Limit read rate (bytes per second) from a device&#13;
--device-read-iops    Limit read rate (IO per second) from a device&#13;
--device-write-bps    Limit write rate (bytes per second) to a device&#13;
--device-write-iops   Limit write rate (IO per second) to a device</pre>&#13;
&#13;
<p>You can test how these impact the performance of a container by running some of the following commands, which use the Linux I/O tester <a href="https://www.coker.com.au/bonnie"><code>bonnie</code></a>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-ti<code class="w"> </code>spkane/train-os:latest<code class="w"> </code>bonnie++<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>-u<code class="w"> </code><code class="m">500</code>:500<code class="w"> </code>-d<code class="w"> </code>/tmp<code class="w"> </code>-r<code class="w"> </code><code class="m">1024</code><code class="w"> </code>-s<code class="w"> </code><code class="m">2048</code><code class="w"> </code>-x<code class="w"> </code><code class="m">1</code><code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="go">real  0m27.715s</code>&#13;
<code class="go">user  0m0.027s</code>&#13;
<code class="go">sys   0m0.030s</code>&#13;
&#13;
<code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--device-write-iops<code class="w"> </code>/dev/vda:256<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>spkane/train-os:latest<code class="w"> </code>bonnie++<code class="w"> </code>-u<code class="w"> </code><code class="m">500</code>:500<code class="w"> </code>-d<code class="w"> </code>/tmp<code class="w"> </code>-r<code class="w"> </code><code class="m">1024</code><code class="w"> </code>-s<code class="w"> </code><code class="m">2048</code><code class="w"> </code>-x<code class="w"> </code><code class="m">1</code><code class="w"/>&#13;
<code class="go">…</code>&#13;
<code class="go">real  0m58.765s</code>&#13;
<code class="go">user  0m0.028s</code>&#13;
<code class="go">sys   0m0.029s</code>&#13;
&#13;
<code class="gp">$ </code><code class="nb">time</code><code class="w"> </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--rm<code class="w"> </code>--device-write-bps<code class="w"> </code>/dev/vda:5mb<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">    </code>spkane/train-os:latest<code class="w"> </code>bonnie++<code class="w"> </code>-u<code class="w"> </code><code class="m">500</code>:500<code class="w"> </code>-d<code class="w"> </code>/tmp<code class="w"> </code>-r<code class="w"> </code><code class="m">1024</code><code class="w"> </code>-s<code class="w"> </code><code class="m">2048</code><code class="w"> </code>-x<code class="w"> </code><code class="m">1</code><code class="w"/>&#13;
<code class="go">…</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>PowerShell users should be able to use the<a data-primary="PowerShell" data-secondary="Measure-Command" data-type="indexterm" id="idm46803147047808"/> <a href="https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/measure-command?view=powershell-7.3"><code>Measure-Command</code></a> function to replace the Unix <code>time</code> command used in these examples.</p>&#13;
</div>&#13;
&#13;
<p>In our experience, the <code>--device-read-iops</code> and <code>--device-write-iops</code> arguments are the most effective way to set block I/O limits and are the ones we recommend.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="ulimits" data-type="sect3"><div class="sect3" id="idm46803147228848">&#13;
<h3>ulimits</h3>&#13;
&#13;
<p>Before Linux cgroups, there was another<a data-primary="resource quotas" data-secondary="user limits via ulimit" data-type="indexterm" id="idm46803147016848"/><a data-primary="ulimit command for user limits" data-type="indexterm" id="idm46803147015872"/> way to place a limit on the resources available to a process: the application of user limits via the <code>ulimit</code> command. That mechanism is still available and still useful for all of the <a href="https://www.linuxhowtos.org/Tips%20and%20Tricks/ulimit.htm">use cases</a> where it was traditionally used.</p>&#13;
&#13;
<p>The following code is a list of the types of system resources that you can usually constrain by setting soft and hard limits via the <code>ulimit</code> command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code><code class="nb">ulimit</code><code class="w"> </code>-a<code class="w"/>&#13;
<code class="go">core file size (blocks, -c) 0</code>&#13;
<code class="go">data seg size (kbytes, -d) unlimited</code>&#13;
<code class="go">scheduling priority (-e) 0</code>&#13;
<code class="go">file size (blocks, -f) unlimited</code>&#13;
<code class="go">pending signals (-i) 5835</code>&#13;
<code class="go">max locked memory (kbytes, -l) 64</code>&#13;
<code class="go">max memory size (kbytes, -m) unlimited</code>&#13;
<code class="go">open files (-n) 1024</code>&#13;
<code class="go">pipe size (512 bytes, -p) 8</code>&#13;
<code class="go">POSIX message queues (bytes, -q) 819200</code>&#13;
<code class="go">real-time priority (-r) 0</code>&#13;
<code class="go">stack size (kbytes, -s) 10240</code>&#13;
<code class="go">cpu time (seconds, -t) unlimited</code>&#13;
<code class="go">max user processes (-u) 1024</code>&#13;
<code class="go">virtual memory (kbytes, -v) unlimited</code>&#13;
<code class="go">file locks (-x) unlimited</code></pre>&#13;
&#13;
<p>It is possible to configure the Docker daemon with the default user limits that you want to apply to every container. The following command tells the Docker daemon to start all containers with a soft limit of 50 open files and a hard limit of 150 open files:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>sudo<code class="w"> </code>dockerd<code class="w"> </code>--default-ulimit<code class="w"> </code><code class="nv">nofile</code><code class="o">=</code><code class="m">50</code>:150<code class="w"/></pre>&#13;
&#13;
<p>You can then override these ulimits on a specific container by passing in values using the <code>--ulimit</code> argument:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--ulimit for user limits" data-tertiary-sortas="ulimit" data-type="indexterm" id="idm46803146926384"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>--rm<code class="w"> </code>-d<code class="w"> </code>--ulimit<code class="w"> </code><code class="nv">nofile</code><code class="o">=</code><code class="m">150</code>:300<code class="w"> </code>nginx<code class="w"/></pre>&#13;
&#13;
<p>There are some additional advanced commands that you can use when creating containers, but this covers many of the more common use cases. The <a href="https://dockr.ly/2ME0ygi">Docker client documentation</a> lists all the available options and is updated with each Docker release.<a data-startref="ch05-creat" data-type="indexterm" id="idm46803146917312"/><a data-startref="ch05-resou" data-type="indexterm" id="idm46803146916704"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Starting a Container" data-type="sect1"><div class="sect1" id="idm46803148044016">&#13;
<h1>Starting a Container</h1>&#13;
&#13;
<p>Before we got into the details of containers<a data-primary="Linux containers" data-secondary="starting a container" data-type="indexterm" id="idm46803146877120"/> and constraints, we created our container using the <code>docker container create</code> command. That container is just sitting there without doing anything. There is a configuration but no running process. When we’re ready to start the container, we can do so using the <code>docker container start</code> command.<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="start" data-tertiary="starting a container" data-type="indexterm" id="idm46803146875216"/></p>&#13;
&#13;
<p>Let’s say that we needed to run a copy of Redis, a common key/value store. We won’t do anything with this Redis container, but it’s a lightweight, long-lived process and serves as an example of something we might do in a real environment. We could first create the container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>create<code class="w"> </code>-p<code class="w"> </code><code class="m">6379</code>:6379<code class="w"> </code>redis:2.8<code class="w"/>&#13;
<code class="go">Unable to find image 'redis:7.0' locally</code>&#13;
<code class="go">7.0: Pulling from library/redis</code>&#13;
<code class="go">3f4ca61aafcd: Pull complete</code>&#13;
<code class="go">…</code>&#13;
<code class="go">20bf15ad3c24: Pull complete</code>&#13;
<code class="go">Digest: sha256:8184cfe57f205ab34c62bd0e9552dffeb885d2a7f82ce4295c0df344cb6f0007</code>&#13;
<code class="go">Status: Downloaded newer image for redis:7.0</code>&#13;
<code class="go">092c5dc850446324e4387485df7b76258fdf9ed0aedcd53a37299d35fc67a042</code></pre>&#13;
&#13;
<p>The result of the command is some output, the last line of which is the full hash that was generated for the container. We could use that long hash to start it, but if we failed to note it down, we could also list all the containers on the system, whether they are running or not, using the following:<a data-primary="hashes" data-secondary="container ID hash" data-tertiary="displaying via docker container ls" data-type="indexterm" id="idm46803146866784"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"> </code>-a<code class="w"> </code>--filter<code class="w"> </code><code class="nv">ancestor</code><code class="o">=</code>redis:2.8<code class="w"/>&#13;
<code class="go">CONTAINER ID IMAGE     COMMAND                CREATED        … NAMES</code>&#13;
<code class="go">092c5dc85044 redis:7.0 "docker-entrypoint.s…" 46 seconds ago elegant_wright</code></pre>&#13;
&#13;
<p>We can confirm the identity of our container by filtering the output by the image that we used and examining the container’s creation time. We can then start the container with the following command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>start<code class="w"> </code>092c5dc85044<code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Most Docker commands will work with<a data-primary="hashes" data-secondary="container references in commands" data-type="indexterm" id="idm46803146818864"/> the container name, the full hash, the short hash, or even just enough of the hash to make it unique. In the previous example, the full hash for the container is <code>092c5dc850446324e…a37299d35fc67a042</code>, but the short hash that is shown in most command output is <code>092c5dc85044</code>. This short hash consists of the first 12 characters of the full hash. In the previous example, running <code>docker container start 6b7</code> would have worked just fine.</p>&#13;
</div>&#13;
&#13;
<p>That <em>should</em> have started the container, but with it running in the background we won’t necessarily know if something went wrong. To verify that it’s running, we can run the following:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="checking for running container" data-type="indexterm" id="idm46803146815584"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">CONTAINER ID  IMAGE      COMMAND                …  STATUS       …</code>&#13;
<code class="go">092c5dc85044  redis:7.0  "docker-entrypoint.s…" …  Up 2 minutes …</code></pre>&#13;
&#13;
<p>And, there it is: running as expected. We can tell because the status says <code>Up</code> and shows how long the container has been running.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Auto-Restarting a Container" data-type="sect1"><div class="sect1" id="idm46803146878096">&#13;
<h1>Auto-Restarting a Container</h1>&#13;
&#13;
<p>In many cases, we want our containers<a data-primary="Linux containers" data-secondary="starting a container" data-tertiary="auto-restarting" data-type="indexterm" id="idm46803146761024"/><a data-primary="Linux containers" data-secondary="auto-restarting" data-type="indexterm" id="idm46803146759776"/> to restart if they exit. Some containers are very short-lived and come and go quickly. But for production applications, for instance, you expect them to be up and running at all times after you’ve told them to run. If you are running a more complex system, a scheduler may do this for you.</p>&#13;
&#13;
<p>In the simple case, we can tell Docker<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--restart" data-tertiary-sortas="restart" data-type="indexterm" id="idm46803146737648"/><a data-primary="exit codes" data-secondary="restarting a container per" data-type="indexterm" id="idm46803146735472"/> to manage restarts on our behalf by passing the <code>--restart</code> argument to the <code>docker container run</code> command. It takes four values: <code>no</code>, <code>always</code>, <code>on-failure</code>, or <code>unless-stopped</code>. If <code>restart</code> is set to <code>no</code>, the container will never restart if it exits. If it is set to <code>always</code>, the container will restart whenever it exits, with no regard to the exit code. If <code>restart</code> is set to <code>on-failure</code>, whenever the container exits with a nonzero exit code, Docker will try to restart the container. If we set <code>restart</code> to <code>on-failure:3</code>, Docker will try and restart the container three times before giving up. <code>unless-stopped</code> is the most common choice and will restart the container unless it is intentionally stopped with something like <code>docker container stop</code>.</p>&#13;
&#13;
<p>We can see this in action by rerunning our last memory-constrained stress container without the <code>--rm</code> argument but with the <code>--restart</code> argument:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>run<code class="w"> </code>-ti<code class="w"> </code>--restart<code class="o">=</code>on-failure:3<code class="w"> </code>--memory<code class="w"> </code>100m<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>spkane/train-os<code class="w"> </code>stress<code class="w"> </code>-v<code class="w"> </code>--cpu<code class="w"> </code><code class="m">2</code><code class="w"> </code>--io<code class="w"> </code><code class="m">1</code><code class="w"> </code>--vm<code class="w"> </code><code class="m">2</code><code class="w"> </code>--vm-bytes<code class="w"> </code>128M<code class="w"> </code><code class="se">\</code>&#13;
<code class="w">  </code>--timeout<code class="w"> </code>120s<code class="w"/></pre>&#13;
&#13;
<p>In this example, we’ll see the output from the first run appear on the console before it dies. If we run a <code>docker container ls</code> immediately after the container dies, we’ll likely see that Docker has restarted the container:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">…  IMAGE           …  STATUS                …</code>&#13;
<code class="go">…  spkane/train-os …  Up Less than a second …</code></pre>&#13;
&#13;
<p>It will continue to fail because we haven’t given it enough memory to function properly. After three attempts, Docker will give up, and we’ll see the container disappear from the output of <code>docker container ls</code>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Stopping a Container" data-type="sect1"><div class="sect1" id="idm46803146641792">&#13;
<h1>Stopping a Container</h1>&#13;
&#13;
<p>Containers can be stopped<a data-primary="Linux containers" data-secondary="stopping a container" data-type="indexterm" id="idm46803146639904"/> and started at will. You might think that starting and stopping a container is analogous to pausing and resuming a normal process, but it’s not quite the same in reality. When stopped, the process is not paused; it exits. And when a container is stopped, it no longer shows up in the normal <code>docker container ls</code> output. On reboot, Docker will attempt to start all of the containers that were running at shutdown. <a data-primary="Linux containers" data-secondary="pausing" data-type="indexterm" id="idm46803146637120"/>If you need to prevent a container from doing any additional work, without actually stopping the process, then you can pause the Linux container with <code>docker container pause</code> and <code>unpause</code>,  which will be discussed in more detail later. For now, go ahead and stop the Redis container that we started a little earlier:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="stop" data-type="indexterm" id="idm46803146635216"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>stop<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</code></pre>&#13;
&#13;
<p>Now that we have stopped the container, nothing is in the running container list! We can start it back up with the container ID, but it would be inconvenient to have to remember that. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="-a for all even non-running" data-type="indexterm" id="idm46803146572816"/>So <code>docker container ls</code> has an additional option <code>(-a)</code> to show all containers, not just the running ones:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"> </code>-a<code class="w"/>&#13;
<code class="go">CONTAINER ID  IMAGE     STATUS                   …</code>&#13;
<code class="go">092c5dc85044  redis:7.0 Exited (0) 2 minutes ago …</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>That <code>STATUS</code> field now shows that our container exited with a status code of 0 (no errors). We can start it back up with the same configuration it had before:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>start<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"> </code>-a<code class="w"/>&#13;
<code class="go">CONTAINER ID  IMAGE     STATUS        …</code>&#13;
<code class="go">092c5dc85044  redis:7.0 Up 14 seconds …</code>&#13;
<code class="go">…</code></pre>&#13;
&#13;
<p>Voilà, our container is back up and running and configured just as it was before.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Remember that containers exist as a blob of configuration in the Docker system even when they are not started. <a data-primary="Linux containers" data-secondary="starting a container" data-type="indexterm" id="idm46803146558672"/>This means that as long as the container has not been deleted, you can restart it without needing to re-create it. <a data-primary="tmpfs for writable within read-only" data-secondary="lost when container stopped" data-type="indexterm" id="idm46803146557472"/>Although memory and temporary file system (tmpfs) contents will have been lost, all of the container’s other filesystem contents and metadata, including environment variables and port bindings, are saved and will still be in place when you restart the container.</p>&#13;
</div>&#13;
&#13;
<p>By now we’ve probably thumped on enough about the idea that containers are just a tree of processes that interact with the system in essentially the same way as any other process on the server. But it’s important to point it out here again because it means that we can send Unix signals to our process in the containers that they can then respond to. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="stop" data-tertiary="SIGTERM signal sent" data-type="indexterm" id="idm46803146517296"/><a data-primary="processes" data-secondary="SIGTERM signal sent on stop" data-type="indexterm" id="idm46803146515776"/><a data-primary="SIGTERM signal when stopping a container" data-type="indexterm" id="idm46803146514864"/><a data-primary="Unix signals" data-secondary="SIGTERM" data-type="indexterm" id="idm46803146514224"/>In the previous <code>docker container stop</code> example, we’re sending the container a <code>SIGTERM</code> signal and waiting for the container to exit gracefully. Containers follow the same process group signal propagation that any other process group would receive on Linux.</p>&#13;
&#13;
<p>A normal <code>docker container stop</code> sends a <code>SIGTERM</code> to the process. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="stop" data-tertiary="-t to kill after some time" data-tertiary-sortas="t" data-type="indexterm" id="idm46803146511008"/><a data-primary="Linux containers" data-secondary="killing" data-tertiary="stop -t argument for time till kill" data-type="indexterm" id="idm46803146509216"/>If you want to force a container to be killed if it hasn’t stopped after a certain amount of time, you can use the <span class="keep-together"><code>-t</code></span> argument, like this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>stop<code class="w"> </code>-t<code class="w"> </code><code class="m">25</code><code class="w"> </code>092c5dc85044<code class="w"/></pre>&#13;
&#13;
<p>This tells Docker to initially send a <code>SIGTERM</code> signal as before, <a data-primary="SIGKILL signal when killing a container" data-type="indexterm" id="idm46803146478752"/><a data-primary="Unix signals" data-secondary="SIGKILL" data-type="indexterm" id="idm46803146478144"/>but if the container has not stopped within 25 seconds (the default is 10), it tells Docker to send a <code>SIGKILL</code> signal to forcefully kill it.</p>&#13;
&#13;
<p>Although <code>stop</code> is the best way to shut down your containers, there are times when it doesn’t work and you’ll need to forcefully kill a container, just as you might have to do with any process outside of a container.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Killing a Container" data-type="sect1"><div class="sect1" id="idm46803146641200">&#13;
<h1>Killing a Container</h1>&#13;
&#13;
<p>When a process is misbehaving,<a data-primary="Linux containers" data-secondary="killing" data-type="indexterm" id="idm46803146470880"/> <code>docker container stop</code> might not cut it. You might just want the container to exit immediately.</p>&#13;
&#13;
<p>In these circumstances, you can use <code>docker container kill</code>. As you’d expect, it looks a lot  like <code>docker container stop</code>:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="kill" data-type="indexterm" id="idm46803146468112"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>start<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code><code class="nb">kill</code><code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code></pre>&#13;
&#13;
<p>A <code>docker container ls</code> command now shows that the container is no longer running, as expected:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</code></pre>&#13;
&#13;
<p>Just because it was killed rather than stopped<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="start" data-tertiary="starting a killed container" data-type="indexterm" id="idm46803146408960"/> does not mean you can’t start it again, though. You can just issue a <code>docker container start</code> like you would for a nicely stopped container. Sometimes you might want to send another signal to a container, one that is not <code>stop</code> or <code>kill</code>. Like the Linux <code>kill</code> command,<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="kill" data-tertiary="--signal" data-tertiary-sortas="signal" data-type="indexterm" id="idm46803146401696"/><a data-primary="Linux containers" data-secondary="killing" data-tertiary="sending a Unix signal" data-type="indexterm" id="idm46803146399872"/> <code>docker container kill</code> supports sending any Unix signal.  Let’s say we wanted to send a <code>USR1</code> signal to our container to tell it to do something like reconnect a remote logging session. We could do the following:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>start<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code><code class="nb">kill</code><code class="w"> </code>--signal<code class="o">=</code>USR1<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code></pre>&#13;
&#13;
<p>If our container process was designed to do something with the <code>USR1</code> signal, it would now do it. Any standard Unix signal can be sent to a container using this method.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pausing and Unpausing a Container" data-type="sect1"><div class="sect1" id="idm46803146341728">&#13;
<h1>Pausing and Unpausing a Container</h1>&#13;
&#13;
<p>There are a few reasons why we might<a data-primary="Linux containers" data-secondary="pausing" data-type="indexterm" id="idm46803146365248"/> not want to completely stop our container. We might want to pause it, leave its resources allocated, and leave its entries in the process table. That could be because we’re taking a snapshot of its filesystem to create a new image or just because we need some CPU on the host for a while. If you are used to normal Unix process handling, you might wonder how this works since containerized processes are just processes.</p>&#13;
&#13;
<p>Pausing leverages the<a data-primary="cgroups in Linux kernel" data-secondary="freezer for pausing containers" data-type="indexterm" id="idm46803146363792"/> <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/freezer-subsystem.txt">cgroup freezer</a>, which essentially just prevents your process from being scheduled until you unfreeze it. This will prevent the container from doing anything while maintaining its overall state, including memory contents. Unlike stopping a container, where the processes are made aware that they are stopping via the <code>SIGSTOP</code> signal, pausing a container doesn’t send any information to the container about its state change. That’s an important distinction. Several Docker commands use pausing and unpausing internally as well. Here is how we pause a container:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="pause" data-type="indexterm" id="idm46803146361616"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>start<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>pause<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>To pause and unpause containers<a data-primary="Windows running Docker" data-secondary="pausing and unpausing containers" data-type="indexterm" id="idm46803146321952"/> in Windows, you must be using Hyper-V or WSL2 as the underlying virtualization technology.</p>&#13;
</div>&#13;
&#13;
<p>If we look at the list of running containers, we will now see that the Redis container status is listed as <code>(Paused)</code>:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">CONTAINER ID  IMAGE     … STATUS                  …</code>&#13;
<code class="go">092c5dc85044  redis:7.0 … Up 25 seconds (Paused)  …</code></pre>&#13;
&#13;
<p>Attempting to use the container in this paused state would fail. It’s present, but nothing is running. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="unpause" data-type="indexterm" id="idm46803146292160"/><a data-primary="Linux containers" data-secondary="pausing" data-tertiary="unpausing" data-type="indexterm" id="idm46803146291072"/>We can now resume the container by using the <code>docker container unpause</code> command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>unpause<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">CONTAINER ID  IMAGE     … STATUS        …</code>&#13;
<code class="go">092c5dc85044  redis:7.0 … Up 55 seconds …</code></pre>&#13;
&#13;
<p>It’s back to running, and <code>docker container ls</code> correctly reflects the new state. <a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="paused containers still running" data-type="indexterm" id="idm46803146254352"/>It shows <code>Up 55 seconds</code> now because Docker still considers the container to be running even when it is paused.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Cleaning Up Containers and Images" data-type="sect1"><div class="sect1" id="idm46803146341136">&#13;
<h1>Cleaning Up Containers and Images</h1>&#13;
&#13;
<p>After running all these commands to build images, create containers, and run them, we have accumulated a lot of image layers and container folders on our system.<a data-primary="Linux containers" data-secondary="cleaning up" data-type="indexterm" id="idm46803146250464"/><a data-primary="OCI images" data-secondary="cleaning up" data-type="indexterm" id="idm46803146249488"/></p>&#13;
&#13;
<p>We can list all the containers on our system using the <code>docker container ls -a</code> command and then delete any of the containers in the list. We must stop all containers that are using an image before removing the image itself. Assuming we’ve done that, we can remove it as follows, using the <code>docker container rm</code> command:<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="rm" data-tertiary="removing a container" data-type="indexterm" id="idm46803146247328"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>stop<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044ls</code>&#13;
&#13;
<code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>rm<code class="w"> </code>092c5dc85044<code class="w"/>&#13;
<code class="go">092c5dc85044</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>It is possible to remove a running container if you use the <code>-f</code> or <code>--force</code> flag with <code>docker container rm</code>.<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="rm" data-tertiary="-f/--force to remove a running container" data-tertiary-sortas="f" data-type="indexterm" id="idm46803146198208"/></p>&#13;
</div>&#13;
&#13;
<p>We can then list all the images on our system using the following:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>ls<code class="w"/>&#13;
<code class="go">REPOSITORY       TAG     IMAGE ID      CREATED       SIZE</code>&#13;
<code class="go">ubuntu           latest  5ba9dab47459  3 weeks ago   188.3MB</code>&#13;
<code class="go">redis            7.0     0256c63af7db  2 weeks ago   117MB</code>&#13;
<code class="go">spkane/train-os  latest  78fb082a4d65  4 months ago  254MB</code></pre>&#13;
&#13;
<p>We can then delete an image and all associated filesystem layers by running the following:<a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="rm to remove" data-type="indexterm" id="idm46803146190512"/><a data-primary="OCI images" data-secondary="removing" data-type="indexterm" id="idm46803146189424"/></p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>rm<code class="w"> </code>0256c63af7db<code class="w"/></pre>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>If you try to delete an image that is in use by a container, you will get a <code>Conflict, cannot delete</code> error. You should stop and delete the container(s) first.</p>&#13;
</div>&#13;
&#13;
<p>There are times, especially during development cycles<a data-primary="docker system" data-primary-sortas="docker-z" data-secondary="prune to remove all containers and images" data-type="indexterm" id="idm46803146164960"/><a data-primary="Linux containers" data-secondary="removing a container" data-tertiary="prune to remove all" data-type="indexterm" id="idm46803146163776"/><a data-primary="OCI images" data-secondary="removing" data-tertiary="prune to remove all" data-type="indexterm" id="idm46803146142096"/> when it makes sense to completely purge all the images or containers from your system. The easiest way to do this is by running the <code>docker system prune</code> command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>system<code class="w"> </code>prune<code class="w"/>&#13;
<code class="go">WARNING! This will remove:</code>&#13;
<code class="go">        - all stopped containers</code>&#13;
<code class="go">        - all networks not used by at least one container</code>&#13;
<code class="go">        - all dangling images</code>&#13;
<code class="go">        - all build cache</code>&#13;
<code class="go">Are you sure you want to continue? [y/N] y</code>&#13;
<code class="go">Deleted Containers:</code>&#13;
<code class="go">cbbc42acfe6cc7c2d5e6c3361003e077478c58bb062dd57a230d31bcd01f6190</code>&#13;
<code class="go">…</code>&#13;
<code class="go">Deleted Images:</code>&#13;
<code class="go">deleted: sha256:bec6ec29e16a409af1c556bf9e6b2ec584c7fb5ffbfd7c46ec00b30bf …</code>&#13;
<code class="go">untagged: spkane/squid@sha256:64fbc44666405fd1a02f0ec731e35881465fac395e7 …</code>&#13;
<code class="go">…</code>&#13;
<code class="go">Total reclaimed space: 1.385GB</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>To remove all unused images, instead of only dangling images, try <code>docker system prune -a</code>.</p>&#13;
</div>&#13;
&#13;
<p>It is also possible to craft more specific commands to accomplish similar goals.</p>&#13;
&#13;
<p>To delete all of the containers on your Docker hosts, use the following command:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>rm<code class="w"> </code><code class="k">$(</code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"> </code>-a<code class="w"> </code>-q<code class="k">)</code><code class="w"/></pre>&#13;
&#13;
<p>And to delete all the images on your Docker host, this command will get the job done:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>rm<code class="w"> </code><code class="k">$(</code>docker<code class="w"> </code>images<code class="w"> </code>-q<code class="k">)</code><code class="w"/></pre>&#13;
&#13;
<p>The <code>docker container ls</code> and <code>docker images</code> commands both<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="rm" data-tertiary="filtering via ls or docker images" data-type="indexterm" id="idm46803146047936"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="ls" data-tertiary="-f/--filter" data-tertiary-sortas="f" data-type="indexterm" id="idm46803146040784"/><a data-primary="docker image" data-primary-sortas="docker-z" data-secondary="-f/--filter" data-secondary-sortas="f" data-type="indexterm" id="idm46803146039024"/> support a &#13;
<span class="keep-together"><code>filter</code></span> argument that can make it easy to fine-tune your delete commands for &#13;
<span class="keep-together">certain circumstances</span>.</p>&#13;
&#13;
<p>To remove all containers that exited with a nonzero state, you can use this filter:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>container<code class="w"> </code>rm<code class="w"> </code><code class="k">$(</code>docker<code class="w"> </code>container<code class="w"> </code>ls<code class="w"> </code>-a<code class="w"> </code>-q<code class="w"> </code>--filter<code class="w"> </code><code class="s1">'exited!=0'</code><code class="k">)</code><code class="w"/></pre>&#13;
&#13;
<p>And to remove all untagged images, you can type this:</p>&#13;
&#13;
<pre data-code-language="console" data-type="programlisting"><code class="gp">$ </code>docker<code class="w"> </code>image<code class="w"> </code>rm<code class="w"> </code><code class="k">$(</code>docker<code class="w"> </code>images<code class="w"> </code>-q<code class="w"> </code>-f<code class="w"> </code><code class="s2">"dangling=true"</code><code class="k">)</code><code class="w"/></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>You can read the <a href="https://docs.docker.com/engine/reference/commandline/ps/#filtering">official Docker documentation</a> to explore<a data-primary="documentation" data-secondary="Docker" data-tertiary="filtering options" data-type="indexterm" id="idm46803145950752"/><a data-primary="resources online" data-secondary="Docker documentation" data-tertiary="filtering options" data-type="indexterm" id="idm46803145949504"/> the filtering options. At the moment, there are very few filters to choose from, but more will likely be added over time.</p>&#13;
&#13;
<p>You can also make your own very creative filters by stringing together commands using pipes (|) and other similar techniques.<a data-primary="pipe (|)" data-secondary="filtering via" data-type="indexterm" id="idm46803145947776"/></p>&#13;
</div>&#13;
&#13;
<p>In production systems that see a lot of deployments, you can sometimes end up with old containers or unused images lying around and filling up disk space. It can be useful to script the <code>docker system prune</code> command to run on a schedule (e.g., running under <code>cron</code> or via a <code>systemd</code> timer).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Windows Containers" data-type="sect1"><div class="sect1" id="windows_containers">&#13;
<h1>Windows Containers</h1>&#13;
&#13;
<p>Up to now we have focused entirely<a data-primary="Windows containers" data-type="indexterm" id="ch05-wincon"/><a data-primary="Hyper-V" data-secondary="running Windows containers" data-type="indexterm" id="ch05-wincon2"/><a data-primary="Windows running Docker" data-secondary="Hyper-V" data-tertiary="running Windows containers" data-type="indexterm" id="ch05-wincon3"/> on Docker commands for Linux containers, since this is the most common use case and works on all Docker platforms. However, since 2016, the Microsoft Windows platform has supported running Windows containers that include native Windows applications and can be managed with the usual set of Docker commands.</p>&#13;
&#13;
<p>Windows containers are not the focus of this book, since they still only make up a small portion of production containers and aren’t 100% compatible with the rest of the Docker ecosystem because <a data-primary="Windows containers" data-secondary="Windows-specific container images" data-type="indexterm" id="idm46803145914944"/>they require Windows-specific container images. However, they’re a growing and important part of the Docker world, so we’ll take a brief look at how they work. In fact, except for the actual contents of the containers, almost everything else works the same as Linux containers. In this section, we’ll run through a quick example of how you can run a Windows container on Windows 10+ with Hyper-V and Docker.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>For this to work, you must be using Docker Desktop on a compatible 64-bit edition of Windows 10 or later.</p>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before">The first thing you’ll need to do is switch Docker from Linux containers to Windows containers. To do this, right-click on the Docker whale icon in your taskbar, select “Switch to Windows Containers…,” and then confirm the switch (Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#figure5-1">5-1</a> and&#13;
<a data-type="xref" data-xrefstyle="select:labelnumber" href="#figure5-2">5-2</a>).</p>&#13;
&#13;
<figure><div class="figure" id="figure5-1">&#13;
<img alt="Switch to Windows containers" src="assets/dur3_0501.png"/>&#13;
<h6><span class="label">Figure 5-1. </span>Switch to Windows containers</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="figure5-2">&#13;
<img alt="Switch to Windows containers confirmation" src="assets/dur3_0502.png"/>&#13;
<h6><span class="label">Figure 5-2. </span>Switch to Windows containers confirmation</h6>&#13;
</div></figure>&#13;
&#13;
<p>This process might take some time, although it usually happens almost immediately. Unfortunately, there is no notification that the switch has completed. If you &#13;
<span class="keep-together">right-click</span> on the Docker icon again, you should now see “Switch to Linux Containers…” in place of the original option.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If the first time you right-click on the Docker icon, it reads “Switch to Linux Containers…,” then you are already configured for Windows containers.</p>&#13;
</div>&#13;
&#13;
<p>We can test a simple Windows container<a data-primary="PowerShell" data-secondary="Windows container tested" data-type="indexterm" id="idm46803145902832"/><a data-primary="Windows containers" data-secondary="Windows-specific container images" data-tertiary="testing via PowerShell" data-type="indexterm" id="idm46803145901888"/> by opening up <a href="https://oreil.ly/SiTXP">PowerShell</a><sup><a data-type="noteref" href="ch05.html#idm46803145899968" id="idm46803145899968-marker">4</a></sup> and trying to run the following command:</p>&#13;
&#13;
<pre data-code-language="ps1con" data-type="programlisting"><code class="gp">PS C:\&gt; </code><code class="n">docker</code> <code class="n">container</code> <code class="n">run</code> <code class="p">-</code><code class="n">-rm</code> <code class="n">-it</code> <code class="n">mcr</code><code class="p">.</code><code class="n">microsoft</code><code class="p">.</code><code class="n">com</code><code class="p">/</code><code class="n">powershell</code> <code class="p">`</code>&#13;
<code class="go">          pwsh -command `</code>&#13;
<code class="go">          'Write-Host "Hello World from Windows `($IsWindows`)"'</code>&#13;
&#13;
<code class="go">Hello World from Windows (True)</code></pre>&#13;
&#13;
<p>This will download and launch a <a href="https://hub.docker.com/_/microsoft-powershell">base container for PowerShell</a> and then use scripting to print <code>Hello World from Windows (True)</code> to the screen.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If the output from the preceding command prints <code>Hello World from Windows (false)</code>, then you have not switched over to Windows Container mode, or you are running this command on a non-Windows platform.</p>&#13;
</div>&#13;
&#13;
<p>If you want to build a Windows container image that accomplishes roughly the same task, you can create the following <em>Dockerfile</em>:<a data-primary="Windows containers" data-secondary="Windows-specific container images" data-tertiary="Dockerfile example" data-type="indexterm" id="idm46803145872560"/><a data-primary="Dockerfiles" data-primary-sortas="docker-a" data-secondary="Windows containers" data-type="indexterm" id="idm46803145871264"/></p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="c"># escape=`</code><code class="w"/>&#13;
<code class="k">FROM</code><code class="w"> </code><code class="s">mcr.microsoft.com/powershell</code><code class="w"/>&#13;
<code class="k">SHELL</code><code class="w"> </code><code class="p">[</code><code class="s2">"pwsh"</code><code class="p">,</code><code class="w"> </code><code class="s2">"-command"</code><code class="p">]</code><code class="w"/>&#13;
&#13;
<code class="k">RUN</code><code class="w"> </code>Add-Content<code class="w"> </code>C:<code class="se">\h</code>elloworld.ps1<code class="w"> </code><code class="sb">`</code><code class="w"/>&#13;
<code class="w">      </code><code class="s1">'Write-Host "Hello World from Windows"'</code><code class="w"/>&#13;
&#13;
<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="s2">"pwsh"</code><code class="p">,</code><code class="w"> </code><code class="s2">"C:\\helloworld.ps1"</code><code class="p">]</code><code class="w"/></pre>&#13;
&#13;
<p>When you build this <em>Dockerfile</em>, it will base the image on <code>mcr.microsoft.com/</code> &#13;
<span class="keep-together"><code>powershell</code></span>, create a small PowerShell script, and then configure the image to run that script when this image is used to launch a container.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>You may have noticed that we had to escape the backslash (<code>\</code>) with an additional backslash in the preceding <em>Dockerfile</em>’s <code>CMD</code> line. This is because Docker has its roots in Unix, and the backslash has a special meaning in Unix shells. So, even though we <a href="https://docs.docker.com/engine/reference/builder/#escape">changed the escape character</a> for the <em>Dockerfile</em> to match what is used in PowerShell by default (which we set via <a href="https://docs.docker.com/engine/reference/builder/#shell-form-entrypoint-example">the <code>SHELL</code> directive</a>), we still need to escape some backslashes to ensure that Docker does not <span class="keep-together">misinterpret</span> them.</p>&#13;
</div>&#13;
&#13;
<p>If you build this <em>Dockerfile</em> now, you’ll see something similar to this:</p>&#13;
&#13;
<pre data-code-language="ps1con" data-type="programlisting"><code class="gp">PS C:\&gt; </code><code class="n">docker</code> <code class="n">image</code> <code class="n">build</code> <code class="n">-t</code> <code class="n">windows-helloworld</code><code class="p">:</code><code class="n">latest</code> <code class="p">.</code>&#13;
&#13;
<code class="go">Sending build context to Docker daemon  2.048kB</code>&#13;
<code class="go">Step 1/4 : FROM mcr.microsoft.com/powershell</code>&#13;
<code class="go"> ---&gt; 7d8f821c04eb</code>&#13;
<code class="go">Step 2/4 : SHELL ["pwsh", "-command"]</code>&#13;
<code class="go"> ---&gt; Using cache</code>&#13;
<code class="go"> ---&gt; 1987fb489a3d</code>&#13;
<code class="go">Step 3/4 : RUN Add-Content C:\helloworld.ps1</code>&#13;
<code class="go">                 'Write-Host "Hello World from Windows"'</code>&#13;
<code class="go"> ---&gt; Using cache</code>&#13;
<code class="go"> ---&gt; 37df47d57bf1</code>&#13;
<code class="go">Step 4/4 : CMD ["pwsh", "C:\\helloworld.ps1"]</code>&#13;
<code class="go"> ---&gt; Using cache</code>&#13;
<code class="go"> ---&gt; 03046ff628e4</code>&#13;
<code class="go">Successfully built 03046ff628e4</code>&#13;
<code class="go">Successfully tagged windows-helloworld:latest</code></pre>&#13;
&#13;
<p>And now if you run the resulting image, you’ll see this:</p>&#13;
&#13;
<pre data-code-language="ps1con" data-type="programlisting"><code class="gp">PS C:\&gt; </code><code class="n">docker</code> <code class="n">container</code> <code class="n">run</code> <code class="p">-</code><code class="n">-rm</code> <code class="n">-ti</code> <code class="n">windows-helloworld</code><code class="p">:</code><code class="n">latest</code>&#13;
&#13;
<code class="go">Hello World from Windows</code></pre>&#13;
&#13;
<p>Microsoft maintains good<a data-primary="Windows containers" data-secondary="documentation" data-type="indexterm" id="idm46803145711136"/><a data-primary="documentation" data-secondary="Windows containers" data-type="indexterm" id="idm46803145710288"/><a data-primary="resources online" data-secondary="Windows containers documentation" data-type="indexterm" id="idm46803145709376"/> <a href="https://oreil.ly/fYMHl">documentation about Windows containers</a><sup><a data-type="noteref" href="ch05.html#idm46803145707776" id="idm46803145707776-marker">5</a></sup> that also includes an <a href="https://oreil.ly/WG2W2">example of building a container that launches a .NET application</a>.<sup><a data-type="noteref" href="ch05.html#idm46803145685248" id="idm46803145685248-marker">6</a></sup></p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>On the Windows platform, it is also useful to know that you can get improved isolation<a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="create" data-tertiary="--isolation=hyperv" data-tertiary-sortas="isolation=hyperv" data-type="indexterm" id="idm46803145682320"/><a data-primary="docker container" data-primary-sortas="docker-z" data-secondary="run" data-tertiary="--isolation=hyperv" data-tertiary-sortas="isolation=hyperv" data-type="indexterm" id="idm46803145680528"/><a data-primary="Windows containers" data-secondary="option to improve isolation" data-type="indexterm" id="idm46803145678736"/> for your container by launching it inside a dedicated and very lightweight Hyper-V VM. You can do this very easily by simply adding the <code>--isolation=hyperv</code> option to your <code>docker container create</code> and <code>docker container run</code> commands. There is a small performance and resource penalty for this, but it significantly improves the isolation of your container. You can read more about this in the <a href="https://learn.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/hyperv-container">documentation</a>.</p>&#13;
</div>&#13;
&#13;
<p>Even if you plan to mostly work with Windows containers, for the rest of the book you should switch back to Linux containers so that all the examples work as expected. When you are done reading and are ready to dive into building your containers, you can always switch back.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Remember that you can re-enable Linux containers by right-clicking on the Docker icon and selecting “Switch to Linux &#13;
<span class="keep-together">Containers</span>….”<a data-startref="ch05-wincon" data-type="indexterm" id="idm46803145673504"/><a data-startref="ch05-wincon2" data-type="indexterm" id="idm46803145672768"/><a data-startref="ch05-wincon3" data-type="indexterm" id="idm46803145672096"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Wrap-Up" data-type="sect1"><div class="sect1" id="idm46803145919760">&#13;
<h1>Wrap-Up</h1>&#13;
&#13;
<p>In the next chapter, we’ll continue our exploration of what Docker brings to the table. For now, it’s probably worth doing a little experimentation on your own. We suggest exercising some of the container control commands we covered here so that you’re familiar with the command-line options and the overall syntax. Now would even be a great time to try to design and build a small image and then launch it as a new container. When you are ready to continue, head on to <a data-type="xref" href="ch06.html#exploring_docker">Chapter 6</a>!</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm46803149032576"><sup><a href="ch05.html#idm46803149032576-marker">1</a></sup> SELinux is one current implementation.</p><p data-type="footnote" id="idm46803148782320"><sup><a href="ch05.html#idm46803148782320-marker">2</a></sup> Typically under <em>/var/lib/docker/containers</em>.</p><p data-type="footnote" id="idm46803147988272"><sup><a href="ch05.html#idm46803147988272-marker">3</a></sup> Full URL: <a class="bare" href="https://docs.docker.com/engine/install/linux-postinstall/#your-kernel-does-not-support-cgroup-swap-limit-capabilities"><em class="hyperlink">https://docs.docker.com/engine/install/linux-postinstall/#your-kernel-does-not-support-cgroup-swap-limit-capabilities</em></a></p><p data-type="footnote" id="idm46803145899968"><sup><a href="ch05.html#idm46803145899968-marker">4</a></sup> Full URL: <a class="bare" href="https://learn.microsoft.com/en-us/powershell/scripting/overview?view=powershell-7.3&amp;viewFallbackFrom=powershell-6"><em class="hyperlink">https://learn.microsoft.com/en-us/powershell/scripting/overview?view=powershell-7.3&amp;viewFallbackFrom=powershell-6</em></a></p><p data-type="footnote" id="idm46803145707776"><sup><a href="ch05.html#idm46803145707776-marker">5</a></sup> Full URL: <a class="bare" href="https://learn.microsoft.com/en-us/virtualization/windowscontainers/about"><em class="hyperlink">https://learn.microsoft.com/en-us/virtualization/windowscontainers/about</em></a></p><p data-type="footnote" id="idm46803145685248"><sup><a href="ch05.html#idm46803145685248-marker">6</a></sup> Full URL: <a class="bare" href="https://learn.microsoft.com/en-us/virtualization/windowscontainers/quick-start/building-sample-app"><em class="hyperlink">https://learn.microsoft.com/en-us/virtualization/windowscontainers/quick-start/building-sample-app</em></a></p></div></div></section></body></html>