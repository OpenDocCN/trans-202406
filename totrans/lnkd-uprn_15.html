<html><head></head><body><section data-pdf-bookmark="Chapter 15. Debugging Linkerd" data-type="chapter" epub:type="chapter" class="preface"><div class="preface" id="LUAR_troubleshooting">
<h1 class="calibre7"><span class="calibre">Chapter 15. </span>Debugging Linkerd</h1>


<p class="author1">If you’ve come this far, you understand how valuable a tool Linkerd can be for a platform to provide. It secures your apps, provides powerful insights into those applications, and can account for underlying application and network issues by making your connections more reliable. In this chapter, we’re going to look at what to do when you need to troubleshoot Linkerd itself.<a data-primary="errors" data-see="debugging; HTTP errors" data-type="indexterm" id="id1849" class="calibre4"/><a data-primary="troubleshooting" data-see="debugging" data-type="indexterm" id="id1850" class="calibre4"/></p>

<p class="author1">In all cases, the first step when<a data-primary="debugging" data-secondary="about linkerd check" data-type="indexterm" id="id1851" class="calibre4"/><a data-primary="linkerd" data-secondary="check command" data-tertiary="debugging Linkerd" data-type="indexterm" id="id1852" class="calibre4"/> diagnosing an issue with Linkerd is to use
the Linkerd CLI’s built-in health checking tool by running <code class="calibre9">linkerd check</code>,
as we discussed in more detail in <a data-type="xref" href="ch06.html#LUAR_cli" class="calibre4">Chapter 6</a>. <code class="calibre9">linkerd check</code> is a
very quick way to pinpoint many of the most common issues with Linkerd
installations; for example, it can immediately diagnose expired certificates,
which is the most common issue that causes Linkerd outages in practice.</p>






<section data-pdf-bookmark="Diagnosing Data Plane Issues" data-type="sect1" class="preface"><div class="preface" id="id196">
<h1 class="calibre8">Diagnosing Data Plane Issues</h1>

<p class="author1">Linkerd is somewhat famous<a data-primary="debugging" data-secondary="data plane issues" data-type="indexterm" id="id1853" class="calibre4"/><a data-primary="data plane of Linkerd" data-secondary="debugging" data-type="indexterm" id="id1854" class="calibre4"/> for not requiring a ton of hands-on work with the
data plane; however, it’s still useful to be able to do some basic
troubleshooting. Many proxy issues end up involving fairly similar sets of
solutions.</p>








<section data-pdf-bookmark="“Common” Linkerd Data Plane Failures" data-type="sect2" class="preface"><div class="preface" id="id334">
<h2 class="calibre27">“Common” Linkerd Data Plane Failures</h2>

<p class="author1">While Linkerd is generally a fault-tolerant service mesh, there are a few
conditions that we see arise more than others. Knowing how to tackle these can
be extremely helpful.</p>










<section data-pdf-bookmark="Pods failing to start" data-type="sect3" class="preface"><div class="preface" id="id222">
<h3 class="calibre33">Pods failing to start</h3>

<p class="author1">If you run into a situation where<a data-primary="debugging" data-secondary="data plane issues" data-tertiary="Pods failing to start" data-type="indexterm" id="id1855" class="calibre4"/><a data-primary="data plane of Linkerd" data-secondary="debugging" data-tertiary="Pods failing to start" data-type="indexterm" id="id1856" class="calibre4"/><a data-primary="Kubernetes" data-secondary="Pod startup process" data-tertiary="Pods failing to start" data-type="indexterm" id="id1857" class="calibre4"/><a data-primary="Pods" data-secondary="startup process" data-tertiary="debugging startup failures" data-type="indexterm" id="id1858" class="calibre4"/> injected Pods are failing to start, the
first step will be to identify exactly where the failure is occurring. This is
where the <code class="calibre9">kubectl describe pod</code> and <code class="calibre9">kubectl logs</code> commands can provide a lot
of useful information.</p>

<p class="author1">It’s often most useful to start by describing a failing Pod, to get a sense of
what Kubernetes believes has happened. For example, did the Linkerd init
container fail? Did the Pod get killed because its probes never reported
ready? This information can help you decide which containers to pull logs
from, if you need the logs.</p>

<p class="author1">If the failing containers belong to the application rather than to Linkerd,
you’ll likely be best off looking at non-Linkerd-specific potential causes,
like a failing common dependency, or perhaps Nodes running out of resources.
If it’s Linkerd containers failing, though, the second step is to understand
whether the failure is affecting all new Pods or only some new Pods:</p>
<dl class="calibre10">
<dt class="calibre11">Single Pod failure</dt>
<dd class="calibre12">
<p class="calibre13">If a single Pod is failing, you’ll want to look at the characteristics of that
Pod. Which containers are failing to start? Is it the proxy, an init
container, or the application itself? If other Pods are starting normally, it
isn’t a systemic issue and you’ll need to dive into the particulars of the specific
Pod.</p>
</dd>
<dt class="calibre11">All Pods are failing to start</dt>
<dd class="calibre12">
<p class="calibre13">If the failure is happening on all new Pods, you likely have a more serious
systemic issue. As noted before, the most common reason that all Pods
fail to start is a certificate issue. The <code class="calibre9">linkerd check</code> command will reveal this kind of
issue immediately, which is why we recommend running it first.</p>

<p class="calibre13">Another possible—though uncommon—issue is that the Linkerd proxy injector
isn’t running or is unhealthy. Note that when running Linkerd in HA mode,
which (as discussed in <a data-type="xref" href="ch14.html#LUAR_production_ready" class="calibre4">Chapter 14</a>) we recommend for production use, Kubernetes will refuse to start any new
application Pods until the injector is healthy.</p>
</dd>
<dt class="calibre11">A subset of Pods is failing to start</dt>
<dd class="calibre12">
<p class="calibre13">If only some new Pods are failing to start, it’s time to begin isolating what
common factors exist across those Pods:</p>

<ul class="calibre57">
<li class="calibre58">
<p class="calibre13">Look at the output of <code class="calibre9">kubectl get pods -o wide</code> to see if they’ve been
scheduled on the same Node or Nodes.</p>
</li>
<li class="calibre58">
<p class="calibre13">Look at the <code class="calibre9">kubectl describe pod</code> output: are the init containers failing
to complete successfully?</p>
</li>
<li class="calibre58">
<p class="calibre13">If you’re using the Linkerd CNI plugin, you’ll want to check the state of the
network validator, and you may need to restart the CNI container for that
Node.</p>
</li>
<li class="calibre58">
<p class="calibre13">If you’re not using the Linkerd CNI plugin, take a look at the output of
<code class="calibre9">kubectl logs</code> for the Linkerd init container. If it failed to complete
successfully, try to see what is unique about the Node it’s running on.</p>
</li>
</ul>
</dd>
</dl>
</div></section>










<section data-pdf-bookmark="Intermittent proxy errors" data-type="sect3" class="preface"><div class="preface" id="id113">
<h3 class="calibre33">Intermittent proxy errors</h3>

<p class="author1">Intermittent proxy errors can be<a data-primary="debugging" data-secondary="data plane issues" data-tertiary="intermittent proxy errors" data-type="indexterm" id="id1859" class="calibre4"/><a data-primary="data plane of Linkerd" data-secondary="debugging" data-tertiary="intermittent proxy errors" data-type="indexterm" id="id1860" class="calibre4"/> one of the hardest issues to solve. Any intermittent problem with
the proxy is necessarily difficult to catch and address. When running Linkerd
in production, it’s important to build in monitoring to catch errors
including:</p>
<dl class="calibre10">
<dt class="calibre11">Permission denied events</dt>
<dd class="calibre12">
<p class="calibre13">These represent either a dangerous<a data-primary="permissions" data-secondary="permission denied errors" data-type="indexterm" id="id1861" class="calibre4"/> misconfiguration in your platform or a
genuine threat to your environment. You’ll need to collect and analyze the
logs from the Linkerd proxies in order to detect these events.</p>
</dd>
<dt class="calibre11">Protocol detection timeouts</dt>
<dd class="calibre12">
<p class="calibre13">Protocol detection, discussed<a data-primary="protocol detection" data-secondary="timeouts during" data-type="indexterm" id="id1862" class="calibre4"/><a data-primary="timeouts" data-secondary="protocol detection timeouts" data-type="indexterm" id="id1863" class="calibre4"/> in <a data-type="xref" href="ch04.html#LUAR_meshing_workloads" class="calibre4">Chapter 4</a>, is the process of
Linkerd automatically identifying traffic between two Pods. It’s an important
step that occurs before the proxy can begin sending and receiving traffic. On
occasion, protocol detection can time out and then fall back to treating a
connection as a standard TCP connection. That means the proxy will
introduce an unnecessary 10-second delay, and then the connection will not
benefit from Linkerd’s ability to do things like request-level routing.</p>

<p class="calibre13">Protocol detection timeout events usually indicate a port that should be
marked as skipped or opaque (again, this is discussed in
<a data-type="xref" href="ch04.html#LUAR_meshing_workloads" class="calibre4">Chapter 4</a>). In particular, the proxy will never be able to
correctly perform protocol detection for server-speaks-first protocols. If
you’re using Linkerd’s policy resources, you have the ability to declare the
protocol on a given port. This allows you to skip protocol detection entirely
and will improve the overall availability, as well as security, of your
applications.</p>

<p class="calibre13">A proxy may also be unable to handle protocol detection if it is overloaded.</p>
</dd>
<dt class="calibre11">Out of memory events</dt>
<dd class="calibre12">
<p class="calibre13">An out of memory event for the<a data-primary="out of memory errors" data-type="indexterm" id="id1864" class="calibre4"/><a data-primary="memory" data-secondary="out of memory errors" data-type="indexterm" id="id1865" class="calibre4"/> proxy represents a resource allocation issue. It’s important to monitor, test, and manage the resource limits for the Linkerd proxy. It intercepts and manages the traffic going into and out of your applications, and managing its resources is a core responsibility of the platform team.</p>

<p class="calibre13">Ensure you’re providing the proxy with the resources it needs to handle the traffic flowing through it, or you’re going to have a bad day.</p>
</dd>
<dt class="calibre11">HTTP errors</dt>
<dd class="calibre12">
<p class="calibre13">In general, Linkerd will reuse <a data-primary="HTTP errors" data-type="indexterm" id="id1866" class="calibre4"/>persistent TCP connections between your Pods
and will surface any application-level errors that occur, so if your
applications have any kind of underlying configuration issues, you should see
the errors that your application is actually generating.</p>

<p class="calibre13">However, there are times that the Linkerd proxy will itself respond to a
request with an immediate 502, 503, or 504, and it’s important to understand
what can cause these:</p>
<dl class="calibre10">
<dt class="calibre11">502s</dt>
<dd class="calibre12">
<p class="calibre13">It’s not uncommon for new <a data-primary="HTTP errors" data-secondary="HTTP 502" data-type="indexterm" id="id1867" class="calibre4"/>service mesh users to see an uptick in the
occurrence of 502 errors when they begin adding applications to the
service mesh. This is because whenever Linkerd sees a connection error between
proxies, it will show up as a 502. If you’re seeing a large number of 502
errors in your environment, consult the
<a href="https://oreil.ly/77p8P" class="calibre4">Linkerd docs</a> for more
troubleshooting steps you can take.</p>
</dd>
<dt class="calibre11">503s and 504s</dt>
<dd class="calibre12">
<p class="calibre13">503s and 504s show up <a data-primary="HTTP errors" data-secondary="HTTP 503" data-type="indexterm" id="id1868" class="calibre4"/><a data-primary="HTTP errors" data-secondary="HTTP 504" data-type="indexterm" id="id1869" class="calibre4"/>when a Linkerd proxy finds that requests are
overwhelming a workload’s ability to respond.</p>

<p class="calibre13">Internally, a Linkerd proxy maintains a queue of requests to dispatch. In
normal operation, an incoming request spends almost no time in the queue:
it is queued, and the proxy chooses an available endpoint for the request and
then immediately dispatches it.</p>

<p class="calibre13">However, suppose there’s a massive flood of incoming requests, far
too many for the workload to handle. <a data-primary="load shedding" data-type="indexterm" id="id1870" class="calibre4"/>When the queue gets too long, Linkerd
begins <em class="hyperlink">load shedding</em>, where any new request that arrives gets an immediate
503 directly from the proxy. To stop load shedding, the incoming request
rate needs to slow enough for the requests in the queue to get dispatched,
allowing the queue to shrink.</p>

<p class="calibre13">Also, the pool of endpoints is dynamic: a given endpoint can be removed from
the pool by circuit breaking, for example. <a data-primary="failfast state" data-type="indexterm" id="id1871" class="calibre4"/>If the pool ever becomes completely
empty—i.e., there are <em class="hyperlink">no</em> available endpoints—then the queue enters a state
called <em class="hyperlink">failfast</em>. In failfast, all requests in the queue immediately get a
504 response, and then Linkerd shifts to load shedding, so new requests again
get a 503.</p>

<p class="calibre13">To get out of failfast, some backend has to become available again. If you got
into failfast due to circuit breaking marking all your backends unavailable,
the most likely way you’ll get out is that circuit breaking will allow a probe
request to go through, it’ll succeed, and then the backend will be marked
available again. At that point Linkerd can bring the workload out of failfast
and things will start being handled normally again.</p>
<div data-type="note" epub:type="note" class="calibre16"><h1 class="calibre26">503 Is Not the Same as 504!</h1>
<p class="calibre13">Note the different responses<a data-primary="HTTP errors" data-secondary="HTTP 503 versus 504" data-type="indexterm" id="id1872" class="calibre4"/> there! 504s happen <em class="hyperlink">only</em> at the point where the
load balancer enters failfast, while 503s indicate load shedding—which
could be due to failfast, or could be due to too much traffic.</p>
</div>
</dd>
</dl>
</dd>
</dl>
</div></section>
</div></section>








<section data-pdf-bookmark="Setting Proxy Log Levels" data-type="sect2" class="preface"><div class="preface" id="id197">
<h2 class="calibre27">Setting Proxy Log Levels</h2>

<p class="author1">In normal operation, the Linkerd<a data-primary="debugging" data-secondary="data plane issues" data-tertiary="setting proxy log levels" data-type="indexterm" id="id1873" class="calibre4"/><a data-primary="logging by Linkerd" data-secondary="setting proxy log levels" data-type="indexterm" id="id1874" class="calibre4"/><a data-primary="Linkerd" data-secondary="logs" data-tertiary="setting proxy log levels" data-type="indexterm" id="id1875" class="calibre4"/><a data-primary="monitoring Linkerd" data-secondary="logs" data-tertiary="setting proxy log levels" data-type="indexterm" id="id1876" class="calibre4"/><a data-primary="debugging" data-secondary="DEBUG-level log messages" data-tertiary="setting proxy log levels" data-type="indexterm" id="id1877" class="calibre4"/> proxy does not log debugging information. If
needed, you can change the Linkerd proxy’s log level without needing to
restart the proxy.</p>
<div data-type="warning" epub:type="warning" class="calibre18"><h1 class="calibre35">Debug Logging Can Be Expensive</h1>
<p class="author1">If you set too verbose a log level, the proxy will consume dramatically more
resources, and its performance will degrade. Do not modify the proxy’s log
level unless you need to, and be sure to reset the log level when you’re not
actively debugging.</p>
</div>

<p class="author1">When you need to start debugging, you can turn on debug-level logging as shown
in <a data-type="xref" href="#EX-troubleshooting-loglevel-debug" class="calibre4">Example 15-1</a>.</p>
<div data-type="example" id="EX-troubleshooting-loglevel-debug" class="calibre40">
<h5 class="calibre41"><span class="calibre">Example 15-1. </span>Turning on debug logging</h5>

<pre data-code-language="bash" data-type="programlisting" class="calibre42"><code class="c"># Be sure to replace $POD_NAME with the name of the Pod in question.</code>
$<code class="w"> </code>kubectl<code class="w"> </code>port-forward<code class="w"> </code><code class="nv">$POD_NAME</code><code class="w"> </code>linkerd-admin<code class="w"/>

$<code class="w"> </code>curl<code class="w"> </code>-v<code class="w"> </code>--data<code class="w"> </code><code class="s">'linkerd=debug'</code><code class="w"> </code>-X<code class="w"> </code>PUT<code class="w"> </code>localhost:4191/proxy-log-level<code class="w"/></pre></div>

<p class="author1">Once you’ve finished debugging, be sure to turn <em class="hyperlink">off</em> debug-level logging, as shown
in <a data-type="xref" href="#EX-troubleshooting-loglevel-normal" class="calibre4">Example 15-2</a>. <em class="hyperlink">Don’t leave the proxy running debug-level
logging for longer than you need to</em>: it <em class="hyperlink">will</em> impact performance.</p>
<div data-type="example" id="EX-troubleshooting-loglevel-normal" class="calibre40">
<h5 class="calibre41"><span class="calibre">Example 15-2. </span>Turning off debug logging</h5>

<pre data-code-language="bash" data-type="programlisting" class="calibre42"><code class="c"># Be sure to replace $POD_NAME with the name of the Pod in question.</code>
$<code class="w"> </code>kubectl<code class="w"> </code>port-forward<code class="w"> </code><code class="nv">$POD_NAME</code><code class="w"> </code>linkerd-admin<code class="w"/>

$<code class="w"> </code>curl<code class="w"> </code>-v<code class="w"> </code>--data<code class="w"> </code><code class="s">'warn,linkerd2_proxy=info'</code><code class="w"> </code>-X<code class="w"> </code>PUT<code class="w"> </code>localhost:4191/proxy-log-level<code class="w"/></pre></div>

<p class="author1">Log levels were discussed in <a data-type="xref" href="ch14.html#accessing_linkerd_logs_ch14" class="calibre4">“Accessing Linkerd Logs”</a>; you can find more information about configuring the Linkerd proxy’s log level in the <a href="https://oreil.ly/GNv9I" class="calibre4">official Linkerd docs</a>.</p>
</div></section>
</div></section>






<section data-pdf-bookmark="Debugging the Linkerd Control Plane" data-type="sect1" class="preface"><div class="preface" id="id198">
<h1 class="calibre8">Debugging the Linkerd Control Plane</h1>

<p class="author1">Linkerd’s control plane is broken<a data-primary="debugging" data-secondary="control plane issues" data-type="indexterm" id="id1878" class="calibre4"/><a data-primary="control plane of Linkerd" data-secondary="debugging" data-type="indexterm" id="id1879" class="calibre4"/> down into the core control plane and its
extensions (such as Linkerd Viz and Linkerd Multicluster). Since every
component of the control plane uses a Linkerd proxy to communicate, you can
take advantage of Linkerd’s observability for debugging.</p>








<section data-pdf-bookmark="Linkerd Control Plane and Availability" data-type="sect2" class="preface"><div class="preface" id="id223">
<h2 class="calibre27">Linkerd Control Plane and Availability</h2>

<p class="author1">The control plane is a part<a data-primary="debugging" data-secondary="control plane issues" data-tertiary="linkerd check command" data-type="indexterm" id="id1880" class="calibre4"/><a data-primary="control plane of Linkerd" data-secondary="debugging" data-tertiary="linkerd check command" data-type="indexterm" id="id1881" class="calibre4"/><a data-primary="linkerd" data-secondary="check command" data-tertiary="debugging Linkerd" data-type="indexterm" id="id1882" class="calibre4"/> of all mesh operations, so its health is critical.
As we mentioned at the start of this chapter, the fastest way to get a good
overview of the health of the control plane—outside of paying for a managed
service—is to run <code class="calibre9">linkerd check</code>.</p>

<p class="author1"><code class="calibre9">linkerd check</code> will go through a series of detailed tests and will validate
that there are no known misconfigurations. If there are issues, <code class="calibre9">linkerd
check</code> will point you to documentation about how to fix the problem.</p>
<div data-type="note" epub:type="note" class="calibre16"><h1 class="calibre26">Always Start with linkerd check</h1>
<p class="author1">It’s hard to overstate how useful <code class="calibre9">linkerd check</code> is. Whenever you see
anything that looks unusual about your mesh, <em class="hyperlink">always</em> start with <code class="calibre9">linkerd
check</code>.</p>
</div>

<p class="author1">It’s also good to realize that <code class="calibre9">linkerd check</code> is deliberate about the order
in which it runs its tests: it starts by running all the tests for the core
control plane, then moves on to each extension in sequence. Within each
section, <code class="calibre9">linkerd check</code> generally performs its tests in sequence, with each
one needing to pass before the next is able to run. If a test fails, the
section it’s in and its position within the section can itself give you a lot
of information about where to start debugging.</p>
</div></section>








<section data-pdf-bookmark="The Core Control Plane" data-type="sect2" class="preface"><div class="preface" id="id199">
<h2 class="calibre27">The Core Control Plane</h2>

<p class="author1">The core control plane controls<a data-primary="debugging" data-secondary="control plane issues" data-tertiary="core control plane" data-type="indexterm" id="ch15-core" class="calibre4"/><a data-primary="control plane of Linkerd" data-secondary="debugging" data-tertiary="core control plane" data-type="indexterm" id="ch15-core2" class="calibre4"/> Pod creation, certificate management, and
traffic routing between Pods. As discussed in <a data-type="xref" href="ch02.html#LUAR_intro_to_linkerd" class="calibre4">Chapter 2</a>, the
core control plane consists of three main components: the proxy injector, the
destination controller, and the identity controller. We’ll dive into failure modes
for those components now and what to do about them.</p>
<div data-type="warning" epub:type="warning" class="calibre18"><h1 class="calibre35">Use HA Mode in Production</h1>
<p class="author1">Any instance of Linkerd that is<a data-primary="production" data-secondary="production-ready Linkerd" data-tertiary="high availability required" data-type="indexterm" id="id1883" class="calibre4"/><a data-primary="high availability configuration" data-secondary="required for production" data-type="indexterm" id="id1884" class="calibre4"/> running in production must use high
availability mode—no exceptions! Without HA mode, a single failure in the
control plane can put the whole mesh at risk, which is not acceptable in
production. You can read more about HA mode in <a data-type="xref" href="ch14.html#LUAR_production_ready" class="calibre4">Chapter 14</a>.</p>
</div>










<section data-pdf-bookmark="The identity controller" data-type="sect3" class="preface"><div class="preface" id="id200">
<h3 class="calibre33">The identity controller</h3>

<p class="author1">Any failure in the identity controller<a data-primary="control plane of Linkerd" data-secondary="debugging" data-tertiary="identity controller" data-type="indexterm" id="id1885" class="calibre4"/><a data-primary="debugging" data-secondary="control plane issues" data-tertiary="identity controller" data-type="indexterm" id="id1886" class="calibre4"/><a data-primary="identity controller of control plane" data-secondary="debugging" data-type="indexterm" id="id1887" class="calibre4"/> will impact the issuing and renewing of workload certificates. If a Pod can’t get a certificate at start time, the proxy will fail to start and it will log a message to that effect. On the other side, if a proxy’s certificate expires, it will begin emitting log messages that it failed to renew and will be unable to connect to any new Pods.</p>

<p class="author1">As of this writing we’re familiar with only two known failure modes for the
identity controller:</p>
<dl class="calibre10">
<dt class="calibre11">Expired certificates</dt>
<dd class="calibre12">
<p class="calibre13">When you install Linkerd, you provide<a data-primary="certificates" data-secondary="Linkerd and" data-tertiary="never let certificates expire" data-type="indexterm" id="id1888" class="calibre4"/><a data-primary="expired certificates" data-secondary="identity controller failure" data-type="indexterm" id="id1889" class="calibre4"/><a data-primary="mTLS (mutual TLS)" data-secondary="certificates should not expire" data-tertiary="identity controller failure" data-type="indexterm" id="id1890" class="calibre4"/><a data-primary="production" data-secondary="downtime from certificate expiration" data-tertiary="identity controller failure" data-type="indexterm" id="id1891" class="calibre4"/><a data-primary="debugging" data-secondary="certificates expiring" data-tertiary="identity controller failure" data-type="indexterm" id="id1892" class="calibre4"/><a data-primary="X.509 certificates" data-secondary="Linkerd and" data-tertiary="never let certificates expire" data-type="indexterm" id="id1893" class="calibre4"/><a data-primary="debugging" data-secondary="control plane issues" data-tertiary="expired certificates" data-type="indexterm" id="id1894" class="calibre4"/><a data-primary="control plane of Linkerd" data-secondary="debugging" data-tertiary="expired certificates" data-type="indexterm" id="id1895" class="calibre4"/><a data-primary="identity controller of control plane" data-secondary="debugging" data-tertiary="expired certificates" data-type="indexterm" id="id1896" class="calibre4"/> the control plane with a trust anchor
certificate and an identity issuer certificate, as discussed at length in
<a data-type="xref" href="ch07.html#LUAR_mtls_and_certs" class="calibre4">Chapter 7</a>. If the identity issuer certificate expires,
the identity controller will no longer be able to issue new certificates, which
will cause a mesh-wide outage as individual proxies become unable to establish
secure connections with one another.</p>
</dd>
</dl>
<div data-type="warning" epub:type="warning" class="calibre18"><h1 class="calibre35">Never Let Your Certificates Expire</h1>
<p class="author1">Expired certificates will cause your entire mesh to grind to a halt, and they
are <em class="hyperlink">the</em> most common cause of production Linkerd outages. You <em class="hyperlink">must</em>
regularly monitor the health of your certificates.</p>
</div>
<dl class="calibre10">
<dt class="calibre11">Identity controller overload</dt>
<dd class="calibre12">
<p class="calibre13">Linkerd’s identity controller is <a data-primary="debugging" data-secondary="control plane issues" data-tertiary="identity controller overload" data-type="indexterm" id="id1897" class="calibre4"/><a data-primary="control plane of Linkerd" data-secondary="debugging" data-tertiary="identity controller overload" data-type="indexterm" id="id1898" class="calibre4"/><a data-primary="identity controller of control plane" data-secondary="debugging" data-tertiary="identity controller overload" data-type="indexterm" id="id1899" class="calibre4"/>accessed every time a new meshed Pod is created.
As such, it’s possible—though difficult—to overwhelm the identity controller
by creating a very large number of Pods. This will manifest as long delays in
Pod creation and a large number of messages about certificate creation in the
identity controller’s logs.</p>

<p class="calibre13">The simplest way to deal with an overloaded identity controller is horizontal
scaling: add more replicas to the <code class="calibre9">linkerd-identity</code> deployment in the
<code class="calibre9">linkerd</code> namespace. You might also want to consider allowing it to request
more CPU.</p>
</dd>
</dl>
</div></section>










<section data-pdf-bookmark="The destination controller" data-type="sect3" class="preface"><div class="preface" id="id201">
<h3 class="calibre33">The destination controller</h3>

<p class="author1">Linkerd’s destination controller <a data-primary="debugging" data-secondary="control plane issues" data-tertiary="destination controller" data-type="indexterm" id="id1900" class="calibre4"/><a data-primary="control plane of Linkerd" data-secondary="debugging" data-tertiary="destination controller" data-type="indexterm" id="id1901" class="calibre4"/><a data-primary="destination controller of control plane" data-secondary="debugging" data-type="indexterm" id="id1902" class="calibre4"/>is responsible for providing the individual proxies with their routing information as well as providing details about the effective policy for your environment. It is critical to the normal operations of the mesh, and any degradation should be considered a critical issue to be addressed immediately. There are two main areas to be aware of here:</p>
<dl class="calibre10">
<dt class="calibre11">Memory</dt>
<dd class="calibre12">
<p class="calibre13">The destination controller’s memory usage scales linearly with the number of
endpoints in your cluster. For most clusters, this results in the destination
controller consuming a fairly consistent amount of memory over time. In turn,
this means that if the destination controller gets OOMKilled by Kubernetes, it is
very likely to reach its memory limit and get OOMKilled again every time it
restarts. Therefore, it’s important to actively monitor and manage the memory
limits on the destination controller.</p>
</dd>
<dt class="calibre11">Proxy cache</dt>
<dd class="calibre12">
<p class="calibre13">The Linkerd proxy maintains a cache of endpoints that can be reused by the
proxy in the event that the destination controller is unavailable. By default, the
proxy will cache its endpoint list for 5 seconds and maintain that cache as
long as it gets reused in any given 5-second interval. You can configure that
timeout with the <code class="calibre9">outboundDiscoveryCacheUnusedTimeout</code> property of the
<code class="calibre9">linkerd-control-plane</code> Helm chart. Increasing the timeout will increase your
overall resiliency in the face of a destination controller outage, particularly
for services that see less traffic.</p>
</dd>
</dl>
</div></section>










<section data-pdf-bookmark="The proxy injector" data-type="sect3" class="preface"><div class="preface" id="id114">
<h3 class="calibre33">The proxy injector</h3>

<p class="author1">Linkerd’s proxy injector is a <a data-primary="debugging" data-secondary="control plane issues" data-tertiary="proxy injector" data-type="indexterm" id="id1903" class="calibre4"/><a data-primary="control plane of Linkerd" data-secondary="debugging" data-tertiary="proxy injector" data-type="indexterm" id="id1904" class="calibre4"/><a data-primary="proxy injector of control plane" data-secondary="debugging" data-type="indexterm" id="id1905" class="calibre4"/>mutating webhook that acts in response to Pod
creation events. Of all the elements in the core control plane, the proxy
injector is the one least likely to see issues, but it’s important to actively
monitor its health:</p>

<ul class="printings">
<li class="calibre6">
<p class="author1">In HA mode, if the proxy injector crashes, new Pods will not be allowed to
start until the proxy injector is back online.</p>
</li>
<li class="calibre6">
<p class="author1">In non-HA mode, if the proxy injector crashes, new Pods won’t be injected
into the mesh until it’s back online.</p>
</li>
</ul>
<div data-type="warning" epub:type="warning" class="calibre18"><h1 class="calibre35">Use HA Mode in Production</h1>
<p class="author1">It should be clear from the above<a data-primary="high availability configuration" data-secondary="required for production" data-type="indexterm" id="id1906" class="calibre4"/><a data-primary="production" data-secondary="production-ready Linkerd" data-tertiary="high availability required" data-type="indexterm" id="id1907" class="calibre4"/> description why it’s so important to use
high availability mode in production. You can read more about HA mode in
<a data-type="xref" href="ch14.html#LUAR_production_ready" class="calibre4">Chapter 14</a>.<a data-startref="ch15-core" data-type="indexterm" id="id1908" class="calibre4"/></p>
</div>
</div></section>
</div></section>








<section data-pdf-bookmark="Linkerd Extensions" data-type="sect2" class="preface"><div class="preface" id="id115">
<h2 class="calibre27">Linkerd Extensions</h2>

<p class="author1">No Linkerd extensions are in<a data-primary="debugging" data-secondary="Linkerd extensions" data-type="indexterm" id="id1909" class="calibre4"/><a data-primary="extensions" data-secondary="debugging" data-type="indexterm" id="id1910" class="calibre4"/><a data-primary="extensions" data-secondary="linkerd check command" data-type="indexterm" id="id1911" class="calibre4"/><a data-primary="linkerd" data-secondary="check command" data-tertiary="Linkerd extension checks" data-type="indexterm" id="id1912" class="calibre4"/><a data-primary="Linkerd Viz extension" data-secondary="debugging" data-type="indexterm" id="id1913" class="calibre4"/><a data-primary="linkerd" data-secondary="check command" data-tertiary="debugging Linkerd" data-type="indexterm" id="id1914" class="calibre4"/><a data-primary="Linkerd Viz extension" data-secondary="linkerd check command" data-type="indexterm" id="id1915" class="calibre4"/> the critical path to mesh operations, but many
users of Linkerd use the Linkerd Viz extension, in particular, to gather
additional details about the operation of their services. In the event that you’re
seeing aberrant behavior from Linkerd Viz, <code class="calibre9">linkerd check</code> will almost always
show you what the failure is, and generally the best remediation is to upgrade
or reinstall the extension.</p>

<p class="author1">The one exception to <a data-primary="OOMKilled Prometheus" data-type="indexterm" id="id1916" class="calibre4"/><a data-primary="Linkerd Viz extension" data-secondary="Prometheus instance" data-tertiary="OOMKilled Prometheus" data-type="indexterm" id="id1917" class="calibre4"/><a data-primary="Linkerd Viz extension" data-secondary="Prometheus instance" data-tertiary="not for production" data-type="indexterm" id="id1918" class="calibre4"/><a data-primary="Prometheus" data-secondary="OOMKilled Prometheus" data-type="indexterm" id="id1919" class="calibre4"/><a data-primary="Prometheus" data-secondary="instance with Linkerd Viz extension" data-tertiary="not for production" data-type="indexterm" id="id1920" class="calibre4"/><a data-primary="debugging" data-secondary="OOMKilled Prometheus" data-type="indexterm" id="id1921" class="calibre4"/>this “turn it off and on again” approach to
troubleshooting Linkerd Viz is if you’re using its built-in Prometheus
instance. As we discussed in <a data-type="xref" href="ch14.html#LUAR_production_ready" class="calibre4">Chapter 14</a> and elsewhere, the built-in
Prometheus instance stores metrics only in memory. This means that as you add more metrics
data, it <em class="hyperlink">will</em> periodically get OOMKilled by Kubernetes, and you will lose
whatever data it had stored. This is a known limitation of the built-in
Prometheus.</p>
<div data-type="warning" epub:type="warning" class="calibre18"><h1 class="calibre35">Do Not Use the Built-in Prometheus in Production</h1>
<p class="author1">It should be clear from the previous description that you <em class="hyperlink">must not use the
built-in Prometheus instance in production</em>. You can read more about this in
<a data-type="xref" href="ch14.html#LUAR_production_ready" class="calibre4">Chapter 14</a>.</p>
</div>
</div></section>
</div></section>






<section data-pdf-bookmark="Summary" data-type="sect1" class="preface"><div class="preface" id="id335">
<h1 class="calibre8">Summary</h1>

<p class="author1">In general, Linkerd is a well-behaved, fault-tolerant mesh—especially in HA
mode. However, as with all software, things can go wrong. After reading this chapter,
you should have an idea of where to start looking when they do.</p>
</div></section>
</div></section></body></html>