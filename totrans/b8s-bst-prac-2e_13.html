<html><head></head><body><section data-pdf-bookmark="Chapter 13. Integrating External Services with Kubernetes" data-type="chapter" epub:type="chapter"><div class="chapter" id="integrating_external_services_and_kubernetes">&#13;
<h1><span class="label">Chapter 13. </span>Integrating External Services <span class="keep-together">with Kubernetes</span></h1>&#13;
&#13;
&#13;
<p>In many of the chapters in this book, we’ve discussed how to build,&#13;
deploy, and manage services in Kubernetes. However, the truth is that&#13;
systems don’t exist in a vacuum, and most of the services that we build&#13;
will need to interact with systems and services that exist outside of&#13;
the Kubernetes cluster in which they’re running. This might be necessary because we are building new services being accessed by legacy&#13;
infrastructure running in virtual or physical machines. Additionally, it&#13;
might be because the services we are building need to access&#13;
preexisting databases or other services that are running on&#13;
physical infrastructure in an on-premises datacenter. Finally, you might&#13;
have multiple Kubernetes clusters with services you need to interconnect. For all these reasons, the ability to expose,&#13;
share, and build services that span the boundary of your Kubernetes&#13;
cluster is an important part of building real-world applications.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Importing Services into Kubernetes" data-type="sect1"><div class="sect1" id="importing">&#13;
<h1>Importing Services into Kubernetes</h1>&#13;
&#13;
<p>The most <a data-primary="services" data-secondary="importing" data-type="indexterm" id="service-import"/><a data-primary="importing services" data-type="indexterm" id="import-service"/><a data-primary="external services, importing" data-type="indexterm" id="external-service-import"/><a data-primary="networking" data-secondary="services" data-tertiary="importing" data-type="indexterm" id="network-service-import"/>common pattern for connecting Kubernetes with external services consists of a Kubernetes Service that is consuming a service that exists&#13;
outside of the Kubernetes cluster. Often, this is because Kubernetes is being used for new application development or is serving as an interface for a legacy resource like an on-premises database. In many existing applications, parts of the application are easier to move than others. For example, a database with mission-critical data may be required to stay on premises for reasons of data governance, compliance, or business continuity. At the same time, there are significant benefits to building new interfaces to these legacy databases in Kubernetes. If every migration to Kubernetes required a lift and shift of the entire application, then many applications would be required to stay with their legacy implementations forever. Instead, this chapter shows how you can integrate cloud native development of new applications with existing services such as databases that may be running on traditional virtual machines, bare metal servers, or even mainframes.</p>&#13;
&#13;
<p>When we consider the task of making an external service accessible from&#13;
Kubernetes, the first challenge is simply to get the networking to work&#13;
correctly. The details of making networking operational are specific to both the location of the database and the location of&#13;
the Kubernetes cluster. As a result, they are beyond the scope of this book, but generally, cloud-based Kubernetes providers enable the deployment of a cluster into a user-provided virtual network (VNET), and those virtual networks can then be peered up with an on-premises network.</p>&#13;
&#13;
<p>After you’ve established network connectivity between pods in the Kubernetes cluster and the&#13;
on-premises resource, the next challenge is to make&#13;
the external service look and feel like a Kubernetes Service. In&#13;
Kubernetes, service discovery occurs via Domain Name System (DNS) lookups, so, to make&#13;
our external database feel like it is a native part of Kubernetes, we&#13;
need to make the database discoverable in the same DNS. We’ll get into the details of how to do<a data-primary="services" data-secondary="importing" data-startref="service-import" data-type="indexterm" id="id887"/><a data-primary="importing services" data-startref="import-service" data-type="indexterm" id="id888"/><a data-primary="external services, importing" data-startref="external-service-import" data-type="indexterm" id="id889"/> this next.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Selector-Less Services for Stable IP Addresses" data-type="sect2"><div class="sect2" id="id108">&#13;
<h2>Selector-Less Services for Stable IP Addresses</h2>&#13;
&#13;
<p>The <a data-primary="services" data-secondary="importing" data-tertiary="selector-less services" data-type="indexterm" id="service-import-selectorless"/><a data-primary="importing services" data-secondary="selector-less services" data-type="indexterm" id="import-service-selectorless"/><a data-primary="external services, importing" data-secondary="selector-less services" data-type="indexterm" id="external-service-import-selectorless"/><a data-primary="selector-less services" data-type="indexterm" id="selectorless"/><a data-primary="IP addresses for selector-less services" data-type="indexterm" id="ip-selectorless"/>first way to achieve this is with a <em>selector-less</em> Kubernetes&#13;
Service. When you create a Kubernetes Service without a selector, there&#13;
are no pods whose labels match the nonexistent service selector; thus, no load balancing is performed. Instead, you can program this selector-less service to have&#13;
endpoints that are the specific IP address(es) of the external resource you want to add to the&#13;
Kubernetes cluster. That way, when a Kubernetes pod performs a lookup for&#13;
<code>your-database</code>, the built-in Kubernetes DNS server will translate that&#13;
to a service IP address of your external service. Here is an example of&#13;
a selector-less service for an external database:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Service</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">my-external-database</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">ports</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">protocol</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">TCP</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">port</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">3306</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">targetPort</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">3306</code><code class="w"/></pre>&#13;
&#13;
<p>When the service exists, you need to update its endpoints to contain&#13;
the database IP address serving at <code>24.1.2.3</code>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Endpoints</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="c1"># Important! This name has to match the Service.</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">my-external-database</code><code class="w"/>&#13;
<code class="nt">subsets</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">addresses</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">ip</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">24.1.2.3</code><code class="w"/>&#13;
<code class="w">    </code><code class="nt">ports</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">      </code><code class="p-Indicator">-</code><code class="w"> </code><code class="nt">port</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">3306</code><code class="w"/></pre>&#13;
&#13;
<p><a data-type="xref" href="#figure1401">Figure 13-1</a> depicts how this integrates a service within Kubernetes. As you can see, the pod looks up the service in the cluster DNS server as it would for any other Kubernetes Service. But instead of being given the IP address of another pod in the Kubernetes cluster, it is instead given an IP address that corresponds to the resource outside of the Kubernetes cluster. In this way, the developer may not even know the service is implemented outside of the<a data-primary="services" data-secondary="importing" data-startref="service-import-selectorless" data-tertiary="selector-less services" data-type="indexterm" id="id890"/><a data-primary="importing services" data-secondary="selector-less services" data-startref="import-service-selectorless" data-type="indexterm" id="id891"/><a data-primary="external services, importing" data-secondary="selector-less services" data-startref="external-service-import-selectorless" data-type="indexterm" id="id892"/><a data-primary="selector-less services" data-startref="selectorless" data-type="indexterm" id="id893"/><a data-primary="IP addresses for selector-less services" data-startref="ip-selectorless" data-type="indexterm" id="id894"/> cluster.</p>&#13;
&#13;
<figure><div class="figure" id="figure1401">&#13;
<img alt="images/figure-14-1.png" src="assets/kbp2_1301.png"/>&#13;
<h6><span class="label">Figure 13-1. </span>Service integration</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="CNAME-Based Services for Stable DNS Names" data-type="sect2"><div class="sect2" id="id109">&#13;
<h2>CNAME-Based Services for Stable DNS Names</h2>&#13;
&#13;
<p>The <a data-primary="services" data-secondary="importing" data-tertiary="CNAME-based services" data-type="indexterm" id="service-import-cname"/><a data-primary="importing services" data-secondary="CNAME-based services" data-type="indexterm" id="import-service-cname"/><a data-primary="external services, importing" data-secondary="CNAME-based services" data-type="indexterm" id="external-service-import-cname"/><a data-primary="CNAME-based services" data-type="indexterm" id="cname"/><a data-primary="DNS names" data-type="indexterm" id="dns-cname"/>previous example assumed that the external resource you were&#13;
trying to integrate with your Kubernetes cluster had a stable IP&#13;
address. Although this is often true of physical on-premises resources,&#13;
depending on the network topology, it might not always be true. It is also&#13;
significantly less likely to be true in a cloud environment where&#13;
virtual machine (VM) IP addresses are more dynamic. Alternatively, the&#13;
service might have multiple replicas sitting behind a single DNS-based&#13;
load balancer. In these situations, the external service you are&#13;
trying to bridge into your cluster doesn’t have a stable IP address, but&#13;
it does have a stable DNS name.</p>&#13;
&#13;
<p>For these instances, you can define a CNAME-based Kubernetes Service.&#13;
If you’re not familiar with DNS records, a CNAME, or <em>Canonical Name</em>,&#13;
record indicates that a particular DNS address should be&#13;
translated to a different <em>Canonical</em> DNS name. For example, a CNAME&#13;
record for <em>foo.com</em> that contains <em>bar.com</em> indicates that anyone&#13;
looking up <em>foo.com</em> should perform a recursive lookup for <em>bar.com</em> to&#13;
obtain the correct IP address. You can use Kubernetes Services to define&#13;
CNAME records in the Kubernetes DNS server. For example, if you have an&#13;
external database with a DNS name of <em>database.myco.com</em>, you might&#13;
create a CNAME <em>Service</em> that is named <code>myco-database</code>. Such a Service&#13;
looks like this:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Service</code><code class="w"/>&#13;
<code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">myco-database</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">ExternalName</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">externalName</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">database.myco.com</code><code class="w"/></pre>&#13;
&#13;
<p>With a Service defined in this way, any pod that does a lookup for&#13;
<code>myco-database</code> will be recursively resolved to <em>database.myco.com</em>. Of&#13;
course, to make this work, the DNS name of your external resource <em>also</em>&#13;
needs to be resolvable from the Kubernetes DNS servers. If the DNS name&#13;
is globally accessible (e.g., from a well-known DNS service provider),&#13;
this will automatically work. However, if the DNS of the external&#13;
service is located in a company-local DNS server (e.g., a DNS server that&#13;
services only internal traffic), the Kubernetes cluster might not know by default how to resolve queries to this corporate DNS server.</p>&#13;
&#13;
<p>To set up the cluster’s DNS server to communicate with an alternate DNS resolver,&#13;
you need to adjust its configuration. You do this by updating a&#13;
Kubernetes ConfigMap with a configuration file for the DNS server.</p>&#13;
&#13;
<p>CNAME records are a useful way to map external services with stable DNS&#13;
names to names that are discoverable within your cluster. At first it&#13;
might seem counterintuitive to remap a well-known DNS address to a&#13;
cluster-local DNS address, but the consistency of having all services&#13;
look and feel the same is usually worth the small amount of added&#13;
complexity. Additionally, because the CNAME Service, like all Kubernetes Services, is defined per&#13;
namespace, you can use namespaces to map the same service name&#13;
(e.g., <code>database</code>) to different external services (e.g., <code>canary</code> or&#13;
<code>production</code>), depending on the Kubernetes<a data-primary="services" data-secondary="importing" data-startref="service-import-cname" data-tertiary="CNAME-based services" data-type="indexterm" id="id895"/><a data-primary="importing services" data-secondary="CNAME-based services" data-startref="import-service-cname" data-type="indexterm" id="id896"/><a data-primary="external services, importing" data-secondary="CNAME-based services" data-startref="external-service-import-cname" data-type="indexterm" id="id897"/><a data-primary="CNAME-based services" data-startref="cname" data-type="indexterm" id="id898"/><a data-primary="DNS names" data-startref="dns-cname" data-type="indexterm" id="id899"/> namespace.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Active Controller-Based Approaches" data-type="sect2"><div class="sect2" id="id110">&#13;
<h2>Active Controller-Based Approaches</h2>&#13;
&#13;
<p>In a <a data-primary="services" data-secondary="importing" data-tertiary="active controller-based services" data-type="indexterm" id="service-import-active"/><a data-primary="importing services" data-secondary="active controller-based services" data-type="indexterm" id="import-service-active"/><a data-primary="external services, importing" data-secondary="active controller-based services" data-type="indexterm" id="external-service-import-active"/><a data-primary="active controller-based services" data-type="indexterm" id="active-controller"/>limited set of circumstances, neither of the previous methods for&#13;
exposing external services within Kubernetes is feasible. Generally,&#13;
this is because there is neither a stable DNS address nor a single&#13;
stable IP address for the service that you want to expose within the&#13;
Kubernetes cluster. In such circumstances, exposing the external&#13;
service within the Kubernetes cluster is significantly more complicated,&#13;
but it isn’t impossible.</p>&#13;
&#13;
<p>To achieve this, you need some understanding of how Kubernetes Services work under the hood. Kubernetes Services are made up of two different resources: the Service resource, with which you are doubtless familiar, and the Endpoints resource that represents the IP&#13;
addresses that make up the service. In normal operation, the Kubernetes controller manager populates the endpoints of a service based on the&#13;
selector in the service. However, if you create a selector-less service, as in the first stable-IP approach, the Endpoints resource for the service will not be populated because no pods are selected. In this situation, you need to supply the control loop to&#13;
create and populate the correct Endpoints resource. You need to&#13;
dynamically query your infrastructure to obtain the IP addresses for the&#13;
service external to Kubernetes that you want to integrate and then&#13;
populate your service’s endpoints with these IP addresses. After you do&#13;
this, the mechanisms of Kubernetes take over and program both the DNS&#13;
server and the <code>kube-proxy</code> correctly to load-balance traffic to your&#13;
external service. <a data-type="xref" href="#fig-external-service">Figure 13-2</a> presents a complete picture of how this works in <a data-primary="networking" data-secondary="services" data-startref="network-service-import" data-tertiary="importing" data-type="indexterm" id="id900"/><a data-primary="services" data-secondary="importing" data-startref="service-import-active" data-tertiary="active controller-based services" data-type="indexterm" id="id901"/><a data-primary="importing services" data-secondary="active controller-based services" data-startref="import-service-active" data-type="indexterm" id="id902"/><a data-primary="external services, importing" data-secondary="active controller-based services" data-startref="external-service-import-active" data-type="indexterm" id="id903"/><a data-primary="active controller-based services" data-startref="active-controller" data-type="indexterm" id="id904"/>&#13;
<span class="keep-together">practice.</span></p>&#13;
&#13;
<figure><div class="figure" id="fig-external-service">&#13;
<img alt="images/figure-14-2.png" src="assets/kbp2_1302.png"/>&#13;
<h6><span class="label">Figure 13-2. </span>An external service</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exporting Services from Kubernetes" data-type="sect1"><div class="sect1" id="id111">&#13;
<h1>Exporting Services from Kubernetes</h1>&#13;
&#13;
<p>In the <a data-primary="services" data-secondary="exporting" data-type="indexterm" id="service-export"/><a data-primary="exporting" data-secondary="services" data-type="indexterm" id="export-service"/><a data-primary="internal services, exporting" data-type="indexterm" id="internal-service-export"/><a data-primary="networking" data-secondary="services" data-tertiary="exporting" data-type="indexterm" id="network-service-export"/>previous section, we explored how to import preexisting services to Kubernetes, but you might also need to export services from Kubernetes to the preexisting environments. This might occur because you have a legacy internal application for customer management that needs access to a new API you are developing in a cloud native infrastructure. Alternatively, you might be building new microservice-based APIs but you need to interface with a preexisting traditional web application firewall (WAF) because of internal policy or regulatory requirements. Regardless of the reason, being able to expose services from a Kubernetes cluster to other internal applications is a critical&#13;
design requirement for many applications.</p>&#13;
&#13;
<p>This can be challenging because in many Kubernetes&#13;
installations, the pod IP addresses are not routable addresses from&#13;
outside the cluster. Via tools like flannel, or other networking&#13;
providers, routing is established within a Kubernetes cluster to&#13;
facilitate communication between pods and also between nodes and pods,&#13;
but the same routing is not generally extended to arbitrary machines&#13;
in the same network. In many cases the IP ranges given to pods are&#13;
distinct from the IP space of a corporate network and routing is not&#13;
possible. Furthermore, in the case of cloud to on-premises&#13;
connectivity, the IP addresses of the pods are not always advertised&#13;
back across a VPN or network peering relationship into the on-premises&#13;
network. Consequently, setting up routing between a traditional&#13;
application and Kubernetes pods is the key task to enable the export of&#13;
Kubernetes-based <a data-primary="services" data-secondary="exporting" data-startref="service-export" data-type="indexterm" id="id905"/><a data-primary="exporting" data-secondary="services" data-startref="export-service" data-type="indexterm" id="id906"/><a data-primary="internal services, exporting" data-startref="internal-service-export" data-type="indexterm" id="id907"/>services.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exporting Services by Using Internal Load Balancers" data-type="sect2"><div class="sect2" id="id112">&#13;
<h2>Exporting Services by Using Internal Load Balancers</h2>&#13;
&#13;
<p>The <a data-primary="services" data-secondary="exporting" data-tertiary="with internal load balancers" data-type="indexterm" id="id908"/><a data-primary="exporting" data-secondary="services" data-tertiary="with internal load balancers" data-type="indexterm" id="id909"/><a data-primary="internal services, exporting" data-secondary="with internal load balancers" data-type="indexterm" id="id910"/><a data-primary="load balancers" data-secondary="internal" data-type="indexterm" id="id911"/><a data-primary="internal load balancers" data-type="indexterm" id="id912"/>easiest way to export from Kubernetes is by using the built-in <code>Service</code> object. If you have any previous experience with Kubernetes, no doubt you have seen how you can connect a cloud-based load balancer to bring external traffic to a collection of pods in the cluster. However, you might not have realized that most clouds also offer an <em>internal</em> load balancer. The internal load balancer provides the same capabilities to map a virtual IP address to a collection of pods, but that virtual IP address is drawn from an internal IP address space (e.g., <code>10.0.0.0/24</code>), so it is routable only from within that virtual network. You activate an internal load balancer by adding a cloud-specific annotation to your Service load balancer. For example, in&#13;
Microsoft Azure, you add the <code>service.beta.kubernetes.io/azure-load-balancer-internal: "true"</code> annotation. On Amazon Web Services (AWS), the annotation is <code>service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0</code>. You place annotations in the <code>metadata</code> field in the Service resource as follows:</p>&#13;
<pre>apiVersion: v1&#13;
kind: Service&#13;
metadata:&#13;
  name: my-service&#13;
  annotations:&#13;
    # Replace this as needed in other environments&#13;
    service.beta.kubernetes.io/azure-load-balancer-internal: "true"&#13;
...</pre>&#13;
&#13;
<p>When you export a Service via an internal load balancer, you receive a&#13;
stable, routable IP address that is visible on the virtual network&#13;
outside of the cluster. Then, you can either use that IP address&#13;
directly or set up internal DNS resolution to provide discovery for&#13;
your exported service.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exporting Services on NodePorts" data-type="sect2"><div class="sect2" id="id113">&#13;
<h2>Exporting Services on NodePorts</h2>&#13;
&#13;
<p>Unfortunately, <a data-primary="services" data-secondary="exporting" data-tertiary="with NodePorts" data-type="indexterm" id="service-export-nodeport"/><a data-primary="exporting" data-secondary="services" data-tertiary="with NodePorts" data-type="indexterm" id="export-service-nodeport"/><a data-primary="internal services, exporting" data-secondary="with NodePorts" data-type="indexterm" id="internal-service-export-nodeport"/><a data-primary="NodePort service type" data-type="indexterm" id="nodeport"/>in on-premises installations, cloud-based internal load&#13;
balancers are unavailable. In this context using a NodePort-based&#13;
service is often a good solution. A Service of type NodePort exports a&#13;
listener on every node in the cluster that forwards traffic from the&#13;
node’s IP address and selected port into the Service that you defined, as shown in <a data-type="xref" href="#figure-node-port">Figure 13-3</a>.</p>&#13;
&#13;
<figure><div class="figure" id="figure-node-port">&#13;
<img alt="images/figure-14-3.png" src="assets/kbp2_1303.png"/>&#13;
<h6><span class="label">Figure 13-3. </span>A NodePort-based service</h6>&#13;
</div></figure>&#13;
&#13;
<p>Here’s an example YAML file for a NodePort service:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">v1</code><code class="w"/>&#13;
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">Service</code><code class="w"/>&#13;
<code class="nt">metadata</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">my-node-port-service</code><code class="w"/>&#13;
<code class="nt">spec</code><code class="p">:</code><code class="w"/>&#13;
<code class="w">  </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">NodePort</code><code class="w"/>&#13;
<code class="p">...</code><code class="w"/></pre>&#13;
&#13;
<p>Following the creation of a Service of type NodePort, Kubernetes automatically&#13;
selects a port for the Service; you can get that port from the Service&#13;
by looking at the <code>spec.ports[*].nodePort</code> field. If you want to choose&#13;
the port yourself, you can specify it when you create the Service, but&#13;
the NodePort must be within the configured range for the cluster. The&#13;
default for this range are ports between <code>30000</code> and <code>30999</code>.</p>&#13;
&#13;
<p>Kubernetes’ work is done when the Service is exposed on this port. To&#13;
export it to an existing application outside of the cluster, you (or your&#13;
network administrator) will need to make it discoverable.&#13;
Depending on the way your application is configured, you might be able to&#13;
give your application a list of <code>${node}:${port}</code> pairs, and the&#13;
application will perform client-side load balancing. Alternatively, you might&#13;
need to configure a physical or virtual load balancer within your&#13;
network to direct traffic from a virtual IP address to this list of&#13;
<code>${node}:${port}</code> backends. The specific details for this configuration&#13;
will differ depending on your<a data-primary="services" data-secondary="exporting" data-startref="service-export-nodeport" data-tertiary="with NodePorts" data-type="indexterm" id="id913"/><a data-primary="exporting" data-secondary="services" data-startref="export-service-nodeport" data-tertiary="with NodePorts" data-type="indexterm" id="id914"/><a data-primary="internal services, exporting" data-secondary="with NodePorts" data-startref="internal-service-export-nodeport" data-type="indexterm" id="id915"/><a data-primary="NodePort service type" data-startref="nodeport" data-type="indexterm" id="id916"/> environment.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Integrating External Machines and Kubernetes" data-type="sect2"><div class="sect2" id="id114">&#13;
<h2>Integrating External Machines and Kubernetes</h2>&#13;
&#13;
<p>If neither<a data-primary="services" data-secondary="exporting" data-tertiary="integration with external machines" data-type="indexterm" id="service-export-integrate"/><a data-primary="exporting" data-secondary="services" data-tertiary="integration with external machines" data-type="indexterm" id="export-service-integrate"/><a data-primary="internal services, exporting" data-secondary="integration with external machines" data-type="indexterm" id="internal-service-export-integrate"/><a data-primary="integrating external machines with Kubernetes" data-type="indexterm" id="integrate-external"/> of the previous solutions work well for you, perhaps because&#13;
you want tighter integration for dynamic service discovery, the&#13;
final choice for exposing Kubernetes Services to outside applications is&#13;
to directly integrate the machine(s) running the application into the&#13;
Kubernetes cluster’s service discovery and <span class="keep-together">networking</span> mechanisms. This&#13;
is significantly more invasive and complicated than either of the&#13;
previous approaches, and you should use it only when necessary for&#13;
your application (which should be infrequently). In some managed&#13;
Kubernetes environments, it might not even be possible.</p>&#13;
&#13;
<p>When integrating an external machine into the cluster for networking,&#13;
you need to ensure that the pod network routing and DNS-based service&#13;
discovery both work correctly. The easiest way to do this is to run the kubelet on the machine that you want to join to the cluster, but&#13;
disable scheduling in the cluster. Joining a kubelet node to a cluster&#13;
is beyond the scope of this book, but there are numerous other books&#13;
or online resources that describe how to achieve this. When the node is&#13;
joined, you need to immediately mark it as unschedulable using the&#13;
<code>kubectl cordon ...</code> command to prevent any additional work being&#13;
scheduled on it. This cordoning will not prevent DaemonSets from landing&#13;
pods onto the node, and thus the pods for both the KubeProxy and network&#13;
routing will land on the machine and make Kubernetes-based services&#13;
discoverable from any application running on that machine.</p>&#13;
&#13;
<p>The approach we just described is quite invasive to the node because it requires&#13;
installing Docker or some other container runtime. As a result, it might not be&#13;
feasible in many environments. A lighter weight but more complex&#13;
approach is to just run the <code>kube-proxy</code> as a process on the machine and&#13;
adjust the machine’s DNS server. Assuming that you can set up pod&#13;
routing to work correctly, running the <code>kube-proxy</code> will set up machine-level networking so that Kubernetes Service virtual IP addresses will&#13;
be remapped to the pods that make up that Service. If you also change&#13;
the machine’s DNS to point to the Kubernetes cluster DNS server,&#13;
you will have effectively enabled Kubernetes discovery on a machine that&#13;
is not part of the Kubernetes cluster.</p>&#13;
&#13;
<p>Both of these approaches are complicated and advanced, and you should not take them lightly. If you find yourself considering this level of&#13;
service discovery integration, ask yourself whether it may be easier to&#13;
actually bring the service you are connecting to the cluster into the&#13;
cluster itself. We<a data-primary="networking" data-secondary="services" data-startref="network-service-export" data-tertiary="exporting" data-type="indexterm" id="id917"/><a data-primary="services" data-secondary="exporting" data-startref="service-export-integrate" data-tertiary="integration with external machines" data-type="indexterm" id="id918"/><a data-primary="exporting" data-secondary="services" data-startref="export-service-integrate" data-tertiary="integration with external machines" data-type="indexterm" id="id919"/><a data-primary="internal services, exporting" data-secondary="integration with external machines" data-startref="internal-service-export-integrate" data-type="indexterm" id="id920"/><a data-primary="integrating external machines with Kubernetes" data-startref="integrate-external" data-type="indexterm" id="id921"/> cover this in <a data-type="xref" href="ch16.html#managing_state_and_stateful_application">Chapter 16</a>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sharing Services Between Kubernetes" data-type="sect1"><div class="sect1" id="id115">&#13;
<h1>Sharing Services Between Kubernetes</h1>&#13;
&#13;
<p>The previous<a data-primary="services" data-secondary="sharing" data-type="indexterm" id="service-share"/><a data-primary="sharing services" data-type="indexterm" id="share-service"/> sections have described how to connect Kubernetes&#13;
applications to outside services and how to connect outside services to&#13;
Kubernetes applications, but another significant use case is connecting&#13;
services <em>between</em> Kubernetes clusters. This may be to achieve East-West&#13;
failover between different regional Kubernetes clusters, or it might be to&#13;
link together services run by different teams. The process of achieving&#13;
this interaction is actually a combination of the designs described in&#13;
the previous sections.</p>&#13;
&#13;
<p>First, you need to expose the Service within the first Kubernetes&#13;
cluster to enable network traffic to flow. Let’s assume that you’re in a&#13;
cloud environment that supports internal load balancers, and that you&#13;
receive a virtual IP address for that internal load balancer of&#13;
10.1.10.1. Next, you need to integrate this virtual IP address into&#13;
the second Kubernetes cluster to enable service discovery. You achieve this in the same manner as importing an external application into&#13;
Kubernetes (we covered this in <a data-type="xref" href="#importing">“Importing Services into Kubernetes”</a>). You create a selector-less service and set its IP address to be 10.1.10.1. With these two steps you have&#13;
integrated service discovery and connectivity between services within&#13;
your two Kubernetes clusters.</p>&#13;
&#13;
<p>These steps are fairly manual, and although this might be acceptable&#13;
for a small, static set of services, if you want to enable tighter or&#13;
automatic service integration between clusters, it makes sense to write a&#13;
cluster daemon <a data-primary="cluster daemons" data-type="indexterm" id="id922"/>that runs in both clusters to perform the integration.&#13;
This daemon would watch the first cluster for Services with a particular&#13;
annotation, say something like <code>myco.com/exported-service</code>; all Services&#13;
with this annotation would then be imported into the second cluster via&#13;
selector-less services. Likewise, the same daemon would garbage-collect&#13;
and delete any services that are exported into the second cluster but&#13;
are no longer present in the first. If you set up such daemons in each&#13;
of your regional clusters, you can enable dynamic, East-West connectivity&#13;
between all clusters in your environment.</p>&#13;
&#13;
<p>There has also been recent work within the Kubernetes project to define a Multi-Cluster Service API. This work<a data-primary="Multi-Cluster Service API" data-type="indexterm" id="id923"/> is experimental&#13;
and can be found within the <a href="https://oreil.ly/ZXZi4">Multi-Cluster Service</a> project on GitHub. At the time of writing, the experimental nature of this project means that it is probably not suitable for production use-cases, but it shows the future direction of multi-cluster service management in the&#13;
Kubernetes ecosystem. As it moves from alpha to beta and eventually to general&#13;
availability, this implementation of Service sharing will make it much easier&#13;
to build cross-cluster microservice applications. Even today, tools such as&#13;
the Fleet cluster manager in Microsoft Azure are starting to implement these&#13;
Multi-Cluster Service APIs in response to user <a data-primary="services" data-secondary="sharing" data-startref="service-share" data-type="indexterm" id="id924"/><a data-primary="sharing services" data-startref="share-service" data-type="indexterm" id="id925"/>needs.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Third-Party Tools" data-type="sect1"><div class="sect1" id="id116">&#13;
<h1>Third-Party Tools</h1>&#13;
&#13;
<p>So far, this chapter has described the various ways to import, export, and&#13;
connect services that span Kubernetes clusters and some outside&#13;
resource. If you have previous experience with <a data-primary="networking" data-secondary="service meshes" data-type="indexterm" id="id926"/><a data-primary="service meshes" data-type="indexterm" id="id927"/>service mesh&#13;
technologies, these concepts might seem quite familiar. Indeed,&#13;
there are a variety of third-party tools and projects that you can use&#13;
to interconnect services both with Kubernetes and with arbitrary&#13;
applications and machines. Generally, these tools provide a lot of&#13;
functionality, but they are also significantly more complex&#13;
operationally than the approaches described earlier. However, if you find&#13;
yourself building more and more networking interconnectivity, you should&#13;
explore the space of service meshes, which is rapidly iterating and&#13;
evolving. Nearly all these third-party tools have an open source&#13;
component, but they also offer commercial support that can reduce the&#13;
operational overhead of running additional infrastructure.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Connecting Cluster and External Services Best Practices" data-type="sect1"><div class="sect1" id="id229">&#13;
<h1>Connecting Cluster and External Services Best Practices</h1>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Establish <a data-primary="services" data-secondary="exporting" data-tertiary="best practices" data-type="indexterm" id="id928"/><a data-primary="exporting" data-secondary="services" data-tertiary="best practices" data-type="indexterm" id="id929"/><a data-primary="importing services" data-secondary="best practices" data-type="indexterm" id="id930"/><a data-primary="services" data-secondary="importing" data-tertiary="best" data-type="indexterm" id="id931"/><a data-primary="services" data-secondary="sharing" data-tertiary="best practices" data-type="indexterm" id="id932"/><a data-primary="sharing services" data-secondary="best practices" data-type="indexterm" id="id933"/><a data-primary="external services, importing" data-secondary="best practices" data-type="indexterm" id="id934"/><a data-primary="internal services, exporting" data-secondary="best practices" data-type="indexterm" id="id935"/><a data-primary="networking" data-secondary="services" data-tertiary="best practices for connecting" data-type="indexterm" id="id936"/><a data-primary="best practices" data-secondary="connecting services" data-type="indexterm" id="id937"/>network connectivity between the cluster and on-premises. Networking can be varied between different sites, clouds, and cluster configurations, but&#13;
first ensure that pods can talk to on-premises machines and vice versa.</p>&#13;
</li>&#13;
<li>&#13;
<p>To access services outside of the cluster, you can use selector-less services&#13;
and directly program in the IP address of the machine (e.g., the database) with which you want to communicate. If you don’t have fixed IP addresses, you can instead use CNAME&#13;
services to redirect to a DNS name. If you have neither a DNS name&#13;
nor fixed services, you might need to write a dynamic operator that periodically&#13;
synchronizes the external service IP addresses with the Kubernetes Service <span class="keep-together">endpoints.</span></p>&#13;
</li>&#13;
<li>&#13;
<p>To export services from Kubernetes, use internal load balancers or NodePort&#13;
services. Internal load balancers are typically easier to use in public cloud&#13;
environments where they can be bound to the Kubernetes Service itself. When&#13;
such load balancers are unavailable, NodePort services can expose the service&#13;
on all the machines in the cluster.</p>&#13;
</li>&#13;
<li>&#13;
<p>You can achieve connections between Kubernetes clusters through a combination&#13;
of these two approaches, exposing a service externally that is then consumed&#13;
as a selector-less service in the other Kubernetes cluster.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id368">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In the real world, not every application is cloud native. Building production-ready applications often involves connecting preexisting&#13;
systems with newer applications. This chapter described how you can&#13;
integrate Kubernetes with legacy applications and also how to integrate&#13;
different services running across multiple distinct Kubernetes clusters.&#13;
Unless you have the luxury of building something brand new, cloud native&#13;
development will always require legacy integration. The techniques described in this chapter will help you achieve that.</p>&#13;
</div></section>&#13;
</div></section></body></html>