<html><head></head><body><section data-pdf-bookmark="Chapter 9. Observability" data-type="chapter" epub:type="chapter"><div class="chapter" id="observability_chapter">&#13;
<h1><span class="label">Chapter 9. </span>Observability</h1>&#13;
&#13;
&#13;
<p>The ability to observe any software system is critical. <a data-primary="observability" data-type="indexterm" id="ix_obsr"/> If you cannot examine the condition of your running applications, you cannot effectively manage them.  And that is what we are addressing with observability: the various mechanisms and systems we use to understand the condition of running software that we are responsible for.  We should acknowledge that  we’re not adhering to the control theory definition of observability in this context.  We chose to use this term simply because it has become popular and we want people to readily understand what we’re getting at.</p>&#13;
&#13;
<p>The components of observability<a data-primary="observability" data-secondary="components of" data-type="indexterm" id="idm45611983062408"/> can be broken into three categories:</p>&#13;
<dl>&#13;
<dt>Logging</dt>&#13;
<dd>&#13;
<p>Aggregating and storing the logged event messages written by programs</p>&#13;
</dd>&#13;
<dt>Metrics</dt>&#13;
<dd>&#13;
<p>Collecting time series data, making it available in dashboards, and alerting upon it<a data-primary="metrics" data-type="indexterm" id="idm45611983058296"/></p>&#13;
</dd>&#13;
<dt>Tracing</dt>&#13;
<dd>&#13;
<p>Capturing data for requests that traverse multiple distinct workloads in the &#13;
<span class="keep-together">cluster</span><a data-primary="tracing" data-type="indexterm" id="idm45611983055752"/></p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>In this chapter, we will cover how to implement effective observability in Kubernetes-based platforms so that you can safely manage a platform and the workloads it hosts in production.  First, we will explore logging and examine the systems for aggregating logs and forwarding them to your company’s logging backend.  Next, we’ll cover how to collect metrics, how to visualize that data, and how to alert upon it.  Lastly, we’ll cover tracing requests through distributed systems so as to better understand what’s happening when applications are composed of distinct workloads.  Let’s jump into logging and cover the commonly successful models there.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Logging Mechanics" data-type="sect1"><div class="sect1" id="idm45611983053736">&#13;
<h1>Logging Mechanics</h1>&#13;
&#13;
<p>This section covers logging concerns in a Kubernetes-based platform.<a data-primary="observability" data-secondary="logging" data-startref="ix_obsrlog" data-type="indexterm" id="idm45611983052008"/><a data-primary="logging" data-type="indexterm" id="ix_logs"/>  We’re primarily dealing with the mechanisms for capturing, processing, and forwarding logs from your platform components and tenant workloads to a storage backend.</p>&#13;
&#13;
<p>Once upon a time, the software we ran in production usually wrote logs to a file on disk.  Aggregation of logs—if performed at all—was a simpler exercise because there were fewer distinct workloads and fewer instances of those workloads compared with today’s systems.  In a containerized world, our applications commonly log to standard out and standard error the way an interactive CLI would.  Indeed, this became accepted as best practice for modern service-oriented software even before containers became prevalent.  In cloud native software ecosystems, there are more distinct workloads and instances of each, but they’re also ephemeral and often without a disk mounted to persist the logs—hence the shift away from writing logs to disk.  This introduced challenges in the collection, aggregation, and storage of logs.</p>&#13;
&#13;
<p>Often a single workload will have multiple replicas, and there may be multiple distinct components to examine. Without centralized log aggregation, analyzing (viewing and parsing) logs in this scenario becomes very tedious, if not practically impossible. Consider having to analyze logs for a workload that has <em>dozens</em> of replicas. In these cases, it is essential to have a central collection point that allows you to search the log entries across replicas.</p>&#13;
&#13;
<p>In covering logging mechanics, we’ll first look at strategies for capturing and routing the logs from the containerized workloads in your platform.  This includes the logs for the Kubernetes control plane and platform utilities as well as the platform tenants.  We’ll also cover the Kubernetes API Server audit logs as well as Kubernetes Events in this section.  Lastly, we’ll address the notion of alerting upon conditions found in logged data and alternative strategies for that.  We will not cover the storage of logs because most enterprises have a log backend that we will integrate with—it is generally not a concern of the Kubernetes-based platform itself.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Container Log Processing" data-type="sect2"><div class="sect2" id="idm45611983045736">&#13;
<h2>Container Log Processing</h2>&#13;
&#13;
<p>Let’s look at three ways log processing could be done for the containerized workloads in a <a data-primary="observability" data-secondary="logging" data-tertiary="container log processing" data-type="indexterm" id="ix_obsrlogCLP"/><a data-primary="container log processing" data-type="indexterm" id="ix_cntrlog"/><a data-primary="logging" data-secondary="container log processing" data-type="indexterm" id="ix_logsCLP"/>Kubernetes-based platform:</p>&#13;
<dl>&#13;
<dt>Application forwarding</dt>&#13;
<dd>&#13;
<p>Send logs to the backend directly from the application.</p>&#13;
</dd>&#13;
<dt>Sidecar processing</dt>&#13;
<dd>&#13;
<p>Use a sidecar to manage the logs for an application.</p>&#13;
</dd>&#13;
<dt>Node agent forwarding</dt>&#13;
<dd>&#13;
<p>Run a Pod on each Node that forwards logs for all containers on that Node to the backend.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Application forwarding" data-type="sect3"><div class="sect3" id="idm45611983016696">&#13;
<h3>Application forwarding</h3>&#13;
&#13;
<p>In this case, the application needs to be integrated with the backend storage of logs.<a data-primary="application forwarding of logs" data-type="indexterm" id="idm45611983015560"/><a data-primary="logging" data-secondary="container log processing" data-tertiary="application forwarding" data-type="indexterm" id="idm45611983014952"/>  The developers have to build this functionality into their application and maintain that functionality.  If the log backend changes, an update to the application will likely be required.  Since log processing is virtually universal, it makes much more sense to offload this from the application.  Application forwarding is not a good option in most situations and is rarely seen in production environments. It makes sense only if you have a heritage application that is being migrated to a Kubernetes-based platform that already integrates with a log backend.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sidecar processing" data-type="sect3"><div class="sect3" id="idm45611983012808">&#13;
<h3>Sidecar processing</h3>&#13;
&#13;
<p>In this model, the application runs in one container and writes logs to one or more files in the shared storage for the Pod.<a data-primary="logging" data-secondary="container log processing" data-tertiary="sidecar processing" data-type="indexterm" id="idm45611983011160"/><a data-primary="sidecars" data-secondary="log processing" data-type="indexterm" id="idm45611983009944"/>  Another container in the same Pod, a sidecar, reads those logs and processes them.  The sidecar does one of two things with the logs:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Forwards them directly to the log storage backend</p>&#13;
</li>&#13;
<li>&#13;
<p>Writes the logs to standard error and standard out</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Forwarding directly to the backend is the primary use case for sidecar log processing.  This approach is uncommon and is usually a makeshift workaround where the platform offers no log aggregation system.</p>&#13;
&#13;
<p>In situations where the sidecar writes the logs to standard out and standard error, it does so to leverage Node agent forwarding (which is covered in the next section). This is also an uncommon method and is only useful if you are running an application that just isn’t able to write logs to standard out and standard error.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Node agent forwarding" data-type="sect3"><div class="sect3" id="idm45611983004840">&#13;
<h3>Node agent forwarding</h3>&#13;
&#13;
<p>With node agent forwarding, a log<a data-primary="logging" data-secondary="container log processing" data-tertiary="node agent forwarding" data-type="indexterm" id="idm45611983003336"/><a data-primary="node agent forwarding of logs" data-type="indexterm" id="idm45611983002072"/> processing workload runs on each node in the cluster, reads the logfiles for each container written by the container runtime, and forwards the logs to the backend storage.</p>&#13;
&#13;
<p>This is the model we generally recommend and is, by far, the most common implementation.  It is a useful pattern because:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>There is a single point of integration between the log forwarder and the backend, as opposed to different sidecars and/or applications having to maintain that &#13;
<span class="keep-together">integration</span>.</p>&#13;
</li>&#13;
<li>&#13;
<p>The configuration of standardized filtering, attaching metadata, and forwarding to multiple backends is centralized.</p>&#13;
</li>&#13;
<li>&#13;
<p>Log rotation is taken care of by the kubelet or container runtime.  If the application is writing logfiles inside the container, the application itself or the sidecar (if there is one) needs to handle log rotation.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The prevailing tools used for this node agent log forwarding are <a href="https://www.fluentd.org">Fluentd</a> and <a href="https://fluentbit.io">Fluent Bit</a>.  As the names suggest, they are related projects.  <a data-primary="Fluentd" data-type="indexterm" id="idm45611982994344"/>Fluentd was the original, is written primarily in Ruby, and has a rich ecosystem of plug-ins around it.  Fluent Bit came from a demand for a more lightweight solution for environments like embedded Linux.  It is written in C and has a much smaller memory footprint than Fluentd, but it does not have as many plug-ins available.</p>&#13;
&#13;
<p>The general <a data-primary="Fluent Bit" data-type="indexterm" id="idm45611982992792"/>guidance we give platform engineers when choosing a log aggregation and forwarding tool is to use Fluent Bit unless there are plug-ins for Fluentd that have compelling features.  If you find a need to leverage Fluentd plug-ins, consider running it as a cluster-wide aggregator in conjunction with Fluent Bit as the node agent.  In this model, you use Fluent Bit as the node agent, which is deployed as a DaemonSet.  Fluent Bit forwards logs to Fluentd running in the cluster as a Deployment or StatefulSet.  Fluentd performs further tagging and routes the logs to one or more backends where developers access them. <a data-type="xref" href="#aggregation_of_logs_from_containerized_apps_to_back_end">Figure 9-1</a> illustrates this pattern.</p>&#13;
&#13;
<figure><div class="figure" id="aggregation_of_logs_from_containerized_apps_to_back_end">&#13;
<img alt="prku 0901" src="assets/prku_0901.png"/>&#13;
<h6><span class="label">Figure 9-1. </span>Aggregation of logs from containerized apps to backend.</h6>&#13;
</div></figure>&#13;
&#13;
<p>While we strongly prefer the node agent forwarding method, it’s worth calling out the potential problems with centralizing log aggregation.<a data-primary="log aggregation, centralizing, problems with" data-type="indexterm" id="idm45611982987848"/>  You are introducing a central point of failure for each node, or for the entire cluster if you use a cluster-wide aggregator in your stack.  If your node agent gets bogged down by one workload that is logging excessively, that could affect the collection of logs for all workloads on that node.  If you have a Fluentd cluster-wide aggregator running as a Deployment, it will be using the ephemeral storage layer in its Pod as a buffer.  If it gets killed before it can flush the logs from its buffer, you will lose logs.  For this reason, consider running it as a StatefulSet so those logs aren’t lost if the Pod goes down.<a data-primary="observability" data-secondary="logging" data-startref="ix_obsrlogCLP" data-tertiary="container log processing" data-type="indexterm" id="idm45611982986280"/><a data-primary="container log processing" data-startref="ix_cntrlog" data-type="indexterm" id="idm45611982984728"/><a data-primary="logging" data-secondary="container log processing" data-startref="ix_logsCLP" data-type="indexterm" id="idm45611982983768"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Kubernetes Audit Logs" data-type="sect2"><div class="sect2" id="idm45611982982408">&#13;
<h2>Kubernetes Audit Logs</h2>&#13;
&#13;
<p>This section covers collecting audit logs from the Kubernetes API.<a data-primary="observability" data-secondary="logging" data-tertiary="Kubernetes audit logs" data-type="indexterm" id="ix_obsrlogAL"/><a data-primary="audit logs" data-type="indexterm" id="ix_audlog"/><a data-primary="logging" data-secondary="Kubernetes audit logs" data-type="indexterm" id="ix_logsKAL"/>  These logs offer a way to find out who did what in the cluster.  You will want to have these turned on in production so that you can perform a root cause analysis in the event that something goes wrong.  You may also have compliance requirements that necessitate them.</p>&#13;
&#13;
<p>Audit logs are enabled and configured with flags on the API server.  The API server allows you to capture a log of every stage of every request sent to it, including the request and response bodies.  In reality, it’s unlikely you will want <em>every</em> request logged.  There are a lot of calls to the API server so there will be a very large number of log entries to store.<a data-primary="audit logs" data-secondary="audit policy" data-type="indexterm" id="idm45611982975592"/>  You can use rules in an audit policy to qualify which requests and stages you wish your API server to write logs for.  Without any audit policy, the API server won’t actually write any logs.  Tell the API server where your audit policy is on the control plane node’s filesystem with the <code>--audit-policy-file</code> flag.  <a data-type="xref" href="#example_9_1">Example 9-1</a> shows several rules that illustrate how the policy rules work so that you can limit the volume of log information without excluding important data.</p>&#13;
<div data-type="example" id="example_9_1">&#13;
<h5><span class="label">Example 9-1. </span>Example audit policy</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">audit.k8s.io/v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Policy</code><code>&#13;
</code><code class="nt">rules</code><code class="p">:</code><code>&#13;
</code><code class="p-Indicator">-</code><code> </code><code class="nt">level</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">None</code><code>  </code><a class="co" href="#callout_observability_CO1-1" id="co_observability_CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>  </code><code class="nt">users</code><code class="p">:</code><code> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">system:kube-proxy</code><code class="s">"</code><code class="p-Indicator">]</code><code>&#13;
</code><code>  </code><code class="nt">verbs</code><code class="p">:</code><code> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">watch</code><code class="s">"</code><code class="p-Indicator">]</code><code>&#13;
</code><code>  </code><code class="nt">resources</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">"</code><code> </code><code class="c1"># core</code><code>&#13;
</code><code>    </code><code class="nt">resources</code><code class="p">:</code><code> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">endpoints</code><code class="s">"</code><code class="p-Indicator">,</code><code> </code><code class="s">"</code><code class="s">services</code><code class="s">"</code><code class="p-Indicator">,</code><code> </code><code class="s">"</code><code class="s">services/status</code><code class="s">"</code><code class="p-Indicator">]</code><code>&#13;
</code><code class="p-Indicator">-</code><code> </code><code class="nt">level</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Metadata</code><code>  </code><a class="co" href="#callout_observability_CO1-2" id="co_observability_CO1-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>  </code><code class="nt">resources</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">"</code><code>&#13;
</code><code>    </code><code class="nt">resources</code><code class="p">:</code><code> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">secrets</code><code class="s">"</code><code class="p-Indicator">,</code><code> </code><code class="s">"</code><code class="s">configmaps</code><code class="s">"</code><code class="p-Indicator">]</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">authentication.k8s.io</code><code>&#13;
</code><code>    </code><code class="nt">resources</code><code class="p">:</code><code> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">tokenreviews</code><code class="s">"</code><code class="p-Indicator">]</code><code>&#13;
</code><code>  </code><code class="nt">omitStages</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="s">"</code><code class="s">RequestReceived</code><code class="s">"</code><code>&#13;
</code><code class="p-Indicator">-</code><code> </code><code class="nt">level</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Request</code><code>  </code><a class="co" href="#callout_observability_CO1-3" id="co_observability_CO1-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>  </code><code class="nt">verbs</code><code class="p">:</code><code> </code><code class="p-Indicator">[</code><code class="s">"</code><code class="s">get</code><code class="s">"</code><code class="p-Indicator">,</code><code> </code><code class="s">"</code><code class="s">list</code><code class="s">"</code><code class="p-Indicator">,</code><code> </code><code class="s">"</code><code class="s">watch</code><code class="s">"</code><code class="p-Indicator">]</code><code>&#13;
</code><code>  </code><code class="nt">resources</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">"</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">apps</code><code class="s">"</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">batch</code><code class="s">"</code><code>&#13;
</code><code>  </code><code class="nt">omitStages</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="s">"</code><code class="s">RequestReceived</code><code class="s">"</code><code>&#13;
</code><code class="p-Indicator">-</code><code> </code><code class="nt">level</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">RequestResponse</code><code>  </code><a class="co" href="#callout_observability_CO1-4" id="co_observability_CO1-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>  </code><code class="nt">resources</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">"</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">apps</code><code class="s">"</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">group</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">batch</code><code class="s">"</code><code>&#13;
</code><code>  </code><code class="nt">omitStages</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="s">"</code><code class="s">RequestReceived</code><code class="s">"</code><code>&#13;
</code><code class="c1"># Default level for all other requests.</code><code>&#13;
</code><code class="p-Indicator">-</code><code> </code><code class="nt">level</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Metadata</code><code>  </code><a class="co" href="#callout_observability_CO1-5" id="co_observability_CO1-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
</code><code>  </code><code class="nt">omitStages</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="s">"</code><code class="s">RequestReceived</code><code class="s">"</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO1-1" id="callout_observability_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The <code>None</code> auditing level means the API server will not log events that match this rule.  So when the user <code>system:kube-proxy</code> requests a watch on the listed resources, the event is not logged.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-2" id="callout_observability_CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The <code>Metadata</code> level means that only request metadata is logged.  When any request for the listed resources is received by the API server, it will log which user made what type of requests for what resource, but not the body of the request or response.  The <code>RequestReceived</code> stage will not be logged.  This means it will not write a separate log entry when the request is received.  It will write a log entry when it starts the response for a long-running watch.  It will write a log entry after it completes the response to the client.  And it will log any panic that occurs.  But will omit a log entry when the request is first received.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-3" id="callout_observability_CO1-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>The <code>Request</code> level will instruct the API server to log the request metadata and request body, but <em>not</em> the response body.  So when any client sends a get, list, or watch request, the potentially verbose response body—that contains the object/s—is not logged.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-4" id="callout_observability_CO1-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>The <code>RequestResponse</code> level logs the most information: the request metadata, the request body, and the response body.  This rule lists the same API groups as the previous.  So, in effect, this rule says that if a request is <em>not</em> a get, list, or watch for a resource in one of these groups, additionally log the response body.  In effect this becomes the default log level for the listed groups.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO1-5" id="callout_observability_CO1-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Any other resources that aren’t matched in previous rules will have this default applied, which says to skip the additional log message when a request is received and log only request metadata and excluded request and response bodies.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p class="pagebreak-before">As with other logs in your system, you will want to forward the audit logs to some backend.<a data-primary="audit logs" data-secondary="forwarding to a backend" data-type="indexterm" id="idm45611982662168"/>  You can use either the application forwarding or node agent forwarding strategies we covered earlier in this chapter.  Much of the same principles and patterns apply.</p>&#13;
&#13;
<p>For the application forwarding approach, you can configure the API server to send logs directly to a webhook backend.<a data-primary="webhooks" data-secondary="sending logs to" data-type="indexterm" id="idm45611982660488"/>  In this case you tell the API server with a flag where the config file is that contains the address and credentials to connect.  This config file uses the kubeconfig format.  You will need to spend some time tuning the configuration options for buffering and batching to ensure all logs arrive at the backend.  For example, if you set a buffer size for the number of events to buffer before batching that is too low and it overflows, events will be dropped.</p>&#13;
&#13;
<p>For node agent forwarding, you can have the API server write logfiles to the filesystem on the control plane node.  You can provide flags to the API server to configure the filepath, maximum retention period, maximum number of files, and maximum logfile size.  In this case you can aggregate and forward logs with tools like Fluent Bit and Fluentd.  This is likely a good pattern to follow if you are already using these tools to manage logs with the node agent forwarding discussed earlier.<a data-primary="observability" data-secondary="logging" data-startref="ix_obsrlogAL" data-tertiary="Kubernetes audit logs" data-type="indexterm" id="idm45611982658136"/><a data-primary="logging" data-secondary="Kubernetes audit logs" data-startref="ix_logsKAL" data-type="indexterm" id="idm45611982656808"/><a data-primary="audit logs" data-startref="ix_audlog" data-type="indexterm" id="idm45611982655720"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Kubernetes Events" data-type="sect2"><div class="sect2" id="idm45611982654744">&#13;
<h2>Kubernetes Events</h2>&#13;
&#13;
<p>In Kubernetes, Events are a native resource.<a data-primary="observability" data-secondary="logging" data-tertiary="Kubernetes Events" data-type="indexterm" id="idm45611982653144"/><a data-primary="events" data-secondary="Kubernetes Events" data-type="indexterm" id="idm45611982652056"/><a data-primary="logging" data-secondary="Kubernetes Events" data-type="indexterm" id="idm45611982651208"/>  They are a way for platform components to expose information about what has happened to different objects through the Kubernetes API.<a data-primary="etcd" data-secondary="Events storage in" data-type="indexterm" id="idm45611982650088"/>  In effect, they are a kind of platform log.  Unlike other logs, they are not generally stored in a logging backend.  They are stored in etcd and, by default, are retained for one hour.  They are most commonly used by platform operators and users when they want to gather information about actions taken against objects. <a data-type="xref" href="#ex_9-2">Example 9-2</a> shows the<a data-primary="Pods" data-secondary="Events" data-type="indexterm" id="idm45611982648040"/> Events provided when describing a newly created Pod.</p>&#13;
<div data-type="example" id="ex_9-2">&#13;
<h5><span class="label">Example 9-2. </span>Events given with Pod description</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl describe pod nginx-6db489d4b7-q8ppw&#13;
Name:         nginx-6db489d4b7-q8ppw&#13;
Namespace:    default&#13;
...&#13;
Events:&#13;
  Type    Reason     Age        From&#13;
  ----    ------     ----       ----&#13;
    Message&#13;
    -------&#13;
  Normal  Scheduled  &lt;unknown&gt;  default-scheduler&#13;
    Successfully assigned default/nginx-6db489d4b7-q8ppw&#13;
  Normal  Pulling    34s        kubelet, ip-10-0-0-229.us-east-2.compute.internal&#13;
    Pulling image <code class="s2">"nginx"</code>&#13;
  Normal  Pulled     30s        kubelet, ip-10-0-0-229.us-east-2.compute.internal&#13;
    Successfully pulled image <code class="s2">"nginx"</code>&#13;
  Normal  Created    30s        kubelet, ip-10-0-0-229.us-east-2.compute.internal&#13;
    Created container nginx&#13;
  Normal  Started    30s        kubelet, ip-10-0-0-229.us-east-2.compute.internal&#13;
    Started container nginx</pre></div>&#13;
&#13;
<p>You can<a data-primary="events" data-secondary="namespace Events retrieved directly" data-type="indexterm" id="idm45611982629512"/> also retrieve the same Events directly as shown in <a data-type="xref" href="#ex_9-3">Example 9-3</a>. In this case it includes the Events for the ReplicaSet and Deployment resources in addition to the Pod Events we saw when describing that resource.</p>&#13;
<div data-type="example" id="ex_9-3">&#13;
<h5><span class="label">Example 9-3. </span>Events for a namespace retrieved directly</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get events -n default&#13;
LAST SEEN   TYPE     REASON              OBJECT&#13;
    MESSAGE&#13;
2m5s        Normal   Scheduled           pod/nginx-6db489d4b7-q8ppw&#13;
    Successfully assigned default/nginx-6db489d4b7-q8ppw&#13;
2m5s        Normal   Pulling             pod/nginx-6db489d4b7-q8ppw&#13;
    Pulling image <code class="s2">"nginx"</code>&#13;
2m1s        Normal   Pulled              pod/nginx-6db489d4b7-q8ppw&#13;
    Successfully pulled image <code class="s2">"nginx"</code>&#13;
2m1s        Normal   Created             pod/nginx-6db489d4b7-q8ppw&#13;
    Created container nginx&#13;
2m1s        Normal   Started             pod/nginx-6db489d4b7-q8ppw&#13;
    Started container nginx&#13;
2m6s        Normal   SuccessfulCreate    replicaset/nginx-6db489d4b7&#13;
    Created pod: nginx-6db489d4b7-q8ppw&#13;
2m6s        Normal   ScalingReplicaSet   deployment/nginx&#13;
    Scaled up replica <code class="nb">set </code>nginx-6db489d4b7 to 1</pre></div>&#13;
&#13;
<p>Being that Kubernetes Events are available through the Kubernetes API, it is entirely possible to build automation to watch for, and react to, specific Events.  However, in reality, we don’t see this commonly done.<a data-primary="Prometheus" data-secondary="Event exporters" data-type="indexterm" id="idm45611982608552"/>  One additional way you can leverage them is through an Event exporter that exposes them as metrics.  See <a data-type="xref" href="#prometheus">“Prometheus”</a> for more on Prometheus exporters.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Alerting on Logs" data-type="sect2"><div class="sect2" id="idm45611982638616">&#13;
<h2>Alerting on Logs</h2>&#13;
&#13;
<p>Application logs expose important information about the behavior of your software.<a data-primary="observability" data-secondary="logging" data-tertiary="alerting on logs" data-type="indexterm" id="idm45611982637432"/><a data-primary="alerts" data-secondary="from logs" data-type="indexterm" id="idm45611982636184"/><a data-primary="logging" data-secondary="alerting on logs" data-type="indexterm" id="idm45611982635240"/>  They are especially valuable when unexpected failures occur that require investigation.  This may lead you to find patterns of events that precipitate problems.  If you find yourself wanting to set up alerts on Events exposed in logs, first consider using metrics instead.  If you expose metrics that represent that behavior, you can implement alerting rules against them.  Log messages are less reliable to alert on as they are more subject to change.  A slight change to the text of a log message may inadvertently break the alerting that uses it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Security Implications" data-type="sect2"><div class="sect2" id="idm45611982625640">&#13;
<h2>Security Implications</h2>&#13;
&#13;
<p>Don’t forget to give some thought to the access users have to the various logs aggregated in your backend.<a data-primary="observability" data-secondary="logging" data-tertiary="security concerns for logs" data-type="indexterm" id="idm45611982624216"/><a data-primary="logging" data-secondary="security concerns" data-type="indexterm" id="idm45611982623000"/><a data-primary="security" data-secondary="logs" data-type="indexterm" id="idm45611982622056"/>  You may not want your production API server audit logs accessible to everyone.  You may have sensitive systems with information that only privileged users should have access to.  This may impact the tagging of logs or may necessitate using multiple backends, impacting your forwarding configurations.</p>&#13;
&#13;
<p>Now that we’ve covered the various mechanics involved in managing the logs from your platform and its tenants, let’s move on to metrics and alerting.<a data-primary="observability" data-secondary="logging" data-startref="ix_obsrlog" data-type="indexterm" id="idm45611982620104"/><a data-primary="logging" data-startref="ix_logs" data-type="indexterm" id="idm45611982618856"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Metrics" data-type="sect1"><div class="sect1" id="idm45611983053112">&#13;
<h1>Metrics</h1>&#13;
&#13;
<p>Metrics and alerting <a data-primary="observability" data-secondary="metrics" data-type="indexterm" id="ix_obsrmtrc"/><a data-primary="metrics" data-type="indexterm" id="ix_mtrc"/>services are vital to the usability of the platform.  Metrics allow us to plot measured data on a timeline and recognize divergences that indicate undesirable or unexpected behavior.  They help us understand what’s happening with our applications, inform us whether they are behaving as we expect, and give us insights into how we can remedy problems or improve how we manage our workloads.  And, critically, metrics give us useful measurements to alert on.  Notifications of failures, or preferably warnings of impending failures, give us the opportunity to avert and/or minimize downtime and errors.</p>&#13;
&#13;
<p>In this section, we’re going to cover how to provide metrics and alerting as a platform service using Prometheus.  There is considerable detail to explore here, and it will be helpful to reference a particular software stack as we do so.  This is not to say you cannot or should not use other solutions.  There are many circumstances where Prometheus may <em>not</em> be the right solution.  However, Prometheus does provide an excellent model for addressing the subject.  Regardless of the exact tools you use, the Prometheus model provides a clear implementation reference that will inform how you approach this topic.</p>&#13;
&#13;
<p>First, we will take a general look at what Prometheus is, how it collects metrics, and what functions it provides.  Then we will address various general subtopics, including long-term storage and the use case for pushing metrics.  Next, we’ll cover custom metrics generation and collection as well as organization and federation of metrics collection across your infrastructure.  Also, we will dive into alerting and using metrics for actionable showback and chargeback data.  Finally, we will break down each of the various components in the Prometheus stack and illustrate how they fit together.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Prometheus" data-type="sect2"><div class="sect2" id="prometheus">&#13;
<h2>Prometheus</h2>&#13;
&#13;
<p>Prometheus is an open source metrics tool that has become the prevalent open source solution for Kubernetes-based platforms.<a data-primary="observability" data-secondary="metrics" data-tertiary="Prometheus" data-type="indexterm" id="idm45611982580664"/><a data-primary="metrics" data-secondary="Prometheus" data-type="indexterm" id="idm45611982579416"/><a data-primary="Prometheus" data-type="indexterm" id="ix_Prom"/>  The control plane components expose Prometheus metrics, and virtually every production cluster uses Prometheus exporters to get metrics from things like the underlying nodes.  Due to this, many enterprise systems such as Datadog, New Relic, and VMware Tanzu Observability support consuming Prometheus metrics.</p>&#13;
&#13;
<p>Prometheus metrics are simply a standard format for time series data that can actually be used by any system.  Prometheus uses a scraping model whereby it collects metrics from targets.  So applications and infrastructure do not typically <em>send</em> metrics anywhere, they expose them at an endpoint from which Prometheus can scrape them.  This model removes the app’s responsibility for knowing anything about the metrics system beyond the format in which to present the data.</p>&#13;
&#13;
<p>This scraping model for collecting metrics, its ability to process large amounts of data, the use of labels in its data model, and the Prometheus Query Language (PromQL) make it a great metrics tool for dynamic, cloud native environments.  New workloads can be readily introduced and monitored.  Expose Prometheus metrics from an application or system, add a scrape configuration to a Prometheus server, and use PromQL to turn the raw data into meaningful insights and alerts.  These are some of the core reasons Prometheus became such a popular choice in the Kubernetes ecosystem.</p>&#13;
&#13;
<p>Prometheus<a data-primary="Prometheus" data-secondary="critical metrics functions" data-type="indexterm" id="idm45611982574360"/> provides several critical metrics functions:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Collects metrics from targets using its scraping model</p>&#13;
</li>&#13;
<li>&#13;
<p>Stores the metrics in a time series database</p>&#13;
</li>&#13;
<li>&#13;
<p>Sends alerts, usually to Alertmanager, which is discussed later in this chapter, based on alerting rules</p>&#13;
</li>&#13;
<li>&#13;
<p>Exposes an HTTP API for other components to access the metrics stored by Prometheus</p>&#13;
</li>&#13;
<li>&#13;
<p>Provides a dashboard that is useful for executing ad hoc metric queries and getting various status info</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Most teams use Prometheus for metrics collection paired with Grafana for visualization when they start out.  However, maintaining organized use of the system in a production environment can become challenging for smaller teams.  You will have to solve for long-term storage of your metrics, scaling Prometheus as the volume of metrics grows, as well as organizing the federation of your metrics systems.  None of these are trivial problems to solve and manage over time.  So if the maintenance of the metrics stack becomes cumbersome as the system scales, you can migrate to one of those commercial systems without changing the type of metrics you use.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Long-Term Storage" data-type="sect2"><div class="sect2" id="idm45611982554968">&#13;
<h2>Long-Term Storage</h2>&#13;
&#13;
<p>It’s important to note that Prometheus is not designed for long-term storage of metrics.<a data-primary="metrics" data-secondary="long term storage" data-type="indexterm" id="idm45611982553368"/><a data-primary="observability" data-secondary="metrics" data-tertiary="long term storage" data-type="indexterm" id="idm45611982552520"/><a data-primary="storage" data-secondary="long term, for metrics" data-type="indexterm" id="idm45611982551432"/>  Instead, it provides support for writing to remote endpoints, and there are a <a href="https://oreil.ly/wcaVl">number of solutions</a> that can be used for this kind of integration.  The questions you have to answer when providing a metrics solution as a part of your application platform are around data retention.  Do you offer long-term storage only in production?  If so, what retention period at the Prometheus layer do you offer in nonprod environments?  How will you expose the metrics in long-term storage to users?  Projects such as <a href="https://thanos.io">Thanos</a> and <a href="https://cortexmetrics.io">Cortex</a> offer tool stacks to help solve these problems.  Just keep in mind how your platform tenants will be able to leverage these systems and let them know what retention policies they can expect.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pushing Metrics" data-type="sect2"><div class="sect2" id="idm45611982547816">&#13;
<h2>Pushing Metrics</h2>&#13;
&#13;
<p>Not every workload is a good fit for the scraping model.<a data-primary="Prometheus" data-secondary="Pushgateway" data-type="indexterm" id="idm45611982546680"/><a data-primary="metrics" data-secondary="pushing" data-type="indexterm" id="idm45611982545832"/><a data-primary="observability" data-secondary="metrics" data-tertiary="pushing" data-type="indexterm" id="idm45611982544984"/>  In these cases the <a href="https://github.com/prometheus/pushgateway">Prometheus Pushgateway</a> may be used.  For example, a batch workload that shuts down when it has finished its work may not give the Prometheus server the chance to collect all metrics before it disappears.  For this situation, the batch workload can push its metrics to the Pushgateway which, in turn, exposes those metrics for the Prometheus server to retrieve.  So if your platform will support workloads that call for this support, you will likely need to deploy the Pushgateway as a part of your metrics stack and publish information for tenants to leverage it.  They will need to know where it is in the cluster and how to use its REST-like HTTP API. <a data-type="xref" href="#pushgateway_for_ephemeral_workload">Figure 9-2</a> illustrates an ephemeral workload leveraging a Prometheus client library that supports pushing metrics to a Pushgateway.  Those metrics are then scraped by a Prometheus server.</p>&#13;
&#13;
<figure><div class="figure" id="pushgateway_for_ephemeral_workload">&#13;
<img alt="prku 0902" src="assets/prku_0902.png"/>&#13;
<h6><span class="label">Figure 9-2. </span>Pushgateway for ephemeral workload.</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Custom Metrics" data-type="sect2"><div class="sect2" id="idm45611982539560">&#13;
<h2>Custom Metrics</h2>&#13;
&#13;
<p>Prometheus metrics can be exposed natively by an application.<a data-primary="metrics" data-secondary="custom" data-type="indexterm" id="idm45611982538184"/><a data-primary="observability" data-secondary="metrics" data-tertiary="custom metrics" data-type="indexterm" id="idm45611982537336"/><a data-primary="Prometheus" data-secondary="custom metrics" data-type="indexterm" id="idm45611982536248"/>  Many applications that are developed expressly to run on Kubernetes-based platforms do just this.  There are several officially supported <a href="https://oreil.ly/t9SLv">client libraries</a> as well as a number of community-supported libraries.  Using these, your application developers will likely find it trivial to expose custom Prometheus metrics for scraping.  This is covered in depth in <a data-type="xref" href="ch14.html#application_considerations_chapter">Chapter 14</a>.</p>&#13;
&#13;
<p>Alternatively, <em>exporters</em> can be used when Prometheus metrics are not natively supported by an app or system.<a data-primary="exporters" data-type="indexterm" id="idm45611982532760"/>  Exporters collect data points from an application or system, then expose them as Prometheus metrics.  A common example of this is the <a data-primary="Node exporter" data-type="indexterm" id="idm45611982531864"/>Node Exporter.  It collects hardware and operating system metrics, then exposes those metrics for a Prometheus server to scrape.  There are <a href="https://oreil.ly/JO8sO">community-supported exporters</a> for a wide range of popular tools, some of which you may find useful.</p>&#13;
&#13;
<p>Once an application that exposes custom metrics is deployed, the next matter is adding the application to the scrape configuration of a Prometheus server.  This is usually done with a ServiceMonitor custom resource used by the Prometheus Operator.  The Prometheus Operator is covered further in <a data-type="xref" href="#metrics_components">“Metrics Components”</a>, but for now it is enough to know that you can use a custom Kubernetes resource to instruct the operator to auto-discover Services based on their Namespace and labels.<a data-primary="labels" data-secondary="in Prometheus" data-type="indexterm" id="idm45611982528728"/></p>&#13;
&#13;
<p>In short, instrument the software you develop in-house where possible.  Develop or leverage exporters where native instrumentation is not feasible.  And collect the exposed metrics using convenient auto-discovery mechanisms to provide visibility into your systems.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>While the use of labels in the Prometheus data model is powerful, with power comes responsibility.  You can shoot yourself in the foot with them.  If you overuse labels, the resource consumption of your Prometheus servers can become untenable.  Familiarize yourself with the impact of high cardinality of metrics and check out the <a href="https://oreil.ly/RAskV">instrumentation guide</a> in the Prometheus docs.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Organization and Federation" data-type="sect2"><div class="sect2" id="organization_and_federation">&#13;
<h2>Organization and Federation</h2>&#13;
&#13;
<p>Processing metrics can be particularly compute-intensive, so subdividing this computational <a data-primary="metrics" data-secondary="organization and federation" data-type="indexterm" id="idm45611982523368"/><a data-primary="observability" data-secondary="metrics" data-tertiary="organization and federation" data-type="indexterm" id="idm45611982522520"/>load can help manage resource consumption for Prometheus servers.<a data-primary="Prometheus" data-secondary="organization and federation of metrics" data-type="indexterm" id="idm45611982521304"/>  For example, use one Prometheus server to collect metrics for the platform and use other Prometheus servers to collect custom metrics from applications or node metrics.  This is particularly applicable in larger clusters where there are far more scrape targets and much larger volumes of metrics to process.</p>&#13;
&#13;
<p>However, doing this will fragment the locations in which you can see this data.  One way to solve this is through federation.<a data-primary="federation" data-secondary="of metrics system" data-type="indexterm" id="idm45611982519480"/>  Federation, in general, refers to consolidating data and control into a centralized system.  Prometheus federation involves collecting important metrics from various Prometheus servers into a central Prometheus server.  This is accomplished using the same scraping model used to collect metrics from workloads.  One of the targets that a Prometheus server can scrape metrics from is another Prometheus server.</p>&#13;
&#13;
<p>This can be done within a single Kubernetes cluster, among several Kubernetes clusters, or both.  This provides a very flexible model in that you can organize and consolidate your metrics systems in ways that suit the patterns you use to manage your Kubernetes clusters.  This includes federating in layers or tiers. <a data-type="xref" href="#prometheus_federation">Figure 9-3</a> shows an example of a global Prometheus server scraping metrics from Prometheus servers in different datacenters which, in turn, scrape metrics from targets within their cluster.</p>&#13;
&#13;
<figure><div class="figure" id="prometheus_federation">&#13;
<img alt="prku 0903" src="assets/prku_0903.png"/>&#13;
<h6><span class="label">Figure 9-3. </span>Prometheus federation.</h6>&#13;
</div></figure>&#13;
&#13;
<p>While Prometheus federation is powerful and flexible, it can be complex and burdensome to manage.  A relatively recent development that offers a compelling way to collect metrics from all your Prometheus servers is <a href="https://thanos.io">Thanos</a>, an open source project that builds federation-like capabilities on top of Prometheus.  It is supported by the Prometheus Operator and can be layered onto existing Prometheus installations.  <a href="https://cortexmetrics.io">Cortex</a> is another promising project in this capacity.  Both Thanos and Cortex are incubating projects in the CNCF.</p>&#13;
&#13;
<p>Carefully plan out the organization and federation of your Prometheus servers to support scaling and expanding your operations as platform adoption grows.  Give careful consideration to the consumption model for tenants.  Avoid making them use a multitude of different dashboards to access metrics for their workloads.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Alerts" data-type="sect2"><div class="sect2" id="idm45611982511640">&#13;
<h2>Alerts</h2>&#13;
&#13;
<p>Prometheus uses alerting rules to generate alerts from metrics.<a data-primary="alerts" data-secondary="from metrics" data-type="indexterm" id="ix_alrtmtr"/><a data-primary="metrics" data-secondary="alerts from" data-type="indexterm" id="ix_mtrcalrt"/>  When an alert is triggered, the alert will usually be sent to a configured Alertmanager instance.  Deploying Alertmanager and configuring Prometheus to send alerts to it is somewhat trivial when using the Prometheus Operator.  Alertmanager will process the alert and integrate with messaging systems to make your engineers aware of issues. <a data-type="xref" href="#alerting_components">Figure 9-4</a> illustrates the use of distinct Prometheus servers for the platform control plane and tenant applications.  They both use a common Alertmanager to process alerts and notify receivers.</p>&#13;
&#13;
<figure><div class="figure" id="alerting_components">&#13;
<img alt="prku 0904" src="assets/prku_0904.png"/>&#13;
<h6><span class="label">Figure 9-4. </span>Alerting components.</h6>&#13;
</div></figure>&#13;
&#13;
<p>In general, be careful not to <em>over</em> alert.  Excessive critical alerts will burn out your on-call engineers and the noise of false positives can drown out actual critical events.  So take the time to tune your alerts to be useful.  Add useful descriptions to the annotations on the alerts so that when engineers are alerted to a problem, they have some useful context to understand the situation.  Consider including links to runbooks or other docs that can aid the resolution of the alerted incident.</p>&#13;
&#13;
<p>In addition to alerts for the platform, consider how to expose alerting for your tenants so that they may set up alerts on the metrics for their application.  This involves giving them ways to add alerting rules to Prometheus, which is covered more in <a data-type="xref" href="#metrics_components">“Metrics Components”</a>.  It also includes setting up the notification mechanisms through Alertmanager so that application teams are alerted according to the rules they set.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Dead man’s switch" data-type="sect3"><div class="sect3" id="idm45611982501992">&#13;
<h3>Dead man’s switch</h3>&#13;
&#13;
<p>One alert in particular is worth addressing as it is universally applicable and particularly critical.<a data-primary="alerts" data-secondary="from metrics" data-tertiary="when alerting and metrics systems go down" data-type="indexterm" id="idm45611982500520"/>  What happens if your metrics and alerting systems go down?  How will you get an alert of <em>that</em> event?  In this case you need to set up an alert that fires periodically under normal operating conditions and that, if those alerts stop, fires a critical alert to let on-call know your metrics and/or alerting systems are down.  <a href="https://oreil.ly/zDJJE">PagerDuty</a> has an integration they call Dead Man’s <em>Snitch</em> that provides this feature.<a data-primary="Dead Man's Snitch" data-type="indexterm" id="idm45611982497560"/>  Alternatively, you could set up a custom solution with webhook alerts to a system you install.  Regardless of the implementation details, ensure you are notified urgently if your alerting system goes offline.<a data-primary="metrics" data-secondary="alerts from" data-startref="ix_mtrcalrt" data-type="indexterm" id="idm45611982496600"/><a data-primary="alerts" data-secondary="from metrics" data-startref="ix_alrtmtr" data-type="indexterm" id="idm45611982495512"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Showback and Chargeback" data-type="sect2"><div class="sect2" id="idm45611982494296">&#13;
<h2>Showback and Chargeback</h2>&#13;
&#13;
<p><em>Showback</em> is a term commonly used to describe resource usage by an organizational unit or its workloads.<a data-primary="observability" data-secondary="metrics" data-tertiary="showback and chargeback" data-type="indexterm" id="ix_obsrmtrcshch"/><a data-primary="metrics" data-secondary="showback and chargeback" data-type="indexterm" id="ix_mtrcshch"/><a data-primary="showback and chargeback" data-type="indexterm" id="ix_shch"/>  <em>Chargeback</em> is the association of costs with that resource usage.<a data-primary="chargeback" data-type="indexterm" id="idm45611982488136"/>  These are perfect examples of meaningful, actionable expressions of metrics data.</p>&#13;
&#13;
<p>Kubernetes offers the opportunity to dynamically manage compute infrastructure used by app development teams.  If this readily available capacity is not managed well, you may find cluster sprawl and poor utilization of resources.  It is greatly advantageous to the business to streamline the process of deploying infrastructure and workloads for efficiency.  However, this streamlining can also lead to waste.  For this reason, many organizations make their teams and lines of business accountable for the usage with showback and chargeback.</p>&#13;
&#13;
<p>In order to make it possible to collect relevant metrics, workloads need to be labeled with something useful like a “team” or “owner” name or identifier.  We recommend establishing a standardized system for this in your organization and use admission control to enforce the use of such a label on all Pods deployed by platform tenants.  There are occasionally other useful methods of identifying workloads, such as by Namespace, but labels are the most flexible.</p>&#13;
&#13;
<p>There are two general approaches to implementing showback:</p>&#13;
<dl>&#13;
<dt>Requests</dt>&#13;
<dd>&#13;
<p>Requests are based on the resources a team reserves with the resource requests that are defined for each container in a Pod.</p>&#13;
</dd>&#13;
<dt>Consumption</dt>&#13;
<dd>&#13;
<p>Consumption is based on what a team actually consumes through resource requests <em>or</em> actual usage, whichever is higher.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Showback by requests" data-type="sect3"><div class="sect3" id="idm45611982481000">&#13;
<h3>Showback by requests</h3>&#13;
&#13;
<p>The requests-based method leverages the aggregate resource requests defined by a workload.  <a data-primary="showback and chargeback" data-secondary="showback by requests" data-type="indexterm" id="idm45611982479560"/>For example, if a Deployment with 10 replicas requests 1 CPU core per replica, it is considered to have used 10 cores per unit of time that it was running.  In this model, if a workload bursts above its requests and uses 1.5 cores per replica on average, it would have gotten those resources for free; those additional 5 cores consumed above its resource requests are <em>not</em> attributed to the workload.  This approach is advantageous in that it is based on what the scheduler can assign to nodes in the cluster.  The scheduler considers resource requests as reserved capacity on a node.  If a node has spare resources that aren’t being used, and a workload bursts to use that otherwise unused capacity, that workload got those resources for free.  The solid line in <a data-type="xref" href="#showback_based_on_cpu_requests">Figure 9-5</a> indicates the CPU resources attributed to a workload using this method.  Consumption that bursts above requests is <em>not</em> attributed.</p>&#13;
&#13;
<figure><div class="figure" id="showback_based_on_cpu_requests">&#13;
<img alt="prku 0905" src="assets/prku_0905.png"/>&#13;
<h6><span class="label">Figure 9-5. </span>Showback based on CPU requests.</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Showback by consumption" data-type="sect3"><div class="sect3" id="idm45611982473736">&#13;
<h3>Showback by consumption</h3>&#13;
&#13;
<p>In a consumption-based model, a workload would be assigned the usage of its resource requests <em>or</em> its actual usage, whichever is higher.<a data-primary="showback and chargeback" data-secondary="showback by consumption" data-type="indexterm" id="idm45611982471704"/>  With this approach, if a workload commonly and consistently used more than its requested resources, it would be shown to have used those resources it actually consumed.  This approach would remove the possible incentive to game the system by setting resource requests low.  This could be more likely to lead to resource contention on overcommitted nodes.  The solid line in <a data-type="xref" href="#showback_based_on_cpu_consumption_when_bursting_above_requests">Figure 9-6</a> indicates the CPU resources attributed to a workload using this consumption-based method.  In this case, consumption that bursts above requests is attributed.</p>&#13;
&#13;
<figure><div class="figure" id="showback_based_on_cpu_consumption_when_bursting_above_requests">&#13;
<img alt="prku 0906" src="assets/prku_0906.png"/>&#13;
<h6><span class="label">Figure 9-6. </span>Showback based on CPU consumption when bursting above requests.</h6>&#13;
</div></figure>&#13;
&#13;
<p>In <a data-type="xref" href="#metrics_components">“Metrics Components”</a>, we will cover kube-state-metrics, a platform service that exposes metrics related to Kubernetes resources.  If you use kube-state-metrics as a part of your metrics stack, you will have the following metrics available for resource requests:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>CPU: <code>kube_pod_container_resource_requests</code></p>&#13;
</li>&#13;
<li>&#13;
<p>Memory: <code>kube_pod_container_resource_requests_memory_bytes</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Resource usage can be obtained with the following metrics:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>CPU: <code>container_cpu_usage_seconds_total</code></p>&#13;
</li>&#13;
<li>&#13;
<p>Memory: <code>container_memory_usage_bytes</code></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Lastly for showback, you should decide whether to use CPU or memory for determining showback for a workload.  For this, calculate the percentage of total cluster resource consumed by a workload for both CPU and memory.   The higher value should apply because if a cluster runs out of CPU <em>or</em> memory it cannot host more workloads.  For example, if a workload uses 1% of cluster CPU and 3% of cluster memory, it is effectively using 3% of the cluster since a cluster without any more memory cannot host any more workloads.  This will also help inform whether you should employ different node profiles to match the workloads they host, which is discussed in <a data-type="xref" href="ch02.html#infrastructure">“Infrastructure”</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Chargeback" data-type="sect3"><div class="sect3" id="idm45611982457144">&#13;
<h3>Chargeback</h3>&#13;
&#13;
<p>Once we solve showback, chargeback becomes possible because we have metrics to apply costs to.<a data-primary="showback and chargeback" data-secondary="chargeback" data-type="indexterm" id="idm45611982455960"/><a data-primary="chargeback" data-type="indexterm" id="idm45611982455112"/>  Costs for machines will usually be pretty straightforward if using a public cloud provider.  It may be a little more complicated if you are buying your own hardware, but somehow or another you need to come up with two cost values:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Cost per unit of time for CPU</p>&#13;
</li>&#13;
<li>&#13;
<p>Cost per unit of time for memory</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Apply these costs to the showback value determined and you have a model for internally charging your platform tenants.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Network and storage" data-type="sect3"><div class="sect3" id="idm45611982450888">&#13;
<h3>Network and storage</h3>&#13;
&#13;
<p>So far we’ve looked at showback and chargeback for the compute infrastructure used by workloads.<a data-primary="showback and chargeback" data-secondary="network and storage" data-type="indexterm" id="idm45611982449448"/><a data-primary="networks" data-secondary="showback and chargeback for" data-type="indexterm" id="idm45611982448472"/><a data-primary="storage" data-secondary="showback and chargeback for" data-type="indexterm" id="idm45611982447560"/>  This covers a majority of use cases we have seen in the field.  However, there are workloads that consume considerable networking bandwidth and disk storage.  This infrastructure can contribute significantly to the true cost of running some applications and should be considered in those cases.  The model will be largely the same: collect the relevant metrics and then decide whether to charge according to resources reserved, consumed, or a combination of both.  How you collect those metrics will depend on the systems used for this infrastructure.</p>&#13;
&#13;
<p>At this point we have covered how Prometheus works and the general topics you should grasp before diving into the details of the deployed components.  Next is a tour of those components that are commonly used in a Prometheus metrics stack.<a data-primary="observability" data-secondary="metrics" data-startref="ix_obsrmtrcshch" data-tertiary="showback and chargeback" data-type="indexterm" id="idm45611982445304"/><a data-primary="showback and chargeback" data-startref="ix_shch" data-type="indexterm" id="idm45611982443784"/><a data-primary="metrics" data-secondary="showback and chargeback" data-startref="ix_mtrcshch" data-type="indexterm" id="idm45611982442840"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Metrics Components" data-type="sect2"><div class="sect2" id="metrics_components">&#13;
<h2>Metrics Components</h2>&#13;
&#13;
<p>In this section we will examine the components in a very commonly used approach to deploying and managing a metrics stack.<a data-primary="observability" data-secondary="metrics" data-tertiary="components of the system" data-type="indexterm" id="ix_obsrmtrccmp"/><a data-primary="metrics" data-secondary="components of the system" data-type="indexterm" id="ix_mtrccmp"/><a data-primary="Prometheus" data-secondary="components of metrics stack" data-type="indexterm" id="idm45611982436840"/>  We’ll also cover some of the management tools at your disposal and how all the pieces fit together. <a data-type="xref" href="#common_components_in_a_prometheus_metrics_stack">Figure 9-7</a> illustrates a common configuration of components in a Prometheus metrics stack.  It does not include the Prometheus Operator, which is a utility for deployment and management of this stack, rather than a part of the stack itself.  The diagram does include some autoscaling components to illustrate the role of Prometheus Adapter, even though autoscaling is not covered here.  See <a data-type="xref" href="ch13.html#autoscaling_chapter">Chapter 13</a> for details on that topic.</p>&#13;
&#13;
<figure><div class="figure" id="common_components_in_a_prometheus_metrics_stack">&#13;
<img alt="prku 0907" src="assets/prku_0907.png"/>&#13;
<h6><span class="label">Figure 9-7. </span>Common components in a Prometheus metrics stack.</h6>&#13;
</div></figure>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Prometheus Operator" data-type="sect3"><div class="sect3" id="idm45611982431448">&#13;
<h3>Prometheus Operator</h3>&#13;
&#13;
<p>The <a href="https://oreil.ly/k1lMx">Prometheus Operator</a> is a Kubernetes operator<a data-primary="Prometheus Operator" data-type="indexterm" id="idm45611982429224"/><a data-primary="metrics" data-secondary="components of the system" data-tertiary="Prometheus Operator" data-type="indexterm" id="idm45611982428520"/><a data-primary="operators (Kubernetes)" data-secondary="Prometheus Operator" data-type="indexterm" id="idm45611982427240"/> that helps deploy and manage the various components of a Kubernetes metrics system for the platform itself as well as the tenant workloads.  For more information about Kubernetes operators in general, see <a data-type="xref" href="ch11.html#operator_pattern">“The Operator Pattern”</a>. The Prometheus Operator uses several custom resources that represent Prometheus servers: Alertmanager deployments, scrape configurations that inform Prometheus of the targets to scrape metrics from, and rules for recording metrics and alerting on them.  This greatly reduces the toil in deploying and configuring Prometheus servers in your platform.</p>&#13;
&#13;
<p>These custom resources are very useful to platform engineers but can also provide a very important interface for your platform tenants.  If they require a dedicated Prometheus server, they can achieve that by submitting a Prometheus resource to their Namespace.  If they need to add alerting rules to an existing Prometheus server, they can do so with a PrometheusRule resource.</p>&#13;
&#13;
<p>The related <a href="https://oreil.ly/DITxj">kube-prometheus</a> project is a great place to start with using the Prometheus Operator.<a data-primary="kube-prometheus project" data-type="indexterm" id="idm45611982422856"/>  It provides a collection of manifests for a complete metrics stack.  It includes Grafana dashboard configurations for useful visualization out of the box, which is very handy.  But treat it as a place to start and understand the system so you can mold it to fit your requirements so that, once in production, you have confidence that you have comprehensive metrics and alerting for your &#13;
<span class="keep-together">systems</span>.</p>&#13;
&#13;
<p>The rest of this section covers the components you will get with a kube-prometheus deployment so you can clearly understand and customize these components for your needs.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Prometheus servers" data-type="sect3"><div class="sect3" id="idm45611982420120">&#13;
<h3>Prometheus servers</h3>&#13;
&#13;
<p>With the Prometheus Operator in your clusters, you can create Prometheus custom resources <a data-primary="Prometheus" data-secondary="components of metrics stack" data-tertiary="Prometheus servers" data-type="indexterm" id="idm45611982418344"/><a data-primary="metrics" data-secondary="components of the system" data-tertiary="Prometheus servers" data-type="indexterm" id="idm45611982417128"/>that will prompt the operator to create a new StatefulSet for a Prometheus server. <a data-type="xref" href="#ex_9-4">Example 9-4</a> is an example manifest for a Prometheus resource.</p>&#13;
<div data-type="example" id="ex_9-4">&#13;
<h5><span class="label">Example 9-4. </span>Sample Prometheus manifest</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">monitoring.coreos.com/v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Prometheus</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform</code><code>&#13;
</code><code>  </code><code class="nt">namespace</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform-monitoring</code><code>&#13;
</code><code>  </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">monitor</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform</code><code>&#13;
</code><code>    </code><code class="nt">owner</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform-engineering</code><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">alerting</code><code class="p">:</code><code>  </code><a class="co" href="#callout_observability_CO2-1" id="co_observability_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>    </code><code class="nt">alertmanagers</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">alertmanager-main</code><code>&#13;
</code><code>      </code><code class="nt">namespace</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform-monitoring</code><code>&#13;
</code><code>      </code><code class="nt">port</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web</code><code>&#13;
</code><code>  </code><code class="nt">image</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">quay.io/prometheus/prometheus:v2.20.0</code><code>  </code><a class="co" href="#callout_observability_CO2-2" id="co_observability_CO2-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>  </code><code class="nt">nodeSelector</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">kubernetes.io/os</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">linux</code><code>&#13;
</code><code>  </code><code class="nt">replicas</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">2</code><code>&#13;
</code><code>  </code><code class="nt">resources</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">requests</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">memory</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">400Mi</code><code>&#13;
</code><code>  </code><code class="nt">ruleSelector</code><code class="p">:</code><code>  </code><a class="co" href="#callout_observability_CO2-3" id="co_observability_CO2-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>    </code><code class="nt">matchLabels</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">monitor</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform</code><code>&#13;
</code><code>      </code><code class="nt">role</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">alert-rules</code><code>&#13;
</code><code>  </code><code class="nt">securityContext</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">fsGroup</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">2000</code><code>&#13;
</code><code>    </code><code class="nt">runAsNonRoot</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">true</code><code>&#13;
</code><code>    </code><code class="nt">runAsUser</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">1000</code><code>&#13;
</code><code>  </code><code class="nt">serviceAccountName</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform-prometheus</code><code>&#13;
</code><code>  </code><code class="nt">version</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">v2.20.0</code><code>&#13;
</code><code>  </code><code class="nt">serviceMonitorSelector</code><code class="p">:</code><code>  </code><a class="co" href="#callout_observability_CO2-4" id="co_observability_CO2-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>    </code><code class="nt">matchLabels</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">monitor</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO2-1" id="callout_observability_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Informs the configuration of Prometheus for where to send alerts.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO2-2" id="callout_observability_CO2-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The container image to use for Prometheus.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO2-3" id="callout_observability_CO2-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Informs the Prometheus Operator which PrometheusRules apply to this Prometheus server.  Any PrometheusRule created with the labels shown here will be applied to this Prometheus server.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO2-4" id="callout_observability_CO2-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>This does the same for ServiceMonitors as the <code>ruleSelector</code> does for PrometheusRules.  Any ServiceMonitor resources that have this label will be used to inform the scrape config for this Prometheus server.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>The Prometheus custom resource allows platform operators to readily deploy Prometheus servers to collect metrics.  As mentioned in <a data-type="xref" href="#organization_and_federation">“Organization and Federation”</a>, it may be useful to divide metrics collection and processing load among multiple deployments of Prometheus within any given cluster.  This model is enabled by the ability to spin up Prometheus servers using a custom Kubernetes resource.</p>&#13;
&#13;
<p>In some use cases, the ability to spin up Prometheus servers with the Prometheus Operator is also helpful to expose to platform tenants.  A team’s applications may emit a large volume of metrics that will overwhelm existing Prometheus servers.  And you may want to include a team’s metrics collection and processing in its resource budget, so having a dedicated Prometheus server in their Namespace may be a useful model.  Not every team will have an appetite for this approach where they deploy and manage their own Prometheus resources.  Many may require further abstraction of the details, but it is an option to consider.  If using this model, don’t discount the added complexity this will introduce for dashboards and alerting for the metrics gathered, as well as for federation and long-term storage.</p>&#13;
&#13;
<p>Deploying Prometheus servers is one thing, but ongoing management of configuration for them is another.  For this, the Prometheus Operator has other custom resources, the most common being the ServiceMonitor.<a data-primary="ServiceMonitor" data-type="indexterm" id="idm45611982228328"/>  When you create a ServiceMonitor resource, the Prometheus Operator responds by updating the scrape configuration of the relevant Prometheus server. <a data-type="xref" href="#ex_9-5">Example 9-5</a> shows a ServiceMonitor that will create a scrape configuration for Prometheus to collect metrics from the Kubernetes API server.</p>&#13;
<div data-type="example" id="ex_9-5">&#13;
<h5><span class="label">Example 9-5. </span>Example manifest for a ServiceMonitor resource</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">monitoring.coreos.com/v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">ServiceMonitor</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">k8s-app</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">apiserver</code><code>&#13;
</code><code>    </code><code class="nt">monitor</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform</code><code> </code><a class="co" href="#callout_observability_CO3-1" id="co_observability_CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">kube-apiserver</code><code>&#13;
</code><code>  </code><code class="nt">namespace</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform-monitoring</code><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">endpoints</code><code class="p">:</code><code>  </code><a class="co" href="#callout_observability_CO3-2" id="co_observability_CO3-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">bearerTokenFile</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">/var/run/secrets/kubernetes.io/serviceaccount/token</code><code>&#13;
</code><code>    </code><code class="nt">interval</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">30s</code><code>&#13;
</code><code>    </code><code class="nt">port</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">https</code><code>&#13;
</code><code>    </code><code class="nt">scheme</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">https</code><code>&#13;
</code><code>    </code><code class="nt">tlsConfig</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">caFile</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</code><code>&#13;
</code><code>      </code><code class="nt">serverName</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">kubernetes</code><code>&#13;
</code><code>  </code><code class="nt">jobLabel</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">component</code><code>  </code><a class="co" href="#callout_observability_CO3-3" id="co_observability_CO3-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>  </code><code class="nt">namespaceSelector</code><code class="p">:</code><code>  </code><a class="co" href="#callout_observability_CO3-4" id="co_observability_CO3-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>    </code><code class="nt">matchNames</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="p-Indicator">-</code><code> </code><code class="l-Scalar-Plain">default</code><code>&#13;
</code><code>  </code><code class="nt">selector</code><code class="p">:</code><code>  </code><a class="co" href="#callout_observability_CO3-5" id="co_observability_CO3-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
</code><code>    </code><code class="nt">matchLabels</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">component</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">apiserver</code><code>&#13;
</code><code>      </code><code class="nt">provider</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">kubernetes</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO3-1" id="callout_observability_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This is the label that is referred to in <a data-type="xref" href="#example_9_1">Example 9-1</a> of a <code>Prometheus</code> manifest by the <code>serviceMonitorSelector</code>.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO3-2" id="callout_observability_CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The <code>endpoints</code> provide configuration about the port to use and how to connect to the instances that Prometheus will scrape metrics from.  This example instructs Prometheus to connect using HTTPS and provides a Certificate Authority and server name to verify the connection endpoint.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO3-3" id="callout_observability_CO3-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>In Prometheus terms, a “job” is a collection of instances of a service.  For example, an individual apiserver is an “instance.”  All the apiservers in the cluster collectively comprise a “job.”  This field indicates which label contains the name that should be used for the job in Prometheus.  In this case the job will be <code>apiserver</code>.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO3-4" id="callout_observability_CO3-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>The <code>namespaceSelector</code> instructs Prometheus in which Namespaces to look for Services to scrape metrics for this target.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO3-5" id="callout_observability_CO3-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>The <code>selector</code> enables service discovery by way of labels on a Kubernetes Service.  In other words, any Service (in the default Namespace) that contains the specified labels will be used to find the targets to scrape metrics from.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Scrape configurations in a Prometheus server may also be managed with PodMonitor resources for monitoring groups of Pods (as opposed to Services with the ServiceMonitor), as well as Probe resources for monitoring Ingresses or static targets.</p>&#13;
&#13;
<p>The PrometheusRule resource <a data-primary="PrometheusRule resource" data-type="indexterm" id="idm45611982051544"/>instructs the operator to generate a rule file for Prometheus that contains rules for recording metrics and alerting upon metrics. <a data-type="xref" href="#ex_9-6">Example 9-6</a> shows an example of a PrometheusRule manifest that contains a recording rule and an alerting rule.  These rules will be put in a ConfigMap and mounted into the Prometheus server’s Pod/s.</p>&#13;
<div data-type="example" id="ex_9-6">&#13;
<h5><span class="label">Example 9-6. </span>Example manifest for a PrometheusRule resource</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">monitoring.coreos.com/v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">PrometheusRule</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">monitor</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform</code><code>&#13;
</code><code>    </code><code class="nt">role</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">alert-rules</code><code> </code><a class="co" href="#callout_observability_CO4-1" id="co_observability_CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">sample-rules</code><code>&#13;
</code><code>  </code><code class="nt">namespace</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform-monitoring</code><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">groups</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">kube-apiserver.rules</code><code>&#13;
</code><code>    </code><code class="nt">rules</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="p-Indicator">-</code><code> </code><code class="nt">expr</code><code class="p">:</code><code> </code><code class="p-Indicator">|</code><code>  </code><a class="co" href="#callout_observability_CO4-2" id="co_observability_CO4-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>        </code><code class="no">sum by (code,resource) (rate(</code><code>&#13;
</code><code>            </code><code class="no">apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]</code><code>&#13;
</code><code>        </code><code class="no">))</code><code>&#13;
</code><code>      </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>        </code><code class="nt">verb</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">read</code><code>&#13;
</code><code>      </code><code class="nt">record</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">code_resource:apiserver_request_total:rate5m</code><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">kubernetes-apps</code><code>&#13;
</code><code>    </code><code class="nt">rules</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="p-Indicator">-</code><code> </code><code class="nt">alert</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">KubePodNotReady</code><code>  </code><a class="co" href="#callout_observability_CO4-3" id="co_observability_CO4-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>      </code><code class="nt">annotations</code><code class="p">:</code><code>&#13;
</code><code>        </code><code class="nt">description</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Pod</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">{{</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">$labels.namespace</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">}}/{{</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">$labels.pod</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">}}</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">has</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">been</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">in</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">a</code><code>&#13;
</code><code>          </code><code class="l-Scalar-Plain">non-ready</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">state</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">for</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">longer</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">than</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">15</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">minutes.</code><code>&#13;
</code><code>        </code><code class="nt">summary</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Pod</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">has</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">been</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">in</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">a</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">non-ready</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">state</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">for</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">more</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">than</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">15</code><code class="l-Scalar-Plain"> </code><code class="l-Scalar-Plain">minutes.</code><code>&#13;
</code><code>      </code><code class="nt">expr</code><code class="p">:</code><code> </code><code class="p-Indicator">|</code><code>&#13;
</code><code>        </code><code class="no">sum by (namespace, pod) (</code><code>&#13;
</code><code>          </code><code class="no">max by(namespace, pod) (</code><code>&#13;
</code><code>            </code><code class="no">kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown"}</code><code>&#13;
</code><code>          </code><code class="no">) * on(namespace, pod) group_left(owner_kind) topk by(namespace, pod) (</code><code>&#13;
</code><code>            </code><code class="no">1, max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!="Job"})</code><code>&#13;
</code><code>          </code><code class="no">)</code><code>&#13;
</code><code>        </code><code class="no">) &gt; 0</code><code>&#13;
</code><code>      </code><code class="nt">for</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">15m</code><code>&#13;
</code><code>      </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>        </code><code class="nt">severity</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">warning</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO4-1" id="callout_observability_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This is the label that is referred to in <a data-type="xref" href="#example_9_1">Example 9-1</a> of a <code>Prometheus</code> manifest by the <code>ruleSelector</code>.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO4-2" id="callout_observability_CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>This is an example of a recording rule for the total LIST and GET requests to all Kubernetes API server instances over a 5-minute period.  It uses an expression on the <code>apiserver_request_total</code> metric exposed by the API server and stores a new metric called <code>code_resource:apiserver_request_total:rate5m</code>.</p></dd>&#13;
<dt><a class="co" href="#co_observability_CO4-3" id="callout_observability_CO4-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Here is an alerting rule that will prompt Prometheus to send a warning alert if any Pod gets stuck in a not ready state for more than 15 minutes.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Using the Prometheus Operator and these custom resources to manage Prometheus servers and their configurations has proven to be a very useful pattern and has become very prevalent in the field.  If you are using Prometheus as your primary metrics tool, we highly recommend it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Alertmanager" data-type="sect3"><div class="sect3" id="idm45611982419528">&#13;
<h3>Alertmanager</h3>&#13;
&#13;
<p>The next major component is Alertmanager.<a data-primary="Alertmanager" data-type="indexterm" id="idm45611981879480"/><a data-primary="metrics" data-secondary="components of the system" data-tertiary="Alertmanager" data-type="indexterm" id="idm45611981878776"/><a data-primary="Prometheus" data-secondary="components of metrics stack" data-tertiary="Alertmanager" data-type="indexterm" id="idm45611981877544"/>  This is a separate, distinct workload that processes alerts and routes them to receivers that constitute the communication medium to the on-call engineers.  Prometheus has alerting rules that prompt Prometheus to fire off alerts in response to measurable conditions.  Those alerts get sent to Alertmanager, where they are grouped and deduplicated so that humans don’t receive a flood of alerts when outages occur that affect multiple replicas or components.  Then notifications are sent via the configured receivers.  Receivers are the supported notification systems, such as email, Slack, or PagerDuty.  If you want to implement an unsupported or custom notification system, Alertmanager has a webhook receiver that allows you to provide a URL to which Alertmanager will send a POST request with a JSON payload.</p>&#13;
&#13;
<p>When using the Prometheus Operator, a new Alertmanager can be deployed with a manifest, as shown in <a data-type="xref" href="#ex_9-7">Example 9-7</a>.</p>&#13;
<div data-type="example" id="ex_9-7">&#13;
<h5><span class="label">Example 9-7. </span>Example manifest for an Alertmanager resource</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">monitoring.coreos.com/v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Alertmanager</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">alertmanager</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">main</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">main</code><code>&#13;
</code><code>  </code><code class="nt">namespace</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">platform-monitoring</code><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">image</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">quay.io/prometheus/alertmanager:v0.21.0</code><code>&#13;
</code><code>  </code><code class="nt">nodeSelector</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">kubernetes.io/os</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">linux</code><code>&#13;
</code><code>  </code><code class="nt">replicas</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">2</code><code>  </code><a class="co" href="#callout_observability_CO5-1" id="co_observability_CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>  </code><code class="nt">securityContext</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">fsGroup</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">2000</code><code>&#13;
</code><code>    </code><code class="nt">runAsNonRoot</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">true</code><code>&#13;
</code><code>    </code><code class="nt">runAsUser</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">1000</code><code>&#13;
</code><code>  </code><code class="nt">serviceAccountName</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">alertmanager-main</code><code>&#13;
</code><code>  </code><code class="nt">version</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">v0.21.0</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_observability_CO5-1" id="callout_observability_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Multiple replicas may be requested to deploy Alertmanager in a highly available configuration.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>While this custom resource gives you very convenient methods to deploy Alertmanager instances, it is very rarely necessary to deploy multiple Alertmanagers in a cluster, especially since it can be deployed in a highly available configuration.  You could consider a centralized Alertmanager for multiple clusters, but having one per cluster is wise since it reduces external dependencies for any given cluster.  Leveraging a common Alertmanager for a cluster provides the opportunity for tenants to leverage a single PrometheusRule resource to configure new alerting rules for their app.  In this model, each Prometheus server is configured to send alerts to the cluster’s &#13;
<span class="keep-together">Alertmanager</span>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Grafana" data-type="sect3"><div class="sect3" id="idm45611981754760">&#13;
<h3>Grafana</h3>&#13;
&#13;
<p>For platform operators to be able to reason about what is happening in a complex <a data-primary="Grafana" data-type="indexterm" id="idm45611981753160"/><a data-primary="Prometheus" data-secondary="components of metrics stack" data-tertiary="Grafana" data-type="indexterm" id="idm45611981752456"/><a data-primary="metrics" data-secondary="components of the system" data-tertiary="Grafana" data-type="indexterm" id="idm45611981751272"/>Kubernetes-based platform, it is crucial to build charts and dashboards from the data stored in Prometheus.  <a href="https://grafana.com">Grafana</a> is an open source visualization layer that has become the default solution for viewing Prometheus metrics.  The kube-prometheus project provides a variety of dashboards to use as a basis and starting point, not to mention many others available in the community.  And, of course, you have the freedom to build your own charts to display the time series data from any system you manage as a part of your platform.</p>&#13;
&#13;
<p>Visualizing metrics is also critical for application teams.  This is relevant to how you deploy your Prometheus servers.<a data-primary="federation" data-secondary="of Prometheus instances" data-type="indexterm" id="idm45611981848664"/>  If you are leveraging multiple Prometheus instances in your cluster, how will you expose the metrics gathered to the tenants of the platform?  On one hand, adding a Grafana dashboard to each Prometheus server may be a useful pattern.  This could provide a convenient separation of concerns.  However, on the other hand, if users find they have to routinely log in to multiple distinct dashboards, that may be cumbersome.  In this case you have two options:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Employ federation to collect metrics from different servers into a single server and then add a dashboard to that for a single place to access metrics for a set of systems.  This is the approach used with projects such as Thanos.</p>&#13;
</li>&#13;
<li>&#13;
<p>Add multiple data sources to a single Grafana dashboard.  In this case a single dashboard exposes metrics from several Prometheus servers.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The choice boils down to whether you prefer the complexity to be in federating Prometheus instances or in managing more complex Grafana configurations.  There is the additional resource consumption to consider with the federation server option, but if that is palatable, it is mostly a matter of preference.</p>&#13;
&#13;
<p>If you are using a single Prometheus server for a cluster and your platform operators and tenants are going to the same place to get metrics, you will need to consider permissions around viewing and editing dashboards.  You will likely need to configure the organizations, teams, and users appropriately for your use case.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Node exporter" data-type="sect3"><div class="sect3" id="idm45611981842920">&#13;
<h3>Node exporter</h3>&#13;
&#13;
<p><a href="https://github.com/prometheus/node_exporter">Node exporter</a> is the node agent that usually runs as a Kubernetes DaemonSet and collects machine and operating system metrics.  <a data-primary="Prometheus" data-secondary="components of metrics stack" data-tertiary="Node exporter" data-type="indexterm" id="idm45611981841048"/><a data-primary="Node exporter" data-type="indexterm" id="idm45611981839784"/><a data-primary="metrics" data-secondary="components of the system" data-tertiary="Node exporter" data-type="indexterm" id="idm45611981839112"/>It gives you the host-level CPU, memory, disk I/O, disk space, network stats, and file descriptor information, to name just a few of the metrics it collects by default.  As mentioned earlier, this is one of the most common examples of an exporter.  Linux systems don’t export Prometheus metrics natively.  The node exporter knows how to collect those metrics from the kernel and then exposes them for scraping by Prometheus.  It is useful any time you want to monitor the system and hardware of Unix-like machines with Prometheus.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="kube-state-metrics" data-type="sect3"><div class="sect3" id="idm45611981836952">&#13;
<h3>kube-state-metrics</h3>&#13;
&#13;
<p><a href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics</a> provides metrics related to a range of Kubernetes resources.  <a data-primary="kube-state-metrics" data-type="indexterm" id="idm45611981835128"/><a data-primary="Prometheus" data-secondary="components of metrics stack" data-tertiary="kube-state-metrics" data-type="indexterm" id="idm45611981834424"/><a data-primary="metrics" data-secondary="components of the system" data-tertiary="kube-state-metrics" data-type="indexterm" id="idm45611981732888"/>It is essentially an exporter for information about resources collected from the Kubernetes API.  For example, kube-state-metrics exposes Pod start times, status, labels, priority class, resource requests, and limits; all the information that you would normally use <code>kubectl get</code> or <code>kubectl describe</code> to collect. These metrics can be useful to detect critical cluster conditions, such as Pods stuck in crash loops or Namespaces nearing their resource quotas.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Prometheus adapter" data-type="sect3"><div class="sect3" id="idm45611981729976">&#13;
<h3>Prometheus adapter</h3>&#13;
&#13;
<p><a href="https://github.com/DirectXMan12/k8s-prometheus-adapter">Prometheus adapter</a> is included here because it is a part of the kube-prometheus stack.<a data-primary="Prometheus" data-secondary="components of metrics stack" data-tertiary="Prometheus adapter" data-type="indexterm" id="idm45611981728120"/><a data-primary="metrics" data-secondary="components of the system" data-tertiary="Prometheus adapter" data-type="indexterm" id="idm45611981726856"/>  However, it is not an exporter, nor is it involved in the core functionality of Prometheus.  Instead, Prometheus adapter is a <em>client</em> of Prometheus.  It retrieves metrics from the Prometheus API and makes them available through the Kubernetes metrics APIs.  This enables autoscaling functionality for workloads. Refer to <a data-type="xref" href="ch13.html#autoscaling_chapter">Chapter 13</a> for more information on autoscaling.</p>&#13;
&#13;
<p>As you can see, there are many components to a production-grade metrics and alerting system.  We’ve looked at how to accomplish this with Prometheus and the patterns demonstrated with the kube-prometheus stack including the Prometheus Operator to alleviate toil in managing these concerns.  Now that we’ve covered logging and metrics, let’s take a look at tracing.<a data-primary="observability" data-secondary="metrics" data-startref="ix_obsrmtrccmp" data-tertiary="components of the system" data-type="indexterm" id="idm45611981723160"/><a data-primary="metrics" data-secondary="components of the system" data-startref="ix_mtrccmp" data-type="indexterm" id="idm45611981721576"/><a data-primary="Prometheus" data-startref="ix_Prom" data-type="indexterm" id="idm45611981720344"/><a data-primary="observability" data-secondary="metrics" data-startref="ix_obsrmtrc" data-type="indexterm" id="idm45611981719400"/><a data-primary="metrics" data-startref="ix_mtrc" data-type="indexterm" id="idm45611981718184"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Distributed Tracing" data-type="sect1"><div class="sect1" id="idm45611982617320">&#13;
<h1>Distributed Tracing</h1>&#13;
&#13;
<p>Tracing in general refers to a specialized kind of event capturing that follows an execution path.<a data-primary="distributed tracing" data-type="indexterm" id="ix_dsttrc"/><a data-primary="observability" data-secondary="distributed tracing" data-type="indexterm" id="ix_obsrtrc"/>  While tracing can be applicable to a single piece of software, in this section we’re dealing with distributed tracing that spans multiple workloads and traces requests in microservice architectures.  Organizations that have embraced distributed systems benefit greatly from this technology.  In this section, we’ll discuss how to make distributed tracing available as a platform service for your application teams.<a data-primary="tracing" data-secondary="distributed" data-see="distributed tracing" data-type="indexterm" id="idm45611981712888"/></p>&#13;
&#13;
<p>An important distinction between distributed tracing compared to logging and metrics is that the tracing technology between the applications and platform must be compatible.  As long as an app logs to stdout and stderr, the platform services to aggregate logs don’t care how logs are written inside the app.  And common metrics like CPU and memory consumption can be gathered from workloads without specialized instrumentation.  However, if an application is instrumented with a client library that is incompatible with the tracing system offered by the platform, tracing will not work at all.  For this reason, close collaboration between platform and application development teams is critical in this area.</p>&#13;
&#13;
<p>In covering the topic of distributed tracing, we will first look at the OpenTracing and OpenTelemetry specifications along with some of the terminology that is used when discussing tracing.  We’ll then cover the components that are common with the popular projects used for tracing.  After that, we’ll touch on the application instrumentation necessary to enable tracing as well as the implications of using a service mesh.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="OpenTracing and OpenTelemetry" data-type="sect2"><div class="sect2" id="idm45611981709576">&#13;
<h2>OpenTracing and OpenTelemetry</h2>&#13;
&#13;
<p><a href="https://opentracing.io">OpenTracing</a> is an open source specification for distributed tracing that helps the ecosystem converge on standards for implementations.<a data-primary="observability" data-secondary="distributed tracing" data-tertiary="OpenTracing and OpenTelemetry" data-type="indexterm" id="idm45611981646904"/><a data-primary="OpenTracing" data-type="indexterm" id="idm45611981645816"/><a data-primary="OpenTelemetry" data-type="indexterm" id="idm45611981645208"/><a data-primary="distributed tracing" data-secondary="OpenTracing and OpenTelemetry" data-type="indexterm" id="idm45611981644600"/>  The spec revolves around three concepts that are important in understanding tracing:</p>&#13;
<dl>&#13;
<dt>Trace</dt>&#13;
<dd>&#13;
<p>When an end user of a distributed application makes a request, that request traverses distinct services that process the request and participate in satisfying the client request.  The trace represents that entire transaction and is the entity that we are interested in analyzing.  A trace consists of multiple spans.</p>&#13;
</dd>&#13;
<dt>Span</dt>&#13;
<dd>&#13;
<p>Each distinct service that processes a request represents a span.  The operations that occur within the workload boundaries constitute a single span that are part of a trace.</p>&#13;
</dd>&#13;
<dt>Tag</dt>&#13;
<dd>&#13;
<p>Tags are metadata that are attached to spans to contextualize them within a trace and provide searchable indexes.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>When traces are visualized, they will generally include each individual trace and readily indicate which components in a system are impacting performance the most.<a data-primary="performance" data-secondary="tracing impacts of system components" data-type="indexterm" id="idm45611981638472"/>  They will also help track down where errors are occurring and how they are affecting other components of an application.</p>&#13;
&#13;
<p>Recently, the OpenTracing project merged with OpenCensus to form <a href="https://opentelemetry.io">OpenTelemetry</a>.  At the time of this writing, OpenTelemetry support is still experimental in Jaeger, which is a fair barometer of adoption, but it is reasonable to expect OpenTelemetry to become the de facto standard.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Tracing Components" data-type="sect2"><div class="sect2" id="idm45611981635992">&#13;
<h2>Tracing Components</h2>&#13;
&#13;
<p>To offer distributed tracing as a platform service, there needs to be a few platform components in place.<a data-primary="observability" data-secondary="distributed tracing" data-tertiary="tracing components" data-type="indexterm" id="idm45611981634616"/><a data-primary="distributed tracing" data-secondary="tracing components" data-type="indexterm" id="idm45611981633528"/>  The patterns we’ll discuss here are applicable to open source projects such as <a href="https://zipkin.io">Zipkin</a> and <a href="https://www.jaegertracing.io">Jaeger</a>, but the same models will often apply for other projects and commercially supported products that implement the OpenTracing standards.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Agent" data-type="sect3"><div class="sect3" id="idm45611981631032">&#13;
<h3>Agent</h3>&#13;
&#13;
<p>Each component in a distributed application will output a span for each request processed.  The agent acts as a server to which the application can send the span information.  In a Kubernetes-based platform it will usually be a node agent that runs on each machine in the cluster and receives all spans for workloads on that node.  The agent will forward batched spans to a central collector.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Collector" data-type="sect3"><div class="sect3" id="idm45611981629224">&#13;
<h3>Collector</h3>&#13;
&#13;
<p>The collector processes the spans and stores them in the backend database.  It is responsible for validating, indexing, and performing any transformations before persisting the spans to storage.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Storage" data-type="sect3"><div class="sect3" id="idm45611981627624">&#13;
<h3>Storage</h3>&#13;
&#13;
<p>The supported <a data-primary="storage" data-secondary="databases for tracing" data-type="indexterm" id="idm45611981626488"/>databases vary from project to project, but the usual suspects are <a href="https://cassandra.apache.org">Cassandra</a> and <a href="https://www.elastic.co/elasticsearch">Elasticsearch</a>.  Even when sampling, distributed tracing systems collect very large amounts of data.  The databases used need to be able to process and quickly search these large volumes of data to produce useful analysis.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="API" data-type="sect3"><div class="sect3" id="idm45611981623784">&#13;
<h3>API</h3>&#13;
&#13;
<p>As you might expect, the next component is an API that allows clients to access the stored data.  It exposes the traces and their spans to other workloads or visualization layers.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="User interface" data-type="sect3"><div class="sect3" id="idm45611981622200">&#13;
<h3>User interface</h3>&#13;
&#13;
<p>This is where the rubber hits the road for your platform tenants.<a data-primary="user interface for tracing service" data-type="indexterm" id="idm45611981621064"/>  This visualization layer queries the API and reveals the data to app developers.  It is where engineers can view the data collected in useful charts to analyze their systems and distributed &#13;
<span class="keep-together">applications</span>.</p>&#13;
&#13;
<p><a data-type="xref" href="#components_of_a_tracing_platform_service">Figure 9-8</a> illustrates these tracing components, their relationships to one another, and the common deployment methods.</p>&#13;
&#13;
<figure><div class="figure" id="components_of_a_tracing_platform_service">&#13;
<img alt="prku 0908" src="assets/prku_0908.png"/>&#13;
<h6><span class="label">Figure 9-8. </span>Components of a tracing platform service.</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Application Instrumentation" data-type="sect2"><div class="sect2" id="idm45611981616376">&#13;
<h2>Application Instrumentation</h2>&#13;
&#13;
<p>In order for these spans to get collected and correlated together into traces, the application has to be instrumented to deliver this information.<a data-primary="application instrumentation for tracing" data-type="indexterm" id="idm45611981614840"/>  For this reason, it is crucial to get buy-in from your application development teams.  The best tracing platform service in the world is useless if the applications are not delivering the raw data needed.  <a data-type="xref" href="ch14.html#application_considerations_chapter">Chapter 14</a> goes into this topic in more depth.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Service Meshes" data-type="sect2"><div class="sect2" id="idm45611981612888">&#13;
<h2>Service Meshes</h2>&#13;
&#13;
<p>If using a service mesh, you will likely want your mesh data included in your traces.<a data-primary="service meshes" data-secondary="tracing and" data-type="indexterm" id="idm45611981611752"/>  Service meshes implement proxies for requests going to and from your workloads, and getting timing trace spans on those proxies helps you understand how they affect performance.  Note that your application will still need to be instrumented, even if using a service mesh.  The request headers need to be propagated from one service request to the next through a trace.  Service meshes are covered in detail in <a data-type="xref" href="ch06.html#chapter6">Chapter 6</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45611981609352">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Observability is a core concern in platform engineering.<a data-primary="observability" data-secondary="distributed tracing" data-startref="ix_obsrtrc" data-type="indexterm" id="idm45611981608216"/><a data-primary="distributed tracing" data-startref="ix_dsttrc" data-type="indexterm" id="idm45611981607128"/>  It’s fair to say that no application platform could be considered production-ready without observability solved.  As a baseline, make sure you are able to reliably collect logs from your containerized workloads and forward them to your logging backend along with the audit logs from the Kubernetes API server.  Also consider metrics and alerting a minimum requirement.  Collect the metrics exposed by the Kubernetes control plane, surface them in a dashboard, and alert on them.  Work with your application development teams to instrument their applications to expose metrics where applicable and collect those, too.  Finally, if your teams have embraced microservice architectures, work with your app dev teams to instrument their apps for tracing and install the platform components to leverage that information as well.  With these systems in place you will have the visibility to troubleshoot and refine your operations to improve performance and stability.<a data-primary="observability" data-startref="ix_obsr" data-type="indexterm" id="idm45611981605176"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>