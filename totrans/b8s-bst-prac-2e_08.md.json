["```\n    CheckNodeConditionPred,\n    CheckNodeUnschedulablePred,\n    GeneralPred,\n    HostNamePred,\n    PodFitsHostPortsPred,\n    MatchNodeSelectorPred,\n    PodFitsResourcesPred,\n    NoDiskConflictPred,\n    PodToleratesNodeTaintsPred,\n    PodToleratesNodeNoExecuteTaintsPred,\n    CheckNodeLabelPresencePred,\n    CheckServiceAffinityPred,\n    MaxEBSVolumeCountPred,\n    MaxGCEPDVolumeCountPred,\n    MaxCSIVolumeCountPred,\n    MaxAzureDiskVolumeCountPred,\n    MaxCinderVolumeCountPred,\n    CheckVolumeBindingPred,\n    NoVolumeZoneConflictPred,\n    CheckNodeMemoryPressurePred,\n    CheckNodePIDPressurePred,\n    CheckNodeDiskPressurePred,\n    MatchInterPodAffinityPred\n```", "```\n    EqualPriority\n    MostRequestedPriority\n    RequestedToCapacityRatioPriority\n    SelectorSpreadPriority\n    ServiceSpreadingPriority\n    InterPodAffinityPriority\n    LeastRequestedPriority\n    BalancedResourceAllocation\n    NodePreferAvoidPodsPriority\n    NodeAffinityPriority\n    TaintTolerationPriority\n    ImageLocalityPriority\n    ResourceLimitsPriority\n```", "```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  selector:\n    matchLabels:\n      app: frontend\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - frontend\n            topologyKey: \"kubernetes.io/hostname\"\n      containers:\n      - name: nginx\n        image: nginx:alpine\n```", "```\nkubectl label node <node_name> disktype=ssd\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: redis\n  labels:\n    env: prod\nspec:\n  containers:\n  - name: frontend\n    image: nginx:alpine\n    imagePullPolicy: IfNotPresent\n  nodeSelector:\n    disktype: ssd\n```", "```\nWarning:  FailedScheduling  10s (x10 over 2m)  default-scheduler\n0/2 nodes are available: 2 node(s) had taints that the pod did not tolerate.\n```", "```\nkubectl top nodes\n```", "```\nNAME                       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%\naks-nodepool1-14849087-0   524m         27%    7500Mi          33%\naks-nodepool1-14849087-1   468m         24%    3505Mi          27%\naks-nodepool1-14849087-2   406m         21%    3051Mi          24%\naks-nodepool1-14849087-3   441m         22%    2812Mi          22%\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: memory-request\nspec:\n  containers:\n  - name: memory-request\n    image: polinux/stress\n    resources:\n      requests:\n        memory: \"8000Mi\"\n```", "```\nkubectl describe pods memory-request\n```", "```\nEvents:\n  Type     Reason        Age                From              Message\n  Warning  FailedSch...  27s (x2 over 27s)  default-sched...  0/3 nodes are\n                                                              available: 3\n                                                              Insufficient memory\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: cpu-demo\n  namespace: cpu-example\nspec:\n  containers:\n  - name: frontend\n    image: nginx:alpine\n    resources:\n      limits:\n        cpu: \"1\"\n      requests:\n        cpu: \"0.5\"\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: qos-demo\n  namespace: qos-example\nspec:\n  containers:\n  - name: qos-demo-ctr\n    image: nginx:alpine\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"700m\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"700m\"\n```", "```\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: frontend-pdb\nspec:\n  minAvailable: 5\n  selector:\n    matchLabels:\n      app: frontend\n```", "```\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: frontend-pdb\nspec:\n  maxUnavailable: 20%\n  selector:\n    matchLabels:\n      app: frontend\n```", "```\nkubectl create ns team-1\n```", "```\nkubectl get pods --namespace team-1\n```", "```\nkubectl config set-context my-context --namespace=team-1\n```", "```\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: mem-cpu-demo\n  namespace: team-1\nspec:\n  hard:\n    requests.cpu: \"1\"\n    requests.memory: 1Gi\n    limits.cpu: \"2\"\n    limits.memory: 2Gi\n    persistentvolumeclaims: \"5\"\n    requests.storage: \"10Gi\n```", "```\nkubectl apply quota.yaml -n team-1\n```", "```\nkubectl run nginx-quotatest --image=nginx --restart=Never --replicas=1 --port=80\n    --requests='cpu=500m,memory=4Gi' --limits='cpu=500m,memory=4Gi' -n team-1\n```", "```\nError from server (Forbidden): pods \"nginx-quotatest\" is forbidden:\n    exceeded quota: mem-cpu-demo\n```", "```\nkubectl create ns team-1\n```", "```\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: team-1-limit-range\nspec:\n  limits:\n  - default:\n      memory: 512Mi\n    defaultRequest:\n      memory: 256Mi\n    type: Container\n```", "```\nkubectl apply -f limitranger.yaml -n team-1\n```", "```\n kubectl run team-1-pod --image=nginx -n team-1\n```", "```\nkubectl describe pod team-1-pod -n team-1\n```", "```\nLimits:\n      memory:  512Mi\n    Requests:\n      memory:  256Mi\n```", "```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  selector:\n    matchlables:\n      app: frontend\n  template:\n    metadata:\n      name: frontend\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: frontend\n        resources:\n          requests:\n            cpu: 100m\n```", "```\nkubectl scale deployment frontend --replicas 5\n```", "```\n kubectl expose deployment frontend --port 80\n```", "```\nkubectl autoscale deployment frontend --cpu-percent=50 --min=1 --max=10\n```", "```\nkubectl run -i --tty load-generator --image=busybox /bin/sh\n```", "```\nHit enter for command prompt\nwhile true; do wget -q -O- http://frontend.default.svc.cluster.local; done\n```", "```\nkubectl get hpa\n```"]