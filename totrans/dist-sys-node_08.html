<html><head></head><body><section data-pdf-bookmark="Chapter 7. Container Orchestration" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch_kubernetes">&#13;
<h1><span class="label">Chapter 7. </span>Container Orchestration</h1>&#13;
&#13;
&#13;
<p>Throughout this book, you ran many different Docker containers on your development machine. Each time that you ran them, you did so using the same mechanism: manually running <code>docker</code> commands in your terminal. Of course, this is fine for doing local development, and perhaps it can be used to run a single service instance in production, but when it comes to running an entire fleet of services, this approach is going to get rough.</p>&#13;
&#13;
<p>This is where a <em>container orchestration</em> tool <a data-primary="container orchestration" data-type="indexterm" id="idm46291182498696"/>comes into play. Loosely put, a container orchestration tool manages the lifetimes of many ephemeral containers. Such a tool has many unique responsibilities and must take into consideration situations like the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Containers need to scale up and down as load increases and decreases.</p>&#13;
</li>&#13;
<li>&#13;
<p>New containers are occasionally added as additional services are created.</p>&#13;
</li>&#13;
<li>&#13;
<p>New versions of containers need to be deployed to replace old versions.</p>&#13;
</li>&#13;
<li>&#13;
<p>A single machine may not handle all the containers required by an organization.</p>&#13;
</li>&#13;
<li>&#13;
<p>Like-containers should be spread across multiple machines for redundancy.</p>&#13;
</li>&#13;
<li>&#13;
<p>Containers should be able to communicate with one another.</p>&#13;
</li>&#13;
<li>&#13;
<p>Incoming requests for like-containers should be load balanced.</p>&#13;
</li>&#13;
<li>&#13;
<p>If a container is deemed unhealthy, it should be replaced by a healthy one.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Container orchestration works great <a data-primary="container orchestration" data-secondary="stateless services" data-type="indexterm" id="idm46291182489752"/><a data-primary="stateless services" data-secondary="container orchestration and" data-type="indexterm" id="idm46291182488776"/>with stateless services, like a typical Node.js &#13;
<span class="keep-together">service</span> where instances can be destroyed or re-created without having many side effects. Stateful services, like databases, require a little more care to run in a container orchestration tool since there are concerns like persisting storage across deploys or resharding data as instances come and go. Many organizations choose to only run application code within a container orchestrator and to rely on a dedicated machine to run their databases.</p>&#13;
&#13;
<p>In this chapter, you’ll only deploy stateless application code to a container orchestration tool. There are a few different tools available, but it seems one of them has surpassed the others in popularity.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Introduction to Kubernetes" data-type="sect1"><div class="sect1" id="idm46291182446824">&#13;
<h1>Introduction to Kubernetes</h1>&#13;
&#13;
<p><em>Kubernetes</em> is an open source <a data-primary="Kubernetes" data-type="indexterm" id="kub"/><a data-primary="container orchestration" data-seealso="Kubernetes" data-type="indexterm" id="idm46291182444344"/>container orchestration tool created by Google. Each major cloud PaaS has a way of exposing or otherwise emulating Kubernetes for its customers. Even the Docker company appears to have embraced Kubernetes by packaging it into their Docker Desktop products.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Kubernetes Overview" data-type="sect2"><div class="sect2" id="idm46291182442968">&#13;
<h2>Kubernetes Overview</h2>&#13;
&#13;
<p>Kubernetes is a very powerful tool, one that requires many moving parts in order to function. <a data-type="xref" href="#fig_kubernetes_overview">Figure 7-1</a> is a high-level overview of some of the concepts that make up Kubernetes.</p>&#13;
&#13;
<figure><div class="figure" id="fig_kubernetes_overview">&#13;
<img alt="The Kubernetes Master controls individual Kubernetes Nodes. Nodes have the Docker Daemon and Kubelet Daemons installed. Each Node can have multiple Pods on it. Pods run one or multiple Containers and may contain Volumes." src="assets/dsnj_0701.png"/>&#13;
<h6><span class="label">Figure 7-1. </span>Overview of a Kubernetes cluster</h6>&#13;
</div></figure>&#13;
&#13;
<p>Each of the components in this diagram has a <a data-primary="Kubernetes" data-secondary="clusters" data-tertiary="hierarchy" data-type="indexterm" id="idm46291182437784"/>hierarchical relationship and can be spread across multiple machines. Here’s an explanation of the different components and how they relate to one another:</p>&#13;
<dl>&#13;
<dt>Container</dt>&#13;
<dd>&#13;
<p>As you might have guessed, a <a data-primary="Kubernetes" data-secondary="containers" data-type="indexterm" id="idm46291182434376"/>container in Kubernetes is equivalent to the containers you’ve been working with so far. They are an isolated environment that encapsulates and runs an application. Kubernetes works with a few different container formats such as Docker and rkt.</p>&#13;
</dd>&#13;
<dt>Volume</dt>&#13;
<dd>&#13;
<p>A volume in Kubernetes is <a data-primary="Kubernetes" data-secondary="volumes" data-type="indexterm" id="idm46291182431736"/>pretty much equivalent to a Docker volume. It provides a way to mount a filesystem in a semipermanent way outside of a container. Volumes won’t be covered in this chapter since a typical stateless Node.js service shouldn’t require a persistent volume. That said, they are certainly useful in a variety of situations.</p>&#13;
</dd>&#13;
<dt>Pod</dt>&#13;
<dd>&#13;
<p>A pod represents an application instance. Typically a <a data-primary="Kubernetes" data-secondary="pods" data-type="indexterm" id="idm46291182428952"/>pod will only contain a single container, though it is possible to have multiple containers in one pod. A pod can also contain any volumes required by the pod’s containers. Each pod has its own IP address, and if multiple containers exist in the same pod, they’ll each share an address. A pod is the smallest unit that the Kubernetes API allows you to interact with.</p>&#13;
</dd>&#13;
<dt>Node</dt>&#13;
<dd>&#13;
<p>A node is a worker machine—be it <a data-primary="Kubernetes" data-secondary="nodes" data-type="indexterm" id="idm46291182426136"/>physical or virtual—that is part of the overall Kubernetes cluster. Each node needs to have a container daemon (such as Docker), the <a data-primary="Kubelet" data-type="indexterm" id="idm46291182424888"/>Kubernetes daemon (called <em>Kubelet</em>), and a network proxy (<em>Kube Proxy</em>) running on the machine. Different nodes may have different memory and CPU available, just as different pods might have different memory and CPU requirements.</p>&#13;
</dd>&#13;
<dt>Master</dt>&#13;
<dd>&#13;
<p>The master represents a <a data-primary="Kubernetes" data-secondary="master" data-type="indexterm" id="idm46291182421560"/>set of services that are run on a master node. The master exposes an API, which is what outside clients communicate with, such as the <code>kubectl</code> command <a data-primary="kubectl command" data-type="indexterm" id="idm46291182419928"/><a data-primary="commands" data-secondary="kubectl" data-type="indexterm" id="idm46291182419192"/>you’ll use throughout this chapter. The master delegates commands to the Kubelet processes running on individual nodes.</p>&#13;
</dd>&#13;
<dt>Cluster</dt>&#13;
<dd>&#13;
<p>A cluster represents the overall <a data-primary="Kubernetes" data-secondary="clusters" data-type="indexterm" id="idm46291182416648"/><a data-primary="clusters, Kubernetes" data-type="indexterm" id="idm46291182415672"/>collection of the master and its various associated nodes. It’s technically possible to use a single cluster for different environments like staging and production by designating which pods belong to which environment. That said, it’s usually safer to maintain multiple clusters to prevent accidental cross-communication, especially if you ever plan on testing a cluster outside of <a data-primary="Kubernetes" data-startref="kub" data-type="indexterm" id="idm46291182414536"/>production.</p>&#13;
</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Kubernetes Concepts" data-type="sect2"><div class="sect2" id="idm46291182435512">&#13;
<h2>Kubernetes Concepts</h2>&#13;
&#13;
<p>When you interact with Kubernetes, <a data-primary="Kubernetes" data-secondary="clusters" data-tertiary="state" data-type="indexterm" id="idm46291182411992"/><a data-primary="clusters, Kubernetes" data-secondary="state" data-type="indexterm" id="idm46291182410744"/>you do so by declaring the desired state of the cluster. For example, you can tell it that you want 10 instances of the <em>recipe-api</em> service at version <em>0.0.3</em> to be running. You do not instruct the cluster how to achieve that state. For example, you don’t tell it to increase the current instance count of six by adding four entries. It’s ultimately up to Kubernetes to decide how to reach the desired state. It’s also up to Kubernetes to decide how long until that state is reached.</p>&#13;
&#13;
<p>There are many additional concepts—beyond that of architecture—that you must understand before you can fluently run your applications on Kubernetes. The Kubernetes API exposes various resources in the cluster as objects. For example, when you deploy (verb) an application, you’re creating a deployment (noun). Here is a high-level list of the most important resources that you’ll work with throughout the rest of the chapter:</p>&#13;
<dl>&#13;
<dt>Scheduling</dt>&#13;
<dd>&#13;
<p>Scheduling is the process <a data-primary="Kubernetes" data-secondary="scheduling" data-type="indexterm" id="idm46291182405272"/><a data-primary="scheduling, Kubernetes" data-type="indexterm" id="idm46291182404296"/>by which Kubernetes determines the best node to assign newly created pods to. The default scheduler used in Kubernetes is called <code>kube-scheduler</code>. Upon encountering a newly created pod, the scheduler examines available nodes. It considers the free CPU and memory of the node, as well as the CPU and memory requirements of the pod (if specified). A compatible node is then chosen to host the pod. If no nodes have capacity for the pod, then it can remain in a <em>scheduled</em> state where it waits for a node to become available.</p>&#13;
</dd>&#13;
<dt>Namespaces</dt>&#13;
<dd>&#13;
<p>A namespace is a Kubernetes <a data-primary="Kubernetes" data-secondary="namespaces" data-type="indexterm" id="idm46291182400520"/><a data-primary="namespaces" data-secondary="Kubernetes" data-type="indexterm" id="idm46291182399544"/>mechanism for logically dividing a cluster into smaller, semi-isolated collections. By default, there are <code>default</code>, <code>kube-system</code>, and <code>kube-public</code> namespaces created. Later, when you run a dashboard, an additional <code>kubernetes-dashboard</code> namespace is created. These can be used for environment namespaces like <code>staging</code> and <code>production</code>. In this chapter you’ll deploy applications to the <code>default</code> namespace.</p>&#13;
</dd>&#13;
<dt>Labels</dt>&#13;
<dd>&#13;
<p>Labels are key/value pairs that <a data-primary="Kubernetes" data-secondary="labels" data-type="indexterm" id="idm46291182393784"/><a data-primary="labels, Kubernetes" data-type="indexterm" id="idm46291182392808"/>are assigned to various resources, such as pods or nodes. They don’t need to be unique, and multiple labels can be assigned to an object. For example, a Node.js application could have the labels <code>platform:node</code> and <code>platform-version:v14</code>. A node might use labels like <code>machine:physical</code> or <code>kernel:3.16</code>. The <code>app</code> label is <a data-primary="recipe-api" data-secondary="app label" data-type="indexterm" id="idm46291182389656"/>how you’ll differentiate an instance of <em>web-api</em> from <em>recipe-api</em>.</p>&#13;
</dd>&#13;
<dt>Selectors</dt>&#13;
<dd>&#13;
<p>Selectors declare the <a data-primary="Kubernetes" data-secondary="selectors" data-type="indexterm" id="idm46291182386408"/><a data-primary="selectors, Kubernetes" data-type="indexterm" id="idm46291182385400"/>requirements of a pod. For example, a particular pod might have the requirement that it run on a physical machine instead of a virtual machine since it needs to perform some extremely time-sensitive work. In this case, the selector might be <code>machine:physical</code>.</p>&#13;
</dd>&#13;
<dt>Stateful sets</dt>&#13;
<dd>&#13;
<p>Kubernetes does work with <a data-primary="Kubernetes" data-secondary="stateful sets" data-type="indexterm" id="idm46291182382520"/><a data-primary="stateful sets, Kubernets" data-type="indexterm" id="idm46291182381544"/>stateful services, and stateful sets are intended to make this process convenient. They provide features often required by stateful services, such as consistent host names and persistent storage. The Node.js apps you’ll deploy in this chapter won’t use stateful sets.</p>&#13;
</dd>&#13;
<dt>Replica sets</dt>&#13;
<dd>&#13;
<p>A replica set <a data-primary="Kubernetes" data-secondary="replica sets" data-type="indexterm" id="idm46291182379112"/><a data-primary="replica sets, Kubernetes" data-type="indexterm" id="idm46291182378104"/>maintains a list of pods, creating new ones or deleting existing ones until the desired number of replicas has been met. It uses a selector to figure out which pods to manage.</p>&#13;
</dd>&#13;
<dt>Deployments</dt>&#13;
<dd>&#13;
<p>A deployment manages a <a data-primary="Kubernetes" data-secondary="deployments" data-type="indexterm" id="idm46291182375816"/><a data-primary="scheduling, Kubernetes" data-type="indexterm" id="idm46291182374808"/><a data-primary="deployments" data-secondary="Kubernetes" data-type="indexterm" id="idm46291182374136"/>replica set. It can deploy new versions of an application, scale the number of instances, or even roll back to a previous version of an &#13;
<span class="keep-together">application.</span></p>&#13;
</dd>&#13;
<dt>Controllers</dt>&#13;
<dd>&#13;
<p>Controllers tell Kubernetes how to change <a data-primary="Kubernetes" data-secondary="controllers" data-type="indexterm" id="idm46291182371000"/><a data-primary="controllers, Kubernetes" data-type="indexterm" id="idm46291182370024"/>from one state to another. Replica sets, deployments, stateful sets, and cron jobs are each examples of a controller.</p>&#13;
</dd>&#13;
<dt>Service</dt>&#13;
<dd>&#13;
<p>A service is a resource <a data-primary="Kubernetes" data-secondary="services" data-type="indexterm" id="idm46291182367816"/><a data-primary="services" data-secondary="Kubernetes" data-type="indexterm" id="idm46291182366840"/>that exposes a set of pods to the network. It’s a lot like a reverse proxy, but instead of targeting a hostname and port, a service uses a selector to target pods. A Kubernetes service isn’t the same concept as the “service” used throughout this book to refer to a running process on a network. In this chapter, those will be referred to as applications.</p>&#13;
</dd>&#13;
<dt>Ingress</dt>&#13;
<dd>&#13;
<p>An ingress resource manages <a data-primary="Kubernetes" data-secondary="ingress resources" data-type="indexterm" id="idm46291182364056"/><a data-primary="ingress, Kubernetes" data-type="indexterm" id="idm46291182363080"/>external network access to a service within a Kubernetes cluster.</p>&#13;
</dd>&#13;
<dt>Probe</dt>&#13;
<dd>&#13;
<p>A probe is a lot like <a data-primary="Kubernetes" data-secondary="probes" data-type="indexterm" id="idm46291182360920"/><a data-primary="probes, Kubernetes" data-type="indexterm" id="idm46291182359912"/>the HAProxy health check that you worked with before. It can be used to tell if a pod is healthy and if it’s ready to receive traffic after being started.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>As you can see, Kubernetes is an extremely powerful and malleable tool for deploying application containers. Kubernetes supports many primitives out of the box. There are often many ways to do the same thing in Kubernetes. For example, different environments can be simulated using either namespaces or labels. An application can be deployed using one or more replica sets. Many complex and opinionated patterns can be adopted for deploying to Kubernetes, yet only a subset of these features are required to get a distributed application running in production.</p>&#13;
&#13;
<p>This list contains the most important concepts for an application developer to worry about. That said, it doesn’t even include everything required to get Kubernetes running in a high-throughput production environment! For example, Kubernetes also depends on the Etcd service. Instead of configuring several complex services to get Kubernetes running locally, you’ll instead depend on the much simpler <em>Minikube</em>. Minikube sacrifices some features, like the ability to run multiple nodes, but simplifies other things, like not having to configure Etcd and combining the master node with a worker node.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Starting Kubernetes" data-type="sect2"><div class="sect2" id="idm46291182356776">&#13;
<h2>Starting Kubernetes</h2>&#13;
&#13;
<p>To continue on with this chapter, you’ll <a data-primary="Kubernetes" data-secondary="starting" data-type="indexterm" id="kub_start"/><a data-primary="Minikube" data-type="indexterm" id="idm46291182353960"/><a data-primary="Kubectl" data-type="indexterm" id="idm46291182353288"/><a data-primary="Kubernetes" data-secondary="Kubectl" data-type="indexterm" id="idm46291182352616"/>need to have Minikube and Kubectl installed on your development machine. Check out <a data-type="xref" href="app03.html#appendix_install_kubernetes">Appendix C</a> for details on how to install them. Run the following commands in your terminal once you’re done to confirm they’re installed:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>minikube version&#13;
<code class="nv">$ </code>kubectl version --client</pre>&#13;
&#13;
<p>Now that you have a version of Kubernetes running on your development machine, you’re ready to start interacting with it.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291182333624">&#13;
<h5>Alternatives to Kubernetes</h5>&#13;
<p>A combination of Apache Mesos and Apache Marathon <a data-primary="Apache Mesos" data-type="indexterm" id="idm46291182348328"/><a data-primary="Apache Marathon" data-type="indexterm" id="idm46291182347656"/>offers functionality similar to that provided by Kubernetes.</p>&#13;
&#13;
<p>Docker Swarm is a tool that <a data-primary="Docker" data-secondary="Swarm" data-type="indexterm" id="idm46291182346472"/>you may have heard of that offers similar functionality, though it has never been as powerful as Kubernetes. The Docker company seems to have given up on Docker Swarm and has embraced Kubernetes, bundling Kubernetes in Docker Desktop and selling Docker Swarm to another company.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Getting Started" data-type="sect1"><div class="sect1" id="idm46291182344264">&#13;
<h1>Getting Started</h1>&#13;
&#13;
<p>Now that you have Minikube <a data-primary="Minikube" data-secondary="running" data-type="indexterm" id="min_run"/><a data-primary="Kubernetes" data-secondary="Minikube" data-tertiary="running" data-type="indexterm" id="min_runkub"/>installed, you’re ready to run it. Execute the following command:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="c"># Linux:</code>&#13;
<code class="nv">$ </code>minikube start&#13;
<code class="c"># MacOS:</code>&#13;
<code class="nv">$ </code>minikube start --vm<code class="o">=</code><code class="nb">true</code></pre>&#13;
&#13;
<p>This command might take a minute to finish. In the background, it’s downloading necessary containers and starting the Minikube service. It actually runs a Docker container dedicated to Minikube within your already-running Docker daemon.<sup><a data-type="noteref" href="ch07.html#idm46291182288360" id="idm46291182288360-marker">1</a></sup> You can see this happening by running the <code><strong>docker ps</strong></code> command, though you might not get any results back if running Minikube on macOS.</p>&#13;
&#13;
<p>In my case, I get the output shown in <a data-type="xref" href="#table_minikube_docker_ps">Table 7-1</a>.</p>&#13;
<div style="page-break-after: always;"/>&#13;
<table id="table_minikube_docker_ps">&#13;
<caption><span class="label">Table 7-1. </span>Minikube running inside Docker</caption>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Container ID</p></td>&#13;
<td><p><code>245e83886d65</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Image</p></td>&#13;
<td><p><code>gcr.io/k8s-minikube/kicbase:v0.0.8</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Command</p></td>&#13;
<td><p><code>"/usr/local/bin/entr…"</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Ports</p></td>&#13;
<td><p><code>127.0.0.1:32776-&gt;22/tcp, 127.0.0.1:32775-&gt;2376/tcp, 127.0.0.1:32774-&gt;8443/tcp</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Names</p></td>&#13;
<td><p><code>minikube</code></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Next, it’s time to take a look at some of the architecture used by Kubernetes. Run the following command to get a list of the nodes that currently make up your Kubernetes cluster:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get pods</pre>&#13;
&#13;
<p>In my case, I get the message “no resources found in default namespace,” and you should get the same thing. This is because no pods are currently running in the <em>default</em> namespace of the cluster. Kubectl uses the <em>default</em> namespace by default. That said, there are several pods already running in the cluster. These are pods required by Minikube itself. To see them, run the following slightly modified command:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get pods --namespace<code class="o">=</code>kube-system</pre>&#13;
&#13;
<p>In my case, I get nine entries, including the following:</p>&#13;
&#13;
<pre data-type="programlisting">NAME                               READY   STATUS    RESTARTS   AGE&#13;
coredns-66bff467f8-8j5mb           1/1     Running   6          95s&#13;
etcd-minikube                      1/1     Running   4          103s&#13;
kube-scheduler-minikube            1/1     Running   5          103s</pre>&#13;
&#13;
<p>You should get similar results, though the names and age and restart count will most likely be different.</p>&#13;
&#13;
<p>Next, recall that another important feature of Kubernetes is the nodes, which represent the machines that ultimately run pods. Also recall that Minikube is a convenient way to run Kubernetes locally on a single node. Run the following command to get a list of nodes in your Kubernetes cluster:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get nodes</pre>&#13;
&#13;
<p>In my case, I get the following results:</p>&#13;
&#13;
<pre data-type="programlisting">NAME       STATUS   ROLES    AGE     VERSION&#13;
minikube   Ready    master   3m11s   v1.18.0</pre>&#13;
&#13;
<p>Here, a single node <a data-primary="Kubernetes" data-secondary="nodes" data-tertiary="minikube" data-type="indexterm" id="idm46291182268792"/>named <em>minikube</em> is present. Again, your results should be very similar.</p>&#13;
&#13;
<p>Minikube comes with its own <a data-primary="Minikube" data-secondary="Docker daemon" data-type="indexterm" id="idm46291182266616"/><a data-primary="Docker" data-secondary="Minikube" data-type="indexterm" id="idm46291182265640"/>Docker daemon. This can make it a little confusing when working with containers on your local machine. For example, when you previously ran <code>docker ps</code>, you saw that a single new Docker container was started for your Minikube installation. You’ve also got a bunch of images in your local Docker daemon left over from the other chapters. However, there are other docker containers running inside of the Docker daemon that comes with Minikube, and it has its own isolated collection of images.</p>&#13;
&#13;
<p>Minikube does come with a convenient tool to configure your <code>docker</code> CLI to switch to using the Minikube docker service. This tool works by exporting some environment variables that the <code>docker</code> CLI makes use of.</p>&#13;
&#13;
<p>If you’re curious to see <a data-primary="environment variables" data-secondary="Minikube" data-type="indexterm" id="idm46291182229048"/><a data-primary="Minikube" data-secondary="environment variables" data-type="indexterm" id="idm46291182228072"/>what these environment variables actually look like, run the command <code><strong>minikube -p minikube docker-env</strong></code>. In my case, I get the following &#13;
<span class="keep-together">output:</span></p>&#13;
&#13;
<pre data-type="programlisting">export DOCKER_TLS_VERIFY="1"&#13;
export DOCKER_HOST="tcp://172.17.0.3:2376"&#13;
export DOCKER_CERT_PATH="/home/tlhunter/.minikube/certs"&#13;
export MINIKUBE_ACTIVE_DOCKERD="minikube"</pre>&#13;
&#13;
<p>You should get slightly different values but with the same environment variable names. Now, to actually apply these changes to your current shell session, run the following command to execute the export statements:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code><code class="nb">eval</code> <code class="k">$(</code>minikube -p minikube docker-env<code class="k">)</code></pre>&#13;
&#13;
<p>Your <code>docker</code> CLI is now configured <a data-primary="Docker CLI, Minikube and" data-type="indexterm" id="idm46291182184056"/><a data-primary="Minikube" data-secondary="Docker CLI" data-type="indexterm" id="idm46291182183416"/>to use Minikube! Just keep in mind that any time you switch to a new terminal shell, you’ll revert back to using your system Docker daemon.</p>&#13;
&#13;
<p>To prove that your <code>docker</code> CLI is now communicating with a different daemon, run the commands <code><strong>docker ps</strong></code> and <code><strong>docker images</strong></code>. In the output, you should see a whole bunch of <em>k8s</em> containers and images listed. Also, note that you shouldn’t see any of the previous containers or images you’ve worked with in this book (if you temporarily switch to a new terminal window and run those two commands again, you’ll see your previous containers and images).</p>&#13;
&#13;
<p>Finally, even though you and I both love to work in the terminal, sometimes it takes a GUI to allow one to fully appreciate the complexity of a particular system. Minikube does come with such a graphical dashboard. It allows you to interact with the Kubernetes API using a browser. It also makes browsing the different types of resources a breeze and allows you to administer the cluster.</p>&#13;
&#13;
<p>Run the following command in a spare terminal window to launch the dashboard:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>minikube dashboard</pre>&#13;
&#13;
<p>This command might take a minute to run. In the background it creates a new Kubernetes namespace <a data-primary="Kubernetes" data-secondary="namespaces" data-tertiary="kubernetes-dashboard" data-type="indexterm" id="idm46291182169336"/>called <em>kubernetes-dashboard</em> and launches a few pods in it. Once the command is complete, it will both attempt to open a web browser to the dashboard and print out a URL to the dashboard. Copy the URL and visit it manually if your browser doesn’t automatically open. <a data-type="xref" href="#fig_kubernetes_dashboard_overview">Figure 7-2</a> is a screenshot of the overview dashboard screen.</p>&#13;
&#13;
<figure><div class="figure" id="fig_kubernetes_dashboard_overview">&#13;
<img alt="The Kubernetes Dashboard Overview, listing Services and Secrets" src="assets/dsnj_0702.png"/>&#13;
<h6><span class="label">Figure 7-2. </span>Kubernetes dashboard overview</h6>&#13;
</div></figure>&#13;
&#13;
<p>Now is a good time to click around the interface and get familiar with the different screens. The sidebar is split into these different sections:</p>&#13;
<dl>&#13;
<dt>Cluster</dt>&#13;
<dd>&#13;
<p>The cluster section <a data-primary="Kubernetes" data-secondary="cluster section" data-type="indexterm" id="idm46291182175784"/><a data-primary="clusters, Kubernetes" data-type="indexterm" id="idm46291182174776"/>lists attributes that affect the entire cluster globally, regardless of the selected namespace. This includes the list of nodes available in the cluster. Click the Nodes entry in the sidebar to see a list of nodes. In this case, you should just see the <em>minikube</em> node listed like when you ran the <code>kubectl get nodes</code> &#13;
<span class="keep-together">command.</span></p>&#13;
</dd>&#13;
<dt>Namespace</dt>&#13;
<dd>&#13;
<p>The namespace drop-down menu allows you <a data-primary="Kubernetes" data-secondary="namespace drop-down" data-type="indexterm" id="idm46291182170936"/><a data-primary="namespaces" data-secondary="Kubernetes" data-type="indexterm" id="idm46291182150600"/>to select which namespace the dashboard is viewing. Currently it is set to <em>default</em>. This is the namespace you’ll work with the most in this chapter. For now, select the <em>kube-system</em> entry. This will let you see some actual entries in the dashboard.</p>&#13;
</dd>&#13;
<dt>Overview</dt>&#13;
<dd>&#13;
<p>The overview is the screen <a data-primary="Kubernetes" data-secondary="overview screen" data-type="indexterm" id="idm46291182147304"/>that you first saw when you opened the dashboard. Click it again now that you’re in the <em>kube-system</em> namespace. This screen contains a list of interesting entries in the namespace, as well as graphs about the health of those entries. On this screen, you should see four green circles (which are health pie charts) displaying stats on Daemon Sets, Deployments, Pods, and Replica Sets. Scroll down further on this screen and you will see individual entries making up each category. The overview screen only shows categories that contain resources, which is why when you first visited this screen in the <em>default</em> namespace it was so empty.</p>&#13;
</dd>&#13;
<dt>Workloads</dt>&#13;
<dd>&#13;
<p>Workloads contains entries <a data-primary="Kubernetes" data-secondary="workloads" data-type="indexterm" id="idm46291182143368"/>for the guts of a Kubernetes cluster. Click the Pods entry in the list. Here you can see a list of the different pods required <a data-primary="Kubernetes" data-secondary="Minikube" data-tertiary="pods" data-type="indexterm" id="idm46291182142120"/><a data-primary="Minikube" data-secondary="pods" data-type="indexterm" id="idm46291182140904"/>to run Minikube. In the new list of pods, click the “etcd-minikube” pod. This takes you to a new screen with more information about this specific pod, such as the labels it uses, the IP address, and how many times Kubernetes has restarted it. At the end of the screen, it even gives you details about the container, such as the command it executed when starting the container.</p>&#13;
</dd>&#13;
<dt>Discovery and load balancing</dt>&#13;
<dd>&#13;
<p>This section contains <a data-primary="Kubernetes" data-secondary="discovery and load balancing" data-type="indexterm" id="idm46291182121768"/><a data-primary="load balancing" data-secondary="Kubernetes" data-type="indexterm" id="idm46291182120696"/>two entries, Ingresses, and Services. Recall that ingresses allow external requests to be passed to a service and that a service is essentially a reverse proxy for a set of pods. Click the Services entry to view the services required by Minikube. In this case, you should see a single entry called “kube-dns.” Click that entry to view more information about the service, such as the pods associated with it. In this case, there are two separate “coredns-*” pods running. Those two pods are managed by a “coredns-*” replica set.</p>&#13;
</dd>&#13;
<dt>Config and storage</dt>&#13;
<dd>&#13;
<p>This section contains entries for <a data-primary="Kubernetes" data-secondary="config and storage section" data-type="indexterm" id="idm46291182117752"/>performing configuration management, storage, and even secrets management. These entries won’t be covered in this chapter, though they’re definitely useful for many organizations.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Once you’re done poking around the dashboard, change the Namespace drop-down menu back to <em>default</em>. In the next section, you will deploy an application of your own, and it will be available in the <em>default</em> namespace. You’ll mostly interact with Kubernetes via the terminal for the rest of the chapter, but feel free to open the dashboard if you ever need a <a data-primary="Minikube" data-secondary="running" data-startref="min_run" data-type="indexterm" id="idm46291182114856"/><a data-primary="Kubernetes" data-secondary="Minikube" data-startref="min_runkub" data-tertiary="running" data-type="indexterm" id="idm46291182113608"/>visualization of the state of your cluster.</p>&#13;
<div style="page-break-after: always;"/>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46291182111304">&#13;
<h5>Alternatives to Minikube</h5>&#13;
<p>Minikube is useful for running Kubernetes on a single machine when dealing with a smaller number of containers. However, in a production environment with much higher demands, you’re going to need something more capable. You can install a full version of Kubernetes on your production machines, which will require several services such as Etcd.</p>&#13;
&#13;
<p>If you’re using AWS, then you might want to consider their managed <a class="orm:hideurl" href="https://aws.amazon.com/eks/">Elastic Kubernetes Service (AWS EKS)</a>. Alternatively, if you’re using Google Cloud, look into their managed <a class="orm:hideurl" href="https://cloud.google.com/kubernetes-engine/">Google Kubernetes Engine (GKE)</a>.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deploying an Application" data-type="sect1"><div class="sect1" id="idm46291182343352">&#13;
<h1>Deploying an Application</h1>&#13;
&#13;
<p>You’re now ready to deploy an <a data-primary="Kubernetes" data-secondary="application deployment" data-type="indexterm" id="kub_appdeploy"/><a data-primary="deployments" data-secondary="applications" data-tertiary="Kubernetes" data-type="indexterm" id="kub_appdeploy1"/><a data-primary="applications" data-secondary="Kubernetes" data-type="indexterm" id="kub_appdeploy2"/>application to Kubernetes, and the <code>kubectl</code> CLI is the only tool that you’ll need to make it happen.</p>&#13;
&#13;
<p>This utility can be used in two common ways. The first way is by passing various subcommands to it. For example, the <code>kubectl get pods</code> command you’ve been using has a subcommand of <code>get</code>, and the object type passed to that subcommand is <code>pods</code>. The other way of using this utility is by using the <code>apply</code> subcommand and passing in a flag for a configuration file. You’ll get to configuration files shortly, but for now, it’s time to use subcommands.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Kubectl Subcommands" data-type="sect2"><div class="sect2" id="idm46291182098680">&#13;
<h2>Kubectl Subcommands</h2>&#13;
&#13;
<p>For this first deployment, <a data-primary="Kubernetes" data-secondary="Kubectl" data-tertiary="subcommands" data-type="indexterm" id="idm46291182096648"/><a data-primary="commands" data-secondary="Kubectl subcommands" data-type="indexterm" id="idm46291182095400"/><a data-primary="Kubectl" data-secondary="subcommands" data-type="indexterm" id="idm46291182094456"/>you’ll use a few different <code>kubectl</code> subcommands to interact with the Kubernetes API. These commands allow you to interact with Kubernetes without needing to write files to disk. This approach is perhaps akin to running <code>docker run</code> commands in your terminal. For this first deployment, you’ll run a generic hello world application to whet your appetite. This application is part of the Kubernetes documentation, but don’t worry, becuase you’ll be deploying real Node.js applications soon enough.</p>&#13;
&#13;
<p>Recall that the deployment controller is <a data-primary="deployments" data-secondary="controllers, Kubernetes" data-type="indexterm" id="idm46291182091560"/>commonly used for deploying applications to Kubernetes. This type of resource is likely the one that you’ll interact with the most as you work with a Kubernetes cluster on a day-to-day basis.</p>&#13;
&#13;
<p>To create your very first deployment, run the following commands. Try to run them quickly so that you can view the status of the Kubernetes cluster while the deployment is in progress:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl create deployment hello-minikube <code class="se">\</code>&#13;
  --image<code class="o">=</code>k8s.gcr.io/echoserver:1.10&#13;
<code class="nv">$ </code>kubectl get deployments&#13;
<code class="nv">$ </code>kubectl get pods&#13;
<code class="nv">$ </code>kubectl get rs</pre>&#13;
&#13;
<p>The first command is what creates your deployment. The actual creation of the deployment resource is pretty quick, and the command should exit almost immediately. However, it still needs to do a bunch of background work before it’s truly complete. For example, the <em>echoserver</em> image needs to be downloaded and a container needs to be instantiated.</p>&#13;
&#13;
<p>If you were able to run the subsequent commands quickly enough, you should see the status of the Kubernetes cluster while it’s trying to get things into the desired state. On my machine, I see the following command output:</p>&#13;
&#13;
<pre data-type="programlisting">$ kubectl get deployments&#13;
  NAME             READY   UP-TO-DATE   AVAILABLE   AGE&#13;
  hello-minikube   0/1     1            0           3s&#13;
$ kubectl get pods&#13;
  NAME                            READY STATUS            RESTARTS AGE&#13;
  hello-minikube-6f5579b8bf-rxhfl 0/1   ContainerCreating 0        4s&#13;
$ kubectl get rs&#13;
  NAME                        DESIRED   CURRENT   READY   AGE&#13;
  hello-minikube-64b64df8c9   1         1         0       0s</pre>&#13;
&#13;
<p>As you can see, the creation of the resources is immediate. In this case, a pod resource named <em>hello-minikube-6f5579b8bf-rxhfl</em> was immediately created. However, the actual pod isn’t up and ready yet. The READY column lists the value for that pod as 0/1. This means that zero of the desired one pods have been created. Note that in this case the deployment “owns” the replica set, and the replica set “owns” the pod. While you technically only requested that a deployment be created when you ran the command, it implicitly creates dependent resources of other types.</p>&#13;
&#13;
<p>Once a minute or two passes, the cluster will most likely have finished creating the other resources. So, run those three <code>kubectl get</code> commands again. When I run those commands a second time, I get these results—though this time I’ve added the <code>-L app</code> flag to show the pod’s <em>app</em> label:</p>&#13;
&#13;
<pre data-type="programlisting">$ kubectl get deployments&#13;
  NAME             READY   UP-TO-DATE   AVAILABLE   AGE&#13;
  hello-minikube   1/1     1            1           7m19s&#13;
$ kubectl get pods -L app&#13;
  NAME                READY  STATUS   RESTARTS  AGE    APP&#13;
  hello-minikube-123  1/1    Running  0         7m24s  hello-minikube&#13;
$ kubectl get rs&#13;
  NAME                        DESIRED   CURRENT   READY   AGE&#13;
  hello-minikube-64b64df8c9   1         1         1       7m25s</pre>&#13;
&#13;
<p>In this case, enough time has passed that the cluster was able to reach the desired state. The images were downloaded, and containers have been instantiated. Your <em>hello-minikube</em> application is <a data-primary="Minikube" data-secondary="hello-minikube application" data-type="indexterm" id="idm46291182079288"/><a data-primary="applications" data-secondary="hello-minikube" data-type="indexterm" id="idm46291182078264"/>now up and running! That said, you can’t easily interact with it. To do that, you first need to create a service.</p>&#13;
&#13;
<p>Recall that a service is like a reverse proxy for containers matching a certain selector. Run the following commands to create a new service and then to list the services:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl expose deployment hello-minikube <code class="se">\</code>&#13;
  --type<code class="o">=</code>NodePort --port<code class="o">=</code>8080&#13;
<code class="nv">$ </code>kubectl get services -o wide</pre>&#13;
&#13;
<p>Here is the list of services available on my machine:</p>&#13;
&#13;
<pre data-type="programlisting">NAME           TYPE      ... PORT(S)        AGE  SELECTOR&#13;
hello-minikube NodePort  ... 8080:31710/TCP 6s   app=hello-minikube&#13;
kubernetes     ClusterIP ... 443/TCP        7d3h &lt;none&gt;</pre>&#13;
&#13;
<p>In this case, the <code>kubernetes</code> entry is <a data-primary="Kubernetes" data-secondary="services" data-type="indexterm" id="idm46291182019960"/><a data-primary="services" data-secondary="Kubernetes" data-type="indexterm" id="idm46291182064152"/>used by the Kubernetes cluster itself. The <code>hello-minikube</code> entry is the one that belongs to your <em>hello-minikube</em> application. The type of this service is set to <em>NodePort</em>, which essentially forwards the specified port on the node machine to the port used by the container within the pod.</p>&#13;
&#13;
<p>The SELECTOR column for this service lists the selectors that are used to target pods. In this case, the selector was implicitly created and it targets pods with an <em>app</em> label set to <em>hello-minikube</em>. As you saw previously, a label of <em>app</em> was implicitly set to <em>hello-minikube</em> on the pods when you created the deployment. These are operations provided by Kubectl to make interacting with the API easier.</p>&#13;
&#13;
<p>The service that you created is ready almost immediately. With it created, you’re now ready to send it an HTTP request. But what URL should you request? In this case, you’ll need a bit of help from the <code>minikube</code> CLI to get the URL of the <em>hello-minikube</em> service. Run the following commands—the first one will display the service’s URL, and the second will make an HTTP request:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>minikube service hello-minikube --url&#13;
<code class="nv">$ </code>curl <code class="sb">`</code>minikube service hello-minikube --url<code class="sb">`</code></pre>&#13;
&#13;
<p>In my case, I see that the URL to the service is <code>http://172.17.0.3:31710</code>. The <em>hello-minikube</em> HTTP service provides a bunch of information when you make the request. Assuming you didn’t receive an error, the request was a success!</p>&#13;
&#13;
<p>Note that in this case there is no concept of ownership between the service and the other resources. The service is only loosely related to the pods since only their selector and labels happen to match. The service could technically match other pods as well, if any existed.</p>&#13;
&#13;
<p>At this point it’s worth visiting the Kubernetes dashboard once again and viewing the resources that you’ve created. Check out the Deployments, Pods, and Replica Sets screens in the Workloads section, as well as the Services screen in the Discovery and Load Balancing sections of the dashboard.</p>&#13;
&#13;
<p>Now that you’re done with the <em>hello-minikube</em> service, it’s time to tear it down. Run the following commands to delete the service and deployment resources that you previously created:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl delete services hello-minikube&#13;
<code class="nv">$ </code>kubectl delete deployment hello-minikube</pre>&#13;
&#13;
<p>When you delete the deployment, it will automatically delete the resources that it owns (in this case, the pods and the replica set). Once that’s done, run these commands to get a list of resources one final time:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get deployments&#13;
<code class="nv">$ </code>kubectl get pods&#13;
<code class="nv">$ </code>kubectl get rs</pre>&#13;
&#13;
<p>Depending on how quickly you run the commands, you may see that the pod still exists. But if you do see it, the status of the pod should be listed as Terminating. Run the command a few more times and you should then see that the pod has disappeared entirely. Most of the interactions you have with Kubernetes will require time before the cluster can change from the existing state to your desired state.</p>&#13;
&#13;
<p>Now that you’re familiar with running Kubectl commands to interact with your Kubernetes cluster, you’re ready to use more powerful <a data-primary="Kubernetes" data-secondary="application deployment" data-startref="kub_appdeploy" data-type="indexterm" id="idm46291181937000"/><a data-primary="deployments" data-secondary="applications" data-startref="kub_appdeploy2" data-tertiary="Kubernetes" data-type="indexterm" id="idm46291181935880"/><a data-primary="applications" data-secondary="Kubernetes" data-startref="kub_appdeploy3" data-type="indexterm" id="idm46291182002120"/>configuration files.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Kubectl Configuration Files" data-type="sect2"><div class="sect2" id="idm46291182097736">&#13;
<h2>Kubectl Configuration Files</h2>&#13;
&#13;
<p>The second approach for interacting with <a data-primary="Kubectl" data-secondary="configuration files" data-type="indexterm" id="kub_configfile"/><a data-primary="configuration files" data-secondary="Kubectl" data-type="indexterm" id="kub_configfile1"/><a data-primary="YAML" data-secondary="Kubernetes" data-type="indexterm" id="idm46291181996584"/>the Kubernetes API makes use of configuration files. This allows you to declaratively describe subsets of your Kubernetes cluster using YAML files, an approach reminiscent of running <code>docker-compose</code> commands. These interactions make use of the <code>kubectl apply -f &lt;FILENAME&gt;</code> &#13;
<span class="keep-together">subcommand.</span></p>&#13;
&#13;
<p>When you ran the other Kubectl commands, you were mostly working with a single resource at a time, like when you created the service, or sometimes multiple resources, like when the pod and replica set were created when you made a deployment. When working with configuration files, several potentially unrelated resources can be created at the same time.</p>&#13;
&#13;
<p>In this section, you’ll deploy and run the <em>recipe-api</em> application <a data-primary="recipe-api" data-secondary="application deployment" data-type="indexterm" id="rec_appdep"/>that you previously built, this time with a few added niceties:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>You’ll run five redundant <em>replicas</em> of the application at once.</p>&#13;
</li>&#13;
<li>&#13;
<p>A Kubernetes service will point to the instances.</p>&#13;
</li>&#13;
<li>&#13;
<p>Kubernetes will automatically restart unhealthy application replicas.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>But first, you’ll need to build a Docker image and push it to the Kubernetes Docker service. Visit your <em>recipe-api</em> directory and build a new version of the image by running the following commands:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code><code class="nb">cd </code>recipe-api&#13;
<code class="nv">$ </code><code class="nb">eval</code> <code class="k">$(</code>minikube -p minikube docker-env<code class="k">)</code> <code class="c"># ensure Minikube docker</code>&#13;
<code class="nv">$ </code>docker build -t recipe-api:v1 .</pre>&#13;
&#13;
<p>A Docker image tagged as <em>recipe-api:v1</em> is now available in your Kubernetes Docker daemon.</p>&#13;
&#13;
<p>Now you’re ready to create a configuration file for your application. First, create a file named <em>recipe-api/recipe-api-deployment.yml</em>. This file describes the <a data-primary="recipe-api" data-secondary="recipe-api/recipe-api-deployment.yml" data-type="indexterm" id="idm46291181916056"/>deployment of the service, including the number of replicas to maintain, the port number, and a URL to use as a health check.</p>&#13;
&#13;
<p>Now that you’ve created the deployment configuration file, begin by adding the content in <a data-type="xref" href="#ex_kubernetes_deploy_1">Example 7-1</a> to it.</p>&#13;
<div data-type="example" id="ex_kubernetes_deploy_1">&#13;
<h5><span class="label">Example 7-1. </span><em>recipe-api/recipe-api-deployment.yml</em>, part one</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">apps/v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Deployment</code><code> </code><a class="co" href="#callout_container_orchestration_CO1-1" id="co_container_orchestration_CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">recipe-api</code><code> </code><a class="co" href="#callout_container_orchestration_CO1-2" id="co_container_orchestration_CO1-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>  </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">app</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">recipe-api</code><code> </code><a class="co" href="#callout_container_orchestration_CO1-3" id="co_container_orchestration_CO1-3"><img alt="3" src="assets/3.png"/></a></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_container_orchestration_CO1-1" id="callout_container_orchestration_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This section of the YAML file defines a deployment.</p></dd>&#13;
<dt><a class="co" href="#co_container_orchestration_CO1-2" id="callout_container_orchestration_CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The name of this deployment is <em>recipe-api</em>.</p></dd>&#13;
<dt><a class="co" href="#co_container_orchestration_CO1-3" id="callout_container_orchestration_CO1-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>The deployment has a label of <code>app=recipe-api</code>.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>The file begins by defining the deployment itself. The values should be pretty straightforward. So far, the file suggests that it’s being used to create a <em>recipe-api</em> deployment.</p>&#13;
&#13;
<p>Next, add the content in <a data-type="xref" href="#ex_kubernetes_deploy_2">Example 7-2</a> to the file.</p>&#13;
<div data-type="example" id="ex_kubernetes_deploy_2">&#13;
<h5><span class="label">Example 7-2. </span><em>recipe-api/recipe-api-deployment.yml</em>, part two</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">replicas</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">5</code><code> </code><a class="co" href="#callout_container_orchestration_CO2-1" id="co_container_orchestration_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>  </code><code class="nt">selector</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">matchLabels</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">app</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">recipe-api</code><code>&#13;
</code><code>  </code><code class="nt">template</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>        </code><code class="nt">app</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">recipe-api</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_container_orchestration_CO2-1" id="callout_container_orchestration_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Five application replicas will run at once.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This section describes <a data-primary="Kubernetes" data-secondary="replica sets" data-type="indexterm" id="idm46291181782392"/>how the replica set will work. In particular, Kubernetes will need to run five replicas of the pods. The <code>matchLabels</code> selector is <a data-primary="recipe-api" data-secondary="labels" data-type="indexterm" id="idm46291181780776"/>set to <em>recipe-api</em>, which means it will match pods with that label.</p>&#13;
&#13;
<p>Now add the final content from <a data-type="xref" href="#ex_kubernetes_deploy_3">Example 7-3</a> to the file. Note that the first line, <code>spec</code>, should have an indentation of four spaces; it’s a sibling property to the <span class="keep-together"><code>metadata</code></span> field.</p>&#13;
<div data-type="example" id="ex_kubernetes_deploy_3">&#13;
<h5><span class="label">Example 7-3. </span><em>recipe-api/recipe-api-deployment.yml</em>, part three</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="c1">#### note the four space indent</code><code>&#13;
</code><code>    </code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">containers</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">recipe-api</code><code>&#13;
</code><code>        </code><code class="nt">image</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">recipe-api:v1</code><code> </code><a class="co" href="#callout_container_orchestration_CO3-1" id="co_container_orchestration_CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>        </code><code class="nt">ports</code><code class="p">:</code><code>&#13;
</code><code>        </code><code class="p-Indicator">-</code><code> </code><code class="nt">containerPort</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">1337</code><code> </code><a class="co" href="#callout_container_orchestration_CO3-2" id="co_container_orchestration_CO3-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>        </code><code class="nt">livenessProbe</code><code class="p">:</code><code> </code><a class="co" href="#callout_container_orchestration_CO3-3" id="co_container_orchestration_CO3-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>          </code><code class="nt">httpGet</code><code class="p">:</code><code>&#13;
</code><code>            </code><code class="nt">path</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">/recipes/42</code><code>&#13;
</code><code>            </code><code class="nt">port</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">1337</code><code>&#13;
</code><code>          </code><code class="nt">initialDelaySeconds</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">3</code><code>&#13;
</code><code>          </code><code class="nt">periodSeconds</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">10</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_container_orchestration_CO3-1" id="callout_container_orchestration_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The pod’s only container uses the <em>recipe-api:v1</em> image.</p></dd>&#13;
<dt><a class="co" href="#co_container_orchestration_CO3-2" id="callout_container_orchestration_CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The container listens on port 1337.</p></dd>&#13;
<dt><a class="co" href="#co_container_orchestration_CO3-3" id="callout_container_orchestration_CO3-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>The <code>livenessProbe</code> section configures a health check.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This section of the file defines the container used by the pod and is a bit more complex than the previous sections. The name of the container is set to <code>recipe-api</code> and it is configured to use the <em>recipe-api:v1</em> image, which is the image you most recently built and tagged.</p>&#13;
&#13;
<p>The <code>livenessProbe</code> section defines the health check used to determine if the container is healthy or not. In this case, it’s configured to wait three seconds after starting the container, and then it makes an HTTP <code>GET</code> request every 10 seconds to the <span class="keep-together"><code>/recipes/42</code></span> endpoint. Note that this URL was chosen merely because it’s already present in the <em>producer-http-basic.js</em> application; consult with <a data-type="xref" href="ch03.html#ch_scaling_sec_rp_subsec_health">“Load Balancing and Health Checks”</a> for building a better health check endpoint.</p>&#13;
&#13;
<p>Now that your file is finished, it’s time to tell the Kubernetes cluster to apply the changes represented within. Run the following command:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl apply -f recipe-api/recipe-api-deployment.yml</pre>&#13;
&#13;
<p>Kubectl reads the file and, assuming it doesn’t find any typos, instructs Kubernetes to apply the changes. The same rules apply when running any other Kubectl commands to change the state of the cluster: changes aren’t immediate. Run this next command &#13;
<span class="keep-together">a few</span> times until the output changes and your pods are marked with a status of &#13;
<span class="keep-together">Running:</span></p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get pods</pre>&#13;
&#13;
<p>I get the following output on my machine:</p>&#13;
&#13;
<pre data-type="programlisting">NAME                          READY   STATUS    RESTARTS   AGE&#13;
recipe-api-6fb656695f-clvtd   1/1     Running   0          2m&#13;
... OUTPUT TRUNCATED ...&#13;
recipe-api-6fb656695f-zrbnf   1/1     Running   0          2m</pre>&#13;
&#13;
<p>The Running status signals that the pod is both running and currently passing its liveness health probes. To view more information about a pod’s health check, run the following command, replacing <code>&lt;POD_NAME&gt;</code> with the name of your pod (<em>recipe-api-6fb656695f-clvtd</em> in my case):</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl describe pods &lt;POD_NAME&gt; <code class="p">|</code> grep Liveness</pre>&#13;
&#13;
<p>I get the following liveness information in return:</p>&#13;
&#13;
<pre data-type="programlisting">Liveness: http-get http://:1337/recipes/42&#13;
  delay=3s timeout=1s period=10s #success=1 #failure=3</pre>&#13;
&#13;
<p>Next, create another file named <em>recipe-api/recipe-api-network.yml</em>, this time to define the Kubernetes service that will point to the pods that you’ve created. The service could have been defined within the same file by placing it in a separate YAML section, but the file was already long enough. Within this file, add the content from <a data-type="xref" href="#ex_kubernetes_network">Example 7-4</a>.</p>&#13;
<div data-type="example" id="ex_kubernetes_network">&#13;
<h5><span class="label">Example 7-4. </span><em>recipe-api/recipe-api-network.yml</em></h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Service</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">recipe-api-service</code><code> </code><a class="co" href="#callout_container_orchestration_CO4-1" id="co_container_orchestration_CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">type</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">NodePort</code><code>&#13;
</code><code>  </code><code class="nt">selector</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">app</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">recipe-api</code><code>&#13;
</code><code>  </code><code class="nt">ports</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="p-Indicator">-</code><code> </code><code class="nt">protocol</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">TCP</code><code>&#13;
</code><code>      </code><code class="nt">port</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">80</code><code>&#13;
</code><code>      </code><code class="nt">targetPort</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">1337</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_container_orchestration_CO4-1" id="callout_container_orchestration_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The service is named <em>recipe-api-service</em>.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This file describes a <a data-primary="recipe-api-service" data-type="indexterm" id="idm46291181528600"/>single service named <em>recipe-api-service</em>. It is a <em>NodePort</em> service, <a data-primary="NodePort service" data-type="indexterm" id="idm46291181526872"/>just like the one you previously defined. It targets pods matching the <code>app=recipe-api</code> selector and will forward requests to port 1337.</p>&#13;
&#13;
<p>Apply the changes represented in this configuration file the same way you did for the previous one, by running this command with a new filename:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl apply -f recipe-api/recipe-api-network.yml</pre>&#13;
&#13;
<p>Once that’s done, run the <strong><code>kubectl get services -o wide</code></strong> command again. You should see an entry just like you saw when previously defining a service using the <code>kubectl expose</code> command, except this time the name of the service is a little longer.</p>&#13;
&#13;
<p>Congratulations! You’ve now defined your Node.js <em>recipe-api</em> application using Kubernetes configuration files and have successfully deployed it to your local Kubernetes cluster. With that out of the way, <a data-primary="Kubernetes" data-secondary="configuration files" data-startref="kub_configfile" data-type="indexterm" id="idm46291181480424"/><a data-primary="configuration files" data-secondary="Kubectl" data-startref="kub_configfile1" data-type="indexterm" id="idm46291181479320"/><a data-primary="recipe-api" data-secondary="application deployment" data-startref="rec_appdep" data-type="indexterm" id="idm46291181500344"/>you are now ready to deploy your <em>web-api</em> &#13;
<span class="keep-together">application.</span></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Service Discovery" data-type="sect1"><div class="sect1" id="idm46291181999864">&#13;
<h1>Service Discovery</h1>&#13;
&#13;
<p>The <em>web-api</em> application <a data-primary="Kubernetes" data-secondary="service discovery" data-type="indexterm" id="kub_servdisco"/><a data-primary="web-api service" data-type="indexterm" id="idm46291181493896"/>is a little more complex than <em>recipe-api</em>. This application will still run redundant copies and require a service, but it will also need to communicate with the <em>recipe-api</em> service, and it will need to accept ingress connections from the outside world. To keep the configuration file short, it won’t contain the health check portion.</p>&#13;
&#13;
<p>Enabling ingress connections <a data-primary="Kubernetes" data-secondary="clusters" data-tertiary="ingress connections" data-type="indexterm" id="idm46291181491560"/><a data-primary="clusters, Kubernetes" data-secondary="ingress connections" data-type="indexterm" id="idm46291181490312"/>for your cluster requires that you manually enable the feature. Run the following commands to do so:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>minikube addons <code class="nb">enable </code>ingress&#13;
<code class="nv">$ </code>kubectl get pods --namespace kube-system <code class="p">|</code> grep ingress</pre>&#13;
&#13;
<p>The first command instructs <a data-primary="Minikube" data-secondary="ingress connections" data-type="indexterm" id="idm46291181484968"/>Minikube to enable the ingress add-on, which is a way of extending the capabilities of Minikube. In this case, it creates a new container that uses the Nginx web server to perform ingress routing. The second command just shows you where the container lives. In this case, Kubernetes launches the Nginx container within the <em>kube-system</em> namespace. You don’t technically need to know where it runs, you’re just looking under the hood.</p>&#13;
&#13;
<p>Many other <a class="orm:hideurl" href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">ingress controllers</a> are available, such as the beloved HAProxy covered in <a data-type="xref" href="ch03.html#ch_scaling_sec_rp">“Reverse Proxies with HAProxy”</a>, though the default Nginx option is maintained directly by the Kubernetes project. Different ingress controllers support different features, but ultimately the controller configures some sort of reverse proxy to map incoming requests to a service.</p>&#13;
&#13;
<p>By enabling ingress, you’re able to make requests <a data-primary="web-api service" data-secondary="requests" data-type="indexterm" id="idm46291181457544"/>to the <em>web-api</em> service by making a curl request to a single hostname instead of having to use the <code>minikube</code> CLI to locate the service’s host and port. This makes it easier to route requests from external clients to the appropriate node and container.</p>&#13;
&#13;
<p>The relationship between these different Kubernetes resources can get a little complex. <a data-type="xref" href="#fig_kubernetes_discovery_overview">Figure 7-3</a> contains a visual overview of them. External requests are passed through <em>web-api-ingress</em>, which then passes the request <a data-primary="web-api-ingress" data-type="indexterm" id="idm46291181450888"/>to the <em>web-api-service</em>. This service passes the request to one of the <em>web-api</em> pods. The pod then sends a request to the <em>recipe-api</em> service, which then passes the request to a <em>recipe-api</em> pod. The mechanism by which the <em>web-api</em> application finds and communicates with the <em>recipe-api</em> application is called <em>service discovery</em> and is largely taken care of by Kubernetes.</p>&#13;
&#13;
<figure><div class="figure" id="fig_kubernetes_discovery_overview">&#13;
<img alt="External requests pass through ingress and are given to web-api-service before being routed to a web-api pod. Then web-api sends requests through recipe-api-service which then routes the request to a recipe-api pod." src="assets/dsnj_0703.png"/>&#13;
<h6><span class="label">Figure 7-3. </span>Service discovery overview</h6>&#13;
</div></figure>&#13;
&#13;
<p>The first thing you need to do to get your <em>web-api</em> service <a data-primary="web-api service" data-secondary="Kubernetes and" data-type="indexterm" id="idm46291181443976"/>ready for Kubernetes is to <a data-primary="Kubernetes" data-secondary="Dockerfile" data-type="indexterm" id="idm46291181442840"/>create a Dockerfile. Previously, when you worked with the project, you had created one for the Zipkin variant of the application. This time, you need one for the basic HTTP server. For this Dockerfile, you can copy the existing <em>recipe-api</em> file and make some changes. Copy the file and enter the <em>web-api</em> directory by running these &#13;
<span class="keep-together">commands:</span></p>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code class="nv">$ </code>cp recipe-api/Dockerfile web-api/Dockerfile&#13;
<code class="nv">$ </code><code class="nb">cd </code>web-api</pre>&#13;
&#13;
<p>Next, modify the final line of the <em>web-api/Dockerfile</em>. Currently it’s still referencing the old <em>producer-http-basic.js</em> file and should instead reference the <em>consumer-http-basic.js</em> file:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">CMD [ "node", "consumer-http-basic.js" ]</code></pre>&#13;
&#13;
<p>With the Dockerfile out of <a data-primary="Kubernetes" data-secondary="configuration files" data-tertiary="creating" data-type="indexterm" id="idm46291181420424"/><a data-primary="configuration files" data-secondary="Kubernetes, creating" data-type="indexterm" id="idm46291181419336"/>the way, it’s now time to create the Kubernetes configuration files. First up is the one that defines the deployment. Create a new file named <em>web-api/web-api-deloyment.yml</em>. It starts off fairly similar to the one you created for <em>recipe-api</em>, except that the app name has been changed to <em>web-api</em>. Add the content in <a data-type="xref" href="#ex_kubernetes_web_deploy_1">Example 7-5</a> to this file to get it started.</p>&#13;
<div data-type="example" id="ex_kubernetes_web_deploy_1">&#13;
<h5><span class="label">Example 7-5. </span><em>web-api/web-api-deployment.yml</em>, part one</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">apps/v1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Deployment</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web-api</code><code>&#13;
</code><code>  </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">app</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web-api</code><code>&#13;
&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">replicas</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">3</code><code> </code><a class="co" href="#callout_container_orchestration_CO5-1" id="co_container_orchestration_CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>  </code><code class="nt">selector</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">matchLabels</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">app</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web-api</code><code>&#13;
</code><code>  </code><code class="nt">template</code><code class="p">:</code><code>&#13;
</code><code>    </code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">labels</code><code class="p">:</code><code>&#13;
</code><code>        </code><code class="nt">app</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web-api</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_container_orchestration_CO5-1" id="callout_container_orchestration_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This time the service will have three replicas.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>So far, so good. Now it’s time to define the pod’s container. Add the content in <a data-type="xref" href="#ex_kubernetes_web_deploy_2">Example 7-6</a> to finish the file. Note that the first line, <code>spec</code>, has four spaces of indentation and is a sibling to the previous <code>metadata</code> field.</p>&#13;
<div data-type="example" id="ex_kubernetes_web_deploy_2">&#13;
<h5><span class="label">Example 7-6. </span><em>web-api/web-api-deployment.yml</em>, part two</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="c1">#### note the four space indent</code><code>&#13;
</code><code>    </code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">containers</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web-api</code><code>&#13;
</code><code>        </code><code class="nt">image</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web-api:v1</code><code>&#13;
</code><code>        </code><code class="nt">ports</code><code class="p">:</code><code>&#13;
</code><code>        </code><code class="p-Indicator">-</code><code> </code><code class="nt">containerPort</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">1337</code><code>&#13;
</code><code>        </code><code class="nt">env</code><code class="p">:</code><code> </code><a class="co" href="#callout_container_orchestration_CO6-1" id="co_container_orchestration_CO6-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>        </code><code class="p-Indicator">-</code><code> </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">TARGET</code><code>&#13;
</code><code>          </code><code class="nt">value</code><code class="p">:</code><code> </code><code class="s">"</code><code class="s">recipe-api-service</code><code class="s">"</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_container_orchestration_CO6-1" id="callout_container_orchestration_CO6-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Environment variable configuration</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This part of the deployment <a data-primary="environment variables" data-secondary="configuration" data-type="indexterm" id="idm46291181241864"/><a data-primary="variables" data-secondary="environment variables" data-tertiary="configuration" data-type="indexterm" id="idm46291181241016"/>configuration file has diverged a bit from the previous file. Most notably you’ve added an <code>env</code> section to the container configuration. This directly translates into the environment variable feature that you previously used when running Docker containers directly. In this case, the <code>TARGET</code> environment variable <a data-primary="recipe-api-service" data-secondary="environment variables" data-type="indexterm" id="idm46291181238712"/><a data-primary="environment variables" data-secondary="recipe-api-service" data-type="indexterm" id="idm46291181237704"/>has been set to <em>recipe-api-service</em>.</p>&#13;
&#13;
<p>This might seem a bit interesting at first. The <code>TARGET</code> variable represents the host portion of a URL. And, since the value is set to <em>recipe-api-service</em> without a port, this means that the URL being requested by the application will look like <code>http://recipe-api-service:80/</code> since HTTP uses a default port of 80.</p>&#13;
&#13;
<p>An application running in Kubernetes can communicate with a service using a host named after the service it wishes to communicate with. This is pretty similar to how Docker works as well since both use a DNS service, except that Docker only pulls this off for containers running on the same machine. Kubernetes is able to achieve this regardless of which node in the cluster the applications are running on. This works because the Kube Proxy daemon running on each node forwards requests to other nodes. This is more impressive in a larger multinode Kubernetes cluster than in your current single-node Minikube cluster.</p>&#13;
&#13;
<p>Now that your deployment configuration file is complete, you’re ready to modify your network configuration file. This file will begin similarly to the previous one you created. For now, add the content from <a data-type="xref" href="#ex_kubernetes_web_network_1">Example 7-7</a> to the file.</p>&#13;
<div data-type="example" id="ex_kubernetes_web_network_1">&#13;
<h5><span class="label">Example 7-7. </span><em>web-api/web-api-network.yml</em>, part one</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">v1</code>&#13;
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Service</code>&#13;
<code class="nt">metadata</code><code class="p">:</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">web-api-service</code>&#13;
<code class="nt">spec</code><code class="p">:</code>&#13;
  <code class="nt">type</code><code class="p">:</code> <code class="l-Scalar-Plain">NodePort</code>&#13;
  <code class="nt">selector</code><code class="p">:</code>&#13;
    <code class="nt">app</code><code class="p">:</code> <code class="l-Scalar-Plain">web-api</code>&#13;
  <code class="nt">ports</code><code class="p">:</code>&#13;
    <code class="p-Indicator">-</code> <code class="nt">port</code><code class="p">:</code> <code class="l-Scalar-Plain">1337</code></pre></div>&#13;
&#13;
<p>This first section defines a service named <em>web-api-service</em>, which will forward incoming requests to port 1337 to the matching port 1337 within the <em>web-api</em> pods.</p>&#13;
&#13;
<p><a data-type="xref" href="#ex_kubernetes_web_network_2">Example 7-8</a> contains the second half of the network file and is a bit more complex. In this case, it begins with three hyphens (<code>---</code>). This is a YAML <a data-primary="YAML" data-secondary="hyphens" data-type="indexterm" id="idm46291181178984"/>convention for specifying that multiple documents exist within the same file. Essentially this allows you to concatenate related resource creation tasks within the same file. Add this content to your file.</p>&#13;
<div data-type="example" id="ex_kubernetes_web_network_2">&#13;
<h5><span class="label">Example 7-8. </span><em>web-api/web-api-network.yml</em>, part two</h5>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="nn">---</code><code>&#13;
</code><code class="nt">apiVersion</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">networking.k8s.io/v1beta1</code><code>&#13;
</code><code class="nt">kind</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">Ingress</code><code>&#13;
</code><code class="nt">metadata</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">name</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web-api-ingress</code><code>&#13;
</code><code>  </code><code class="nt">annotations</code><code class="p">:</code><code> </code><a class="co" href="#callout_container_orchestration_CO7-1" id="co_container_orchestration_CO7-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>    </code><code class="nt">nginx.ingress.kubernetes.io/rewrite-target</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">/$1</code><code>&#13;
</code><code class="nt">spec</code><code class="p">:</code><code>&#13;
</code><code>  </code><code class="nt">rules</code><code class="p">:</code><code> </code><a class="co" href="#callout_container_orchestration_CO7-2" id="co_container_orchestration_CO7-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>  </code><code class="p-Indicator">-</code><code> </code><code class="nt">host</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">example.org</code><code>&#13;
</code><code>    </code><code class="nt">http</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="nt">paths</code><code class="p">:</code><code>&#13;
</code><code>      </code><code class="p-Indicator">-</code><code> </code><code class="nt">path</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">/</code><code>&#13;
</code><code>        </code><code class="nt">backend</code><code class="p">:</code><code>&#13;
</code><code>          </code><code class="nt">serviceName</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">web-api-service</code><code>&#13;
</code><code>          </code><code class="nt">servicePort</code><code class="p">:</code><code> </code><code class="l-Scalar-Plain">1337</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_container_orchestration_CO7-1" id="callout_container_orchestration_CO7-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Nginx-specific configuration, such as URL rewriting, is supplied.</p></dd>&#13;
<dt><a class="co" href="#co_container_orchestration_CO7-2" id="callout_container_orchestration_CO7-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Additional virtual host routing rules are supplied.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This configuration file is intentionally more complex than it has to be in order to convey how the reverse proxy provided by the ingress controller can be configured in a very granular fashion.</p>&#13;
&#13;
<p>First, notice the <code>metadata.annotations</code> configuration. In this case, it has an Nginx-specific line for configuring how incoming URLs can be rewritten before being passed to the service. In this example, the path from the incoming URL is passed through unchanged and, in fact, the entire <code>annotations</code> section can be removed and the configuration file would work just the same. However, within a more complex organization, you might need the ability to modify incoming requests.</p>&#13;
&#13;
<p>The second set of configuration allows for routing based on virtual hosts. This configuration is universal and all ingress controllers should be able to use it. In this case, only requests destined for the domain <code>example.org</code> will match the rule. The configuration gets even more complex, matching paths beginning with <code>/</code> (this is also essentially a no-op). Finally, matching requests are passed to <em>web-api-service</em>. Note that the rule section can be simplified greatly to send any request, regardless of hostname and path, to the same service. By configuring this section of the ingress controller, you can apply the API facade pattern to expose multiple backend services using a single interface.</p>&#13;
&#13;
<p>Now that your files have been configured, you’re ready to build the image for your <em>web-api</em> service and to deploy it to your Kubernetes cluster.</p>&#13;
<div style="page-break-after: always;"/>&#13;
&#13;
<p>Run the following commands to do just that:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code><code class="nb">eval</code> <code class="k">$(</code>minikube -p minikube docker-env<code class="k">)</code> <code class="c"># ensure Minikube docker</code>&#13;
<code class="nv">$ </code>docker build -t web-api:v1 .&#13;
<code class="nv">$ </code>kubectl apply -f web-api-deployment.yml&#13;
<code class="nv">$ </code>kubectl apply -f web-api-network.yml</pre>&#13;
&#13;
<p>Again, the pod creation step may take a minute to finish. Run the <strong><code>kubectl get pods</code></strong> command until your newly created <em>web-api</em> instances are running. Once that’s done, you’re ready to make a request using the ingress controller.</p>&#13;
&#13;
<p>To make a request via ingress (instead of directly requesting the service), you’ll first need to get the IP address that the ingress is listening on. Run the following command to get this address:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get ingress web-api-ingress</pre>&#13;
&#13;
<p>I get the following output when I run the command:</p>&#13;
&#13;
<pre data-type="programlisting">NAME              CLASS    HOSTS         ADDRESS      PORTS   AGE&#13;
web-api-ingress   &lt;none&gt;   example.org   172.17.0.3   80      21s</pre>&#13;
&#13;
<p>In my case, the IP address that I need to send requests to is 172.17.0.3. If you don’t see an IP address listed, you may need to wait a moment and run the command again. Also, note that the port is set to 80, which is the default port of an HTTP ingress.</p>&#13;
&#13;
<p>Now you’re ready to make a request via ingress. Execute the following command, replacing <code>&lt;INGRESS_IP&gt;</code> with the IP address you obtained from the previous &#13;
<span class="keep-together">command:</span></p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>curl -H <code class="s2">"Host: example.org"</code> http://&lt;INGRESS_IP&gt;/</pre>&#13;
&#13;
<p>If all goes to plan, you’ll receive the JSON payload that you’ve seen throughout this book. The <code>consumer_pid</code> and <code>producer_pid</code> values aren’t that interesting since each of the Docker containers runs your application with a process ID of 1. Rest assured that the two different Kubernetes services that the requests are being passed through are routing requests to the individual pods using round robin.</p>&#13;
&#13;
<p>The IP address of the ingress controller will remain stable throughout the lifetime of the Kubernetes cluster. Even though pods will come and go, each of them getting new IP addresses, the IP address of the ingress remains the same.</p>&#13;
&#13;
<p>If you wanted, you could run a reverse proxy on your machine, accepting incoming requests from port 80, and proxying the requests to the IP address of the ingress controller. This is how Kubernetes can be used in production to expose applications running within the cluster.</p>&#13;
&#13;
<p>Of course, not just any resource within the cluster is exposed via ingress. Instead, &#13;
<span class="keep-together">you must</span> define exactly which services are exposed. This is useful for segregating shallow upstream services, like the <em>web-api</em>, from internal downstream <a data-primary="Kubernetes" data-secondary="service discovery" data-startref="kub_servdisco" data-type="indexterm" id="idm46291181023048"/>services, like &#13;
<span class="keep-together"><em>recipe-api</em>.</span></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Modifying Deployments" data-type="sect1"><div class="sect1" id="idm46291181020568">&#13;
<h1>Modifying Deployments</h1>&#13;
&#13;
<p>Deployments are the <a data-primary="deployments" data-secondary="modifying" data-type="indexterm" id="idm46291181496024"/>resources that you’re most likely to interact with on a regular basis as an application developer. As you saw in the previous sections, modifying a deployment can trigger changes to an underlying replica set and pods.</p>&#13;
&#13;
<p>The deployments that you’ve worked with so far all have names. Run the <strong><code>kubectl get deployments</code></strong> command and you will see two entries returned, one named <em>recipe-api</em> and the other named <em>web-api</em>. Those names were provided directly by the commands you ran. However, the names of dependent resources have been a little more dynamic. For example, on my machine, my <em>recipe-api</em> deployment has a replica set named <em>recipe-api-6fb656695f</em>, which in turn has a pod named <em>recipe-api-6fb656695f-clvtd</em>.</p>&#13;
&#13;
<p>Since the deployment has a stable name, you’re able to modify it by reusing that same name. This section covers a few of the common ways that you’re likely to modify deployments as an application developer. Much like when you deployed an application using either configuration files or standard <code>kubectl</code> commands, you’re also able to modify deployments using both approaches.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Scaling Application Instances" data-type="sect2"><div class="sect2" id="idm46291181014248">&#13;
<h2>Scaling Application Instances</h2>&#13;
&#13;
<p>The most basic way to modify a <a data-primary="applications" data-secondary="instances, scaling" data-type="indexterm" id="app_scale"/><a data-primary="scaling" data-secondary="application instances" data-type="indexterm" id="app_scale1"/>deployment is to scale the number of instances. In Kubernetes parlance, each redundant instance of an application is referred to as a replica. So, when you scale a deployment, you’re changing the number of pod replicas within that deployment.</p>&#13;
&#13;
<p>You’re currently running five replicas of the <em>recipe-api</em> application. Run the following commands to get a list of your pods, to scale the number of replicas to 10, and to get the new list of pods:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get pods -l <code class="nv">app</code><code class="o">=</code>recipe-api&#13;
<code class="nv">$ </code>kubectl scale deployment.apps/recipe-api --replicas<code class="o">=</code>10&#13;
<code class="nv">$ </code>kubectl get pods -l <code class="nv">app</code><code class="o">=</code>recipe-api</pre>&#13;
&#13;
<p>In this case, you should see that Kubernetes creates the five new pods, and depending on how quickly you ran the final command, some of them will have a status of <em>ContainerCreating</em>. Wait some time and run the final command again, and their statuses should have changed to <em>Running</em>.</p>&#13;
&#13;
<p>You could modify that command to set the number of replicas back down to five, &#13;
<span class="keep-together">but there’s</span> another way to modify a deployment. The <em>recipe-api/recipe-api-deployment.yml</em> file that was used to first create the deployment can also be used to modify it. Specifically, when you run the <code>kubectl apply</code> command, it’s not just limited to creating resources. Really, it instructs the Kubernetes cluster to make whatever changes are necessary to then resemble the resource definitions in the specified configuration file.</p>&#13;
&#13;
<p>In this case, the state of the cluster is currently different than that of the configuration file. Specifically, the file wants a replica count of 5, but the cluster has a replica count of 10. To scale the number of replicas back down to five, run the same <span class="keep-together"><code>kubectl apply</code></span> command again:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl apply -f recipe-api/recipe-api-deployment.yml</pre>&#13;
&#13;
<p>The output for the apply command can take on three forms:</p>&#13;
&#13;
<pre data-type="programlisting">deployment.apps/recipe-api created&#13;
deployment.apps/recipe-api configured&#13;
deployment.apps/recipe-api unchanged</pre>&#13;
&#13;
<p>The first line is what you had encountered previously when running <code>kubectl apply</code>. This line states that a new resource has been created. This time, however, you should have received the second line of output. This line means that the resource represented in the configuration file was found—using the resource’s name—and that the resource was modified. The final line is what you’ll see if the cluster currently resembles the state desired by the file and no action is necessary. Go ahead and run that <code>kubectl apply</code> command one more time. This time you should get the unchanged line in response.</p>&#13;
&#13;
<p>Note that as the number of pod replicas grows and shrinks, the service is still able to route requests to each of the available pods. Once a pod is terminated, it should no longer receive any requests. Once a pod has been added, it will wait for the health <a data-primary="health checks" data-secondary="recipe-api" data-type="indexterm" id="idm46291180927448"/><a data-primary="recipe-api" data-secondary="health checks" data-type="indexterm" id="idm46291180926472"/>check to pass (which have been enabled for the <em>recipe-api</em>) before it begins receiving requests.</p>&#13;
&#13;
<p>Kubernetes has an advanced feature called the <a class="orm:hideurl" href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler</a>. This is <a data-primary="Kubernetes" data-secondary="Horizontal Pod Autoscaler" data-type="indexterm" id="idm46291180922888"/>used to dynamically scale the number of replicas based on various criteria such as CPU usage or even based on custom metrics like the ones you previously generated in <a data-type="xref" href="ch04.html#ch_monitoring_sec_metrics">“Metrics with Graphite, StatsD, and Grafana”</a>. This is an advanced feature supported by Kubernetes that you may consider using for production <a data-primary="applications" data-secondary="instances, scaling" data-startref="app_scale" data-type="indexterm" id="idm46291180920760"/><a data-primary="scaling" data-secondary="application instances" data-startref="app_scale1" data-type="indexterm" id="idm46291180919544"/>applications, but it won’t be covered here.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deploying New Application Versions" data-type="sect2"><div class="sect2" id="idm46291181013624">&#13;
<h2>Deploying New Application Versions</h2>&#13;
&#13;
<p>You’ll also probably find <a data-primary="deployments" data-secondary="applications" data-tertiary="new versions" data-type="indexterm" id="app_new"/><a data-primary="applications" data-secondary="new versions" data-type="indexterm" id="app_new1"/>yourself in a situation where you need to deploy newer versions of an application. Since Kubernetes deals with applications encapsulated in a container, this means building new versions of an application’s Docker image, pushing the image to a Docker server, and then instructing Kubernetes to deploy the new version of an application container based on the image.</p>&#13;
&#13;
<p>When you deploy a new version of an application, you don’t want to kill off the old deployment resource and create a new one. Instead, you want to piggy back on it and replace the pods that belong to that deployment.</p>&#13;
&#13;
<p>Before you can deploy a new version of the application, you first need to create it. For the sake of illustration, you can do this by simply adding a new endpoint to the existing application code. Run the following commands to add a new endpoint and to build a <em>web-api:v2</em> version of your application:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code><code class="nb">cd </code>web-api&#13;
<code class="nv">$ </code><code class="nb">echo</code> <code class="s2">"server.get('/hello', async () =&gt; 'Hello');"</code> <code class="se">\</code>&#13;
  &gt;&gt; consumer-http-basic.js&#13;
<code class="nv">$ </code><code class="nb">eval</code> <code class="k">$(</code>minikube -p minikube docker-env<code class="k">)</code> <code class="c"># ensure Minikube docker</code>&#13;
<code class="nv">$ </code>docker build -t web-api:v2 .</pre>&#13;
&#13;
<p>Next, edit the <em>web-api/web-api-deployment.yml</em> file. Once inside, modify the <span class="keep-together"><code>spec.template.spec.container.image</code></span> property&#13;
and change it from <code>image: web-api:v1</code> to <code>image: web-api:v2</code>.&#13;
Once you’ve made that change, run the following command to deploy the changes and to watch the pods deploy:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl apply -f web-api-deployment.yml&#13;
<code class="nv">$ </code>kubectl get pods -w -l <code class="nv">app</code><code class="o">=</code>web-api</pre>&#13;
&#13;
<p>The <code>-w</code> flag tells Kubectl to watch the changes being made to the Kubernetes cluster, and it will keep drawing output as changes are made to the <em>web-api</em> pods in your &#13;
<span class="keep-together">cluster.</span> Once the process is finally complete you can kill the watch operation with &#13;
<span class="keep-together">Ctrl + C.</span></p>&#13;
&#13;
<p><a data-type="xref" href="#fig_kubernetes_deployment_default">Figure 7-4</a> displays a timeline of what you should see in your terminal. To start off, you have three instances of <em>v1</em> running. When you ran the command to apply the deployment, new <em>v2</em> pods were created. Eventually, the desired number of <em>v2</em> pods were created and deemed healthy. Kubernetes then switches the service over from <em>v1</em> to <em>v2</em>. Once that’s done, Kubernetes handles the termination of the <em>v1</em> pods. Finally, all the old pods are gone and only the new pods are running.</p>&#13;
&#13;
<figure><div class="figure" id="fig_kubernetes_deployment_default">&#13;
<img alt="When web-api:v2 is deployed, new pods are listed with a status of ContainerCreating, then Running. Once web-api:v2 is running, web-api:v2 gets a status of Terminating, then the pods are removed." src="assets/dsnj_0704.png"/>&#13;
<h6><span class="label">Figure 7-4. </span>How deployments affect pod state</h6>&#13;
</div></figure>&#13;
&#13;
<p>At this point, you can send a request to one of your pods by using the existing <em>web-api-service</em> service.</p>&#13;
<div style="page-break-after: always;"/>&#13;
&#13;
<p>You can do so by running the following command to request your newly added <em>/hello</em> route:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>curl <code class="sb">`</code>minikube service web-api-service --url<code class="sb">`</code>/hello</pre>&#13;
&#13;
<p>You should see the message “Hello” displayed in your terminal.</p>&#13;
&#13;
<p>One thing to note is that when you deployed a new version of the application, the old replica set has been left behind! It has been updated to have a scale of zero. You can see this happen when you run the following command to list your replica sets:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl get rs -l <code class="nv">app</code><code class="o">=</code>web-api</pre>&#13;
&#13;
<p>In my case, I get the following replica sets in return:</p>&#13;
&#13;
<pre data-type="programlisting">NAME                 DESIRED   CURRENT   READY   AGE&#13;
web-api-6cdc56746b   0         0         0       9m21s&#13;
web-api-999f78685    3         3         3       3m8s</pre>&#13;
&#13;
<p>Here the new replica set <em>web-api-999f78685</em> has three instances and the old set <em>web-api-6cdc56746b</em> has zero. You can also see this happen when you read the list of pods in your cluster. By default the pods are named with the following pattern when they’re created as part of a deployment: <code>&lt;DEPLOYMENT&gt;-&lt;REPLICA_SET&gt;-&lt;RANDOM&gt;</code>.</p>&#13;
&#13;
<p>The replica set names are actually fairly consistent. If you were to, for example, modify the <em>web-api-deployment.yml</em> file to revert it back to having an image of <em>web-api:v1</em>, the previous replica set would get used again and the new replica set would get scaled down <a data-primary="deployments" data-secondary="applications" data-startref="app_new" data-tertiary="new versions" data-type="indexterm" id="idm46291180809336"/><a data-primary="applications" data-secondary="new versions" data-startref="app_new1" data-type="indexterm" id="idm46291180807816"/>to zero.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Rolling Back Application Deployments" data-type="sect2"><div class="sect2" id="idm46291180917224">&#13;
<h2>Rolling Back Application Deployments</h2>&#13;
&#13;
<p>If you’re anything like me, you will occasionally merge some bad code, forget to catch an exception, or will otherwise release a faulty version of an application to production. When this happens, such a broken version needs to be reverted to a previous known-good version of the application. This act of reverting a bad version <a data-primary="applications" data-secondary="deployment rollbacks" data-type="indexterm" id="app_roll"/><a data-primary="deployments" data-secondary="applications" data-tertiary="rollbacks" data-type="indexterm" id="app_roll2"/><a data-primary="rollbacks" data-type="indexterm" id="app_roll3"/>to a good version is known as a <em>rollback</em>.</p>&#13;
&#13;
<p>Docker already maintains a list of previous images, which is nice, but an image doesn’t contain everything required to represent a container. For example, the <em>web-api</em> service requires some metadata such as environment variables and a port to listen on—things that are defined in the deployment YAML <a data-primary="YAML" data-secondary="Docker images" data-type="indexterm" id="idm46291180753512"/>file. If you had lost this YAML file and only had the Docker image, would you be confident that you could rebuild and deploy a properly configured container? What if you were also dealing with the stress of a production incident?</p>&#13;
&#13;
<p>Luckily for you and me, Kubernetes retains information about previous deployments. This allows you to roll back to a previous deployment by executing a few commands.</p>&#13;
&#13;
<p>But first, it’s time to release a broken application. This version of the application adds a new endpoint <em>/kill</em> that causes the process to immediately exit. Run the following commands to amend the <em>web-api</em> service with the new route and to build a new version of the container:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code><code class="nb">cd </code>web-api&#13;
<code class="nv">$ </code><code class="nb">echo</code> <code class="s2">"server.get('/kill', async () =&gt; { process.exit(42); });"</code> <code class="se">\</code>&#13;
  &gt;&gt; consumer-http-basic.js&#13;
<code class="nv">$ </code><code class="nb">eval</code> <code class="k">$(</code>minikube -p minikube docker-env<code class="k">)</code> <code class="c"># ensure Minikube docker</code>&#13;
<code class="nv">$ </code>docker build -t web-api:v3 .</pre>&#13;
&#13;
<p>Once your image has been built, you’re ready to perform another deployment. Edit the <em>web-api-deployment.yml</em> file again, this time changing the image line from <em>web-api:v2</em> to <em>web-api:v3</em>. Once that’s done, run the following command to perform another deployment:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl apply -f web-api-deployment.yml --record<code class="o">=</code><code class="nb">true</code></pre>&#13;
&#13;
<p>Note that this time the <code>--record=true</code> flag has been added. You’ll see what this flag is used for in a moment. Once the new version of the application deploys, you’re ready to test the new endpoint. Make the following request:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>curl <code class="sb">`</code>minikube service web-api-service --url<code class="sb">`</code>/kill</pre>&#13;
&#13;
<p>Once you run that command, you should get an error back that curl received an empty reply from the server. Next, run the command <code><strong>kubectl get pods -l app=web-api</strong></code> to get a list of your pods again. When I run this command, I get the following results:</p>&#13;
&#13;
<pre data-type="programlisting">NAME                       READY   STATUS    RESTARTS   AGE&#13;
web-api-6bdcb55856-b6rtw   1/1     Running   0          6m3s&#13;
web-api-6bdcb55856-ctqmr   1/1     Running   1          6m7s&#13;
web-api-6bdcb55856-zfscv   1/1     Running   0          6m5s</pre>&#13;
&#13;
<p>Notice how the second entry has a restart count of one, while the others have a restart count of zero. This is because the container had crashed and Kubernetes automatically restarted it for me. Depending on how quickly you ran the command, you might either see the restart count set to one or the count set to zero but with a status of Error—an indication that Kubernetes hasn’t yet restarted the container.</p>&#13;
&#13;
<p>The investigative methods were a little contrived, but at this point you’ve confirmed that <em>v3</em> of the application is broken and that it should be rolled back. In a production setting, you would hopefully be proactively alerted, like what you had set up in <a data-type="xref" href="ch04.html#ch_monitoring_sec_alert">“Alerting with Cabot”</a>.</p>&#13;
&#13;
<p>Kubectl provides a subcommand for viewing a deployment’s history. Run the following command to get the history of your <em>web-api</em> deployment:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl rollout <code class="nb">history </code>deployment.v1.apps/web-api</pre>&#13;
&#13;
<p>When I run the command, I get the following results:</p>&#13;
&#13;
<pre data-type="programlisting">REVISION  CHANGE-CAUSE&#13;
7         &lt;none&gt;&#13;
8         &lt;none&gt;&#13;
9         kubectl apply --filename=web-api-deployment.yml --record=true</pre>&#13;
&#13;
<p>You should get three different values in your revision column from what I have. In this case, I can see that there are three revisions, each with an incrementing counter to identify it, and that the third revision displays the command I had executed in the Change Cause column. The <code>--record=true</code> flag tells Kubectl to keep track of the command used to trigger the deployment. This can be more useful if the filename contains the application version, for example.</p>&#13;
&#13;
<p>In my case, revision number 9 is the last one that I made, which must correlate to <em>v3</em> of the application. The one before it, revision 8, therefore must correlate to <em>v2</em> of the application. So, in order to deploy a working version of the application, I need to roll back from release 9 to release 8.</p>&#13;
&#13;
<p>Run the following command to roll back your application deployment, replacing <code>&lt;RELEASE_NUMBER&gt;</code> with the second release number in your list (in my case, 8):</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl rollout undo deployment.v1.apps/web-api <code class="se">\</code>&#13;
  --to-revision<code class="o">=</code>&lt;RELEASE_NUMBER&gt;</pre>&#13;
&#13;
<p>Once you run that command, you should get the output message of <span class="keep-together"><code>deployment.apps/web-api rolled back</code></span>. Once that happens, run the <code><strong>kubectl rollout history deployment.v1.apps/web-api</strong></code> command again to see your list of deployments. In my case, I get the following list:</p>&#13;
&#13;
<pre data-type="programlisting">REVISION  CHANGE-CAUSE&#13;
7         &lt;none&gt;&#13;
9         kubectl apply --filename=web-api-deployment.yml --record=true&#13;
10        &lt;none&gt;</pre>&#13;
&#13;
<p>In this example, revision 8 has been removed from the list and has been moved to the end as revision 10. Think of this as a timeline where older revisions are at the top and newer revisions are at the bottom and where revision counts always increment and duplicate revisions aren’t listed.</p>&#13;
&#13;
<p>To prove that the pods have been reverted to <em>v2</em> of the application, make that same curl request to <em>/kill</em> one more time. This time, instead of taking out a server, you should get a 404 error.</p>&#13;
&#13;
<p>And there you have it; you’ve successfully reverted a bad application deployment!</p>&#13;
&#13;
<p>Now that you’re done with Kubernetes, you can either leave it running on your machine or clean up all the services that are currently running in the background. Personally, I find that my battery life is cut in half with it running. Run the following commands to delete all of the Kubernetes objects that you’ve created:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>kubectl delete services recipe-api-service&#13;
<code class="nv">$ </code>kubectl delete services web-api-service&#13;
<code class="nv">$ </code>kubectl delete deployment recipe-api&#13;
<code class="nv">$ </code>kubectl delete deployment web-api&#13;
<code class="nv">$ </code>kubectl delete ingress web-api-ingress&#13;
<code class="nv">$ </code>minikube stop&#13;
<code class="nv">$ </code>minikube delete</pre>&#13;
&#13;
<p>You should also switch to the terminal where you had run <code>minikube dashboard</code> and kill it with Ctrl + C.</p>&#13;
&#13;
<p>You might also want to disable Kubernetes <a data-primary="applications" data-secondary="rollbacks" data-startref="app_roll" data-type="indexterm" id="idm46291180598344"/><a data-primary="deployments" data-secondary="applications" data-startref="app_roll2" data-tertiary="rollbacks" data-type="indexterm" id="idm46291180597304"/><a data-primary="rollbacks" data-startref="app_roll3" data-type="indexterm" id="idm46291180595816"/>if you’re using Docker Desktop. Open the GUI preferences panel, visit the Kubernetes section and uncheck the Enable Kubernetes option, and then apply the changes.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm46291182288360"><sup><a href="ch07.html#idm46291182288360-marker">1</a></sup> The MacOS variant also installs the HyperKit hypervisor, which is necessary to later use the Ingress feature.</p></div></div></section></body></html>