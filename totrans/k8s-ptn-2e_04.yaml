- en: Chapter 2\. Predictable Demands
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章\. 可预测需求
- en: The foundation of successful application deployment, management, and coexistence
    on a shared cloud environment is dependent on identifying and declaring the application
    resource requirements and runtime dependencies. This *Predictable Demands* pattern
    indicates how you should declare application requirements, whether they are hard
    runtime dependencies or resource requirements. Declaring your requirements is
    essential for Kubernetes to find the right place for your application within the
    cluster.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在共享云环境中成功部署、管理和共存应用程序的基础取决于识别和声明应用程序的资源需求和运行时依赖。这种*可预测需求*模式表明了您应如何声明应用程序的需求，无论是硬运行时依赖还是资源需求。声明您的需求对于
    Kubernetes 在集群中找到适当位置以运行您的应用程序至关重要。
- en: Problem
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Kubernetes can manage applications written in different programming languages
    as long as the application can be run in a container. However, different languages
    have different resource requirements. Typically, a compiled language runs faster
    and often requires less memory compared to just-in-time runtimes or interpreted
    languages. Considering that many modern programming languages in the same category
    have similar resource requirements, from a resource consumption point of view,
    more important aspects are the domain, the business logic of an application, and
    the actual implementation details.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 可以管理用不同编程语言编写的应用程序，只要这些应用程序可以在容器中运行。然而，不同语言具有不同的资源需求。通常，编译语言运行速度更快，通常比即时运行时或解释语言需要更少的内存。考虑到同一类别中许多现代编程语言具有类似的资源需求，从资源消耗的角度来看，更重要的方面是应用程序的领域、业务逻辑和实际实现细节。
- en: Besides resource requirements, application runtimes also have dependencies on
    platform-managed capabilities like data storage or application configuration.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 除了资源需求外，应用程序运行时还依赖于平台管理的能力，如数据存储或应用程序配置。
- en: Solution
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案
- en: Knowing the runtime requirements for a container is important mainly for two
    reasons. First, with all the runtime dependencies defined and resource demands
    envisaged, Kubernetes can make intelligent decisions about where to place a container
    on the cluster for the most efficient hardware utilization. In an environment
    with shared resources among a large number of processes with different priorities,
    the only way to ensure a successful coexistence is to know the demands of every
    process in advance. However, intelligent placement is only one side of the coin.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 了解容器的运行时需求主要有两个重要原因。首先，通过定义所有运行时依赖和资源需求，Kubernetes 可以智能地决定在集群中何处放置容器，以实现最高效的硬件利用率。在具有不同优先级的大量进程共享资源的环境中，确保成功共存的唯一方法是提前了解每个进程的需求。然而，智能放置只是其中一方面。
- en: Container resource profiles are also essential for capacity planning. Based
    on the particular service demands and the total number of services, we can do
    some capacity planning for different environments and come up with the most cost-effective
    host profiles to satisfy the entire cluster demand. Service resource profiles
    and capacity planning go hand in hand for successful cluster management in the
    long term.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 容器资源配置文件对于容量规划也是至关重要的。根据特定服务的需求和服务的总数，我们可以为不同的环境做一些容量规划，并提出最具成本效益的主机配置文件，以满足整个集群的需求。服务资源配置文件和容量规划手段长期成功管理集群密不可分。
- en: Before diving into resource profiles, let’s look at declaring runtime dependencies.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解资源配置文件之前，让我们看看如何声明运行时依赖。
- en: Runtime Dependencies
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行时依赖
- en: One of the most common runtime dependencies is file storage for saving application
    state. Container filesystems are ephemeral and are lost when a container is shut
    down. Kubernetes offers volume as a Pod-level storage utility that survives container
    restarts.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的运行时依赖之一是文件存储，用于保存应用程序状态。容器文件系统是临时的，在容器关闭时会丢失。Kubernetes 提供了卷作为 Pod 级别的存储工具，可在容器重新启动时保留数据。
- en: The most straightforward type of volume is `emptyDir`, which lives as long as
    the Pod lives. When the Pod is removed, its content is also lost. The volume needs
    to be backed by another kind of storage mechanism to survive Pod restarts. If
    your application needs to read or write files to such long-lived storage, you
    must declare that dependency explicitly in the container definition using volumes,
    as shown in [Example 2-1](#ex-dependency-pv).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最直接的卷类型是 `emptyDir`，它与 Pod 同存亡。当 Pod 被移除时，其内容也会丢失。该卷需要由另一种存储机制支持，以便在 Pod 重启时生存下来。如果您的应用程序需要读取或写入文件到这种长期存储中，必须在容器定义中明确声明这种依赖关系，如[示例
    2-1](#ex-dependency-pv)所示。
- en: Example 2-1\. Dependency on a PersistentVolume
  id: totrans-12
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-1\. 对 PersistentVolume 的依赖
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_predictable_demands_CO1-1)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_predictable_demands_CO1-1)'
- en: Dependency of a PersistentVolumeClaim (PVC) to be present and bound.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: PersistentVolumeClaim (PVC) 的依赖要求其存在且已绑定。
- en: The scheduler evaluates the kind of volume a Pod requires, which affects where
    the Pod gets placed. If the Pod needs a volume that is not provided by any node
    on the cluster, the Pod is not scheduled at all. Volumes are an example of a runtime
    dependency that affects what kind of infrastructure a Pod can run and whether
    the Pod can be scheduled at all.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器评估 Pod 需要的卷类型，这影响 Pod 放置的位置。如果 Pod 需要的卷在集群的任何节点上都没有提供，那么根本不会调度该 Pod。卷是运行时依赖关系的一个例子，它影响
    Pod 可以运行在什么样的基础设施上，以及是否可以被调度。
- en: A similar dependency happens when you ask Kubernetes to expose a container port
    on a specific port on the host system through `hostPort`. The usage of a `hostPort`
    creates another runtime dependency on the nodes and limits where a Pod can be
    scheduled. `hostPort` reserves the port on each node in the cluster and is limited
    to a maximum of one Pod scheduled per node. Because of port conflicts, you can
    scale to as many Pods as there are nodes in the Kubernetes cluster.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当您要求 Kubernetes 通过 `hostPort` 在主机系统上的特定端口上公开容器端口时，会发生类似的依赖关系。使用 `hostPort` 在集群中的每个节点上保留端口，并且每个节点最多只能调度一个
    Pod。由于端口冲突，您可以扩展到 Kubernetes 集群中的节点数量相同的 Pod。
- en: Configurations are another type of dependency. Almost every application needs
    some configuration information, and the recommended solution offered by Kubernetes
    is through ConfigMaps. Your services need to have a strategy for consuming settings—either
    through environment variables or the filesystem. In either case, this introduces
    a runtime dependency of your container to the named ConfigMaps. If not all of
    the expected ConfigMaps are created, the containers are scheduled on a node, but
    they do not start up.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 配置是另一种依赖类型。几乎每个应用程序都需要一些配置信息，Kubernetes 提供的推荐解决方案是通过 ConfigMaps。您的服务需要一种消耗设置的策略——通过环境变量或文件系统。无论哪种情况，这都会将容器对命名
    ConfigMaps 的命名引入运行时依赖。如果未创建所有预期的 ConfigMaps，容器会被调度到节点上，但不会启动。
- en: Similar to ConfigMaps, Secrets offer a slightly more secure way of distributing
    environment-specific configurations to a container. The way to consume a Secret
    is the same as it is for ConfigMaps, and using a Secret introduces the same kind
    of dependency from a container to a namespace.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与 ConfigMaps 类似，Secrets 提供了一种稍微更安全的方法来向容器分发特定于环境的配置。使用 Secret 的方式与 ConfigMaps
    的方式相同，并且使用 Secret 从容器到命名空间引入了相同类型的依赖关系。
- en: ConfigMaps and Secrets are explained in more detail in [Chapter 20, “Configuration
    Resource”](ch20.html#ConfigurationResource), and [Example 2-2](#ex-dependency-configmap)
    shows how these resources are used as runtime dependencies.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMaps 和 Secrets 在[第 20 章，“配置资源”](ch20.html#ConfigurationResource)中有更详细的解释，[示例
    2-2](#ex-dependency-configmap)展示了这些资源作为运行时依赖的使用方式。
- en: Example 2-2\. Dependency on a ConfigMap
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-2\. 对 ConfigMap 的依赖
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_predictable_demands_CO2-1)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_predictable_demands_CO2-1)'
- en: Mandatory dependency on the ConfigMap `random-generator-config`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对 ConfigMap `random-generator-config` 的强制依赖。
- en: While the creation of ConfigMap and Secret objects are simple deployment tasks
    we have to perform, cluster nodes provide storage and port numbers. Some of these
    dependencies limit where a Pod gets scheduled (if anywhere at all), and other
    dependencies may prevent the Pod from starting up. When designing your containerized
    applications with such dependencies, always consider the runtime constraints they
    will create later.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然创建 ConfigMap 和 Secret 对象是我们必须执行的简单部署任务，但集群节点提供存储和端口号。其中一些依赖限制了 Pod 可以调度的位置（如果有的话），而其他依赖可能会阻止
    Pod 启动。在设计带有这些依赖的容器化应用程序时，始终要考虑它们将在运行时创建的约束条件。
- en: Resource Profiles
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源配置文件
- en: Specifying container dependencies such as ConfigMap, Secret, and volumes is
    straightforward. We need some more thinking and experimentation for figuring out
    the resource requirements of a container. Compute resources in the context of
    Kubernetes are defined as something that can be requested by, allocated to, and
    consumed from a container. The resources are categorized as *compressible* (i.e.,
    can be throttled, such as CPU or network bandwidth) and *incompressible* (i.e.,
    cannot be throttled, such as memory).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 指定诸如 ConfigMap、Secret 和卷等容器依赖关系非常简单。我们需要更多的思考和实验来确定容器的资源需求。在 Kubernetes 的上下文中，计算资源被定义为容器可以请求、分配和消耗的东西。这些资源被分类为*可压缩*（即可以被限制，如
    CPU 或网络带宽）和*不可压缩*（即不能被限制，如内存）。
- en: Making the distinction between compressible and incompressible resources is
    important. If your containers consume too many compressible resources such as
    CPU, they are throttled, but if they use too many incompressible resources (such
    as memory), they are killed (as there is no other way to ask an application to
    release allocated memory).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 区分可压缩和不可压缩资源的区别非常重要。如果您的容器消耗了太多的可压缩资源，例如 CPU，它们将被限制，但如果它们使用了太多的不可压缩资源（如内存），它们将被终止（因为没有其他方法要求应用程序释放已分配的内存）。
- en: Based on the nature and the implementation details of your application, you
    have to specify the minimum amount of resources that are needed (called `requests`)
    and the maximum amount it can grow up to (the `limits`). Every container definition
    can specify the amount of CPU and memory it needs in the form of a request and
    limit. At a high level, the concept of `requests`/`limits` is similar to soft/hard
    limits. For example, similarly, we define heap size for a Java application by
    using the `-Xms` and `-Xmx` command-line options.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的应用程序的性质和实现细节，您必须指定所需的最小资源量（称为 `requests`）以及它可以增长到的最大量（`limits`）。每个容器定义可以指定它所需的
    CPU 和内存量，形式为请求和限制。在高级别上，`requests`/`limits` 的概念类似于软限制/硬限制。例如，类似地，我们通过使用 `-Xms`
    和 `-Xmx` 命令行选项为 Java 应用程序定义堆大小。
- en: The `requests` amount (but not `limits`) is used by the scheduler when placing
    Pods to nodes. For a given Pod, the scheduler considers only nodes that still
    have enough capacity to accommodate the Pod and all of its containers by summing
    up the requested resource amounts. In that sense, the `requests` field of each
    container affects where a Pod can be scheduled or not. [Example 2-3](#ex-resource-limits)
    shows how such limits are specified for a Pod.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`requests` 量（但不包括 `limits`）在调度 Pod 到节点时由调度程序使用。对于给定的 Pod，调度程序仅考虑仍然具有足够容量来容纳
    Pod 及其所有容器的节点，通过汇总请求的资源量。从这个意义上说，每个容器的 `requests` 字段影响 Pod 是否可以被调度。'
- en: Example 2-3\. Resource limits
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-3\. 资源限制
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_predictable_demands_CO3-1)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_predictable_demands_CO3-1)'
- en: Initial resource request for CPU and memory.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 初始的 CPU 和内存资源请求。
- en: '[![2](assets/2.png)](#co_predictable_demands_CO3-2)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_predictable_demands_CO3-2)'
- en: Upper limit until we want our application to grow at max. We don’t specify CPU
    limits by intention.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 直到我们希望我们的应用程序增长到最大的上限。我们故意不指定 CPU 的限制。
- en: 'The following types of resources can be used as keys in the `requests` and
    `limits` specification:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的资源类型可以作为 `requests` 和 `limits` 规范中的键使用：
- en: '`memory`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`memory`'
- en: 'This type is for the heap memory demands of your application, including volumes
    of type `emptyDir` with the configuration `medium: Memory`. Memory resources are
    incompressible, so containers that exceed their configured memory limit will trigger
    the Pod to be evicted; i.e., it gets deleted and recreated potentially on a different
    node.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '该类型用于应用程序的堆内存需求，包括配置为 `medium: Memory` 的 `emptyDir` 类型卷。内存资源是不可压缩的，因此超出配置的内存限制的容器将触发
    Pod 被驱逐；即，它可能会被删除并且可能重新创建在另一个节点上。'
- en: '`cpu`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`cpu`'
- en: The `cpu` type is used to specify the range of needed CPU cycles for your application.
    However, it is a compressible resource, which means that in an overcommit situation
    for a node, all assigned CPU slots of all running containers are throttled relative
    to their specified requests. Therefore, it is highly recommended that you set
    `requests` for the CPU resource but *no* `limits` so that they can benefit from
    all excess CPU resources that otherwise would be wasted.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`cpu` 类型用于指定应用程序所需的 CPU 循环范围。然而，它是一个可压缩资源，这意味着在节点超分配的情况下，所有运行容器的分配 CPU 槽位将按照其指定的请求进行限制。因此，强烈建议您为
    CPU 资源设置 `requests`，但是不要设置 `limits`，这样它们可以从所有多余的 CPU 资源中受益，否则这些资源将被浪费。'
- en: '`ephemeral-storage`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`ephemeral-storage`'
- en: Every node has some filesystem space dedicated for ephemeral storage that holds
    logs and writable container layers. `emptyDir` volumes that are not stored in
    a memory filesystem also use ephemeral storage. With this request and limit type,
    you can specify the application’s minimal and maximal needs. `ephemeral-storage`
    resources are not compressible and will cause a Pod to be evicted from the node
    if it uses more storage than specified in its `limit`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点都有一些专门用于临时存储的文件系统空间，用于保存日志和可写容器层。未存储在内存文件系统中的 `emptyDir` 卷也会使用临时存储。使用此请求和限制类型，您可以指定应用程序的最小和最大需求。`ephemeral-storage`
    资源是不可压缩的，如果 Pod 使用的存储空间超过其 `limit` 中指定的值，则会导致 Pod 从节点驱逐。
- en: '`hugepage-<size>`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`hugepage-<size>`'
- en: '*Huge pages* are large, contiguous pre-allocated pages of memory that can be
    mounted as volumes. Depending on your Kubernetes node configuration, several sizes
    of huge pages are available, like 2 MB and 1 GB pages. You can specify a request
    and limit for how many of a certain type of huge pages you want to consume (e.g.,
    `hugepages-1Gi: 2Gi` for requesting two 1 GB huge pages). Huge pages can’t be
    overcommitted, so the request and limit must be the same.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*Huge pages* 是大的、连续预分配的内存页，可以作为卷挂载。根据您的 Kubernetes 节点配置，有多种大小的 huge pages 可供选择，如
    2 MB 和 1 GB 的页。您可以指定请求和限制，以确定您想要消耗某种类型的 huge pages 的数量（例如，`hugepages-1Gi: 2Gi`
    表示请求两个 1 GB 的 huge pages）。Huge pages 不能超分配，因此请求和限制必须相同。'
- en: 'Depending on whether you specify the `requests`, the `limits`, or both, the
    platform offers three types of Quality of Service (QoS):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您是否指定了 `requests`、`limits` 或两者，平台提供三种类型的服务质量（QoS）：
- en: Best-Effort
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Best-Effort
- en: Pods that do not have any requests and limits set for its containers have a
    QoS of *Best-Effort*. Such a *Best-Effort* Pod is considered the lowest priority
    and is most likely killed first when the node where the Pod is placed runs out
    of incompressible resources.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其容器未设置任何请求和限制的 Pod，其 QoS 是 *Best-Effort*。这样的 *Best-Effort* Pod 被认为是最低优先级的，当放置
    Pod 的节点耗尽不可压缩资源时，很可能首先被杀死。
- en: Burstable
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Burstable
- en: A Pod that defines an unequal amount for `requests` and `limits` values (and
    `limits` is larger than `requests`, as expected) are tagged as *Burstable*. Such
    a Pod has minimal resource guarantees but is also willing to consume more resources
    up to its `limit` when available. When the node is under incompressible resource
    pressure, these Pods are likely to be killed if no *Best-Effort* Pods remain.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `requests` 和 `limits` 值不相等（并且如预期的那样，`limits` 大于 `requests`）的 Pod 被标记为 *Burstable*。这样的
    Pod 具有最小的资源保证，但也愿意在可用时消耗更多资源直到其 `limit`。当节点处于不可压缩资源压力下时，这些 Pod 如果没有 *Best-Effort*
    Pod，则可能会被杀死。
- en: Guaranteed
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Guaranteed
- en: A Pod that has an equal amount of `request` and `limit` resources belongs to
    the *Guaranteed* QoS category. These are the highest-priority Pods and are guaranteed
    not to be killed before *Best-Effort* and *Burstable* Pods. This QoS mode is the
    best option for your application’s memory resources, as it entails the least surprise
    and avoids out-of-memory triggered evictions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有相等的 `request` 和 `limit` 资源的 Pod 属于 *Guaranteed* QoS 类别。这些是最高优先级的 Pod，在 *Best-Effort*
    和 *Burstable* Pod 之前保证不会被杀死。对于您的应用程序的内存资源，这种 QoS 模式是最佳选择，因为它涉及最少的意外并避免由于内存不足而触发的驱逐。
- en: So the resource characteristics you define or omit for the containers have a
    direct impact on its QoS and define the relative importance of the Pod in the
    event of resource starvation. Define your Pod resource requirements with this
    consequence in mind.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您为容器定义或省略的资源特性直接影响其 QoS，并定义 Pod 在资源匮乏情况下的相对重要性。考虑到这一后果，请定义您的 Pod 资源需求。
- en: Pod Priority
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod 优先级
- en: We explained how container resource declarations also define Pods’ QoS and affect
    the order in which the Kubelet kills the container in a Pod in case of resource
    starvation. Two other related concepts are Pod priority and preemption. *Pod priority*
    allows you to indicate the importance of a Pod relative to other Pods, which affects
    the order in which Pods are scheduled. Let’s see that in action in [Example 2-4](#ex-predictable-demands-pod-priority).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解释了容器资源声明如何定义 Pods 的 QoS 并在资源匮乏时影响 Kubelet 杀死 Pod 中的容器的顺序。另外两个相关概念是 Pod 优先级
    和 抢占。*Pod 优先级* 允许您指示 Pod 相对于其他 Pods 的重要性，这影响 Pods 被调度的顺序。让我们在 [示例 2-4](#ex-predictable-demands-pod-priority)
    中看看它是如何运作的。
- en: Example 2-4\. Pod priority
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-4\. Pod 优先级
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_predictable_demands_CO4-1)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_predictable_demands_CO4-1)'
- en: The name of the priority class object.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 优先级类对象的名称。
- en: '[![2](assets/2.png)](#co_predictable_demands_CO4-2)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_predictable_demands_CO4-2)'
- en: The priority value of the object.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对象的优先级值。
- en: '[![3](assets/3.png)](#co_predictable_demands_CO4-3)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_predictable_demands_CO4-3)'
- en: '`globalDefault` set to `true` is used for Pods that do not specify a `priorityClassName`.
    Only one PriorityClass can have `globalDefault` set to `true`.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`globalDefault` 设为 `true` 用于未指定 `priorityClassName` 的 Pods。只能有一个 PriorityClass
    的 `globalDefault` 设为 `true`。'
- en: '[![4](assets/4.png)](#co_predictable_demands_CO4-4)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_predictable_demands_CO4-4)'
- en: The priority class to use with this Pod, as defined in PriorityClass resource.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 用于此 Pod 的优先级类，如在 PriorityClass 资源中定义。
- en: We created a PriorityClass, a non-namespaced object for defining an integer-based
    priority. Our PriorityClass is named `high-priority` and has a priority of 1,000\.
    Now we can assign this priority to Pods by its name as `priorityClassName:` `high-priority`.
    PriorityClass is a mechanism for indicating the importance of Pods relative to
    one another, where the higher value indicates more important Pods.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个 PriorityClass，这是一个非命名空间对象，用于定义基于整数的优先级。我们的 PriorityClass 名为 `high-priority`，优先级为
    1,000。现在我们可以通过其名称将此优先级分配给 Pods，例如 `priorityClassName:` `high-priority`。PriorityClass
    是一种指示 Pods 相对重要性的机制，其中更高的值表示更重要的 Pods。
- en: Pod priority affects the order in which the scheduler places Pods on nodes.
    First, the priority admission controller uses the `priorityClassName` field to
    populate the priority value for new Pods. When multiple Pods are waiting to be
    placed, the scheduler sorts the queue of pending Pods by highest priority first.
    Any pending Pod is picked before any other pending Pod with lower priority in
    the scheduling queue, and if there are no constraints preventing it from scheduling,
    the Pod gets scheduled.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 优先级影响调度程序在节点上放置 Pods 的顺序。首先，优先级准入控制器使用 `priorityClassName` 字段为新 Pods 填充优先级值。当多个
    Pods 等待放置时，调度程序首先按最高优先级对待处理 Pods 排序。任何等待处理的 Pod 都会在排队中的任何其他优先级较低的 Pod 之前被选中，并且如果没有阻止其调度的约束条件，则会被调度。
- en: Here comes the critical part. If there are no nodes with enough capacity to
    place a Pod, the scheduler can preempt (remove) lower-priority Pods from nodes
    to free up resources and place Pods with higher priority. As a result, the higher-priority
    Pod might be scheduled sooner than Pods with a lower priority if all other scheduling
    requirements are met. This algorithm effectively enables cluster administrators
    to control which Pods are more critical workloads and place them first by allowing
    the scheduler to evict Pods with lower priority to make room on a worker node
    for higher-priority Pods. If a Pod cannot be scheduled, the scheduler continues
    with the placement of other lower-priority Pods.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来看关键部分。如果没有节点具有足够的容量来放置一个 Pod，则调度程序可以抢占（移除）节点上的优先级较低的 Pods，以释放资源并放置优先级较高的
    Pods。因此，如果满足所有其他调度要求，则具有更高优先级的 Pod 可能比具有较低优先级的 Pods 更早地被调度。该算法有效地使集群管理员能够通过允许调度程序驱逐优先级较低的
    Pods 为更关键的工作负载腾出空间，并首先放置它们。如果无法调度一个 Pod，则调度程序继续安排其他优先级较低的 Pods。
- en: 'Suppose you want your Pod to be scheduled with a particular priority but don’t
    want to evict any existing Pods. In that case, you can mark a PriorityClass with
    the field `preemptionPolicy: Never`. Pods assigned to this priority class will
    not trigger any eviction of running Pods but will still get scheduled according
    to their priority value.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '假设您希望您的 Pod 以特定优先级调度，但不想驱逐任何现有的 Pods。在这种情况下，您可以将 PriorityClass 标记为字段 `preemptionPolicy:
    Never`。分配到此优先级类别的 Pods 将不会触发任何正在运行的 Pods 的驱逐，但仍会根据其优先级值进行调度。'
- en: Pod QoS (discussed previously) and Pod priority are two orthogonal features
    that are not connected and have only a little overlap. QoS is used primarily by
    the Kubelet to preserve node stability when available compute resources are low.
    The Kubelet first considers QoS and then the PriorityClass of Pods before eviction.
    On the other hand, the scheduler eviction logic ignores the QoS of Pods entirely
    when choosing preemption targets. The scheduler attempts to pick a set of Pods
    with the lowest priority possible that satisfies the needs of higher-priority
    Pods waiting to be placed.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Pod QoS（前文讨论过）和 Pod 优先级是两个独立的特性，它们没有连接并且只有少量重叠。QoS 主要由 Kubelet 在可用计算资源不足时用于保护节点稳定性。Kubelet
    在驱逐之前首先考虑 QoS，然后再考虑 Pods 的 PriorityClass。另一方面，调度程序的驱逐逻辑在选择抢占目标时完全忽略 Pods 的 QoS。调度程序尝试选择一组具有最低优先级的
    Pods，以满足等待放置的更高优先级 Pods 的需求。
- en: When Pods have a priority specified, it can have an undesired effect on other
    Pods that are evicted. For example, while a Pod’s graceful termination policies
    are respected, the PodDisruptionBudget as discussed in [Chapter 10, “Singleton
    Service”](ch10.html#SingletonService), is not guaranteed, which could break a
    lower-priority clustered application that relies on a quorum of Pods.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Pod 指定了优先级时，可能会对被驱逐的其他 Pod 产生不良影响。例如，尽管尊重了 Pod 的优雅终止策略，但如[第10章，“单例服务”](ch10.html#SingletonService)所述的
    PodDisruptionBudget并不受保证，这可能会破坏依赖于一组 Pod 团队的较低优先级集群应用。
- en: Another concern is a malicious or uninformed user who creates Pods with the
    highest possible priority and evicts all other Pods. To prevent that, ResourceQuota
    has been extended to support PriorityClass, and higher-priority numbers are reserved
    for critical system-Pods that should not usually be preempted or evicted.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是恶意或不知情的用户创建具有最高优先级的 Pods 并驱逐所有其他 Pods。为防止这种情况发生，ResourceQuota 已扩展以支持 PriorityClass，并且较高优先级的数字保留用于不应通常被抢占或驱逐的关键系统
    Pods。
- en: In conclusion, Pod priorities should be used with caution because user-specified
    numerical priorities that guide the scheduler and Kubelet about which Pods to
    place or to kill are subject to gaming by users. Any change could affect many
    Pods and could prevent the platform from delivering predictable service-level
    agreements.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，应谨慎使用 Pod 优先级，因为用户指定的数值优先级会指导调度程序和 Kubelet 放置或终止哪些 Pods，用户可能会利用这一点进行操作。任何更改都可能影响多个
    Pods，并可能阻止平台提供可预测的服务级别协议。
- en: Project Resources
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目资源
- en: Kubernetes is a self-service platform that enables developers to run applications
    as they see suitable on the designated isolated environments. However, working
    in a shared multitenanted platform also requires the presence of specific boundaries
    and control units to prevent some users from consuming all the platform’s resources.
    One such tool is ResourceQuota, which provides constraints for limiting the aggregated
    resource consumption in a namespace. With ResourceQuotas, the cluster administrators
    can limit the total sum of computing resources (CPU, memory) and storage consumed.
    It can also limit the total number of objects (such as ConfigMaps, Secrets, Pods,
    or Services) created in a namespace. [Example 2-5](#ex-predictable-demands-resourcequota)
    shows an instance that limits the usage of certain resources. See the official
    Kubernetes documentation on [Resource Quotas](https://oreil.ly/TLRMe) for the
    full list of supported resources for which you can restrict usage with ResourceQuotas.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个自助服务平台，使开发人员可以在指定的隔离环境中按其需求运行应用程序。然而，在共享的多租户平台上工作也需要特定边界和控制单元，以防止某些用户消耗平台的所有资源。其中一种工具是
    ResourceQuota，它提供了命名空间中限制聚合资源消耗的约束条件。通过 ResourceQuotas，集群管理员可以限制在命名空间中消耗的计算资源总和（如
    CPU、内存）和存储。它还可以限制创建在命名空间中的对象总数（如 ConfigMaps、Secrets、Pods 或 Services）。[示例2-5](#ex-predictable-demands-resourcequota)展示了限制某些资源使用的实例。请参阅官方
    Kubernetes 文档中有关 [Resource Quotas](https://oreil.ly/TLRMe) 的完整支持资源列表，您可以使用 ResourceQuotas
    限制这些资源的使用。
- en: Example 2-5\. Definition of resource constraints
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_predictable_demands_CO5-1)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Namespace to which resource constraints are applied.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_predictable_demands_CO5-2)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Allow four active Pods in this namespace.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_predictable_demands_CO5-3)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: The sum of all memory limits of all Pods in this namespace must not be more
    than 5 GB.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Another helpful tool in this area is LimitRange, which allows you to set resource
    usage limits for each type of resource. In addition to specifying the minimum
    and maximum permitted amounts for different resource types and the default values
    for these resources, it also allows you to control the ratio between the `requests`
    and `limits`, also known as the *overcommit level*. [Example 2-6](#ex-predictable-demands-limitrange)
    shows a LimitRange and the possible configuration options.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-6\. Definition of allowed and default resource usage limits
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_predictable_demands_CO6-1)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Minimum values for requests and limits.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_predictable_demands_CO6-2)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Maximum values for requests and limits.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_predictable_demands_CO6-3)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Default values for limits when no limits are specified.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_predictable_demands_CO6-4)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Default values for requests when no requests are specified.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_predictable_demands_CO6-5)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Maximum ratio limit/request, used to specify the allowed overcommit level. Here,
    the memory limit must not be larger than twice the memory request, and the CPU
    limit can be as high as four times the CPU request.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](assets/6.png)](#co_predictable_demands_CO6-6)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Type can be `Container`, `Pod`, (for all containers combined), or `PersistentVolumeClaim`
    (to specify the range for a request persistent volume).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: LimitRanges help control the container resource profiles so that no containers
    require more resources than a cluster node can provide. LimitRanges can also prevent
    cluster users from creating containers that consume many resources, making the
    nodes not allocatable for other containers. Considering that the `requests` (and
    not `limits`) are the primary container characteristic the scheduler uses for
    placing, LimitRequestRatio allows you to control the amount of difference between
    the `requests` and `limits` of containers. A big combined gap between `requests`
    and `limits` increases the chances of overcommitting on the node and may degrade
    application performance when many containers simultaneously require more resources
    than initially requested.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that other shared node-level resources such as process IDs (PIDs)
    can be exhausted before hitting any resource limits. Kubernetes allows you to
    reserve a number of node PIDs for the system use and ensure that they are never
    exhausted by user workloads. Similarly, Pod PID limits allow a cluster administrator
    to limit the number of processes running in a Pod. We are not reviewing these
    in details here as they are set as Kubelet configurations options by cluster administrators
    and are not used by application developers.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，其他共享的节点级资源，如进程 ID（PIDs），可能在达到任何资源限制之前耗尽。Kubernetes 允许您为系统使用保留一些节点 PIDs，并确保它们永远不会被用户工作负载耗尽。类似地，Pod
    PID 限制允许集群管理员限制 Pod 中运行的进程数量。由于这些设置是由集群管理员设置为 Kubelet 配置选项，而不是由应用程序开发人员使用，我们在此不对其进行详细审查。
- en: Capacity Planning
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容量规划
- en: Considering that containers may have different resource profiles in different
    environments, and a varied number of instances, it is evident that capacity planning
    for a multipurpose environment is not straightforward. For example, for best hardware
    utilization, on a nonproduction cluster, you may have mainly *Best-Effort* and
    *Burstable* containers. In such a dynamic environment, many containers are starting
    up and shutting down at the same time, and even if a container gets killed by
    the platform during resource starvation, it is not fatal. On the production cluster,
    where we want things to be more stable and predictable, the containers may be
    mainly of the *Guaranteed* type, and some may be *Burstable*. If a container gets
    killed, that is most likely a sign that the capacity of the cluster should be
    increased.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到容器在不同环境中可能具有不同的资源配置文件和各种实例数量，显然，多用途环境的容量规划并不简单。例如，在非生产集群上，为了实现最佳硬件利用率，您可能主要有
    *Best-Effort* 和 *Burstable* 类型的容器。在这样一个动态的环境中，许多容器同时启动和关闭，即使一个容器在资源饥饿时被平台终止，也不是致命的。在生产集群中，我们希望事情更稳定和可预测，容器可能主要是
    *Guaranteed* 类型，部分可能是 *Burstable* 类型。如果一个容器被终止，这很可能是集群容量应增加的迹象。
- en: '[Table 2-1](#table-demands-service-example) presents a few services with CPU
    and memory demands.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 2-1](#table-demands-service-example) 展示了几个具有 CPU 和内存需求的服务。'
- en: Table 2-1\. Capacity planning example
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-1. 容量规划示例
- en: '| Pod | CPU request | Memory request | Memory limit | Instances |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Pod | CPU 请求 | 内存请求 | 内存限制 | 实例数 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| A | 500 m | 500 Mi | 500 Mi | 4 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| A | 500 m | 500 Mi | 500 Mi | 4 |'
- en: '| B | 250 m | 250 Mi | 1000 Mi | 2 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| B | 250 m | 250 Mi | 1000 Mi | 2 |'
- en: '| C | 500 m | 1000 Mi | 2000 Mi | 2 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| C | 500 m | 1000 Mi | 2000 Mi | 2 |'
- en: '| D | 500 m | 500 Mi | 500 Mi | 1 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| D | 500 m | 500 Mi | 500 Mi | 1 |'
- en: '| **Total** | **4000 m** | **5000 Mi** | **8500 Mi** | **9** |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| **总计** | **4000 m** | **5000 Mi** | **8500 Mi** | **9** |'
- en: Of course, in a real-life scenario, the more likely reason you are using a platform
    such as Kubernetes is that there are many more services to manage, some of which
    are about to retire, and some of which are still in the design and development
    phase. Even if it is a continually moving target, based on a similar approach
    as described previously, we can calculate the total amount of resources needed
    for all the services per environment.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在实际场景中，您使用 Kubernetes 等平台的更可能原因是有更多的服务需要管理，其中一些即将退役，一些仍处于设计和开发阶段。即使它是一个不断变化的目标，基于先前描述的类似方法，我们可以计算每个环境所有服务所需的总资源量。
- en: Keep in mind that in the different environments, there are different numbers
    of containers, and you may even need to leave some room for autoscaling, build
    jobs, infrastructure containers, and more. Based on this information and the infrastructure
    provider, you can choose the most cost-effective compute instances that provide
    the required resources.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同的环境中，请记住，容器的数量各不相同，甚至可能需要留出一些空间用于自动扩展、构建作业、基础设施容器等。根据这些信息和基础设施提供者，您可以选择提供所需资源的最具成本效益的计算实例。
- en: Discussion
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论
- en: Containers are useful not only for process isolation and as a packaging format.
    With identified resource profiles, they are also the building blocks for successful
    capacity planning. Perform some early tests to discover the resource needs for
    each container, and use that information as a base for future capacity planning
    and prediction.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 容器不仅用于进程隔离和作为打包格式，还是成功容量规划的构建块，具有确定的资源配置文件。执行一些早期测试，以了解每个容器的资源需求，并将该信息作为未来容量规划和预测的基础。
- en: Kubernetes can help you here with the *Vertical Pod Autoscaler* (VPA), which
    monitors the resource consumption of your Pod over time and gives a recommendation
    for requests and limits. The VPA is described in detail in [“Vertical Pod Autoscaling”](ch29.html#elasticscale-vertical).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 可以通过 *垂直 Pod 自动缩放器*（VPA）来帮助你，在一段时间内监控 Pod 的资源消耗，并推荐请求和限制。VPA 在 [“垂直
    Pod 自动缩放”](ch29.html#elasticscale-vertical) 中有详细描述。
- en: However, more importantly, resource profiles are the way an application communicates
    with Kubernetes to assist in scheduling and managing decisions. If your application
    doesn’t provide any `requests` or `limits`, all Kubernetes can do is treat your
    containers as opaque boxes that are dropped when the cluster gets full. So it
    is more or less mandatory for every application to think about and provide these
    resource declarations.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，更重要的是，资源配置文件是应用程序与 Kubernetes 通信以帮助调度和管理决策的方式。如果你的应用程序没有提供任何 `requests` 或
    `limits`，那么 Kubernetes 只能将你的容器视为在集群变满时会被丢弃的不透明盒子。因此，对于每个应用程序来说，思考并提供这些资源声明几乎是强制性的。
- en: Now that you know how to size our applications, in [Chapter 3, “Declarative
    Deployment”](ch03.html#DeclarativeDeployment), you will learn multiple strategies
    to install and update our applications on Kubernetes.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道如何调整我们的应用程序大小，在 [第 3 章，“声明式部署”](ch03.html#DeclarativeDeployment)，你将学习在
    Kubernetes 上安装和更新我们的应用程序的多种策略。
- en: More Information
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多信息
- en: '[Predictable Demands Example](https://oreil.ly/HYIqJ)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可预测需求示例](https://oreil.ly/HYIqJ)'
- en: '[Configure a Pod to Use a ConfigMap](https://oreil.ly/c54Gh)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[配置 Pod 使用 ConfigMap](https://oreil.ly/c54Gh)'
- en: '[Kubernetes Best Practices: Resource Requests and Limits](https://oreil.ly/8bKD5)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kubernetes 最佳实践：资源请求和限制](https://oreil.ly/8bKD5)'
- en: '[Resource Management for Pods and Containers](https://oreil.ly/a37eO)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pod 和容器的资源管理](https://oreil.ly/a37eO)'
- en: '[Manage HugePages](https://oreil.ly/RXQD1)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管理 HugePages](https://oreil.ly/RXQD1)'
- en: '[Configure Default Memory Requests and Limits for a Namespace](https://oreil.ly/ozlU1)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为命名空间配置默认内存请求和限制](https://oreil.ly/ozlU1)'
- en: '[Node-Pressure Eviction](https://oreil.ly/fxRvs)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[节点压力驱逐](https://oreil.ly/fxRvs)'
- en: '[Pod Priority and Preemption](https://oreil.ly/FpUoH)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pod 的优先级和抢占](https://oreil.ly/FpUoH)'
- en: '[Configure Quality of Service for Pods](https://oreil.ly/x07OT)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[配置 Pod 的服务质量](https://oreil.ly/x07OT)'
- en: '[Resource Quality of Service in Kubernetes](https://oreil.ly/yORlL)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kubernetes 的资源服务质量](https://oreil.ly/yORlL)'
- en: '[Resource Quotas](https://oreil.ly/rFSLa)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[资源配额](https://oreil.ly/rFSLa)'
- en: '[Limit Ranges](https://oreil.ly/1bXfO)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[限制范围](https://oreil.ly/1bXfO)'
- en: '[Process ID Limits and Reservations](https://oreil.ly/lkmMK)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[进程 ID 的限制和预留](https://oreil.ly/lkmMK)'
- en: '[For the Love of God, Stop Using CPU Limits on Kubernetes](https://oreil.ly/Yk-Ag)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[亲爱的上帝，请停止在 Kubernetes 上使用 CPU 限制](https://oreil.ly/Yk-Ag)'
- en: '[What Everyone Should Know About Kubernetes Memory Limits](https://oreil.ly/cdJkP)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kubernetes 内存限制：所有人都应该知道的内容](https://oreil.ly/cdJkP)'
