- en: Chapter 4\. Working with Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章 数据处理
- en: Cloud computing has made a big impact on how we build and operate software today,
    including how we work with the data. The cost of storing data has significantly
    decreased, making it cheaper and more feasible for companies to keep vastly larger
    amounts of data. The operational overhead of database systems is considerably
    less with the advent of managed and serverless data storage services. This has
    made it easier to spread data across different data storage types, placing data
    into the systems better suited to manage the classification of data stored. A
    trend in microservices architectures encourages the decentralization of data,
    spreading the data for an application across multiple services, each with its
    own datastores. It’s also common that data is replicated and partitioned in order
    to scale a system. [Figure 4-1](#data_is_often_spread_across_multiple_dat) shows
    how a typical architecture will consist of multiple data storage systems with
    data spread across them. It’s not uncommon that data in one datastore is a copy
    derived from data in another store, or has some other relationship to data in
    another store.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算已经对我们今天的软件构建和操作方式产生了重大影响，包括我们处理数据的方式。存储数据的成本显著降低，使得公司可以更便宜、更可行地保留大量数据。随着托管和无服务器数据存储服务的出现，数据库系统的运营开销大幅减少。这使得数据更容易分布到不同的数据存储类型中，将数据放入更适合管理存储的系统中。微服务架构的趋势鼓励数据的去中心化，将应用程序的数据分布到多个服务中，每个服务都有自己的数据存储。数据复制和分区是扩展系统的常见做法。[图 4-1](#data_is_often_spread_across_multiple_dat)
    显示了典型架构将包含多个数据存储系统，并在它们之间分布数据。在一个数据存储中存储的数据通常是从另一个存储中的数据复制而来，或者与另一个存储中的数据有某种关系。
- en: Cloud native applications take advantage of managed and serverless data storage
    and processing services. All of the major public cloud providers offer a number
    of different managed services to store, process, and analyze data. In addition
    to cloud provider–managed database offerings, some companies provide managed databases
    on the cloud provider of your choice. MongoDB, for example, offers a cloud-managed
    database service called MongoDB Atlas that is available on Amazon Web Services
    (AWS), Microsoft Azure, and Google Cloud Platform (GCP). By using a managed database,
    the team can focus on building applications that use the database instead of spending
    time provisioning and managing the underlying data systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生应用充分利用托管和无服务器数据存储和处理服务。所有主要的公共云提供商都提供多种不同的托管服务来存储、处理和分析数据。除了云提供商提供的托管数据库服务外，一些公司还在您选择的云提供商上提供托管数据库。例如，MongoDB
    提供了一种名为 MongoDB Atlas 的云托管数据库服务，可在亚马逊云服务（AWS）、微软 Azure 和谷歌云平台（GCP）上使用。通过使用托管数据库，团队可以专注于构建使用数据库的应用程序，而不是花费时间进行底层数据系统的预配和管理。
- en: '![clna 0401](Images/clna_0401.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0401](Images/clna_0401.png)'
- en: Figure 4-1\. Data is often spread across multiple data systems
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 数据通常分布在多个数据系统中
- en: Note
  id: totrans-5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '*Serverless database* is a term that has been used to refer to a type of managed
    database with usage-based billing in which customers are charged based on the
    amount of data stored and processed. This means that if a database is not being
    accessed, the user is billed only for the amount of data stored. When there is
    an operation on the database, either the user is charged for the specific operation
    or the database is scaled from zero and back during the processing of the operation.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*无服务器数据库* 是一种术语，用来指代一种按使用量计费的托管数据库类型，客户根据存储和处理的数据量收费。这意味着如果数据库没有被访问，用户仅需支付存储数据的费用。当数据库执行操作时，用户要么按特定操作收费，要么在操作处理过程中从零开始并进行扩展。'
- en: 'Cloud native applications take full advantage of the cloud, including data
    systems used. The following is a list of cloud native application characteristics
    for data:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生应用充分利用云的所有优势，包括使用的数据系统。以下是用于数据的云原生应用程序特征列表：
- en: Prefer managed data storage and analytics services.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更喜欢托管的数据存储和分析服务。
- en: Use polyglot persistence, data partitioning, and caching.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多语言持久性、数据分区和缓存。
- en: Embrace eventual consistency and use strong consistency when necessary.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受最终一致性，在必要时使用强一致性。
- en: Prefer cloud native databases that scale out, tolerate faults, and are optimized
    for cloud storage.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更喜欢云原生数据库，它们能够横向扩展、容忍故障，并优化云存储。
- en: Deal with data distributed across multiple datastores.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理分布在多个数据存储中的数据。
- en: Cloud native applications often need to deal with silos of data, which require
    a different approach to working with data. There are a number of benefits to polyglot
    persistence, decentralized data, and data partitioning, but there are also trade-offs
    and considerations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Data Storage Systems
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a growing number of options for storing and processing data. It can
    be difficult to determine which products to use when building an application.
    Teams will sometimes engage in a number of iterations evaluating languages, frameworks,
    and the data storage systems that will be used in the application. Many are still
    not convinced they made the correct decision, and it’s common for those storage
    systems to be replaced or new ones added as the application evolves anyway.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: It can be helpful to understand the various types of datastores and the workloads
    they are optimized for when deciding which products to use. Many products are,
    however, multimodel and are designed to support multiple data models, falling
    into multiple data storage classifications. Applications will often take advantage
    of multiple data storage systems, storing files in an object store, writing data
    to a relational database, and caching with an in-memory key/value store.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Objects, Files, and Disks
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Every public cloud provider offers an inexpensive *object storage service*.
    Object storage services manage data as objects. Objects are usually stored with
    metadata for the object and a key that’s used as a reference for the object. File
    storage services generally provide shared access to files through a traditional
    file sharing model with a hierarchical directory structure. Disks or block storage
    provides storage of disk volumes used by computing instances. Determining where
    to store files such as images, documents, content, and genomics data files will
    largely depend on the systems that access them. Each of the following storage
    types is better suited for different types of files:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You should prefer object storage for storing file data. Object storage is relatively
    inexpensive, extremely durable, and highly available. All of the major cloud providers
    offer different storage tiers enabling cost saving based on data access requirements.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Object/blob storage
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Use it with files when the applications accessing the data support the cloud
    provider API.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is inexpensive and can store large amounts of data.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications need to implement a cloud provider API. If application portability
    is a requirement, see [Chapter 7](ch07.xhtml#portability).
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: File storage
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Use it with applications designed to support Network Attached Storage (NAS).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use it when using a library or service that requires shared access to files.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is more expensive than object storage.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disk (block) storage
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Use it for applications that assume persistent local storage disks, like MongoDB
    or a MySQL database.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to the various cloud provider–managed storage options for files
    and objects, you can provision a distributed filesystem. The Hadoop Distributed
    File System (HDFS) is popular for big data analytics. The distributed filesystem
    can use the cloud provider disk or block storage services. Many of the cloud providers
    have managed services for popular distributed filesystems that include the analytics
    tools used. You should consider these filesystems when using the analytics tools
    that work with them.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了各种云服务提供商管理的文件和对象存储选项外，您还可以提供分布式文件系统。Hadoop分布式文件系统（HDFS）在大数据分析中非常流行。分布式文件系统可以使用云提供商的磁盘或块存储服务。许多云提供商还为流行的分布式文件系统提供了管理服务，其中包括使用的分析工具。在使用与它们兼容的分析工具时，您应考虑这些文件系统。
- en: Databases
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库
- en: Databases are generally used for storing more structured data with well-defined
    formats. A number of databases have been released over the past few years, and
    the number of databases available for us to choose from continues to grow every
    year. Many of these databases have been designed for specific types of data models
    and workloads. Some of them support multiple models and are often labeled as *multimodel
    databases*. It helps to organize databases into a group or classification when
    considering which database to use where in an application.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库通常用于存储更结构化、有明确定义格式的数据。在过去几年中发布了许多数据库，并且可供我们选择的数据库数量每年都在增加。许多这些数据库都是为特定类型的数据模型和工作负载设计的。其中一些支持多个模型，并经常被标记为*多模型数据库*。在考虑在应用程序中使用哪个数据库时，将数据库组织成一组或分类是有帮助的。
- en: Key/value
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 键/值
- en: Often, application data needs to be retrieved using only the primary key, or
    maybe even part of the key. A key/value store can be viewed as simply a very large
    hash table that stores some value under a unique key. The value can be retrieved
    very efficiently using the key or, in some cases, part of the key. Because the
    value is opaque to the database, a consumer would need to scan record-by-record
    in order to find an item based on the value. The keys in a key/value database
    can comprise multiple elements and even can be ordered for efficient lookup. Some
    of the key/value databases allow for the lookup using the key prefix, making it
    possible to use compound keys. If the data can be queried based on some simple
    nesting of keys, this might be a suitable option. If we’re storing orders for
    customer xyz in a key/value store, we might store them using the customer ID as
    a key prefix followed by the order number, “xyz-1001.” A specific order can be
    retrieved using the entire key, and orders for customer xyz could be retrieved
    using the “xyz” prefix.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 经常情况下，应用程序数据需要仅使用主键或甚至部分主键来检索。键/值存储可以被视为一个简单存储一些值在唯一键下的大型哈希表。可以非常有效地使用键或在某些情况下使用部分键来检索值。因为值对于数据库来说是不透明的，消费者需要逐条记录扫描以查找基于值的项目。键/值数据库中的键可以由多个元素组成，甚至可以进行排序以实现高效的查找。一些键/值数据库允许使用键前缀进行查找，从而可以使用复合键。如果数据可以基于某些简单键的嵌套进行查询，这可能是一个合适的选项。如果我们在键/值存储中存储客户xyz的订单，我们可以使用客户ID作为键前缀，后跟订单号“xyz-1001”。可以使用整个键来检索特定订单，而使用“xyz”前缀可以检索客户xyz的订单。
- en: Note
  id: totrans-36
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Key/value databases are generally inexpensive and very scalable datastores.
    Key/value data storage services are capable of partitioning and even repartitioning
    data based on the key. Selecting a key is important when using these datastores
    because it will have a significant impact on the scale and the performance of
    data storage reads and writes.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 键/值数据库通常是价格便宜且非常可扩展的数据存储。键/值数据存储服务能够根据键来分区甚至重新分区数据。在使用这些数据存储时选择键是很重要的，因为它将对数据存储的规模和性能读写产生显著影响。
- en: Document
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文档
- en: A document database is similar to a key/value database in that it stores a document
    (value) by a primary key. Unlike a key/value database, which can store just about
    any value, the documents in a document database need to conform to some defined
    structure. This enables features like the maintenance of secondary indexes and
    the ability to query data based on the document. The values commonly stored in
    a document database are a composition of hashmaps (JSON objects) and lists (JSON
    arrays). JSON is a popular format used in document databases, although many database
    engines use a more efficient internal storage format like MongoDB’s BSON.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 文档数据库类似于键/值数据库，它通过主键存储文档（值）。与键/值数据库不同的是，文档数据库中的文档需要符合某些定义的结构。这样可以实现维护辅助索引和根据文档查询数据等功能。文档数据库中通常存储的值是哈希映射（JSON对象）和列表（JSON数组）的组合。JSON是文档数据库中常用的格式，尽管许多数据库引擎使用更高效的内部存储格式，如MongoDB的BSON。
- en: Tip
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: You will need to think differently about how you organize data in a document-oriented
    database when coming from relational databases. It takes time for many to make
    the transition to this different approach to data modeling.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当从关系数据库过渡到面向文档的数据库时，您需要以不同的方式考虑如何组织数据。许多人需要时间来适应这种不同的数据建模方法。
- en: You can use these databases for much of what was traditionally stored in a relational
    database like PostgreSQL. They have been growing in popularity and unlike wwith
    relational databases, the documents map nicely to objects in programming languages
    and don’t require object relational mapping (ORM) tools. These databases generally
    don’t enforce a schema, which has some advantages with regard to Continuous Delivery
    (CD) of software changes requiring data schema changes.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用这些数据库存储传统上存储在关系数据库（如PostgreSQL）中的许多数据。它们在流行度上正在增长，并且与关系数据库不同，文档在编程语言中的对象映射得很好，不需要对象关系映射（ORM）工具。这些数据库通常不强制执行模式，在软件变更要求数据模式更改的持续交付（CD）方面具有一些优势。
- en: Note
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Databases that do not enforce a schema are often referred to “schema on read”
    because although the database does not enforce the schema, an inherent schema
    exists in the applications consuming the data and will need to know how to work
    with the data returned.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 不强制执行模式的数据库通常被称为“读取时模式”，因为尽管数据库不强制执行模式，但应用程序中存在隐含的模式，并且需要知道如何处理返回的数据。
- en: Relational
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关系
- en: Relational databases organize data into two-dimensional structures called tables,
    consisting of columns and rows. Data in one table can have a relationship to data
    in another table, which the database system can enforce. Relational databases
    generally enforce a strict schema, also referred to *schema on write*, in which
    a consumer writing data to a database must conform to a schema defined in the
    database.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关系数据库将数据组织成称为表的二维结构，由列和行组成。一个表中的数据可以与另一个表中的数据有关联，数据库系统可以强制执行这种关系。关系数据库通常强制执行严格的模式，也称为*写入时模式*，即向数据库写入数据的消费者必须符合数据库中定义的模式。
- en: Relational databases have been around for a long time and a lot of developers
    have experience working with them. The most popular and commonly used databases,
    as of today, are still relational databases. These databases are very mature,
    they’re good with data that contains a large number of relationships, and there’s
    a large ecosystem of tools and applications that know how to work with them. *Many-to-many
    relationships* can be difficult to work with in document databases, but in relational
    database they are very simple. If the application data has a lot of relationships,
    especially those that require transactions, these databases might be a good fit.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 关系数据库存在已久，许多开发人员有使用它们的经验。截至今天，最受欢迎和常用的数据库仍然是关系数据库。这些数据库非常成熟，对于包含大量关系的数据非常有效，并且有大量的工具和应用程序生态系统知道如何处理它们。*多对多关系*在文档数据库中可能难以处理，但在关系数据库中非常简单。如果应用程序数据有许多关系，特别是那些需要事务的关系，这些数据库可能非常适合。
- en: Graph
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图
- en: 'A graph database stores two types of information: *edges* and *nodes*. Edges
    define the relationships between nodes, and you can think of a node as the entity.
    Both nodes and edges can have properties providing information about that specific
    edge or node. An edge will often define the direction or nature of a relationship.
    Graph databases work well at analyzing the relationships between entities. Graph
    data can be stored in any of the other databases, but when graph traversal becomes
    increasingly complex, it can be challenging to meet the performance and scale
    requirements of graph data in the other storage types.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图数据库存储两种类型的信息：*边* 和 *节点*。边定义节点之间的关系，你可以将节点视为实体。节点和边都可以具有描述特定边或节点的属性。边通常定义关系的方向或性质。图数据库在分析实体之间的关系方面表现良好。图数据可以存储在其他任何数据库中，但当图遍历变得越来越复杂时，在其他存储类型中满足图数据的性能和规模要求可能会有挑战。
- en: Column family
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 列族
- en: A column-family database organizes data into rows and columns, and can initially
    appear very similar to a relational database. You can think of a column-family
    database as holding tabular data with rows and columns, but the columns are divided
    into groups known as column families. Each column family holds a set of columns
    that are logically related together and are typically retrieved or manipulated
    as a unit. Other data that is accessed separately can be stored in separate column
    families. Within a column family, new columns can be added dynamically, and rows
    can be sparse (that is, a row doesn’t need to have a value for every column).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 列族数据库将数据组织成行和列，最初可能看起来与关系数据库非常相似。你可以把列族数据库看作是带有行和列的表格数据，但列被划分为称为列族的组。每个列族包含一组逻辑相关的列，通常作为一个单元进行检索或操作。可以将单独访问的其他数据存储在单独的列族中。在列族中，可以动态添加新列，行可以是稀疏的（即，行不需要为每一列都有值）。
- en: Time-series
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 时间序列
- en: Time-series data is a database that’s optimized for time, storing values based
    on time. These databases generally need to support a very high number of writes.
    They are commonly used to collect large amounts of data in real time from a large
    number of sources. Updates to the data are rare and deletes are often completed
    in bulk. The records written to a time-series database are usually very small,
    but there are often a large number of records. Time-series databases are good
    for storing telemetry data. Popular uses include Internet of Things (IoT) sensors
    or application/system counters. Time-series databases will often include features
    for data retention, down-sampling, and storing data in different mediums depending
    on configuration data usage patterns.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据是针对时间进行优化的数据库，根据时间存储值。这些数据库通常需要支持非常高数量的写入操作。它们通常用于实时从大量来源收集大量数据。对数据的更新很少，删除通常是批量完成的。写入时间序列数据库的记录通常非常小，但通常有大量记录。时间序列数据库非常适合存储遥测数据。常见用途包括物联网（IoT）传感器或应用程序/系统计数器。时间序列数据库通常包含用于数据保留、降采样以及根据配置数据使用模式将数据存储在不同介质中的功能。
- en: Search
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索
- en: Search engine databases are often used to search for information held in other
    datastores and services. A search engine database can index large volumes of data
    with near-real-time access to the indexes. In addition to searching across unstructured
    data like that in a web page, many applications use them to provide structured
    and ad hoc search features on top of data in another database. Some databases
    have full-text indexing features, but search databases are also capable of reducing
    words to their root forms through stemming and normalization.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎数据库通常用于搜索其他数据存储和服务中保存的信息。搜索引擎数据库可以索引大量数据，并几乎实时访问索引。除了搜索类似网页中的非结构化数据外，许多应用程序还使用它们在另一个数据库的数据上提供结构化和特定查询的搜索功能。某些数据库具有全文索引功能，但搜索数据库还能通过词干提取和规范化将单词减少到它们的根形式。
- en: Streams and Queues
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流和队列
- en: Streams and queues are data storage systems that store events and messages.
    Although they are sometimes used for the same purpose, they are very different
    types of systems. In an event stream, data is stored as an immutable stream of
    events. A consumer is able to read events in the stream at a specific location
    but is unable to modify the events or the stream. You cannot remove or delete
    individual events from the stream. Messaging queues or topics will store messages
    that can be changed (mutated), and it’s possible to remove an individual message
    from a queue. Streams are great at recording a series of events, and streaming
    systems are generally able to store and process very large amounts of data. Queues
    or topics are great for messaging between different services, and these systems
    are generally designed for the short-term storage of messages that can be changed
    and randomly deleted. This chapter focuses more on streams because they are more
    commonly used with data systems, and queues more commonly used for service communications.
    For more information on queues, see [Chapter 3](ch03.xhtml#designing_cloud-native_applications).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 流和队列是存储事件和消息的数据存储系统。虽然它们有时用于相同的目的，但它们是非常不同类型的系统。在事件流中，数据以不可变的事件流形式存储。消费者能够在特定位置读取流中的事件，但无法修改事件或流。您不能从流中删除或删除单个事件。消息队列或主题将存储可以更改（变异）的消息，并且可以从队列中删除单个消息。流非常适合记录一系列事件，流处理系统通常能够存储和处理大量数据。队列或主题非常适合不同服务之间的消息传递，这些系统通常设计用于可以更改和随机删除的消息的短期存储。本章更多地关注流，因为它们在数据系统中更常用，而队列更常用于服务通信。有关队列的更多信息，请参见[第三章](ch03.xhtml#designing_cloud-native_applications)。
- en: Note
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: A topic is a concept used in a publish-subscribe messaging model. The only difference
    between a topic and a queue is that a message on a queue goes to one subscriber,
    whereas a message to a topic will go to multiple subscribers. You can think of
    a queue as a topic with one, and only one, subscriber.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 主题是发布-订阅消息模型中使用的概念。主题和队列唯一的区别在于队列上的消息发送给一个订阅者，而主题上的消息将发送给多个订阅者。您可以将队列视为只有一个订阅者的主题。
- en: Blockchain
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 区块链
- en: Records on a blockchain are stored in a way that they are immutable. Records
    are grouped in a *block*, each of which contains some number of records in the
    database. Every time new records are created, they are grouped into a single block
    and added to the chain. Blocks are chained together using hashing to ensure that
    they are not tampered with. The slightest change to the data in a block will change
    the hash. The hash from each block is stored at the beginning of the next block,
    ensuring that nobody can change or remove a block from the chain. Although a blockchain
    could be used like any other centralized database, it’s commonly decentralized,
    removing power from a central organization.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 记录在区块链上以一种不可变的方式存储。记录被分组在一个*区块*中，每个区块包含数据库中的若干记录。每次创建新记录时，它们被组合成一个单独的区块并添加到链中。使用哈希将区块链接在一起，以确保它们不被篡改。对区块中数据的最轻微更改都会改变哈希值。每个区块的哈希存储在下一个区块的开头，确保没有人可以改变或移除链中的区块。尽管区块链可以像任何其他集中式数据库一样使用，但通常是去中心化的，从而削弱了中央组织的权力。
- en: Selecting a Datastore
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择数据存储
- en: When selecting a datastore, you need to consider a number of requirements. Selecting
    data storage technologies and services can be quite challenging, especially given
    the cool new databases constantly becoming available and changes in how we build
    software. Start with the architecturally significant requirements—also known as
    *nonfunctional* requirements—for a system and then move to the functional requirements.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择数据存储时，您需要考虑一些要求。选择数据存储技术和服务可能非常具有挑战性，特别是考虑到不断出现的新型数据库和我们构建软件的方式的变化。首先从架构上重要的要求——也称为*非功能*要求——开始考虑系统，然后再考虑功能性要求。
- en: Selecting the appropriate datastore for your requirements can be an important
    design decision. There are literally hundreds of implementations to choose from
    among SQL and NoSQL databases. Datastores are often categorized by how they structure
    data and the types of operations they support. A good place to begin is by considering
    which storage model is best suited for the requirements. Then, consider a particular
    datastore within that category, based on factors such as feature set, cost, and
    ease of management.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的需求选择适当的数据存储可以是一个重要的设计决策。在SQL和NoSQL数据库中有数百种实现可供选择。数据存储通常根据它们如何结构化数据以及它们支持的操作类型进行分类。开始的好地方是考虑哪种存储模型最适合需求。然后，根据功能集、成本和管理易用性等因素，考虑该类别内的特定数据存储。
- en: Gather as much of the following information as you can about your data requirements.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能收集有关您数据需求的以下信息。
- en: Functional requirements
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 功能需求
- en: Data format
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据格式
- en: What type of data do you need to store?
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要存储哪些类型的数据？
- en: Read and write
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 读和写
- en: How will the data need to be consumed and written?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 数据需要如何被消耗和写入？
- en: Data size
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 数据大小
- en: How large are the items that will be placed in the datastore?
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 存储数据的项目有多大？
- en: Scale and structure
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 规模和结构
- en: How much storage capacity do you need, and do you anticipate needing to partition
    your data?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要多少存储容量，是否预计需要对数据进行分区？
- en: Data relationships
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据关系
- en: Will your data need to support complex relationships?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据是否需要支持复杂的关系？
- en: Consistency model
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性模型
- en: Will you require strong consistency or is eventual consistency acceptable?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否需要强一致性，或者最终一致性可以接受？
- en: Schema flexibility
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 模式灵活性
- en: What kind of schemas will you apply to your data? Is a fixed or strongly enforced
    schema important?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据将应用哪种模式？固定的或强制执行的模式重要吗？
- en: Concurrency
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 并发性
- en: Will the application benefit from multiversion concurrency control? Do you require
    pessimistic and/or optimistic concurrency control?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序是否会从多版本并发控制中受益？是否需要悲观和/或乐观的并发控制？
- en: Data movement
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 数据移动
- en: Will your application need to move data to other stores or data warehouses?
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 您的应用程序是否需要将数据移动到其他存储或数据仓库？
- en: Data life cycle
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据生命周期
- en: Is the data write-once, read-many? Can it be archived over time or can the fidelity
    of the data be reduced through down-sampling?
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是否写入一次，读取多次？是否可以通过归档或通过降采样减少数据的保真度？
- en: Change streams
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 变更流
- en: Do you need to support change data capture (CDC) and fire events when data changes?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 是否需要支持变更数据捕获（CDC）并在数据变化时触发事件？
- en: Other supported features
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 其他支持的功能
- en: Do you need any other specific features, full-text search, indexing, and so
    on?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 是否需要其他特定功能，如全文搜索、索引等？
- en: Nonfunctional requirements
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 非功能性需求
- en: Team experience
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 团队经验
- en: Probably one of the biggest reasons teams select a specific database solution
    is because of experience.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 选择特定数据库解决方案的一个最大原因可能是经验。
- en: Support
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 支持
- en: Sometimes the database system that’s the best technical fit for an application
    is not the best fit for a project because of the support options available. Consider
    whether or not available support options meet the organizations needs.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，对于一个应用程序而言，在技术上最合适的数据库系统可能不是最适合项目的，因为支持选项的问题。考虑可用的支持选项是否满足组织的需求。
- en: Performance and scalability
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 性能和可伸缩性
- en: What are your performance requirements? Is the workload heavy on ingestion?
    Query and analytics?
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 您的性能要求是什么？工作负载是否主要是摄入、查询和分析？
- en: Reliability
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 可靠性
- en: What are the availability requirements? What backup and restore features are
    necessary?
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您的可用性要求是什么？需要哪些备份和恢复功能？
- en: Replication
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 复制
- en: Will data need to be replicated across multiple regions or zones?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是否需要在多个区域或区域间复制？
- en: Limits
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 限制
- en: Are there any hard limits on size and scale?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 数据大小和规模是否有任何硬性限制？
- en: Portability
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 可移植性
- en: Do you need to deploy on-premises or to multiple cloud providers?
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 是否需要部署在本地或多个云服务提供商上？
- en: Management and cost
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理和成本
- en: Managed service
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 托管服务
- en: When possible, use a managed data service. There are, however, situations for
    which a feature is not available and needed.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能的情况下，请使用托管数据服务。然而，有时需要的功能是不可用的。
- en: Region or cloud provider availability
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 区域或云服务提供商的可用性
- en: Is there a managed data storage solution available?
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 是否有可用的托管数据存储解决方案？
- en: Licensing
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 许可证
- en: Are there any restrictions on licensing types in the organization? Do you have
    a preference of a proprietary versus open source software (OSS) license?
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 组织内对许可类型是否有任何限制？您对专有软件与开源软件（OSS）许可证有偏好吗？
- en: Overall cost
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 总体成本
- en: What is the overall cost of using the service within your solution? A good reason
    to prefer managed services is for the reduced operational cost.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的解决方案中使用服务的总体成本是多少？选择托管服务的一个好理由是降低操作成本。
- en: 'Selecting a database can be a bit daunting when you’re looking across the vast
    number of databases available today and the new ones constantly introduced in
    the market. A site that tracks database popularity, db-engines ([*https://db-engines.com*](https://db-engines.com)),
    lists 329 different databases as of this writing. In many cases the skillset of
    the team is a major driving factor when selecting a database. Managing data systems
    can add significant operational overhead and burden to the team and managed data
    systems are often preferred for cloud-native applications, so the availability
    of managed data systems will quite often narrow down the options. Deploying a
    simple database can be easy, but consider that the patching, upgrades, performance
    tuning, backups, and highly available database configurations increase operations
    burden. Yet there are situations in which managing a database is necessary, and
    you might prefer some of the new databases built for the cloud, like CockroachDB
    or YugaByte. Also consider available tooling: it might make sense to deploy and
    manage a certain database if this avoids the need to build software to consume
    the data, like a dashboard or reporting systems.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天众多可用的数据库和市场上不断推出的新数据库中，选择一个数据库可能会有些令人生畏。一个追踪数据库流行度的网站，db-engines（[*https://db-engines.com*](https://db-engines.com)），截至本文撰写时列出了329种不同的数据库。在许多情况下，团队的技能组成是选择数据库的主要驱动因素。管理数据系统可能会给团队增加显著的操作负担，因此云原生应用通常更喜欢托管数据系统，这会显著减少选择的选项。部署一个简单的数据库可能很容易，但需要考虑补丁、升级、性能调优、备份以及高可用数据库配置等操作负担。然而，在某些情况下，管理数据库是必要的，你可能更喜欢一些为云而建的新数据库，如CockroachDB或YugaByte。同时，也要考虑可用的工具：如果这可以避免构建用于消费数据的软件，如仪表板或报告系统，可能会有意义部署和管理某些数据库。
- en: Data in Multiple Datastores
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多个数据存储中的数据
- en: 'Whether you’re working with data across partitions, databases, or services,
    data in multiple datastores can introduce some data management challenges. Traditional
    transaction management might not be possible and distributed transactions will
    adversely affect the performance and scale of a system. The following are some
    of the challenges of distributing data:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是在分区、数据库还是服务之间工作，多个数据存储中的数据可能会引入一些数据管理挑战。传统的事务管理可能不可行，分布式事务会对系统的性能和规模产生不利影响。以下是分布数据的一些挑战：
- en: Data consistency across the datastores
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储中的数据一致性
- en: Analysis of data in multiple datastores
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个数据存储中的数据分析
- en: Backup and restore of the datastores
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储的备份和恢复
- en: The consistency and integrity of the data can be challenging when spread across
    multiple datastores. How do you ensure a related record in one system is updated
    to reflect a change in another system? How do you manage copies of data, whether
    they are cached in memory, a materialized view, or stored in the systems of another
    service team? How do you effectively analyze data that’s stored across multiple
    silos? Much of this is addressed through data movement, and a growing number of
    technologies and services are showing up in the market to handle this.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 跨多个数据存储中保持数据的一致性和完整性可能会很具挑战性。当一个系统中的相关记录更新以反映另一个系统的变化时，如何确保？如何管理数据的副本，无论是在内存中缓存、物化视图中，还是存储在另一个服务团队的系统中？如何有效分析存储在多个隔离区中的数据？很多这些问题通过数据移动来解决，市场上出现了越来越多的技术和服务来处理这些问题。
- en: Change Data Capture
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变更数据捕获
- en: 'Many of the database options available today offer a stream of data change
    events (change log) and expose this through an easy-to-consume API. This can make
    it possible to perform some actions on the events, like triggering a function
    when a document changes or updating a materialized view. For example, successfully
    adding a document that contains an order could trigger an event to update reporting
    totals and notify an accounting service that an order for the customer has been
    created. Given a move to polyglot persistence and decentralized datastores, these
    event streams are incredibly helpful in maintaining consistency across these silos
    of data. Some common use cases for CDC include:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Notifications
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: In a microservices architecture, it’s not uncommon that another service will
    want to be notified of changes to data in a service. For this, you can use a webhook
    or subscription to publish events for other services.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Materialized views
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Materialized views make for efficient and simplified queries on a system. The
    change events can be used to update these views.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Cache invalidation
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Caches are great for improving the scale and performance of a system, but invalidating
    the cache when the backing data has changed is a challenge. Instead of using a
    time-to-live (TTL), you can use change events to either remove the cached item
    or update it.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Auditing
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Many systems need to maintain a record of changes to data. You can use this
    log of changes to track what was changed and when. The user that made the change
    is often needed, so it might be necessary to ensure that this information is also
    captured.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Search
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Many databases are not very good at handling search, and the search datastores
    do not provide all of the features needed in other databases. You can use change
    streams to maintain a search index.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Analytics
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: The data analytics requirements of an organization often require a view across
    many different databases. Moving the data to a central data lake, warehouse, or
    database can enable richer reporting and analytics requirements.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Change analytics
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Near-real-time analysis of data changes can be separated from the data access
    concerns and performed on the data changes.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Archive
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: In some applications, it is necessary to maintain an archive of state. This
    archive is rarely accessed, and it’s often better to store this in a less expensive
    storage system.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Legacy systems
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Replacing a legacy system will sometimes require data to be maintained in multiple
    locations. These change streams can be used to update data in a legacy system.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 4-2](#cdc_used_to_synchronize_data_changes), we see an app writing
    to a database that logs a change. That change is then written to a stream of change
    logs and processed by multiple consumers. Many database systems maintain an internal
    log of changes that can be subscribed to with checkpoints to resume at a specific
    location. MongoDB, for example, allows you to subscribe to events on a deployment,
    data, or collection, and provide a token to resume at a specific location. Many
    of the cloud provider databases handle the watch process and will invoke a serverless
    function for every change.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 4-2](#cdc_used_to_synchronize_data_changes)中，我们看到一个应用程序向记录更改的数据库写入数据。然后，该更改被写入更改日志流并由多个消费者处理。许多数据库系统维护一个内部更改日志，可以订阅以便在特定位置恢复检查点。例如，MongoDB
    允许您订阅部署、数据或集合上的事件，并提供一个标记以在特定位置恢复。许多云提供商的数据库处理观察过程，并将为每次更改调用一个无服务器函数。
- en: '![clna 0402](Images/clna_0402.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0402](Images/clna_0402.png)'
- en: Figure 4-2\. CDC used to synchronize data changes
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 用于同步数据更改的 CDC
- en: The application could have written the change to the stream and the database,
    but this presents some problems if one of the two operations fails and it potentially
    creates a race condition. For example, if the application were updating some data
    in the database, like an account shipping preference, and then failed to write
    to an event stream, the data in the database would have changed, but the other
    systems would not have been notified or updated, like a shipping service. The
    other concern is that if two processes made a change to the same record at close
    to the same time, the order to events can be a problem. Depending on the change
    and how it’s processed, this might not be an issue, but it’s something to consider.
    The concern is that we either record the event that something changed when it
    didn’t, or change something and don’t record the event.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序本可以将更改写入流和数据库，但如果两个操作中的一个失败，可能会出现一些问题，并且可能会创建竞争条件。例如，如果应用程序正在更新数据库中的一些数据，如帐户的运输偏好设置，然后未能写入事件流，那么数据库中的数据将已更改，但其他系统未被通知或更新，如运输服务。另一个问题是，如果两个进程几乎同时对同一记录进行更改，则事件顺序可能成为问题。根据更改的内容及其处理方式，这可能不是问题，但需要考虑。关键是，我们要么记录某事物变更的事件，而事实上并未发生变更，要么更改了某事物却没有记录事件。
- en: By using the databases change stream, we can write the change or mutation of
    the document and the log of that change as a transaction. Even though data systems
    consuming the event stream are eventually consistent after some period of time,
    it’s important that they become consistent. [Figure 4-3](#changes_to_a_record_and_operation_log_in)
    shows a document that has been updated and the change recorded as part of a transaction.
    This ensures that the change event and the actual change itself are consistent,
    so now we just need to consume and process that event into other systems.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用数据库更改流，我们可以将文档的更改或变异以事务的形式写入并记录该更改的日志。尽管数据系统在一段时间后消费事件流后最终一致，但重要的是它们变得一致。[图 4-3](#changes_to_a_record_and_operation_log_in)显示了已更新的文档及其作为事务一部分记录的更改。这确保了更改事件与实际更改本身的一致性，因此现在我们只需要消费和处理那些事件到其他系统中。
- en: '![clna 0403](Images/clna_0403.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0403](Images/clna_0403.png)'
- en: Figure 4-3\. Changes to a record and operation log in a transaction scope
  id: totrans-148
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. 在事务范围内对记录进行的更改和操作日志
- en: Many of the managed data services make this really easy to implement and can
    be quickly configured to invoke a serverless function when a change happens in
    the datastore. You can configure MongoDB Atlas to invoke a function in the MongoDB
    Stitch service. A change in Amazon DynamoDB or Amazon Simple Storage Service (Amazon
    S3) can trigger a lambda function. Microsoft Azure Functions can be invoked when
    a change happens in Azure Cosmos DB or Azure Blob Storage. A change in Google
    Cloud Firestore or object storage service can trigger a Cloud Function. Implementation
    with popular managed data storage services can be fairly straightforward. This
    is becoming a popular and necessary feature with most datastores.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 许多托管数据服务使这种实现变得非常容易，并且可以快速配置以在数据存储中发生更改时调用无服务器函数。您可以配置 MongoDB Atlas 来调用 MongoDB
    Stitch 服务中的函数。Amazon DynamoDB 或 Amazon Simple Storage Service (Amazon S3) 中的更改可以触发
    lambda 函数。当 Azure Cosmos DB 或 Azure Blob Storage 中发生更改时，可以调用 Microsoft Azure Functions。Google
    Cloud Firestore 或对象存储服务的更改可以触发 Cloud Function。使用流行的托管数据存储服务进行实现通常非常简单。这已成为大多数数据存储中受欢迎且必要的功能。
- en: Write Changes as an Event to a Change Log
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将更改作为事件写入更改日志
- en: As we just saw an application failure during an operation that affects multiple
    datastores can result in data consistency issues. Another approach that you can
    use when an operation spans multiple databases is to write the set of changes
    to a change log and then apply those changes. A group of changes can be written
    to a stream maintaining order, and if a failure occurs while the changes are being
    applied, it can be easy to retry or resume the operation, as shown in [Figure 4-4](#saving_a_set_of_changes_before_writing).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚刚看到的，在涉及多个数据存储的操作中发生应用程序故障可能导致数据一致性问题。当操作涉及多个数据库时，另一种方法是将一组更改写入更改日志，然后应用这些更改。一组更改可以按顺序写入流中，如果在应用更改时发生故障，则可以轻松重试或恢复操作，如[图 4-4](#saving_a_set_of_changes_before_writing)所示。
- en: '![clna 0404](Images/clna_0404.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0404](Images/clna_0404.png)'
- en: Figure 4-4\. Saving a set of changes before writing each change
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-4\. 每次写入更改之前保存一组更改
- en: Transaction Supervisor
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事务监督员
- en: You can use a supervisor service to ensure that a transaction is successfully
    completed or is compensated. This can be especially useful when you’re performing
    transactions involving external services—for example, writing an order to the
    system and processing a credit card, in which credit card processing can fail,
    or saving the results of the processing. As [Figure 4-5](#failing_to_save_order_details_after_proc)
    illustrates, a checkout service receives an order, processes a credit card payment,
    and then fails to save the order to the order database. Most customers would be
    upset to know that their credit card was processed but there was no record of
    their order. This is a fairly common implementation.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用监督服务确保事务成功完成或进行补偿。当您执行涉及外部服务的交易时特别有用——例如，将订单写入系统并处理信用卡，信用卡处理可能会失败，或保存处理结果。正如[图 4-5](#failing_to_save_order_details_after_proc)所示，结账服务接收订单，处理信用卡付款，然后未能将订单保存到订单数据库中。大多数客户会感到不安，因为他们的信用卡已经被扣款，但却没有订单记录。这是一个相当常见的实现。
- en: '![clna 0405](Images/clna_0405.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0405](Images/clna_0405.png)'
- en: Figure 4-5\. Failing to save order details after processing an order
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5\. 在处理订单后未能保存订单详细信息
- en: Another approach might be to save the order or cart with a status of processing,
    then make the call to the payment gateway to process the credit card payment,
    and finally, update the status of the order. [Figure 4-6](#failing_to_update_order_status)
    demonstrates how if we fail to update the order status, at least we have the record
    of an order submitted and the intention to process it. If the payment gateway
    service offered a notification service like a webhook callback, we could configure
    that to ensure that the status was accurate.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法可能是以处理中的状态保存订单或购物车，然后调用支付网关进行信用卡支付，最后更新订单状态。如果未能更新订单状态，[图 4-6](#failing_to_update_order_status)显示了我们至少有一个已提交订单的记录和处理意图。如果支付网关服务提供像
    webhook 回调这样的通知服务，我们可以配置它以确保状态准确。
- en: '![clna 0406](Images/clna_0406.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0406](Images/clna_0406.png)'
- en: Figure 4-6\. Failing to update order status
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-6\. 未能更新订单状态
- en: In [Figure 4-7](#a_supervisor_service_monitors_transactio), a supervisor is
    added to monitor the order database for processing transactions that have not
    completed and reconciles the state. The supervisor could be a simple function
    that’s triggered at a specific interval.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 4-7](#a_supervisor_service_monitors_transactio)中，添加了一个监督员来监视订单数据库中未完成的处理交易并对状态进行调和。监督员可以是在特定间隔触发的简单函数。
- en: '![clna 0407](Images/clna_0407.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0407](Images/clna_0407.png)'
- en: Figure 4-7\. A supervisor service monitors transactions for errors
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-7\. 监控事务错误的监督服务
- en: You can use this approach—using a supervisor and setting status—in many different
    ways to monitor systems and databases for consistency and take action to correct
    them or generate a notification of the issue.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用这种方法——使用监督服务并设置状态——以多种不同的方式监视系统和数据库的一致性，并采取纠正措施或生成问题通知。
- en: Compensating Transactions
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 补偿性交易
- en: Traditional distributed transactions are not commonly used in today’s cloud
    native applications, and not always available. There are situations for which
    transactions are necessary to maintain consistency across services or datastores.
    For example, a consumer posts some data with a file to an API requiring the application
    to write the file to object storage and some data to a document database. If we
    write the file to object storage and then fail when writing to the database, for
    any reason, we have a potentially orphaned file in object storage if the only
    way to find it is through a query on the database and reference. This is a situation
    in which we want to treat writing the file and the database record as a transaction;
    if one fails, both should fail. The file then should be removed to compensate
    for the failed database write. This is essentially what a compensating transaction
    does. A logical set of operations need to complete; if one of the operations fails,
    we might need to compensate the ones that succeeded.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的云原生应用程序中，传统的分布式事务并不常用，也不总是可用。有些情况下需要事务以保持服务或数据存储一致性。例如，消费者通过API向文件发送一些数据，要求应用程序将文件写入对象存储并将一些数据写入文档数据库。如果我们将文件写入对象存储，然后在写入数据库时失败（无论何种原因），则如果唯一找到文件的方法是通过对数据库和引用的查询，则对象存储中可能会有一个孤立的文件。这种情况下，我们希望将写文件和数据库记录的操作视为一个事务；如果其中一个失败，则两者都应失败。然后应删除文件以补偿失败的数据库写入。这本质上就是补偿事务所做的。一组逻辑操作需要完成；如果其中一个操作失败，则可能需要补偿成功的操作。
- en: Note
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You should avoid service coordination. In many cases, you can avoid complex
    transaction coordination by designing for eventual consistency and using techniques
    like CDC.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 应避免服务协调。在许多情况下，可以通过设计事件一致性并使用CDC等技术避免复杂的事务协调。
- en: Extract, Transform, and Load
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取、转换和加载
- en: 'The need to move and transform data for business intelligence (BI) is quite
    common. Businesses have been using Extract, Transform, and Load (ETL) platforms
    for a long time to move data from one system to another. Data analytics is becoming
    an important part of every business, large and small, so it should be no surprise
    that ETL platforms have become increasingly important. Data has become spread
    out across more systems and analytics tools have become much more accessible.
    Everyone can take advantage of data analytics, and there’s a growing need to move
    the data into a location for performing data analysis, like a data lake or date
    warehouse. You can use ETL to get the data from these operational data systems
    into a system to be analyzed. ETL is a process that comprises the following three
    different stages:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据移动和转换以进行业务智能（BI）的需求非常普遍。企业长期以来一直在使用提取、转换和加载（ETL）平台将数据从一个系统移动到另一个系统。数据分析正在成为每个大大小小企业的重要组成部分，因此并不奇怪ETL平台变得越来越重要。数据已经分布在更多的系统中，分析工具也变得更加易于获取。每个人都可以利用数据分析，因此有将数据移动到用于执行数据分析的位置（如数据湖或数据仓库）的增长需求。可以使用ETL将这些操作数据系统中的数据获取到要分析的系统中。ETL是一个包括以下三个不同阶段的过程：
- en: Extract
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 提取
- en: Data is extracted or exported from business systems and data storage systems,
    legacy systems, operational databases, external services, and event Enterprise
    Resource Planning (ERP) or Customer Relationship Management (CRM) systems. When
    extracting data from the various sources, it’s important to determine the velocity,
    how often the data is extracted from each source, and the priority across the
    various sources.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是从业务系统和数据存储系统、遗留系统、运营数据库、外部服务以及企业资源规划（ERP）或客户关系管理（CRM）系统中提取或导出的。从各种来源提取数据时，重要的是确定速度，即每个来源的数据提取频率以及在各种来源之间的优先级。
- en: Transform
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 转换
- en: Next, the extracted data is transformed; this would typically involve a number
    of data cleansing, transformation, and enrichment tasks. The data can be processed
    off a stream and is often stored in an interim staging store for batch processing.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，提取的数据进行转换；这通常涉及多个数据清洗、转换和增强任务。数据可以通过流进行处理，并经常存储在中间临时存储中以进行批处理处理。
- en: Load
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 加载
- en: The transformed data then is loaded into the destination and can be analyzed
    for BI.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 转换后的数据然后加载到目标位置，可以进行业务智能分析。
- en: All of the major cloud providers offer managed ETL services, like AWS Glue,
    Azure Data Factory, and Google Cloud DataFlow. Moving and processing data from
    one source to another is increasingly important and common in today’s cloud native
    applications.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 所有主要的云服务提供商都提供托管的ETL服务，例如AWS Glue、Azure Data Factory和Google Cloud DataFlow。
    在今天的云原生应用程序中，从一个源移动和处理数据变得越来越重要和普遍。
- en: Microservices and Data Lakes
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务和数据湖
- en: One challenge of dealing with decentralized data in a microservices architecture
    is the need to perform reporting or analysis across data in multiple services.
    Some reporting and analytics requirements will need the data from the services
    to be in a common datastore.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务架构中处理分散的数据的一个挑战是需要跨多个服务的数据执行报告或分析。 某些报告和分析需求将需要来自服务的数据在一个共同的数据存储中。
- en: Note
  id: totrans-180
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It might not be necessary to move the data in order to perform the required
    analysis and reporting across all of the data. Some or all of the analysis can
    be performed on each of the individual datastores in conjunction with some centralized
    analysis tasks on the results.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行所需的所有数据分析和报告，可能并不需要移动数据。 可以在每个单独的数据存储中执行部分或全部分析，同时结合一些集中的分析任务对结果进行分析。
- en: Having each service work from a shared or common database will, however, violate
    one of the microservices principles and potentially introduce coupling between
    the services. A common way to approach this is through data movement and aggregating
    the data into a location for a reporting or analytics team. In [Figure 4-8](#data_from_multiple_microservices_aggrega),
    data from multiple microservices datastores is aggregated into a centralized database
    in order to deliver the necessary reporting and analytics requirements.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，让每个服务从一个共享或共同的数据库工作，可能会违反微服务原则之一，并且可能引入服务之间的耦合。 处理这个的常见方法是通过数据移动和将数据聚合到一个位置供报告或分析团队使用。
    在[图 4-8](#data_from_multiple_microservices_aggrega)中，来自多个微服务数据存储的数据被聚合到一个集中数据库中，以满足必要的报告和分析需求。
- en: '![clna 0408](Images/clna_0408.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0408](Images/clna_0408.png)'
- en: Figure 4-8\. Data from multiple microservices aggregated in a centralized datastore
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-8\. 多个微服务的数据聚合在一个集中的数据存储中
- en: The data analytics or reporting team will need to determine how to get the data
    from the various service teams that it requires for the purpose of reporting without
    introducing coupling. There are a number of ways to approach this, and it will
    be important to ensure loose coupling is maintained, allowing the teams to remain
    agile and deliver value quickly.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析或报告团队将需要确定如何从各个服务团队获取所需的数据以进行报告，而不引入耦合。 有多种方法可以解决这个问题，重要的是要确保保持松散耦合，使团队能够保持敏捷并快速交付价值。
- en: The individual services team could give the data analytics teams read access
    to the database and allow them to replicate the data, as depicted in [Figure 4-9](#the_data_analytics_team_consumes_data).
    This would be a very quick and easy approach, but the service team does not control
    when or how much load the data extraction will put on the store, causing potential
    performance issues. This also introduces coupling, and it’s likely that the service
    teams then will need to coordinate with the data analytics team when making internal
    schema changes. The ETL load on the database adversely affecting service performance
    can be addressed by giving the data analytics team access to a read replica instead
    of the primary data. It might also be possible to give the data analytics team
    access to a view on the data instead of the raw documents or tables. This would
    help to mitigate some of the coupling concerns.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 服务团队可以给数据分析团队对数据库的只读访问权限，并允许他们复制数据，如[图 4-9](#the_data_analytics_team_consumes_data)所示。
    这将是一种非常快速和简便的方法，但服务团队无法控制数据提取对存储的负载和影响，可能会导致性能问题。 这也引入了耦合，并且很可能服务团队在进行内部模式更改时需要与数据分析团队协调。
    为了解决数据库上的ETL负载对服务性能的不利影响，可以让数据分析团队访问只读复制品而不是主数据。 另外，也可能让数据分析团队访问数据的视图而不是原始文档或表格。
    这有助于减轻一些耦合问题。
- en: '![clna 0409](Images/clna_0409.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0409](Images/clna_0409.png)'
- en: Figure 4-9\. The data analytics team consumes data directly from the service
    team’s database
  id: totrans-188
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-9\. 数据分析团队直接从服务团队的数据库消耗数据
- en: This approach can work in the early phases of the application with a handful
    of services, but it will be challenging as the application and teams grow. Another
    approach is to use an *integration datastore*. The service team provisions and
    maintains a datastore for internal integrations, as shown in [Figure 4-10](#database_as_an_api).
    This allows the service team to control what data and the shape of the data in
    the integration repository. This integration repository should be managed like
    an API, documented and versioned. The service team could run ETL jobs to maintain
    the database or use CDC and treat it like a materialized view. The service team
    could make changes to its operational store without affecting the other teams.
    The service team would be responsible for the integration store.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用早期阶段，这种方法可以处理少量服务，但随着应用和团队的增长，将会变得具有挑战性。另一种方法是使用*集成数据存储*。服务团队为内部集成配置和维护数据存储，如
    [图 4-10](#database_as_an_api) 所示。这使得服务团队可以控制集成存储库中的数据及其数据形式。集成存储库应该像 API 一样进行管理、文档化和版本控制。服务团队可以运行
    ETL 作业来维护数据库，也可以使用 CDC 并将其视为物化视图。服务团队可以对其运营存储进行更改，而不影响其他团队。服务团队将负责集成存储。
- en: '![clna 0410](Images/clna_0410.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0410](Images/clna_0410.png)'
- en: Figure 4-10\. Database as an API
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-10\. 数据库作为 API
- en: This could be turned around such that a service consumer, like the data analytics
    team, asks a service team to export or write data to the data lake, as illustrated
    in [Figure 4-11](#service_team_data_export_service_api), or to a staging store,
    as in [Figure 4-12](#service_teams_write_to_a_staging_store). The service teams
    support replication or data, logs, or data exports to a client-provided location
    as part of the service features and API. The data analytics team would provision
    a store or location in a datastore for each service team. The data analytics team
    then subscribes to data needed for aggregated analytics.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以转变为服务消费者（如数据分析团队）请求服务团队将数据导出或写入数据湖，如 [图 4-11](#service_team_data_export_service_api)
    所示，或者写入到临时存储，如 [图 4-12](#service_teams_write_to_a_staging_store) 所示。服务团队支持数据复制、日志或数据导出到客户提供的位置作为服务功能和
    API 的一部分。数据分析团队将为每个服务团队在数据存储中配置存储或位置。然后数据分析团队订阅所需的数据进行聚合分析。
- en: '![clna 0411](Images/clna_0411.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0411](Images/clna_0411.png)'
- en: Figure 4-11\. Service team data export service API
  id: totrans-194
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-11\. 服务团队数据导出服务 API
- en: '![clna 0412](Images/clna_0412.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0412](Images/clna_0412.png)'
- en: Figure 4-12\. Service teams write to a staging store
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-12\. 服务团队写入到临时存储
- en: It’s not uncommon for services to support data exports. The service implementation
    would define what export format and protocols are part of its API. This, for example,
    would be a configuration for an object storage location and credentials to which
    to send nightly exports, or maybe a webhook to which to send batches of changes.
    A service consumer such as the data analytics team would have access to the service
    API, allowing it to subscribe to data changes or exports. The team could send
    locations and credentials to which to either dump export files or send events.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 服务支持数据导出并非罕见。服务实现将定义其 API 的导出格式和协议。例如，配置对象存储位置和凭据以发送夜间导出，或者是发送变更批次的 Webhook。数据分析团队等服务消费者可以访问服务
    API，允许其订阅数据变更或导出。团队可以发送位置和凭据，以便要么倒入导出文件，要么发送事件。
- en: Client Access to Data
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户端访问数据
- en: Clients applications generally do not have direct access to the datastores in
    most applications built today. Data is commonly accessed through a service that’s
    responsible for performing authorizations, auditing, validation, and transformation
    of the data. The service is usually responsible for carrying out other functions,
    although in many data-centric applications, a large part of the service implementation
    simply handles data read and write operations.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的大多数应用程序中，客户端应用程序通常无法直接访问数据存储。数据通常通过负责进行授权、审计、验证和数据转换的服务来访问。尽管在许多数据中心的应用程序中，服务实现的大部分工作只是处理数据的读写操作。
- en: A simple data-centric application would generally require you to build and operate
    a service that performs authentication, authorization, logging, transformations,
    and validation of data. It does, however, need to control who can access what
    within the datastore and validate what’s being written. [Figure 4-13](#client_application_with_a_backend_servic)
    shows a typical frontend application calling a backend service that reads and
    writes to a single database. This is a common architecture for many applications
    today.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的数据中心应用通常需要您构建和操作一个服务，该服务执行身份验证、授权、日志记录、数据转换和验证。但是，它确实需要控制数据存储中谁能访问什么，并验证正在写入的内容。[图 4-13](#client_application_with_a_backend_servic)显示了一个典型的前端应用程序调用后端服务，后者读取和写入单个数据库。这是今天许多应用程序的常见架构。
- en: '![clna 0413](Images/clna_0413.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0413](Images/clna_0413.png)'
- en: Figure 4-13\. Client application with a backend service and database
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-13\. 带有后端服务和数据库的客户端应用程序
- en: Restricted Client Tokens (Valet-Key)
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 受限客户端令牌（代客钥匙）
- en: A service can create and return a token to a consumer that has limited use.
    This can actually be implemented using OAuth or even a custom cryptographically
    signed policy. The valet key is commonly used as a metaphor to explain how OAuth
    works and is a commonly used cloud design pattern. The token returned might be
    able to access only a specific data item for a limited period of time or upload
    a file to a specific location in a datastore. This can be a convenient way to
    offload processing from a service, reducing the cost and scale of the service
    and delivering better performance. In [Figure 4-14](#client_uploading_a_file_thatas_passed_th),
    a file is uploaded to a service that writes the file to storage.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 服务可以创建并返回一个对消费者有限使用的令牌。实际上，可以使用OAuth甚至自定义的加密签名策略来实现此功能。代客钥匙通常用作解释OAuth工作原理的隐喻，并且是常用的云设计模式。返回的令牌可能只能访问数据存储中的特定数据项，且仅在有限时间内或将文件上传到特定位置。这可以是一种从服务中卸载处理的便捷方式，降低服务的成本和规模，并提供更好的性能。在[图 4-14](#client_uploading_a_file_thatas_passed_th)中，文件上传到将文件写入存储的服务中。
- en: '![clna 0414](Images/clna_0414.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0414](Images/clna_0414.png)'
- en: Figure 4-14\. Client uploading a file that’s passed through the service
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-14\. 客户端上传通过服务传递的文件
- en: Instead of streaming a file through the service, it can be much more efficient
    to return a token to the client with a location to access the file if it were
    reading or uploading the file to a specific location. In [Figure 4-15](#the_client_gets_a_token_and_path_from),
    the client requests a token and a location from the service, which then generates
    a token with some policies. The token policy can restrict the location to which
    the file can be uploaded, and it’s a best practice to set an expiration so that
    the token cannot be used anytime later on. The token should follow the principle
    of *least privilege*, granting the minimum permissions necessary to complete the
    task. In Microsoft Azure Blob Storage, the token is also referred to as a *shared-access
    signature*, and in Amazon S3, this would be a *presigned URL*. After the file
    is uploaded, an object storage function could be used to update the application
    state.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 与通过服务流式传输文件不同，将一个位置令牌返回给客户端可能更有效，以便客户端读取或上传文件到特定位置。在[图 4-15](#the_client_gets_a_token_and_path_from)中，客户端请求服务的令牌和位置，然后服务生成带有某些策略的令牌。令牌策略可以限制文件上传的位置，并且最佳实践是设置过期时间，以便令牌在稍后任何时间都无法使用。令牌应遵循*最小权限*原则，仅授予完成任务所需的最低权限。在Microsoft
    Azure Blob Storage中，该令牌也称为*共享访问签名*，在Amazon S3中，这将是*预签名 URL*。文件上传后，可以使用对象存储功能更新应用程序状态。
- en: '![clna 0415](Images/clna_0415.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0415](Images/clna_0415.png)'
- en: Figure 4-15\. The client gets a token and path from a service to upload directly
    to storage
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-15\. 客户端从服务获取令牌和路径直接上传到存储
- en: Database Services with Fine-Grained Access Control
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库服务与细粒度访问控制
- en: Some databases provide fine-grained access control to data in the database.
    These database services are sometimes called a Backend as a Service (BaaS) or
    Mobile Backend as a Service (MBaaS). A full-featured MBaaS will generally offer
    more than just data storage, given that mobile applications often need identity
    management and notification services as well. This almost feels like we have circled
    back to the days of the old thick-client applications. Thankfully, data storage
    services have evolved so that it’s not exactly the same. [Figure 4-16](#a_mobile_application_connecting_to_a_dat)
    presents a mobile client connecting to a database service without having to deploy
    and manage an additional API. If there’s no need to ship a customer API, this
    can be a great way to quickly get an application out with low operational overhead.
    Careful attention is needed with releasing updates and testing the security rules
    to ensure that only the appropriate people are able to access the data.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据库提供对数据库中数据的精细访问控制。这些数据库服务有时称为后端即服务 (BaaS) 或移动后端即服务 (MBaaS)。一个功能齐全的 MBaaS
    通常不仅提供数据存储，因为移动应用程序通常还需要身份管理和通知服务。这几乎感觉像是我们回到了旧的厚客户端应用程序的时代。值得庆幸的是，数据存储服务已经发展，所以情况并非完全相同。[图
    4-16](#a_mobile_application_connecting_to_a_dat) 展示了一个移动客户端连接到数据库服务，而无需部署和管理额外的
    API。如果不需要提供客户 API，这是一个快速推出应用程序的好方法，操作开销低。需要注意发布更新和测试安全规则，以确保只有适当的人员能够访问数据。
- en: '![clna 0416](Images/clna_0416.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0416](Images/clna_0416.png)'
- en: Figure 4-16\. A mobile application connecting to a database
  id: totrans-213
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-16\. 移动应用连接到数据库
- en: Databases such as Google’s Cloud FireStore allow you to apply security rules
    that provide access control and data validation. Instead of building a service
    to control access and validate requests, you write security rules and validation.
    A user is required to authenticate to Google Firebase Authentication service,
    which can federate to other identity providers, like Microsoft’s Azure Active
    Directory services. After a user is authenticated, the client application can
    connect directly to the database service and read or write data, provided the
    operations satisfy the defined security rules.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如 Google 的 Cloud FireStore 等数据库允许您应用安全规则，提供访问控制和数据验证。您可以编写安全规则和验证，而不是构建一个控制访问和验证请求的服务。用户需要对接到
    Google Firebase 认证服务进行身份验证，该服务可以联合其他身份提供者，如微软的 Azure Active Directory 服务。用户认证通过后，客户端应用程序可以直接连接到数据库服务，并读取或写入数据，只要操作符合定义的安全规则。
- en: GraphQL Data Service
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GraphQL 数据服务
- en: Instead of building and operating a custom service to manage client access to
    data, you can deploy and configure a GraphQL server to provide clients access
    to data. In [Figure 4-17](#graphql_data_access_service), a GraphQL service is
    deployed and configured to handle authorization, validation, caching, and pagination
    of data. Fully managed GraphQL services, like AWS AppSync, make it extremely easy
    to deploy a GraphQL-based backend for your client services.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以部署和配置一个 GraphQL 服务器来为客户端提供数据访问，而不是构建和操作自定义服务来管理客户端对数据的访问。在 [图 4-17](#graphql_data_access_service)
    中，部署和配置了一个 GraphQL 服务来处理数据的授权、验证、缓存和分页。像 AWS AppSync 这样的完全托管的 GraphQL 服务极大地简化了为客户端服务部署基于
    GraphQL 的后端的过程。
- en: Note
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: GraphQL is neither a database query language nor storage model; it’s an API
    that returns application data based on a schema that’s completely independent
    of how the data is stored.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: GraphQL 不是数据库查询语言或存储模型；它是一个 API，根据完全独立于数据存储方式的模式返回应用程序数据。
- en: '![clna 0417](Images/clna_0417.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0417](Images/clna_0417.png)'
- en: Figure 4-17\. GraphQL data access service
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-17\. GraphQL 数据访问服务
- en: GraphQL is flexible and configurable through a GraphQL specification. You can
    configure it with multiple providers, and even configure it to execute services
    either running in a container or deployed as functions that are invoked on request,
    as shown in [Figure 4-18](#graphql_service_with_multiple_providers). GraphQL is
    a great fit for data-centric backends with the occasional service method that
    needs to be invoked. Services like GitHub are actually moving their entire API
    over to GraphQL because this provides more flexibility to the consumers of the
    API. GraphQL can be helpful in addressing the over-fetching and chattiness that’s
    sometimes common with REST-based APIs.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: GraphQL 通过 GraphQL 规范变得灵活且可配置。您可以配置它与多个提供者一起使用，并且甚至可以配置它执行在容器中运行的多个服务，或者作为请求时调用的函数，如[图 4-18](#graphql_service_with_multiple_providers)所示。GraphQL
    非常适合于以数据为中心的后端，偶尔需要调用的服务方法。像 GitHub 这样的服务实际上正在将其整个 API 转移到 GraphQL，因为这为 API 的消费者提供了更大的灵活性。GraphQL
    在解决基于 REST 的 API 中有时常见的过度获取和过多请求的问题方面非常有帮助。
- en: GraphQL uses a schema-first approach, defining nodes (objects) and edges (relationships)
    as part of a schema definition for the graph structure. Consumers can query the
    schema for details about the types and relationships across the objects. One benefit
    of GraphQL is that it makes it easy to define the data you want, and only the
    data you want, without having to make multiple calls or fetch data that’s not
    needed. The specification supports authorizations, pagination, caching, and more.
    This can make it quick and easy to create a backend that handles most of the features
    needed in a data-centric application. For more information, visit the [GraphQL
    website](http://www.graphql.org).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: GraphQL 使用基于模式的方法，将节点（对象）和边（关系）定义为图结构的模式定义的一部分。消费者可以查询模式以获取有关对象之间类型和关系的详细信息。GraphQL
    的一个好处是它可以轻松定义您想要的数据，仅获取您想要的数据，而无需进行多次调用或获取不需要的数据。该规范支持授权、分页、缓存等功能。这使得快速且轻松地创建处理大部分数据中心应用程序所需功能的后端成为可能。有关更多信息，请访问[GraphQL
    网站](http://www.graphql.org)。
- en: '![clna 0418](Images/clna_0418.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0418](Images/clna_0418.png)'
- en: Figure 4-18\. GraphQL service with multiple providers and execution
  id: totrans-224
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-18\. 具有多个提供者和执行的 GraphQL 服务
- en: Fast Scalable Data
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速可扩展的数据
- en: A large majority of application scaling and performance problems can be attributed
    to the databases. This is a common point of contention that can be challenging
    to scale out while meeting an application’s data-quality requirements. In the
    past, it was too easy to put logic into a database in the form of stored procedures
    and triggers, increasing compute requirements on a system that was notoriously
    expensive to scale. We learned to do more in the application and rely less on
    the database for something other than focusing on storing data.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序的大部分扩展和性能问题可以归因于数据库。这是一个常见的争议点，挑战在满足应用程序数据质量要求的同时进行扩展。过去，将逻辑以存储过程和触发器的形式放入数据库中太容易了，这增加了系统的计算需求，而该系统本来就昂贵且难以扩展。我们学会在应用程序中处理更多事务，减少对数据库的依赖，除了用来存储数据之外的其他事务。
- en: Tip
  id: totrans-227
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: There are very few reasons to put logic in a database. Don’t do it. If you go
    there, make sure that you understand the trade-offs. It might make sense in a
    few cases and it might improve performance, but likely at the cost of scalability.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 将逻辑放入数据库几乎没有多少理由。不要这样做。如果你非要这么做，请确保你理解了其中的权衡。在少数情况下这么做可能是有道理的，它可能会提高性能，但很可能会牺牲可扩展性。
- en: Scaling anything and everything can be achieved through replication and partitioning.
    Replicating the data to a cache, materialized view, or read-replica can help increase
    the scalability, availability, and performance of data systems. Partitioning data
    either horizontally through sharding, vertically based on data model, or functionally
    based on features will help improve scalability by distributing the load across
    systems.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 通过复制和分区可以实现任何事物的扩展。将数据复制到缓存、物化视图或只读副本可以帮助提高数据系统的可扩展性、可用性和性能。通过水平分片、基于数据模型的垂直分区或基于功能的功能分区数据将有助于通过系统分布负载来提高可扩展性。
- en: Sharding Data
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据分片
- en: Sharding data is about dividing the datastore into horizontal partitions, known
    as *shards*. Each shard contains the same schema, but holds a subset of the data.
    Sharding often is used to scale a system by distributing the load across multiple
    data storage systems.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分片是将数据存储区划分为水平分区，称为*分片*。每个分片包含相同的模式，但持有数据的子集。通过将负载分布到多个数据存储系统中，分片通常用于通过扩展系统来实现扩展。
- en: When sharding data, it’s important to determine how many shards to use and how
    to distribute the data across the shards. Deciding how to distribute the data
    across shards heavily depends on the application’s data. It’s important to distribute
    the data in such a way that one single shard does not become overloaded and receive
    all or most of the load. Because the data for each shard or partition is commonly
    in a separate datastore, it’s important that the application can connect to the
    appropriate shard (partition or database).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在分片数据时，确定使用多少分片以及如何在分片之间分配数据是非常重要的。决定如何在分片之间分配数据在很大程度上取决于应用程序的数据。重要的是以这样的方式分配数据，使得单个分片不会过载并接收所有或大部分负载。由于每个分片或分区的数据通常位于单独的数据存储中，因此应用程序能够连接到适当的分片（分区或数据库）是非常重要的。
- en: Caching Data
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓存数据
- en: Data caching is important to scaling applications and improving performance.
    Caching is really just about copying the data to a faster storage medium like
    memory, and generally closer to the consumer. There might even be varying layers
    of cache; for example, data can be cached in the memory of the client application
    and in a shared distributed cache on the backend.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 数据缓存对于扩展应用程序和提高性能至关重要。缓存实际上只是将数据复制到更快的存储介质（如内存），通常更靠近消费者。甚至可能存在多个层次的缓存；例如，数据可以在客户端应用程序的内存中缓存，并在后端的共享分布式缓存中缓存。
- en: 'When working with a cache, one of the biggest challenges is keeping the cached
    data synchronized with the source. When the source data changes, it is often necessary
    to either invalidate or update the cached copy of the data. Sometimes, the data
    rarely changes; in fact, in some cases the data will not change through the lifetime
    of the application process, making it possible to load this static data into a
    cache when the application starts and then not need to worry about invalidation.
    Here are some common approaches for cache invalidation and updates:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用缓存时，最大的挑战之一是保持缓存数据与源数据的同步。当源数据发生变化时，通常需要使缓存中的数据失效或更新。有时，数据很少更改；事实上，在某些情况下，数据在应用程序进程的生命周期内不会更改，因此可以在应用程序启动时将这些静态数据加载到缓存中，然后无需担心失效。以下是一些常见的缓存失效和更新方法：
- en: Rely on TTL configurations by setting a value that removes a cached item after
    a configurable expiration time. The application or a service layer then would
    be responsible for reloading the data when it does not find an item in the cache.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过设置一个值来依赖 TTL 配置，该值在可配置的过期时间后移除缓存项。当应用程序或服务层在缓存中找不到项目时，应负责重新加载数据。
- en: Use CDC to update or invalidate a cache. A process subscribes to a datastore
    change stream and is responsible for updating the cache.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 CDC 更新或使缓存失效。一个进程订阅数据存储的变更流，并负责更新缓存。
- en: Application logic is responsible for invalidating or updating the cache when
    it makes changes to the source data.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当应用程序逻辑对源数据进行更改时，负责使缓存失效或更新缓存。
- en: Use a passthrough caching layer that’s responsible for managing cached data.
    This can remove the concern of the data caching implementation from the application.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用透传缓存层来管理缓存数据。这可以减少应用程序对数据缓存实现的关注。
- en: Run a background service at a configuration interval to update a cache.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后台服务以配置的间隔运行，更新缓存。
- en: Use the data replication features of the database or another service to replicate
    the data to a cache.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据库或其他服务的数据复制功能将数据复制到缓存中。
- en: Caching layer renews cached items based on access and available cache resources.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存层根据访问和可用缓存资源更新缓存项。
- en: Content Delivery Networks
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内容传送网络
- en: 'A content delivery network (CDN) is a group of geographically distributed datacenters,
    also known as points of presence (POP). A CDN often is used to cache static content
    closer to consumers. This reduces the latency between the consumer and the content
    or data needed. Following are some common CDN use cases:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 内容传送网络（CDN）是一组地理分布的数据中心，也称为点对点（POP）。CDN通常用于将静态内容缓存在消费者附近，从而减少消费者与所需内容或数据之间的延迟。以下是一些常见的
    CDN 使用案例：
- en: Improve website loading times by placing content closer to the consumer.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将内容放置在靠近消费者的地方来改善网站加载时间。
- en: Improve application performance of an API by terminating traffic closer to the
    consumer.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在接近消费者的地方终止流量来提高 API 的应用程序性能。
- en: Speed up software downloads and updates.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加快软件下载和更新。
- en: Increase content availability and redundancy.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加内容可用性和冗余性。
- en: Accelerate file upload through CDN services like Amazon CloudFront.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The content is cached, so a copy of it is stored at the edge locations and will
    be used instead of the source content. In [Figure 4-19](#a_client_accesses_content_cached_in_a_cd),
    a client is fetching a file from a nearby CDN with a much lower latency of 15
    ms as opposed to the 82 ms latency between the client and the source location
    of the file, also known as the *origin*. Caching and CDN technologies enable faster
    retrieval of the content, and scale by removing load from the origin as well.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '![clna 0419](Images/clna_0419.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
- en: Figure 4-19\. A client accesses content cached in a CDN closer to the client
  id: totrans-252
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The content cached in a CDN is usually configured with an expiration date-time,
    also known as *TTL properties*. When the expiration date-time is exceeded, the
    CDN reloads the content from the origin, or source. Many CDN services allow you
    to explicitly invalidate content based on a path; for example, */img/**. Another
    common technique is to change the name of the content by adding a small hash to
    it and updating the reference for consumers. This technique is commonly used for
    web application bundles like the JavaScript and CSS files used in a web application.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some considerations regarding CDN cache management:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Use content expiration to refresh content at specific intervals.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the name of the resource by appending a hash or version to the content.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explicitly expire the cache either through management console or API.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CDN vendors continue adding more features, making it possible to push more and
    more content, data, and services closer to the consumers, improving performance,
    scale, security, and availability. [Figure 4-20](#accelerated_access_to_a_backend_api)
    demonstrates a client calling a backend API with the request being routed through
    the CDN and over the cloud provider’s backbone connection between datacenters.
    This is a much faster route to the API with lower latency, improving the Secure
    Sockets Layer (SSL) handshake between the client and the CDN as well as the API
    request.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '![clna 0420](Images/clna_0420.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
- en: Figure 4-20\. Accelerated access to a backend API
  id: totrans-260
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here are a few additional features to consider when using CDN technologies:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Rules or behaviors
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: It can be necessary to configure routing, adding response headers, or enable
    redirects based on request properties like SSL.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Application logic
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Some CDN vendors like Amazon CloudFront allow you to run application logic at
    the edge, making it possible to personalize content for a consumer.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Custom name
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: It’s often necessary to use a custom name with SSL, especially when serving
    a website through a CDN.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: File upload acceleration
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Some CDN technologies are able to accelerate file upload by reducing the latency
    to the consumer.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: API acceleration
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: As with file upload, it’s possible to accelerate APIs through a CDN by reducing
    the latency to the consumer.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-272
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Use a CDN as much as possible, pushing as much as you can over the CDN.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing Data
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data created and stored continues to grow at exponential rates. The tools
    and technologies used to extract information from data continues to evolve to
    support the growing demand to derive insights from the data, making business insights
    through complex analytics available to even the smallest businesses.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Streams
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Businesses need to reduce their time to insights in order to gain an edge in
    today’s competitive fast-moving markets. Analyzing the data streams in real time
    is a great way to reduce this latency. Streaming data-processing engines are designed
    for unbounded datasets. Unlike data in a traditional data storage system in which
    you have a holistic view of the data at a specific point in time, streams have
    an entity-by-entity view of the data over time. Some data, like stock market trades,
    click streams, or sensor data from devices, comes in as a stream of events that
    never end. Stream processing can be used to detect patterns, identify sequences,
    and look at results. Some events, like a sudden transition in a sensor, might
    be more valuable when they happen and diminish over time or enable a business
    to react more quickly and immediately to these important changes. Detecting a
    sudden drop in inventory, for example, allows a company to order more stock and
    avoid some missed sales opportunities.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Batch
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike stream processing, which is done in real time as the data arrives, batch
    processing is generally performed on very large bounded sets of data as part of
    exploring a data science hypothesis, or at specific intervals to derive business
    insights. Batch processing is able to process all or most of the data and can
    take minutes or hours to complete, whereas stream processing is completed in a
    matter of seconds or less. Batch processing works well with very large volumes
    of data, which might have been stored over a long period of time. This could be
    data from legacy systems or simply data for which you’re looking for patterns
    over many months or years.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Data analytics systems typically use a combination of batch and stream processing.
    The approaches to processing streams and batches have been captured as some well-known
    architecture patterns. The Lambda architecture is an approach in which applications
    write data to an immutable stream. Multiple consumers read data from the stream
    independent of one another. One consumer is concerned with processing data very
    quickly, in near real time, whereas the other consumer is concerned with processing
    in batch and a lower velocity across a larger set of data or archiving the data
    to object storage.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Data Lakes on Object Storage
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data lakes are large, scalable, and generally centralized datastores that allow
    you to store structured and unstructured data. They are commonly used to run map-and-reduce
    jobs for analyzing vast amounts of data. The analytics jobs are highly parallelizable
    so the analysis of the data can easily be distributed across the store. Hadoop
    has become the popular tool for data lakes and big data analysis. Data is commonly
    stored on a cluster of computers in the Hadoop Distributed File System (HDFS),
    and various tools in the Hadoop ecosystem are used to analyze the data. All of
    the major public cloud vendors provide managed Hadoop clusters for storing and
    analyzing the data. The clusters can become expensive, requiring a large number
    of very big machines. These machines might be running even when there are no jobs
    to run on the cluster. It is possible to shut down these clusters and maintain
    state for cost savings when they are not in use and resume the clusters during
    periods of data loading or analysis.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: It’s becoming increasingly common to use fully managed services that allow you
    to pay for the data loaded in the service and pay-per-job execution. These services
    not only can reduce operational costs related to managing these services, but
    also can result in big savings when running the occasional analytics jobs. Cloud
    vendors have started providing services that align with a serverless cost model
    for provisioning data lakes. Azure Data Lake and Amazon S3–based AWS Lake Formation
    are some examples of this.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Data Lakes and Data Warehouses
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data lakes are often compared and contrasted with data warehouses because they
    are similar, although in large organizations it’s not uncommon to see both used.
    Data lakes are generally used to store raw and unstructured data, whereas the
    data in a data warehouse has been processed and organized into a well-defined
    schema. It’s common to write data into a data lake and then process it from the
    data lake into a data warehouse. Data scientists are able to explore and analyze
    the data to discover trends that can help define what is processed into a data
    warehouse for business professionals.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Distributed Query Engines
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Distributed query engines are becoming increasingly popular, supporting the
    need to quickly analyze data stored across multiple data systems. Distributed
    query engines separate the query engine from the storage engine and use techniques
    to distribute the query across a pool of workers. A number of open source query
    engines have become popular in the market: Presto, Spark SQL, Drill, and Impala,
    to name a few. These query engines utilize a provider model to access various
    data storage systems and partitions.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop jobs were designed for processing large amounts of data through jobs
    that would run for minutes or even hours crunching through the vast amounts of
    data. Although a structured query language (SQL)–like interface exists in tools
    such as HIVE, the queries are translated to jobs submitted to a job queue and
    scheduled. A client would not expect that the results from a job would return
    in minutes or seconds. It is, however, expected that distributed query engines
    like Facebook’s Presto would return results from a query in the matter of minutes
    or even seconds.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 作业旨在通过运行几分钟甚至几小时的作业来处理大量数据。虽然工具如 HIVE 中存在类似结构化查询语言（SQL）的界面，但查询会被转换为提交到作业队列并进行调度的作业。客户端不会期望作业的结果在几分钟或几秒钟内返回。然而，分布式查询引擎如
    Facebook 的 Presto 可以在几分钟甚至几秒钟内返回查询结果。
- en: 'At a high level, a client submits a query to the distributed query engine.
    A coordinator is responsible for parsing the query and scheduling work to a pool
    of workers. The pool of workers then connects to the datastores needed to satisfy
    the query, fetches the results, and merges the results from each to the workers.
    The query can run against a combination of datastores: relational, document, object,
    file, and so on. [Figure 4-21](#overview_of_a_distributed_query_engine) depicts
    a query that fetches information from a MongoDB database and some comma-separated
    values (CSV) files stored in an object store like Amazon S3, Azure Blob Storage,
    or Google Object Storage.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，客户端向分布式查询引擎提交查询。协调器负责解析查询并将工作调度到一组工作节点。工作节点连接到需要满足查询的数据存储，获取结果，并将来自每个工作节点的结果合并。查询可以针对多种数据存储运行：关系型、文档型、对象型、文件型等等。[图 4-21](#overview_of_a_distributed_query_engine)
    描述了从 MongoDB 数据库和存储在像 Amazon S3、Azure Blob Storage 或 Google Object Storage 这样的对象存储中的逗号分隔值（CSV）文件中获取信息的查询。
- en: The cloud makes it possible to quickly and easily scale workers, allowing the
    distributed query engine to handle query demands.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算使得快速和简单地扩展工作节点成为可能，从而使分布式查询引擎能够处理查询需求。
- en: '![clna 0421](Images/clna_0421.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0421](Images/clna_0421.png)'
- en: Figure 4-21\. Overview of a distributed query engine
  id: totrans-292
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-21\. 分布式查询引擎概述
- en: Databases on Kubernetes
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 上的数据库
- en: Kubernetes dynamic environment can make it challenging to run data storage systems
    in a Kubernetes cluster. Kubernetes pods are created and destroyed, and cluster
    nodes can be added or removed, forcing pods to move to new nodes. Running a stateful
    workload like a database is much different than stateless services. Kubernetes
    has features like stateful sets and support for persistent volumes to help with
    deploying and operating databases in a Kubernetes cluster. Most of the durable
    data storage systems require a disk volume as the underlying persistent storage
    mechanism, so understanding how to attach storage to pods and how volumes work
    is important when deploying databases on Kubernetes.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 动态环境可能会使在 Kubernetes 集群中运行数据存储系统变得具有挑战性。Kubernetes Pod 可以创建和销毁，并且集群节点可以添加或移除，强制
    Pod 移动到新节点。运行像数据库这样的有状态工作负载与无状态服务有很大不同。Kubernetes 具有诸如有状态集和对持久卷的支持等特性，有助于在 Kubernetes
    集群中部署和操作数据库。大多数持久数据存储系统需要磁盘卷作为底层持久存储机制，因此在在 Kubernetes 上部署数据库时，了解如何将存储附加到 Pod
    和存储卷的工作原理非常重要。
- en: In addition to providing the underlying storage volumes, data storage systems
    have different routing and connectivity needs as well as hardware, scheduling,
    and operational requirements. Some of the newer cloud native databases have been
    built for these more dynamic environments and can take advantage of the environments
    to scale out and tolerate transient errors.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供底层存储卷外，数据存储系统还具有不同的路由和连接需求，以及硬件、调度和操作需求。一些新型的云原生数据库已经为这些更动态的环境构建，并且可以利用这些环境来进行扩展和容忍瞬态错误。
- en: Note
  id: totrans-296
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There are a growing number of operators available to help simplify the deployment
    and management of data systems on Kubernetes. Operator Hub is a directory listing
    of operators ([*https://www.operatorhub.io*](https://www.operatorhub.io)).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 有越来越多的操作者可用来简化在 Kubernetes 上部署和管理数据系统。Operator Hub 是操作者的目录列表（[*https://www.operatorhub.io*](https://www.operatorhub.io)）。
- en: Storage Volumes
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储卷
- en: 'A database system like MongoDB runs in a container on Kubernetes and often
    needs a durable volume with a life cycle different from the container. Managing
    storage is much different than managing compute. Kubernetes volumes are mounted
    into pods using persistent volumes, persistent volume claims, and underlying storage
    providers. Following are some fundamental storage volume terms and concepts:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 像 MongoDB 这样的数据库系统在 Kubernetes 上运行在容器中，通常需要一个与容器不同的生命周期的持久卷。管理存储与管理计算有很大的不同。Kubernetes
    卷通过持久卷、持久卷声明和底层存储提供程序挂载到 Pod 中。以下是一些基本的存储卷术语和概念：
- en: Persistent volume
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 持久卷
- en: A persistent volume is the Kubernetes resource that represents the actual physical
    storage service, like a cloud provider storage disk.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 持久卷是代表实际物理存储服务的 Kubernetes 资源，例如云提供商的存储磁盘。
- en: Persistent volume claim
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 持久卷声明
- en: A persistent volume storage claim is a storage request, and Kubernetes will
    assign and associate a persistent volume to it.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 持久卷存储声明是一个存储请求，Kubernetes 将为其分配并关联一个持久卷。
- en: Storage class
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类
- en: A storage class defines storage properties for the dynamic provisioning of a
    persistent volume.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类定义了用于动态配置持久卷的存储属性。
- en: A cluster administrator will provision persistent volumes that capture the underlying
    implementation of the storage. This could be a persistent volume to a network-attached
    file share or cloud provider durable disks. When using cloud provider disks, it’s
    more likely one or more storage classes will be defined and dynamic provisioning
    will be used. The storage class will be created with a name that can be used to
    reference the resource, and the storage class will define a provisioner as well
    as the parameters to pass to the provisioner. Cloud providers offer multiple disk
    options with different price and performance characteristics. Different storage
    classes are often created with the different options that should be available
    in the cluster.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 群集管理员将配置捕获存储的持久卷。这可以是持久卷到网络附加文件共享或云提供商的持久性磁盘。当使用云提供商的磁盘时，很可能定义一个或多个存储类，并使用动态配置。存储类将以可用于引用资源的名称创建，并定义一个提供者以及传递给提供者的参数。云提供商提供多种具有不同价格和性能特征的磁盘选项。通常会创建不同的存储类，以便在群集中可用不同的选项。
- en: A pod is going to be created that requires a persistent storage volume so that
    data is still there when the pod is removed and comes back up on another node.
    Before creating the pod, a persistent volume claim is created, specifying the
    storage requirements for the workload. When a persistent volume claim is created,
    and references a specific storage class, the provisioner and parameters defined
    in that storage class will be used to create a persistent volume that satisfies
    the persistent volume claims request. The pod that references the persistent volume
    claim is created and the volume is mounted at the path specified by the pod. [Figure 4-22](#a_kubernetes_pod_persistent_volume_relat)
    shows a pod with a reference to a persistent volume claim that references a persistent
    volume. The persistent volume resource and plug-in contains the configuration
    and implementation necessary to attach the underlying storage implementation.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 将创建一个需要持久存储卷的 Pod，以便当 Pod 被删除并在另一个节点上重新启动时数据仍然存在。在创建 Pod 之前，会创建一个持久卷声明，指定工作负载的存储要求。创建持久卷声明时，如果引用了特定的存储类，则将使用存储类中定义的提供者和参数来创建满足持久卷声明请求的持久卷。创建引用持久卷声明的
    Pod，并在 Pod 指定的路径上挂载卷。[图 4-22](#a_kubernetes_pod_persistent_volume_relat) 显示了一个引用持久卷声明的
    Pod，并引用了一个持久卷的 Pod。持久卷资源和插件包含了附加底层存储实现所需的配置和实现。
- en: '![clna 0422](Images/clna_0422.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0422](Images/clna_0422.png)'
- en: Figure 4-22\. A Kubernetes pod persistent volume relationship
  id: totrans-309
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-22\. Kubernetes Pod 持久卷关系
- en: Note
  id: totrans-310
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Some data systems might be deployed in a cluster using ephemeral storage. Do
    not configure these systems to store data in the container; instead, use a persistent
    volume mapped to a node’s ephemeral disks.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据系统可能使用临时存储在群集中部署。不要将这些系统配置为将数据存储在容器中；而是使用映射到节点临时磁盘的持久卷。
- en: StatefulSets
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StatefulSets
- en: StatefulSets were designed to address the problem of running stateful services
    like data storage systems on Kubernetes. StatefulSets manage the deployment and
    scaling of a set of pods based on a container specification. StatefulSets provide
    a guarantee about the order and uniqueness of the pods. The pods created from
    the specification each have a persistent identifier that is maintained across
    any rescheduling. The unique pod identity comprises the StatefulSet name and an
    ordinal starting with zero. So, a StatefulSet named “mongo” and a replica setting
    of “3” would create three pods named “mongo-0,” “mongo-1,” and “mongo-2,” each
    of which could be addressed using this stable pod name. This is important because
    clients often need to be able to address a specific replica in a storage system
    and the replicas often need to communicate between one another. StatefulSets also
    create a persistent volume and persistent volume claim for each individual pod,
    and they are configured such that the disk created for the “mongo-0” pod is bound
    to the “mongo-0” pod when it’s rescheduled.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSets旨在解决在Kubernetes上运行类似数据存储系统等有状态服务的问题。StatefulSets管理一组基于容器规范的Pod的部署和扩展。StatefulSets提供有关Pod顺序和唯一性的保证。从规范创建的Pod具有跨任何重新调度维护的持久标识符。唯一的Pod标识包括StatefulSet名称和从零开始的序数。因此，一个名为“mongo”的StatefulSet和“3”的副本设置将创建三个名为“mongo-0”、“mongo-1”和“mongo-2”的Pod，每个Pod都可以使用这个稳定的Pod名称进行访问。这很重要，因为客户端通常需要能够访问存储系统中的特定副本，并且副本通常需要彼此之间进行通信。StatefulSets还为每个单独的Pod创建持久卷和持久卷声明，并且它们被配置为当“mongo-0”
    Pod重新调度时，为“mongo-0” Pod绑定创建的磁盘。
- en: Note
  id: totrans-314
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: StatefulSets currently require a headless service, which is responsible for
    the network identity of the pods and must be created in addition to the StatefulSet.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 目前StatefulSets需要一个无头服务，负责Pod的网络标识，并且必须在StatefulSet之外创建。
- en: Affinity and anti-affinity is a feature of Kubernetes that allows you to constrain
    which nodes pods will run on. Pod anti-affinity can be used to improve the availability
    of a data storage system running on Kubernetes by ensuring replicas are not running
    on the same node. If a primary and secondary were running on the same node and
    that node happened to go down, the database would be unavailable until the pods
    were rescheduled and started on another node.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 亲和性和反亲和性是Kubernetes的一个功能，允许您约束Pod将在哪些节点上运行。Pod反亲和性可以通过确保副本不在同一个节点上运行来提高在Kubernetes上运行的数据存储系统的可用性。如果主节点和备份节点运行在同一个节点上，并且该节点发生故障，则数据库将不可用，直到Pod重新调度并在另一个节点上启动。
- en: Cloud providers offer many different types of compute instance types that are
    better suited for different types of workloads. Data storage systems will often
    run better on compute instances that are optimized for disk access, although some
    might require higher memory instances. The stateless services running the cluster,
    however, do not require these specialized instances that will often cost more
    and are fine running on general commodity instances. You can add a pool of storage-optimized
    nodes to a Kubernetes cluster to run the storage workloads that can benefit from
    these resources. You can use Kubernetes node selection along with taints and tolerations
    to ensure the data storage systems are scheduled on the pool of storage optimized
    nodes and that other services are not.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 云提供商提供许多不同类型的计算实例类型，这些类型更适合不同类型的工作负载。数据存储系统通常在优化了磁盘访问的计算实例上运行得更好，尽管有些可能需要更高内存的实例。然而，运行在集群中的无状态服务不需要这些专门的实例，这些实例通常成本更高，可以在通用的普通实例上正常运行。您可以向Kubernetes集群添加一组优化了存储的节点池，以运行可以从这些资源中受益的存储工作负载。您可以使用Kubernetes节点选择以及污点和容忍来确保数据存储系统被调度在优化了存储的节点池上，并且其他服务不被调度到这些节点上。
- en: Given most data storage systems are not Kubernetes aware, it’s often necessary
    to create an adapter service that runs with the data storage system pod. These
    services are often responsible for injecting configuration or cluster environment
    settings into the data storage system. For example, if we deployed a MongoDB cluster
    and need to scale the cluster with another node, the MongoDB sidecar service would
    be responsible for adding the new MongoDB pod to the MongoDB cluster.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于大多数数据存储系统不具备Kubernetes感知能力，通常需要创建一个适配器服务，与数据存储系统Pod一起运行。这些服务通常负责向数据存储系统注入配置或集群环境设置。例如，如果我们部署了一个MongoDB集群，并且需要通过另一个节点扩展集群，MongoDB的sidecar服务将负责将新的MongoDB
    Pod添加到MongoDB集群中。
- en: DaemonSets
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DaemonSets
- en: 'A DaemonSet ensures that a group of nodes runs a single copy of a pod. This
    can be a useful approach to running data storage systems when the system needs
    to be part of the cluster and use nodes dedicated to storage system. A pool of
    nodes would be created in the cluster for the purpose of running the data storage
    system. A node selector would be used to ensure the data storage system was only
    scheduled to these dedicated nodes. Taints and tolerations would be used to ensure
    other processes were not scheduled on these nodes. Here are some trade-offs and
    considerations when deciding between daemon and stateful sets:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 当一组节点运行单个 pod 的副本时，DaemonSet 确保了系统的一部分需要成为集群的一部分并且使用专门用于存储系统的节点。集群中会创建一个节点池，用于运行存储系统。使用节点选择器可以确保只将存储系统调度到这些专用节点上。使用污点和容忍性可以确保其他进程不会被调度到这些节点上。在决定使用守护程序集和有状态集之间时，以下是一些权衡和考虑因素：
- en: Kubernetes StatefulSets work like any other Kubernetes pods, allowing them to
    be scheduled in the cluster as needed with available cluster resources.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes StatefulSets 就像任何其他 Kubernetes pod 一样工作，允许根据需要利用集群资源调度它们。
- en: StatefulSets generally rely on remote network attached storage devices.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: StatefulSets 通常依赖于远程网络附加存储设备。
- en: DaemonSets offer a more natural abstraction for running on a database on a pool
    of dedicated nodes.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当在专用节点池上运行数据库时，DaemonSets 提供了更自然的抽象。
- en: Discovery and communications will add some challenges that need to be addressed.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现和通信会增加一些需要解决的挑战。
- en: Summary
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Migrating and building applications in the cloud requires a different approach
    to the architecture and design of applications’ data-related requirements. Cloud
    providers offer a rich set of managed data storage and analytics services, reducing
    the operating costs for data systems. This makes it much easier to consider running
    multiple and different types of data systems, using storage technologies that
    might be better suited for the task. This cost and scale of the datastores has
    changed, making it easier to store large amounts of data at a price point that
    keeps going down as cloud providers continue to innovate and compete in these
    areas.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在云中迁移和构建应用程序需要一种不同的方法来设计和构建应用程序数据相关的需求。云服务提供商提供了丰富的托管数据存储和分析服务，降低了数据系统的运营成本。这使得考虑同时运行多个不同类型的数据系统变得更加容易，可以使用更适合任务的存储技术。随着云服务提供商在这些领域持续创新和竞争，数据存储的成本和规模发生了变化，使得以更低的价格存储大量数据变得更加容易。
