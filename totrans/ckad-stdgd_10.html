<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:epub="http://www.idpf.org/2007/ops" lang="en" xml:lang="en" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd">
  <head>
    <title>Unknown</title>
    <link rel="stylesheet" type="text/css" href="../stylesheet.css"/>
    <link rel="stylesheet" type="text/css" href="../page_styles.css"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  </head>
  <body class="calibre"><div id="sbo-rt-content" class="calibre1"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 10. Deployments" class="praise"><div class="dedication" id="deployments">
<h1 class="calibre14"><span class="keep-together">Chapter 10. </span>Deployments</h1>


<p class="author1">A big selling point of Kubernetes is its scalability and replication. To support those features, Kubernetes offers the Deployment primitive. In this chapter we’ll show the creation of a Deployment scaled to multiple replicas, how to roll out a revision of your application, how to roll back to a previous revision, and how to use auto-scalers to handle scaling concerns automatically based on the current workload.</p>
<aside data-type="sidebar" epub:type="sidebar" class="calibre48"><div class="sidebar" id="id479">
<h1 class="calibre49">Coverage of Curriculum Objectives</h1>
<p class="author1">This chapter addresses the following curriculum objective:</p>

<ul class="printings">
<li class="calibre13">
<p class="author1">Understand Deployments and how to perform rolling updates</p>
</li>
</ul>
</div></aside>






<section data-type="sect1" data-pdf-bookmark="Working with Deployments" class="praise"><div class="dedication" id="id249">
<h1 class="calibre17">Working with Deployments</h1>

<p class="author1">The primitive for running an application in a container is the Pod. Using a single instance of a Pod to operate an application has its flaws—it represents a single point of failure because all traffic targeting the application is funneled to this Pod. This behavior is specifically problematic when the load increases due to higher demand (e.g., during peak shopping season for an e-commerce application or when an increasing number of microservices communicate with a centralized microservice functionality, e.g. an authentication provider).</p>

<p class="author1">Another important aspect of running an application in a Pod is failure tolerance. The scheduler cluster component will not reschedule a Pod in the case of a node failure, which can lead to a system outage for end users. In this chapter, we’ll talk about the Kubernetes mechanics that support application scalability and failure tolerance.</p>

<p class="author1">A <em class="calibre3">ReplicaSet</em> is a Kubernetes API resource that controls multiple, identical instances of a Pod running the application, so-called replicas. It has the capability of scaling the number of replicas up or down on demand. Moreover, it knows how to roll out a new version of the application across all replicas.</p>

<p class="author1">A <em class="calibre3">Deployment</em> abstracts the functionality of ReplicaSet and manages it internally. In practice, this means you do not have to create, modify, or delete ReplicaSet objects yourself. The Deployment keeps a history of application versions and can roll back to an older version to counteract a blocking or potentially costly production issue. Furthermore, it offers the capability of scaling the number of replicas.</p>

<p class="author1"><a data-type="xref" href="#deployment_replicaset" class="calibre10">Figure 10-1</a> illustrates the relationship between a Deployment, a ReplicaSet, and its controlled replicas.</p>

<figure class="calibre35"><div id="deployment_replicaset" class="figure">
<img src="Images/ckd2_1001.png" alt="ckd2 1001" class="calibre83"/>
<h6 class="calibre32"><span class="keep-together">Figure 10-1. </span>Relationship between a Deployment and a ReplicaSet</h6>
</div></figure>

<p class="author1">The following sections explain how to manage Deployments, including scaling and rollout features.</p>








<section data-type="sect2" data-pdf-bookmark="Creating Deployments" class="praise"><div class="dedication" id="id250">
<h2 class="calibre33">Creating Deployments</h2>

<p class="author1">You can create a Deployment using the imperative command <code class="calibre15">create deployment</code>. The command offers a range of options, some of which are mandatory. At a minimum, you need to provide the name of the Deployment and the container image. The Deployment passes this information to the ReplicaSet, which uses it to manage the replicas. The default number of replicas created is 1; however, you can define a higher number of replicas using the option <code class="calibre15">--replicas</code>.</p>

<p class="author1">Let’s observe the command in action. The following command creates the Deployment named <code class="calibre15">app-cache</code>, which runs the object cache <a href="https://memcached.org" class="calibre10">Memcached</a> inside the container on four replicas:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl create deployment app-cache --image=memcached:1.6.8 --replicas=4</strong>
deployment.apps/app-cache created
</pre>

<p class="author1">The mapping between the Deployment and the replicas it controls happens through label selection. When you run the imperative command, <code class="calibre15">kubectl</code> sets up the mapping for you. <a data-type="xref" href="#yaml_manifest_deployment" class="calibre10">Example 10-1</a> shows the label selection in the YAML manifest. This YAML manifest can be used to create a Deployment declaratively or by inspecting the live object created by the previous imperative command.</p>
<div id="yaml_manifest_deployment" data-type="example" class="calibre45">
<h5 class="calibre46"><span class="keep-together">Example 10-1. </span>A YAML manifest for a Deployment</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre47"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="calibre15">apps/v1</code><code class="w"></code>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Deployment</code><code class="w"></code>
<code class="nt">metadata</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">app-cache</code><code class="w"></code>
<code class="w">  </code><code class="nt">labels</code><code class="p">:</code><code class="w"></code>
<code class="w">    </code><code class="nt">app</code><code class="p">:</code><code class="w"> </code><code class="calibre15">app-cache</code><code class="w"></code>
<code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">replicas</code><code class="p">:</code><code class="w"> </code><code class="calibre15">4</code><code class="w"></code>
<code class="w">  </code><code class="nt">selector</code><code class="p">:</code><code class="w"></code>
<code class="w">    </code><code class="nt">matchLabels</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="nt">app</code><code class="p">:</code><code class="w"> </code><code class="calibre15">app-cache</code><code class="w"></code>
<code class="w">  </code><code class="nt">template</code><code class="p">:</code><code class="w"></code>
<code class="w">    </code><code class="nt">metadata</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="nt">labels</code><code class="p">:</code><code class="w"></code>
<code class="w">        </code><code class="nt">app</code><code class="p">:</code><code class="w"> </code><code class="calibre15">app-cache</code><code class="w"></code>
<code class="w">    </code><code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="nt">containers</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">memcached</code><code class="w"></code>
<code class="w">        </code><code class="nt">image</code><code class="p">:</code><code class="w"> </code><code class="calibre15">memcached:1.6.8</code><code class="w"></code></pre></div>

<p class="author1">When created by the imperative command, <code class="calibre15">app</code> is the label key the Deployment uses by default. You can find this key in three different places in the YAML output:</p>
<ol class="calibre55">
<li class="calibre56">
<p class="author1"><code class="calibre15">metadata.labels</code></p>
</li>
<li class="calibre56">
<p class="author1"><code class="calibre15">spec.selector.matchLabels</code></p>
</li>
<li class="calibre56">
<p class="author1"><code class="calibre15">spec.template.metadata.labels</code></p>
</li>

</ol>

<p class="author1">For label selection to work properly, the assignment of <code class="calibre15">spec.selector.matchLabels</code> and <code class="calibre15">spec.template.metadata</code> needs to match, as shown in <a data-type="xref" href="#deployment_label_selection" class="calibre10">Figure 10-2</a>.</p>

<p class="author1">The values of <code class="calibre15">metadata.labels</code> is irrelevant for mapping the Deployment to the Pod template. As you can see in the figure, the label assignment to <code class="calibre15">metadata.labels</code> has been changed deliberately to <code class="calibre15">deploy: app-cache</code> to underline that it is not important for the Deployment to Pod template selection.</p>

<figure class="calibre35"><div id="deployment_label_selection" class="figure">
<img src="Images/ckd2_1002.png" alt="ckd2 1002" class="calibre84"/>
<h6 class="calibre32"><span class="keep-together">Figure 10-2. </span>Deployment label selection</h6>
</div></figure>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Listing Deployments and Their Pods" class="praise"><div class="dedication" id="id251">
<h2 class="calibre33">Listing Deployments and Their Pods</h2>

<p class="author1">You can inspect a Deployment after its creation by using the <code class="calibre15">get deployments</code> command. The output of the command renders the important details of its replicas, as shown here:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl get deployments</strong>
NAME        READY   UP-TO-DATE   AVAILABLE   AGE
app-cache   4/4     4            4           125m
</pre>

<p class="author1">The column titles relevant to the replicas controlled by the Deployment are shown in <a data-type="xref" href="#runtime_replica_information" class="calibre10">Table 10-1</a>.</p>
<table id="runtime_replica_information" class="calibre58">
<caption class="calibre59"><span class="keep-together">Table 10-1. </span>Runtime replica information when listing deployments</caption>
<thead class="calibre61">
<tr class="calibre62">
<th class="calibre63">Column Title</th>
<th class="calibre63">Description</th>
</tr>
</thead>
<tbody class="calibre64">
<tr class="calibre62">
<td class="calibre65"><p class="author1">READY</p></td>
<td class="calibre65"><p class="author1">Lists the number of replicas available to end users in the format of &lt;ready&gt;/&lt;desired&gt;. The number of desired replicas corresponds to the value of <code class="calibre60">spec.replicas</code>.</p></td>
</tr>
<tr class="calibre66">
<td class="calibre65"><p class="author1">UP-TO-DATE</p></td>
<td class="calibre65"><p class="author1">Lists the number of replicas that have been updated to achieve the desired state.</p></td>
</tr>
<tr class="calibre62">
<td class="calibre65"><p class="author1">AVAILABLE</p></td>
<td class="calibre65"><p class="author1">Lists the number of replicas available to end users.</p></td>
</tr>
</tbody>
</table>

<p class="author1">You can identify the Pods controlled by the Deployment by their naming prefix. In the case of the previously created Deployment, the Pods’ names start with <code class="calibre15">app-cache-</code>. The hash following the prefix is autogenerated and appended to the name upon creation:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl get pods</strong>
NAME                         READY   STATUS    RESTARTS   AGE
app-cache-596bc5586d-84dkv   1/1     Running   0          6h5m
app-cache-596bc5586d-8bzfs   1/1     Running   0          6h5m
app-cache-596bc5586d-rc257   1/1     Running   0          6h5m
app-cache-596bc5586d-tvm4d   1/1     Running   0          6h5m
</pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Rendering Deployment Details" class="praise"><div class="dedication" id="id252">
<h2 class="calibre33">Rendering Deployment Details</h2>

<p class="author1">You can render the details of a Deployment. Those details include the label selection criteria, which can be extremely valuable when troubleshooting a misconfigured Deployment. The following output provides the full gist:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl describe deployment app-cache</strong>
Name:                   app-cache
Namespace:              default
CreationTimestamp:      Sat, 07 Aug 2021 09:44:18 -0600
Labels:                 app=app-cache
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=app-cache
Replicas:               4 desired | 4 updated | 4 total | 4 available | \
                        0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=app-cache
  Containers:
   memcached:
    Image:        memcached:1.6.10
    Port:         &lt;none&gt;
    Host Port:    &lt;none&gt;
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Progressing    True    NewReplicaSetAvailable
  Available      True    MinimumReplicasAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   app-cache-596bc5586d (4/4 replicas created)
Events:          &lt;none&gt;</pre>

<p class="author1">You might have noticed that the output contains a reference to a ReplicaSet. The 
<span class="keep-together">purpose</span> of a ReplicaSet is to <em class="calibre3">replicate</em> a set of identical Pods. You do not need to deeply understand the core functionality of a ReplicaSet for the exam. Just be aware that the Deployment automatically creates the ReplicaSet and uses the Deployment’s name as a prefix for the ReplicaSet, similar to the Pods it controls. In the case of the previous Deployment named <code class="calibre15">app-cache</code>, the name of the ReplicaSet is <code class="calibre15">app-⁠cache-596bc5586d</code>.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Deleting a Deployment" class="praise"><div class="dedication" id="id253">
<h2 class="calibre33">Deleting a Deployment</h2>

<p class="author1">A Deployment takes full charge of the creation and deletion of the objects it controls: Pods and ReplicaSets. When you delete a Deployment, the corresponding objects are deleted as well. Say you are dealing with the following set of objects shown in the 
<span class="keep-together">output:</span></p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl get deployments,pods,replicasets</strong>
NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app-cache   4/4     4            4           6h47m

NAME                             READY   STATUS    RESTARTS   AGE
pod/app-cache-596bc5586d-84dkv   1/1     Running   0          6h47m
pod/app-cache-596bc5586d-8bzfs   1/1     Running   0          6h47m
pod/app-cache-596bc5586d-rc257   1/1     Running   0          6h47m
pod/app-cache-596bc5586d-tvm4d   1/1     Running   0          6h47m

NAME                                   DESIRED   CURRENT   READY   AGE
replicaset.apps/app-cache-596bc5586d   4         4         4       6h47m
</pre>

<p class="author1">Run the <code class="calibre15">delete deployment</code> command for a cascading deletion of its managed objects:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl delete deployment app-cache</strong>
deployment.apps "app-cache" deleted
<strong class="calibre38">$ kubectl get deployments,pods,replicasets</strong>
No resources found in default namespace.
</pre>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Performing Rolling Updates and Rollbacks" class="praise"><div class="dedication" id="id254">
<h1 class="calibre17">Performing Rolling Updates and Rollbacks</h1>

<p class="author1">A Deployment fully abstracts rollout and rollback capabilities by delegating this responsibility to the ReplicaSet(s) it manages. Once a user changes the definition of the Pod template in a Deployment, it will create a new ReplicaSet that applies the changes to the replicas it controls and then shut down the previous ReplicaSet. In this section, we’ll talk about both scenarios: deploying a new version of an application and reverting to an old version of an application.</p>








<section data-type="sect2" data-pdf-bookmark="Updating a Deployment’s Pod Template" class="praise"><div class="dedication" id="id255">
<h2 class="calibre33">Updating a Deployment’s Pod Template</h2>

<p class="author1">You can choose from a range of options to update the definition of replicas controlled by a Deployment. Any of those options is valid, but they vary in ease of use and operational environment.</p>

<p class="author1">In real-world projects, you should check your manifest files into version control. Changes to the definition would then be made by directly editing the file. The <code class="calibre15">kubectl apply</code> can update a live object by pointing to the changed manifest:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl apply -f deployment.yaml</strong>
</pre>

<p class="author1">The <code class="calibre15">kubectl edit</code> command lets you change the Pod template interactively by modifying the live object’s manifest in an editor. To edit the Deployment live object named <code class="calibre15">web-server</code>, use the following command:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl edit deployment web-server</strong>
</pre>

<p class="author1">The imperative <code class="calibre15">kubectl set image</code> command changes only the container image assigned to a Pod template by selecting the name of the container. For example, you could use his command to assign the image <code class="calibre15">nginx:1.25.2</code> to the container named <code class="calibre15">nginx</code> in the Deployment <code class="calibre15">web-server</code>:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl set image deployment web-server nginx=nginx:1.25.2</strong>
</pre>

<p class="author1">The <code class="calibre15">kubectl replace</code> command lets you replace the existing Deployment with a new definition that contains your change to the manifest. The optional <code class="calibre15">--force</code> flag first deletes the existing object and then creates it from scratch. The following command assumes that you changed the container image assignment in <code class="calibre15">deployment.yaml</code>:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl replace -f deployment.yaml</strong>
</pre>

<p class="author1">The command <code class="calibre15">kubectl patch</code> requires you to provide the merges as a patch to update a Deployment. The following command shows the operation in action. Here, you are sending the changes to be made in the form of a JSON structure:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl patch deployment web-server -p '{"spec":{"template":{"spec":\
{"containers":[{"name":"nginx","image":"nginx:1.25.2"}]}}}}'</strong>
</pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Rolling Out a New Revision" class="praise"><div class="dedication" id="id256">
<h2 class="calibre33">Rolling Out a New Revision</h2>

<p class="author1">Deployments make it easy to roll out a new version of the application to all replicas it controls. Say you want to upgrade the version of Memcached from 1.6.8 to 1.6.10 to benefit from the latest features and bug fixes. All you need to do is change the desired state of the object by updating the Pod template. The Deployment updates all replicas to the new version one by one. This process is called the <em class="calibre3">rolling update</em> strategy.</p>

<p class="author1">The command <code class="calibre15">set image</code> offers a quick, convenient way to change the image of a Deployment, as shown in the following command:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl set image deployment app-cache memcached=memcached:1.6.10</strong>
deployment.apps/app-cache image updated
</pre>

<p class="author1">You can check the current status of a rollout that’s in progress using the command <code class="calibre15">rollout status</code>. The output indicates the number of replicas that have already been updated since emitting the command:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl rollout status deployment app-cache</strong>
Waiting for rollout to finish: 2 out of 4 new replicas have been updated...
deployment "app-cache" successfully rolled out
</pre>

<p class="author1">Kubernetes keeps track of the changes you make to a Deployment over time in the rollout history. Every change is represented by a <em class="calibre3">revision</em>. When changing the Pod template of a Deployment—for example, by updating the image—the Deployment triggers the creation of a new ReplicaSet. The Deployment will gradually migrate the Pods from the old ReplicaSet to the new one. You can check the rollout history by running the following command. You will see two revisions listed:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl rollout history deployment app-cache</strong>
deployment.apps/app-cache
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         &lt;none&gt;</pre>

<p class="author1">The first revision was recorded for the original state of the Deployment when you created the object. The second revision was added for changing the image tag.</p>
<div data-type="note" epub:type="note" class="calibre26"><h6 class="calibre27">Note</h6>
<p class="author1">By default, a Deployment persists for a maximum of 10 revisions in its history. You can change the limit by assigning a different value to <code class="calibre15">spec.revisionHistoryLimit</code>.</p>
</div>

<p class="author1">To get a more detailed view of the revision, run the following command. You can see that the image uses the value <code class="calibre15">memcached:1.6.10</code>:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl rollout history deployments app-cache --revision=2</strong>
deployment.apps/app-cache with revision #2
Pod Template:
  Labels:	app=app-cache
	pod-template-hash=596bc5586d
  Containers:
   memcached:
    Image:	memcached:1.6.10
    Port:	&lt;none&gt;
    Host Port:	&lt;none&gt;
    Environment:	&lt;none&gt;
    Mounts:	&lt;none&gt;
  Volumes:	&lt;none&gt;</pre>

<p class="author1">The rolling update strategy ensures that the application is always available to end users. This approach implies that two versions of the same application are available during the update process. As an application developer, you have to be aware that convenience doesn’t come without potential side effects. If you happen to introduce a breaking change to the public API of your application, you might temporarily break consumers, as they could hit revision 1 or 2 of the application.</p>

<p class="author1">You can change the default update strategy of a Deployment by providing a different value to the attribute <code class="calibre15">spec.strategy.type</code>; however, consider the trade-offs. For example, the value <code class="calibre15">Recreate</code> kills all Pods first, then creates new Pods with the latest revision, causing potential downtime for consumers. See <a data-type="xref" href="ch11.xhtml#deployment_strategies" class="calibre10">Chapter 11</a> for a more detailed description of common deployment strategies.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Adding a Change Cause for a Revision" class="praise"><div class="dedication" id="id257">
<h2 class="calibre33">Adding a Change Cause for a Revision</h2>

<p class="author1">The rollout history renders the column <code class="calibre15">CHANGE-CAUSE</code>. You can populate the information for a revision to document <em class="calibre3">why</em> you introduced a new change or <em class="calibre3">which</em> <code class="calibre15">kubectl</code> command you use to make the change.</p>

<p class="author1">By default, changing the Pod template does not automatically record a change cause. To add a change cause to the current revision, add an annotation with the reserved key <code class="calibre15">kubernetes.io/change-cause</code> to the Deployment object. The following imperative <code class="calibre15">annotate</code> command assigns the change cause “Image updated to 1.6.10”:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl annotate deployment app-cache kubernetes.io/change-cause=\
"Image updated to 1.6.10"</strong>
deployment.apps/app-cache annotated
</pre>

<p class="author1">The rollout history now renders the change cause value for the current revision:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl rollout history deployment app-cache</strong>
deployment.apps/app-cache
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         Image updated to 1.6.10</pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Rolling Back to a Previous Revision" class="praise"><div class="dedication" id="id258">
<h2 class="calibre33">Rolling Back to a Previous Revision</h2>

<p class="author1">Problems can arise in production that require swift action. For example, the container image you just rolled out contains a crucial bug. Kubernetes gives you the option to roll back to one of the previous revisions in the rollout history. You can achieve this by using the <code class="calibre15">rollout undo</code> command. To pick a specific revision, provide the command-line option <code class="calibre15">--to-revision</code>. The command rolls back to the previous revision if you do not provide the option. Here, we are rolling back to revision 1:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl rollout undo deployment app-cache --to-revision=1</strong>
deployment.apps/app-cache rolled back
</pre>

<p class="author1">As a result, Kubernetes performs a rolling update to all replicas with the revision 1.</p>
<div data-type="tip" class="calibre26"><h1 class="calibre34">Rollbacks and persistent data</h1>
<p class="author1">The <code class="calibre15">rollout undo</code> command does not restore any persistent data associated with applications. Rather, it simply restores to a new instance of the previous declared state of the ReplicaSet.</p>
</div>

<p class="author1">The rollout history now lists revision 3. Given that we rolled back to revision 1, there’s no more need to keep that entry as a duplicate. Kubernetes simply turns revision 1 into 3 and removes 1 from the list:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl rollout history deployment app-cache</strong>
deployment.apps/app-cache
REVISION  CHANGE-CAUSE
2         Image updated to 1.16.10
3         &lt;none&gt;</pre>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Scaling Workloads" class="praise"><div class="dedication" id="id259">
<h1 class="calibre17">Scaling Workloads</h1>

<p class="author1">Scalability is one of Kubernetes’ built-in capabilities. We’ll learn how to manually scale the number of replicas as a reaction to increased application load. Furthermore, we’ll talk about the API resource Horizontal Pod Autoscaler, which allows you to automatically scale the managed set of Pods based on resource thresholds such as CPU and memory.</p>








<section data-type="sect2" data-pdf-bookmark="Manually Scaling a Deployment" class="praise"><div class="dedication" id="id260">
<h2 class="calibre33">Manually Scaling a Deployment</h2>

<p class="author1">Scaling (up or down) the number of replicas controlled by a Deployment is a straightforward process. You can either manually edit the live object using the <code class="calibre15">edit deployment</code> command and change the value of the attribute <code class="calibre15">spec.replicas</code>, or you can use the imperative <code class="calibre15">scale deployment</code> command. In real-world production environments, you want to edit the Deployment YAML manifest, check it into version control, and apply the changes. The following command increases the number of replicas from four to six:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl scale deployment app-cache --replicas=6</strong>
deployment.apps/app-cache scaled
</pre>

<p class="author1">You can observe the creation of replicas in real time using the <code class="calibre15">-w</code> command line flag. You’ll see a change of status for the newly created Pods turning from <code class="calibre15">ContainerCreat⁠ing</code> to <code class="calibre15">Running</code>:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl get pods -w</strong>
NAME                         READY   STATUS              RESTARTS   AGE
app-cache-5d6748d8b9-6cc4j   1/1     ContainerCreating   0          11s
app-cache-5d6748d8b9-6rmlj   1/1     Running             0          28m
app-cache-5d6748d8b9-6z7g5   1/1     ContainerCreating   0          11s
app-cache-5d6748d8b9-96dzf   1/1     Running             0          28m
app-cache-5d6748d8b9-jkjsv   1/1     Running             0          28m
app-cache-5d6748d8b9-svrxw   1/1     Running             0          28m
</pre>

<p class="author1">Manually scaling the number of replicas takes a bit of guesswork. You will still have to monitor the load on your system to see if your number of replicas is sufficient to handle the incoming traffic.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Autoscaling a Deployment" class="praise"><div class="dedication" id="id261">
<h2 class="calibre33">Autoscaling a Deployment</h2>

<p class="author1">Another way to scale a Deployment is with the help of a Horizontal Pod Autoscaler (HPA). The HPA is an API primitive that defines rules for automatically scaling the number of replicas under certain conditions. Common scaling conditions include a target value, an average value, or an average utilization of a specific metric (e.g., for CPU and/or memory). Refer to the <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/#metrictarget-v2-autoscaling" class="calibre10">MetricTarget API</a> for more information.</p>

<p class="author1">Let’s say you want to define average CPU utilization of CPU as the scaling condition. At runtime, the HPA checks the metrics collected by the <a href="https://oreil.ly/Lmamb" class="calibre10">metrics server</a> to determine if the average maximum CPU or memory usage across all replicas of a Deployment is less than or greater than the defined threshold. Make sure that you have the metrics server installed in the cluster. Collecting metrics may take a couple of minutes initially after installing the component. See <a data-type="xref" href="ch15.xhtml#metrics_server" class="calibre10">“Inspecting Resource Metrics”</a> for more information.</p>

<p class="author1"><a data-type="xref" href="#autoscaling_deployment" class="calibre10">Figure 10-3</a> shows an overview architecture diagram involving an HPA.</p>

<figure class="calibre35"><div id="autoscaling_deployment" class="figure">
<img src="Images/ckd2_1003.png" alt="ckd2 1003" class="calibre85"/>
<h6 class="calibre32"><span class="keep-together">Figure 10-3. </span>Autoscaling a Deployment</h6>
</div></figure>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Creating Horizontal Pod Autoscalers" class="praise"><div class="dedication" id="id262">
<h2 class="calibre33">Creating Horizontal Pod Autoscalers</h2>

<p class="author1"><a data-type="xref" href="#horizonal_pod_autoscaler" class="calibre10">Figure 10-4</a> shows the use of an HPA that will scale up the number of replicas if an average of 80% CPU utilization is reached across all available Pods controlled by the Deployment.</p>

<figure class="calibre35"><div id="horizonal_pod_autoscaler" class="figure">
<img src="Images/ckd2_1004.png" alt="ckd2 1004" class="calibre86"/>
<h6 class="calibre32"><span class="keep-together">Figure 10-4. </span>Autoscaling a Deployment horizontally</h6>
</div></figure>

<p class="author1">You can use the <code class="calibre15">autoscale deployment</code> command to create an HPA for an existing Deployment. The option <code class="calibre15">--cpu-percent</code> defines the average maximum CPU usage threshold. At the time of writing, the imperative command doesn’t offer an option for defining the average maximum memory utilization threshold. The options <code class="calibre15">--min</code> and <code class="calibre15">--max</code> provide the minimum number of replicas to scale down to and the maximum number of replicas the HPA can create to handle the increased load, respectively:</p>
<pre data-type="programlisting" class="calibre37">
<strong class="calibre38">$ kubectl autoscale deployment app-cache --cpu-percent=80 --min=3 --max=5</strong>
horizontalpodautoscaler.autoscaling/app-cache autoscaled
</pre>

<p class="author1">This command is a great shortcut for creating an HPA for a Deployment. The YAML manifest representation of the HPA object looks like <a data-type="xref" href="#yaml_manifest_hpa" class="calibre10">Example 10-2</a>.</p>
<div id="yaml_manifest_hpa" data-type="example" class="calibre45">
<h5 class="calibre46"><span class="keep-together">Example 10-2. </span>A YAML manifest for an HPA</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre47"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="calibre15">autoscaling/v2</code><code class="w"></code>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="calibre15">HorizontalPodAutoscaler</code><code class="w"></code>
<code class="nt">metadata</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">app-cache</code><code class="w"></code>
<code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">scaleTargetRef</code><code class="p">:</code><code class="w"></code>
<code class="w">    </code><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="calibre15">apps/v1</code><code class="w"></code>
<code class="w">    </code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Deployment</code><code class="w"></code>
<code class="w">    </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">app-cache</code><code class="w"></code>
<code class="w">  </code><code class="nt">minReplicas</code><code class="p">:</code><code class="w"> </code><code class="calibre15">3</code><code class="w"></code>
<code class="w">  </code><code class="nt">maxReplicas</code><code class="p">:</code><code class="w"> </code><code class="calibre15">5</code><code class="w"></code>
<code class="w">  </code><code class="nt">metrics</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">resource</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">cpu</code><code class="w"></code>
<code class="w">      </code><code class="nt">target</code><code class="p">:</code><code class="w"></code>
<code class="w">        </code><code class="nt">averageUtilization</code><code class="p">:</code><code class="w"> </code><code class="calibre15">80</code><code class="w"></code>
<code class="w">        </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Utilization</code><code class="w"></code>
<code class="w">    </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Resource</code><code class="w"></code></pre></div>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Listing Horizontal Pod Autoscalers" class="praise"><div class="dedication" id="id263">
<h2 class="calibre33">Listing Horizontal Pod Autoscalers</h2>

<p class="author1">The short-form command for a Horizontal Pod Autoscaler is <code class="calibre15">hpa</code>. Listing all of the HPA objects transparently describes their current state: the CPU utilization and the number of replicas at this time:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl get hpa</strong>
NAME        REFERENCE              TARGETS         MINPODS   MAXPODS   REPLICAS \
  AGE
app-cache   Deployment/app-cache   &lt;unknown&gt;/80%   3         5         4        \
  58s</pre>

<p class="author1">If the Pod template of the Deployment does not define CPU resource requirements or if the CPU metrics cannot be retrieved from the metrics server, the left-side value of the column <code class="calibre15">TARGETS</code> says &lt;unknown&gt;. <a data-type="xref" href="#cpu_resource_requirements_pod_template" class="calibre10">Example 10-3</a> sets the resource requirements for the Pod template so that the HPA can work properly. You can learn more about defining resource requirements in <a data-type="xref" href="ch18.xhtml#container_resource_requirements" class="calibre10">“Working with Resource Requirements”</a>.</p>
<div id="cpu_resource_requirements_pod_template" data-type="example" class="calibre45">
<h5 class="calibre46"><span class="keep-together">Example 10-3. </span>Setting CPU resource requirements for Pod template</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre47"><code class="c"># ...</code><code class="w"></code>
<code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="c"># ...</code><code class="w"></code>
<code class="w">  </code><code class="nt">template</code><code class="p">:</code><code class="w"></code>
<code class="w">    </code><code class="c"># ...</code><code class="w"></code>
<code class="w">    </code><code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="nt">containers</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">memcached</code><code class="w"></code>
<code class="w">        </code><code class="c"># ...</code><code class="w"></code>
<code class="w">        </code><code class="nt">resources</code><code class="p">:</code><code class="w"></code>
<code class="w">          </code><code class="nt">requests</code><code class="p">:</code><code class="w"></code>
<code class="w">            </code><code class="nt">cpu</code><code class="p">:</code><code class="w"> </code><code class="calibre15">250m</code><code class="w"></code>
<code class="w">          </code><code class="nt">limits</code><code class="p">:</code><code class="w"></code>
<code class="w">            </code><code class="nt">cpu</code><code class="p">:</code><code class="w"> </code><code class="calibre15">500m</code><code class="w"></code></pre></div>

<p class="author1">Once traffic hits the replicas, the current CPU usage is shown as a percentage. Here the average maximum CPU utilization is 15%:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl get hpa</strong>
NAME        REFERENCE              TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
app-cache   Deployment/app-cache   15%/80%   3         5         4          58s</pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Rendering Horizontal Pod Autoscaler Details" class="praise"><div class="dedication" id="id264">
<h2 class="calibre33">Rendering Horizontal Pod Autoscaler Details</h2>

<p class="author1">The event log of an HPA can provide additional insight into the rescaling activities. Rendering the HPA details can be a great tool for overseeing when the number of replicas was scaled up or down, as well as their scaling conditions:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl describe hpa app-cache</strong>
Name:                                                  app-cache
Namespace:                                             default
Labels:                                                &lt;none&gt;
Annotations:                                           &lt;none&gt;
CreationTimestamp:                                     Sun, 15 Aug 2021 \
                                                       15:54:11 -0600
Reference:                                             Deployment/app-cache
Metrics:                                               ( current / target )
  resource cpu on pods  (as a percentage of request):  0% (1m) / 80%
Min replicas:                                          3
Max replicas:                                          5
Deployment pods:                                       3 current / 3 desired
Conditions:
  Type            Status  Reason            Message
  ----            ------  ------            -------
  AbleToScale     True    ReadyForNewScale  recommended size matches current size
  ScalingActive   True    ValidMetricFound  the HPA was able to successfully \
  calculate a replica count from cpu resource utilization (percentage of request)
  ScalingLimited  True    TooFewReplicas    the desired replica count is less \
  than the minimum replica count
Events:
  Type    Reason             Age   From                       Message
  ----    ------             ----  ----                       -------
  Normal  SuccessfulRescale  13m   horizontal-pod-autoscaler  New size: 3; \
  reason: All metrics below target</pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Defining Multiple Scaling Metrics" class="praise"><div class="dedication" id="id265">
<h2 class="calibre33">Defining Multiple Scaling Metrics</h2>

<p class="author1">You can define more than a single resource type as a scaling metric. As you can see in <a data-type="xref" href="#autoscaler_hpa" class="calibre10">Example 10-4</a>, we are inspecting CPU and memory utilization to determine if the replicas of a Deployment need to be scaled up or down.</p>
<div id="autoscaler_hpa" data-type="example" class="calibre45">
<h5 class="calibre46"><span class="keep-together">Example 10-4. </span>A YAML manifest for a HPA with multiple metrics</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre47"><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="calibre15">autoscaling/v2</code><code class="w"></code>
<code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="calibre15">HorizontalPodAutoscaler</code><code class="w"></code>
<code class="nt">metadata</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">app-cache</code><code class="w"></code>
<code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="nt">scaleTargetRef</code><code class="p">:</code><code class="w"></code>
<code class="w">    </code><code class="nt">apiVersion</code><code class="p">:</code><code class="w"> </code><code class="calibre15">apps/v1</code><code class="w"></code>
<code class="w">    </code><code class="nt">kind</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Deployment</code><code class="w"></code>
<code class="w">    </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">app-cache</code><code class="w"></code>
<code class="w">  </code><code class="nt">minReplicas</code><code class="p">:</code><code class="w"> </code><code class="calibre15">3</code><code class="w"></code>
<code class="w">  </code><code class="nt">maxReplicas</code><code class="p">:</code><code class="w"> </code><code class="calibre15">5</code><code class="w"></code>
<code class="w">  </code><code class="nt">metrics</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Resource</code><code class="w"></code>
<code class="w">    </code><code class="nt">resource</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">cpu</code><code class="w"></code>
<code class="w">      </code><code class="nt">target</code><code class="p">:</code><code class="w"></code>
<code class="w">        </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Utilization</code><code class="w"></code>
<code class="w">        </code><code class="nt">averageUtilization</code><code class="p">:</code><code class="w"> </code><code class="calibre15">80</code><code class="w"></code>
<code class="w">  </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="calibre15">Resource</code><code class="w"></code>
<code class="w">    </code><code class="nt">resource</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">memory</code><code class="w"></code>
<code class="w">      </code><code class="nt">target</code><code class="p">:</code><code class="w"></code>
<code class="w">        </code><code class="nt">type</code><code class="p">:</code><code class="w"> </code><code class="calibre15">AverageValue</code><code class="w"></code>
<code class="w">        </code><code class="nt">averageValue</code><code class="p">:</code><code class="w"> </code><code class="calibre15">500Mi</code><code class="w"></code></pre></div>

<p class="author1">To ensure that the HPA determines the currently used resources, we’ll set the memory resource requirements for the Pod template as well, as shown in <a data-type="xref" href="#memory_resource_requirements_pod_template" class="calibre10">Example 10-5</a>.</p>
<div id="memory_resource_requirements_pod_template" data-type="example" class="calibre45">
<h5 class="calibre46"><span class="keep-together">Example 10-5. </span>Setting memory resource requirements for Pod template</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre47"><code class="p">...</code><code class="w"></code>
<code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">  </code><code class="p">...</code><code class="w"></code>
<code class="w">  </code><code class="nt">template</code><code class="p">:</code><code class="w"></code>
<code class="w">    </code><code class="p">...</code><code class="w"></code>
<code class="w">    </code><code class="nt">spec</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="nt">containers</code><code class="p">:</code><code class="w"></code>
<code class="w">      </code><code class="calibre15">-</code><code class="w"> </code><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="calibre15">memcached</code><code class="w"></code>
<code class="w">        </code><code class="p">...</code><code class="w"></code>
<code class="w">        </code><code class="nt">resources</code><code class="p">:</code><code class="w"></code>
<code class="w">          </code><code class="nt">requests</code><code class="p">:</code><code class="w"></code>
<code class="w">            </code><code class="nt">cpu</code><code class="p">:</code><code class="w"> </code><code class="calibre15">250m</code><code class="w"></code>
<code class="w">            </code><code class="nt">memory</code><code class="p">:</code><code class="w"> </code><code class="calibre15">100Mi</code><code class="w"></code>
<code class="w">          </code><code class="nt">limits</code><code class="p">:</code><code class="w"></code>
<code class="w">            </code><code class="nt">cpu</code><code class="p">:</code><code class="w"> </code><code class="calibre15">500m</code><code class="w"></code>
<code class="w">            </code><code class="nt">memory</code><code class="p">:</code><code class="w"> </code><code class="calibre15">500Mi</code><code class="w"></code></pre></div>

<p class="author1">Listing the HPA renders both metrics in the <code class="calibre15">TARGETS</code> column, as in the output of the <code class="calibre15">get</code> command shown here:</p>

<pre data-type="programlisting" class="calibre37"><strong class="calibre38">$ kubectl get hpa</strong>
NAME        REFERENCE              TARGETS                 MINPODS   MAXPODS \
  REPLICAS   AGE
app-cache   Deployment/app-cache   1994752/500Mi, 0%/80%   3         5       \
  3          2m14s</pre>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Summary" class="praise"><div class="dedication" id="id266">
<h1 class="calibre17">Summary</h1>

<p class="author1">The Deployment is an essential primitive for providing declarative updates and life cycle management of Pods. The ReplicaSet performs the heavy lifting of managing those Pods, commonly referred to as replicas. Application developers do not have to interact directly with the ReplicaSet; a Deployment manages the ReplicaSet under the hood.</p>

<p class="author1">Deployments can easily roll out and roll back revisions of the application represented by an image running in the container. In this chapter you learned about the commands for controlling the revision history and its operations. Scaling a Deployment manually requires deep insight into the requirements and the load of an application. A Horizontal Pod Autoscaler can automatically scale the number of replicas based on CPU and memory thresholds observed at runtime.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Exam Essentials" class="praise"><div class="dedication" id="id267">
<h1 class="calibre17">Exam Essentials</h1>
<dl class="calibre18">
<dt class="calibre19">Know the ins and outs of a Deployment</dt>
<dd class="calibre20">
<p class="calibre21">Given that a Deployment is such a central primitive in Kubernetes, you can expect that the exam will test you on it. Know how to create a Deployment and learn how to scale to multiple replicas. One of the superior features of a Deployment is its rollout functionality for new revisions. Practice how to roll out a new revision, inspect the rollout history, and roll back to a previous revision.</p>
</dd>
<dt class="calibre19">Understand the implications of using a Horizontal Pod Autoscaler</dt>
<dd class="calibre20">
<p class="calibre21">The number of replicas controlled by a Deployment can be scaled up or down using the Horizontal Pod Autoscaler (HPA). An HPA defines thresholds for resources like CPU and memory that will tell the object that a scaling event needs to happen. It’s important to understand that the HPA functions properly only if you install the metrics server component and define resource requests and limits for containers.</p>
</dd>
</dl>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Sample Exercises" class="praise"><div class="dedication" id="id268">
<h1 class="calibre17">Sample Exercises</h1>

<p class="author1">Solutions to these exercises are available in <a href="app01_split_006.xhtml#appendix_a_deployments" class="calibre10">Appendix A</a>.</p>
<ol class="calibre55">
<li class="calibre56">
<p class="author1">Create a Deployment named <code class="calibre15">nginx</code> with 3 replicas. The Pods should use the <code class="calibre15">nginx:1.23.0</code> image and the name <code class="calibre15">nginx</code>. The Deployment uses the label <code class="calibre15">tier=backend</code>. The Pod template should use the label <code class="calibre15">app=v1</code>.</p>

<p class="author1">List the Deployment and ensure that the correct number of replicas is running.</p>

<p class="author1">Update the image to <code class="calibre15">nginx:1.23.4</code>.</p>

<p class="author1">Verify that the change has been rolled out to all replicas.</p>

<p class="author1">Assign the change cause “Pick up patch version” to the revision.</p>

<p class="author1">Scale the Deployment to 5 replicas.</p>

<p class="author1">Have a look at the Deployment rollout history. Revert the Deployment to 
<span class="keep-together">revision 1.</span></p>

<p class="author1">Ensure that the Pods use the image <code class="calibre15">nginx:1.23.0</code>.</p>
</li>
<li class="calibre56">
<p class="author1">Create a Deployment named <code class="calibre15">nginx</code> with 1 replica. The Pod template of the Deployment should use container image <code class="calibre15">nginx:1.23.4</code>; set the CPU resource request to 0.5 and the memory resource request/limit to 500Mi.</p>

<p class="author1">Create a HorizontalPodAutoscaler for the Deployment named <code class="calibre15">nginx-hpa</code> that scales to a minimum of 3 and a maximum of 8 replicas. Scaling should happen based on an average CPU utilization of 75% and an average memory utilization of 60%.</p>

<p class="author1">Inspect the HorizontalPodAutoscaler object and identify the currently-utilized resources. How many replicas do you expect to exist?</p>
</li>

</ol>
</div></section>
</div></section></div></body>
</html>