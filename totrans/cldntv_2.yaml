- en: Chapter 2\. Fundamentals
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 基础知识
- en: As discussed in [Chapter 1](ch01.xhtml#introduction_to_cloud_native), cloud
    native applications are applications that are distributed in nature and utilize
    cloud infrastructure. There are many technologies and tools that are being used
    to implement cloud native applications, but from a compute perspective, it is
    mainly *functions* and *containers*. From an architectural perspective, *microservices
    architectures* have gained a lot of popularity. More often than not, those terms
    are mistakenly used, and often believed to be one and the same. In reality, functions
    and containers are different technologies, each serving a particular purpose,
    whereas microservices describes an architectural style. That said, understanding
    how to best use functions and containers, along with *eventing* or *messaging*
    technologies, allows developers to design, develop, and operate a new generation
    of cloud native microservices-based applications in the most efficient and agile
    way. To make the correct architectural decisions to design those types of applications,
    it is important to understand the basics of the underlying terms and technologies.
    This chapter explains important technologies used with cloud native applications
    and concludes by providing an overview of the microservices architectural style.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在[第一章](ch01.xhtml#introduction_to_cloud_native)中讨论的，云原生应用是分布式的，并利用云基础设施。有许多技术和工具用于实现云原生应用，但从计算角度看，主要是*函数*和*容器*。从架构角度来看，*微服务架构*已经非常流行。往往这些术语被误用，并经常被认为是同一回事。事实上，函数和容器是不同的技术，每种技术都有其特定的用途，而微服务则描述了一种架构风格。因此，了解如何最佳地使用函数和容器，以及*事件*或*消息传递*技术，使开发者能够以最高效和敏捷的方式设计、开发和运行新一代基于云原生微服务的应用程序非常重要。为了做出正确的架构决策来设计这些类型的应用程序，理解基础术语和技术的基础知识至关重要。本章解释了与云原生应用程序一起使用的重要技术，并通过概述微服务架构风格来结束。
- en: Containers
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器
- en: Initially, containers were brought into the spotlight by startups and born-in-the-cloud
    companies, but over the past couple of years, containers have become synonymous
    with application modernization. Today there are very few companies that are not
    using containers or at least considering using containers in the future, which
    means that architects and developers alike need to understand what containers
    offer and what they don’t offer.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，容器是由创业公司和云原生公司推广的，但在过去几年中，容器已成为应用现代化的代名词。如今，几乎没有公司不在使用容器或至少考虑将来使用容器，这意味着架构师和开发者都需要理解容器提供和不提供的内容。
- en: When people talk about containers today, they refer to “Docker containers” most
    of the time, because it’s Docker that has really made containers popular. However,
    in the Linux operating system (OS) world, containers date back more than 10 years.
    The initial idea of containers was to slice up an OS so that you can securely
    run multiple applications without them interfering with one another. The required
    isolation is accomplished through namespaces and control groups, which are Linux
    kernel features. Namespaces allow the different components of the OS to be sliced
    up and thus create isolated workspaces. Control groups then allow fine-grained
    control of resource utilization, effectively stopping one container from consuming
    all system resources.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，人们在谈论容器时，大多数时候指的是“Docker容器”，因为Docker确实使容器变得流行起来。然而，在Linux操作系统（OS）世界中，容器已有十多年的历史。容器最初的想法是将操作系统切片，以便可以安全地运行多个应用程序而彼此不干扰。这种所需的隔离是通过命名空间和控制组来实现的，这些是Linux内核的功能。命名空间允许切片化操作系统的不同组件，从而创建隔离的工作空间。控制组则允许对资源利用进行精细化控制，有效地防止一个容器占用所有系统资源。
- en: Because the interaction with kernel features was not exactly what we would call
    developer friendly, Linux containers (LXC) were introduced to abstract away some
    of the complexity of composing the various technology underpinnings of what is
    now commonly call a “container.” Eventually it was Docker that made containers
    mainstream by introducing a developer-friendly packaging of the kernel features.
    Docker defines containers as a “standardized unit of software.” The “unit of software”—or,
    more accurately, the service or application running within a container—has full,
    private access to their own isolated view of OS constructs. In other words, you
    can view containers as encapsulated, individually deployable components running
    as isolated instances on the same kernel with virtualization happening on the
    OS level.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由于与内核特性的交互并不完全符合我们所说的开发者友好，Linux 容器（LXC）被引入以抽象化组合现在通常称为“容器”的各种技术基础的复杂性。最终，Docker通过引入开发者友好的内核特性打包，使容器成为主流。Docker将容器定义为“标准化的软件单元”。“软件单元”——或者更准确地说，运行在容器内的服务或应用程序——具有对自己独立的操作系统结构的全面私密访问。换句话说，您可以将容器视为封装的、可单独部署的组件，在同一内核上以隔离的实例运行，并在操作系统级别进行虚拟化。
- en: '![clna 0201](Images/clna_0201.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0201](Images/clna_0201.png)'
- en: Figure 2-1\. VMs and containers on a single host
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1\. 单个主机上的 VM 和容器
- en: In addition, containers use the copy-on-write filesystem strategy, which allows
    multiple containers to share the same data, and the OS provides a copy of the
    data to the container that needs to modify or write data. This allows containers
    to be very lightweight in terms of memory and disk space usage, resulting in faster
    startup times, which is one of the great benefits of using containers. Other benefits
    are *deterministic deployments*, allowing portability between environments, isolation,
    and higher density. For modern cloud native applications, container images have
    become the unit of deployment encapsulating the application or service code, its
    runtime, dependencies, system libraries, and so on. Due to their fast startup
    times, containers are an ideal technology for scale-out scenarios, which are very
    common in cloud native applications. [Figure 2-1](#vms_and_containers_in_a_single_host)
    shows the difference between virtual machines (VMs) and containers on a single
    host.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，容器采用写时复制文件系统策略，允许多个容器共享相同的数据，操作系统将数据的副本提供给需要修改或写入数据的容器。这使得容器在内存和磁盘空间使用方面非常轻量化，从而导致更快的启动时间，这是使用容器的重要好处之一。其他好处包括*确定性部署*，允许在不同环境间的可移植性、隔离性以及更高的密度。对于现代云原生应用来说，容器镜像已成为封装应用或服务代码、运行时、依赖关系、系统库等的部署单元。由于它们快速的启动时间，容器成为规模化应用场景的理想技术。[图 2-1](#vms_and_containers_in_a_single_host)展示了单个主机上虚拟机（VMs）和容器之间的区别。
- en: Container Isolation Levels
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器隔离级别
- en: 'Because containers are based on OS virtualization, they share the same kernel
    when running on the same host. Although this is sufficient enough isolation for
    most scenarios, it falls short of the isolation level that hardware-based virtualization
    options such as VMs provide. Following are some of the downsides of using VMs
    as the foundation of cloud native applications:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因为容器基于操作系统虚拟化，在同一主机上运行时它们共享相同的内核。尽管这对大多数场景来说提供了足够的隔离，但它无法达到基于硬件虚拟化选项（例如 VM）提供的隔离级别。以下是将
    VM 作为云原生应用基础的一些不足之处：
- en: VMs can take a considerable amount of time to start because they boot a full
    OS.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VM 的启动可能需要相当长的时间，因为它们会启动完整的操作系统。
- en: The size of the VM can be an issue. A VM contains an entire OS, which can easily
    be several gigabytes in size. Copying this image across a network—for example,
    if they are kept in a central image repository—will take a lot of time.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VM 的大小可能是一个问题。一个 VM 包含整个操作系统，其大小可能轻易达到几个千兆字节。跨网络复制此映像（例如，如果它们存储在中央映像库中）将需要大量时间。
- en: Scaling of VMs has its challenges. Scaling up (adding more resources) requires
    a new, larger VM (more CPU, memory, storage, etc.) to be provisioned and booted.
    Scaling out might not be fast enough to respond to demand; it takes time for new
    instances to start.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VM 的扩展具有其挑战性。扩展（增加更多资源）需要配置和启动一个新的、更大的 VM（更多的 CPU、内存、存储等）。扩展输出可能不足以快速响应需求；新实例的启动需要时间。
- en: VMs have more overhead and use considerably more resources such as memory, CPU,
    and disk. This limits the density, or number of VMs that can run on a single host
    machine.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The most common scenarios that demand high isolation on a hardware virtualization
    level are hostile multitenant scenarios in which you typically need to protect
    against malicious escape and breakout attempts into other targets on the same
    host or on the shared infrastructure. Cloud providers have been using technologies
    internally that provide VM-level isolation while maintaining the expected speed
    and efficiency of containers. These technologies are known as *Hyper-V containers*,
    *sandboxed containers*, or *MicroVMs*. Here are the most popular MicroVM technologies
    (in nonspecific order):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[Nabla containers](https://nabla-containers.github.io/)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: These enable better isolation by taking advantage of unikernel techniques, specifically
    those from the [Solo5 project](https://github.com/Solo5/solo5), to limit system
    calls from the container to host kernel. The Nabla container runtime (runc) is
    an Open Container Initiative (OCI)-compliant runtime. OCI will be explained in
    a bit more detail later in this chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[Google’s gVisor](https://github.com/google/gvisor)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: This is a container runtime and user space kernel written in Go. The new kernel
    is a “user space” process that addresses the container’s system call needs, preventing
    direct interaction with the host OS. The gVisor runtime (runSC) is an OCI-compliant
    runtime, and it supports Kubernetes orchestration as well.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[Microsoft’s Hyper-V containers](https://oreil.ly/5njcd)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft’s Hyper-V containers were introduced a couple of years ago and are
    based on VM Worker Process (*vmwp.exe*). Those containers provide full VM-level
    isolation and are OCI compliant. As for running [Hyper-V containers in Kubernetes](http://bit.ly/33vZb7U)
    in production, you will want to wait for general availability of Kubernetes on
    Windows.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[Kata containers](https://katacontainers.io/)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Kata containers are a combination of Hyper.sh and Intel’s clear containers and
    provide classic hardware-assisted virtualization. Kata containers are compatible
    with the OCI specification for Docker containers and CRI for Kubernetes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Amazon’s Firecracker
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Firecracker is powering Amazon’s Lambda infrastructure and has been open sourced
    under the Apache 2.0 license. Firecracker is a user-mode VM solution that sits
    on top of the KVM API and is designed to run modern Linux kernels. The goal of
    Firecracker is to provide support for running Linux containers in a hypervisor-isolated
    fashion similar to other more isolated container technologies such as Kata containers.
    Note that, as of this writing, you are not able to use Firecracker with Kubernetes,
    Docker, or Kata containers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2-2](#isolation_levels_for_vms_comma_container) provides an overview
    of the isolation levels of the these technologies.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![clna 0202](Images/clna_0202.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. Isolation levels for VMs, containers, and processes
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2\. 虚拟机、容器和进程的隔离级别
- en: Container Orchestration
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器编排
- en: 'To manage the life cycle of containers at scale, you need to use a container
    orchestrator. The tasks of a container orchestrator are the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要管理规模化的容器生命周期，您需要使用容器编排器。容器编排器的任务如下：
- en: The provisioning and deployment of containers onto the cluster nodes
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向集群节点上的容器进行供应和部署
- en: Resource management of containers, meaning placing containers on nodes that
    provide sufficient resources or moving containers to other nodes if the resource
    limits of a node is reached
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器资源管理，即将容器放置在提供足够资源的节点上，或者在节点资源限制达到时将容器移动到其他节点
- en: Health monitoring of the containers and the nodes to initiaing restarted and
    rescheduling in case of failures on a container or node level
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对容器和节点进行健康监控，以便在容器或节点级别出现故障时进行重新启动和重新调度
- en: Scaling in or out containers within a cluster
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在集群中缩放容器的数量
- en: Providing mappings for containers to connect to networking
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供容器连接网络的映射
- en: Internal load balancing between containers
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器间的内部负载均衡
- en: There are multiple container orchestrators available, but there is no doubt
    that Kubernetes is by far the most popular choice for cluster management and the
    scheduling of container-centric workloads in a cluster.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当前存在多种容器编排器，但毫无疑问 Kubernetes 是管理集群和调度容器工作负载的最受欢迎选择。
- en: Kubernetes Overview
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 概述
- en: Kubernetes (often abbreviated as k8s) is an open source project for running
    and managing containers. Google open sourced the project in 2014, and Kubernetes
    is often viewed as a container platform, microservices platform, and/or a cloud
    portability layer. All of the major cloud vendors have a managed Kubernetes offering
    today.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes（通常简称为 k8s）是一个用于运行和管理容器的开源项目。Google 在2014年开源了该项目，Kubernetes 通常被视为容器平台、微服务平台和/或云可移植性层。所有主要的云供应商今天都提供托管的
    Kubernetes 服务。
- en: 'A Kubernetes cluster runs multiple components that can be grouped in one of
    three categories: *master components*, *node components*, or *addons*. Master
    components provide the cluster control plane. These components are responsible
    for making cluster-wide decisions like scheduling tasks in the cluster or responding
    to events, such as starting new tasks if one fails or does not meet the desired
    number of replicas. The master components can run on any node in the cluster,
    but are commonly deployed to dedicated master nodes. Managed Kubernetes offerings
    from cloud providers will handle the management of the control plane, including
    on-demand upgrades and patches.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群运行多个组件，可以分为三类：*主控组件*、*节点组件*或*插件*。主控组件提供集群控制平面。这些组件负责做出整个集群范围的决策，如在集群中调度任务或响应事件，例如如果一个任务失败或不符合所需副本数量，则启动新任务。主控组件可以运行在集群的任何节点上，但通常部署在专用的主节点上。云供应商提供的托管
    Kubernetes 服务将处理控制平面的管理，包括按需升级和补丁。
- en: 'Kubernetes master components include the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 主控组件包括以下内容：
- en: kube-apiserver
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: kube-apiserver
- en: Exposes the Kubernetes API and is the frontend for the Kubernetes control plane
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 提供 Kubernetes API，是 Kubernetes 控制平面的前端
- en: etcd
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: etcd
- en: A key/value store used for all cluster data
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 用于存储所有集群数据的键/值存储
- en: kube-scheduler
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: kube-scheduler
- en: Monitors newly created *pods* (a Kubernetes-specific management wrapper around
    containers, which we explain in more detail later in this chapter) that are not
    assigned to a node and finds an available node
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 监视新创建的*pods*（Kubernetes 中特定管理容器的封装，稍后在本章节详细解释）是否已分配到节点，并找到可用节点
- en: kube-controller-manager
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: kube-controller-manager
- en: Manages a number of controllers that are responsible for responding to nodes
    that go down or maintaining the correct number of replicas
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 管理一些控制器，负责响应宕机节点或维持正确数量的副本
- en: cloud-controller-manager
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: cloud-controller-manager
- en: Run controllers that interact with the underlying cloud providers
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 运行与底层云提供商交互的控制器
- en: Node components run on every node in the cluster, which is also referred to
    as the *data plane*, and are responsible for maintaining running pods and the
    environment for the node to which they are deployed.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 节点组件在集群中的每个节点上运行，也称为*数据平面*，负责维护运行中的 Pod 和部署到节点的环境。
- en: 'Kubernetes node components include the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 节点组件包括以下内容：
- en: kubelet
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: kubelet
- en: An agent that runs on each node in the cluster and is responsible for running
    containers in pods based on their pod specification
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群中每个节点上运行的代理，负责根据其 pod 规范在 pods 中运行容器
- en: kube-proxy
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: kube-proxy
- en: Maintains network rules on the nodes and performs connection forwarding
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在节点上维护网络规则并执行连接转发
- en: container runtime
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时
- en: The software responsible for running containers (see [“Kubernetes and Containers”](#kubernetes_and_containers))
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 负责运行容器的软件（参见 [“Kubernetes and Containers”](#kubernetes_and_containers)）
- en: '[Figure 2-3](#kubernetes_master_and_worker_node_compon) shows the Kubernetes
    master and worker node components.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2-3](#kubernetes_master_and_worker_node_compon) 展示了 Kubernetes 主控节点和工作节点组件。'
- en: '![clna 0203](Images/clna_0203.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0203](Images/clna_0203.png)'
- en: Figure 2-3\. Kubernetes master and worker node components
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3\. Kubernetes 主控节点和工作节点组件
- en: Kubernetes is commonly deployed with addons that are managed by the master and
    worker node components. These addons will include services like Domain Name System
    (DNS) and a management user interface (UI).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 通常与由主控节点和工作节点组件管理的插件一起部署。这些插件包括域名系统（DNS）和管理用户界面（UI）等服务。
- en: 'A deep dive into Kubernetes is beyond the scope of this book. There are, however,
    some fundamental concepts that are important for you to understand:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不涉及 Kubernetes 的深入讨论。然而，有一些基本概念对您理解是很重要的：
- en: Pods
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Pods
- en: A pod is basically a management wrapper around one or multiple containers, storage
    resources, or a unique network IP, that governs the container life cycle. Although
    Kubernetes supports multiple containers per pod, most of the time there is only
    one application container per pod. That said, the pattern of *sidecar containers*,
    which extends or enhances the functionality of the application container, is very
    popular. Service meshes like Istio rely heavily on sidecars, as you can see in
    [Chapter 3](ch03.xhtml#designing_cloud-native_applications).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 基本上是围绕一个或多个容器、存储资源或唯一网络 IP 的管理包装器，管理容器的生命周期。尽管 Kubernetes 支持每个 pod 多个容器，但大多数情况下每个
    pod 只有一个应用程序容器。也就是说，“sidecar 容器”模式非常流行，它扩展或增强应用程序容器的功能。像 Istio 这样的服务网格大量依赖 sidecars，如您可以在
    [第三章](ch03.xhtml#designing_cloud-native_applications) 中看到的那样。
- en: Services
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 服务
- en: A Kubernetes service provides a steady endpoint to a grouping of pods that are
    running on the cluster. Kubernetes uses label selectors to identify which pods
    are targeted by a service.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 服务为集群上运行的一组 pods 提供稳定的端点。Kubernetes 使用标签选择器标识服务的目标 pods。
- en: ReplicaSets
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSets
- en: The easiest way to think about ReplicaSets is to think about service instances.
    You basically define how many replicas of a pod you need, and Kubernetes makes
    sure that you have that number of replicas running at any given time.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方式来理解 ReplicaSets 就是将其视为服务实例。您基本上定义了需要多少个 pod 的副本，Kubernetes 确保在任何给定时间内都有这些副本在运行。
- en: Deployments
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Deployments
- en: The Kubernetes Deployment documentation states that you “describe a desired
    state in a Deployment object, and the Deployment controller changes the actual
    state to the desired state at a controlled rate.” In other words, you should use
    Deployments for rolling out and monitoring ReplicaSets, scaling ReplicaSets, updating
    pods, rolling back to earlier Deployments versions, and cleaning up older ReplicaSets.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 部署文档说明，“您可以使用 Deployment 对象描述所需的状态，部署控制器以受控速率将实际状态更改为所需状态。” 换句话说，您应该使用
    Deployments 来逐步推出和监控 ReplicaSets，扩展 ReplicaSets，更新 pods，回滚到早期的 Deployment 版本，并清理旧的
    ReplicaSets。
- en: '[Figure 2-4](#fundamental_kubernetes_concepts) provides a logical view of the
    fundamental Kubernetes concepts and how they interact with one another.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2-4](#fundamental_kubernetes_concepts) 展示了基本 Kubernetes 概念的逻辑视图及其相互作用。'
- en: '![clna 0204](Images/clna_0204.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0204](Images/clna_0204.png)'
- en: Figure 2-4\. Fundamental Kubernetes concepts
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-4\. 基本 Kubernetes 概念
- en: Kubernetes and Containers
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 和容器
- en: Kubernetes is simply the orchestration platform for containers, so it needs
    a container runtime to manage the container life cycle. The Docker runtime was
    supported from day one in Kubernetes, but it isn’t the only container runtime
    available on the market. As a consequence, the Kubernetes community has pushed
    for a generic way to integrate container runtimes into Kubernetes. Interfaces
    have proven to be a good software pattern for providing contracts between two
    systems, so the community created the [Container Runtime Interface (CRI)](http://bit.ly/31y3pdC).
    The CRI avoids “hardcoding” specific runtime requirements into the Kubernetes
    codebase, with the consequence of always needing to update the Kubernetes codebase
    when there are changes to a container runtime. Instead, the CRI describes the
    functions that need to be implemented by a container runtime to be CRI compliant.
    The functions that the CRI describes handle the life cycle of container pods (start,
    stop, pause, kill, delete), container image management (e.g., download images
    from a registry), and some helper functions around observability, such as log
    and metric collections and networking. [Figure 2-5](#docker_versus_kata_container_on_kubernet)
    shows high-level CRI example architectures for Docker and Kata containers.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 只是容器的编排平台，因此需要一个容器运行时来管理容器的生命周期。从一开始，Kubernetes 就支持 Docker 运行时，但市场上并非只有
    Docker 运行时可用。因此，Kubernetes 社区推动了一种通用的方法来集成容器运行时到 Kubernetes 中。接口已被证明是在两个系统之间提供契约的良好软件模式，因此社区创建了
    [容器运行时接口 (CRI)](http://bit.ly/31y3pdC)。CRI 避免了将特定的运行时需求硬编码到 Kubernetes 代码库中的问题，因此当容器运行时发生更改时，总是需要更新
    Kubernetes 代码库。相反，CRI 描述了容器运行时必须实现的功能。CRI 描述的功能包括处理容器 pod 的生命周期（启动、停止、暂停、杀死、删除）、容器镜像管理（例如从注册表下载镜像）以及一些辅助功能，如日志和指标收集以及网络功能。[图
    2-5](#docker_versus_kata_container_on_kubernet) 展示了 Docker 和 Kata 容器的高级 CRI 示例架构。
- en: '![clna 0205](Images/clna_0205.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0205](Images/clna_0205.png)'
- en: Figure 2-5\. Docker versus Kata container on Kubernetes
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-5\. Docker versus Kata container on Kubernetes
- en: 'The following list provides other container-related technologies that might
    be useful:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表提供了其他可能有用的与容器相关的技术：
- en: OCI
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: OCI
- en: The OCI is a [Linux Foundation](https://en.wikipedia.org/wiki/Linux_Foundation)
    project that aims to design open standards for container images and runtimes.
    Many container technologies implement an OCI-compliant runtime and image specification.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: OCI 是一个由 [Linux Foundation](https://en.wikipedia.org/wiki/Linux_Foundation)
    推动的项目，旨在设计容器镜像和运行时的开放标准。许多容器技术实现了兼容 OCI 的运行时和镜像规范。
- en: containerd
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: containerd
- en: containerd is an industry-standard container runtime used by Docker and Kubernetes
    CRI, just to name the most popular ones. It is available as a daemon for Linux
    and Windows, which can manage the complete container life cycle of its host system,
    including container image management, container execution, low-level storage,
    and network attachments.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: containerd 是一个行业标准的容器运行时，被 Docker 和 Kubernetes CRI 使用，仅举两个最流行的例子。它作为 Linux 和
    Windows 的守护程序可用，可以管理其主机系统的完整容器生命周期，包括容器镜像管理、容器执行、底层存储和网络附加。
- en: Moby
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Moby
- en: Moby is a set of open source tools created by Docker to enable and accelerate
    software containerization. The toolkit includes container build tools, a container
    registry, orchestration tools, a runtime, and more, and you can use these as building
    blocks in conjunction with other tools and projects. Moby is using containerd
    as the default container runtime.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Moby 是由 Docker 创建的一组开源工具，旨在实现和加速软件容器化。这套工具包括容器构建工具、容器注册表、编排工具、运行时等等，你可以将其作为其他工具和项目的构建模块。Moby
    使用 containerd 作为默认的容器运行时。
- en: Serverless Computing
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无服务器计算
- en: Serverless computing means that scale and the underlying infrastructure is managed
    by the cloud provider; that is, your application automatically drives the allocation
    and deallocation of resources, and you do not need to worry about managing the
    underlying infrastructure at all. All management and operations are abstracted
    away from the user and managed by cloud providers such as Microsoft Azure, Amazon
    Web Services (AWS), and Google Cloud Platform (GCP). From a developer perspective,
    serverless often adds an event-driven programming model, and from an economic
    perspective, you pay only per execution (CPU time consumed).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Many people think Function as a Service (FaaS) is serverless. This is technically
    true, but FaaS is only one variation of serverless computing. Microsoft Azure’s
    Container Instances (ACI) and Azure SF Mesh, as well as AWS Fargate and GCP’s
    Serverless Containers on Cloud Functions, are good examples. ACI and AWS Fargate
    are serverless container offerings also known as Container as a Service (CaaS),
    which allow you to deploy containerized applications without needing to know about
    the underlying infrastructure. Other examples of serverless offerings are API
    management and machine learning services—basically, any service that lets you
    consume functionality without managing the underlying infrastructure and a pay-only-for-what-you-use
    model qualifies as serverless offering.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Functions
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When talking about functions, people typically talk about FaaS offerings such
    as AWS Lambda, Azure Functions, and Google Cloud Functions, which are implemented
    on serverless infrastructure. The advantages of serverless computing—fast startup
    and execution time, plus the simplification of their applications—makes FaaS offerings
    very compelling to developers because it allows them to focus solely on writing
    code.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: From a development perspective, a function is the unit of work, which means
    that your code has a start and a finish. Functions are usually triggered by events
    that are emitted by either other functions or platform services. For example,
    a function can be triggered by adding an entry to a database service or eventing
    service. There are quite a few things to consider when you want to build a large,
    complex application just with functions. You will need to manage more independent
    code, you will need to ensure state is being taken care of, and you will need
    to implement patterns if functions must depend on one another, just to name a
    few. Containerized microservices share a lot of the same patterns, so there have
    been quite a few discussions around when to use FaaS or a container. [Table 2-1](#comparison_of_faas_and_containerized_ser)
    provides some high-level guidance between FaaS and containers, and [Chapter 3](ch03.xhtml#designing_cloud-native_applications)
    covers the trade-offs in more detail.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1\. Comparison of FaaS and containerized services
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '| FaaS | Containerized service |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
- en: '| Does one thing | Does more than one thing |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
- en: '| Can’t deploy dependencies | Can deploy dependencies |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 无法部署依赖 | 可以部署依赖 |'
- en: '| Must respond to one kind of event | Can respond to more than one kind of
    event |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 必须响应一种事件 | 可以响应多种事件 |'
- en: There are two scenarios in which using FaaS offerings might not be ideal, although
    it offers the best economics. First, you want to avoid vendor lock-in. Because
    you need to develop your function specific to the FaaS offering and consume higher-level
    cloud services from a provider, your entire application becomes less portable.
    Second, you want to run functions on-premises or your own clusters. There are
    a bunch of FaaS runtimes that are available as open source runtimes and that you
    can run on any Kubernetes cluster. Kubeless, OpenFaaS, Serverless, and Apache
    OpenWhisk are among the most popular installable FaaS platforms, with Azure Functions
    gaining more popularity since it has been open sourced. Installable FaaS platforms
    are typically deployed through containers and allow the developer to simply deploy
    small bits of code (functions) without needing to worry about the underlying infrastructure.
    Many installable FaaS frameworks use Kubernetes resources for routing, autoscaling,
    and monitoring.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用FaaS提供的服务可能并不总是理想的两种情况。尽管它提供了最好的经济性，但首先，你需要避免供应商锁定。因为你需要根据FaaS提供的服务来开发你的函数，并且使用提供商的更高级云服务，这使得整个应用程序变得不太可移植。其次，你可能希望在本地或自己的集群上运行函数。有许多开源的FaaS运行时可用，并且可以在任何Kubernetes集群上运行。Kubeless、OpenFaaS、Serverless和Apache
    OpenWhisk是最受欢迎的可安装FaaS平台，Azure Functions自开源以来也越来越受欢迎。可安装的FaaS平台通常通过容器部署，并允许开发人员简单地部署小段代码（函数），而不必担心底层基础设施。许多可安装的FaaS框架使用Kubernetes资源进行路由、自动缩放和监控。
- en: A critical aspect of any FaaS implementation, no matter whether it runs on a
    cloud provider’s serverless infrastructure or is installed on your own clusters,
    is the startup time. In general, you expect functions to execute very quickly
    after they have been triggered, which implies that their underlying technology
    needs to provide very fast boot-up times. As previously discussed, containers
    provide good startup times, but do not necessarily offer the best isolation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 任何FaaS实现的关键方面，无论它是在云提供商的无服务器基础设施上运行还是安装在你自己的集群上，都是启动时间。通常情况下，你希望函数在被触发后能够非常快速地执行，这意味着它们的底层技术需要提供非常快的启动时间。正如前面讨论的，容器提供良好的启动时间，但并不一定提供最佳的隔离性。
- en: From VMs to Cloud Native
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从虚拟机到云原生
- en: To understand how we ended up with the next generation of cloud native applications,
    it is worth looking at how applications evolve from running on VMs to functions.
    Describing the journey should give you a good idea of how the IT industry is changing
    to put developer productivity into focus and how you can take advantage of all
    the new technologies. There are really two different paths to the cloud native
    world. The first one is mainly used for *brownfield scenarios*, which means that
    you have an existing application, and typically follows a lift-and-shift, application
    modernization, and eventually an application optimization process. The second
    one is a *greenfield scenario* in which you start your application from scratch.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解我们是如何进入下一代云原生应用的，值得看一看应用程序是如何从运行在虚拟机上到函数上演变的过程。描述这一旅程应该能够给你一个很好的想法，即IT行业正在如何转变以提升开发者的生产力，以及如何利用所有新技术的优势。云原生世界真的有两条不同的路径。第一条主要用于*现有场景*，这意味着你有一个现有的应用程序，并且通常遵循搬迁和升级，最终进行优化的过程。第二条是*新建场景*，在这种情况下，你可以从头开始创建你的应用程序。
- en: Lift-and-Shift
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搬迁和升级
- en: Installing software directly on machines in the cloud is still the very first
    step for many customers to move to the cloud. The benefits are mainly in the capital
    and operational expense areas given that customers do not need to operate their
    own datacenters or can at least reduce operations and, therefore, the costs. From
    a technical perspective, lift-and-shift into Infrastructure as a Service (IaaS)
    gives you the most control over the entire stack. With control comes responsibility,
    and installing software directly on machines often resulted in errors caused by
    missing dependencies, runtime versioning conflicts, resource contention, and isolation.
    The next logical step is to move applications into a Platform as a Service (PaaS)
    environment. PaaS existed long before containers became popular; for example,
    Azure Cloud Services dates back to 2010\. In most past PaaS environments, access
    to the underlying VMs is restricted or in some cases prohibited so that moving
    to the cloud requires some rewriting of the applications. The benefit for developers
    is not to worry about the underlying infrastructure anymore. Operational tasks
    such as patching the OS were handled by the cloud providers, but some of the problems,
    like missing dependencies, remained. Because many PaaS services were based on
    VMs, scaling in burst scenarios was still a challenge due to the downsides of
    VMs, which we discussed previously, and for economic reasons.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Application Modernization
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Besides offering super-fast startup times, containers drastically removed the
    issues of missing dependencies, because everything an application needed is packaged
    inside a container. It didn’t take long for developers to begin to love the concept
    of containers as a packaging format, and now pretty much every new application
    is using containers, and more and more monolithic legacy applications are being
    containerized. Many customers see the containerization of an existing application
    as an opportunity to also move to a more suitable architecture for cloud native
    environments. Microservices is the obvious choice, but as you will see later in
    the chapter, moving to such an architecture comes with some disadvantages. There
    are a few very obvious reasons, though, why you want to break up your monolith:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Time to deployment is faster.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Certain components need to update more frequently than others.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Certain components need different scale requirements.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Certain components should be developed in a different technology.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The codebase has gotten too big and complex.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although the methodology to break up a monolith goes beyond the scope of this
    book, it is worth mentioning the two major patterns to move from a monolithic
    application to microservices.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '*Strangler* pattern'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: With the Strangler pattern, you strangle the monolithic application. New services
    or existing components are implemented as microservices. A facade or gateway routes
    user requests to the correct application. Over time, more and more features are
    moved to the new architecture until the monolithic application has been entirely
    transformed into a microservices application.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用“Strangler”模式，你逐步重构单体应用程序。新服务或现有组件被实现为微服务。一个门面或者网关将用户请求路由到正确的应用程序。随着时间的推移，越来越多的功能被转移到新的架构中，直到单体应用程序完全转变为微服务应用程序。
- en: '*Anticorruption Layer* pattern'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*防腐层*模式'
- en: This is similar to the Strangler pattern but is used when new services need
    to access the legacy application. The layer then translates the concepts from
    existing app to new, and vice versa.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当新服务需要访问旧应用程序时，类似于 Strangler 模式。该层将现有应用程序的概念转换为新的概念，反之亦然。
- en: We describe both patterns in more detail in [Chapter 6](ch06.xhtml#best_practices).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第六章](ch06.xhtml#best_practices)中更详细地描述了这些模式。
- en: With applications being packaged in container images, orchestrators began to
    play a more important role. Even though there were several choices in the beginning,
    Kubernetes has become the most popular choice today; in fact, it is considered
    the new cloud OS. Orchestrators, however, added another variable to the equation
    insomuch as development and operations teams needed to understand them. The management
    part of the environment has become better, as pretty much every cloud vendor now
    offers “orchestrators” as a service. As with any cloud provider, “managed” Kubernetes
    means that the setup and runtime part of the Kubernetes service is managed. From
    an economical point of view, users are typically being charged for compute hours,
    which means that you pay as long as the nodes of the cluster are up and running
    even though the application might be sitting idle or utilizing low resources.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 随着应用程序被打包为容器镜像，编排器开始扮演更重要的角色。尽管一开始有几种选择，但 Kubernetes 如今已成为最流行的选择；事实上，它被视为新的云操作系统。然而，编排器为开发和运维团队增加了另一个变量。环境管理部分变得更好了，因为几乎每个云供应商现在都提供“编排器即服务”。与任何云提供商一样，“托管”
    Kubernetes 意味着 Kubernetes 服务的设置和运行时部分是由供应商管理的。从经济学角度来看，用户通常按计算小时付费，这意味着只要集群节点运行，即使应用程序可能处于空闲状态或低资源利用率，也会产生费用。
- en: From a developer perspective, you still need to understand how Kubernetes works
    if you want to build microservices applications on top of it given that Kubernetes
    does not offer any PaaS or CaaS features out of the box.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 从开发者的角度来看，如果你想在其上构建微服务应用程序，你仍然需要了解 Kubernetes 的工作原理，因为 Kubernetes 默认不提供任何平台即服务（PaaS）或容器即服务（CaaS）功能。
- en: For example, a Kubernetes service does not really represent the service code
    within a container, it just provides an endpoint to it, so that the code within
    the container can always be accessed through the same endpoint. In addition to
    needing to understand Kubernetes, developers are also being introduced to distributed
    systems patterns to handle resiliency, diagnostics, and routing, just to name
    a few.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Kubernetes 服务并不真正代表容器内的服务代码，它只是为其提供一个端点，以便始终可以通过相同的端点访问容器内的代码。除了需要理解 Kubernetes
    外，开发人员还开始接触处理弹性、诊断和路由等分布式系统模式。
- en: Service meshes such as Istio or Linkerd are gaining popularity because they
    are moving some of the distributed systems complexity into the platform layer.
    [Chapter 3](ch03.xhtml#designing_cloud-native_applications) covers service meshes
    in great detail, but for now you can think of a service mesh as being a dedicated
    networking infrastructure layer that handles the service-to-service communication.
    Among other things, service meshes enable resiliency features such as retries
    and circuit breakers, distributed tracing, and routing.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如 Istio 或 Linkerd 的服务网格因将部分分布式系统复杂性移到平台层而日益流行。[第三章](ch03.xhtml#designing_cloud-native_applications)详细介绍了服务网格，但现在你可以将服务网格看作是一个专用的网络基础设施层，用于处理服务间的通信。服务网格除了其他功能外，还支持重试、熔断器、分布式跟踪和路由等弹性特性。
- en: The next step of application evolution is to use serverless infrastructure for
    containerized workloads, aka CaaS offerings such as Azure Container Instances
    or AWS Fargate. Microsoft Azure has done a great job to meld the world of its
    managed Kubernetes Service (AKS) with its CaaS offering, ACI, by using *virtual
    nodes*. Virtual nodes is based on Microsoft’s open source project called Virtual
    Kubelet, which allows any compute resource to act as a Kubernetes node and use
    the Kubernetes control plane. In the case of AKS virtual nodes, you are able to
    schedule your application on AKS and burst into ACI without needing to set up
    additional nodes in case your cluster cannot offer any more resources in a scale-out
    scenario. [Figure 2-6](#modernized_application_with_feature_3_be) shows how an
    existing monolithic application (Legacy App) is broken down into smaller microservices
    (Feature 3). The legacy application and the new microservice (Feature 3) are on
    a service mesh on Kubernetes. In this case Feature 3 has independent scale needs
    and can be scaled out into a CaaS offering using Virtual Kubelet.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 应用演进的下一步是使用无服务器基础设施来处理容器化工作负载，即 CaaS 提供的解决方案，如 Azure 容器实例或 AWS Fargate。微软 Azure
    在将其托管的 Kubernetes 服务（AKS）与其 CaaS 提供的 ACI 融合方面做得非常出色，通过使用*虚拟节点*。虚拟节点基于微软的开源项目 Virtual
    Kubelet，它允许任何计算资源充当 Kubernetes 节点并使用 Kubernetes 控制平面。对于 AKS 虚拟节点而言，您可以将应用程序调度到
    AKS 并在需要扩展的情况下无需设置额外的节点即可扩展到 ACI。[图 2-6](#modernized_application_with_feature_3_be)
    显示了现有的单片应用程序（Legacy App）如何被拆分为更小的微服务（Feature 3）。遗留应用程序和新的微服务（Feature 3）位于 Kubernetes
    上的服务网格中。在这种情况下，Feature 3 具有独立的扩展需求，并且可以使用 Virtual Kubelet 扩展到 CaaS 提供的环境中。
- en: '![clna 0206](Images/clna_0206.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0206](Images/clna_0206.png)'
- en: Figure 2-6\. Modernized application with Feature 3 being scaled out into CaaS
    using Virtual Kubelet
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 使用 Virtual Kubelet 将 Feature 3 扩展到 CaaS 中的现代化应用程序
- en: Application Optimization
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用程序优化
- en: The next step is to improve the application in terms not only of further cost
    optimization, but also of code optimization. Functions really excel in short-lived
    compute scenarios, such as updating records, sending emails, transforming messages,
    and so on. To take advantage of functions, you can identify short-lived compute
    functionality in your service codebase and implement it using functions. A good
    example is an order service in which the containerized microservice does all the
    Create, Read, Update, and Delete (CRUD) operations, and a function sends the notification
    of a successfully placed order. To trigger the function, eventing or messaging
    systems are being used. Eventually, you could decide to build the entire order
    service using functions, with each function executing one of the CRUD operations.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是不仅在成本优化方面进一步优化应用程序，还包括代码优化。函数在短期计算场景（如更新记录、发送电子邮件、转换消息等）中表现出色。要利用函数，您可以在服务代码库中识别出短期计算功能，并使用函数来实现。一个很好的例子是订单服务，其中容器化微服务执行所有的创建、读取、更新和删除（CRUD）操作，而函数则发送成功下单的通知。为了触发函数，通常使用事件或消息系统。最终，您可以决定使用函数构建整个订单服务，每个函数执行
    CRUD 操作中的一个。
- en: Microservices
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务
- en: Microservices is a term commonly used to refer to a microservices architecture
    style, or the individual services in a microservices architecture. A microservices
    architecture is a service-oriented architecture in which applications are decomposed
    into small, loosely coupled services by area of functionality. It’s important
    that services remain relatively small, are loosely coupled, and are decomposed
    around business capability.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '"微服务" 是一个常用术语，用来指代微服务架构风格或微服务架构中的各个服务。微服务架构是一种面向服务的架构，其中应用程序根据功能领域被分解为小型、松耦合的服务。服务保持相对较小、松耦合，并围绕业务能力进行分解是非常重要的。'
- en: Microservices architectures are often compared and contrasted with monolithic
    architectures. Instead of managing a single codebase, a shared datastore, and
    data structure, as in a monolith, in a microservices architecture an application
    is composed of smaller codebases, created and managed by independent teams. Each
    service is owned and operated by a small team, with all elements of the service
    contributing to a single well-defined task. Services run in separate processes
    and communicate through APIs that are either synchronous or asynchronous message
    based.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构通常与单体架构进行比较和对比。与单体架构管理单一代码库和共享数据存储和数据结构不同，在微服务架构中，一个应用程序由由独立团队创建和管理的更小的代码库组成。每个服务由一个小团队拥有和操作，服务的所有元素都贡献于一个单一明确定义的任务。服务在单独的进程中运行，并通过同步或异步基于消息的
    API 进行通信。
- en: Each service can be viewed as its very own application with an independent team,
    tests, builds, data, and deployments. [Figure 2-7](#inventory_service_in_a_microservices_arc)
    shows the concept of a microservices architecture, using the Inventory service
    as an example.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 每个服务都可以被视为具有独立团队、测试、构建、数据和部署的独立应用程序。[图 2-7](#inventory_service_in_a_microservices_arc)展示了微服务架构的概念，以库存服务为例。
- en: '![clna 0207](Images/clna_0207.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![clna 0207](Images/clna_0207.png)'
- en: Figure 2-7\. Inventory service in a microservices architecture
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-7\. 微服务架构中的库存服务
- en: Benefits of a Microservices Architecture
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务架构的优点
- en: A properly implemented microservices architecture will increase the release
    velocity of large applications, enabling businesses to deliver value to customers
    faster and more reliably.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一个正确实施的微服务架构将增加大型应用程序的发布速度，使企业能够更快、更可靠地为客户提供价值。
- en: Agility
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 敏捷性
- en: Fast, reliable deployments can be challenging with large, monolithic applications.
    A deployment of a small change to a module in one feature area can be held up
    by a change to another feature. As an application grows, testing of the application
    will increase and it can take a considerable amount of time to deliver new value
    to stakeholders. A change to one feature will require the entire application to
    be redeployed and rolled forward or back if there is an issue with that change.
    By decomposing an application into smaller services, the time needed to verify
    and release changes can be reduced and deployed more reliably.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 大型的单体应用程序可能会面临快速、可靠的部署挑战。对一个特性区域的模块进行小改动的部署可能会受到对另一个特性的改动的影响。随着应用程序的增长，应用程序的测试将增加，并且要向利益相关者交付新的价值可能需要相当长的时间。对一个特性的更改将要求整个应用程序被重新部署并前进或后退，如果出现问题。通过将应用程序分解为更小的服务，可以减少验证和发布变更所需的时间，并更可靠地进行部署。
- en: Continuous innovation
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续创新
- en: 'Companies need to move increasingly faster in order to remain relevant today.
    This requires organizations to be agile and capable of quickly adapting to fast-changing
    market conditions. Companies can no longer wait years or months to deliver new
    value to customers: they must often deliver new value daily. A microservices architecture
    can make it easier to deliver value to stakeholders in a reliable way. Small independent
    teams are able to release features and perform A/B testing to improve conversions
    or user experience during even the busiest times.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 企业需要更快地移动，以保持今天的相关性。这要求组织具备敏捷性，并能够快速适应快速变化的市场条件。企业不能再等待数年或数月来为客户提供新的价值：他们通常必须每天交付新的价值。微服务架构可以更容易地以可靠的方式向利益相关者交付价值。小而独立的团队能够发布功能，并在繁忙时期进行A/B测试以改进转化率或用户体验。
- en: Evolutionary design
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进化设计
- en: With a large monolithic application, it can be very difficult to adopt new technologies
    or techniques because this will often require that the entire application be rewritten
    or care needs to be taken to ensure that some new dependency can run side-by-side
    with a previous one. Loose coupling and high functional cohesion is important
    to a system design that is able to evolve through changing technologies. By decomposing
    an application by features into small, loosely coupled services, it can be much
    easier to change individual services without affecting the entire application.
    Different languages, frameworks, and libraries can be used across the different
    services if needed to support the business.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型单体应用中，很难采用新技术或技术，因为这通常要求整个应用程序被重写，或者需要确保某些新依赖可以与之前的依赖并行运行。松散耦合和高功能内聚对于能够通过变化的技术进行演变的系统设计非常重要。通过将应用程序按特性分解为小型、松散耦合的服务，可以更轻松地修改单个服务而不影响整个应用程序。如果需要支持业务，可以在不同服务之间使用不同的语言、框架和库。
- en: Small, focused teams
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小而专注的团队
- en: Structuring engineering teams at scale and keeping them focused and productive
    can be challenging. Making people responsible for designing, running, and operating
    what they build can also be challenging if what you are building is heavily intertwined
    with what everyone else is building. It can sometimes take new team members days,
    weeks, or even months to get up to speed and begin contributing because they are
    burdened with understanding aspects of a system that are unrelated to their area
    of focus. By decomposing an application into smaller services, small agile teams
    are able to focus on a smaller concern and move quickly. It can be much easier
    for a new member joining because they need to be concerned with only a smaller
    service. Team members can more easily operate and take accountability for the
    services they build.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在规模化构建工程团队并保持他们专注和高效可能是具有挑战性的。如果你正在构建的内容与其他人正在构建的内容紧密相连，那么让人们负责设计、运行和操作他们构建的内容也可能会很具有挑战性。新团队成员有时需要花费几天、几周，甚至几个月的时间才能迅速上手并开始贡献，因为他们需要理解与他们关注领域无关的系统方面。通过将应用程序分解为较小的服务，小敏捷团队能够专注于较小的关注点并快速迭代。新成员加入时也会更容易，因为他们只需关注较小的一个服务。团队成员可以更容易地运行和对他们构建的服务负责。
- en: Fault isolation
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 故障隔离
- en: In a monolithic application, a single library or module can cause problems for
    the entire application. A memory leak in one module not only can affect the stability
    and performance of the entire application, but can often be difficult to isolate
    and identify. By decomposing features of the application into independent services,
    teams can isolate a defect in one service to that service.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在单体应用中，一个单一的库或模块可能会对整个应用程序造成问题。一个模块中的内存泄漏不仅会影响整个应用程序的稳定性和性能，而且往往很难隔离和识别。通过将应用程序的特性分解为独立服务，团队可以将一个服务中的缺陷隔离到该服务中。
- en: Improved scale and resource usage
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 改进的规模和资源使用
- en: Applications are generally scaled up or out. They are scaled up by increasing
    the size or type of machine, and scaled out by increasing the number of instances
    deployed and routing users across these instances. Different features of an application
    will sometimes have different resource requirements; for example, memory, CPU,
    disk, and so on. Application features will often have different scale requirements.
    Some features might easily scale out with very few resources required for each
    instance, whereas other features might require large amounts of memory with limited
    ability to scale out. By decoupling these features into independent services,
    teams can configure the services to run in environments that best meet the services,
    individual resource and scale requirements.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 应用通常是通过增加机器的大小或类型来进行扩展，也可以通过增加部署的实例数量并在这些实例之间路由用户来进行扩展。应用程序的不同特性有时会有不同的资源需求；例如内存、CPU、磁盘等。应用程序的不同特性通常会有不同的规模需求。一些特性可能可以轻松地通过很少的资源在每个实例上进行扩展，而其他特性可能需要大量内存，且能力有限以进行扩展。通过将这些特性解耦为独立服务，团队可以配置这些服务在最符合服务、个体资源和规模需求的环境中运行。
- en: Improved observability
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 改进的可观察性
- en: In a monolithic application it can be difficult to measure and observe the individual
    components of an application without careful and detailed instrumentation throughout
    the application. By decomposing features of an application into separate services,
    teams can use tools to gain deeper insights into the behavior of the individual
    features and interactions with other features. System metrics such as process
    utilization and memory usage can now easily be tied back to the feature team because
    it’s running in a separate process or container.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在单体应用程序中，如果不对整个应用程序进行仔细和详细的仪表化，很难测量和观察应用程序的各个组件。通过将应用程序的特性分解为单独的服务，团队可以使用工具更深入地了解各个特性的行为以及与其他特性的交互。例如，系统指标如进程利用率和内存使用现在可以轻松地与特性团队关联起来，因为它们运行在单独的进程或容器中。
- en: Challenges with a Microservices Architecture
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务架构的挑战
- en: Despite all the benefits of a microservices architecture, there are trade-offs,
    and a microservices architecture does have its own set of challenges. Tooling
    and technologies have begun to address some of these challenges, but many of them
    still remain. A microservices architecture might not be the best choice for all
    applications today, but we can still apply many of the concepts and practices
    to other architectures. The best approach often lies somewhere in between.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管微服务架构带来了诸多好处，但也存在权衡和挑战。工具和技术已经开始解决其中一些挑战，但许多挑战仍然存在。对于所有应用程序来说，微服务架构可能并非今天的最佳选择，但我们仍然可以将许多概念和实践应用于其他架构中。最佳方法通常介于两者之间。
- en: Complexity
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复杂性
- en: Distributed systems are inherently complex. As we decompose the application
    into individual services, network calls are necessary for the individual services
    to communicate. Networks calls add latency and experience transient failures,
    and the operations can run on different machines with a different clock, each
    having a slightly different sense of the current time. We cannot assume that the
    network is reliable, latency is zero, bandwidth is infinite, the network is secure,
    the topology will not change, there is one administrator, transport costs are
    zero, and that the network is homogenous. Many developers are not familiar with
    distributed systems and often make false assumptions when entering that world.
    The *Fallacies of Distributed Computing*, as discussed in [Chapter 1](ch01.xhtml#introduction_to_cloud_native),
    is a set of assertions describing those false assumptions commonly made by developers.
    They were first documented by L. Peter Deutsch and other Sun Microsystems engineers
    and are covered in numerous blog articles. [Chapter 6](ch06.xhtml#best_practices)
    provides more information about best practices, tools, and techniques for dealing
    with the complexities of distributed systems.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统本质上复杂。当我们将应用程序分解为单独的服务时，网络调用是这些服务之间通信的必要手段。网络调用会增加延迟，并可能经历暂时性故障，而且运行在不同机器上的操作可能具有不同的时钟，每个时钟对当前时间有稍微不同的感知。我们不能假设网络是可靠的，延迟为零，带宽是无限的，网络是安全的，拓扑结构不会改变，有一个管理员，传输成本为零，并且网络是同质化的。许多开发人员对分布式系统不熟悉，并且在进入这个领域时常常做出错误的假设。*分布式计算的谬误*，正如在[第1章](ch01.xhtml#introduction_to_cloud_native)中讨论的那样，是一组描述开发人员常犯的这些错误假设的声明。这些错误首次由L.
    Peter Deutsch和其他Sun Microsystems工程师记录，并在众多博客文章中进行了讨论。[第6章](ch06.xhtml#best_practices)提供了处理分布式系统复杂性的最佳实践、工具和技术的更多信息。
- en: Data integrity and consistency
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据完整性和一致性
- en: Decentralized data means that data will often exist in multiple places with
    relationships spanning different systems. Performing transactions across these
    systems can be difficult, and we need to employ a different approach to data management.
    One service might have a relationship to data in another service; for example,
    an order service might have a reference to a customer in an account service. Data
    might have been copied from the account service in order to satisfy some performance
    requirements. If the customer is removed or disabled, it can be important that
    the order service is updated to indicate this status. Dealing with data will require
    a different approach. [Chapter 4](ch04.xhtml#working_with_data) covers patterns
    for dealing with this.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 分散化的数据意味着数据通常存在于多个地方，并且跨不同系统存在关系。在这些系统之间执行事务可能会很困难，我们需要采用不同的数据管理方法。一个服务可能与另一个服务中的数据存在关联；例如，订单服务可能会引用帐户服务中的客户。为了满足某些性能要求，数据可能已经从帐户服务复制过来。如果客户被删除或禁用，则订单服务更新指示此状态可能很重要。处理数据将需要不同的方法。[第4章](ch04.xhtml#working_with_data)涵盖了处理这些情况的模式。
- en: Performance
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 性能
- en: Networking requests and data serialization add overhead. In a microservices-based
    architecture the number of network requests will increase. Remember, components
    are libraries that are no longer making direct calls; this is happening over a
    network. A call to one service can result in a call to another dependent service.
    It might take a number of requests to multiple services in order to satisfy the
    original request. We can implement some patterns and best practices to mitigate
    potential performance overhead in a microservices architecture, which we look
    at in [Chapter 6](ch06.xhtml#best_practices).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 网络请求和数据序列化会增加额外开销。在基于微服务的架构中，网络请求的数量将会增加。请记住，组件是不再直接调用的库；而是通过网络进行调用。对一个服务的调用可能会导致对其他依赖服务的调用。为了满足原始请求，可能需要向多个服务发送多个请求。我们可以实施一些模式和最佳实践，以减轻微服务架构中潜在的性能开销，这些内容将在[第6章](ch06.xhtml#best_practices)中介绍。
- en: Development and testing
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开发和测试
- en: Development can be a bit more challenging because the tools and practices used
    today don’t work with a microservices architecture. Given the velocity of change
    and the fact that there are many more external dependencies, it can be challenging
    to run a complete test suite on versions of the dependent services that will be
    running in production. We can implement a different approach to testing to address
    these challenges, and a proper Continuous Integration/Continuous Deployment (CI/CD)
    pipeline will be necessary. Development tooling and test strategies have evolved
    over the years to better accommodate a microservices architecture. [Chapter 5](ch05.xhtml#devops)
    covers many of the tools, techniques, and best practices.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 开发可能会更具挑战性，因为今天使用的工具和实践方法不适用于微服务架构。考虑到变化的速度以及存在更多外部依赖的事实，运行与生产环境中运行的依赖服务版本完全一致的完整测试套件可能会很具挑战性。我们可以采用不同的测试方法来解决这些挑战，而且将需要一个适当的持续集成/持续部署（CI/CD）流水线。多年来，开发工具和测试策略已经在演变，以更好地适应微服务架构。[第5章](ch05.xhtml#devops)涵盖了许多工具、技术和最佳实践。
- en: Versioning and integration
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 版本控制和集成
- en: Changing an interface in a monolithic application can require some refactoring,
    but the changes are often built, tested, and deployed as a single cohesive unit.
    In a microservices architecture service, dependencies are changing and evolving
    independently of the consumers. Careful attention to forward and backward compatibility
    is necessary when dealing with service versioning. In addition to maintaining
    forward and backward compatibility with service changes, it might be possible
    to deploy an entirely new version of the service, running it side-by-side with
    the previous version for some period of time. [Chapter 5](ch05.xhtml#devops) explores
    service versioning and integration strategies.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在单体应用程序中更改接口可能需要进行一些重构，但更改通常作为一个单一的统一单元构建、测试和部署。在微服务架构中，服务的依赖关系是在独立演化和变化的。在处理服务版本控制时，需要特别注意前向和后向兼容性。除了与服务更改保持前向和后向兼容性之外，还可能需要在一段时间内与之前版本并存并在旁边运行完全新的服务版本。[第5章](ch05.xhtml#devops)探讨了服务版本控制和集成策略。
- en: Monitoring and logging
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控和日志记录
- en: Many organizations struggle with monitoring and logging of monolithic applications,
    even when they are using a common shared logging library. Inconsistencies in naming,
    data types, and values make it difficult to correlate relevant log events. In
    a microservices architecture, when relevant events span multiple services—all
    potentially using different logging implementations—correlating these events can
    be even more challenging. Planning and early attention to the importance of logging
    and monitoring can help address much of this, which we examine in [Chapter 5](ch05.xhtml#devops).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 许多组织在监视和记录单体应用程序时遇到困难，即使它们使用了共享的日志记录库。名称、数据类型和值的不一致性使得相关日志事件的关联变得困难。在微服务架构中，当相关事件跨越多个服务时——每个服务可能使用不同的日志记录实现——关联这些事件可能会更加具有挑战性。计划并早期关注日志记录和监视的重要性可以帮助解决其中大部分问题，我们将在[第五章](ch05.xhtml#devops)进行详细探讨。
- en: Service dependency management
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务依赖管理
- en: With a monolithic application, dependencies on libraries are generally compiled
    into a single package and tested. In a microservices architecture, service dependencies
    are managed differently, requiring environment-specific routing and discovery.
    Service discovery and routing tools and technologies have come a long way in addressing
    these challenges. [Chapter 3](ch03.xhtml#designing_cloud-native_applications)
    looks at these in depth.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单体应用程序时，通常会将对库的依赖项编译到单个包中并进行测试。在微服务架构中，服务依赖关系的管理方式不同，需要特定于环境的路由和发现。在解决这些挑战方面，服务发现和路由工具和技术已经取得了长足的进步。[第三章](ch03.xhtml#designing_cloud-native_applications)深入探讨了这些内容。
- en: Availability
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可用性
- en: Although a microservices architecture can help isolate faults to individual
    services, if other services or the application as a whole is unable to function
    without that service, the application will be unavailable. As the number of services
    increases, the chance that one of those services experiences a failure also increases.
    Services will need to implement resilient design patterns, or some functionality
    downgraded in the event of a service outage. [Chapter 6](ch06.xhtml#best_practices)
    covers patterns and best practices for building highly available applications
    and provides more detail on the specific challenges.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管微服务架构可以帮助将故障隔离到单个服务，但如果其他服务或整个应用程序无法在没有该服务的情况下运行，则应用程序将无法使用。随着服务数量的增加，某个服务遇到故障的可能性也增加。服务将需要实施弹性设计模式，或在服务故障时降低某些功能。[第六章](ch06.xhtml#best_practices)涵盖了构建高可用应用程序的模式和最佳实践，并详细讨论了具体的挑战。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Every application, whether cloud native or traditional, needs infrastructure
    on which to be hosted, technology that addresses pain points with development
    and deployment, and an architectural style that helps with achieving the business
    objectives, such as time to market. The goal of this chapter was to provide the
    basic knowledge for cloud native applications. By now you should understand that
    there are various container technologies with different isolation levels, how
    functions relate to containers, and that serverless infrastructure does not always
    need to be FaaS. Further, you should have a basic understanding of microservices
    architectures and of how you can migrate and modernize an existing application
    to be a cloud native application.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 每个应用程序，无论是云原生还是传统的，都需要基础设施来托管，技术来解决开发和部署中的痛点，以及能够帮助实现业务目标的架构风格，如市场投放时间。本章的目标是为云原生应用程序提供基础知识。到目前为止，您应该了解到有各种容器技术具有不同的隔离级别，函数如何与容器相关联，以及无服务器基础设施并不总是需要函数即服务。此外，您应该对微服务架构有基本的理解，以及如何将现有应用程序迁移到云原生应用程序。
- en: The upcoming chapters build on this knowledge and go deep into how to design,
    develop, and operate cloud native applications.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 即将到来的章节将在此基础上深入探讨如何设计、开发和运营云原生应用程序。
