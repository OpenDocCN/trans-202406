- en: Chapter 12\. Interactive Analysis in Jupyter Notebook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With this chapter, we round out the experience of working in the cloud. We started
    out in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud) running individual commands
    in a shell, and built up proficiency with GATK tools in [Chapter 5](ch05.xhtml#first_steps_with_gatk)
    through [Chapter 7](ch07.xhtml#gatk_best_practices_for_somatic_variant). Then,
    in [Chapter 8](ch08.xhtml#automating_analysis_execution_with_work), you learned
    about scripted workflows and discovered progressively better ways to run them
    in subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Yet we’re now coming back to the inescapable fact that not everything in genomics
    can (or should) be done as a scripted workflow. Sometimes, you just want to interact
    directly with the data, maybe generate a couple of plots and determine what your
    next step should be based on what the plots look like. You might be in an early
    exploratory phase of your project, stuck midway through with some failed samples
    to troubleshoot, or moving on to digging into the genetics of a group of people.
    In any case, you need to be able to try out ideas quickly, keep track of what
    each attempt produces, and share your work with others.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we show you how to use Jupyter Notebook in Terra to achieve
    these objectives. We kick it off with a brief introduction to Jupyter, in case
    you’re not already familiar with the concept and tooling. We spend a bit more
    time on describing how Jupyter works in Terra, focusing on the capabilities and
    behaviors that are more specific to Terra and the cloud environment. Then, in
    the hands-on portion of this chapter, we guide you through an example notebook
    that demonstrates three types of interactive analyses, with direct connections
    to topics and exercises covered in earlier chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Jupyter in Terra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you’re reading this book in its intended order, we introduced you to Terra
    in [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in), primarily
    so that you could experience working with its built-in Cromwell server to run
    workflows efficiently at scale. You learned to clone a workspace, read a workflow
    configuration, and launch the workflow on part or all of a preset dataset. However,
    Terra is not only built for running workflows, but also includes tooling for performing
    interactive analysis, including a Jupyter service. In this chapter, we’re going
    to show you how to use Jupyter in Terra to interact with data and perform analysis
    in real time. You’ll still work within the same workspace, but this time you’ll
    be going to the Notebooks tab instead of the Workflows tab.
  prefs: []
  type: TYPE_NORMAL
- en: In the first part of this introduction, we aim to provide enough context and
    fundamentals so that if you’ve never heard of Jupyter before, you’ll be able to
    complete the exercises that follow. If you’re already familiar with Jupyter, feel
    free to skip this part. In the second part, we talk specifically about how Jupyter
    works in Terra, focusing mostly on what is different compared to typical local
    installations. We strongly recommend that you read it even if you’re familiar
    with Jupyter, in general because it will help you to better understand key points
    of the exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Jupyter Notebooks in General
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a nutshell, *Jupyter* is an application that creates a special kind of document
    that combines static content (like text and images) with executable code and even
    interactive elements. For example, the tutorial notebook that you’ll work with
    in this chapter has sections of plain text that explain briefly what’s going on
    as well as *code cells* that include fully functional tool commands (which you
    can execute to actually run GATK on real data). It includes an integrated IGV
    module that allows you to view the results of the commands. To run the contents
    of a code cell, you simply click the cell and then press Shift+Enter on your keyboard,
    or, on the menu bar, click the Run icon. As the command runs, the output log of
    the command appears directly below the code cell, as shown in [Figure 12-1](#a_screenshot_of_doc_textcomma_code_cell).
    When you send to collaborators a copy of a notebook with code cells that have
    been run, they can view your results embedded within the document.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of doc text, code cell, and execution output in a Jupyter Notebook.](Images/gitc_1201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-1\. Doc text, code cell, and execution output in a Jupyter notebook.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The basic idea is to combine analysis methods and findings in a single place,
    in a form that anyone can easily distribute. In a way, this is a logical evolution
    of the traditional scientific paper, but much better because it dramatically shortens
    the path between reading how an analysis was done and actually being able to reproduce
    it. It’s difficult to overstate how powerful this concept is and what a dramatic
    impact it can have on the reusability and reproducibility of findings in the computational
    sciences.
  prefs: []
  type: TYPE_NORMAL
- en: So what kind of code can you run in such an interactive notebook? The original
    concept had been developed under the name [IPython](https://ipython.org) to run
    Python code specifically. The Jupyter project came out of IPython with the goal
    of extending the concept to other languages, starting with Julia, Python, and
    R, which are reflected in the name Jupyter (hence, the *py* spelling of Jupyter,
    as opposed to Jupiter, the Roman god of thunder). There are now Jupyter *kernels*
    for [other popular languages](https://oreil.ly/Pf8Or), such as Ruby, for example.
    In this chapter’s exercises, we work with a Python kernel that supports including
    R code, as well as running pretty much anything you could run in a shell environment,
    thanks to a neat set of features called *Python magic methods*. In our opinion,
    it’s like having the best of both worlds, but for many worlds.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In general computing, the *kernel* is the program at the core of an operating
    system. In the Jupyter context, the kernel is the program that interprets code
    cells, passes those instructions to the actual operating system of the machine
    that the notebook is running on, and retrieves results to display them in the
    notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Jupyter notebooks are backed by a server application that has fairly simple
    requirements and can be run on almost any kind of computing infrastructure, including
    your laptop. In addition, a Jupyter notebook enables researchers to encapsulate
    the information necessary to re-create the software environment used by the analysis
    that it describes, making it a great vector for distributing reproducible code.
    It’s also an increasingly popular teaching tool, for reasons that will hopefully
    become evident as you work through the exercises in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The growing popularity of Jupyter has spawned a rich ecosystem of add-on tools
    and services. For example, GCP operates a service called [Colaboratory](https://oreil.ly/3Tr2r)
    that offers free access to cloud-based notebooks, with tutorial materials that
    are heavily geared toward machine learning applications. The Google Cloud AI Platform,
    meanwhile, offers a paid service that offers preconfigured VMs for running notebooks
    integrated with other Google Cloud services. Another example is [Binder](https://mybinder.org),
    an open source community-driven project that can take any Jupyter notebook in
    a GitHub repository and open it in an interactive environment. These free services
    usually have limitations on the amount of computing power associated with the
    environments they provide, but they can be extremely convenient nonetheless for
    sharing working code, tutorials, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: That being said, it’s practically impossible for a single tool to satisfy the
    full spectrum of needs and preferences of people in computational sciences, and
    we recognize that Jupyter notebooks do have some shortcomings that limit their
    appeal to certain audiences. For example, people with advanced programming experience
    typically criticize the lack of development features that are standard on most
    modern programming tools, like syntax highlighting and code introspection. In
    addition, data scientists who are used to exploratory analysis interfaces like
    [RStudio](https://oreil.ly/1M5Jh) tend to find the primary Jupyter interface too
    basic and lacking in assistive features. The [JupyterLab](https://oreil.ly/RCfhB)
    project aims to remedy that limitation by providing a richer interface that is
    closer in concept to RStudio. Given the surge in economic investment in data sciences
    that we’ve seen in recent years, we expect that the tooling options will only
    improve over time, and we look forward to seeing what the next generation of interfaces
    will look like.
  prefs: []
  type: TYPE_NORMAL
- en: In the meantime, we choose to use Jupyter for its accessibility to newcomers
    and its as-yet unparalleled support of portability and reproducibility.
  prefs: []
  type: TYPE_NORMAL
- en: How Jupyter Notebooks Work in Terra
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we get into the details, you should know that Terra uses a standard Jupyter
    server implementation, so the interface and core capabilities that you will be
    working with are all basically the same as those you would see in any other setting.
    As a result, you can take advantage of the wealth of documentation and tutorials
    available on the internet for learning how to use the various menu options, widgets,
    and so on that we’re not going to cover in detail here.
  prefs: []
  type: TYPE_NORMAL
- en: The one thing that is truly different about how Jupyter notebooks work in Terra
    compared to typical local installations is the way the computing environment is
    set up. Let’s go over that now given that it will have important consequences
    for you on several fronts; for example, the amount of flexibility you have to
    customize the environment, and the way you will access data and then save your
    analysis results.
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Terra, notebook documents live in your workspace’s storage bucket. When you
    open a notebook for the first time, Terra requests a VM in GCP, spins up a container
    with a Jupyter server on it, and loads your notebook within that container environment,
    as illustrated in [Figure 12-2](#an_overview_of_the_jupyter_notebooks_se).
  prefs: []
  type: TYPE_NORMAL
- en: '![An overview of the Jupyter service in Terra.](Images/gitc_1202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-2\. An overview of the Jupyter service in Terra.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: From that point on, any code that you run in the notebook will be executed in
    the container on that VM. You can even run commands that install software packages
    or load libraries on the VM to customize the environment on the fly. Conceptually,
    it’s similar to working with the VM you set up through the GCP console in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud)
    and subsequently used in every chapter up through [Chapter 8](ch08.xhtml#automating_analysis_execution_with_work),
    except it is originally created by Terra, and it provides you with the Jupyter
    interface instead of the bare shell terminal.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to pull up a terminal interface to the notebook, which allows
    you to perform actions like listing files and installing packages without having
    to put these actions into code cells. However, we recommend using this capability
    sparingly, largely because it runs counter to the underlying purpose of Jupyter,
    which is to capture every meaningful action taken during an analysis. Listing
    directory contents might not be meaningful in that context, but installing a package
    or importing data, on the other hand, can play an essential role. Omitting such
    actions from the notebook record could create missing links that break the reproducibility
    of the work.
  prefs: []
  type: TYPE_NORMAL
- en: The cost model is the same, as well; GCP will charge you for the amount of time
    that the VM is in a running state, even if it’s not actively doing anything. The
    good news is that Terra has an automatic feature to detect inactivity; more on
    that in a minute. The base rate depends on the VM configuration you choose to
    use; by default, Terra provides a basic configuration that accommodates common
    performance needs, but you can dial it up or down based on your specific needs.
    We get back to that shortly.
  prefs: []
  type: TYPE_NORMAL
- en: The overall computing environment constituted by the VM plus the container and
    all the software it contains is called the *notebook runtime*. It is strictly
    personal to you; no one else can access it even if you share your workspace with
    them. We talk about sharing and collaboration in the last section of this introduction,
    when you’ll have a better sense of how it all works.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Your notebook runtime comes equipped with local storage space. Cloud subtleties
    notwithstanding, it’s basically like a hard drive with a filesystem on it. You
    can interact with the filesystem through code cells in the notebook, via the Jupyter
    built-in graphical file explorer, or through the aforementioned terminal interface,
    which supports classic commands like `ls` and `cd`. This allows you to run commands
    in the notebook using regular file paths as you would on a regular local system,
    such as your laptop. In addition, there are a few ways to run commands on data
    without first copying it to the local filesystem. We’re not going to go through
    the laundry list of options for accessing data from a notebook, because that would
    be boring. Instead, here’s a list of those we use most commonly:'
  prefs: []
  type: TYPE_NORMAL
- en: Upload files from your desktop to your notebook’s local storage through the
    notebook’s graphical file explorer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy data from a GCS bucket to your notebook’s local storage using `gsutil cp`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run tools that support streaming (like GATK4) directly on files in GCS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import tabular data from tables on the DATA tab of the workspace by using a
    programmatic interface (API).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import tabular data from Google’s BigQuery datastore service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We show you how to use the second and third options in practice in the next
    section, and we will provide pointers to additional resources for learning the
    fourth and fifth on the book’s companion blog.
  prefs: []
  type: TYPE_NORMAL
- en: Saving, stopping, and restarting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While you work in the notebook, the system will regularly save changes back
    to the original notebook document in your workspace bucket. However, aside from
    the notebook itself, Terra does not automatically save any files from the notebook’s
    local storage back to the workspace. For reasons that we discuss shortly, you
    can’t depend on the notebook runtime for permanent storage, so you must take action
    to save a copy of any output files you care about, preferably to the workspace
    storage bucket. We show you an easy way to do this in [“Setting Up a Sandbox and
    Saving Output Files to the Workspace Bucket”](#setting_up_a_sandbox_and_practice_savin).
  prefs: []
  type: TYPE_NORMAL
- en: 'When you’re done working and close the notebook, Terra instructs GCP to stop
    the notebook runtime but save its state, which includes the state of the Jupyter
    container, with any modifications that you might have made by installing packages,
    for example, and any files present on its local storage partition. That way, you
    can resume working at any time with minimal effort: when you reopen the notebook,
    Terra restarts the VM and restores the notebook runtime to its saved state. The
    restart process can take up to two minutes on the GCP side, but while you wait,
    Terra gives you a read-only view of the notebook contents based on the document’s
    latest saved state. Finally, as mentioned in the previous paragraph, Terra is
    able to detect when you are no longer actively working in your notebook (based
    on how long the VM has been idle) and will automatically save the notebook and
    stop the VM to limit your costs.'
  prefs: []
  type: TYPE_NORMAL
- en: Customizing your notebook’s computing environment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You might want to customize your notebook runtime in two main ways: modify
    the VM resource allocations (how many CPUs, how much memory, etc.) and/or modify
    which software is preinstalled in the container.'
  prefs: []
  type: TYPE_NORMAL
- en: As noted earlier in passing, you can readily modify the VM resources allocated
    to your notebook runtime; for example, if you need more CPUs or memory than is
    included in the default configuration, you can adjust the notebook runtime configuration
    accordingly. You can even request a Spark cluster instead of a single VM if you’re
    planning to use tools that are Spark enabled. Conveniently, Terra includes a notebook
    runtime configuration panel that is much simpler than the equivalent GCP interface,
    which you might remember from [Chapter 4](ch04.xhtml#first_steps_in_the_cloud).
    But what’s really cool is that you can do it at any time, even if you’ve already
    started working in the notebook. You’ll just pull up the configuration panel,
    specify what you want, and let the system regenerate your notebook runtime with
    the new specifications. As a result, you don’t need to try too hard to guess up
    front the kind of resources you’re going to need to do your work. You can start
    working with minimal settings and then dial them up if you run into limitations.
  prefs: []
  type: TYPE_NORMAL
- en: 'However—and this is a big caveat—the new runtime *will be a blank slate* because
    the regeneration process provisions a new VM with a fresh install of the original
    container image and an empty storage partition. If the work you’re doing in your
    notebook includes mostly short-running commands that don’t amount to much computation
    cost, this isn’t a big problem: the Jupyter menu includes an option to rerun all
    code cells (or all up to a certain point) so that you can simply regenerate the
    previous state. However, if some of your work involves massive computations that
    would not be trivial to rerun, you might need a better strategy. For example,
    you could explicitly save the outputs generated so far to the workspace bucket
    and then set your notebook to take those saved outputs as inputs for the next
    section of the work.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second customization point, modifying the software in the container when
    the notebook runtime is being generated, is a little more complicated but worth
    taking a few minutes to discuss. First, why would you want to do that? Suppose
    that your analysis is going to require software packages that are not part of
    the default notebook runtime configuration. You could start the notebook with
    some installation steps, but that can turn into a maintenance headache if you
    have multiple notebooks that require the same configuration commands. It would
    be much easier to move some of those software installation steps out of the notebooks
    and into the environment configuration proper. You can do exactly that in Terra
    in two ways: you can specify a setup script that Terra will run in the container
    when it is creating or regenerating the notebook runtime, or you can supply a
    custom container image to the runtime service. Or you can, in fact, combine both:
    specify a custom container and a startup script to modify its setup. [Figure 12-3](#options_for_customizing_the_software_in)
    illustrates the difference between these options.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Options for customizing the software installed in the notebook runtime.](Images/gitc_1203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-3\. Options for customizing the software installed in the notebook
    runtime.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In the upcoming exercises, we show you how to use the startup script option
    because it’s a good compromise of power and ease of use: it’s not difficult to
    make your own, and you can readily distribute the script for others who are also
    using the same kernel in Terra. The custom container image option is technically
    more powerful and more portable, but it’s a bit more complicated. If you’re interested
    in learning how that works, check out the [Terra documentation on custom containers](https://oreil.ly/R-Grd).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you know how much power you have to customize your notebook runtime,
    we need to address a crucial question that we’ve been careful to avoid bringing
    up until now: how many notebook runtimes do you get to work with? Do you use the
    same runtime for everything, one per workspace, one per notebook, or can you create
    new runtimes willy-nilly like you can spin up VMs in the GCP console? To be frank,
    the answer is likely to evolve over time as the platform matures further and the
    product development team collects more data regarding what researchers actually
    want (so feel free to give them your opinion!).'
  prefs: []
  type: TYPE_NORMAL
- en: As of this writing, the Terra Notebooks service provides you with a single notebook
    runtime for all workspaces within a particular billing project. To be clear, this
    means that if you open or create another notebook in any workspace attached to
    the same billing project as your first notebook, the new notebook will open in
    the same runtime environment. This can be very convenient if you have a lot of
    overlap between the data, resources, and software that you plan to use in both
    notebooks. However, it can be a source of major complications if you are working
    on different projects with very different configuration needs. In that case, you
    might want to consider developing notebooks with incompatible requirements under
    different billing projects, because that will give you a completely separate notebook
    runtime for each one.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing and collaboration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With that, you’ve reached the last section of this introduction, and now it’s
    time to talk about how to play nice with others. As we noted earlier, the notebook
    runtime is personal to you: only you have access to that machine, container, and
    Jupyter server. If you share your workspace with a collaborator who then opens
    up the same notebook, it will open in their own runtime environment. As a result,
    any work they do in the notebook will not affect the state of your runtime environment.
    However, the system will automatically save any changes they make to the shared
    document in the workspace, so it’s important to set expectations clearly with
    your collaborators about whether it’s OK for them to modify the notebook or whether
    they should work in a separate copy.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, be aware that Terra will *lock* the notebook document in the workspace
    whenever someone is actively working with it, to avoid having multiple people
    making conflicting changes at the same time. When this happens, your collaborator
    can open the notebook in the read-only preview mode, or they can open it in a
    special *playground mode* that allows them to make changes and run code in their
    own runtime environment but does not save any changes to the original file, as
    illustrated in [Figure 12-4](#options_for_sharing_and_collaboration_a). This falls
    a bit short of the ideal collaborative experience that you could envision based
    on Google Docs, for example, but it provides a reasonable compromise given the
    constraints at play.
  prefs: []
  type: TYPE_NORMAL
- en: '![Options for sharing and collaboration around notebooks in Terra.](Images/gitc_1204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-4\. Notebooks in shared workspaces are protected from overwriting
    when two people open them concurrently.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If you’re having a difficult time envisioning how this all works in practice,
    don’t worry! First, that’s totally OK; if anything is unclear, it’s our fault,
    not yours. Second, good news: you’ve reached the end of the wall of theory, and
    now it’s time to work through practical exercises in a real-life notebook.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started with Jupyter in Terra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’re going to work with a prewritten notebook, so you’ll mostly just need to
    run cells, though whenever possible we tried to include hints for additional things
    that you can try in order to reinforce the learning. In [Chapter 13](ch13.xhtml#assembling_your_own_workspace_in_terra),
    we talk about creating your own notebooks from scratch or importing existing notebooks
    from external sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, go back to the workspace that you created by cloning the original
    book workspace in [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in).
    If you don’t have the URL on hand, you should be able to find it in [Your Workspaces](https://oreil.ly/bKWll);
    or if you deleted it, you can clone the original again by following the relevant
    instructions at the beginning of [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in).
    After you’ve found your workspace, open it and go to the Notebooks tab. There,
    you’ll see two notebooks listed, as shown in [Figure 12-5](#the_notebooks_tab_showing_two_copies_of).
    Those are actually two copies of the same notebook: one that has never been run,
    and the other where we ran everything so that you can see the expected output.'
  prefs: []
  type: TYPE_NORMAL
- en: '![The NOTEBOOKS tab showing two copies of the notebook: one already executed
    and another without any previous results.](Images/gitc_1205.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-5\. The Notebooks tab showing two copies of the notebook: one already
    executed and another without any previous results.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We recommend that you open the second only in preview mode to preserve its contents
    as a reference in case you encounter anything surprising in the other one, which
    you will use to run through the upcoming exercise.
  prefs: []
  type: TYPE_NORMAL
- en: However, before you open anything, we’re going to walk you through customizing
    your runtime configuration. If you already started opening one of the notebooks,
    don’t panic; you’ll still be able to reconfigure the notebook runtime. We just
    want to save you a little bit of time given that it takes a few minutes to get
    a new runtime up and running, and we know that we’re going to want more than what
    the default configuration has to offer.
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting and Customizing the Notebook Runtime Configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As noted earlier, the runtime environment that Terra creates for you by default
    is set up with basic resource allocations and a set of standard software packages.
    You can view this configuration at any time without having to open a notebook,
    as long as you’re in a workspace under the appropriate billing project. To do
    so, look for the Notebook Runtime status widget, which, as of this writing, is
    displayed in the upper-right corner of almost all workspace pages, as demonstrated
    in [Figure 12-6](#the_notebook_runtime_status_widgetdot).
  prefs: []
  type: TYPE_NORMAL
- en: '![The Notebook Runtime status widget.](Images/gitc_1206.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-6\. The Notebook Runtime status widget.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We have heard rumblings from the Terra product development team that the display
    of the Notebook Runtime status widget might change in the near future, in which
    case you’ll need to poke around to find it, or if that fails, consult the documentation
    in the book’s repository on [GitHub](https://oreil.ly/genomics-repo).
  prefs: []
  type: TYPE_NORMAL
- en: Click the gear icon on the right to bring up the runtime configuration page.
    If you haven’t made any customizations to the runtime under your current billing
    project, the form should display all default settings, as depicted in [Figure 12-7](#the_default_notebook_runtime_configurat).
  prefs: []
  type: TYPE_NORMAL
- en: '![The default Notebook Runtime configuration settings.](Images/gitc_1207.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-7\. The default Notebook Runtime configuration settings.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can see a small list of default environments to choose from, identified
    by the packages that are considered most important. For full details on what is
    installed on each, select the environment you’re interested in and click “What’s
    installed on this environment?” to bring up the detailed view. As shown in [Figure 12-8](#detailed_view_of_the_packages_installed),
    this detailed view is further broken into categories such as Python, R, and Tools.
    Selecting either Python or R brings up the full list of packages of the corresponding
    language that are included in the runtime environment. Selecting Tools will bring
    up the list of command-line executable tools also included in the runtime environment.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, if you select Tools, you’ll see that this default set actually includes
    GATK, which is a nice touch for those of us in the genomics field, considering
    Terra has a much wider audience than just genomics. That being said, for the purposes
    of this book, we are using a different version than the one included in the default
    configuration as of this writing, so we need to customize this. In addition, we’re
    going to want to use a Python library that (spoiler alert) makes it possible to
    embed an IGV browser window within the notebook (which is so cool). We could install
    both from within the notebook itself, but as noted in the introduction, we prefer
    to use a startup script that will install them in the Jupyter container during
    the notebook runtime creation process. We provide a closer look at the script
    in question in the accompanying sidebar in case you’re curious, but feel free
    to skip it if it’s not your cup of tea or if you’re eager to get started with
    the notebook itself.
  prefs: []
  type: TYPE_NORMAL
- en: '![Detailed view of the packages installed on the default runtime environment.](Images/gitc_1208.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-8\. Detailed view of the packages installed on the default runtime
    environment.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: So where should we specify the startup script? You might be tempted to look
    in the environments menu on the notebook runtime customization page, maybe even
    select the Custom Environment option, and you would be so close to being right,
    conceptually—but in practice, you’d be wrong. That is where you would go to specify
    a custom Docker image to substitute for the built-in one. Instead, you need to
    look a little farther down at the Compute Power section (shown earlier in [Figure 12-7](#the_default_notebook_runtime_configurat)),
    which allows you to modify the VM resource allocations. This section includes
    a menu that allows you to choose from three preset configurations, designated
    as providing Moderate, Increased, or High computer power, or provide your own
    under the label Custom.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To be frank, we wouldn’t be surprised if this part of the interface also evolved
    a bit in the near future because it’s not super logical to find a software customization
    option grouped with hardware allocations. Not to mention the names of the preset
    configurations, which are about as helpful as Starbucks cup sizes: once you get
    used to them, they kind of make sense, but the first time you set foot in a Starbucks,
    you’re just happy that the prices tell you which one is bigger.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Feel free to select each preset and look at how their respective resource allocations
    differ. When you’re ready to move on, select the Custom option to bring up an
    editable configuration window. You should see a new field named “Startup script”
    appear that wasn’t available earlier ([Figure 12-9](#the_compute_power_section_allows_you_to)).
    You can finally input the path to the startup script there, in the text box labeled
    URI (for [uniform resource identifier](https://oreil.ly/Ltao0), a close cousin
    of [URL](https://oreil.ly/jUtVr), the uniform resource locator). We included a
    copy of the script in the book bucket, so you can use this path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The rest of the resource allocations will be fine with the default (Moderate)
    values of 4 CPUs, 15 GB of memory (RAM), and 50 GB of disk (storage space). [Figure 12-9](#the_compute_power_section_allows_you_to)
    demonstrates what this looks like.
  prefs: []
  type: TYPE_NORMAL
- en: As a reminder, this startup script installs GATK version 4.1.3.0 in the runtime
    environment, as well as an IGV integration module that will make it possible to
    view genomic data using IGV from within the notebook itself.
  prefs: []
  type: TYPE_NORMAL
- en: '![The COMPUTE POWER section allows you to specify a startup script if you choose
    the Custom profile.](Images/gitc_1209.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-9\. The Compute Power section allows you to specify a startup script
    if you choose the Custom profile.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Click the Create button when you are done (labeled Replace if you had already
    created a runtime earlier), and Terra begins to create a new runtime environment
    with your settings. You can go grab yourself a cup of something nice or continue
    on to the next set of instructions, as you prefer. You will probably need to wait
    a few minutes in either case while Terra communicates with GCP to provision your
    shiny new runtime environment.
  prefs: []
  type: TYPE_NORMAL
- en: Opening Notebook in Edit Mode and Checking the Kernel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You don’t need to wait for the runtime to be ready in order to take a peek
    at the notebook, so go ahead and open the never-been-run copy of the tutorial
    notebook. Whether your runtime is ready or not, Terra will initially open the
    notebook in preview mode, in which the notebook is read-only. As [Figure 12-10](#menu_on_the_notebook_preview_page_displ)
    illustrates, a menu at the top of the preview panel offers you the two options
    for opening the notebook in an interactive mode: Edit, to work with the notebook
    normally; or Playground Mode, to experiment without saving anything, as we briefly
    discussed in the introduction.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Menu on the notebook preview page displaying the main options: Preview, Edit,
    and Playground Mode.](Images/gitc_1210.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-10\. Menu on the notebook preview page displaying the main options:
    Preview, Edit, and Playground Mode.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Click Edit and wait for the runtime to be ready. You’ll recognize when the transition
    to Edit mode happens by the appearance of the standard Jupyter menu bar, shown
    in [Figure 12-11](#the_standard_jupyter_notebooks_menu_bar). A more subtle but
    also important sign is the little white box toward the right of the menu bar showing
    the label Edit Mode. If you had opened the notebook in Playground Mode by mistake,
    the Jupyter menu bar would also be displayed, but instead of the white Edit Mode
    label, you’d see an orange “Playground Mode (Edits not saved)” label.
  prefs: []
  type: TYPE_NORMAL
- en: '![The standard Jupyter menu bar.](Images/gitc_1211.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-11\. The standard Jupyter menu bar.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Further to the right in that area of the menu bar is the Python 3 label that
    identifies the active kernel as well as the Python logo. You might remember that
    the *kernel* of the notebook is the computational engine that interprets the code
    in the notebook and initiates execution of each cell that you run. For this particular
    notebook, we decided to use a Python 3 kernel so we can execute terminal commands
    (including to programs like `gsutil` and GATK) using Python magic methods—which
    is an actual technical term, we swear. You’ll see it in action shortly: it is
    truly magical.'
  prefs: []
  type: TYPE_NORMAL
- en: In case you’re wondering, yes you can switch the kernel while the notebook is
    running using the Kernel menu, but we really don’t recommend doing that. It might
    sound useful in principle—for example, to run code in a different language in
    a subset of cells—but in practice it’s dangerous and can mess you up if you’re
    not careful. If you need to use both Python and R code within the same notebook,
    you’re much better off using the Python 3 kernel and magic methods commands as
    we demonstrate in this notebook.
  prefs: []
  type: TYPE_NORMAL
- en: And with that, it’s time to run some actual code cells!
  prefs: []
  type: TYPE_NORMAL
- en: Running the Hello World Cells
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s run through a few simple examples so you can get a feel for what it’s
    like to work in a Jupyter notebook if you’ve never done so before. We’re going
    to run three types of commands to demonstrate the syntax for running Python code
    as well as R code and a command-line tool from the Python context.
  prefs: []
  type: TYPE_NORMAL
- en: Python Hello World
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the classic Hello World in Python, using the `print()` function and
    giving it the string `Hello World`. As you may recall from the Hello World we
    did in WDL in [Chapter 8](ch08.xhtml#automating_analysis_execution_with_work),
    this is the equivalent of the `echo "Hello World"` command that we used at the
    time. To run the cell, click anywhere in the gray area to select the cell and
    then press Shift+Enter on your keyboard, or, at the top of the page, on the toolbar,
    use the Run menu to run the cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use a variable for the greeting if you want to give yourself some flexibility.
    Double-click the cell to edit it and modify the code, as follows, and then run
    it again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Incidentally, this shows you that when you have a cell containing multiple lines,
    running it executes all the code in the cell. Sometimes, it makes sense to group
    multiple commands in a single cell because you’re always going to want to run
    them all. However, you could also choose to divide them into separate cells. Try
    doing that now. You can add a new cell to the notebook either by clicking the
    “+” icon on the toolbar at the top of the page or by going to the Insert menu.
    The former automatically creates the new cell below the one that is currently
    active, whereas the Insert menu gives you an explicit choice to add it either
    above or below the active cell.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This allows you to decouple the assignment of the variable and the execution
    of the task itself. In this simple example, it doesn’t make much difference, but
    when you are performing more complex operations, the choice of which commands
    to group versus which to break apart becomes more important.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the basic mechanics down, let’s have a look at how we can
    run some R code within this Python notebook.
  prefs: []
  type: TYPE_NORMAL
- en: R Hello World using Python magic methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This one requires a tiny bit of setup before we can dive into the Hello World
    exercise itself. Remember the startup script we used to customize the notebook
    runtime? One of the steps in that script installs the `rpy2` package, which handles
    the interpretation of R code within the Python notebook, into the runtime environment.
    It’s one of the magic methods features we mentioned earlier in the chapter. To
    activate it, you first need to import the `rpy` package and activate the corresponding
    notebook extension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This can take a few seconds, during which time the server displays an asterisk
    (`*`) in the brackets to the left of the cell to indicate that it’s working on
    it. After the package is loaded, you have two ways to invoke the magic methods:
    use `%R` for a single line of code or `%%R` for an entire cell.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the same basic Hello World as we ran earlier but in R this time, using
    the single-line magic methods invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Yes, that’s the same code as we ran in the Python example, because R also has
    a `print()` function. You can recognize that it’s the R version because the output
    shows up as an array with the greeting as a single string element, whereas the
    Python version just returned the text of the greeting as a string by itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'That being said, modifying it to use a variable assignment makes it a little
    more obvious that it’s R code as opposed to Python. This time, use `%%R` to apply
    the magic methods to the whole cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'There you go: you’re running R code in a Python notebook. This is going to
    be really handy when we get to the “serious” exercises, because we need to use
    Python in order to embed an IGV browser (coming up real soon!), but we also want
    to use an existing R script later for plotting. Now we have access to the best
    of both worlds. Just remember that when you start using this in your own notebooks,
    you’ll need to include the cell that imports `rpy2` and activates the extension.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This brings us to the third type of command that we’re going to want to run
    in our notebook: command-line tools like `ls`, `gsutil`, and GATK.'
  prefs: []
  type: TYPE_NORMAL
- en: Command-line tool Hello World using Python magic methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For this one, there’s nothing to load; the Hello World case works out of the
    box. We’ll use the classic `echo` command that we used in our WDL Hello World
    example. Simply prepend an exclamation mark to the command and then run the cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You can use all the classic shell commands in this way; for example, if you
    want to list the contents of the working directory, type `**! ls**` in a cell
    and run it. Similarly, you can run any command-line tool installed in the notebook
    runtime environment in this way. All preset environments available in Terra include
    the `gsutil` package, so you can use those tools in any Terra notebook. We walk
    you through specific examples of that in the next section. Later, we also run
    commands to run GATK, which our startup script installed, using the same basic
    syntax.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve been focusing on code cells so far, but keep in mind all of the descriptive
    text cells are also editable, of course. Feel free to double-click a few and see
    how their appearance changes to show that they are in editing mode. Try making
    some edits and then, when you’re done, “run” the cell (just as you would run a
    code cell) to exit the text-editing mode. The descriptive text cells use a simple
    formatting markup language called *Markdown*, so you can set header levels, make
    bullet-point lists, and so on. For more on working with Markdown, see this helpful
    [page](https://oreil.ly/07KtL) in the Jupyter project documentation. When you
    create new cells in your notebook, the system makes them code cells by default,
    but you can switch them to Markdown via the Cell menu, by choosing Cell Type >
    Markdown.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a firm grip on the fundamentals, it’s time to do some work
    that is more specific to the cloud environment and the genomics subject matter
    that interests us.
  prefs: []
  type: TYPE_NORMAL
- en: Using gsutil to Interact with Google Cloud Storage Buckets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most of the time, the data we want to work with in the notebook resides in
    GCS buckets, so the first thing you need to learn is how to access that data.
    Here’s some good news: you can use `gsutil` commands to do all the same things
    we’ve previously shown you in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud)
    and beyond. For example, use `gsutil ls` to list the contents of the book bucket:^([1](ch12.xhtml#idm45625613561112))'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, you can use `gsutil cp` to *localize* files; that is, copy them
    from a bucket to the notebook’s local storage space. For example, use the following
    command to copy a file from the book bucket to the *sandbox* directory in the
    notebook runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Then, you can run `cat` to read the contents of the localized file. You could
    write this in Python instead because this is a Python notebook, but it’s hard
    to beat the brevity of `cat`!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, these are essentially the same commands we used in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud),
    except that we added the `!` in front to signal the Python interpreter to execute
    that line as a terminal command instead of reading it as Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up a Variable Pointing to the Germline Data in the Book Bucket
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next few exercises are going to make use of the germline data that we provide
    in the book’s data bundle. Because the path to the example data is rather long,
    let’s set up a variable to store it in the notebook in a more concise form, much
    as we did with an environmental variable back in [Chapter 5](ch05.xhtml#first_steps_with_gatk):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a Python variable, so when you use it in a shell command, you’ll need
    to wrap it up in curly braces. For example, a command using `gsutil` to list the
    contents of that directory would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Take a moment to think about how we’re using curly braces around this variable
    instead of calling it as `$GERM_DATA`, which you might have expected based on
    the Bash environment variables that we’ve been using quite a bit so far. The key
    point to remember here is that we set up the bucket shortcut as a Python variable,
    not a shell environment variable. It is possible to use shell environment variables
    in the notebook, but that’s a topic for another time.
  prefs: []
  type: TYPE_NORMAL
- en: You can also compose paths based on this variable in order to list subdirectories;
    for example, to get a list of the BAM files, or perform operations on specific
    files. For each of the following commands, try to infer what its function is,
    then run it in the notebook and evaluate the result against your expectation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Later in this chapter, we also show you how to use this same `GERM_DATA` variable
    in the context of some Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up a Sandbox and Saving Output Files to the Workspace Bucket
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you run commands in the notebook that produce output files, by default
    those files will be saved on the notebook’s local storage space. However, the
    local storage associated with your notebook is temporary, so you’ll need to copy
    any outputs that you care about to a GCS bucket. You can use any bucket to which
    you have write access for that purpose, but we recommend using the workspace’s
    dedicated bucket.
  prefs: []
  type: TYPE_NORMAL
- en: 'To streamline the process of saving outputs to the bucket, we like to do two
    things: create a sandbox to house the output files that we’re going to produce,
    and set up a variable pointing to the workspace bucket.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin with the *sandbox* directory; go ahead and create a new directory,
    and then move some files there for demonstration purposes. Once again, we include
    the commands here but don’t detail their purpose or results. We do provide additional
    detail in the notebook. Try to infer the function of each command before you look
    at its full description and run it in the notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'When you have your sandbox ready, let’s tackle the workspace bucket. The workspace
    bucket name is a long machine-generated sequence of letters and numbers, which
    is annoying to work with. Fortunately, we can import it programmatically (rather
    than looking it up manually in the workspace dashboard) because Terra makes it
    available to the notebook as a system variable. And to make it even easier, we’re
    going to create a Python variable from that system variable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use Python commands to set variables at the Python level. The `import
    os` command allows us to interact with the operating system from within Python
    code, and the `os.environ['WORKSPACE_BUCKET']` call uses that to access the value
    of the environment variable `'WORKSPACE_BUCKET'`, which was originally set for
    you by the Terra Notebooks service.
  prefs: []
  type: TYPE_NORMAL
- en: 'From here on, you’ll be able to refer to the workspace bucket as `WS_BUCKET`.
    For example, you can use `gsutil ls` to list its contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we wrapped the `WS_BUCKET` variable in curly braces, just as we
    did for the germline data variable in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that’s set up, you can simply run the same `gsutil cp` command on the
    *sandbox* directory whenever you want to save your outputs to the workspace bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This copies the entire *sandbox* directory from the notebook’s local storage
    to the workspace bucket. Keep in mind that this approach might not scale very
    well if you’re producing many large files; in that case, you might want to consider
    dividing and managing your sandbox in separate subdirectories. It is admittedly
    not ideal that you must synchronize files manually to the bucket; we look forward
    to seeing improvements to the experience of using these tools as the technology
    develops further. At least the notebook file itself is saved automatically, as
    we discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing Genomic Data in an Embedded IGV Window
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that our notebook is all set up and ready to roll,  let’s use it to try
    out a cool trick: visualizing genomic data with IGV within the context of the
    notebook. In previous chapters, we had you work with the desktop version of IGV,
    which you had set up to pull data from GCS. This time, we’re going to do something
    a little different: we’re going to use a special IGV package called *IGV.js* that
    allows us to embed an IGV browser in the notebook. This is especially convenient
    when you want to include the data visualization within a tutorial for students,
    or within a report to communicate results to collaborators, in such a way that
    they don’t need to resort to using a separate program.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The *IGV.js* package has limitations that we describe further in just a moment.
    In a nutshell, it’s very cool when it works, so we do think it’s worth showing
    you how to use it in a Jupyter notebook, but it doesn’t always work seamlessly.
    If you experience any difficulties while using it, we recommend that you fall
    back to using Desktop IGV, as previously described.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this exercise, we’re going to load two BAM files: the WGS mother sample,
    which has been our go-to test file for most of the book, and an exome sample from
    the same person for comparison. You might recall that in [Chapter 2](ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new)
    (a lifetime ago), we touched on the differences between several library design
    strategies, including WGS and exome sequencing. In particular, we discussed how
    their coverage profiles have very different shapes: the WGS tends to look like
    a distant mountain range, whereas the exome sample looks more like a series of
    volcanic islands scattered in the ocean. This is an opportunity for you to see
    that for yourself, essentially replicating [Figure 2-18](ch02.xhtml#visual_appearance_of_whole_genome_seque)
    in an interactive form, while trying out the *IGV.js* integration.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up the Embedded IGV Browser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The good news is that there’s not much you need to do here. Remember the startup
    script that you ran as part of the runtime environment customization? That included
    instructions to install all the prerequisite software to run *IGV.js*, which the
    system executed when it created your customized runtime environment. As a result,
    we just need to do a one-time import to activate the `igv` Python package. After
    that, it’s just a matter of creating an IGV browser wherever you want one to appear,
    as shown in the code cell that follows. This is all Python code that follows the
    guidelines documented by the IGV team in the [IGV-Jupyter repository](https://oreil.ly/JgOtt)
    on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The name we give the browser (here, `IGV_Explore`) is completely arbitrary.
    You could provide other parameters to initialize the browser, but the only one
    that is absolutely required is the genome reference; everything else is optional.
    That being said, we usually specify some coordinates (or the name of a gene of
    interest) for the browser to zoom in on straight away.
  prefs: []
  type: TYPE_NORMAL
- en: When you run the cell, you should see an embedded IGV browser that includes
    the reference genome and a RefSeq gene track, but no actual data tracks, as shown
    in [Figure 12-12](#a_newly_created_igv_browserdot).
  prefs: []
  type: TYPE_NORMAL
- en: '![A newly created IGV browser.](Images/gitc_1212.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-12\. A newly created IGV browser.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Next, let’s add the two sample BAM files that we want to compare.
  prefs: []
  type: TYPE_NORMAL
- en: Adding Data to the IGV Browser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For each track that we want to load, we need to provide this same set of metadata:
    a name for the track, the path to where the file lives in GCS, the format, and
    the path to the corresponding index file. We provide this information to IGV using
    the `load_track()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Because this is all Python code, we can use the Python variable that we set
    up for the germline data simply by referring to its name, `GERM_DATA`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Take a moment to note the Python syntax, which explicitly uses a `+` operator
    to concatenate the variable and the subdirectory strings in order to compose the
    full address pointing to where the data files reside. This is in contrast to the
    shell syntax that we used earlier in the `gsutil` command, `"{GERM_DATA}/bams"`,
    which is a more implicit instruction. If you’re not very familiar with Python,
    know that this exemplifies one of the cardinal rules of Python programming: explicit
    is better than implicit.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After you’ve run both cells and each of them returns `OK` as a result, scroll
    up to the browser, where you should see spinning symbols that indicate the data
    is loading. When the spinners go away and the data displays, you should have two
    data tracks in your IGV browser: the WGS and exome versions of the mother sample,
    respectively, as shown in [Figure 12-13](#the_igv_browser_showing_the_two_sequenc).'
  prefs: []
  type: TYPE_NORMAL
- en: '![The IGV browser showing the two sequence data tracks.](Images/gitc_1213.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-13\. The IGV browser showing the two sequence data tracks.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Try zooming in and out, and drag the sequence left and right to pan the view
    and get a sense of how the data is distributed in these two samples. You’ll observe
    the classic “mountain range versus volcanic islands” difference in coverage profile,
    which you can use from here onward to identify the library design type of any
    sequencing sample on sight.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It is technically possible to load VCF and BAM files in the embedded IGV browser
    without specifying an index file. To do so, omit the `"indexURL"` line and replace
    it with `"indexed": False`. Be aware, however, that doing so will cause IGV to
    take much longer to load the data. It can take a couple of minutes for the data
    to load, and you might see a pop-up window stating that the page is unresponsive.
    If so, dismiss the alert and give it another minute. If it takes much longer than
    that, you might need to fall back to using the desktop version of IGV.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We hope you’ll agree this is a neat way to include a view of the genomic data
    within an analysis log or report, even though it suffers from a few limitations.
    One limitation is the lag that you might experience when you originally load the
    data; another is the fact that not all display customization options are available
    compared to the desktop version of IGV. Authentication can be a major stumbling
    block if you don’t have proper guidance: if you want to access data in private
    buckets (which includes your workspace bucket!), you need to jump through additional
    hoops that involve access credentials. You might recall that in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud)
    you had to enable a Google login option in the desktop version of IGV in order
    to view files from a private bucket. Here, we’re going to do something similar,
    except instead of a point-and-click process, it will consist of a few lines of
    code.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up an Access Token to View Private Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous example, we were reading data from completely public buckets,
    so we didn’t need to do any authentication. However, you’ll eventually want to
    view files in private buckets. To do that, you need to set up an access token
    that IGV can use to access data in your private bucket.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s use `gcloud auth` to generate an access token and save it to a
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As long as this file is saved only to your notebook’s local storage, it is secure
    because your runtime environment is strictly personal to you and cannot be accessed
    by others, even if you share your workspace or your notebook with them. But don’t
    save this file to your workspace bucket! Saving it to the bucket would make it
    visible to anyone with whom you share the workspace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, read the contents of the token file into a Python variable. Because the
    token consists of a single line of text, we can use the `readline()` function,
    which reads the first line of a file into a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: At this point, you have the `token` variable stored and ready to use with IGV
    whenever you want to load a file that resides in a private bucket.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, recall that in the previous section, we had you copy the *mother.bam*
    file and its index to your workspace bucket. Even though you own that bucket,
    the IGV process that is running in your notebook doesn’t “know” that you’re allowed
    to access it. You must instruct it explicitly by providing the token that you
    just set up when you make the call to `load_track()` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we copied the same code we used earlier to load BAM files, except
    this time we provided the path to the files in the workspace bucket and added
    the token that we generated earlier. If you’re curious to see what would happen
    if you didn’t provide the token, feel free to try it out by deleting that line
    (as well as the comma that ends the previous line). Note that it is also possible
    to access data that resides in private buckets managed outside of Terra. As we’ll
    see in [Chapter 13](ch13.xhtml#assembling_your_own_workspace_in_terra), this requires
    giving access to the bucket to your proxy group service account.
  prefs: []
  type: TYPE_NORMAL
- en: If you were to have multiple private files to load in the IGV browser, you would
    include the token in each track definition. The [IGV documentation](https://oreil.ly/RWDqg)
    states that it is possible to set a global IGV configuration variable, `igv.setGoogleOauth​Token​(accessToken)`,
    that would apply to all tracks, but as of this writing, that did not work within
    our notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Running GATK Commands to Learn, Test, or Troubleshoot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s all well and good that we can visualize the sequencing data from within
    a notebook, but we were already able to achieve the equivalent result with the
    desktop version of IGV. What’s really cool about the notebook concept is that
    we can run analysis commands and then visualize the output, all within the same
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: What kind of analyses can you run, you ask? Well, just about anything you want.
    As you saw when we had you run `gsutil` commands, you’re not constrained to running
    only Python code in a Python notebook. You can run pretty much anything that you
    can install and run in the shell environment.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here we’re relying on the startup script that you used to initialize your notebook
    runtime environment at the start of this chapter’s exercises. That script includes
    instructions to download the GATK package and make it available for command-line
    invocation, which were executed when the environment was created for you, so you
    don’t need to do any of it yourself.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we show you how to run GATK commands and visualize the results
    in IGV, both from within the notebook. We find that this provides a much more
    integrated and seamless experience than the “split-screen” approach we took in
    earlier chapters in which we were running GATK commands in a VM and then visualizing
    results in the desktop version of IGV. We put you through all that because we’re
    sadists, and also because it gave you the opportunity to build up foundational
    skills. Through that process, you gained a measure of familiarity with the underlying
    components of cloud computing that should help you conceptualize what’s happening
    behind the scenes when you run a workflow or work in a notebook. And perhaps having
    gone through that will enhance your appreciation of the notebook-based approach,
    if only for purposes like teaching, testing, and troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: To that end, we’re going to revisit exercises that you previously worked through
    in [Chapter 5](ch05.xhtml#first_steps_with_gatk) so you can focus your attention
    on *how* you are doing the work rather than what the analysis means.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running a Basic GATK Command: HaplotypeCaller'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s begin by running the `HaplotypeCaller` tool on the same sample we’ve
    been using throughout the book. You should recognize this command, which we copied
    almost verbatim from [Chapter 5](ch05.xhtml#first_steps_with_gatk):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: What are the differences in this command compared to how we ran it in [Chapter 5](ch05.xhtml#first_steps_with_gatk)?
    By now you should recognize the `!` that precedes the GATK command as the signal
    to bypass the Python interpreter and run it as a shell command. The reference
    to the file path variable is also a little different since we’re using curly braces
    instead of `$`, as noted earlier. We’re also writing the output VCF file in the
    compressed *gzip* form, which is a requirement for IGV in the next step.
  prefs: []
  type: TYPE_NORMAL
- en: Another difference is a bit hidden by our use of a Python variable to store
    the common part of the input file paths, *gs://genomics-in-the-cloud/v1/data/germline*.
    This time, we’re using the paths to the files in GCS instead of pointing to a
    local copy. We can do that because, as we’ve noted several times by now, GATK
    tools are capable of streaming most types of file inputs directly from GCS. In
    practice this behavior kicks in whenever the GATK command-line parser identifies
    that an eligible input file path starts with *gs://*. This is great because it
    allows us to avoid localizing the relevant files to the notebook’s local storage.
    Incidentally, this also works for writing output files directly to GCS, though
    we don’t demonstrate it here.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.xhtml#first_steps_with_gatk) through [Chapter 7](ch07.xhtml#gatk_best_practices_for_somatic_variant),
    we had you localize the full data bundle and run all GATK commands with local
    file inputs. We could have had you run most of the commands with the bucket paths
    instead and relied on GATK’s data streaming capabilities; it would have worked
    just fine on your VM. However, we felt that introducing those aspects so early
    would overcomplicate what might well be your first experience with the cloud.
    We chose instead to have you work with localized files in the hope that the ensuing
    experience would provide enough familiarity to make you feel more comfortable.
    We bring this up now in case you choose to go back to working in a VM environment,
    so that you know that you can still take advantage of the streaming feature. And,
    as you might remember from the discussion on optimizations in [Chapter 10](ch10.xhtml#running_single_workflows_at_scale_with),
    this also works in the context of WDL workflows.
  prefs: []
  type: TYPE_NORMAL
- en: When you run the command, you should see the log output being written to the
    notebook below the cell. This is a really nice touch in terms of keeping all the
    information about the analysis together in a single place—it’s one of the key
    benefits of the Jupyter concept. On the downside, if you’re running a tool that’s
    particularly verbose (as GATK can occasionally be), you can end up with pages
    and pages of a log in the middle of your notebook. That’s where it really helps
    to use clear section headers in Markdown cells to demarcate the different parts
    of your analysis, especially in combination with the notebook widget that automatically
    creates a table of contents and sidebar navigation menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the `HaplotypeCaller`’s run is complete, let’s list the sandbox contents
    to confirm that the command worked and that the VCF of variant calls was created
    as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Yep, there it is, along with its index file. Let’s look at it in IGV.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the Data (BAM and VCF) into IGV
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose that we want to open the output VCF with IGV in our notebook, mainly
    to do a visual check and compare it to the BAM file. We could use the IGV browser
    that we created earlier to look at the different BAM files, but because this is
    a separate exercise with a different purpose—and we’re too lazy to scroll up a
    bunch of pages—we’re going to create a new one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first bit of code is essentially the same as what we used earlier except
    that we’re using a different name for the browser object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates a new browser below the cell, zoomed in on intervals of interest
    but without any data. So, let’s load the variant data from the VCF file that we
    produced with the `HaplotypeCaller` command, which resides in the *sandbox* directory
    on the notebook’s local storage space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This is the same code that we used earlier to load BAM files, except this time
    we changed the track `format` property to `vcf` instead of `bam`, and the file
    paths (`url` and `indexURL`) are pointing to local files instead of pointing to
    locations in GCS.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Pay attention to those file paths: you should notice that they’re not exactly
    the file paths you would expect based on the directory structure of the notebook’s
    local storage space. Do you see it? The `files/` part does not refer to a real
    directory! It’s a prefix that we add for IGV’s benefit, as instructed in the [IGV-Jupyter
    project documentation](https://oreil.ly/JgOtt).'
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, you could run the `gsutil cp` command to copy the sandbox to
    the workspace bucket and then use the paths to the workspace bucket copy to load
    the VCF track. However, if you do that, don’t forget to include the access token
    as explained in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s load the BAM file and its index from the original germline data
    bundle. These files are located in a public bucket and therefore do not require
    specifying the access token (but if you do include it, nothing bad will happen):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The resulting view, shown in [Figure 12-14](#igvdotjs_rendering_of_the_sequencing_da),
    should look essentially the same as what you produced in [Chapter 5](ch05.xhtml#first_steps_with_gatk),
    with a few differences in appearance between the desktop version and the *IGV.js*
    version of the visual rendering.
  prefs: []
  type: TYPE_NORMAL
- en: '![IGV.js rendering of the sequencing data ("Mother WGS" track) and output variants
    produced by HaplotypeCaller ("Mother variants" track).](Images/gitc_1214.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-14\. IGV.js rendering of the sequencing data (“Mother WGS” track)
    and output variants produced by HaplotypeCaller (“Mother variants” track).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can click elements of data (e.g., reads or variants) in the viewer to bring
    up additional details, just as we did in [Chapter 5](ch05.xhtml#first_steps_with_gatk).
    The visual display is a little different, but it’s basically the same functionality,
    except that you can’t switch it to show details “on hover.”
  prefs: []
  type: TYPE_NORMAL
- en: One difference that’s not obvious here is that the embedded IGV window organizes
    tracks a little differently compared to the way the desktop version of IGV does
    it. In the desktop version, variant tracks are automatically displayed above sequence
    data tracks, regardless of the order in which they are loaded. You could load
    a BAM file first and then a VCF file, yet the variant track will always be on
    top. In contrast, the embedded IGV window displays tracks in whatever order they
    are added. So, if you load the BAM file first, that’s what will be on top, even
    if you load a VCF file afterward.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully this gives you a good sense of how you can use the embedded IGV within
    a notebook. Let’s work through one more exercise from the original [Chapter 5](ch05.xhtml#first_steps_with_gatk)
    curriculum to practice using this tooling and cover a few more minor options.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting a Questionable Variant Call in the Embedded IGV Browser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might recall that in [Chapter 5](ch05.xhtml#first_steps_with_gatk) we took
    a closer look at the homozygous variant insertion of three T bases that appears
    in the variant track in this region. At first glance, we were skeptical of `HaplotypeCaller`’s
    decision because the call didn’t seem to be supported by the sequencing data.
    Do you remember the first thing we did to investigate? That’s right, we turned
    on the display of soft clips, those bits of sequence data tagged as “unusable”
    by the mapper that are normally hidden by default. Let’s do that now in the IGV
    window in the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in [Figure 12-15](#menu_of_display_options_for_the_quotmot),
    you can bring up track-viewing options by clicking on the gear icon to the right
    of the track of interest. Do that now for the Mother WGS sequence data track and
    select “Show soft clips;” then, in the upper-right corner of the menu, click the
    X to close it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Menu of display options for the "Mother WGS" sequence data track.](Images/gitc_1215.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-15\. Menu of display options for the Mother WGS sequence data track.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You should see the entire area light up in the bright glare of multitudes of
    mismatches, as shown in [Figure 12-16](#display_of_soft_clipsdot).
  prefs: []
  type: TYPE_NORMAL
- en: '![Display of soft-clips.](Images/gitc_1216.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-16\. Display of soft clips.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You know what to do now, right? Questionable indel call, tons of soft clips…Yes,
    it’s time to generate a bamout to see what `HaplotypeCaller` was thinking when
    it made that call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'That should run very quickly and produce the key output we’re interested in,
    which is the BAM file that shows how `HaplotypeCaller` has realigned the read
    data, as explained in [Chapter 5](ch05.xhtml#first_steps_with_gatk). Let’s add
    that file to our IGV browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Again, this should produce a view that is equivalent, though not identical,
    to the one we encountered in [Chapter 5](ch05.xhtml#first_steps_with_gatk). As
    previously, we can conclude that `HaplotypeCaller`’s call of an indel was reasonable,
    given the realigned data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Incidentally, you might notice that in this one we specified the height of
    the track with `"height": 500`. This can be useful when we’re trying to showcase
    a specific view of the data in a way that minimizes scrolling, for example. Feel
    free to experiment with setting the height of different tracks.'
  prefs: []
  type: TYPE_NORMAL
- en: What do you think of this approach to running and examining GATK commands? We
    could continue mirroring all of the material that we covered in [Chapter 5](ch05.xhtml#first_steps_with_gatk)
    through [Chapter 7](ch07.xhtml#gatk_best_practices_for_somatic_variant) in this
    way, and in fact, there are several such GATK tutorial notebooks in public Terra
    workspaces, which the GATK team uses in its popular series of international workshops.
    We encourage you to check those out for further study.
  prefs: []
  type: TYPE_NORMAL
- en: However, for the purposes of this book, and this chapter in particular, we want
    to focus on covering the most useful aspects of Jupyter notebooks in relation
    to the types of interactions you would typically have with genomic data. We have
    a few more that we’re excited to show you, so we need to move on.
  prefs: []
  type: TYPE_NORMAL
- en: The next logical step is to plot variant data. There are many aspects of variant
    data that you might want to explore visually, but we can’t cover them all—in fact,
    we can really cover only one. So, let’s tackle the topic of visualizing how variant
    context annotation values are distributed, which can be helpful for understanding
    variant filtering methods, as we discussed in [Chapter 5](ch05.xhtml#first_steps_with_gatk).
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing Variant Context Annotation Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might recall that in [Chapter 5](ch05.xhtml#first_steps_with_gatk) we described
    using an annotation (`callsets`) derived from the GiaB truth set in order to understand
    how the distributions of variant context annotations can inform us about the quality
    of our variant calls. We used a visual approach to making that assessment, which
    involved plotting variant context annotation values in a couple of ways (density
    plots and scatter plots). If that doesn’t ring a bell or if you’re feeling fuzzy
    on the details, please take a few minutes to read through that section again to
    refresh your memory. At the time, we focused on the concepts and outlined the
    procedure only in general terms, so here we’re going to take the opportunity to
    show you how to apply key steps to reproduce the plots shown in [Figure 5-8](ch05.xhtml#aright_parenthesis_density_plot_of_qual)
    through [Figure 5-11](ch05.xhtml#a_scatter_plot_with_marginal_densities).
  prefs: []
  type: TYPE_NORMAL
- en: Exporting Annotations of Interest with VariantsToTable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We start with the VCF of SNPs called from the Mother WGS sample that we’ve previously
    annotated with information for the GiaB truth set. For a tutorial showing how
    to perform the full procedure, including subsetting and annotation steps, see
    this [GATK tutorial workspace](https://oreil.ly/WGncb).
  prefs: []
  type: TYPE_NORMAL
- en: 'The VCF file format is rather painful to work with directly, so for this exercise,
    we’re going to make life easier on ourselves and export the information we care
    about from the VCF file into a tab-delimited table, to make it easier to parse
    in R. To that end, we run the GATK tool `VariantsToTable` on the annotated input
    VCF file, providing it with the list of annotations we’re interested in. We use
    the `-F` argument for INFO (site-level) annotations and `-GF` for FORMAT (sample-level)
    annotations, where the *F* stands for field, and *GF* for genotype field, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The `VariantsToTable` command should run very quickly to produce the output
    file, *motherSNP.giab.txt*. This is a plain-text file, so we can view a snippet
    of it using `cat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the tool produced a table in which each line represents a variant
    record from the VCF, and each column represents an annotation that we specified
    in the export command. Wherever a requested annotation was not present (for example,
    homozygous sites do not have `RankSum` annotations, because that annotation can
    be calculated only for heterozygous sites), the value was replaced by `NA`. With
    this plain-text table in hand, we can easily load the full set of variant calls
    and their annotation values into an R DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'To load the table contents into an R DataFrame, we call the `readr` library
    and use its `read_delim` function to load the *motherSNP.giab.txt* table into
    the `motherSNP.giab` DataFrame object. Notice that the R command is preceded by
    the `%%R` symbol, which as we learned earlier instructs the notebook kernel that
    all of the code in this cell should be interpreted in R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: When the DataFrame is ready, you can manipulate it using your favorite R functions.
    And, as it happens, we have some handy plotting functions all lined up for you.
  prefs: []
  type: TYPE_NORMAL
- en: Loading R Script to Make Plotting Functions Available
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’re going to take advantage of an existing R script provided by the GATK support
    team. The script, which is available in the book repository and in the bucket,
    defines three plotting functions that utilize a fantastic R library called `ggplot2`
    to visualize the distribution of variant annotation values.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make these functions available in the notebook, we could simply copy the
    contents of the R script into a code cell and run it. However, because this is
    a script that we might want to run in multiple notebooks, and we don’t want to
    have to maintain separate copies, let’s use a smarter way to import the code.
    You’re going to copy the R script to the notebook’s local storage, and then use
    the `source()` function in R to load the R script code into the notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This outputs about a page’s worth of log, which we’re not showing here. The
    log output is displayed on a red background, which is a tad alarming, but don’t
    worry about it unless the next steps fail. If you do encounter issues, check whether
    your output is different from what is shown in the prerun copy of the notebook
    (which also contains solutions to the do-it-yourself exercises). If everything
    works as it should, you’ll now have a few new R packages installed and loaded,
    and the plotting functions will be available.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try that out, shall we? First up, the density plot.
  prefs: []
  type: TYPE_NORMAL
- en: Making Density Plots for QUAL by Using makeDensityPlot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `makeDensityPlot` function takes a DataFrame and an annotation of interest
    to generate a density plot, which is basically a smoothed version of the histogram,
    representing the distribution of values for that annotation. Here’s how we can
    use it to reproduce Figures [5-8](ch05.xhtml#aright_parenthesis_density_plot_of_qual)
    and [5-9](ch05.xhtml#density_plot_of_qual_aright_parenthesis). In each of the
    following cells, the first line creates the plot and then the second line calling
    its name displays it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The QUAL distribution shown in [Figure 12-17](#qual_distributiondot) has a
    very long tail on the right, so let’s zoom in by restricting the x-axis to a reasonable
    maximum value by using the optional `xmax` argument, with the result presented
    in [Figure 12-18](#qual_density_plotdot):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '![QUAL distribution.](Images/gitc_1217.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-17\. QUAL distribution.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![QUAL density plot.](Images/gitc_1218.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-18\. QUAL density plot.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can also specify an annotation to use for organizing the data into subsets
    and have the function generate a separate density curve for each subset of data.
    Here, we use the `giab.callsets` annotation, which refers to the number of callsets
    in the GiaB truth set called the same variant. The higher the number, the more
    we can trust the variant call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 12-19](#qual_density_plots_by_callsets_from_gia) shows the result.'
  prefs: []
  type: TYPE_NORMAL
- en: '![QUAL density plots by callsets from GiaB.](Images/gitc_1219.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-19\. QUAL density plots by callsets from GiaB.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: After you have that working, try generating the same kind of plots for other
    annotations. As an example, we used similar commands to generate [Figure 5-10](ch05.xhtml#density_plot_of_qd_aright_parenthesis_a)
    for the `QualByDepth` (QD) annotation.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s try making scatter plots. Everyone loves a good scatter plot, right?
  prefs: []
  type: TYPE_NORMAL
- en: Making a Scatter Plot of QUAL Versus DP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `makeScatterPlot` function takes a DataFrame and two annotations of interest
    to generate a 2D scatter plot of the two annotations in which each data point
    is an individual variant call. Here’s how we can use it to reproduce [Figure 5-8](ch05.xhtml#aright_parenthesis_density_plot_of_qual)
    from [Chapter 5](ch05.xhtml#first_steps_with_gatk), with [Figure 12-20](#scatter_plot_qual_versus_dpdot)
    displaying the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '![Scatter plot QUAL versus DP.](Images/gitc_1220.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-20\. Scatter plot QUAL versus DP.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This function accepts the same `xmax` argument as `makeDensityPlot` for limiting
    the range of values on the x-axis, and a new `ymax` argument to limit values on
    the y-axis. Feel free to experiment with these arguments to zoom in on subsets
    of data.
  prefs: []
  type: TYPE_NORMAL
- en: You can also use the same `split` argument for splitting the data into subsets,
    with the effect of coloring the points based on the subset they belong to. Try
    doing that now based on what you learned in the previous exercise and then try
    applying the same principles to plot other annotations.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in our last plotting exercise, we’re going to combine both the scatter
    and the density plotting.
  prefs: []
  type: TYPE_NORMAL
- en: Making a Scatter Plot Flanked by Marginal Density Plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `makeScatterPlotWithMarginalDensity` function takes a DataFrame and two
    annotations, combining the other two functions to generate a scatter plot flanked
    horizontally and vertically by the annotations’ respective density plots. Here’s
    how we can use it to reproduce [Figure 5-11](ch05.xhtml#a_scatter_plot_with_marginal_densities)
    from [Chapter 5](ch05.xhtml#first_steps_with_gatk), with the result shown in [Figure 12-21](#a_scatter_plot_along_with_density_plots):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '![A scatter plot along with density plots.](Images/gitc_1221.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-21\. A scatter plot along with density plots.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As previously, we specify `giab.callsets` as the variable to use for splitting
    the variant data points into groups according to how much we trust them. We also
    set optional parameters (`xmax` and `ymax`) to limit the axes to display a subset
    of values, and we tweak the display of the data to optimize readability (`ptSize`
    and `ptAlpha`).
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and try applying this to other pairs of annotations. Note that some
    annotations can have negative values, so be aware that the plotting functions
    also accept `xmin` and `ymin` arguments to limit the range of negative values
    to display.
  prefs: []
  type: TYPE_NORMAL
- en: To be clear, there are a lot of other ways to manipulate and plot variant data
    from within a notebook. In fact, this particular method would not scale well for
    larger datasets, because it involves reading a potentially very large table directly
    into memory. We chose it for this tutorial because it has the advantage of being
    approachable for newcomers, and our primary goal was to give you a sense of the
    possibilities and familiarize you with the basic mechanics involved. However,
    for full-scale work, you’ll probably want to use more robust methods. We recommend
    checking out [Hail](https://hail.is), a Python-based, genetics-focused toolkit
    that is extraordinarily scalable and includes a suite of variant quality control
    functions, among other capabilities. Like some of the more recent GATK tools,
    Hail is capable of using Spark to parallelize analysis, and has been used to perform
    genome-wide analysis studies (GWAS) on massive datasets like the [UK Biobank](https://oreil.ly/mes1R).
    The Terra Library has a few workspaces that feature Hail, including a [set of
    tutorial notebooks](https://oreil.ly/-h7Zj) and a [complete GWAS example](https://oreil.ly/Q-LJD).
  prefs: []
  type: TYPE_NORMAL
- en: Wrap-Up and Next Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you learned how to use Jupyter in Terra to interact with your
    data. You began by learning the basic mechanics of using notebooks on the cloud,
    setting up your computing environment, opening an example notebook, and running
    code cells. With those foundations in place, you worked through three types of
    interactive analysis: visualizing genomic data in an embedded IGV browser, running
    and troubleshooting GATK commands, and plotting variant context annotation data
    in R.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This was by no means an exhaustive catalog of what you can do in this environment;
    if anything, we barely scratched the surface of what is possible. However, you
    now have enough grounding in the technology and tooling to start adapting your
    own analyses to work within the Terra framework. In [Chapter 13](ch13.xhtml#assembling_your_own_workspace_in_terra),
    we show you how to assemble your own workspaces from component elements: data,
    tools, and code from various origins.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch12.xhtml#idm45625613561112-marker)) From this point on, we don’t show
    the output of the cells. You can check your outputs against the copy of the notebook
    included in the Terra workspace. We also provide an html version of the pre-run
    notebook in the book’s [Github repository](https://oreil.ly/genomics-repo).
  prefs: []
  type: TYPE_NORMAL
