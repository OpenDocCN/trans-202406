["```\n# We can set the cluster's default policy with Helm...\n$ helm install linkerd-control-plane -n linkerd \\\n     ... \\\n     --set proxy.defaultInboundPolicy=all-authenticated \\\n     ...\n\n# ...or with the Linkerd CLI.\n$ linkerd install \\\n        ...\n        --set proxy.defaultInboundPolicy=all-authenticated \\\n        ... \\\n    | kubectl install -\n```", "```\n$ kubectl annotate namespace *`your-namespace`* \\\n        config.linkerd.io/default-inbound-policy=all-authenticated\n```", "```\napiVersion: policy.linkerd.io/v1beta1\nkind: Server\nmetadata:\n  name: foo\n  namespace: foo-ns\nspec:\n  podSelector:\n    matchLabels:\n      app: foo\n  port: http\n  proxyProtocol: HTTP/1\n```", "```\napiVersion: policy.linkerd.io/v1alpha1\nkind: MeshTLSAuthentication\nmetadata:\n  name: foo\n  namespace: foo-ns\nspec:\n  identities:\n    - \"foo.foo-ns.serviceaccount.identity.linkerd.cluster.local\"\n```", "```\n# Use helm upgrade to set the global inbound policy to all-authenticated.\n$ helm upgrade linkerd-control-plane -n linkerd \\\n  --set proxy.defaultInboundPolicy=all-authenticated \\\n  --version  1.12.4 \\\n  --reuse-values \\\n  linkerd/linkerd-control-plane\n\n# Now we can install the emojivoto app in our cluster to validate that it\n# can operate normally while meshed.\n$ curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/emojivoto.yml \\\n  | linkerd inject - | kubectl apply -f -\n\n# Once your Pods are up and running, test the emojivoto application to see\n# if it's still working.\n$ kubectl -n emojivoto port-forward svc/web-svc 8080:80\n\n# Now browse to localhost:8080 and look at the emojivoto app. You should\n# see the normal voting page.\n```", "```\n# Start by using kubectl to annotate the namespace. We're going to set it\n# to deny all traffic that hasn't been explicitly authorized.\n$ kubectl annotate namespace emojivoto config.linkerd.io/default-inbound-policy=deny\n\n# With that done, the policy changes won't have any impact on the Pods that\n# are already running. You will need to perform a rollout restart for the\n# new default policy to take effect.\n$ kubectl rollout restart deploy -n emojivoto\n\n# Once your Pods are up and running, test the emojivoto application to see\n# if it's still working.\n$ kubectl -n emojivoto port-forward svc/web-svc 8080:80\n\n# Now browse to localhost:8080 and look at the emojivoto app. You should now\n# see the page load, but all the emojis are gone. That is because the web\n# frontend can no longer talk to either of its backends, voting or emoji.\n```", "```\n# To start applying policies to the emojivoto workloads, we need to create\n# Server objects. A Server object selects a single named port on one or more\n# Pods.\n#\n# We'll start by setting up a Server that matches the Linkerd admin port,\n# used for metrics, for every Pod in our namespace.\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1beta1\nkind: Server\nmetadata:\n namespace: emojivoto\n name: linkerd-admin\nspec:\n podSelector:\n matchLabels: {}\n port: linkerd-admin\n proxyProtocol: HTTP/2\nEOF\n\n# This object, a Server called linkerd, will, due to our matchLabels selector,\n# match every Pod in our namespace. On each Pod it will bind to a port named\n# linkerd-admin and allow us to apply policy to it.\n#\n# Next, we will create a Server object for each part of our application,\n# starting with the web service (which serves the GUI).\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1beta1\nkind: Server\nmetadata:\n namespace: emojivoto\n name: web-http\n labels:\n app.kubernetes.io/part-of: emojivoto\n app.kubernetes.io/name: web\n app.kubernetes.io/version: v11\nspec:\n podSelector:\n matchLabels:\n app: web-svc\n port: http\n proxyProtocol: HTTP/1\nEOF\n\n```", "```\n# The Server web-http matches the HTTP port for Pods that are part of the\n# web service by selecting any Pods with the app=web-svc label. It also has\n# the added benefit of allowing us to skip protocol detection on this port\n# by specifying the protocol as HTTP/1.\n#\n# Now we'll create the Servers for emojivoto's backing services,\n# voting and emoji.\n$ kubectl apply -f - <<EOF\n---\napiVersion: policy.linkerd.io/v1beta1\nkind: Server\nmetadata:\n namespace: emojivoto\n name: emoji-grpc\n labels:\n app.kubernetes.io/part-of: emojivoto\n app.kubernetes.io/name: emoji\n app.kubernetes.io/version: v11\n app: emoji-svc\n emojivoto/api: internal-grpc\nspec:\n podSelector:\n matchLabels:\n app: emoji-svc\n port: grpc\n proxyProtocol: gRPC\n---\napiVersion: policy.linkerd.io/v1beta1\nkind: Server\nmetadata:\n namespace: emojivoto\n name: voting-grpc\n labels:\n app: voting-svc\n emojivoto/api: internal-grpc\nspec:\n podSelector:\n matchLabels:\n app: voting-svc\n port: grpc\n proxyProtocol: gRPC\nEOF\n\n```", "```\n# These are basically the same idea as the web Server, just with different\n# label selectors. Also, since emojivoto uses gRPC for these workloads, we\n# set the protocol to gRPC.\n#\n# With that, all of our Servers have been created, and we are ready to begin\n# to allow communication within our namespace. We'll next define a single\n# MeshTLSAuthentication resource that matches all service accounts within\n# the emojivoto namespace.\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1alpha1\nkind: MeshTLSAuthentication\nmetadata:\n name: emojivoto-accounts\n namespace: emojivoto\nspec:\n identities:\n - \"*.emojivoto.serviceaccount.identity.linkerd.cluster.local\"\nEOF\n\n# Then, we will bind that MeshTLSAuthentication to our Servers. We could do it\n# individually on a port-by-port basis, but in this case it's simpler to bind\n# to every policy object in the namespace.\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1alpha1\nkind: AuthorizationPolicy\nmetadata:\n name: emojivoto-only\n namespace: emojivoto\n labels:\n app.kubernetes.io/part-of: emojivoto\n project: emojivoto\nspec:\n targetRef:\n kind: Namespace\n name: emojivoto\n requiredAuthenticationRefs:\n - name: emojivoto-accounts\n kind: MeshTLSAuthentication\n group: policy.linkerd.io\nEOF\n\n# With that, we should see that the emojivoto workloads are able to communicate\n# with each other once again. You can check this by using a port forward to\n# look at the emojivoto app's GUI: start this forwarder, then open\n# http://localhost:8080/ in your browser.\n$ kubectl -n emojivoto port-forward svc/web-svc 8080:80\n```", "```\n# Let's install the Linkerd Viz extension. We'll continue our theme of\n# installing things with Helm.\n$ helm install linkerd-viz linkerd/linkerd-viz \\\n  -n linkerd-viz \\\n  --create-namespace \\\n  --version 30.8.4\n\n# This command will install the linkerd 2.13.4 version of Linkerd's Viz\n# extension.\n#\n# Once that's done, wait for Viz to be ready.\n$ linkerd check\n\n# We now want to restart our emojivoto workloads so that they start\n# collecting Tap data. This is critical for observability.\n$ kubectl rollout restart deploy -n emojivoto\n\n# With that complete, we can now move on to validating that the Linkerd\n# Viz extension is unable to talk to our workloads.\n$ linkerd viz stat deploy -n emojivoto\n\n# You should see all your deployments with no statistics associated with\n# them. That's because Linkerd's Prometheus instance is located in the\n# linkerd-viz namespace, and it hasn't been given permission to talk to\n# anything in the emojivoto namespace.\n```", "```\n# Let's fix that now. First, we define a MeshTLSAuthentication resource\n# that matches the identities used by Tap and Prometheus, which are the\n# parts of Linkerd Viz that collect data.\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1alpha1\nkind: MeshTLSAuthentication\nmetadata:\n name: linkerd-viz\n namespace: emojivoto\nspec:\n identities:\n - \"tap.linkerd-viz.serviceaccount.identity.linkerd.cluster.local\"\n - \"prometheus.linkerd-viz.serviceaccount.identity.linkerd.cluster.local\"\nEOF\n\n# Next, we permit that MeshTLSAuthentication to talk to Pods in the\n# emojivoto namespace, using an AuthorizationPolicy as before.\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1alpha1\nkind: AuthorizationPolicy\nmetadata:\n name: allow-viz\n namespace: emojivoto\nspec:\n targetRef:\n kind: Namespace\n name: emojivoto\n requiredAuthenticationRefs:\n - name: linkerd-viz\n kind: MeshTLSAuthentication\n group: policy.linkerd.io\nEOF\n\n# At this point, Tap and Prometheus should be happily collecting data.\n# Give them a minute or so to get something substantive, then you should\n# be able to see good results from a second \"linkerd viz stat\" command.\n$ linkerd viz stat deploy -n emojivoto\n```", "```\n$ linkerd viz edges deploy -n emojivoto\n```", "```\n$ linkerd viz dashboard\n```", "```\n# Start by grabbing the name of the first vote-bot Pod (which should\n# be the only vote-bot Pod).\n#\n# This kubectl command uses -l app=vote-bot to pick all Pods with the\n# \"app: vote-bot\" label, then uses JSONPath to pick the metadata.name\n# of the first Pod in the list.\n$ VOTEBOTPOD=$(kubectl get pods -n emojivoto -l app=vote-bot \\\n             -o jsonpath='{ .items[0].metadata.name }')\n\n# Now use the Pod name for vote-bot to get the Subject name.\n$ linkerd identity $VOTEBOTPOD -n emojivoto | grep Subject:\n\n# This will print out the Subject name for the vote-bot Pod, which is\n# the name of that Pod's identity. It will look like:\n#\n#   Subject: CN=default.emojivoto.serviceaccount.identity.linkerd.cluster.local\n#\n# We only want the part after CN=, so\n# default.emojivoto.serviceaccount.identity.linkerd.cluster.local.\n\n# Repeat for the web Pod, which we can find using the \"app: web-svc\" label.\n$ WEBPOD=$(kubectl get pods -n emojivoto -l app=web-svc \\\n         -o jsonpath='{ .items[0].metadata.name }')\n\n$ linkerd identity $WEBPOD -n emojivoto | grep Subject:\n\n# It should output a name like:\n#    Subject: CN=web.emojivoto.serviceaccount.identity.linkerd.cluster.local\n#\n# and again, we'll want the part after CN=:\n# web.emojivoto.serviceaccount.identity.linkerd.cluster.local\n```", "```\n# We'll start by creating two new MeshTLSAuthentication objects. The\n# first allows only the default identity (currently used by the vote-bot);\n# the second allows only the web identity.\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1alpha1\nkind: MeshTLSAuthentication\nmetadata:\n name: default\n namespace: emojivoto\nspec:\n identities:\n - 'default.emojivoto.serviceaccount.identity.linkerd.cluster.local'\n---\napiVersion: policy.linkerd.io/v1alpha1\nkind: MeshTLSAuthentication\nmetadata:\n name: web\n namespace: emojivoto\nspec:\n identities:\n - 'web.emojivoto.serviceaccount.identity.linkerd.cluster.local'\nEOF\n\n```", "```\n# Each object corresponds to either the vote-bot or web application. We\n# inserted the names we gathered in Example 8-8 to populate these\n# objects. It's a good practice to name them after the identity they\n# represent, rather than the workload -- in particular, the \"default\"\n# identity is probably used by more than just the vote-bot, so we don't\n# want to name that MeshTLSAuthentication \"vote-bot\" as that might give\n# the impression that we need only think about the vote-bot when using\n# that!\n\n# With that done, we can begin binding those authentications to our servers.\n# We'll start with allowing vote-bot (using the default identity) to talk\n# to web.\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1alpha1\nkind: AuthorizationPolicy\nmetadata:\n labels:\n app.kubernetes.io/part-of: emojivoto\n project: emojivoto\n name: allow-default-to-web\n namespace: emojivoto\nspec:\n requiredAuthenticationRefs:\n - group: policy.linkerd.io\n kind: MeshTLSAuthentication\n name: default\n targetRef:\n group: policy.linkerd.io\n kind: Server\n name: web-http\nEOF\n\n```", "```\n# This AuthorizationPolicy will allow any workload using the default\n# identity to talk to the web workload, using the \"web-http\" Server we\n# already created.\n\n# Now we will give the web application access to emoji and voting. In\n# order to accomplish this we will need to create two AuthorizationPolicy\n# objects, one for each Server.\n$ kubectl apply -f - <<EOF\napiVersion: policy.linkerd.io/v1alpha1\nkind: AuthorizationPolicy\nmetadata:\n labels:\n app.kubernetes.io/part-of: emojivoto\n project: emojivoto\n name: allow-web-to-voting\n namespace: emojivoto\nspec:\n requiredAuthenticationRefs:\n - group: policy.linkerd.io\n kind: MeshTLSAuthentication\n name: web\n targetRef:\n group: policy.linkerd.io\n kind: Server\n name: voting-grpc\n---\napiVersion: policy.linkerd.io/v1alpha1\nkind: AuthorizationPolicy\nmetadata:\n labels:\n app.kubernetes.io/part-of: emojivoto\n project: emojivoto\n name: allow-web-to-emoji\n namespace: emojivoto\nspec:\n requiredAuthenticationRefs:\n - group: policy.linkerd.io\n kind: MeshTLSAuthentication\n name: web\n targetRef:\n group: policy.linkerd.io\n kind: Server\n name: emoji-grpc\nEOF\n\n```", "```\n# Here, the allow-web-to-voting AuthorizationPolicy allows any workload\n# using the web identity to talk to the voting workload; allow-web-to-emoji\n# does the same for the emoji workload. Again, we're using Servers we created\n# earlier.\n\n# Now that we have our new policies in place, we can delete the policies that\n# allow all the apps in the emojivoto namespace to talk to one another.\n$ kubectl delete authorizationpolicies.policy.linkerd.io emojivoto-only -n emojivoto\n\n# Finally, we'll use a port forward to test the emojivoto app and be sure it\n# still operates normally.\n$ kubectl -n emojivoto port-forward svc/web-svc 8080:80\n```"]