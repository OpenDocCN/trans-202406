- en: Chapter 2\. Getting Started with OpenShift and Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we cover a variety of topics that present a foundational understanding
    of Kubernetes and OpenShift. We begin with an overview of the Kubernetes architecture
    and then describe several deployment options that will enable you to get both
    a basic Kubernetes environment and an OpenShift environment up and running. Next,
    we give an introduction to the command-line tools `kubectl` and `oc`, which are
    used for interacting with Kubernetes and OpenShift respectively. We then introduce
    a short review of the fundamental Kubernetes concepts of pods, deployments, and
    service accounts. In the second half of this chapter, we present several enhancement
    concepts that OpenShift provides over traditional Kubernetes. We then conclude
    this chapter with a discussion of more advanced topics that are often used when
    running Kubernetes or OpenShift in production.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The [Kubernetes architecture](https://oreil.ly/QEYUe) at a high level is relatively
    straightforward. It is composed of a *master node* and a set of *worker nodes*.
    The nodes can be either physical servers or VMs. Users of the Kubernetes environment
    interact with the master node using either a CLI (`kubectl`), an API, or a GUI.
    The master node is responsible for scheduling work across the worker nodes. In
    Kubernetes, the unit of work that is scheduled is called a *pod*, and a pod can
    hold one or more containers. The primary components that exist on the master node
    are the *kube-apiserver*, *kube-scheduler*, *kube-controller-manager,* and *etcd*:'
  prefs: []
  type: TYPE_NORMAL
- en: kube-apiserver
  prefs: []
  type: TYPE_NORMAL
- en: The kube-apiserver makes available the Kubernetes API that is used to operate
    the Kubernetes environment.
  prefs: []
  type: TYPE_NORMAL
- en: kube-scheduler
  prefs: []
  type: TYPE_NORMAL
- en: The kube-scheduler component is responsible for selecting the nodes on which
    pods should be created.
  prefs: []
  type: TYPE_NORMAL
- en: kube-controller-manager
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes provides several high-level abstractions for supporting replicas
    of pods, managing nodes, and so on. Each of these is implemented with a controller
    component, which we describe later in this chapter. The kube-controller-manager
    is responsible for managing and running controller components.
  prefs: []
  type: TYPE_NORMAL
- en: etcd
  prefs: []
  type: TYPE_NORMAL
- en: The etcd component is a distributed key-value store and is the primary datastore
    of the Kubernetes control plane. This component stores and replicates all the
    critical information states of your Kubernetes environment. The key feature of
    etcd is its ability to support a watch. A *watch* is a remote procedure call (RPC)
    mechanism that allows for callbacks to functions on key-value create, update,
    or delete operations. Kubernetes’s outstanding performance and scalability characteristics
    depend on etcd being a highly efficient data storage mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: 'The worker nodes are responsible for running the pods that are scheduled on
    them. The primary Kubernetes components that exist on worker nodes are the `kubelet`,
    *kube-proxy*, and *container runtime*:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubelet`'
  prefs: []
  type: TYPE_NORMAL
- en: The `kubelet` is responsible for making sure that the containers in each pod
    are created and stay up and running. The `kubelet` will restart containers upon
    recognizing that they have terminated unexpectedly or failed other health checks
    defined by the user.
  prefs: []
  type: TYPE_NORMAL
- en: kube-proxy
  prefs: []
  type: TYPE_NORMAL
- en: One of Kubernetes’s key strengths is the networking support it implements for
    containers. The kube-proxy component provides networking support in the form of
    connection forwarding, load balancing, and mapping of a single IP address to a
    pod. Kube-proxy is unique in that it gives a distributed load-balancing capability
    that is critical to the high availability architecture of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: container runtime
  prefs: []
  type: TYPE_NORMAL
- en: The container runtime component is responsible for running the containers that
    exist in each pod. Kubernetes supports several container runtime environment options,
    including Docker, `rkt`, CRI-O, and containerd.^([1](ch02.html#ch01fn14))
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2-1](#graphical_representation_of_the_kubernet) shows a graphical representation
    of the Kubernetes architecture encompassing a master node and two worker nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. Graphical representation of the Kubernetes architecture
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As shown in [Figure 2-1](#graphical_representation_of_the_kubernet), users interact
    with the Kubernetes API server using either a GUI or by `kubectl` CLI. Both of
    these use the Kubernetes API to interact with the kube-apiserver on the Kubernetes
    master node. The Kubernetes master node’s kube-scheduler component schedules pods
    to run on different worker nodes. Each pod contains one or more containers and
    is assigned its own IP address.In many real-world applications, Kubernetes deploys
    multiple replicas (running copies) of the same pod to improve scalability and
    ensure high availability. Pods A1 and A2 are pod replicas that differ only in
    the IP address they are allocated. Similarly, Pods B1 and B2 are also replica
    copies of the same pod. The containers located in the same pod are permitted to
    communicate with one another using standard interprocess communication (IPC) mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we present several approaches to getting OpenShift and
    Kubernetes environments up and running.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment Options for Kubernetes and OpenShift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes and OpenShift have both reached incredible levels of popularity.
    As a result, several options are available for deploying either basic Kubernetes
    or Red Hat’s OpenShift Kubernetes distribution. In the following sections, we
    summarize the different types of deployment options that are currently available,
    including Red Hat’s CodeReady Containers, IBM Cloud, and several OpenShift deployment
    options.
  prefs: []
  type: TYPE_NORMAL
- en: Red Hat’s CodeReady Containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Red Hat provides a minimal preconfigured OpenShift version 4 cluster called
    [CodeReady Containers](https://oreil.ly/1rI07) that you can run on your laptop
    or desktop computer. The CodeReady OpenShift environment is intended to be used
    for development and testing purposes. CodeReady Containers provide a fully functional
    cloud development environment on your local machine and contain all the tooling
    necessary for you to develop container-based applications.
  prefs: []
  type: TYPE_NORMAL
- en: IBM Cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[IBM Cloud](https://cloud.ibm.com) gives users their choice of either a traditional
    Kubernetes cluster or a Red Hat OpenShift cluster. IBM Cloud’s Kubernetes offering
    is a cloud service providing Kubernetes as a Service that brings all of the standard
    Kubernetes features, including intelligent scheduling, self-healing, horizontal
    scaling, service discovery and load balancing, automated rollout and rollbacks,
    and secret and configuration management. In addition, IBM Cloud’s Kubernetes Service
    includes automated operations for cluster deployment, updates, and scaling, expert
    security, optimized configuration, and seamless integration with the IBM Cloud
    Infrastructure platform. It produces highly available multizone clusters across
    6 regions and 35 datacenters. IBM Cloud offers both a free Kubernetes cluster
    with over 40 free services and pay-as-you-go options.'
  prefs: []
  type: TYPE_NORMAL
- en: IBM Cloud also provides users with highly available, fully managed [OpenShift
    clusters](https://oreil.ly/qsOdD). IBM’s OpenShift offering implements unique
    security and productivity capabilities designed to eliminate substantial time
    spent on updating, scaling, and provisioning. Additionally, IBM Cloud’s OpenShift
    delivers the resiliency to handle unexpected surges and protects against attacks
    that can lead to financial and productivity losses. In addition to pay-as-you-go
    and subscription options, IBM Cloud offers a free preconfigured OpenShift version
    4.3 environment that is available for four hours at no charge.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift Deployment Options
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Several deployment options for OpenShift are defined at the [Getting Started
    with OpenShift](https://www.openshift.com/try) website. The options described
    include installing OpenShift version 4 on your laptop, deploying it in your datacenter
    or public cloud, or having Red Hat manage OpenShift for you. In addition, Red
    Hat offers hands-on OpenShift tutorials and playground OpenShift environments
    for unstructured learning and experimentation. [Figure 2-2](#openshift_deployment_options_available_a)
    shows the myriad of OpenShift deployment options available.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. OpenShift deployment options available at [Get Started with OpenShift](https://www.openshift.com/try)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the next section, we describe the command-line tools used for interacting
    with these platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes and OpenShift Command-Line Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in [Chapter 1](ch01.html#kubernetes_and_openshift_overview), OpenShift
    provides a 100% conformant Kubernetes platform and supplements it with a variety
    of tools and capabilities focused on improving the productivity of developers
    and IT operations. In this section, we begin with an introduction to `kubectl`
    and `oc`, which are the standard command-line tools used for interacting with
    Kubernetes and OpenShift respectively. We present several concepts that OpenShift
    uses to represent the enhancements it serves over traditional Kubernetes. OpenShift
    concepts that we describe include authentication, projects, applications, security
    contexts, and image streams.
  prefs: []
  type: TYPE_NORMAL
- en: 'After covering some core concepts in Kubernetes, the next sections give several
    examples in the form of YAML files. For all Kubernetes environments, the samples
    included can be run using the standard Kubernetes command-line tool `kubectl`.
    Many Kubernetes environments, including the ones mentioned earlier in this chapter,
    describe how `kubectl` can be installed. Once you have your Kubernetes environment
    up and running and `kubectl` installed, all of the YAML file samples in the following
    sections can be run by first saving the YAML to a file (e.g., *kubesample1.yaml*)
    and then by running the following `kubectl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'As previously discussed, the OpenShift distribution of Kubernetes adds several
    new enhancements and capabilities beyond those used by traditional Kubernetes.
    OpenShift provides access to these features by extending the capabilities of `kubectl`.
    To make it explicit that the OpenShift version of `kubectl` has extended functionality,
    OpenShift renamed its version of `kubectl` to be a new command-line tool called
    `oc.` Thus, the following is equivalent to the previous `kubectl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In addition to one-for-one matching support for all `kubectl` commands, `oc`
    adds commands for administrative functions like managing roles and role bindings
    for users and groups.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on the breadth of commands available from the OpenShift
    `oc` CLI, please see the [OpenShift command line documentation](https://oreil.ly/7NQW3).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes has several concepts that are specific to its model for managing
    containers. In this section we briefly review key Kubernetes concepts, including
    pods, deployments, and service accounts.
  prefs: []
  type: TYPE_NORMAL
- en: What’s a Pod?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Because Kubernetes supports the management and orchestration of containers,
    you would assume that the smallest deployable unit supported by Kubernetes would
    be a container. However, the designers of Kubernetes learned from experience^([2](ch02.html#ch01fn15))
    that it was more optimal to have the smallest deployable unit be something that
    could hold multiple containers. In Kubernetes, this smallest deployable unit is
    called a *pod*. A pod can hold one or more application containers. The application
    containers that are in the same pod have the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: They share an IP address and port space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They share the same hostname
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They can communicate with one another using native IPC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In contrast, application containers that run in separate pods are guaranteed
    to have different IP addresses and different hostnames. Essentially, containers
    in different pods should be viewed as running on different servers even if they
    ended up on the same node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes contributes a robust set of features that make pods easy to use:'
  prefs: []
  type: TYPE_NORMAL
- en: Easy-to-use pod management API
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes provides the `kubectl` CLI, which supports a variety of operations
    on pods, including creating, viewing, deleting, updating, interacting, and scaling
    pods.
  prefs: []
  type: TYPE_NORMAL
- en: File copy support
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes makes it very easy to copy files back and forth between your local
    host machine and your pods running in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Connectivity from your local machine to your pod
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, you will want to have network connectivity from your local host
    machine to your pods running in the cluster. Kubernetes supports port forwarding
    whereby a network port on your local host machine is connected via a secure tunnel
    to a port on your pod that is running in the cluster. This is an excellent feature
    to assist in debugging applications and services without having to expose them
    publicly.
  prefs: []
  type: TYPE_NORMAL
- en: Volume storage support
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes pods support the attachment of remote network storage volumes to
    enable the containers in pods to access persistent storage that remains long after
    the lifetime of the pods and the containers that initially utilized the storage.
  prefs: []
  type: TYPE_NORMAL
- en: Probe-based health-check support
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes provides health checks in the form of probes to ensure that the main
    processes of your containers are still running. In addition, Kubernetes administers
    liveness checks that ensure the containers are actually functioning and capable
    of doing real work. With this health-check support, Kubernetes can recognize if
    your containers have crashed or become nonfunctional and restart them on your
    behalf.
  prefs: []
  type: TYPE_NORMAL
- en: How Do I Describe What’s in My Pod?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Pods and all other resources managed by Kubernetes are described using a YAML
    file. The following is a simple YAML file that describes a rudimentary pod resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This YAML file contains the following fields and sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '`apiVersion`'
  prefs: []
  type: TYPE_NORMAL
- en: This field is used to declare which version of the Kubernetes API schema is
    being used. Kubernetes continues to experience rapid growth in features and functionality.
    It manages the complexity that results from its growth in capabilities by supporting
    multiple versions of its API. By setting the `apiVersion` field, you can control
    the API version that your resource uses.
  prefs: []
  type: TYPE_NORMAL
- en: '`kind`'
  prefs: []
  type: TYPE_NORMAL
- en: Use the `kind` field to identify the type of resource the YAML file is describing.
    In the preceding example, the YAML file declares that it is describing a `Pod`
    object.
  prefs: []
  type: TYPE_NORMAL
- en: '`metadata`'
  prefs: []
  type: TYPE_NORMAL
- en: The `metadata` section contains information about the resource that the YAML
    is defining. In the preceding example, the `metadata` contains a name field that
    declares the name of this pod. The `metadata` section can contain other types
    of identifying information, such as labels and annotations. We describe these
    in more detail in [“Deployments”](#deployments).
  prefs: []
  type: TYPE_NORMAL
- en: '`spec`'
  prefs: []
  type: TYPE_NORMAL
- en: The `spec` section provides a specification for what the desired state for this
    resource should be. As shown in the example, the desired state for this pod is
    to have a container with the name `nginx` that is built from the Docker image
    identified as `nginx:1.7.9`*.* The container shares the IP address of the pod
    it is contained in, and the `containerPort` field is used to allocate this container
    a network port (in this case, `80`) that it can use to send and receive network
    traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The `apply` command will either create a resource or update any existing matching
    resources. There is also a supported `create` command that will assume the resources
    described by the YAML document do not yet exist. You can typically use `apply`
    wherever you use `create`. In some cases, such as the special `generateName` attribute,
    only `create` is supported.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the previous example, save the file as *pod.yaml*. You can now run it
    by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this command, you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To confirm that your pod is actually running, use the `kubectl get pods` command
    to verify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this command, you should see output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'When the pod is running, you can also view the logs of the process running
    within the pod with the `logs` command (if there are multiple containers, select
    the specific container you want to view with the `-c` option):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'If you need to debug your running container, you can create an interactive
    shell that runs within the container by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This command instructs Kubernetes to run an interactive shell for the container
    that runs in the pod named `nginx`. Because this pod has only one container, Kubernetes
    knows which container you want to connect to even if you have not specified the
    container name. Accessing the container interactively to modify it at runtime
    is typically considered a bad practice. However, interactive shells can be useful
    as you are learning or debugging apps before deploying to production. After you
    run the preceding command, you can interact with the container’s runtime environment,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If your pod has multiple containers within it, you will need to include the
    container name as well in your `kubectl exec` command. To do this, use the `-c`
    option and include the container name in addition to the pod name. Here is an
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'To delete the pod that you just created, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following confirmation that the pod has been deleted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: When using Kubernetes, you can expect to have large numbers of pods running
    in a cluster. In the next section, we describe how labels and annotations are
    used to help you keep track of and identify your pods.
  prefs: []
  type: TYPE_NORMAL
- en: Deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Deployments* are a high-level Kubernetes abstraction that not only allow you
    to control the number of pod replicas that are instantiated, but also provide
    support for rolling out new versions of the pods. Deployments are configurable
    such that they can leverage extra resources for faster rollouts that have no downtime,
    or they can perform slower rollouts that do canary testing. The advantage of a
    slower rollout is that it can reduce the risk and validate new software by releasing
    the software to a small percentage of users, thus ensuring that the new version
    of the application is stable. Deployments rely on the `ReplicaSet` resource to
    manage pod replicas and then add pod version management support on top of this
    capability. Deployments also enable newly rolled-out versions of pods to be rolled
    back to previous versions if there is something wrong with the new versions of
    the pods. Furthermore, deployments support two options for upgrading pods, `Recreate`
    and `RollingUpdate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Recreate`'
  prefs: []
  type: TYPE_NORMAL
- en: The `Recreate` pod upgrade option is very straightforward. In this approach,
    the deployment resource modifies its associated `ReplicaSet` to point to the new
    version of the pod. It then proceeds to terminate all the pods. The `ReplicaSet`
    then notices that all the pods have been terminated and thus spawns new pods to
    ensure that the number of desired replicas are up and running. The `Recreate`
    approach will typically result in your pod application not being accessible for
    a period of time, and thus it is not recommended for applications that need to
    always be available.
  prefs: []
  type: TYPE_NORMAL
- en: '`RollingUpdate`'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes’s deployment resource also provides a `RollingUpdate` option. With
    the `RollingUpdate` option, your pods are replaced with the newer versions incrementally
    over time. This approach results in there being a mixture of both the old version
    and the new version of the pod running simultaneously and thus avoids having your
    pod application unavailable during this maintenance period. The readiness of each
    pod is measured and used to inform kube-proxy and ingress controllers which pod
    replicas are available to handle network requests to ensure that no requests are
    dropped during the update process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example YAML specification for a deployment that uses the
    `RollingUpdate` option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The previous deployment example encompasses many of the characteristics that
    we have seen in `ReplicaSet`s and pods. In its metadata it contains labels and
    annotations. For the deployment, an annotation with `deployment.kubernetes.io/​revi⁠sion`
    as the key and `1` as its value provides information that this is the first revision
    of the contents in this deployment. Similar to `ReplicaSet`s, the deployment declares
    the number of replicas it provides and uses a `matchLabels` field to declare what
    labels it uses to identify the pods it manages.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Label matching is a very common aspect of Kubernetes API. If you need to organize
    or categorize resources, add descriptive labels that serve as lightweight metadata.
    You can also query or find resources using the `-l` option in kubectl like `kubectl
    get` or `kubectl patch`.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to `ReplicaSet`s, the deployment has both a `spec` section for the deployment
    and a nested `spec` section inside a `template` that is used to describe the containers
    that comprise the pod replicas managed by this deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The fields that are new and specific to a deployment resource are the `strategy`
    field and its subfields of `type` and `RollingUpdate`. The `type` field is used
    to declare the deployment strategy being used and can currently be set to `Recreate`
    or `RollingUpdate`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the `RollingUpdate` option is selected, the subfields of `maxUnavailable`
    and `maxSurge` need to be set as well. The options are used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`maxSurge`'
  prefs: []
  type: TYPE_NORMAL
- en: The `maxSurge RollingUpdate` option enables extra resources to be allocated
    during a rollout. The value of this option can be set to a number or a percentage.
    As a simple example, assume a deployment is supporting three replicas and `maxSurge`
    is set to `2`. In this scenario, there will be a total of five replicas available
    during the `RollingUpdate`.
  prefs: []
  type: TYPE_NORMAL
- en: At the peak of the deployment, there will be three replicas with the old version
    of the pods running and two with the new version of the pods running. At this
    point, one of the old version pod replicas will need to be terminated, and then
    another replica of the new pod version can be created. At this stage, there would
    be a total of five replicas, three that have the new revision and two that have
    the old version of the pods. Finally, having reached a point of the correct number
    of pod replicas being available with the new version, the two pods with the old
    version can be terminated.
  prefs: []
  type: TYPE_NORMAL
- en: '`maxUnavailable`'
  prefs: []
  type: TYPE_NORMAL
- en: This `RollingUpdate` option is used to declare the number of the deployment
    replica pods that may be unavailable during the update. It can be set to either
    a number or a percentage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following YAML example shows a deployment that has been updated to initiate
    a rollout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Note that a new annotation label with a key of `kubernetes.op/change-cause`
    has been added with a value that denotes an update to the version of nginx running
    in the container. Also notice that the name of the image used by the container
    in the `spec` section has changed to `nginx:1.13.10`. This declaration is what
    actually drives the pod replicas managed by the deployment to now have a new version
    of the container images when the upgrade occurs.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate the capabilities of deployments, let’s run the two previous
    examples. Save the first deployment example as *deploymentset.yaml* and the second
    example as *deploymentset2.yaml*. You can now run the first deployment example
    by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this command, you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'To confirm that your pod replicas managed by the deployment are actually running,
    use the `kubectl get pods` command to verify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this command, you should see output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'With deployments, we have a new command called `kubectl get deployments` that
    provides status on the deployments as they update their images. Run this command
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this command, you should see output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now to make things interesting, let’s update the image in our deployment by
    applying the second deployment example that we saved in *deploymentset2.yaml*.
    Note that we could have just updated the original YAML that we saved in *deploymentset.yaml*
    instead of using two separate files. We begin the update by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this command, you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when we rerun the `kubectl get deployments` command, which provides status
    on the deployments as they update their images, we see a much more interesting
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in this output, the deployment currently has three pod replicas running.
    Three of the pod replicas are up to date, which means they are now running the
    updated nginx image. In addition, there are three pod replicas in total, and of
    these three replicas, two are available to handle requests. After some amount
    of time, when the rolling image update is complete, we reach the desired state
    of having three updated pod replicas available. We can confirm this by rerunning
    the `kubectl get deployments` command and viewing that the output now matches
    our desired state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'To delete the deployment that was just created, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the following confirmation that the deployment has been deleted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Deployments also include commands for pausing rollouts, resuming rollouts, and
    rolling back the update of an image. The commands are quite helpful if you have
    some concerns about the new image being rolled out that merits investigation or
    if you determine that the updated image being rolled out is problematic and needs
    to be rolled back to a previous version. See the [Kubernetes Deployment documentation](https://oreil.ly/BJ115)
    for more information on how to use these deployment capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we examine the extra steps that are needed to run the previous
    examples in a secure Kubernetes production-level environment such as OpenShift.
  prefs: []
  type: TYPE_NORMAL
- en: Running the Pod and Deployment Examples in Production on OpenShift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The pod and deployment examples presented in the previous sections are perfect
    for instructional purposes and for running in a local development environment.
    When running in production on a highly secure Kubernetes platform such as OpenShift,
    there are other factors that need to be addressed. First, the nginx container
    image we used in the previous examples is configured to run as a privileged root
    user. By default, secure production Kubernetes platforms such as OpenShift are
    configured to not allow a container image to run as root. This is because running
    a container image as root increases the risk that malicious code could find a
    way to cause harm to the host system.^([3](ch02.html#ch01fn16)) To address this
    issue, we will replace the nginx container used earlier in this chapter with a
    version of the image that does not need to run as a privileged root user. The
    nginx container image from Bitnami runs as a nonroot container and can be used
    in a production OpenShift environment. The following example is an updated version
    of our previously created *pod.yaml*, which uses the Bitnami nonroot nginx container
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Remember that all resources are either *cluster scoped,* meaning that only one
    resource of that kind can exist within the cluster, or *namespace scoped,* meaning
    that the resources are isolated from other similar resources on the cluster. Within
    OpenShift, you may also see the term *project,* which predated the concept that
    Red Hat worked with the community to generalize as namespace. *Project* and *namespace*
    are synonymous, and OpenShift will respond to either `get projects` or `get namespaces`.
    You can think of namespaces as like folders within a filesystem that you use to
    assign to a group of users who are collaborating on a collection of files. We
    will talk more about namespaces or projects in [“OpenShift Enhancements”](#openshift_enhancements).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another issue with our earlier pod and deployment examples that needs to be
    addressed is that when they were created, we did not isolate our resources from
    others by creating a Kubernetes namespace that was specific to our resources.
    Instead, the earlier examples placed our resources in the Kubernetes default namespace.
    To encourage proper isolation of applications, secure production Kubernetes platforms
    such as OpenShift will enforce that your Kubernetes resources are not created
    in the default namespace but instead are created in a user-defined namespace that
    provides the required isolation. To create a properly configured namespace, OpenShift
    provides the `oc new-project` command. OpenShift’s project capability is described
    more thoroughly in [“OpenShift Enhancements”](#openshift_enhancements). For now,
    however, we will use the `oc new-project` command to create a new project called
    `book`, which will provide the required isolation to be able to run our pod example.
    We create our new project by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then use the `oc apply -f` command, pass in our updated *pod.yaml,*
    and use the `-n` option to declare that we want our resources created in the `book`
    namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have used a nonroot container image and are no longer using the
    default namespace, our pod example will be permitted by OpenShift to run in production.
    We can confirm this is the case by using the `oc get pods` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can clean up and remove the pod example by using the `oc delete pod` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The same techniques we used for the pod example can be applied to the deployment
    examples as well. Simply update the nginx image that is used in *deploymentset.yaml,*
    and make sure to use the `book` namespace when doing the `oc apply` command. In
    the next section, we’ll introduce another fundamental Kubernetes concept called
    *service accounts,* which are used to provide authentication for key parts of
    the Kubernetes platform.
  prefs: []
  type: TYPE_NORMAL
- en: Service Accounts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you interact with your cluster, you often represent yourself as a user
    identity. In the world of Kubernetes, we build intelligence into the system to
    help it interact with its world. Many times, pods may use the Kubernetes API to
    interact with other parts of the system or to spawn jobs. When we deploy a pod,
    it may interact with volume storage, interact with the host filesystem, interact
    with the host networking, or be sensitive to which operating system user it is
    given access to use for filesystem access. In most cases, you want to restrict
    the default permissions for a given pod from doing anything more than the absolute
    basics. Basically, the less surface area that a pod is given access to in the
    cluster, the host operating system, the networking layer, and your storage layer,
    the fewer attack vectors that can be exploited.
  prefs: []
  type: TYPE_NORMAL
- en: For a pod to interact with the system, it is assigned a service account. Think
    of this as a functional identity. The service accounts are subjects that can authenticate
    with kube-apiserver via tokens and are authorized for certain behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: In some Kubernetes systems, the service account projected into the pod can have
    identity outside of Kubernetes. A powerful use case is when using the open source
    [Istio](https://istio.io) service mesh project with Kubernetes. In this scenario,
    the Istio identity is projected via the service account, and this allows one pod
    to authenticate with another when making service requests. Some cloud providers
    and other security tools also allow for projection of a service account identity
    into the pod, and this allows for authentication with these external platforms.
  prefs: []
  type: TYPE_NORMAL
- en: In OpenShift, service accounts are also used to associate a grouping of security
    privileges with each pod. The object that OpenShift uses for creating specialized
    groupings of security privileges is called a *security context constraint*. In
    the next section, we provide a more detailed discussion of security context constraints,
    as well as several other important enhancements that OpenShift delivers to supplement
    basic Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift Enhancements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenShift introduces several new concepts that it uses to simplify development
    and operations. Approaches that are specific to OpenShift include authentication,
    projects, applications, security contexts, and image streams.
  prefs: []
  type: TYPE_NORMAL
- en: Authentication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Security is paramount to the OpenShift Kubernetes platform. As a result, all
    users must authenticate with the cluster to be able to access it. OpenShift supports
    a variety of common authentication methods, including basic authentication with
    username and password, OAuth access tokens, and X.509 client certificates.^([4](ch02.html#ch01fn17))
    OpenShift provides the `oc login` command for performing authentication, which
    is run by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In a basic authentication use case, when this command is run, the user will
    be asked to enter the OpenShift Container Platform server URL and whether or not
    secure connections are needed, and then the user will be asked to input their
    username and password. In addition, OpenShift’s configurable OAuth server allows
    for users to integrate OpenShift identity with external providers, such as LDAP
    servers.
  prefs: []
  type: TYPE_NORMAL
- en: Projects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Standard Kubernetes provides the concept of a [*namespace*](https://oreil.ly/IAiIw),
    which allows you to define isolation for your Kubernetes resources. Namespaces
    enable cluster resources to be divided among a large number of users, and the
    isolation that results from the scoping that they administer keeps users from
    accidentally using someone else’s resource due to a naming collision. Namespaces
    are incredibly useful, and OpenShift has adapted namespaces for grouping applications.
    OpenShift accomplishes this by taking a Kubernetes namespace and adding a special
    standard list of annotations to the namespace. OpenShift refers to this specific
    type of namespace as a *project.* OpenShift uses projects as its mechanism for
    grouping applications. Projects support the notion of access permissions. This
    enables you to add one or more users who have access to the project, and role-based
    access control is used to set the permissions and capabilities that various users
    have when accessing a project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Projects are created using the `oc new-project` command and by providing a
    project name, description, and display name as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'OpenShift makes it easy to switch between projects by using the `oc project`
    command. Here we switch to a different project called `secondproject`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To view the list of projects that you are authorized to access, you can use
    the `oc get projects` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: For more information on the use of projects, please see the [OpenShift project
    documentation](https://oreil.ly/xXs4d).
  prefs: []
  type: TYPE_NORMAL
- en: Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using a basic Kubernetes environment, one of the more tedious steps that
    needs to be performed by a cloud native application developer is creating their
    own container images. Typically, this involves finding the proper base image and
    creating a `Dockerfile` with all the necessary commands for taking a base image
    and adding in the developer’s code to create an assembled image that can be deployed
    by Kubernetes. OpenShift introduced the [application construct](https://oreil.ly/3RpbY)
    to greatly simplify the process of creating, deploying, and running container
    images in Kubernetes environments.
  prefs: []
  type: TYPE_NORMAL
- en: Applications are created using the `oc new-app` command. This command supports
    a variety of options that enable container images to be built many ways. For example,
    with the `new-app` command, application images can be built from local or remote
    Git repositories, or the application image can be pulled from a Docker Hub or
    private image registry. In addition, the `new-app` command supports the creation
    of application images by inspecting the root directory of the repository to determine
    the proper way to create the application image. For example, the OpenShift `new-app`
    command will look for a `JenkinsFile` in the root directory of your repository,
    and if it finds this file, it will use it to create the application image. Furthermore,
    if the `new-app` command does not find a `JenkinsFile`, it will attempt to detect
    the programming language that your application is built in by looking at the files
    in your repository. If it is able to determine the programming language that was
    used, the `new-app` command will locate an acceptable base image for the programming
    language you are using and will use this to build your application image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example illustrates using the the `oc new-app` command to create
    a new application image from an OpenShift example ruby hello world application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This command will create the application as part of whichever OpenShift project
    was most recently selected to be the current context for the user. For more information
    on the application image creation options supported by the `new-app` command,
    see the [OpenShift application creation documentation](https://oreil.ly/3RpbY).
  prefs: []
  type: TYPE_NORMAL
- en: Security Context Constraints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Security is always at the forefront in OpenShift. But with added security can
    come extra complexity and aggravation. If enhanced security is used and a container
    is not given the proper security options, it will fail. If security is relaxed
    to avoid issues, then vulnerabilities can result. In an effort to enable users
    to leverage enhanced security with less aggravation, OpenShift includes a security
    construct called *security context constraints*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The security context constraints identify a set of security privileges that
    a pod’s container is guaranteed to execute with. Thus, before the pod’s container
    begins execution, it knows what security privileges it will get. The following
    is a list of the common security privilege options that are provided by security
    context constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: Allow pods to run privileged containers
  prefs: []
  type: TYPE_NORMAL
- en: Security context constraints can declare if a pod is permitted to run privileged
    containers or if it can run only nonprivileged containers.
  prefs: []
  type: TYPE_NORMAL
- en: Require Security-Enhanced Linux (SELinux)
  prefs: []
  type: TYPE_NORMAL
- en: '[SELinux](https://oreil.ly/SlHNy) is a security architecture for Linux that
    defines access controls for applications, processes, and files on a system. SELinux
    presents extra protections beyond what standard Linux uses. Security context constraints
    provide the `MustRunAs` attribute value for declaring if SELinux must be run by
    a pod’s container and a `RunAsAny` attribute value for declaring if the pod’s
    container can run either standard Linux or SELinux.'
  prefs: []
  type: TYPE_NORMAL
- en: Run the pod’s container as a specific user or as nonroot
  prefs: []
  type: TYPE_NORMAL
- en: Containers running as root have a bigger vulnerability footprint than containers
    running as a nonroot. Security context constraints provide a `MustRunAsNonRoot`
    attribute value to denote that a Pod’s container is not permitted to run as root.
    Additionally, the security context constraints use a `RunAsAny` attribute value
    that permits a pod’s container to run as either a root or nonroot user. Finally,
    the security context constraint administers a `MustRunAsRange` attribute value
    that allows a pod’s container to run if the user ID is within a specific range
    of user IDs.
  prefs: []
  type: TYPE_NORMAL
- en: Allow the pod’s container access to File System Group block storage
  prefs: []
  type: TYPE_NORMAL
- en: Security context constraints can be used to limit the block storage that a pod’s
    container has access to. Block storage portions are identified through the use
    of a File System Group identifier. Security context constraints provide a `RunAsAny`
    attribute value that permits a pod’s container to access any File System Group
    of block storage, as well as a `MustRunAs` attribute value, which is used to denote
    that the pod’s block storage must be in the range of File System Group IDs listed
    in the security context constraint.
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenShift includes several built-in security context constraint profiles that
    can be reused. To view the list of projects that you are authorized to access,
    you can use the `oc get scc` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown, OpenShift contributes security context constraint profiles for common
    scenarios, such as privileged, restricted, or running as nonroot. To see all the
    individual capability settings for the security constraint profile, use the `oc
    describe scc` command and pass in the name of the profile that you want more details
    on. For example, if you wanted more details on how powerful the privileged constraint
    profile is, you would invoke the `oc describe scc` command as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this command will list a large number of constraint attributes associated
    with this profile. Here are a few of the more interesting ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'For comparison purposes, we can run the same command for the restricted profile.
    As shown in the following output, the constraint attribute values are much more
    restrictive than those in the privileged profile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The key point here is that security context constraint profiles are able to
    group and encapsulate large groups of capability attributes and ensure that all
    the attributes are met before a pod is permitted to execute. This reduces the
    chance of improperly setting the capability attributes and reduces the chance
    of an unexpected pod failure due to an incorrect security setting.
  prefs: []
  type: TYPE_NORMAL
- en: Security context constraint profiles are associated with pods by using the Kubernetes
    service account object. For more information on the use of security context constraints,
    see the [OpenShift security context constraints documentation](https://oreil.ly/W41Sq).
  prefs: []
  type: TYPE_NORMAL
- en: Image Streams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the key steps in deploying a cloud native application is retrieving the
    correct container application image from a repository. When running in production,
    there are several possible pitfalls with this retrieval process. First, container
    images are retrieved by a tag identifier, but it is possible that container images
    can be overwritten, and thus the image that is referenced by the tag can change.
    If this change goes unnoticed, it could result in introducing unexpected errors
    into the cloud native application that is deployed. Second, when running in production,
    the image retrieval process also needs to be supplemented with support for automating
    builds and deployments, and many image repositories are limited in their ability
    to support this automation. Third, in some cases a container image needs to have
    multiple tags associated with it because the container image is used for different
    purposes in different environments. Unfortunately, many image repositories do
    not support the ability to associate multiple tags with a container application
    image.
  prefs: []
  type: TYPE_NORMAL
- en: To address all of these issues, OpenShift introduced the concept of *image streams*.^([5](ch02.html#ch01fn18))
    Image streams are intended to provide a more stable pointer for tagged images.
    The image stream maintains an SHA-256 secure hash function to the image it points
    to in order to ensure that the image is not mistakenly changed. Image streams
    also support multiple tags for images to better support using them in multiple
    environments. In addition, image streams include triggers that enable builds and
    deployments to be started automatically when the image stream is updated. Furthermore,
    image streams can not only reference container images from external repositories,
    but can also be scheduled to periodically reimport the external container image
    to ensure that they always have the most recently updated copy of the container
    image they are referencing in the external repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating and updating image streams is relatively straightforward. The `oc
    import-image` command is used to create an image stream. In the following example,
    the `oc import-image` command is used to create an initial image stream called
    `nginx` with an initial image stream tag for the imported image that has the value
    `1.12`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: As shown in this example, the initial container image that is being imported
    into the `nginx` image stream is the image that is located at `centos/nginx-112-centos7`.
    The `confirm` option states that the image stream should be created if it doesn’t
    already exist.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the image stream is created, we can examine it using the `oc describe`
    command. In the following example, the `is` value is the short name for an input
    stream resource. The specific input stream that we want described is the one with
    the name `nginx`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from this command looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We can add an extra tag for this image by using the `oc tag` command. We add
    an `nginx:latest` tag to the existing `nginx:1.12` tag by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we can tag an image from an external repository and schedule this image
    to be periodically reimported by calling the `oc tag` command. As shown in the
    following example, we reference the image from the external repository, associate
    it with an image stream tag, and then add the scheduled option to denote that
    the tag should be periodically updated:^([6](ch02.html#ch01fn19))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: For more information on the use of image streams, please see the documentation
    on [managing image streams](https://oreil.ly/YMfdZ).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes and OpenShift Advanced Topics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Several advanced concepts are frequently used when running Kubernetes or OpenShift
    in production. In this section, we discuss these advanced topics, including webhooks,
    admission controllers, role-based access control, and operators.
  prefs: []
  type: TYPE_NORMAL
- en: Webhooks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *webhook* is an HTTP callback.^([7](ch02.html#ch01fn20)) Essentially, a webhook
    enables information to be pushed to an external entity when an interesting event
    is occurring. Typically, an HTTP Post operation is used to push the event information,
    and the event information is most commonly represented as a JSON payload. In Kubernetes,
    webhooks are used for a variety of security-related operations. For example, Kubernetes
    can use a webhook to query an external service to determine if a user has the
    correct privileges to perform a specific operation.
  prefs: []
  type: TYPE_NORMAL
- en: Webhooks are also used by OpenShift as [a mechanism for triggering builds](https://oreil.ly/bmfyW).
    With webhooks, you can configure your GitHub repository to send an alert whenever
    there is a change in the repository. This alert can be used to kick off a new
    build and, if the build succeeds, perform a deployment as well.
  prefs: []
  type: TYPE_NORMAL
- en: Webhooks are also used heavily by Kubernetes admission controllers, which are
    described in the next section. For more information on the use of webhooks in
    Kubernetes, see [Webhook Mode in the Kubernetes documentation](https://oreil.ly/Aiw7t).
  prefs: []
  type: TYPE_NORMAL
- en: Admission Controllers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key to keeping your Kubernetes platform secure is to protect it from requests
    that can cause harm. *Admission controllers* are one of the mechanisms that Kubernetes
    uses to protect the platform from harmful requests. In some cases, an admission
    controller will prevent a request from creating the Kubernetes object at all.
    In other cases, the admission controller will allow the request to be processed,
    but it will modify the request to make it safer. As an example, if a request comes
    in to start a pod and the request does not specify whether the pod should be started
    in privileged or nonprivileged mode, the admission controller could change the
    request such that in this situation the pod is requested to be started in nonprivileged
    mode.
  prefs: []
  type: TYPE_NORMAL
- en: A number of admission controllers are embedded in the kube-controller-manager,
    and many are enabled in Kubernetes by default to keep the Kubernetes platform
    secure. In some cases, the admin needs enforcement beyond the scope of the included
    admission controllers. Kubernetes allows the admin to add additional admission
    controllers via registration of webhooks to process requests on Kubernetes objects.
    We will go into more detail regarding admission controllers in [Chapter 3](ch03.html#advanced_resource_management).
  prefs: []
  type: TYPE_NORMAL
- en: Role-Based Access Control
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Authorization in Kubernetes is integrated into the platform. Kubernetes authorization
    uses a role-based access control (RBAC) model and provides a fully featured authorization
    platform that allows operators to define various roles via the Kubernetes objects
    `ClusterRole` and `Role` and to bind them to users and groups using `Cluster​Ro⁠leBinding`
    and `RoleBinding`. Think of RBAC as a way of setting permissions on a file system,
    but in the case of Kubernetes, it’s setting permissions on the Kubernetes object
    model. We’ll cover the details of how to use RBAC and how best to build a multitenancy
    model around it in [Chapter 4](ch04.html#single_cluster_availability).
  prefs: []
  type: TYPE_NORMAL
- en: Operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes has built-in abstractions like deployments that are extremely well-suited
    stateless applications. In addition, Kubernetes has a very elegant design based
    on control loops that enables it to support a declarative programming model and
    allows the platform to execute robustly at large scale even when failures are
    common.
  prefs: []
  type: TYPE_NORMAL
- en: To support complex stateful applications, Kubernetes needed an extensibility
    model that would enable users to add custom resources and perform life-cycle management
    for those resources. Additionally, it would be ideal if the extensibility model
    could also support the control loop architecture that is used extensively inside
    the Kubernetes platform. Kubernetes includes the [operator pattern](https://oreil.ly/OujZb),
    which provides an extensibility model for custom resources that meet all of these
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Operators support the creation of custom resources. What this means is that
    you can define a new resource type in Kubernetes by creating a custom resource
    definition, and this new resource can be stored in the Kubernetes etcd database
    just like any standard Kubernetes resource. Additionally, you can create a custom
    controller for your resource that performs the same type of control loop behavior
    that the standard Kubernetes controllers perform. The custom controller can then
    monitor the actual state of your stateful application, compare it to the desired
    state, and then take actions to attempt to achieve the desired state for the application.
    For example, let’s say you create an operator for a special type of database,
    which is a stateful application. The operator and its controller can make sure
    that the actual number of replicas of the database that are running matches the
    desired number of copies. Furthermore, since the operator has a custom controller,
    any custom life-cycle management code that is needed for starting up new copies
    of the database or updating existing copies of the database can be added to the
    controller.
  prefs: []
  type: TYPE_NORMAL
- en: The operator pattern is well-designed, and a key advantage is that it is seamless.
    The custom resources associated with an operator are managed using the `kubectl`
    command-line tool and look just like a standard Kubernetes resource from a management
    perspective. To ease the creation of operators, an operator software development
    kit exists to generate the custom resource definitions and a large portion of
    the controller code required to run the operator’s control loop. As a result of
    the clean architectural design of the operator framework and also due to extensive
    tooling available, creating new operators as the means of adding stateful applications
    continues to grow in popularity. There is now an [Operator Hub](https://operatorhub.io)
    that hosts a large number of existing and reusable operators for managing a variety
    of applications for the Kubernetes platform. We will go into more detail about
    operators and their consumption within Kubernetes in [Chapter 7](ch07.html#multicluster_policy_configuration).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we covered a wide range of topics to give you a broad foundation
    and solid introduction to Kubernetes and OpenShift. We touched upon several topics
    that are critical for running in production, and we will explore many of these
    topics in greater detail in subsequent chapters of this book. In addition, this
    chapter helps to illustrate how the Kubernetes and OpenShift ecosystems have matured
    into platforms that provide a lot of enterprise-level functionality and flexibility.
    In [Chapter 3](ch03.html#advanced_resource_management), we cover a crucial production
    topic: advanced management of Kubernetes resources while running in production.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch02.html#ch01fn14-marker)) Lantao Liu and Mike Brown, “Kubernetes Containerd
    Integration Goes GA,” Kubernetes Blog (May 24, 2018), [*https://oreil.ly/SlHmh*](https://oreil.ly/SlHmh).
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch02.html#ch01fn15-marker)) Brendan Burns et al., “Borg, Omega, and Kubernetes:
    Lessons Learned from Three Container-Management Systems over a Decade,” *ACM Queue*
    14 (2016): 70–93, [*http://bit.ly/2vIrL4S*](http://bit.ly/2vIrL4S).'
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch02.html#ch01fn16-marker)) Tomas Pizarro Moreno, “Running Non-root Containers
    on OpenShift,” Bitnami Engineering (October 27, 2017), [*https://oreil.ly/pxSGf*](https://oreil.ly/pxSGf).
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch02.html#ch01fn17-marker)) The [OpenShift authentication documentation](https://oreil.ly/23ON5)
    provides more detail on supported authentication methods.
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch02.html#ch01fn18-marker)) The [documentation on image streams](https://oreil.ly/T7vSF)
    provides more information.
  prefs: []
  type: TYPE_NORMAL
- en: ^([6](ch02.html#ch01fn19-marker)) Maciej Szulik, “How to Simplify Container
    Image Management in Kubernetes with OpenShift Image Streams,” Red Hat OpenShift
    Blog (March 23, 2017), [*https://oreil.ly/JEV4u*](https://oreil.ly/JEV4u).
  prefs: []
  type: TYPE_NORMAL
- en: ^([7](ch02.html#ch01fn20-marker)) Wikipedia provides an [overview of webhooks](https://oreil.ly/PLH43).
  prefs: []
  type: TYPE_NORMAL
