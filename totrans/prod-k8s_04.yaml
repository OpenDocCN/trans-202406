- en: Chapter 3\. Container Runtime
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章 容器运行时
- en: Kubernetes is a container orchestrator. Yet, Kubernetes itself does not know
    how to create, start, and stop containers. Instead, it delegates these operations
    to a pluggable component called the *container runtime*. The container runtime
    is a piece of software that creates and manages containers on a cluster node.
    In Linux, the container runtime uses a set of kernel primitives such as control
    groups (cgroups) and namespaces to spawn a process from a container image. In
    essence, Kubernetes, and more specifically, the kubelet, works together with the
    container runtime to run containers.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个容器编排器。然而，Kubernetes 本身并不知道如何创建、启动和停止容器。相反，它将这些操作委托给一个可插拔的组件，称为*容器运行时*。容器运行时是一种软件，用于在集群节点上创建和管理容器。在
    Linux 中，容器运行时使用一组内核原语，如控制组（cgroups）和命名空间，从容器镜像生成一个进程。实质上，Kubernetes，尤其是 kubelet，与容器运行时共同工作来运行容器。
- en: As we discussed in [Chapter 1](ch01.html#chapter1), organizations building platforms
    on top of Kubernetes are faced with multiple choices. Which container runtime
    to use is one such choice. Choice is great as it lets you customize the platform
    to your needs, enabling innovation and advanced use cases that might otherwise
    not be possible. However, given the fundamental nature of a container runtime,
    why does Kubernetes not provide an implementation? Why does it choose to provide
    a pluggable interface and offload the responsibility to another component?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第一章](ch01.html#chapter1)中讨论的那样，构建基于 Kubernetes 平台的组织面临多种选择。选择使用哪种容器运行时就是其中之一。选择是很好的，因为它让您可以根据自己的需求定制平台，从而促进创新和可能原本无法实现的高级用例。然而，考虑到容器运行时的基本性质，为什么
    Kubernetes 不提供一个实现？为什么选择提供一个可插拔的接口，并将责任转移给另一个组件？
- en: To answer these questions, we will look back and briefly review the history
    of containers and how we got here. We will first discuss the advent of containers
    and how they changed the software development landscape. After all, Kubernetes
    would probably not exist without them. We will then discuss the Open Container
    Initiative (OCI), which arose from the need for standardization around container
    runtimes, images, and other tooling. We will review the OCI specifications and
    how they pertain to Kubernetes. After OCI, we will discuss the Kubernetes-specific
    Container Runtime Interface (CRI). The CRI is the bridge between the kubelet and
    the container runtime. It specifies the interface that the container runtime must
    implement to be compatible with Kubernetes. Finally, we will discuss how to choose
    a runtime for your platform and review the available options in the Kubernetes
    ecosystem.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答这些问题，我们将回顾一下容器的历史以及我们如何到达现在的地步。我们将首先讨论容器的出现以及它们如何改变软件开发的格局。毕竟，没有它们，可能 Kubernetes
    并不存在。然后，我们将讨论开放容器倡议（OCI），这是因为需要在容器运行时、镜像和其他工具周围进行标准化而产生的。我们将回顾 OCI 的规范及其与 Kubernetes
    的关系。在 OCI 之后，我们将讨论专用于 Kubernetes 的容器运行时接口（CRI）。CRI 是 kubelet 与容器运行时之间的桥梁。它规定了容器运行时必须实现的接口，以便与
    Kubernetes 兼容。最后，我们将讨论如何为您的平台选择运行时，并回顾 Kubernetes 生态系统中的可用选项。
- en: The Advent of Containers
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器的出现
- en: Control groups (cgroups) and namespaces are the primary ingredients necessary
    to implement containers. Cgroups impose limits on the amount of resources a process
    can use (e.g., CPU, memory, etc.), while namespaces control what a process can
    see (e.g., mounts, processes, network interfaces, etc.). Both these primitives
    have been in the Linux kernel since 2008\. Even earlier in the case of namespaces.
    So why did containers, as we know them today, become popular years later?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 控制组（cgroups）和命名空间是实现容器所需的主要组成部分。Cgroups 对进程可以使用的资源量（如 CPU、内存等）施加限制，而命名空间控制进程可以看到的内容（如挂载点、进程、网络接口等）。这两个基本原语自
    2008 年以来就已经存在于 Linux 内核中。在命名空间的情况下，更早些时候已经存在。那么，为什么像今天这样的容器才会在多年后变得流行起来呢？
- en: To answer this question, we first need to consider the environment surrounding
    the software and IT industry at the time. An initial factor to think about is
    the complexity of applications. Application developers built applications using
    service-oriented architectures and even started to embrace microservices. These
    architectures brought various benefits to organizations, such as maintainability,
    scalability, and productivity. However, they also resulted in an explosion in
    the number of components that made up an application. Meaningful applications
    could easily involve a dozen services, potentially written in multiple languages.
    As you can imagine, developing and shipping these applications was (and continues
    to be) complex. Another factor to remember is that software quickly became a business
    differentiator. The faster you could ship new features, the more competitive your
    offerings. Having the ability to deploy software in a reliable manner was key
    to a business. Finally, the emergence of the public cloud as a hosting environment
    is another important factor. Developers and operations teams had to ensure that
    applications behaved the same across all environments, from a developer’s laptop
    to a production server running in someone else’s datacenter.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答这个问题，我们首先需要考虑软件和IT行业当时周围的环境。首先要考虑的一个因素是应用程序的复杂性。应用程序开发人员使用面向服务的架构构建应用程序，甚至开始接受微服务。这些架构为组织带来了各种好处，如可维护性、可扩展性和生产力。然而，它们也导致应用程序组成部分数量的激增。有意义的应用程序可能涉及数十个服务，可能使用多种语言编写。可以想象，开发和发布这些应用程序是（并且继续是）复杂的。另一个要记住的因素是软件迅速成为企业的差异化因素。您能越快推出新功能，您的竞争力就越强。以可靠方式部署软件对企业至关重要。最后，公共云作为托管环境的出现是另一个重要因素。开发人员和运维团队必须确保应用程序在所有环境中表现一致，从开发者的笔记本电脑到运行在他人数据中心的生产服务器。
- en: Keeping these challenges in mind, we can see how the environment was ripe for
    innovation. Enter Docker. Docker made containers accessible to the masses. They
    built an abstraction that enabled developers to build and run containers with
    an easy-to-use CLI. Instead of developers having to know the low-level kernel
    constructs needed to leverage container technology, all they had to do was type
    `docker run` in their terminal.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这些挑战，我们可以看到环境已经成熟，可以进行创新。进入 Docker。Docker 使容器变得普及。他们构建了一个抽象层，使开发人员可以通过易于使用的
    CLI 构建和运行容器。开发人员无需了解利用容器技术所需的低级内核构造，他们只需在终端中输入 `docker run`。
- en: While not the answer to all our problems, containers improved many stages of
    the software development life cycle. First, containers and container images allowed
    developers to codify the application’s environment. Developers no longer had to
    wrestle with missing or mismatched application dependencies. Second, containers
    impacted testing by providing reproducible environments for testing applications.
    Lastly, containers made it easier to deploy software to production. As long as
    there was a Docker Engine in the production environment, the application could
    be deployed with minimum friction. Overall, containers helped organizations to
    ship software from zero to production in a more repeatable and efficient manner.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然并非解决我们所有问题的答案，但容器改善了软件开发生命周期的许多阶段。首先，容器和容器镜像允许开发人员编码应用程序的环境。开发人员不再需要处理缺失或不匹配的应用程序依赖关系。其次，容器通过为测试应用程序提供可复制的环境影响了测试。最后，容器使得将软件部署到生产环境变得更加容易。只要在生产环境中有一个
    Docker 引擎，应用程序就可以以最小的摩擦部署。总体而言，容器帮助组织以更加可重复和高效的方式从零到生产部署软件。
- en: 'The advent of containers also gave birth to an abundant ecosystem full of different
    tools, container runtimes, container image registries, and more. This ecosystem
    was well received but introduced a new challenge: How do we make sure that all
    these container solutions are compatible with each other? After all, the encapsulation
    and portability guarantees are one of the main benefits of containers. To solve
    this challenge and to improve the adoption of containers, the industry came together
    and collaborated on an open source specification under the umbrella of the Linux
    Foundation: the Open Container Initiative.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的出现也催生了一个充满不同工具、容器运行时、容器镜像注册表等多样化生态系统。这个生态系统受到了良好的接受，但也带来了一个新挑战：如何确保所有这些容器解决方案彼此兼容？毕竟，封装性和可移植性保证是容器的主要好处之一。为了解决这一挑战并促进容器的采用，业界汇聚在
    Linux 基金会的旗帜下共同合作，推出了一个开放源代码规范：Open Container Initiative。
- en: The Open Container Initiative
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开放容器倡议
- en: As containers continued to gain popularity across the industry, it became clear
    that standards and specifications were required to ensure the success of the container
    movement. The Open Container Initiative (OCI) is an open source project established
    in 2015 to collaborate on specifications around containers. Notable founders of
    this initiative included Docker, which donated runc to the OCI, and CoreOS, which
    pushed the needle on container runtimes with rkt.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着容器在行业中持续流行，清楚地需要制定标准和规范以确保容器运动的成功。Open Container Initiative（OCI）是一个于2015年成立的开源项目，旨在协作制定关于容器的规范。这一倡议的重要创始人包括
    Docker（将 runc 捐赠给 OCI）和 CoreOS（通过 rkt 推动容器运行时的发展）。
- en: 'The OCI includes three specifications: the OCI runtime specification, the OCI
    image specification, and the OCI distribution specification. These specs enable
    development and innovation around containers and container platforms such as Kubernetes.
    Furthermore, the OCI aims to allow end users to use containers in a portable and
    interoperable manner, enabling them to move between products and solutions more
    easily when necessary.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: OCI 包括三个规范：OCI 运行时规范、OCI 镜像规范和 OCI 分发规范。这些规范促进了围绕容器和容器平台（如 Kubernetes）的开发和创新。此外，OCI
    的目标是允许最终用户以便捷和互操作的方式使用容器，使他们在必要时更轻松地在产品和解决方案之间进行迁移。
- en: In the following sections, we will explore the runtime and image specifications.
    We will not dig into the distribution specification, as it is primarily concerned
    with container image registries.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探讨运行时和镜像规范。我们不会深入讨论分发规范，因为它主要涉及容器镜像注册表。
- en: OCI Runtime Specification
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OCI Runtime 规范
- en: 'The OCI runtime specification determines how to instantiate and run containers
    in an OCI-compatible fashion. First, the specification describes the schema of
    a container’s configuration. The schema includes information such as the container’s
    root filesystem, the command to run, the environment variables, the user and group
    to use, resource limits, and more. The following snippet is a trimmed example
    of a container configuration file obtained from the OCI runtime specification:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: OCI 运行时规范决定如何以兼容 OCI 的方式实例化和运行容器。首先，规范描述了容器配置的模式。模式包括容器的根文件系统、运行命令、环境变量、要使用的用户和用户组、资源限制等信息。以下摘录是从
    OCI 运行时规范获取的容器配置文件的简化示例：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The runtime specification also determines the operations that a container runtime
    must support. These operations include create, start, kill, delete, and state
    (which provides information about the container’s state). In addition to the operations,
    the runtime spec describes the life cycle of a container and how it progresses
    through different stages. The life cycle stages are (1) `creating`, which is active
    when the container runtime is creating the container; (2) `created`, which is
    when the runtime has completed the `create` operation; (3) `running`, which is
    when the container process has started and is running; and (4) `stopped`, which
    is when the container process has finished.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时规范还确定了容器运行时必须支持的操作。这些操作包括创建、启动、终止、删除和状态（提供容器状态信息）。除了操作外，运行时规范描述了容器的生命周期及其在不同阶段的进展。生命周期阶段包括（1）`creating`，即容器运行时正在创建容器时的活动状态；（2）`created`，即运行时已完成`create`操作时的状态；（3）`running`，即容器进程已启动并正在运行时的状态；以及（4）`stopped`，即容器进程已完成运行时的状态。
- en: The OCI project also houses *runc*, a low-level container runtime that implements
    the OCI runtime specification. Other higher-level container runtimes such as Docker,
    containerd, and CRI-O use runc to spawn containers according to the OCI spec,
    as shown in [Figure 3-1](#docker_engine_containerd_and_other_runtimes_use_runc_to_spawn).
    Leveraging runc enables container runtimes to focus on higher-level features such
    as pulling images, configuring networking, handling storage, and so on while conforming
    to the OCI runtime spec.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: OCI 项目还包括 *runc*，这是一个实现 OCI 运行时规范的低级容器运行时。其他高级容器运行时如 Docker、containerd 和 CRI-O
    使用 runc 根据 OCI 规范生成容器，如 [图 3-1](#docker_engine_containerd_and_other_runtimes_use_runc_to_spawn)
    所示。利用 runc，容器运行时可以专注于诸如拉取镜像、配置网络、处理存储等高级功能，同时遵循 OCI 运行时规范。
- en: '![prku 0301](assets/prku_0301.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![prku 0301](assets/prku_0301.png)'
- en: Figure 3-1\. Docker Engine, containerd, and other runtimes use runc to spawn
    containers according to the OCI spec.
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. Docker Engine、containerd 和其他运行时根据 OCI 规范使用 runc 生成容器。
- en: OCI Image Specification
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OCI 镜像规范
- en: 'The OCI image specification focuses on the container image. The specification
    defines a manifest, an optional image index, a set of filesystem layers, and a
    configuration. The image manifest describes the image. It includes a pointer to
    the image’s configuration, a list of image layers, and an optional map of annotations.
    The following is an example manifest obtained from the OCI image specification:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: OCI 镜像规范关注容器镜像。规范定义了一个清单、一个可选的镜像索引、一组文件系统层和一个配置。镜像清单描述了镜像。它包括指向镜像配置、镜像层列表和可选的注释映射的指针。以下是从
    OCI 镜像规范获取的示例清单：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The *image index* is a top-level manifest that enables the creation of multiplatform
    container images. The image index contains pointers to each of the platform-specific
    manifests. The following is an example index obtained from the specification.
    Notice how the index points to two different manifests, one for `ppc64le/linux`
    and another for `amd64/linux`:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*镜像索引* 是一个顶级清单，用于创建多平台容器镜像。镜像索引包含指向每个平台特定清单的指针。以下是从规范中获取的示例索引。请注意索引如何指向两个不同的清单，一个是
    `ppc64le/linux`，另一个是 `amd64/linux`：'
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Each OCI image manifest references a container image configuration. The configuration
    includes the image’s entry point, command, working directory, environment variables,
    and more. The container runtime uses this configuration when instantiating a container
    from the image. The following snippet shows the configuration of a container image,
    with some fields removed for brevity:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 OCI 镜像清单都引用一个容器镜像配置。配置包括镜像的入口点、命令、工作目录、环境变量等。容器运行时在实例化镜像时使用此配置。以下摘录显示了容器镜像配置的部分内容，为了简洁起见省略了一些字段：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The OCI image spec also describes how to create and manage container image layers.
    Layers are essentially TAR archives that include files and directories. The specification
    defines different media types for layers, including uncompressed layers, gzipped
    layers, and nondistributable layers. Each layer is uniquely identified by a digest,
    usually a SHA256 sum of the contents of the layer. As we discussed before, the
    container image manifest references one or more layers. The references use the
    SHA256 digest to point to a specific layer. The final container image filesystem
    is the result of applying each of the layers, as listed in the manifest.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: OCI 镜像规范还描述了如何创建和管理容器镜像层。层实质上是包含文件和目录的 TAR 存档。规范定义了不同的层媒体类型，包括未压缩层、gzip 压缩层和不可分发层。每个层都通过摘要唯一标识，通常是层内容的
    SHA256 摘要。如前所述，容器镜像清单引用一个或多个层。这些引用使用 SHA256 摘要指向特定的层。最终容器镜像文件系统是应用每个层后的结果，如清单中所列。
- en: The OCI image specification is crucial because it ensures that container images
    are portable across different tools and container-based platforms. The spec enables
    the development of different image build tools, such as kaniko and Buildah for
    userspace container builds, Jib for Java-based containers, and Cloud Native Buildpacks
    for streamlined and automated builds. (We will explore some of these tools in
    [Chapter 15](ch15.html#chapter15)). Overall, this specification ensures that Kubernetes
    can run container images regardless of the tooling used to build them.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: OCI 镜像规范至关重要，因为它确保容器镜像在不同工具和基于容器的平台上是可移植的。该规范支持开发不同的镜像构建工具，如 kaniko 和 Buildah
    用于用户空间容器构建，Jib 用于基于 Java 的容器，以及 Cloud Native Buildpacks 用于简化和自动化构建。我们将在 [第 15
    章](ch15.html#chapter15) 中探讨其中一些工具。总体而言，该规范确保 Kubernetes 可以运行不管使用何种构建工具生成的容器镜像。
- en: The Container Runtime Interface
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器运行时接口
- en: As we’ve discussed in prior chapters, Kubernetes offers many extension points
    that allow you to build a bespoke application platform. One of the most critical
    extension points is the Container Runtime Interface (CRI). The CRI was introduced
    in Kubernetes v1.5 as an effort to enable the growing ecosystem of container runtimes,
    which included rkt by CoreOS and hypervisor-based runtimes such as Intel’s Clear
    Containers, which later became Kata Containers.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在之前的章节中讨论过的，Kubernetes 提供了许多扩展点，允许您构建一个定制的应用平台。其中一个最关键的扩展点是容器运行时接口 (CRI)。CRI
    在 Kubernetes v1.5 中引入，旨在支持包括 CoreOS 的 rkt 和基于虚拟化的运行时，如 Intel 的 Clear Containers（后来成为
    Kata Containers）在内的不断增长的容器运行时生态系统。
- en: Prior to CRI, adding support for a new container runtime required a new release
    of Kubernetes and intimate knowledge of the Kubernetes code base. Once the CRI
    was established, container runtime developers could simply adhere to the interface
    to ensure compatibility of the runtime with Kubernetes.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CRI 出现之前，为新的容器运行时添加支持需要发布新版本的 Kubernetes 并对 Kubernetes 代码库有深入了解。一旦建立了 CRI，容器运行时开发人员只需遵循接口即可确保与
    Kubernetes 的兼容性。
- en: Overall, the goal of the CRI was to abstract the implementation details of the
    container runtime away from Kubernetes, more specifically the kubelet. This is
    a classic example of the dependency inversion principle. The kubelet evolved from
    having container runtime–specific code and if-statements scattered throughout
    to a leaner implementation that relied on the interface. Thus, the CRI reduced
    the complexity of the kubelet implementation while also making it more extensible
    and testable. These are all important qualities of well-designed software.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，CRI 的目标是将容器运行时的实现细节与 Kubernetes 分离，更具体地说是 kubelet。这是依赖反转原则的一个典型示例。kubelet
    从具有分散在各处的容器运行时特定代码和 if 语句的实现逐步演变为依赖接口的更精简实现。因此，CRI 减少了 kubelet 实现的复杂性，同时使其更具可扩展性和可测试性。这些都是设计良好的软件的重要特性。
- en: 'The CRI is implemented using gRPC and Protocol Buffers. The interface defines
    two services: the *RuntimeService* and the *ImageService*. The kubelet leverages
    these services to interact with the container runtime. The RuntimeService is responsible
    for all the Pod-related operations, including creating Pods, starting and stopping
    containers, deleting Pods, and so on. The ImageService is concerned with container
    image operations, including listing, pulling, and removing container images from
    the node.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: CRI 使用 gRPC 和 Protocol Buffers 实现。该接口定义了两个服务：*RuntimeService* 和 *ImageService*。kubelet
    利用这些服务与容器运行时交互。RuntimeService 负责所有与 Pod 相关的操作，包括创建 Pod、启动和停止容器、删除 Pod 等。ImageService
    则涉及容器镜像操作，包括在节点上列出、拉取和删除容器镜像等。
- en: 'While we could detail the APIs of both the RuntimeService and ImageService
    in this chapter, it is more useful to understand the flow of perhaps the most
    important operation in Kubernetes: starting a Pod on a node. Thus, let’s explore
    the interaction between the kubelet and the container runtime through CRI in the
    following section.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以在本章节详细描述 RuntimeService 和 ImageService 的 API，但更有用的是理解 Kubernetes 中可能最重要操作的流程：在节点上启动一个
    Pod。因此，让我们在接下来的部分探索 kubelet 与容器运行时通过 CRI 的交互。
- en: Starting a Pod
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动一个 Pod
- en: Note
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注：
- en: The following descriptions are based on Kubernetes v1.18.2 and containerd v1.3.4\.
    These components use the v1alpha2 version of the CRI.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下描述基于 Kubernetes v1.18.2 和 containerd v1.3.4。这些组件使用 CRI 的 v1alpha2 版本。
- en: Once the Pod is scheduled onto a node, the kubelet works together with the container
    runtime to start the Pod. As mentioned, the kubelet interacts with the container
    runtime through the CRI. In this case, we will explore the interaction between
    the kubelet and the containerd CRI plug-in.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 Pod 被调度到一个节点上，kubelet 会与容器运行时一起工作，启动 Pod。正如前文所述，kubelet 通过 CRI 与容器运行时进行交互。在这种情况下，我们将探讨
    kubelet 与 containerd CRI 插件之间的交互。
- en: 'The containerd CRI plug-in starts a gRPC server that listens on a Unix socket.
    By default, this socket is located at */run/containerd/containerd.sock*. The kubelet
    is configured to interact with containerd through this socket with the `container-runtime`
    and `container-runtime-endpoint` command-line flags:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: containerd CRI 插件启动一个 gRPC 服务器，监听一个 Unix 套接字。默认情况下，此套接字位于 */run/containerd/containerd.sock*。kubelet
    配置为通过此套接字与 containerd 进行交互，使用 `container-runtime` 和 `container-runtime-endpoint`
    命令行标志：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To start the Pod, the kubelet first creates a Pod sandbox using the `RunPodSandbox`
    method of the RuntimeService. Because a Pod is composed of one or more containers,
    the sandbox must be created first to establish the Linux network namespace (among
    other things) for all containers to share. When calling this method, the kubelet
    sends metadata and configuration to containerd, including the Pod’s name, unique
    ID, Kubernetes Namespace, DNS configuration, and more. Once the container runtime
    creates the sandbox, the runtime responds with a Pod sandbox ID that the kubelet
    uses to create containers in the sandbox.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动 Pod，kubelet 首先使用 RuntimeService 的 `RunPodSandbox` 方法创建一个 Pod 沙箱。因为一个 Pod
    由一个或多个容器组成，所以必须首先创建沙箱，以建立 Linux 网络命名空间（等等）供所有容器共享。调用此方法时，kubelet 向 containerd
    发送元数据和配置，包括 Pod 的名称、唯一 ID、Kubernetes 命名空间、DNS 配置等。一旦容器运行时创建了沙箱，运行时会返回一个 Pod 沙箱
    ID，kubelet 使用该 ID 在沙箱中创建容器。
- en: Once the sandbox is available, the kubelet checks whether the container image
    is present on the node using the `ImageStatus` method of the ImageService. The
    `ImageStatus` method returns information about the image. When the image is not
    present, the method returns null and the kubelet proceeds to pull the image. The
    kubelet uses the `PullImage` method of the ImageService to pull the image when
    necessary. Once the runtime pulls the image, it responds with the image SHA256
    digest, which the kubelet then uses to create the container.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦沙箱可用，kubelet 通过 ImageService 的 `ImageStatus` 方法检查节点上是否存在容器镜像。`ImageStatus`
    方法返回关于镜像的信息。当镜像不存在时，该方法返回 null，并且 kubelet 继续拉取镜像。当需要时，kubelet 使用 ImageService
    的 `PullImage` 方法拉取镜像。一旦运行时拉取了镜像，它会返回镜像的 SHA256 摘要，kubelet 然后使用该摘要创建容器。
- en: 'After creating the sandbox and pulling the image, the kubelet creates the containers
    in the sandbox using the `CreateContainer` method of the RuntimeService. The kubelet
    provides the sandbox ID and the container configuration to the container runtime.
    The container configuration includes all the information you might expect, including
    the container image digest, command and arguments, environment variables, volume
    mounts, etc. During the creation process, the container runtime generates a container
    ID that it then passes back to the kubelet. This ID is the one you see in the
    Pod’s status field under container statuses:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建沙箱和拉取镜像后，kubelet 使用 RuntimeService 的 `CreateContainer` 方法在沙箱中创建容器。kubelet
    向容器运行时提供沙箱 ID 和容器配置。容器配置包括您可能期望的所有信息，包括容器镜像摘要、命令和参数、环境变量、卷挂载等。在创建过程中，容器运行时生成一个容器
    ID，并将其传递回 kubelet。这个 ID 是您在 Pod 的状态字段下容器状态中看到的那个：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The kubelet then proceeds to start the container using the `StartContainer`
    method of the RuntimeService. When calling this method, it uses the container
    ID it received from the container runtime.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，kubelet 继续使用 RuntimeService 的 `StartContainer` 方法启动容器。在调用此方法时，它使用容器运行时传递的容器
    ID。
- en: And that’s it! In this section, we’ve learned how the kubelet interacts with
    the container runtime using the CRI. We specifically looked at the gRPC methods
    invoked when starting a Pod, which include those on the ImageService and the RuntimeService.
    Both of these CRI services provide additional methods that the kubelet uses to
    complete other tasks. Besides the Pod and container management (i.e., CRUD) methods,
    the CRI also defines methods to execute a command inside a container (`Exec` and
    `ExecSync`), attach to a container (`Attach`), forward a specific container port
    (`PortForward`), and others.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！在本节中，我们学习了 kubelet 如何使用 CRI 与容器运行时交互。我们特别关注了启动 Pod 时调用的 gRPC 方法，其中包括 ImageService
    和 RuntimeService 上的方法。这两个 CRI 服务除了 Pod 和容器管理（即 CRUD）方法外，还提供了 kubelet 用于完成其他任务的其他方法。除了执行容器内命令（`Exec`
    和 `ExecSync`）、附加到容器（`Attach`）、转发特定容器端口（`PortForward`）等任务外，CRI 还定义了其他方法。
- en: Choosing a Runtime
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择运行时
- en: Given the availability of the CRI, platform teams get the flexibility of choice
    when it comes to container runtimes. The reality, however, is that over the last
    couple of years the container runtime has become an implementation detail. If
    you are using a Kubernetes distribution or leveraging a managed Kubernetes service,
    the container runtime will most likely be chosen for you. This is the case even
    for community projects such as Cluster API, which provide prebaked node images
    that include a container runtime.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到 CRI 的可用性，平台团队在选择容器运行时时有了灵活性。然而，事实上，在过去几年中，容器运行时已经成为一个实施细节。如果您使用 Kubernetes
    发行版或利用托管的 Kubernetes 服务，则容器运行时很可能会为您选择。即使是像 Cluster API 这样的社区项目也是如此，它提供预先构建的包含容器运行时的节点镜像。
- en: With that said, if you do have the option to choose a runtime or have a use
    case for a specialized runtime (e.g., VM-based runtimes), you should be equipped
    with information to make that decision. In this section, we will discuss considerations
    you should make when choosing a container runtime.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，如果您确实有选择运行时的选项或者有专用运行时的用例（例如基于 VM 的运行时），您应该具备足够的信息来做出决策。在本节中，我们将讨论选择容器运行时时应考虑的因素。
- en: The first question we like to ask when helping organizations in the field is
    which container runtime they have experience with. In most cases, organizations
    that have a long history with containers are using Docker and are familiar with
    Docker’s toolchain and user experience. While Kubernetes supports Docker, we discourage
    its use as it has an extended set of capabilities that Kubernetes does not need,
    such as building images, creating container networks, and so on. In other words,
    the fully fledged Docker daemon is too heavy or bloated for the purposes of Kubernetes.
    The good news is that Docker uses containerd under the covers, one of the most
    prevalent container runtimes in the community. The downside is that platform operators
    have to learn the containerd CLI.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在帮助现场组织时，我们通常会问的第一个问题是他们对容器运行时有何经验。在大多数情况下，有长期容器历史的组织使用 Docker，并熟悉 Docker 的工具链和用户体验。虽然
    Kubernetes 支持 Docker，但我们不鼓励使用它，因为它具有一些 Kubernetes 不需要的扩展功能，例如构建镜像、创建容器网络等。换句话说，完整的
    Docker 守护程序对于 Kubernetes 来说过于臃肿。好消息是 Docker 在幕后使用 containerd，这是社区中最普遍的容器运行时之一。不利之处是平台操作员必须学习
    containerd 的 CLI。
- en: Another consideration to make is the availability of support. Depending on where
    you are getting Kubernetes from, you might get support for the container runtime.
    Kubernetes distributions such as VMware’s Tanzu Kubernetes Grid, RedHat’s OpenShift,
    and others usually ship a specific container runtime. You should stick to that
    choice unless you have an extremely compelling reason not to. In that case, ensure
    that you understand the support implications of using a different container runtime.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个要考虑的因素是支持的可用性。根据您获取 Kubernetes 的位置，您可能会获得容器运行时的支持。诸如 VMware 的 Tanzu Kubernetes
    Grid、RedHat 的 OpenShift 等 Kubernetes 发行版通常会预装特定的容器运行时。除非您有极其强烈的理由选择其他选项，否则应坚持这种选择。在这种情况下，请确保您理解使用不同容器运行时的支持影响。
- en: Closely related to support is conformance testing of the container runtime.
    The Kubernetes project, specifically the Node Special Interest Group (sig-node),
    defines a set of CRI validation tests and node conformance tests to ensure container
    runtimes are compatible and behave as expected. These tests are part of every
    Kubernetes release, and some runtimes might have more coverage than others. As
    you can imagine, the more test coverage the better, as any issues with the runtime
    are caught during the Kubernetes release process. The community makes all tests
    and results available through the [Kubernetes Test Grid](https://k8s-testgrid.appspot.com).
    When choosing a runtime, you should consider the container runtime’s conformance
    tests and more broadly, the runtime’s relationship with the overall Kubernetes
    project.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 与支持密切相关的是容器运行时的一致性测试。Kubernetes 项目，特别是节点特别兴趣小组（sig-node），定义了一组 CRI 验证测试和节点一致性测试，以确保容器运行时兼容并如预期般行为。这些测试是每个
    Kubernetes 发布的一部分，某些运行时可能比其他运行时有更多的覆盖。可以想象，测试覆盖越多越好，因为运行时的任何问题都会在 Kubernetes 发布过程中被捕捉到。社区通过
    [Kubernetes 测试网格](https://k8s-testgrid.appspot.com) 提供所有测试和结果。在选择运行时时，应考虑容器运行时的一致性测试以及其与整体
    Kubernetes 项目的关系。
- en: Lastly, you should determine if your workloads need stronger isolation guarantees
    than those provided by Linux containers. While less common, there are use cases
    that require VM-level isolation for workloads, such as executing untrusted code
    or running applications that require strong multitenancy guarantees. In these
    cases, you can leverage specialized runtimes such as Kata Containers.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你应确定你的工作负载是否需要比 Linux 容器提供的更强的隔离保证。虽然不常见，但有些用例需要工作负载的 VM 级别隔离，比如执行不受信任的代码或运行需要强大的多租户保证的应用程序。在这些情况下，你可以利用专用运行时，比如
    Kata Containers。
- en: 'Now that we have discussed the considerations you should make when choosing
    a runtime, let’s review the most prevalent container runtimes: Docker, containerd,
    and CRI-O. We will also explore Kata Containers to understand how we can run Pods
    in VMs instead of Linux Containers. Finally, while not a container runtime or
    component that implements CRI, we will learn about Virtual Kubelet, as it provides
    another way to run workloads on Kubernetes.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了在选择运行时时应考虑的因素，让我们回顾一下最常见的容器运行时：Docker、containerd 和 CRI-O。我们还将探讨 Kata
    Containers，以了解如何在虚拟机中运行 Pod，而不是 Linux 容器。最后，虽然 Virtual Kubelet 不是容器运行时或实现 CRI
    的组件，但我们将了解它，因为它提供了在 Kubernetes 上运行工作负载的另一种方式。
- en: Docker
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker
- en: Kubernetes supports the Docker Engine as a container runtime through a CRI shim
    called the *dockershim*. The shim is a component that’s built into the kubelet.
    Essentially, it is a gRPC server that implements the CRI services we described
    earlier in this chapter. The shim is required because the Docker Engine does not
    implement the CRI. Instead of special-casing all the kubelet code paths to work
    with both the CRI and the Docker Engine, the dockershim serves as a facade that
    the kubelet can use to communicate with Docker via the CRI. The dockershim handles
    the translation between CRI calls to Docker Engine API calls. [Figure 3-2](#interaction_between_the_kubelet_and_docker_engine_via_the_dockershim)
    depicts how the kubelet interacts with Docker through the shim.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 通过称为 *dockershim* 的 CRI 适配器支持 Docker Engine 作为容器运行时。这个适配器是内置到 kubelet
    中的一个组件。本质上，它是一个实现我们在本章前面描述的 CRI 服务的 gRPC 服务器。dockershim 的存在是因为 Docker Engine 没有实现
    CRI。为了不特别处理所有 kubelet 代码路径以与 CRI 和 Docker Engine 一起工作，dockershim 作为一个外观，kubelet
    可以通过它与 Docker 通信，通过 CRI。dockershim 处理 CRI 调用到 Docker Engine API 调用的转换。[图 3-2](#interaction_between_the_kubelet_and_docker_engine_via_the_dockershim)
    描述了 kubelet 如何通过 shim 与 Docker 交互。
- en: '![prku 0302](assets/prku_0302.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![prku 0302](assets/prku_0302.png)'
- en: Figure 3-2\. Interaction between the kubelet and Docker Engine via the dockershim.
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. kubelet 与 Docker Engine 通过 dockershim 之间的交互。
- en: 'As we mentioned earlier in the chapter, Docker leverages containerd under the
    hood. Thus, the incoming API calls from the kubelet are eventually relayed to
    containerd, which starts the containers. In the end, the spawned container ends
    up under containerd and not the Docker daemon:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章前面提到的，Docker 在底层利用 containerd。因此，kubelet 的传入 API 调用最终会被转发到 containerd，containerd
    开始容器。最终，生成的容器结束在 containerd 而不是 Docker 守护程序下：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'From a troubleshooting perspective, you can use the Docker CLI to list and
    inspect containers running on a given node. While Docker does not have the concept
    of Pods, the dockershim encodes the Kubernetes Namespace, Pod name, and Pod ID
    into the name of containers. For example, the following listing shows the containers
    that belong to a Pod called `nginx` in the `default` namespace. The Pod infrastructure
    container (aka, pause container) is the one with the `k8s_POD_` prefix in the
    name:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从故障排除的角度来看，您可以使用Docker CLI列出并检查在给定节点上运行的容器。虽然Docker没有Pod的概念，但dockershim将Kubernetes命名空间、Pod名称和Pod
    ID编码到容器的名称中。例如，以下列表显示属于`default`命名空间中名为`nginx`的Pod的容器。Pod基础设施容器（即暂停容器）在名称中具有`k8s_POD_`前缀：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You can also use the containerd CLI, `ctr`, to inspect containers, although
    the output is not as user friendly as the Docker CLI output. The Docker Engine
    uses a containerd namespace called `moby`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用containerd CLI `ctr`来检查容器，尽管其输出不如Docker CLI输出友好。Docker Engine使用名为`moby`的containerd命名空间：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, you can use `crictl` if available on the node. The `crictl` utility
    is a command-line tool developed by the Kubernetes community. It is a CLI client
    for interacting with container runtimes over the CRI. Even though Docker does
    not implement the CRI, you can use `crictl` with the dockershim Unix socket:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果节点上有`crictl`可用，您可以使用它。`crictl`实用程序是由Kubernetes社区开发的命令行工具。它是用于通过CRI与容器运行时进行交互的CLI客户端。尽管Docker不实现CRI，您仍然可以使用`crictl`与dockershim
    Unix套接字一起使用：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: containerd
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: containerd
- en: containerd is perhaps the most common container runtime we encounter when building
    Kubernetes-based platforms in the field. At the time of writing, containerd is
    the default container runtime in Cluster API-based node images and is available
    across various managed Kubernetes offerings (e.g., AKS, EKS, and GKE).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建基于Kubernetes的平台时，containerd可能是我们在现场遇到的最常见的容器运行时。撰写本文时，containerd是基于Cluster
    API的节点映像中的默认容器运行时，并且在各种托管的Kubernetes提供中可用（例如，AKS、EKS和GKE）。
- en: The containerd container runtime implements the CRI through the containerd CRI
    plug-in. The CRI plug-in is a native containerd plug-in that is available since
    containerd v1.1 and is enabled by default. containerd exposes its gRPC APIs over
    a Unix socket at */run/containerd/containerd.sock*. The kubelet uses this socket
    to interact with containerd when it comes to running Pods, as depicted in [Figure 3-3](#interaction_between_the_kubelet_and_containerd_through_the_containerd_cri_plugin).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: containerd容器运行时通过containerd CRI插件实现CRI。CRI插件是自containerd v1.1起可用的本地containerd插件，并且默认启用。containerd通过Unix套接字`/run/containerd/containerd.sock`公开其gRPC
    API。kubelet在运行Pod时使用此套接字与containerd进行交互，如[图3-3](#interaction_between_the_kubelet_and_containerd_through_the_containerd_cri_plugin)所示。
- en: '![prku 0303](assets/prku_0303.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![prku 0303](assets/prku_0303.png)'
- en: Figure 3-3\. Interaction between the kubelet and containerd through the containerd
    CRI plug-in.
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3\. kubelet与containerd通过containerd CRI插件之间的交互。
- en: 'The process tree of spawned containers looks exactly the same as the process
    tree when using the Docker Engine. This is expected, as the Docker Engine uses
    containerd to manage containers:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的容器的进程树与使用Docker Engine时的进程树完全相同。这是预期的，因为Docker Engine使用containerd来管理容器：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To inspect containers on a node, you can use `ctr`, the containerd CLI. As
    opposed to Docker, the containers managed by Kubernetes are in a containerd namespace
    called `k8s.io` instead of `moby`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查节点上的容器，您可以使用containerd CLI `ctr`。与Docker相反，由Kubernetes管理的容器位于名为`k8s.io`的containerd命名空间中，而不是`moby`：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You can also use the `crictl` CLI to interact with containerd through the containerd
    unix socket:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`crictl` CLI与containerd通过containerd的Unix套接字进行交互：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: CRI-O
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CRI-O
- en: CRI-O is a container runtime specifically designed for Kubernetes. As you can
    probably tell from the name, it is an implementation of the CRI. Thus, in contrast
    to Docker and containerd, it does not cater to uses outside of Kubernetes. At
    the time of writing, one of the primary consumers of the CRI-O container runtime
    is the RedHat OpenShift platform.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: CRI-O是专为Kubernetes设计的容器运行时。从名称中您可能能够看出，它是CRI的一个实现。因此，与Docker和containerd相比，它不适用于Kubernetes以外的用途。在撰写本文时，CRI-O容器运行时的主要使用者之一是RedHat
    OpenShift平台。
- en: Similar to containerd, CRI-O exposes the CRI over a Unix socket. The kubelet
    uses the socket, typically located at */var/run/crio/crio.sock*, to interact with
    CRI-O. [Figure 3-4](#interaction_between_the_kubelet_and_crio_using_the_cri_apis)
    depicts the kubelet interacting directly with CRI-O through the CRI.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 与 containerd 类似，CRI-O 通过 Unix 套接字暴露 CRI。 kubelet 使用套接字与 CRI-O 进行交互，通常位于 */var/run/crio/crio.sock*。
    [图 3-4](#interaction_between_the_kubelet_and_crio_using_the_cri_apis) 展示了 kubelet
    直接通过 CRI 与 CRI-O 交互的过程。
- en: '![prku 0304](assets/prku_0304.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![prku 0304](assets/prku_0304.png)'
- en: Figure 3-4\. Interaction between the kubelet and CRI-O using the CRI APIs.
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. kubelet 与 CRI-O 使用 CRI API 的交互。
- en: 'When spawning containers, CRI-O instantiates a process called *conmon*. Conmon
    is a container monitor. It is the parent of the container process and handles
    multiple concerns, such as exposing a way to attach to the container, storing
    the container’s STDOUT and STDERR streams to logfiles, and handling container
    termination:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成容器时，CRI-O 实例化了一个名为 *conmon* 的进程。 Conmon 是容器监视器。 它是容器进程的父进程，并处理多个问题，例如提供连接到容器的方式，将容器的
    STDOUT 和 STDERR 流存储到日志文件中，并处理容器的终止：
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Because CRI-O was designed as a low-level component for Kubernetes, the CRI-O
    project does not provide a CLI. With that said, you can use `crictl` with CRI-O
    as with any other container runtime that implements the CRI:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 CRI-O 被设计为 Kubernetes 的低级组件，所以 CRI-O 项目不提供 CLI。 话虽如此，您可以像对待其他实现 CRI 的容器运行时一样使用
    `crictl` 与 CRI-O 进行交互：
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Kata Containers
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kata Containers
- en: 'Kata Containers is an open source, specialized runtime that uses lightweight
    VMs instead of containers to run workloads. The project has a rich history, resulting
    from the merge of two prior VM-based runtimes: Clear Containers from Intel and
    RunV from Hyper.sh.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Kata Containers 是一个开源的专用运行时，使用轻量级虚拟机而不是容器来运行工作负载。 该项目源于两个先前基于 VM 的运行时的合并：Intel
    的 Clear Containers 和 Hyper.sh 的 RunV。
- en: Due to the use of VMs, Kata provides stronger isolation guarantees than Linux
    containers. If you have security requirements that prevent workloads from sharing
    a Linux kernel or resource guarantee requirements that cannot be met by cgroup
    isolation, Kata Containers can be a good fit. For example, a common use case for
    Kata containers is to run multitenant Kubernetes clusters that run untrusted code.
    Cloud providers such as [Baidu Cloud](https://oreil.ly/btDL9) and [Huawei Cloud](https://oreil.ly/Mzarh)
    use Kata Containers in their cloud infrastructure.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于使用了虚拟机，Kata 提供比 Linux 容器更强的隔离保证。 如果您有安全要求，禁止工作负载共享 Linux 内核，或者有 cgroup 隔离无法满足的资源保证要求，那么
    Kata Containers 可能是一个很好的选择。 例如，Kata 容器的常见用例是运行运行不受信任代码的多租户 Kubernetes 集群。 云提供商如
    [百度云](https://oreil.ly/btDL9) 和 [华为云](https://oreil.ly/Mzarh) 在其云基础设施中使用 Kata
    Containers。
- en: To use Kata Containers with Kubernetes, there is still a need for a pluggable
    container runtime to sit between the kubelet and the Kata runtime, as shown in
    [Figure 3-5](#interaction_between_the_kubelet_and_kata_containers_through_containerd).
    The reason is that Kata Containers does not implement the CRI. Instead, it leverages
    existing container runtimes such as containerd to handle the interaction with
    Kubernetes. To integrate with containerd, the Kata Containers project implements
    the containerd runtime API, specifically the [v2 containerd-shim API](https://oreil.ly/DxGyZ).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Kubernetes 中使用 Kata Containers，仍然需要一个可插拔的容器运行时放置在 kubelet 和 Kata 运行时之间，如
    [图 3-5](#interaction_between_the_kubelet_and_kata_containers_through_containerd)
    所示。 原因在于 Kata Containers 没有实现 CRI。 取而代之，它利用现有的容器运行时（如 containerd）来处理与 Kubernetes
    的交互。 为了与 containerd 集成，Kata Containers 项目实现了 containerd 运行时 API，特别是 [v2 containerd-shim
    API](https://oreil.ly/DxGyZ)。
- en: '![prku 0305](assets/prku_0305.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![prku 0305](assets/prku_0305.png)'
- en: Figure 3-5\. Interaction between the kubelet and Kata Containers through containerd.
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. kubelet 与 Kata Containers 之间通过 containerd 的交互。
- en: 'Because containerd is required and available on the nodes, it is possible to
    run Linux container Pods and VM-based Pods on the same node. Kubernetes provides
    a mechanism to configure and run multiple container runtimes called Runtime Class.
    Using the RuntimeClass API, you can offer different runtimes in the same Kubernetes
    platform, enabling developers to use the runtime that better fits their needs.
    The following snippet is an example RuntimeClass for the Kata Containers runtime:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 因为节点上需要并且可用 containerd，因此可以在同一节点上运行 Linux 容器 Pod 和基于 VM 的 Pod。 Kubernetes 提供了一种称为
    Runtime Class 的机制，用于配置和运行多个容器运行时。 使用 RuntimeClass API，可以在同一 Kubernetes 平台上提供不同的运行时，使开发人员可以选择更适合其需求的运行时。
    下面的片段是 Kata Containers 运行时的示例 RuntimeClass：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To run a Pod under the `kata-containers` runtime, developers must specify the
    runtime class name in their Pod’s specification:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 要在`kata-containers`运行时下运行一个 Pod，开发者必须在他们 Pod 的规格中指定运行时类名：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Kata Containers supports different hypervisors to run workloads, including
    [QEMU](https://www.qemu.org), [NEMU](https://github.com/intel/nemu), and [AWS
    Firecracker](https://firecracker-microvm.github.io). When using QEMU, for example,
    we can see a QEMU process after launching a Pod that uses the `kata-containers`
    runtime class:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Kata Containers 支持不同的虚拟化程序来运行工作负载，包括 [QEMU](https://www.qemu.org)，[NEMU](https://github.com/intel/nemu)，和
    [AWS Firecracker](https://firecracker-microvm.github.io)。例如，当使用 QEMU 时，我们可以在使用
    `kata-containers` 运行时类的 Pod 启动后看到一个 QEMU 进程：
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: While Kata Containers provides interesting capabilities, we consider it a niche
    and have not seen it used in the field. With that said, if you need VM-level isolation
    guarantees in your Kubernetes cluster, Kata Containers is worth looking into.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Kata Containers 提供了一些有趣的功能，但我们认为它是一个小众产品，并且没有看到它在实际场景中的应用。话虽如此，如果你在 Kubernetes
    集群中需要 VM 级别的隔离保证，那么 Kata Containers 值得一试。
- en: Virtual Kubelet
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟 Kubelet
- en: '[Virtual Kubelet](https://github.com/virtual-kubelet/virtual-kubelet) is an
    open source project that behaves like a kubelet but offers a pluggable API on
    the backend. While not a container runtime per se, its main purpose is to surface
    alternative runtimes to run Kubernetes Pods. Because of the Virtual Kubelet’s
    extensible architecture, these alternative runtimes can essentially be any systems
    that can run an application, such as serverless frameworks, edge frameworks, etc.
    For example, as shown in [Figure 3-6](#virtual_kubelet_running_pods_on_a_cloud_service_such_as_azure_container_instances_aws_fargate_etc),
    the Virtual Kubelet can launch Pods on a cloud service such as Azure Container
    Instances or AWS Fargate.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[虚拟 Kubelet](https://github.com/virtual-kubelet/virtual-kubelet) 是一个开源项目，行为类似于
    kubelet，但在后端提供可插拔 API。虽然它本身不是一个容器运行时，但其主要目的是公开替代运行时以运行 Kubernetes Pods。由于虚拟 Kubelet
    的可扩展架构，这些替代运行时本质上可以是任何能运行应用程序的系统，如无服务器框架、边缘框架等。例如，如图 [3-6](#virtual_kubelet_running_pods_on_a_cloud_service_such_as_azure_container_instances_aws_fargate_etc)
    所示，虚拟 Kubelet 可以在 Azure 容器实例或 AWS Fargate 等云服务上启动 Pods。'
- en: '![prku 0306](assets/prku_0306.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![prku 0306](assets/prku_0306.png)'
- en: Figure 3-6\. Virtual Kubelet running Pods on a cloud service, such as Azure
    Container Instances, AWS Fargate, etc.
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. 虚拟 Kubelet 在云服务（如 Azure 容器实例、AWS Fargate 等）上运行 Pods。
- en: The Virtual Kubelet community offers a variety of providers that you can leverage
    if they fit your need, including AWS Fargate, Azure Container Instances, HashiCorp
    Nomad, and others. If you have a more specific use case, you can implement your
    own provider as well. Implementing a provider involves writing a Go program using
    the Virtual Kubelet libraries to handle the integration with Kubernetes, including
    node registration, running Pods, and exporting APIs expected by Kubernetes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟 Kubelet 社区提供了多种提供者，如果符合你的需求，你可以利用它们，包括 AWS Fargate、Azure 容器实例、HashiCorp Nomad
    等。如果你有更具体的用例，你也可以实现自己的提供者。实现一个提供者涉及使用虚拟 Kubelet 库编写一个 Go 程序，用于处理与 Kubernetes 的集成，包括节点注册、运行
    Pods 和导出 Kubernetes 期望的 API。
- en: Even though Virtual Kubelet enables interesting scenarios, we have yet to run
    into a use case that needed it in the field. With that said, it is useful to know
    that it exists, and you should keep it in your Kubernetes toolbox.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然虚拟 Kubelet 可以启用有趣的场景，但我们还没有在实际场景中遇到需要它的用例。话虽如此，了解其存在是有益的，你应该将其纳入你的 Kubernetes
    工具箱。
- en: Summary
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The container runtime is a foundational component of a Kubernetes-based platform.
    After all, it is impossible to run containerized workloads without a container
    runtime. As we learned in this chapter, Kubernetes uses the Container Runtime
    Interface (CRI) to interact with the container runtime. One of the main benefits
    of the CRI is its pluggable nature, which allows you to use the container runtime
    that best fits your needs. To give you an idea of the different container runtimes
    available in the ecosystem, we discussed those that we typically see in the field,
    such as Docker, containerd, etc. Learning about the different options and further
    exploring their capabilities should help you select the container runtime that
    satisfies the requirements of your application platform.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时是基于 Kubernetes 平台的基础组件。毕竟，在没有容器运行时，是不可能运行容器化工作负载的。正如我们在本章学到的那样，Kubernetes
    使用容器运行时接口（CRI）与容器运行时进行交互。CRI 的主要优点之一是其可插拔性，这使您可以选择最适合您需求的容器运行时。为了让您了解生态系统中的不同容器运行时选项，我们讨论了一些在实际场景中常见的选项，如
    Docker、containerd 等。了解这些不同的选择并进一步探索它们的能力，应该有助于您选择满足应用平台需求的容器运行时。
