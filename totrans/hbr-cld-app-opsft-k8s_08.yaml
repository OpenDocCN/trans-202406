- en: Chapter 7\. Multicluster Policy Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key aspect of Kubernetes that we’ve already seen is how it is a declarative,
    API-driven system. Initial support for orchestration focused purely on containers
    and their required support services, such as network services, `PersistentVolumeClaim`s,
    and administrative policies. Now we will look at how we can generalize the underlying
    pattern that Kubernetes API controllers follow. It turns out, declarative management
    of applications is also a great way to operate the Kubernetes cluster itself.
    In this chapter, we will discuss the concept of an operator and how we can use
    operators to simplify the management of our clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Your Cluster with Operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s talk a bit about how the Kubernetes system works and how you can extend
    the system to meet your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each API provider includes a balancing loop (pictured in [Figure 7-1](#a_balancing_loop_reconciles_the_observed)):
    observe actual system state, reconcile with desired system state, apply changes,
    and report status.'
  prefs: []
  type: TYPE_NORMAL
- en: Such a powerful pattern led to more orchestration providers and ultimately was
    generalized to allow the creation of new CRDs and their responsible controllers
    in Kubernetes 1.16\. Controllers react to the presence of new custom resources
    (that are instances of CRDs) or updates to existing custom resources. Controllers
    also interact with objects under management, traditionally containers or pods,
    but now the vocabulary exposed by CRDs allows for the management of stateful workloads
    that require additional orchestration behaviors, of VMs, and even of cloud-based
    services (such as object store, database as a service, etc.). The net is that
    you can use the Kubernetes API paradigm to program a broad array of infrastructure
    and application services using a consistent approach and a source-controllable
    representation of the declarative API.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0701.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. A balancing loop reconciles the observed differences between the
    desired state and current state of the system
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Red Hat helped catalyze the community around the operator framework, or a way
    of applying Kubernetes controllers to manage software life cycles, including deployment,
    configuration, upgrade, and decommissioning. You can leverage these operators
    on [OperatorHub.io](https://operatorhub.io) to more easily manage the containerized
    software running on your cluster. We will see an example of how to deploy an operator
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Red Hat OpenShift applies operators to the management of the entire platform,
    from initiating a cluster and its supporting infrastructure-provisioning life
    cycle to configuring DNS routes for cluster services to configuring identity providers.
    In essence, virtually all aspects of cluster state are specified through declarative
    APIs (via CRDs), and operators implement the intelligent life cycle of reconciliation
    (e.g., the balancing loop pattern discussed previously).
  prefs: []
  type: TYPE_NORMAL
- en: What distinguishes a controller and an operator? This is largely subjective,
    and discussion ranges from the intent of the orchestrator (e.g., operators are
    for the management of software life cycles running in containers) to how you might
    deploy the orchestrator to your cluster (a simple Kubernetes deployment versus
    an operator life cycle bundle). Subjective discussion aside, we will talk about
    operators as custom Kubernetes CRDs and controllers created by the `operator-sdk`.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 7-2](#the_operator_catalog_in_red_hat_openshif), we can see the operators
    available that are built and published by Red Hat alongside the operators that
    are built and supported by the community.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0702.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. The Operator Catalog in Red Hat OpenShift
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Example: Container Security Operator'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can consume operators in OpenShift in two steps. First, deploy the operator
    itself. Second, deploy one or more resources managed by the operator. Let’s practice
    deploying an operator that will help with image security scans in your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example demonstrates how to deploy an example operator, the Container
    Security operator. You will need an OpenShift Container Platform 4.4+ cluster
    to follow the demonstration on your own. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Open the OperatorHub catalog and find the Container Security operator.**
    From the web console, open the Operators > OperatorHub section and enter “container
    security” in the filter text box. A tile named “Container Security” should remain
    in the list.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Open the Container Security operator overview** (as shown in [Figure 7-3](#the_container_security_operator_overview)).
    Click the tile. If a message about Community operators appears, review the message
    and click Continue. Community operators do not qualify for official support guarantees
    and SLAs from Red Hat and are often supported by community contributors in the
    upstream.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/hcok_0703.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7-3\. The Container Security operator overview page
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Review the summary and click Install.** The Summary page describes the operator
    and other supporting details. Pay attention to the Capability Level and Provider
    Type attributes, as these are critical to understanding whether you should adopt
    a particular operator for your needs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Configure the operator subscription** (as shown in [Figure 7-4](#configuring_the_operator_lifecycle_manag)).
    Review your desired choices for the Update Channel and Approval Strategy, then
    click Subscribe.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/hcok_0704.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-4\. Configuring the Operator Lifecycle Manager (OLM) subscription to
    install the Container Security operator
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Subscriptions enable an operator to consume updates as needed, either with manual
    or automatic approval. For each operator, you must decide what choice to make
    for the Update Channel and the Approval Strategy.
  prefs: []
  type: TYPE_NORMAL
- en: The *Update Channel* for each operator can be different and reflects how often
    updates to the operator behavior will be made available and how stable the updates
    are. Channels might reflect stable, released, supported versions of the operator
    or early-access developer previews. The channel you pick will depend on the operator
    and your specific needs and risk tolerance.
  prefs: []
  type: TYPE_NORMAL
- en: The *Approval Strategy* allows you to inject a manual decision prior to upgrades.
    Operators that follow best practices should be able to apply updates without causing
    an outage in supported services. The best practice, where possible, is to allow
    upgrades to proceed automatically, applying the latest security and function fixes
    that are available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have applied an example operator, let’s take a look at the new
    behavior available to our cluster. The act of subscribing to the new operator
    created two resources on your cluster: `ClusterServiceVersion` and `Subscription`.'
  prefs: []
  type: TYPE_NORMAL
- en: The `ClusterServiceVersion` resource provides metadata about the operator, including
    details like display names and a description, as well as operational metadata
    about the types of custom resources that the operator can manage and the types
    of RBAC required to support the operator’s behavior on the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example provides a list of the `ClusterServiceVersion` resources
    defined in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Each of these resources defines metadata about an operator that is installed
    on the cluster and defines information about what the operator contributes to
    the cluster, including the CRDs (remember, this is the Kubernetes way of adding
    new types to the API model).
  prefs: []
  type: TYPE_NORMAL
- en: The `Subscription` resource declares the intent to apply the operator to the
    cluster. The OLM will apply resources, including roles, `RoleBinding`s, a service
    account, the CRDs acted upon by the operator, and of course the operator’s deployment.
    After all, the operator is just another Kubernetes controller, ever reconciling
    desired state and actual state.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we see which operators are deployed in the cluster
    based on the subscription API provided by the OLM framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The OLM handles the installation, upgrade, and removal of operators on your
    cluster. For OpenShift Container Platform clusters, the OLM is deployed out of
    the box. You can optionally deploy OLM against any compliant Kubernetes cluster
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Each subscription results in a set of installed CRDs and running pods that act
    on those custom types.
  prefs: []
  type: TYPE_NORMAL
- en: Using Cluster Operators to Manage OpenShift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we saw with the provisioning life cycle of OpenShift 4.x clusters, operators
    play a central role in how the cluster is configured and continuously reconciled.
    We can introspect the special operators that manage underlying cluster behavior
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: For each of these operators, there will be one or more CRDs that define an API
    you can configure or query to understand the state of the cluster. What is extremely
    powerful is that, regardless of the infrastructure substrate supporting the OpenShift
    4.x cluster, the API and operators function in a consistent manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Configuring the Authentication Operator'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Access control is obviously critical for any organization. To support authentication,
    a Kubernetes provider must establish the identity of a given user or service account.
    Identity can be established by means of traditional user credentials, *Transport
    Layer Security* (TLS) certificates, or security tokens, as in the case of service
    accounts. When no identity information is presented in an API, the user identity
    is treated as the identity `system:anonymous`.
  prefs: []
  type: TYPE_NORMAL
- en: The Kubernetes API server is configured with options for how to trust information
    about identity that is provided for each API request. Information about the identity
    is then asserted for each API request and validated by the Kubernetes API server
    prior to allowing the request to proceed.
  prefs: []
  type: TYPE_NORMAL
- en: A few special identities beyond typical users to be aware of are listed in [Table 7-1](#example_identities_available_within_a_ku).
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-1\. Example identities available within a Kubernetes cluster to specify
    as the subject of a `RoleBinding` or `ClusterRoleBinding`
  prefs: []
  type: TYPE_NORMAL
- en: '| Identity | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Anonymous requests without an explicitly provided identity: User: `system:anonymous`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `system:unauthenticated` | Provides a default identity for any incoming
    API requests that have not provided identity information. You can establish what
    (if any) default API resources are available to anonymous requests by way of Kubernetes
    RBAC. |'
  prefs: []
  type: TYPE_NORMAL
- en: '| All authenticated requests: User: `*`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `system:authenticated` | All authenticated requests will include the
    group `system:authenticated` to support establishing default permissions across
    all users. |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Any request using *Mutual Transport Layer Security* (mTLS) authentication
    by X.509 certificates: User: Common Name specified in the certificate (e.g., CN=username)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: Organizations specified in the certificate (e.g., O=group1/O=group2)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create an example X.509 certificate:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**$ openssl req -new -key username.pem -out username-csr.pem \**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**-subj "/CN=username/O=group1/O=group2"**` | Any API request made with mTLS
    authentication from an X.509 certificate that is signed either by the cluster
    Certificate Authority (CA) or the `--client-ca-file=SOMEFILE` command option provided
    to the Kubernetes API server will authenticate as `username` with groups `group1`
    and `group2`. |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Any request made by a service account: User: `system:serviceaccount:<*namespace*>:<*serviceaccount*>`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `system:serviceaccounts, system:serviceaccounts:<*namespace*>` | A service
    account is an identity created by the API server typically for nonhuman actors
    like bots or long-running jobs. Service accounts establish a token that can be
    used externally or internally by pods that work with the Kubernetes API server.
    Service accounts work like any other identity and can be referenced by Kubernetes
    RBAC to associate permissions. |'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Service accounts can be a simple and enticing way to set up automation against
    your clusters, but take note that service account tokens are long lived and do
    not automatically rotate or expire. If you have the need for long-running automated
    access, consider whether to use mTLS certificates (which can have set expiration
    dates and are resistant to some kinds of security infiltration attacks). Performance
    of requests using service accounts can also be limited, as for every request made,
    the kube-apiserver will make a call to itself to retrieve the service account
    token and validate it. At extremely high API request rates, this can become a
    bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift simplifies the management of identity by way of *identity providers*
    (IdPs) that are configured through operators on the platform. When a user or service
    account authenticates, typically an IdP accepts and validates credential information
    for the requestor. Through command options to the Kubernetes API server, trust
    is established between the IdP and the Kubernetes API server for incoming requests
    and used for authorization in the Kubernetes API server. Later, we’ll see how
    the identity is then authorized using Kubernetes RBAC.
  prefs: []
  type: TYPE_NORMAL
- en: A number of IdPs are available in OpenShift. Here, we will discuss a subset
    of the most commonly used IdPs. In addition, we will review how managed Kubernetes
    as a Service providers associate identity in relation to the cloud provider’s
    *identity and access management* (IAM).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `OAuth` kind in the API group config.openshift.io with version v1 is a
    cluster-scoped resource that allows complete control over the available IdPs for
    OpenShift. The canonical name for this resource is `cluster`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: When configured, the authentication cluster operator will respond to configure
    the specified IdPs or report the status if there is a problem.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift htpasswd Identity Provider
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `htpasswd` IdP is about as simple as it comes. The provider establishes
    identities and credentials by the standard *.htpasswd* file format, loaded into
    a secret. If you have a cluster shared by a small group (such as a “department”
    or “project” scope), consider whether this approach allows you to assign and maintain
    identities for your needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to configure the `htpasswd` IdP:'
  prefs: []
  type: TYPE_NORMAL
- en: Create or update an *.htpasswd* file with your users.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create or update the `htpasswd` secret in openshift-config.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the `cluster OAuth` resource to list the `htpasswd` IdP and reference
    the `htpasswd` secret in the `openshift-config` namespace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use `htpasswd` to generate or update an existing file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then create or apply updates from this file to the secret maintained in `openshift-config`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, update the cluster `OAuth` API resource as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Policy and Compliance Across Multiple Clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let’s take a look at how we can declaratively manage the desired configuration
    after the cluster is provisioned. For this topic, we will introduce additional
    aspects of the [Open Cluster Management project](https://oreil.ly/3J1SW) and use
    RHACM, which provides a supported distribution of this open source project.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need a way to describe policies for our cluster fleet. The Open Cluster
    Management project introduces the `Policy` (API group: policy.open-cluster-management.io)
    API to describe the desired configuration, along with rules about whether the
    expected configuration “must” exist or “must not” exist. Policies can also be
    configured to audit a cluster and report if the cluster configuration is compliant.
    Alternatively, policies can be enforced, ensuring that the cluster matches the
    desired configuration and is considered compliant as a result.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will express a `Policy` resource that acts as an envelope of one or more
    (1..*) `ConfigurationPolicies` (API group: policy.open-cluster-management.io).
    Each `ConfigurationPolicy` is then able to describe one or more (1..*) configurations
    as a rule set. The policy can be enforced as required, in which case changes are
    made to ensure compliance, or audit only to report compliance of the fleet (see
    [Figure 7-5](#visual_representation_of_the_policy_api)). Since we’re talking about
    Kubernetes, each policy is continuously reconciled against fleet members, even
    when a specific fleet member may lose connectivity to the control plane hub cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hcok_0705.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-5\. Visual representation of the `Policy` API from the Open Cluster
    Management Project
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Policy Example: Federate a Project Across Your Fleet'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start with a simple example where we want to federate a specific project
    across all clusters in the fleet. We have a single `Policy` envelope that contains
    a single `ConfigurationPolicy` for our desired project, named `frontend-app-prod`,
    along with a required `LimitRange` configuration to ensure that all pods deployed
    in our project describe memory requests. This example shows a `Policy` envelope
    with nested configurations for a project and a `LimitRange` for that project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Take note of the following important aspects of the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Policy` describes categorization that allows an auditor to quickly understand
    which technical controls are noncompliant if the given `Policy` cannot be properly
    enforced.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ConfigurationPolicy` specifies namespaces that are governed by the `ConfigurationPolicy`
    and can optionally specify an overriding value for `remediationAction` if the
    list of `ConfigurationPolicies` within a single envelope has a mix of enforcement
    and auditing behavior. Further, the severity of a given `ConfigurationPolicy`
    can provide hints to an operator on how to prioritize compliance remediation if
    violations are detected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `object-templates` specify a desired template (either an entire API object
    or a patch) and a `complianceType` rule of whether the desired configuration should
    exist, should not exist, or should be unique.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `PlacementRule` describes how to match a `Policy` against a set of available
    clusters. We’ll talk more about how these work shortly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `PlacementBinding` links the `Policy` to a `PlacementRule`. A given `Policy`
    can be bound to multiple `PlacementRule`s. Each `PlacementRule` can match zero
    or more clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The annotations applied to the `Policy` allow users to organize violations
    according to their own technical standards. In the previous example, the annotations
    link this `Policy` to the National Institute of Standards and Technology Cybersecurity
    Framework (NIST-CSF) standard under the “Information Protection Processes and
    Procedures” category as part of the “Baseline configuration” controls:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: An [open library for policies](https://oreil.ly/hdqzx) that are categorized
    according to the NIST-053 is available.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `complianceType` allows you to define how the `Policy` engine will address
    a noncompliant rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The enumerated values for `complianceType` include:'
  prefs: []
  type: TYPE_NORMAL
- en: '`musthave`'
  prefs: []
  type: TYPE_NORMAL
- en: More than one of the desired configurations may exist, but at least one of the
    desired configurations must match the given `objectDefinition` as specified. When
    the `remediationAction` is `enforce`, the relevant `objectDefinition`s will be
    applied to the cluster. If the `objectDefinition`s cannot be applied, the status
    of the policy will note the ongoing violation.
  prefs: []
  type: TYPE_NORMAL
- en: '`mustonlyhave`'
  prefs: []
  type: TYPE_NORMAL
- en: Exactly one matching configuration must be present and no more. This is particularly
    useful when expressing desired configurations for RBAC or security context constraints.
    If more than one applicable configuration is found, then the status of the policy
    will note the ongoing violation.
  prefs: []
  type: TYPE_NORMAL
- en: '`mustnothave`'
  prefs: []
  type: TYPE_NORMAL
- en: If a matching configuration is found that conforms to the `objectDefinition`,
    then a violation has been detected. If a violation is found, then the status of
    the policy will note the ongoing violation.
  prefs: []
  type: TYPE_NORMAL
- en: PlacementRules to Assign Content to ManagedClusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`PlacementRule`s (API group: apps.open-cluster-management.io) are a powerful
    mechanism used by Open Cluster Management to assign content to clusters. Each
    `PlacementRule` allows you to specify a `clusterSelector` and `clusterConditions`
    to match available `ManagedCluster`s. Remember that `ManagedCluster`s define labels
    like any Kubernetes object. The `clusterSelector` defines a combination of `match​Exp⁠res⁠sion`
    or `matchLabel`s that is evaluated against available `ManagedCluster`s.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `matchExpression`s clause can use binary operators defined by Kubernetes,
    including `In`, `NotIn`, and `Exists`. For example, if you wanted to match a `Managed​Clus⁠ter`
    with the labels `apps/pacman=deployed`, `region=us-east`, `env=development`, and
    `authenticationProfile=htpasswd`, the following combination would work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to the `clusterSelector`, `PlacementRule`s can evaluate the conditions
    that a `ManagedCluster` has reported in its status. Three status conditions are
    available as of the time of this writing that can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '`HubAcceptedManagedCluster`'
  prefs: []
  type: TYPE_NORMAL
- en: Indicates that the `ManagedCluster` was allowed to join by a cluster-manager-admin
    user
  prefs: []
  type: TYPE_NORMAL
- en: '`ManagedClusterConditionAvailable`'
  prefs: []
  type: TYPE_NORMAL
- en: Indicates that the `ManagedCluster` has updated its lease reservation within
    the required period of time and is considered available by the hub
  prefs: []
  type: TYPE_NORMAL
- en: '`ManagedClusterJoined`'
  prefs: []
  type: TYPE_NORMAL
- en: Indicates that the `ManagedCluster` has completed the registration protocol
    and has established a valid connection with the control plane hub cluster
  prefs: []
  type: TYPE_NORMAL
- en: RBAC is important to consider when creating a `PlacementRule`. When a user creates
    a `PlacementRule`, only `ManagedCluster`s that the user has access to are available
    to be evaluated for set inclusion. Hence, the user or role that is responsible
    for defining `PlacementRule`s has a lot of control over how broadly content can
    be applied to the entire fleet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Policy Example: Managing etcd Encryption Within ManagedClusters'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `APIServer` kind within an OpenShift cluster can be configured to encrypt
    any sensitive resources, including secrets, `ConfigMaps`, routes, OAuth access
    tokens, and OAuth authorization tokens. To ensure that all clusters in the fleet
    use encryption, we can define a policy that will update all cluster `APIServer`
    kinds to specify what type of encryption should be used. Using `PlacementRules`,
    we can match this policy against our desired clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we see a policy that is ensuring that the `APIServer`
    CRD, managed by OpenShift, is configured to enforce application-level encryption
    of sensitive data within etcd:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After applying this policy, any `ManagedCluster` with the label `environment=dev`
    or `environment=prod` will be updated to configure the `APIServer` (API group:
    config.openshift.io) to use encryption for any sensitive resources. You can connect
    directly to the managed cluster to review the progress of encrypting the etcd
    datastore as described in the OpenShift product documentation. In this example,
    the command is retrieving status conditions from the `OpenShiftAPIServer` object
    and printing information about the current progress:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If you simply wanted to audit for whether sensitive resources managed in the
    etcd datastore were encrypted, you can change the `remediationAction` to `inform`,
    and the policy will report any `ManagedCluster` that is not encrypting its API
    state as noncompliant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Policy Example: Managing RBAC Within ManagedClusters'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the benefits of OpenShift’s consistency is that you have the same set
    of `ClusterRole`s and roles out of the box across all platforms. You may choose
    to add additional roles to meet your specific organization’s needs.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Of course, modifying the out-of-the-box roles is strongly discouraged because
    that can be reverted or prevent successful upgrades as you adopt maintenance updates.
    That said, you can always create new `ClusterRole`s or roles to meet your organization’s
    standards.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example defines two roles: `developer-read` and `developer-write`.
    These are cluster-scoped roles. If you create a `ClusterRoleBinding` to a user
    or group, then you are granting cluster-wide access to the resources enumerated
    in the `ClusterRole`. If you create a `RoleBinding` within a specific namespace
    or project, then the user will have access to the enumerated resources only within
    that specific project.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code example, a policy with category `AC Access Control` under
    the control `AC-3 Access Enforcement` is defined that will ensure that any matching
    cluster has the `ClusterRole`s specified within object-templates defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: If you think about how your security protocols provide for separation of duty,
    you can follow the same pattern to enforce your anticipated permissions for each
    logical security role provided for your users.
  prefs: []
  type: TYPE_NORMAL
- en: 'A second policy ensures that any project named `pacman-app` contains a `RoleBinding`
    for a specific group named game-developers. The group would be defined by your
    IdP for the cluster (e.g., a Lightweight Directory Access Protocol service). This
    shows an example to configure the user group game-developers to have a binding
    to the `ClusterRole`s `developer-read` and `developer-write`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: If either policy in these two samples were to be in violation, then you would
    have direct feedback that your access control protocols may be incorrectly configured,
    either granting certain users too much control or other users not enough control.
  prefs: []
  type: TYPE_NORMAL
- en: 'Policy Example: Managing IdPs Within ManagedClusters'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For every cluster that you provision, you are going to want to define how the
    cluster recognizes identities. OpenShift has an authentication operator that allows
    you to define how the cluster validates an identity provided by user credentials.
    One of the most straightforward IdPs uses an `htpasswd`-formatted credential file,
    defined by a secret in a particular namespace (`openshift-config`). Here we define
    a policy that configures the `OAuth` API object on the cluster to respect an IdP
    of type `htpasswd`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous example, we see that the following rules are enforced:'
  prefs: []
  type: TYPE_NORMAL
- en: The `OAuth` API kind is configured by this policy to use a custom identity provider.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `htpasswd` contents must be updated for this policy to be valid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create the contents of the `htpasswd` secret, use the `htpasswd` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Then you can create a secret from the generated file to specify as another `object​Defi⁠nition`
    in the policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Policy Example: Managing Upgrades with Policy Across ManagedClusters'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Keeping your cluster fleet up to date will undoubtedly be a core concern for
    any enterprise that is serious about security and maintenance updates. That’s
    the kind of sentence that just writes itself—of course you want to keep your fleet
    up to date, and we’re going to look at how you can do this with policies across
    the entire fleet.
  prefs: []
  type: TYPE_NORMAL
- en: As we have already discussed in this chapter, the OpenShift Container Platform
    encapsulates a substantial amount of in-cluster life-cycle management to upgrade
    the cluster in the CVO. We’ve also seen how RHACM can invoke upgrades for one
    or more clusters from the web console.
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we accomplish the same thing declaratively? As you’ve seen, policies
    are going to play a big role here. To declaratively manage cluster versions, we
    need to specify the desired state of the `ClusterVersion` API object on a `ManagedCluster`.
    Here is an example policy that does exactly that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The heart of this policy is the specification of the `ClusterVersion`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Here, the desired version (4.5.9) must be available from the associated channel
    that was configured for the cluster. Additionally, the assumption is that this
    cluster used the connected install method and remains connected to the public
    image registries for OpenShift.
  prefs: []
  type: TYPE_NORMAL
- en: What if your cluster cannot be created from the connected install method? OpenShift
    makes a disconnected install method available. To configure a disconnected image
    registry, please refer to the [product documentation](https://oreil.ly/rodMz).
    The next example assumes that you have already configured a disconnected registry
    and that all clusters in the fleet are able to consume images from that registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'For an OpenShift cluster to consume updates from a disconnected registry, the
    cluster must have a running instance of the OSUS operator deployed and configured.
    We can define a policy to configure this operator for any cluster in the fleet
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous example policy configures an operator that will support our disconnected
    installation by providing a valid “update graph” used to calculate how the cluster
    should proceed from its current version to a new desired version. The following
    kinds are required for this particular operator to be deployed and configured
    correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: `Cincinnati`'
  prefs: []
  type: TYPE_NORMAL
- en: The configuration of the Cincinnati operator. The OSUS operator defines a CRD
    that deploys additional pods on the cluster to help calculate the update graphs
    available to be consumed. A `ClusterVersion` API object will reference the update
    graph to know which versions are available to be upgraded. Information about available
    update graphs is stored within images that are mirrored as part of the disconnected
    registry that you define for disconnected installs.
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: `Subscription`'
  prefs: []
  type: TYPE_NORMAL
- en: The OLM subscription to install the OSUS operator on the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: `OperatorGroup`'
  prefs: []
  type: TYPE_NORMAL
- en: The `OperatorGroup` is a prerequisite for all operators to be installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: `Image`'
  prefs: []
  type: TYPE_NORMAL
- en: The `Image` configuration for a given OpenShift cluster must be told about the
    CA if you are using a self-signed certificate for your disconnected registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: `ConfigMap`'
  prefs: []
  type: TYPE_NORMAL
- en: The `trusted-ca` referenced from the `Image objectDefinition` is defined here
    to include the certificate for the registry. If your disconnected registry uses
    a certificate that is trusted by one of the global CAs, you may not require this
    part.
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: `Namespace`'
  prefs: []
  type: TYPE_NORMAL
- en: Like all pods in Kubernetes, a namespace must exist on the cluster to run the
    pods for the OSUS operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'To consume available updates from your disconnected registry, you would define
    a policy for your `ClusterVersion` to reference the available update graphs that
    are made known to the cluster via the OSUS operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `ClusterVersion` object must reference the update graph made available by
    the OSUS operator. The upstream field in the preceding `ClusterVersion` spec should
    reference the route exposed by the OSUS operator.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed how operators expose additional APIs that provide
    for the configuration of a Kubernetes or OpenShift cluster. We walked through
    deploying an example operator that continuously scans running pods for references
    to container images that have known vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: We then examined how operators support the configuration of all manner of behavior
    within the cluster and looked at an example of configuring authentication for
    the Kubernetes API layer by customizing the `OAuth` CRD that is acted upon by
    the authentication operator within the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Next we looked at how the rich API surface provided by operators allows you
    to control all aspects of your cluster and how the Open Cluster Management policy
    framework allows you to customize policies that define configuration—or indeed
    even deploy new operators via the OLM framework on all of your clusters. The last
    policy demonstrates a powerful means for driving the entire upgrade configuration
    and even triggering active upgrades across the entire collection of managed clusters.
    You should be able to adapt any one of these working examples to form the foundation
    of your policies for your multicluster fleet.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at an example that takes advantage of many
    of these building blocks to distribute an entire application across multiple clusters
    that could run across multiple cloud providers.
  prefs: []
  type: TYPE_NORMAL
