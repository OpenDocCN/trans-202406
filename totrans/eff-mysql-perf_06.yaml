- en: Chapter 6\. Server Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MySQL metrics are closely related to MySQL performance—that’s obvious. After
    all, the purpose of metrics in any system is to measure and report how the system
    is operating. What’s not obvious is how they are related. It’s not unreasonable
    if you currently see MySQL metrics as depicted in [Figure 6-1](#mysql-metrics-blackbox):
    MySQL is a black box with metrics inside that, in some way, indicate something
    about MySQL.'
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0601](assets/emsp_0601.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-1\. MySQL as a black box: metrics are not revealing'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'That view is not unreasonable (or uncommon) because MySQL metrics are often
    discussed but never taught. Even in my career with MySQL, I have never read or
    heard an exposition of MySQL metrics—and I have worked with people who created
    them. The lack of pedagogy for MySQL metrics is due to a false presumption that
    metrics do not require understanding or interpretation because their meaning is
    self-evident. That presumption has a semblance of truth when considering a single
    metric in isolation, such as `Threads_running`; it’s the number of threads running—what
    more is there to know? But isolation is the fallacy: MySQL performance is revealed
    through a spectrum of MySQL metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: Think of MySQL as a prism. The application figuratively shines a workload into
    MySQL. That workload physically interacts with MySQL and the hardware on which
    it runs. Metrics are the spectrum revealed by the figurative refraction of the
    workload through MySQL, as depicted in [Figure 6-2](#mysql-metrics-prism).
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0602](assets/emsp_0602.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-2\. MySQL as a prism: metrics reveal workload performance'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In the physical sciences, this technique is called *spectrometry*: understanding
    matter through its interaction with light. For MySQL, this is more than a clever
    analogy, it’s the actual relationship between MySQL metrics and MySQL server performance,
    and there are two proofs:'
  prefs: []
  type: TYPE_NORMAL
- en: When you shine a light through a real prism, the resulting color spectrum reveals
    properties of the light, not the prism. Likewise, when you run a workload on MySQL,
    the resulting metrics reveal properties of the workload, not MySQL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Given previous chapters—especially [“MySQL Does Nothing”](ch04.html#mysql-does-nothing)—performance
    is directly attributable to workload: queries, data, and access patterns. Without
    a workload, all metric values are zero (generally speaking).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewed this way, MySQL metrics can be taught in a new light, and that is the
    focus of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'This analogy has another pedagogical utility: it separates MySQL metrics into
    *spectra* (the plural of *spectrum*). This is very useful because MySQL metrics
    are vast and unorganized (several hundred metrics strewn throughout MySQL), but
    effective teaching requires focus and organization. As a result, the [“Spectra”](#spectra)
    section, which illuminates over 70 metrics divided into 11 spectra, makes up the
    bulk of this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A final note before we shine a light on MySQL: only a fraction of metrics are
    essential for understanding and analyzing MySQL server performance. The relevance
    and importance of the remaining metrics varies widely:'
  prefs: []
  type: TYPE_NORMAL
- en: Some are noise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some are historical
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some are disabled by default
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some are very technically specific
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some are only useful in specific cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some are informational, not proper metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some are inscrutable by feeble mortal creatures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This chapter analyzes the spectra of MySQL metrics that are essential for understanding
    how the workload interacts with and affects MySQL server performance. There are
    six major sections. The first draws a distinction between query performance and
    server performance. Previous chapters focus on the former, but this chapter focuses
    on the latter. The second is boring—you’ll see why. The third lists key performance
    indicators (KPIs) that quickly gauge MySQL performance. The fourth explores the
    field of metrics: a model to more deeply understand how metrics describe and relate
    to MySQL server performance. The fifth presents the spectra of MySQL metrics:
    over 70 MySQL metrics organized into 11 spectra—an epic and exciting journey that
    tours the inner workings of MySQL, after which you will see MySQL in a new light.
    The sixth addresses important topics related to monitoring and alerting.'
  prefs: []
  type: TYPE_NORMAL
- en: Query Performance Versus Server Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MySQL performance has two sides: query performance and server performance.
    Previous chapters address *query performance*: improving response time by optimizing
    the workload. This chapter addresses *server performance*: analyzing the performance
    of MySQL as a function of executing the workload.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this chapter, *MySQL performance* means *server performance*.
  prefs: []
  type: TYPE_NORMAL
- en: In simplest terms, the workload is input and server performance is output, as
    shown in [Figure 6-3](#query-and-server-perf).
  prefs: []
  type: TYPE_NORMAL
- en: If you put an optimized workload into MySQL, you get high performance out of
    MySQL. Server performance is almost always an issue with the workload, not MySQL.
    Why? Because MySQL is incredibly good at executing a variety of workloads. MySQL
    is a mature, highly optimized data store—*decades* of tuning by world-class database
    experts. That’s why the first five chapters of this book extol query performance,
    and only one chapter (this one) analyzes server performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0603](assets/emsp_0603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-3\. Query and server performance
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'There are three reasons to analyze server performance:'
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency and contention
  prefs: []
  type: TYPE_NORMAL
- en: 'Concurrency leads to contention that reduces query performance. A query executed
    in isolation exhibits different performance when executed with other queries.
    Recall the Universal Scalability Law in [Equation 4-1](ch04.html#usl): contention
    (`α`) is in the divisor of the equation, which means it reduces throughput as
    load increases. Unless you’re living in a different universe than the rest of
    us, concurrency and contention are unavoidable.'
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing server performance is most useful and most commonly undertaken to
    see how MySQL handles the workload when all queries (concurrency) are competing
    for shared and limited system resources (contention). Certain workloads have very
    little—if any—contention, while other workloads kill performance—both query and
    server performance—despite the best efforts of MySQL. The access pattern trait
    [“Concurrency”](ch04.html#ap-concurrency) is, unsurprisingly, a major factor in
    contention, but all the access pattern traits are important, too. Analyzing server
    performance reveals how well the queries in the workload play together. As engineers
    responsible for those queries, we need to ensure that they play well.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning
  prefs: []
  type: TYPE_NORMAL
- en: 'Server performance is directly *but not entirely* attributable to workload.
    There are three additional factors in server performance: MySQL, operating system,
    and hardware. In query performance, it’s presumed that MySQL, operating system,
    and hardware are properly configured and adequate for the workload. Problems (like
    faulty hardware) and bugs notwithstanding, these three affect performance far
    less than the workload because we’re living in an age of abundance: MySQL is very
    mature and highly optimized, operating systems are advanced and sophisticated,
    and hardware is fast and affordable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Matters discussed in [“MySQL Tuning”](ch02.html#mysql-tuning) still hold true:
    tuning MySQL is akin to squeezing blood from a turnip. You most likely never need
    to tune MySQL. But if you do, it requires analyzing server performance with a
    known and stable workload; otherwise, you cannot be certain that any performance
    gains are the result of tuning—it’s basic science: controls, variables, reproducibility,
    and falsifiability.'
  prefs: []
  type: TYPE_NORMAL
- en: Performance regressions
  prefs: []
  type: TYPE_NORMAL
- en: 'I praise MySQL throughout this book, but I would be remiss if I did not, at
    least once, clearly state: sometimes, MySQL is wrong. But MySQL did not become
    the most popular open source relational database in the world by being wrong.
    It is usually correct, and suspecting a performance regression (or bug) is the
    last resort of experts after ensuring that query performance, MySQL tuning, and
    faulty hardware are not the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: The blog posts [“Checkpointing in MySQL and MariaDB”](https://oreil.ly/MuRIt)
    and [“More on Checkpoints in InnoDB MySQL 8”](https://oreil.ly/NDQkP) by renowned
    MySQL expert Vadim Tkachenko contain perfect examples of analyzing server performance
    to reveal a performance regression. It’s normal for Vadim to be doing this type
    of work; the rest of us plod through much simpler problems, like indexing and
    whether or not to have a third cup of coffee before lunch.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency and contention are the implicit focus of this chapter because they
    are the responsibility of the engineers who maintain the application that executes
    the queries. Tuning and performance regressions are the responsibility of MySQL
    DBAs and experts. Learning to analyze server performance for the former (concurrency
    and contention) is excellent training for the latter because the difference is
    primarily a matter of focus. I hope the former sparks an interests in the latter
    because the MySQL industry needs more DBAs and experts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Normal and Stable: The Best Database Is a Boring Database'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the most part, *normal* and *stable* are intuitively understood by engineers
    once they become familiar with the application and how its workload runs on MySQL.
    Humans are good at pattern recognition, so it’s easy to see when the charts for
    any metric are unusual. Therefore, I won’t belabor terminology that is generally
    well understood, but I need to make two clarifying points to ensure that we’re
    on the same page, and to address the rare times when engineers ask “What is normal?”
    with respect to MySQL performance:'
  prefs: []
  type: TYPE_NORMAL
- en: Normal
  prefs: []
  type: TYPE_NORMAL
- en: Every application, workload, MySQL configuration, and environment are different.
    Therefore, normal is whatever performance MySQL exhibits for your application
    on a typical day when everything is working properly. That normal—your normal—is
    the baseline for determining if some aspect of performance is higher or lower,
    faster or slower, better or worse than normal. It’s as simple as that.
  prefs: []
  type: TYPE_NORMAL
- en: 'When I state a presumptive norm like “It’s normal for `Threads_running` to
    be less than 50,” it’s only an abbreviation of language, short for “A stable value
    for `Threads_running` is less than 50 given my experience, and given that current
    hardware typically has less than 48 CPU cores, and given that benchmarks show
    that MySQL performance does not currently scale well past 64 running threads.”
    But if 60 threads running is normal and stable for your application, then great:
    you have achieved extraordinary performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Stable
  prefs: []
  type: TYPE_NORMAL
- en: 'Don’t lose sight of stable performance in your quest for greater performance.
    [“Performance Destabilizes at the Limit”](ch04.html#perf-at-the-limit) illustrates
    and explains why squeezing maximum performance from MySQL is not the goal: at
    the limit, performance destabilizes, and then you have bigger problems than performance.
    Stability does not limit performance; it ensures that performance—at any level—is
    sustainable, because that’s what we really want: MySQL fast all the time, not
    sometimes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'At times, MySQL performance is glamorous—the highs, the lows, the screaming
    fans and packed stadiums—but the real art is optimizing the database into pristine
    boredom: all queries respond quickly, all metrics are stable and normal, and all
    users are happy.'
  prefs: []
  type: TYPE_NORMAL
- en: Key Performance Indicators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Four metrics quickly gauge MySQL performance:'
  prefs: []
  type: TYPE_NORMAL
- en: Response time
  prefs: []
  type: TYPE_NORMAL
- en: 'Response time is no surprise: as noted in [“North Star”](ch01.html#north-star),
    it’s the only metric anyone truly cares about. Even if response time is great,
    you must factor in other KPIs. For example, if every query fails with an error,
    response time might be amazing (near zero), but that’s not normal. The goal is
    normal and stable response time, and lower is better.'
  prefs: []
  type: TYPE_NORMAL
- en: Errors
  prefs: []
  type: TYPE_NORMAL
- en: 'Errors is the rate of errors. Which errors? At least query errors, but ideally
    all errors: query, connection, client, and server. Don’t expect a zero error rate
    because, for example, there’s nothing you, the application, or MySQL can do if
    a client aborts a connection. The goal is a normal and stable error rate, and
    lower (near zero) is better.'
  prefs: []
  type: TYPE_NORMAL
- en: QPS
  prefs: []
  type: TYPE_NORMAL
- en: 'Queries per second is also no surprise: executing queries is the main purpose
    and work of MySQL. QPS indicates performance, but it does not equal performance.
    Abnormally high QPS, for example, can signal problems. The goal is normal and
    stable QPS, and the value is arbitrary.'
  prefs: []
  type: TYPE_NORMAL
- en: Threads running
  prefs: []
  type: TYPE_NORMAL
- en: Threads running gauges how hard MySQL is working to achieve QPS. One thread
    executes one query, so you must consider both metrics because they’re closely
    related. The goal is normal and stable threads running; lower is better.
  prefs: []
  type: TYPE_NORMAL
- en: 'I expound these metrics in [“Spectra”](#spectra). Here, the point is that these
    four metrics are the KPIs for MySQL: when the values for all four are normal,
    MySQL performance is practically guaranteed also to be normal. Always monitor
    response time, errors, QPS, and threads running. Whether or not to alert on them
    is discussed later in [“Alert on User Experience and Objective Limits”](#alert-on).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Simplifying the performance of a complex system to a handful of metrics is
    not unique to MySQL or computers. For example, you have vital signs (I hope):
    height, weight, age, blood pressure, and heart rate. Five biological metrics succinctly
    and accurately gauge your health. Likewise, four MySQL metrics succinctly and
    accurately gauge server performance. That’s nifty, but what’s really insightful
    is the field of metrics in which all metrics are situated.'
  prefs: []
  type: TYPE_NORMAL
- en: Field of Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every MySQL metric belongs to one of six classes shown as boxes in [Figure 6-4](#field-of-metrics).
    Collectively, I call it the *field of metrics*.
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0604](assets/emsp_0604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-4\. Field of metrics
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: MySQL performance cannot be fully understood by analyzing metrics in isolation
    because performance is not an isolated property. Performance is the result of
    many factors for which there are many related metrics. The field of metrics is
    a model to understand how metrics are related. The relationships connect the proverbial
    dots (the metrics) to complete the intricate picture that is MySQL performance.
  prefs: []
  type: TYPE_NORMAL
- en: Response Time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Response time metrics indicate *how long* MySQL takes to respond. They are top
    level in the field because they encompass (or hide) details from lower levels.
  prefs: []
  type: TYPE_NORMAL
- en: Query response time is, of course, the most important one and the only one commonly
    monitored. MySQL executes statements in stages, and stages can be timed. These
    are response time metrics, too, but they measure around query execution, not within
    it. Actual query execution is just one stage of many. If you recall [Example 1-3](ch01.html#update-stages)
    in [Chapter 1](ch01.html#ch01), executing the actual `UPDATE` of an `UPDATE` statement
    was only 1 of 15 stages. Consequently, stage response times are mostly used by
    MySQL experts to investigate deep server performance issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Response time metrics are important but also completely opaque: what was MySQL
    doing that accounts for the time? To answer that, we must dig deeper into the
    field.'
  prefs: []
  type: TYPE_NORMAL
- en: Rate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rate metrics indicate *how fast* MySQL completes a discrete task. Queries per
    second (QPS) is the ubiquitous and universally known database rate metric. Most
    MySQL metrics are rates because—no surprise—MySQL does many discrete tasks.
  prefs: []
  type: TYPE_NORMAL
- en: When a rate increases, it can increase related utilizations. Some rates are
    innocuous and don’t increase utilization, but the important and commonly monitored
    rates do increase utilization.
  prefs: []
  type: TYPE_NORMAL
- en: The rate-utilization relationship presumes no other changes. That means you
    can increase a rate without increasing utilization only if you change something
    about the rate or the utilization that it affects. It’s usually easier to change
    the rate rather than the utilization because the rate is the cause in the relationship.
    For example, when QPS increases across the board, CPU utilization could increase
    because more queries require more CPU time. (Increasing QPS could increase other
    utilizations; CPU is just one example.) To avoid or reduce the increase in CPU
    utilization, you should optimize the queries so they require less CPU time to
    execute. Or, you could increase the number of CPU cores by scaling up the hardware,
    but [“Better, Faster Hardware!”](ch02.html#better-faster-hardware) and [“Better,
    Faster Hardware?”](ch04.html#better-faster-hardware-again) address the shortcomings
    of this approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rate-utilization relationship is not a novel insight—you probably already
    knew it—but it’s important to highlight because it’s the beginning of a series
    of relationships that unify the field. Don’t feel sorry for utilization: it pushes
    back.'
  prefs: []
  type: TYPE_NORMAL
- en: Utilization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Utilization metrics indicate *how much* MySQL uses a finite resource. Utilization
    metrics are everywhere in computers: CPU usage, memory usage, disk usage, and
    so on. Since computers are finite machines, almost everything can be expressed
    as a utilization because nothing has infinite capacity—not even the cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Bounded rates* can be expressed as a utilization. A rate is bounded if there
    is a maximum rate. Disk I/O, for example, is usually expressed as a rate (IOPS),
    but every storage device has a maximum rate. Therefore, disk I/O utilization is
    the current rate over the maximum rate. By contrast, *unbounded rates* cannot
    be expressed as a utilization because there’s no maximum rate: QPS, bytes sent
    and received, and so forth.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When a utilization increases, it can decrease related rates. I bet you’ve seen
    or experienced something like this before: a rogue query causes 100% disk I/O
    utilization, which causes QPS to drop precipitously, which causes an outage. Or,
    MySQL uses 100% of memory and is killed by the operating system kernel, which
    causes the ultimate rate decrease: to zero. This relationship is an expression
    of the USL (recall [Equation 4-1](ch04.html#usl)) because utilization increases
    contention (`α`) and coherency (`β`), which are in the divisor of the equation.'
  prefs: []
  type: TYPE_NORMAL
- en: What happens at *or near* 100% utilization? MySQL waits. In [Figure 6-4](#field-of-metrics),
    this is indicated by the arrow between *Utilization* and *Wait*—the utilization-wait
    relationship. The arrow is labeled *Stall* because query execution waits, then
    resumes—perhaps many times. I emphasize *or near* because, as discussed in [“Performance
    Destabilizes at the Limit”](ch04.html#perf-at-the-limit), stalls can occur before
    100% utilization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stalls are anti-stable but unavoidable for two reasons: MySQL load is usually
    greater than hardware capacity; and latency is inherent in all systems, especially
    hardware. The first reason can be ameliorated by reducing load (optimizing the
    workload) or increasing hardware capacity. The second reason is difficult to address
    but not impossible. If, for example, you still use spinning disks, upgrading to
    NVMe storage will dramatically reduce storage latency.'
  prefs: []
  type: TYPE_NORMAL
- en: Wait
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Wait metrics indicate idle time during query execution. Waits occur when query
    execution stalls due to contention and coherency. (Waits also occur due to MySQL
    bugs or performance regressions, but these are exceedingly rare enough not to
    raise concern.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Wait metrics are calculated as rates or response times (depending on the metric),
    but they merit a separate class because they reveal when MySQL is *not working*
    (idle), which is the opposite of performance. *Not working* is why the wait class
    in [Figure 6-4](#field-of-metrics) is darker: MySQL has gone dark.'
  prefs: []
  type: TYPE_NORMAL
- en: Waits are unavoidable. Eliminating waits is not the goal; the goal is reducing
    and stabilizing them. When waits are stabilized and reduced to an acceptable level,
    they effectively disappear, blending into response time as an inherent part of
    query execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'When MySQL waits too long, it times out—the wait-error relationship. The most
    important, high-level MySQL waits have configurable timeouts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[`MAX_EXECUTION_TIME`](https://oreil.ly/H0fwi) (SQL statement optimizer hint)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`max_execution_time`](https://oreil.ly/2rdKw)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`lock_wait_timeout`](https://oreil.ly/WD6p7)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`innodb_lock_wait_timeout`](https://oreil.ly/4uT4F)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`connect_timeout`](https://oreil.ly/R7HwC)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`wait_timeout`](https://oreil.ly/C7M9a)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use these but don’t rely on them because, for example, take a guess at the default
    value for `lock_wait_timeout`. The default value for `lock_wait_timeout` is 31,536,000
    seconds—365 days. Establishing default values is not easy, so we must give MySQL
    some leeway, but wow—365 days. Consequently, applications should always employ
    code-level timeouts, too. Long-running transactions and queries are a common problem
    because MySQL is fast but, perhaps, too patient.
  prefs: []
  type: TYPE_NORMAL
- en: Error
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Error metrics indicate errors. (I allow myself one tautological statement in
    this book; there it is.) Wait timeouts are one type of error, and there are many
    more (see [“MySQL Error Message Reference”](https://oreil.ly/Jtpqd) for more).
    I don’t need to enumerate MySQL errors because, with respect to server performance
    and MySQL metrics, the point is simple and clear: an abnormal error rate is bad.
    Like waits, errors are also calculated as rates, but they merit a separate class
    because they indicate when MySQL or the client (the application) has failed, which
    is why the error class in [Figure 6-4](#field-of-metrics) is darker.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To reiterate a point about errors from [“Key Performance Indicators”](#kpi):
    don’t expect a zero error rate because, for example, there’s nothing you, the
    application, or MySQL can do if a client aborts a connection.'
  prefs: []
  type: TYPE_NORMAL
- en: Access Pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Access pattern metrics indicate how the application uses MySQL. These metrics
    relate to [“Data Access Patterns”](ch04.html#access-patterns). For example, MySQL
    has metrics for each type of SQL statement (`Com_select`, `Com_insert`, and so
    on) that relate to [“Read/Write”](ch04.html#ap-read-write).
  prefs: []
  type: TYPE_NORMAL
- en: As indicated in [Figure 6-4](#field-of-metrics), access pattern metrics underlie
    higher level metrics. The `Com_select` access pattern metric counts the number
    of `SELECT` statements executed. This can be represented as a rate (`SELECT` QPS)
    or a utilization (`% SELECT`); either way, it reveals something deeper about server
    performance that helps explain higher level metrics. For example, if response
    time is abysmal and the access pattern metric `Select_full_join` is high, that’s
    a smoking gun (see [“Select full join”](ch01.html#Select-full-join)).
  prefs: []
  type: TYPE_NORMAL
- en: Internal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There’s a seventh class of metrics shown in [Figure 6-5](#field-of-metrics-with-internal):
    internal metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0605](assets/emsp_0605.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-5\. Field of metrics with internal metrics
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: I didn’t mention this class at the beginning of [“Field of Metrics”](#field-of-metrics-toc)
    because, as engineers and users of MySQL, we’re not supposed to know or care about
    it. But it’s the most interesting—if not arcane—part of the field, and I want
    you to be fully informed in case you need or want to fathom the depths of MySQL.
    Down here, things are esoteric.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, *esoteric* is subjective. What I consider to be an internal metric
    might be the most favorite and useful rate metric for another engineer. But metrics
    like `buffer_page_read_index_ibuf_non_leaf` make a strong case for the internal
    class of metrics. That metric indicates the number of non-leaf index pages read
    in the change buffer. Not exactly your daily bread.
  prefs: []
  type: TYPE_NORMAL
- en: Spectra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prepare yourself for another journey: into the penumbra of MySQL metrics. This
    section examines over 70 MySQL metrics divided into 11 spectra, some of which
    have sub-spectra. I organize MySQL metrics into spectra for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Spectra give the journey waypoints. Without them, we face a vast and unorganized
    universe swirling with nearly *one thousand* metrics from different sources that
    vary by MySQL version, distribution, and configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spectra reveal important areas of MySQL to understand and monitor with respect
    to performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Even with spectra illuminating a path through the darkness, we need a metric
    naming convention to talk clearly and precisely about the MySQL metrics and system
    variables that constitute each spectrum. The reason is simple: MySQL does not
    have a metric naming convention, and there is no industry standard, either. [Table 6-1](#metric-naming-convention)
    is the MySQL metric naming convention that I use in this book.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6-1\. MySQL metric naming convention
  prefs: []
  type: TYPE_NORMAL
- en: '| Example | Refers to |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `Threads_running` | Global status variables |'
  prefs: []
  type: TYPE_TB
- en: '| `var.max_connections` | Global system variables |'
  prefs: []
  type: TYPE_TB
- en: '| `innodb.log_lsn_checkpoint_age` | InnoDB metrics |'
  prefs: []
  type: TYPE_TB
- en: '| *`replication lag`* | Derived metrics |'
  prefs: []
  type: TYPE_TB
- en: 'Most metrics are global status variables that you have likely seen or used
    by executing [`SHOW GLOBAL STATUS`](https://oreil.ly/NacuT): `Aborted_connects`,
    `Queries`, `Threads_running`, and so forth. In MySQL and this book, global status
    variable names begin with a single uppercase letter followed by lowercase letters,
    even if the first word is an acronym: `Ssl_client_connects`, *not* `SSL_client_connects`.
    (This is one aspect of MySQL metrics that is consistent.) By contrast, global
    system variables are lowercase; and to make them more distinct, I prefix them
    with `var.`, which is important given the next convention. InnoDB metrics are
    also lowercase, like `lock_timeouts`. Since that can look like a global system
    variable, I prefix InnoDB metrics with `innodb.`, like `innodb.lock_timeouts`.
    Derived metrics are ubiquitous in monitoring but not native to MySQL. *`Replication
    lag`*, for example, is a metric that nearly every monitor will emit, but the precise
    metric name depends on the monitor, which is why I use a descriptive name without
    underscore characters rather than a specific technical name.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The InnoDB metrics in this section require enabling certain counters or modules.
    For example, starting MySQL with `inno​db_​mon​itor_​enable=​module_​log,​mod⁠ule_​buffer,​module_​trx`.
    See [`var.innodb_monitor_enable`](https://oreil.ly/nFKFT) and [“InnoDB INFORMATION_SCHEMA
    Metrics Table”](https://oreil.ly/e0wpA) in the MySQL manual.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second to last bit of mental equipment: *global* refers to the entire MySQL
    server: all clients, all users, all queries, and so on—combined. By contrast,
    there are *session* and *summary* metrics. Session metrics are global metrics
    scoped to a single client connection. Summary metrics are usually a subset of
    global metrics scoped to a variety of aspects: account, host, thread, transaction,
    and so on. This chapter looks only at global metrics since they underlie all metrics.
    (Global metrics are also the original: in ancient times, MySQL had only global
    metrics; then it added session metrics; then it added summary metrics.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Last bit of mental equipment before we begin the journey: most MySQL metrics
    are simple counters, and only a few are gauges. I explicitly note the gauges;
    otherwise, counter is implied. Let’s begin!'
  prefs: []
  type: TYPE_NORMAL
- en: Query Response Time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Global query response time is one of the four [“Key Performance Indicators”](#kpi).
    Surprisingly, MySQL did not have this metric until version 8.0. As of MySQL 8.0.1,
    you can obtain the 95th percentile (P95) global query response time in milliseconds
    from the [Performance Schema](https://oreil.ly/dj06D) by executing the query in
    [Example 6-1](#qrt-query).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-1\. Global 95th percentile query response time
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'That query returns a percentile very close to—but not exactly—the P95: 95.2%
    instead of 95.0%, for example.^([1](ch06.html#idm45829110960368)) The difference
    is negligible and does not affect monitoring.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can replace `0.95` in the query to return a different percentile: `0.99`
    for P99, or `0.999` for P999. I prefer and advise P999 for the reasons stated
    in [“Average, Percentile, and Maximum”](ch01.html#avg-p-max-distro).'
  prefs: []
  type: TYPE_NORMAL
- en: The rest of this section is for MySQL 5.7 and older—skip it if you’re running
    MySQL 8.0 or newer.
  prefs: []
  type: TYPE_NORMAL
- en: MySQL 5.7 and older
  prefs: []
  type: TYPE_NORMAL
- en: 'MySQL 5.7 and older do not expose a global query response time metric. Only
    query metrics include response time (see [“Query time”](ch01.html#Query-time)),
    but that is per-query response time. To calculate global response time, you would
    need to aggregate it from every query. That’s possible, but there are two better
    alternatives: upgrade to MySQL 8.0; or, switch to Percona Server or MariaDB, which
    have a plug-in to capture global response time.'
  prefs: []
  type: TYPE_NORMAL
- en: Percona Server 5.7
  prefs: []
  type: TYPE_NORMAL
- en: Way back in 2010, [Percona Server](https://oreil.ly/Gyq8J) introduced a plug-in
    to capture global response time called [Response Time Distribution](https://oreil.ly/PE5kh).
    It’s easy to install the plug-in, but it takes work to configure and use because
    it’s a histogram of response time ranges, which means you need to set `var.query_response_time_range_base`—a
    global system variable that the plug-in creates—to configure the histogram bucket
    ranges, then compute a percentile from the bucket counts. MySQL 8.0 global response
    time is also a histogram, but the bucket ranges and percentiles are preset and
    precomputed, which is why the query in [Example 6-1](#qrt-query) works out of
    the box. It’s not that difficult to set up; it only sounds complicated. The benefit
    of having global response time is well worth the effort.
  prefs: []
  type: TYPE_NORMAL
- en: MariaDB 10.0
  prefs: []
  type: TYPE_NORMAL
- en: '[MariaDB](https://oreil.ly/oeGJO) uses the same plug-in from Percona but it
    has a slightly different name: [Query Response Time Plugin](https://oreil.ly/kb4gA).
    Although introduced in MariaDB 10.0, it was not marked stable until MariaDB 10.1.'
  prefs: []
  type: TYPE_NORMAL
- en: Before MySQL 8.0, obtaining global query response time is not trivial, but it’s
    worth the effort if you’re running Percona Server or MariaDB. If you’re running
    MySQL in the cloud, check the cloud provider metrics because some provide a response
    time metric (which the cloud provider might call *latency*). If nothing else,
    frequently review the query profile to keep an eye on response times.
  prefs: []
  type: TYPE_NORMAL
- en: Errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Errors are one of the four [“Key Performance Indicators”](#kpi). As of MySQL
    8.0.0, it’s easy to obtain a count of *all* errors from the [Performance Schema](https://oreil.ly/glJUC)
    by executing the query in [Example 6-2](#all-errors-query).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-2\. Global error count
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Error number 1287, excluded in the `WHERE` clause in [Example 6-2](#all-errors-query),
    is for deprecation warnings: when a query uses a feature that is deprecated, MySQL
    issues a warning. Including this error number is likely to make the global error
    count too noisy, which is why I exclude it.'
  prefs: []
  type: TYPE_NORMAL
- en: Since MySQL has so many errors and warnings, there’s no telling what your global
    error rate will be. Don’t expect or try to achieve a zero error rate. That’s essentially
    impossible because clients can cause errors, and there’s nothing you, the application,
    or MySQL can do to prevent that. The goal is to establish the normal error rate
    for the application. If the query in [Example 6-2](#all-errors-query) is too noisy—which
    means it produces a high rate of errors but you are certain the application is
    functioning normally—then fine tune the query by excluding additional error numbers.
    MySQL error codes are documented in the [“MySQL Error Message Reference”](https://oreil.ly/wKfnV).
  prefs: []
  type: TYPE_NORMAL
- en: Before MySQL 8.0, you cannot obtain a global error count from MySQL, but you
    can obtain a count of all *query* errors from the [Performance Schema](https://oreil.ly/QiHj8)
    by executing the query in [Example 6-3](#query-errors-query).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-3\. Query error count
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Since this works in all distributions as of MySQL 5.6, there is no reason not
    to monitor all query errors. Granted, the application should report query errors,
    too; but if it also retries on error, it might hide a certain amount of errors.
    By contrast, this will expose all query errors, potentially revealing a problem
    that application retries are masking.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last error metrics are client connection errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Aborted_clients`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Aborted_connects`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Connection_errors_%`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first two metrics are commonly monitored to ensure that there are no issues
    *while connecting* or *already connected* to MySQL. That wording is precise: if
    the application cannot make a network connection to MySQL, then MySQL does not
    see the client and does not report a client connection error because, from the
    MySQL point of view, there is no client connection yet. Low-level network connection
    issues should be reported by the application. However, if the application cannot
    connect, you’re likely to see a drop in the other three KPIs (QPS, threads running,
    and response time) because the application isn’t executing queries.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The `%` character in `Connection_errors_%` is a MySQL wildcard; several metrics
    exist with the prefix `Connection_errors_`. To list them, execute `SHOW GLOBAL
    STATUS LIKE *Connection_errors_%*;`.
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on to the next spectrum, let’s address a problem that’s also not
    a problem—at least not for MySQL. If the application begins to spew errors but
    MySQL does not and the other three KPIs are normal, then the problem is with the
    application or the network. MySQL has many quirks, but lying is not one of them.
    If MySQL KPIs are thumbs up (all okay and normal), then you can trust that MySQL
    is working normally.
  prefs: []
  type: TYPE_NORMAL
- en: Queries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Metrics related to queries reveal how fast MySQL is working and what type of
    work it’s doing—at a very high level. These metrics reveal two access pattern
    traits: throughput and read/write (see [“Throughput”](ch04.html#ap-throughput)
    and [“Read/Write”](ch04.html#ap-read-write)).'
  prefs: []
  type: TYPE_NORMAL
- en: QPS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'QPS is one of the four [“Key Performance Indicators”](#kpi). The underlying
    metric is aptly named:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Queries`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'That metric is a counter, but QPS is a rate, so technically QPS equals the
    difference of two `Queries` measurements divided by the number of seconds between
    the measurements: QPS = (Queries @ T1 – Queries @ T0) / (T1 – T0), where T0 is
    the time of the first measurement and T1 is the time of the second measurement.
    Metric graphing systems (like [Grafana](https://grafana.com)) convert counters
    to rates by default. As a result, you should not need to convert `Queries` or
    any other counters to rates. Just be aware that most MySQL metrics are counters,
    but they are converted to and expressed as rates.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Metric graphing systems convert counters to rates by default.
  prefs: []
  type: TYPE_NORMAL
- en: QPS receives a lot of attention because it indicates overall MySQL throughput—how
    fast MySQL is executing queries—but don’t fixate on it. As mentioned in [“Less
    QPS Is Better”](ch03.html#less-qps-is-better), QPS reveals nothing qualitative
    about the queries or performance in general. If QPS is incredibly high but response
    time is also incredibly high, then QPS indicates a problem, not great performance.
    Other metrics reveal more about MySQL performance than QPS.
  prefs: []
  type: TYPE_NORMAL
- en: When everything is running normally, QPS fluctuates with application usage.
    When there is a problem, QPS fluctuations correlate with other metrics. To analyze
    performance or diagnose a problem, I glance at QPS to see where (in a chart) its
    value is abnormal. Then I correlate that period (time along the X axis of the
    chart) with other, more specific metrics in the spectra. As a KPI, QPS indicates
    a problem, but other metrics pinpoint the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'All abnormal changes in QPS are suspect and worth investigating. Most, if not
    all, engineers know that a drop in QPS is bad, but an abnormal increase in QPS
    can be equally bad or worse. Also bad but more rare is flatline QPS—a nearly constant
    QPS value—because minor fluctuations are normal. When QPS changes abnormally,
    the first question is usually: what’s the cause? I address that later in this
    chapter (see [“Cause and Effect”](#cause-and-effect)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'MySQL exposes another closely related metric: `Questions`. (The term *question*
    is only used for this metric; it’s not used for anything else inside MySQL.) `Questions`
    counts only queries sent by clients, not queries executed by stored programs.
    For example, queries executed by a trigger do *not* count in `Questions` because
    a client did not send them; but they do count in `Queries`. Since `Questions`
    is a subset of `Queries`, the difference is only informational, and monitoring
    `Questions` is optional. For QPS, always use `Queries`.'
  prefs: []
  type: TYPE_NORMAL
- en: TPS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the application relies on explicit, multistatement transactions, then transactions
    per second (TPS) is as important as QPS. For some applications, a database transaction
    represents a unit of work in the application, so TPS is a better rate than QPS
    because the application unit of work is all or nothing, which is why it’s executed
    in an explicit transaction.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: An *implicit transaction* is a single SQL statement with [`autocommit`](https://oreil.ly/zrjQK)
    enabled, which is the default. An *explicit transaction* starts with `BEGIN` or
    `START TRANSACTION` and ends with either `COMMIT` or `ROLLBACK`, regardless of
    `autocommit`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In MySQL, explicit transaction throughput is revealed by three metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Com_begin`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_commit`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_rollback`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normally, the rate of `Com_begin` and `Com_commit` are the same because every
    transaction must begin and successful transactions must commit. When there’s a
    problem that causes transactions to stall (one of the [“Common Problems”](ch08.html#trx-problems)),
    the rate of `Com_begin` exceeds the other two metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Use `Com_commit` to measure TPS because transaction throughput implies successful
    transactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'A transaction rollback is supposed to indicate an error—since transactions
    are all or nothing—but the `ROLLBACK` statement is also commonly used for cleanup:
    it ensures that the previous transaction—if any—is closed before starting the
    next transaction. Consequently, the rollback rate might not be zero. As with most
    metrics, normal and stable is the goal (see [“Normal and Stable: The Best Database
    Is a Boring Database”](#normal-and-stable)).'
  prefs: []
  type: TYPE_NORMAL
- en: Another gauge metric that indicates the current number of active transactions
    is `innodb.trx_active_transactions`.
  prefs: []
  type: TYPE_NORMAL
- en: '`BEGIN` starts a transaction, but a transaction is not *active* until, generally
    speaking, a query accesses a table. For example, `BEGIN; SELECT NOW();` starts
    a transaction that is not active because no query accesses a table.'
  prefs: []
  type: TYPE_NORMAL
- en: Read/write
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are nine read/write metrics named according to a type of SQL statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Com_select`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_delete`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_delete_multi`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_insert`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_insert_select`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_replace`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_replace_select`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_update`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_update_multi`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, `Com_select` is a counter for the number of `SELECT` statements.
    The `_multi` suffix in `Com_delete_multi` and `Com_update_multi` refers to queries
    that reference multiple tables. A multitable `DELETE` increments only `Com_delete_multi`,
    whereas a single-table `DELETE` only updates `Com_delete`. The same is true for
    `UPDATE` statements with respect to `Com_update_multi` and `Com_update`.
  prefs: []
  type: TYPE_NORMAL
- en: Read/write metrics reveal the important types and throughputs of queries that
    constitute `Queries`. These metrics do not fully account for `Queries`; they are
    only the most important metrics with respect to performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Monitor these metrics as individual rates and percentages of `Queries`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Com_select` indicates the read percentage of the workload:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (Com_select / Queries) × 100.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The sum of the other eight metrics indicates the write percentage of the workload.^([2](ch06.html#idm45829110678032))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The read and write percentages will *not* equal 100% because `Queries` accounts
    for other types of SQL statements: `SHOW`, `FLUSH`, `GRANT`, and many more. If
    the remaining percentage is suspiciously high (more than 20%), it probably won’t
    affect performance, but it’s worth investigating: examine other `Com_` metrics
    to account for other types of SQL statements.'
  prefs: []
  type: TYPE_NORMAL
- en: Admin
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Admin metrics refer to commands that, typically, only database administrators
    invoke:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Com_flush`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_kill`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_purge`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_admin_commands`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first three metrics refer to [`FLUSH`](https://oreil.ly/O6j77), [`KILL`](https://oreil.ly/fMbiY),
    and [`PURGE`](https://oreil.ly/czxYb), respectively. These commands could affect
    performance, but they should be very rare. If not, ask your DBA or cloud provider
    what they’re doing.
  prefs: []
  type: TYPE_NORMAL
- en: The last metric, `Com_admin_commands`, is an oddity. It refers to other admin
    commands for which there are not specific `Com_` status variables. For example,
    the MySQL protocol has a ping command that is commonly used by MySQL client drivers
    to test the connection. This is harmless in moderation, but problems can result
    from a lack of moderation. Don’t expect `Com_admin_commands` to indicate any problems,
    but monitoring it is still a best practice.
  prefs: []
  type: TYPE_NORMAL
- en: SHOW
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'MySQL has over 40 [`SHOW`](https://oreil.ly/u7Xzs) statements, most of which
    have a corresponding `Com_show_` metric. `SHOW` commands never change MySQL or
    modify data, so in that sense they’re harmless. But they are queries, which means
    they use a thread, time, and resources in MySQL. `SHOW` commands can stall, too.
    `SHOW GLOBALS STATUS`, for example, can take a full second or more on a busy server.
    Consequently, it’s a best practice to monitor at least the following 10 metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Com_show_databases`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_engine_status`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_errors`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_processlist`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_slave_status`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_status`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_table_status`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_tables`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_variables`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_show_warnings`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As of MySQL 8.0.22, monitor `Com_show_replica_status` instead of `Com_show_slave_status`.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t expect `SHOW` metrics to indicate any problems, but don’t be surprised
    if one does because it wouldn’t be the first time.
  prefs: []
  type: TYPE_NORMAL
- en: Threads and Connections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Threads_running` is one of the four [“Key Performance Indicators”](#kpi).
    It indicates how hard MySQL is working because it’s directly connected to active
    query execution (when a client connection is not executing a query, its thread
    is idle), and it’s effectively limited by the number of CPU cores. Let’s come
    back to `Threads_running` after looking at related metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Threads and connections are one spectrum because they are directly related:
    MySQL runs one thread per client connection. The four most important metrics for
    threads and connections are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Connections`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Max_used_connections`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Threads_connected`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Threads_running`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Connections` is the number of connection attempts to MySQL, both successful
    and failed. It reveals the stability of the application connection pool to MySQL.
    Usually, application connections to MySQL are long-lived, where *long* is at least
    a few seconds, if not minutes or hours. Long-lived connections avoid the overhead
    of establishing a connection. When the application and MySQL are on the same local
    network, the overhead is negligible: 1 millisecond or less. But network latency
    between the application and MySQL adds up quickly when multiplied by hundreds
    of connections and multiplied again by the connection rate. (`Connections` is
    a counter but expressed as a rate: connections/second.) MySQL can easily handle
    hundreds of connections per second, but if this metric reveals an abnormally high
    rate of connections, find and fix the root cause.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Max_used_connections` as a percentage of [`var.max_connections`](https://oreil.ly/MVZaQ)
    reveals connection utilization. The default value for `var.max_connections` is
    151, which is probably too low for most applications but *not* because the application
    needs more connections for performance. The application needs more connections
    only because each application instance has its own connection pool. (I presume
    the application is scaled out.) If the connection pool size is 100 and there are
    3 application instances, then the application (all instances) can create 300 connections
    to MySQL. That is the main reason why 151 max connections is not sufficient.'
  prefs: []
  type: TYPE_NORMAL
- en: A common misconception is that the application needs thousands of connections
    to MySQL for performance or to support thousands of users. This is patently not
    true. The limiting factor is threads, not connections—more on `Threads_running`
    in a moment. A single MySQL instance can easily handle thousands of connections.
    I’ve seen 4,000 connections in production and more in benchmarks. But for most
    applications, several hundred connections (total) is more than sufficient. If
    your application demonstrably requires several thousand connections, then you
    need to shard (see [Chapter 5](ch05.html#ch05)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The real problem to monitor and avoid is 100% connection utilization. If MySQL
    runs out of available connections, an application outage is essentially guaranteed.
    If connection utilization rises suddenly, approaching 100%, the cause is always
    an external problem, or bug, or both. (MySQL cannot connect to itself, so the
    cause must be external.) In response to an external problem—like a network issue,
    for example—the application creates more connections than normal. Or, a bug causes
    the application not to close connections—commonly known as a *connection leak*.
    Or, an external problem triggers a bug in the application—I’ve seen it happen.
    Either way, the underlying cause is always external: something outside MySQL is
    connecting to MySQL and using all the connections.'
  prefs: []
  type: TYPE_NORMAL
- en: As clients connect and disconnect, MySQL increments and decrements the `Threads_connected`
    gauge metric. The name of this metric is a little misleading since *clients* are
    connected, not threads, but it reflects that MySQL runs one thread per client
    connection.
  prefs: []
  type: TYPE_NORMAL
- en: '`Threads_running` is a gauge metric and an implicit utilization relative to
    the number of CPU cores. Although `Threads_running` can spike into the hundreds
    and thousands, performance will degrade sharply at much lower values: around twice
    the number of CPU cores. The reason is simple: one CPU core runs one thread. When
    the number of threads running is greater than the number of CPU cores, it means
    that some threads are stalled—waiting for CPU time. This is analogous to rush
    hour traffic: thousands of cars in gridlock on the highway, engines running but
    barely moving. (Or, for electric cars: batteries running but barely moving.) Consequently,
    it’s normal for `Threads_running` to be quite low: less than 30. Bursts lasting
    seconds or less are possible with good hardware and an optimized workload, but
    sustained (normal and stable) `Threads_running` should be as low as possible.
    As in [“Less QPS Is Better”](ch03.html#less-qps-is-better), less `Threads_running`
    is better too.'
  prefs: []
  type: TYPE_NORMAL
- en: 'High throughput (QPS) with very low threads running is a strong indication
    of efficient performance because there is only one way to achieve both: very fast
    query response time. [Table 6-2](#threads-running-qps) lists threads running and
    QPS from five real (and different) applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6-2\. Threads running and QPS
  prefs: []
  type: TYPE_NORMAL
- en: '| Threads running | QPS |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 8,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 6,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 30,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 23,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 33,000 |'
  prefs: []
  type: TYPE_TB
- en: 'The second and third rows highlight how profoundly the application workload
    affects performance: with one workload, 6,000 QPS needs 8 threads running; but
    another workload achieves 5x QPS (30,000) with the same number of threads. For
    the last row, 33,000 QPS is not exceptionally high, but that database is sharded:
    total QPS across all shards exceeds one million. Empirically, high throughput
    is possible with few threads running.'
  prefs: []
  type: TYPE_NORMAL
- en: Temporary Objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Temporary objects are temporary files and tables that MySQL uses for various
    purposes: sorting rows, large joins, and so on. Three metrics count the number
    of temporary tables on disk, temporary tables in memory, and temporary files (on
    disk) created:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Created_tmp_disk_tables`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Created_tmp_tables`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Created_tmp_files`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These metrics are rarely zero because temporary objects are common and harmless
    as long as the rates are stable. The most impactful metric is `Created_tmp_disk_tables`,
    which is the reciprocal of `Created_tmp_tables`. When MySQL needs a temporary
    table to execute a query (for `GROUP BY`, for example), it starts with an in-memory
    temporary table and increments `Created_tmp_tables`. This shouldn’t impact performance
    because it’s in memory. But if that temporary table grows larger than [`var.tmp_table_size`](https://oreil.ly/4plVm)—the
    system variable that determines the in-memory temporary table size—then MySQL
    writes the temporary table to disk and increments `Created_tmp_disk_tables`. In
    moderation, this probably won’t impact performance, but it certainly doesn’t help,
    either, because storage is significantly slower than memory. The same is true
    for `Created_tmp_files`: acceptable in moderation, but not helping performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As of MySQL 8.0, `Created_tmp_disk_tables` does *not* count temporary tables
    created on disk. This is due to the new storage engine used for internal temporary
    tables: `TempTable`. The corresponding metric is a Performance Schema memory instrument:
    `memory/temptable/physical_disk`. (A related instrument is `memory/temptable/physical_ram`,
    which tracks `TempTable` memory allocation for in-memory temporary tables.) If
    you’re using MySQL 8.0, talk with your DBA to ensure that this metric is collected
    and reported correctly.'
  prefs: []
  type: TYPE_NORMAL
- en: Since temporary objects are side effects of queries, these metrics are most
    revealing when a change in one correlates to a change in KPIs. For example, a
    sudden increase in `Created_tmp_disk_tables` coupled with a sudden increase in
    response time screams “Look at me!”^([3](ch06.html#idm45829110575632))
  prefs: []
  type: TYPE_NORMAL
- en: Prepared Statements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Prepared statements are a double-edged sword: used properly, they increase
    efficiency; but used improperly (or unknowingly), they increase waste. The proper
    and most efficient way to use prepared statements is to prepare once and execute
    many times, which is counted by two metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Com_stmt_prepare`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_stmt_execute`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Com_stmt_execute` should be significantly greater than `Com_stmt_prepare`.
    If it isn’t, then prepared statements are increasing waste due to extra queries
    to prepare and close the statement. The worst case is when these metrics are one-to-one,
    or close to it, because a single query incurs two wasted roundtrips to MySQL:
    one to prepare and another to close the statement. When MySQL and the application
    are on the same local network, two extra roundtrips might not be noticeable, but
    they are pure waste multiplied by QPS. For example, an extra 1 millisecond at
    1,000 QPS is a wasted second—a second during which another 1,000 queries could
    have been executed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside from the performance implications, you should monitor these prepared
    statement metrics because the application might be using prepared statements unintentionally.
    For example, the MySQL driver for the Go programming language defaults to using
    prepared statements for security: to avoid SQL injection vulnerabilities. At first
    glance (or any number of glances), you would not think that the Go code in [Example 6-4](#hidden-ps)
    uses a prepared statement, but it does.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-4\. Hidden prepared statement
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the documentation for the MySQL driver that the application uses. If
    it does not explicitly mention if and when it uses prepared statements, then verify
    manually: on a development instance of MySQL (your laptop, for example), enable
    the [general query log](https://oreil.ly/1Vczu) and write a test program to execute
    SQL statements using the same methods and function calls that the application
    uses. The general log indicates when prepared statements are used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the number of open prepared statements is limited to [`var.max_​pre⁠pared_​stmt_count`](https://oreil.ly/K2MWz),
    which is 16,382 by default. (Even 1,000 prepared statements is a lot for one application,
    unless the application is programmatically generating statements.) This gauge
    metric reports the current number of open prepared statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Prepared_stmt_count`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t let `Prepared_stmt_count` reach `var.max_prepared_stmt_count`, else the
    application will stop working. If this happens, it’s an application bug due to
    leaking (not closing) prepared statements.
  prefs: []
  type: TYPE_NORMAL
- en: Bad SELECT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Four metrics count the occurrence of `SELECT` statements that are usually bad
    for performance:^([4](ch06.html#idm45829110547888))
  prefs: []
  type: TYPE_NORMAL
- en: '`Select_scan`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Select_full_join`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Select_full_range_join`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Select_range_check`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Select_scan` and `Select_full_join` are described in [Chapter 1](ch01.html#ch01):
    [“Select scan”](ch01.html#Select-scan) and [“Select full join”](ch01.html#Select-full-join),
    respectively. The only difference here is that these two metrics apply globally
    (all queries).'
  prefs: []
  type: TYPE_NORMAL
- en: '`Select_full_range_join` is the lesser evil of `Select_full_join`: instead
    of a full table scan to join a table, MySQL uses an index to do a range scan.
    It’s possible that the range is limited and response time for the `SELECT` is
    acceptable, but it’s bad enough to warrant its own metric.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Select_range_check` is similar to but worse than `Select_full_range_join`.
    It’s easiest to explain with a simple query: `SELECT * FROM t1, t2 WHERE t1.id
    > t2.id`. When MySQL joins tables `t1` and `t2` (in that order), it does *range
    checks* on `t2`: for every value from `t1`, MySQL checks if it can use an index
    on `t2` to do a range scan or index merge. Rechecking every value from `t1` is
    necessary because, given the query, MySQL cannot know `t1` values ahead of time.
    But rather than do the worst possible execution plan—`Select_full_join`—MySQL
    keeps trying to use an index on `t2`. In the `EXPLAIN` output, the `Extra` field
    for `t2` lists “Range checked for each record,” and `Select_range_check` is incremented
    once for the table. The metric is *not* incremented for each range change; it’s
    incremented once to signal that a table was joined by doing range checks.'
  prefs: []
  type: TYPE_NORMAL
- en: Bad `SELECT` metrics should be zero or virtually zero (if you round down). A
    few `Select_scan` or `Select_full_range_join` are inevitable, but the other two—`Select_full_join`
    and `Select_range_check`—should be found and fixed immediately if not zero.
  prefs: []
  type: TYPE_NORMAL
- en: Network Throughput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The MySQL protocol is very efficient and rarely uses any noticeable amount
    of network bandwidth. Usually, it’s the network affecting MySQL rather than MySQL
    affecting the network. Nevertheless, it’s good to monitor network throughput as
    recorded by MySQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Bytes_sent`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Bytes_received`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since these metrics count network bytes sent and received, respectively, convert
    the values to network units: Mbps or Gbps, whichever matches the link speed of
    the server running MySQL. Gigabit links are most common, even in the cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Metric graphing systems convert counters to rates by default, but you probably
    need to multiply these metrics by eight (8 bits per byte) and set the graph unit
    to bits to display as Mbps or Gbps.
  prefs: []
  type: TYPE_NORMAL
- en: 'I have seen MySQL saturate a network only once. The cause was related to a
    system variable that’s not usually a problem: [`var.binlog_row_image`](https://oreil.ly/tboxy).
    This system variable is related to replication that [Chapter 7](ch07.html#ch07)
    addresses in more detail, but the short version is: this system variable controls
    whether or not `BLOB` and `TEXT` columns are logged in the binary logs and replicated.
    The default value is `full`, which logs and replicates `BLOB` and `TEXT` columns.
    Normally, that’s not a problem, but one application created a perfect storm by
    having all of the following attributes at once:'
  prefs: []
  type: TYPE_NORMAL
- en: Using MySQL as a queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huge `BLOB` values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write-heavy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High throughput
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These access patterns combined to replicate a small flood of data, causing
    major replication lag. The solution was changing `var.binlog_row_image` to `noblob`
    to stop replicating the `BLOB` values, which didn’t need to be replicated. This
    true story leads to the next spectrum: replication.'
  prefs: []
  type: TYPE_NORMAL
- en: Replication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Lag* is the bane of replication: the delay between a write on the source MySQL
    instance and when that write is applied on a replica MySQL instance. When replication
    (and the network) is working normally, replication lag is subsecond, limited only
    by network latency.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Before MySQL 8.0.22, the replica lag metric and command were `Sec​onds_​Behind_Master`
    and `SHOW SLAVE STATUS`, respectively. As of MySQL 8.0.22, the metric and command
    are `Sec​onds_​Behind_Source` and `SHOW REPLICA STATUS`. I use the current metric
    and command in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'MySQL has an infamous gauge metric for replication lag: `Seconds_Behind_Source`.
    This metric is infamous because it’s not wrong but it’s also not what you expect.
    It can jump between zero and a high value, which is as amusing as it is confusing.
    Consequently, the best practice is to ignore this metric and, instead, use a tool
    like [`pt-heartbeat`](https://oreil.ly/VMg4c) to measure true replication lag.
    Then you have to configure your MySQL monitor software (or service) to measure
    and report *replication lag* from `pt-heartbeat`. Since `pt-heartbeat` has been
    around for so long, some MySQL monitors support it natively; and there’s a good
    chance that the engineers who manage your MySQL instances are already using it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'MySQL exposes one metric related to replication that is not infamous: `Binlog_cache_disk_use`.
    [Chapter 7](ch07.html#ch07) clarifies the following details; for now, a high level
    explanation is sufficient. For each client connection, a in-memory binary log
    cache buffers writes before they’re written to the binary log files—from which
    the writes replicate to replicas. If the binary log cache is too small to hold
    all the writes for a transaction, the changes are written to disk and `Binlog_cache_disk_use`
    is incremented. In moderation, this is acceptable, but it shouldn’t be frequent.
    If it becomes frequent, you can alleviate it by increasing the binary log cache
    size: [`var.binlog_cache_size`](https://oreil.ly/0TEIJ).'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the example in the previous section, we know that `var.binlog_row_image`
    affects the binary log cache, too: full row images can require a lot of space
    if the table has `BLOB` or `TEXT` columns.'
  prefs: []
  type: TYPE_NORMAL
- en: Data Size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Chapter 3](ch03.html#ch03) explains why less data is more performance. Monitoring
    data size is important because it’s common for databases to grow larger than expected.
    If data growth is due to application growth—the application is becoming increasingly
    popular—then it’s a good problem to have, but it’s a problem nevertheless.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s also easy to overlook because MySQL performance scales effortlessly as
    data grows, but not forever. A database can grow from 10 GB to 300 GB—a 30x increase—and
    not encounter performance issues if queries and access patterns are optimized
    well. But another 30x increase to 9 TB? Not possible. Even a 3x increase to 900
    GB is asking too much—it could happen if the access patterns are exceptionally
    favorable, but don’t bet on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'MySQL exposes table sizes (and other table metadata) in an Information Schema
    table: [`information_schema.tables`](https://oreil.ly/PqATu). The query in [Example 6-5](#db-size-query)
    returns the size of each database in gigabytes.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-5\. Database sizes (GB)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The query in [Example 6-6](#tbl-size-query) returns the size of each table in
    gigabytes.
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-6\. Table sizes (GB)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: There is no standard for database and table size metrics. Query and aggregate
    values from `information_schema.tables` to suit your needs. At a bare minimum,
    collect database sizes ([Example 6-5](#db-size-query)) every hour. It’s better
    to be more precise and collect table sizes every 15 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Be sure that, wherever you store or send MySQL metrics, you can retain data
    size metrics for at least a year. Near-term data growth trending is used to estimate
    when the disk will run out of space; or, in the cloud, when more storage will
    need to be provisioned. Long-term data growth trending is used to estimate when
    sharding ([Chapter 5](ch05.html#ch05)) becomes necessary, as covered in [“Practice:
    Four-Year Fit”](ch05.html#ch05-ai).'
  prefs: []
  type: TYPE_NORMAL
- en: InnoDB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[InnoDB](https://oreil.ly/4b5qP) is complex.'
  prefs: []
  type: TYPE_NORMAL
- en: However, since it is the default MySQL storage engine, we must steel ourselves
    to embrace it. A deep dive is not necessary—or even possible within the limits
    of this book. Although this section is long, it barely breaks the surface of InnoDB
    internals. Nevertheless, the following InnoDB metrics reveal some of the inner
    workings of the storage engine responsible for reading and writing data.
  prefs: []
  type: TYPE_NORMAL
- en: History list length (metric)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'History list length (HLL) is a curious metric because every engineer that uses
    MySQL learns what it *means*, but very few know what it *is*. When HLL increases
    significantly over a period of minutes or hours, it means that InnoDB is keeping
    a significant number of old row versions instead of purging them because one or
    more long-running transaction has not committed or was abandoned without being
    rolled back due to an undetected lost client connection. All of that, which I
    explain later in [“History List Length”](ch08.html#hll), is revealed by one gauge
    metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.trx_rseg_history_len`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A normal value for `innodb.trx_rseg_history_len` is less than 1,000. You should
    monitor and alert if HLL is greater than 100,000. Contrary to [“Wild Goose Chase
    (Thresholds)”](#thresholds) and [“Alert on User Experience and Objective Limits”](#alert-on)
    later in this chapter, this is a reliable threshold and actionable alert. The
    action: find and terminate the long-running or abandoned transaction.'
  prefs: []
  type: TYPE_NORMAL
- en: History list length does not directly affect performance, but it is a harbinger
    of trouble—do not ignore it. The trouble relates to the fact that, since InnoDB
    is a transactional storage engine, every query on an InnoDB table is a transaction.
    Transactions incur overhead, and the HLL metric reveals when a long-running or
    abandoned transaction is causing InnoDB to handle an unreasonable amount of overhead.
    Some overhead is necessary—even beneficial—but too much amounts to waste, and
    waste is antithetical to performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s so much more to say about transactions and HLL that it won its own
    chapter: [Chapter 8](ch08.html#ch08). For now, let’s stay focused on metrics because
    we’ve only begun with InnoDB.'
  prefs: []
  type: TYPE_NORMAL
- en: Deadlock
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A deadlock occurs when two (or more) transactions hold row locks that the other
    transaction needs. For example, transaction *A* holds a lock on row 1 and needs
    a lock on row 2, and transaction *B* holds a lock on row 2 and needs a lock on
    row 1. MySQL automatically detects and rolls back one transaction to resolve the
    deadlock, and increments one metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.lock_deadlocks`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deadlocks should not occur. A prevalence of deadlocks is related to the concurrency
    access pattern trait (see [“Concurrency”](ch04.html#ap-concurrency)). Highly concurrent
    data access must be designed (in the application) to avoid deadlocks by ensuring
    that different transactions accessing the same rows (or nearby rows) examine the
    rows in roughly the same order. In the earlier example of transaction *A* and
    transaction *B*, they access the same two rows in opposite order, which can lead
    to a deadlock when the transactions execute at the same time. To learn more about
    deadlocks, read [“Deadlocks in InnoDB”](https://oreil.ly/UpX0r) in the MySQL manual.
  prefs: []
  type: TYPE_NORMAL
- en: Row lock
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Row lock metrics reveal *lock contention*: how quickly (or not) queries acquire
    row locks to write data. The most fundamental row lock metrics are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.lock_row_lock_time`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.lock_row_lock_current_waits`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.lock_row_lock_waits`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.lock_timeouts`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first metric, `innodb.lock_row_lock_time`, is a rare type: the total number
    of milliseconds spent acquiring row locks. It’s in the class of response time
    metrics (see [“Response Time”](#field-response-time)), but unlike [“Query Response
    Time”](#metrics-qrt), it is collected as a running total rather than a histogram.
    Consequently, it’s not possible to report `innodb.lock_row_lock_time` as a percentile,
    which would be ideal. And reporting it as a rate (see [“Rate”](#field-rate)) is
    nonsensical: milliseconds per second. Instead, this metric must be reported as
    a difference: if 500 milliseconds at time T1 and 700 milliseconds at time T2,
    then report T2 value – T1 value = 200 ms. (Use maximum for the chart rollup function.
    Don’t average the data points because it’s better to see the worst case.) As a
    response time metric, lower is better. The value of `innodb.lock_row_lock_time`
    cannot be zero (unless the workload is read-only and never needs to acquire a
    single row lock) because it takes a nonzero amount of time to acquire locks. The
    goal, as always, is that the metric is normal and stable. When it’s not, the other
    row lock metrics will not be normal either.'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.lock_row_lock_current_waits` is a gauge metric for the current number
    of queries waiting to acquire a row lock. `innodb.lock_row_lock_waits` is a count
    of the number of queries that waited to acquire a row. The two variables are essentially
    the same: the former is a current gauge, and the latter is a historical counter
    and rate. When the rate of row lock waits increases, it’s a sure sign of trouble
    because MySQL does not wait by accident: something must cause it to wait. In this
    case, the cause will be concurrent queries accessing the same (or nearby) rows.'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.lock_timeouts` is incremented when a row lock wait times out. The default
    row lock wait timeout is 50 seconds, configured by [`var.innodb_lock_wait_timeout`](https://oreil.ly/4kCLg),
    and applies *per row lock*. This is far too long for any normal application to
    wait; I advise a much lower value: 10 seconds or less.'
  prefs: []
  type: TYPE_NORMAL
- en: 'InnoDB locking is sophisticated and nuanced. As a result, lock contention is
    *not* a common problem unless the workload exhibits three particular access patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: Write-heavy ([“Read/Write”](ch04.html#ap-read-write))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High throughput ([“Throughput”](ch04.html#ap-throughput))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High concurrency ([“Concurrency”](ch04.html#ap-concurrency))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That would be a very particular application and workload. But lock contention
    can become a problem for any application and workload (even with low throughput
    and concurrency), so always monitor rock lock metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Data throughput
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Data throughput in bytes per seconds is measured by two metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Innodb_data_read`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Innodb_data_written`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data throughput is rarely an issue: SSD is fast; PCIe and NVMe made it even
    faster. Regardless, monitoring data throughput is a best practice because storage
    throughput is limited, especially in the cloud. Do not expect to achieve published
    storage throughput rates because published rates are measured under ideal conditions:
    data straight to (or from) disk. InnoDB is super fast and efficient, but it’s
    still a complex layer of software between the data and the disk that inherently
    precludes achieving published storage throughput rates.'
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Be careful about throughput in the cloud: storage is unlikely to be locally
    attached, which limits throughput to network speeds. 1 Gbps equals 125 MB/s, which
    is throughput similar to spinning disks.'
  prefs: []
  type: TYPE_NORMAL
- en: IOPS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'InnoDB has a deep and sometimes complicated relationship with storage I/O capacity,
    measured in IOPS. But first, the easy part: InnoDB read and write IOPS are counted
    by two metrics, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.os_data_reads`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.os_data_writes`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These metrics are counters, so like other counters, they are converted to and
    expressed as rates by metric graphing systems. Be sure to set the graph unit to
    IOPS for each.
  prefs: []
  type: TYPE_NORMAL
- en: The performance raison d’être of InnoDB is to optimize and reduce storage I/O.
    Although high IOPS are impressive from an engineering point of view, they are
    the bane of performance because storage is slow. But storage is required for durability—persisting
    data changes to disk—so InnoDB goes to great lengths to be fast *and* durable.
    Consequently, as in [“Less QPS Is Better”](ch03.html#less-qps-is-better), fewer
    IOPS are better.
  prefs: []
  type: TYPE_NORMAL
- en: 'But don’t underutilize IOPS, either. If your company runs its own hardware,
    the maximum number of storage IOPS is determined by the storage device—check the
    device specifications, or ask the engineers who manage the hardware. In the cloud,
    storage IOPS are allocated or provisioned, so it’s usually easier to tell the
    maximum because you purchase the IOPS—check the storage settings, or ask the cloud
    provider. If InnoDB never uses more than 2,000 IOPS, for example, then don’t purchase
    (or provision) 40,000 IOPS: InnoDB simply won’t use the excess IOPS. By contrast,
    if InnoDB constantly uses the maximum number of storage IOPS, then either the
    application workload needs to be optimized to reduce storage I/O (see Chapters
    [1](ch01.html#ch01)–[5](ch05.html#ch05)), or InnoDB legitimately needs more IOPS.'
  prefs: []
  type: TYPE_NORMAL
- en: 'InnoDB I/O capacity for *background tasks* is largely configured by [`var​.inno​db_​io_capacity`](https://oreil.ly/zU6iW)
    and [`var.innodb_io_capacity_max`](https://oreil.ly/LiilY), two system variables
    that default to 200 and 2,000 IOPS, respectively. (There are other variables,
    but I must gloss over them to stay focused on metrics. To learn more, read [“Configuring
    InnoDB I/O Capacity”](https://oreil.ly/G9Bcw) in the MySQL manual.) Background
    tasks include page flushing, change buffer merging, and more. In this book, I
    cover only page flushing, which is arguably the single most important background
    task. Limiting background task storage I/O ensures that InnoDB does not overwhelm
    the server. It also allows InnoDB to optimize and stabilize storage I/O rather
    than bombard the storage device with erratic access. By contrast, foreground tasks
    do not have any configurable I/O capacities or limits: they use as many IOPS as
    necessary and available. The primary foreground task is executing queries, but
    this does not mean queries use high or excessive IOPS because, remember, the performance
    raison d’être of InnoDB is to optimize and reduce storage I/O. For reads, the
    buffer pool purposefully optimizes and reduces IOPS. For writes, page flushing
    algorithms and the transaction log purposefully optimize and reduce storage I/O.
    The following sections reveal how.'
  prefs: []
  type: TYPE_NORMAL
- en: 'InnoDB can achieve high IOPS, but can the application? Probably not because
    there are many layers between the application and the IOPS that preclude the former
    from achieving a high number of the latter. In my experience, applications use
    hundreds to thousands of IOPS, and exceptionally optimized applications that are
    “going viral” push around 10,000 IOPS on a single MySQL instance. Recently, I
    was benchmarking MySQL in the cloud and hit a ceiling at 40,000 IOPS. The cloud
    provider publishes 80,000 IOPS as the maximum and allows me to provision that,
    but their storage system is capped at 40,000 IOPS. Point being: InnoDB can achieve
    high IOPS, but everything around it is a different question.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This section is only a primer on InnoDB I/O because it underlies the final
    three InnoDB spectra that consume IOPS: [“Buffer pool efficiency”](#metrics-buff-pool),
    [“Page flushing”](#metrics-page-flushing), and [“Transaction log”](#metrics-trx-log).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more InnoDB I/O, start by reading [“Configuring InnoDB I/O Capacity”](https://oreil.ly/w9MOg)
    in the MySQL manual. To really dive into the nitty-gritty details of InnoDB I/O,
    read an illuminating three-part blog post by renowned MySQL experts Yves Trudeau
    and Francisco Bordenave: [“Give Love to Your SSDs: Reduce innodb_io_capacity_max!”](https://oreil.ly/q0L61),
    [“InnoDB Flushing in Action for Percona Server for MySQL”](https://oreil.ly/ZY2Xe),
    and [“Tuning MySQL/InnoDB Flushing for a Write-Intensive Workload”](https://oreil.ly/P03EX).
    But finish this chapter first because it’s a great foundation for those blog posts.'
  prefs: []
  type: TYPE_NORMAL
- en: InnoDB works with data in memory, not on disk. It reads data from disk when
    necessary, and it writes data to disk to make changes durable, but these are lower
    level operations into which the next three sections delve. At a higher level,
    InnoDB works with data in memory because storage is too slow—even with a million
    IOPS. Consequently, there is not a direct correlation between queries, rows, and
    IOPS. Writes always consume IOPS (for durability). Reads can execute without consuming
    any IOPS, but it depends on buffer pool efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Buffer pool efficiency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The InnoDB buffer pool is an *in-memory* cache of table data and other internal
    data structures. From [“InnoDB Tables Are Indexes”](ch02.html#tables-are-indexes),
    you know that the buffer pool contains index pages—more on pages in the next section.
    InnoDB certainly understands rows, but internally it’s far more concerned with
    pages. At this depth of MySQL performance, the focus changes from rows to pages.
  prefs: []
  type: TYPE_NORMAL
- en: 'At a high level, InnoDB accesses (reads and writes) all data by pages in the
    buffer pool. (Low-level writes are more complicated and addressed in the last
    InnoDB section: [“Transaction log”](#metrics-trx-log).) If data is not in the
    buffer pool when accessed, InnoDB reads it from storage and saves it in the buffer
    pool.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Buffer pool efficiency* is the percentage of data accessed from memory, calculated
    from two metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Innodb_buffer_pool_read_request`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Innodb_buffer_pool_reads`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Innodb_buffer_pool_read_request` counts all requests to access data in the
    buffer pool. If the requested data is *not* in memory, InnoDB increments `Inno​db_​buf​fer_​pool_reads`
    and loads the data from disk. Buffer pool efficiency equals (`Innodb_buffer_pool_read_request`
    / `Innodb_buffer_pool_reads`) × 100.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The word *read* in these metrics does not mean `SELECT`. InnoDB reads data
    from the buffer pool for all queries: `INSERT`, `UPDATE`, `DELETE`, and `SELECT`.
    For example, on `UPDATE`, InnoDB reads the row from the buffer pool. If not in
    the buffer pool, it loads the row from disk into the buffer pool.'
  prefs: []
  type: TYPE_NORMAL
- en: Buffer pool efficiency will be very low when MySQL starts. This is normal; it’s
    called a *cold buffer pool*. Loading data warms the buffer pool—like throwing
    logs on a fire. It usually takes several minutes to fully warm the buffer pool,
    which is indicated when buffer pool efficiency reaches its normal and stable value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Buffer pool efficiency should be extremely close to 100%—ideally 99.0% or greater—but
    don’t fixate on the value. Technically, this metric is a cache hit ratio, but
    that’s not how it’s used. A cache hit ratio reveals little beyond the metric:
    values are cached, or they’re not. On the contrary, buffer pool efficiency reveals
    how well InnoDB is able to keep frequently accessed data—the working set—in memory
    while balancing speed and durability. To put it colorfully, buffer pool efficiency
    is how well InnoDB can keep a match lit in a hurricane. The working set is the
    flame; durability is the rain (it dampens throughput);^([5](ch06.html#idm45829110227344))
    the application is the wind.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In a bygone era, performance equated to cache hit ratios. Today, that is no
    longer true: performance is query response time. If buffer pool efficiency is
    extremely low but response time is great, then performance is great. That probably
    won’t happen, but the point is not to lose focus—recall [“North Star”](ch01.html#north-star).'
  prefs: []
  type: TYPE_NORMAL
- en: 'If total data size is less than available memory, then all data can fit in
    the buffer pool at once. (Buffer pool size is configured by [`var.innodb_buffer_pool_size`](https://oreil.ly/N4lnI).
    Or, as of MySQL 8.0.3, enabling [`var.innodb_dedicated_server`](https://oreil.ly/I5KaC)
    automatically configures buffer pool size and other related system variables.)
    In this case, buffer pool efficiency is a nonissue and performance bottlenecks—if
    any—will occur in CPU or storage (since all data is in memory). But this case
    is the exception, not the norm. The norm is total data size being *far greater*
    than available memory. In this (normal) case, buffer pool efficiency has three
    primary influences:'
  prefs: []
  type: TYPE_NORMAL
- en: Data access
  prefs: []
  type: TYPE_NORMAL
- en: Data access brings data into the buffer pool. The data age access pattern trait
    (see [“Data Age”](ch04.html#ap-data-age)) is the primary influence because only
    new data needs to be loaded into the buffer pool.
  prefs: []
  type: TYPE_NORMAL
- en: Page flushing
  prefs: []
  type: TYPE_NORMAL
- en: Page flushing allows data to be evicted from the buffer pool. Page flushing
    is necessary for new data to be loaded into the buffer pool. The next section
    goes into more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Available memory
  prefs: []
  type: TYPE_NORMAL
- en: The more data that InnoDB keeps in memory, the less it needs to load or flush
    data. In the exceptional case previously mentioned, when all data fits in memory,
    buffer pool efficiency is a nonissue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Buffer pool efficiency reveals the combined effect of those three influences.
    As a combined effect, it cannot pinpoint one cause. If its value is lower than
    normal, the cause could be one, two, or all three influences. You must analyze
    all three to determine which is the greatest *or* the most feasible to change.
    For example, as detailed in [Chapter 4](ch04.html#ch04), changing access patterns
    is a best practice for improving performance, but if you’re page-deep in MySQL
    performance, you’ve probably already done that. In that case, more memory or faster
    storage (more IOPS) might be more feasible—and more justified since you’ve already
    optimized the workload. Although buffer pool efficiency cannot give you answers,
    it tells you where to look: access patterns (especially [“Data Age”](ch04.html#ap-data-age)),
    page flushing, and memory size.'
  prefs: []
  type: TYPE_NORMAL
- en: InnoDB buffer pool efficiency is the tip of the iceberg. Underneath, page flushing
    is the internal machinery that keeps it afloat.
  prefs: []
  type: TYPE_NORMAL
- en: Page flushing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This spectrum is large and complicated, so it’s further subdivided into *Pages*
    and *Flushing*, which are inextricable.
  prefs: []
  type: TYPE_NORMAL
- en: Pages
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As mentioned in the previous section, the buffer pool contains index pages.
    There are four types of pages:'
  prefs: []
  type: TYPE_NORMAL
- en: Free pages
  prefs: []
  type: TYPE_NORMAL
- en: These contain no data; InnoDB can load new data into them.
  prefs: []
  type: TYPE_NORMAL
- en: Data pages
  prefs: []
  type: TYPE_NORMAL
- en: These contain data that has not been modified; also called *clean pages*.
  prefs: []
  type: TYPE_NORMAL
- en: Dirty pages
  prefs: []
  type: TYPE_NORMAL
- en: These contain modified data that has not been flushed to disk.
  prefs: []
  type: TYPE_NORMAL
- en: Misc pages
  prefs: []
  type: TYPE_NORMAL
- en: These contain miscellaneous internal data not covered in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since InnoDB keeps the buffer pool full of data, monitoring the number of data
    pages is not necessary. Free and dirty pages are the most revealing with respect
    to performance, especially when viewed with flushing metrics in the next section.
    Three gauges and one counter (the last metric) reveal how many free and dirty
    pages are sloshing around in the buffer pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.buffer_pool_pages_total`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.buffer_pool_pages_dirty`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.buffer_pool_pages_free`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.buffer_pool_wait_free`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.buffer_pool_pages_total` is the total number of pages in the buffer
    pool (total page count), which depends on the buffer pool size ([`var​.inno​db_​buffer_pool_size`](https://oreil.ly/fXHQ4)).
    (Technically, this is a gauge metric because, as of MySQL 5.7.5, the InnoDB buffer
    pool size is dynamic. But frequently changing the buffer pool size is not common
    because it’s sized according to system memory, which cannot change quickly—even
    cloud instances require a few minutes to resize.) Total page count calculates
    the percentage of free and dirty pages: `innodb.buffer_pool_pages_free` and `innodb.buffer_pool_pages_dirty`
    divided by total pages, respectively. Both percentages are gauge metrics, and
    the values change frequently due to page flushing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure that free pages are available when needed, InnoDB maintains a nonzero
    balance of free pages that I call the *free page target*. The free page target
    is equal to the product of two system variables: the system variable [`var.innodb_lru_scan_depth`](https://oreil.ly/TG9hj)
    multiplied by [`var.innodb_buffer_pool_instances`](https://oreil.ly/srIHw). The
    name of the former system variable is somewhat misleading, but it configures the
    number of free pages that InnoDB maintains in *each* buffer pool instance; the
    default is 1024 free pages. Until now, I have written about *the buffer pool*
    as one logical part of InnoDB. Under the hood, the buffer pool is divided into
    multiple *buffer pool instances*, each with its own internal data structures to
    reduce contention under heavy load. The default for `var.innodb_buffer_pool_instances`
    is 8 (or 1 if the buffer pool size is less than 1 GB). Therefore, with defaults
    for both system variables, InnoDB maintains 1024 × 8 = 8192 free pages. Free pages
    should hover around the free page target.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Reducing `var.innodb_lru_scan_depth` is a best practice because, with default
    values, it yields 134 MB of free page size: 8192 free pages × 16 KB/page = 134
    MB. That is excessive given that rows are typically hundreds of bytes. It’s more
    efficient for free pages to be as low as possible without hitting zero and incurring
    free page waits (explained in the next paragraph). It’s good to be aware of this,
    but it’s MySQL tuning, which is beyond the scope of this book. The default does
    not hinder performance; MySQL experts just abhor inefficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If free pages are consistently near zero (below the free page target), that’s
    fine as long as `innodb.buffer_pool_wait_free` remains zero. When InnoDB needs
    a free page but none is available, it increments `innodb.buffer_pool_wait_free`
    and waits. This is called a *free page wait* and it should be exceptionally rare—even
    when the buffer pool is full of data—because InnoDB actively maintains the free
    page target. But under very heavy load, it might not be able to flush and free
    pages fast enough. Simply put: InnoDB is reading new data faster than it can flush
    old data. Presuming that the workload is already optimized, there are three solutions
    to free page waits:'
  prefs: []
  type: TYPE_NORMAL
- en: Increase free page target
  prefs: []
  type: TYPE_NORMAL
- en: If your storage can provide more IOPS (or you can provision more IOPS in the
    cloud), then increasing `var.innodb_lru_scan_depth` causes InnoDB to flush and
    free more pages, which requires more IOPS (see [“IOPS”](#metrics-iops)).
  prefs: []
  type: TYPE_NORMAL
- en: Better storage system
  prefs: []
  type: TYPE_NORMAL
- en: If your storage cannot provide more IOPS, upgrade to better storage, then increase
    the free page target.
  prefs: []
  type: TYPE_NORMAL
- en: More memory
  prefs: []
  type: TYPE_NORMAL
- en: The more memory, the bigger the buffer pool, and the more pages can fit in memory
    without needing to flush and evict old pages to load new pages. There’s one more
    detail about free page waits that I clarify later when explaining LRU flushing.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Remember from [“Buffer pool efficiency”](#metrics-buff-pool): *read* doesn’t
    mean `SELECT`. InnoDB reads new data from the buffer pool for all queries: `INSERT`,
    `UPDATE`, `DELETE`, and `SELECT`. When data is accessed but not in the buffer
    pool (in memory), InnoDB reads it from disk.'
  prefs: []
  type: TYPE_NORMAL
- en: If free pages are consistently much higher than the free page target, or never
    decrease to the target, then the buffer pool is too large. For example, 50 GB
    of data fills only 39% of 128 GB of RAM. MySQL is optimized to use only the memory
    that it needs, so giving it an overabundance of memory will not increase performance—MySQL
    simply won’t use the excess memory. Don’t waste memory.
  prefs: []
  type: TYPE_NORMAL
- en: Dirty pages as a percentage of total pages varies between 10% and 90% by default.
    Although dirty pages contain modified data that has not been flushed to disk,
    the data changes have been flushed to disk in the transaction log—more on this
    in the next two sections. Even with 90% dirty pages, all data changes are guaranteed
    durable—persisted to disk. It’s completely normal to have a high percentage of
    dirty pages. In fact, it’s expected unless the workload is exceptionally read-heavy
    (recall access pattern trait [“Read/Write”](ch04.html#ap-read-write)) and simply
    does not modify data very often. (In this case, I would consider whether another
    data store is better suited to the workload.)
  prefs: []
  type: TYPE_NORMAL
- en: Since a high percentage of dirty pages is expected, this metric is used to corroborate
    other metrics related to page flushing (next section), the transaction log ([“Transaction
    log”](#metrics-trx-log)), and disk I/O ([“IOPS”](#metrics-iops)). For example,
    writing data causes dirty pages, so a spike in dirty pages corroborates a spike
    in IOPS and transaction log metrics. But a spike in IOPS without a corresponding
    spike in dirty pages cannot be caused by writes; it must be another issue—maybe
    an engineer manually executed an ad hoc query that dredged up a mass of old data
    that hadn’t seen the light of day in eons, and now InnoDB is reading it from disk
    in a maelstrom of IOPS. Ultimately, dirty pages rise and fall with the gentle
    tides of page flushing.
  prefs: []
  type: TYPE_NORMAL
- en: Page flushing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Page flushing* cleans dirty pages by writing the data modifications to disk.
    Page flushing serves three closely related purposes: durability, checkpointing,
    and page eviction. For simplicity, this section focuses on page flushing with
    respect to page eviction. [“Transaction log”](#metrics-trx-log) clarifies how
    page flushing serves durability and checkpointing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From [“Buffer pool efficiency”](#metrics-buff-pool), you know that page flushing
    makes space for new data to be loaded into the buffer pool. More specifically,
    page flushing makes dirty pages clean, and clean pages can be evicted from the
    buffer pool. Thus, the circle of page life is complete:'
  prefs: []
  type: TYPE_NORMAL
- en: A free page becomes a clean (data) page when data is loaded
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A clean page becomes a dirty page when its data is modified
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dirty page becomes a clean page again when the data modifications are flushed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A clean page becomes a free page again when it’s evicted from the buffer pool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The implementation of page flushing is complex and varies among distributions
    (Oracle MySQL, Percona Server, and MariaDB Server), so you might want to reread
    the following information to fully absorb the many intricate details. [Figure 6-6](#page-flushing)
    depicts the high-level components and flow of InnoDB page flushing from committing
    transactions in the transaction log (at top) to flushing and evicting pages from
    the buffer pool (at bottom).
  prefs: []
  type: TYPE_NORMAL
- en: Figuratively, InnoDB page flushing works top to bottom in [Figure 6-6](#page-flushing),
    but I’m going to explain it from the bottom up. In the buffer pool, dirty pages
    are dark, clean (data) pages are white, and free pages have a dotted outline.
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0606](assets/emsp_0606.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-6\. InnoDB page flushing
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Dirty pages are recorded in two internal lists (for each buffer pool instance):'
  prefs: []
  type: TYPE_NORMAL
- en: Flush list
  prefs: []
  type: TYPE_NORMAL
- en: Dirty pages from writes committed in the transaction log.
  prefs: []
  type: TYPE_NORMAL
- en: LRU list
  prefs: []
  type: TYPE_NORMAL
- en: Clean and dirty pages in the buffer pool ordered by data age.
  prefs: []
  type: TYPE_NORMAL
- en: Strictly speaking, the LRU list tracks all pages with data, and that just happens
    to include dirty pages; whereas the flush list explicitly tracks only dirty pages.
    Either way, MySQL uses both lists to find dirty pages to flush. (In [Figure 6-6](#page-flushing),
    the LRU list is connected to [tracking] only one dirty page, but this only a simplification
    to avoid a clutter of lines.)
  prefs: []
  type: TYPE_NORMAL
- en: Once every second, dirty pages are flushed from both lists by background threads
    aptly named *page cleaner threads*. By default, InnoDB uses four page cleaner
    threads, configured by [`var.innodb_page_cleaners`](https://oreil.ly/ELUoy). Each
    page cleaner flushes both lists; but for simplicity, [Figure 6-6](#page-flushing)
    shows one page cleaner flushing one list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two flushing algorithms are primarily responsible for flush list flushing and
    LRU list flushing, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive flushing
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive flushing determines the rate at which page cleaners flush dirty pages
    from the flush list.^([6](ch06.html#idm45829110113632)) The algorithm is *adaptive*
    because it varies the page flush rate based on the rate of transaction log writes.
    Faster writes, faster page flushing. The algorithm responds to write load, but
    it’s also finely tuned to produce a stable rate of page flushing under varying
    write loads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Page flushing by page cleaners is a background task, therefore the page flush
    rate is limited by the configured InnoDB I/O capacity explained in [“IOPS”](#metrics-iops),
    specifically: `var.innodb_io_capacity` and `var.innodb_io_capacity_max`. Adaptive
    flushing does a fantastic job of keeping the flush rate (in terms of IOPS) between
    these two values.'
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of adaptive flushing is to allow checkpointing to reclaim space
    in the transaction logs. (Actually, this is the purpose of flush list flushing
    in general; algorithms are just different methods of accomplishing it.) I explain
    checkpointing in [“Transaction log”](#metrics-trx-log), but I mention it here
    to clarify that, although flushing makes pages clean and candidates for eviction,
    that is not the purpose of adaptive flushing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The intricate details of the adaptive flushing algorithm are beyond the scope
    of this book. The important point is: adaptive flushing flushes dirty pages from
    the flush list in response to transaction log writes.'
  prefs: []
  type: TYPE_NORMAL
- en: LRU flushing
  prefs: []
  type: TYPE_NORMAL
- en: 'LRU flushing flushes dirty pages from the tail of the LRU list, which contains
    the oldest pages. Simply put: LRU flushing flushes and evicts old pages from the
    buffer pool.'
  prefs: []
  type: TYPE_NORMAL
- en: LRU flushing happens in the background and the foreground. Foreground LRU flushing
    happens when a user thread (a thread executing a query) needs a free page but
    there are none. This is not good for performance because it’s a wait—it increases
    query response time. When it occurs, MySQL increments `innodb.buffer_pool_wait_free`,
    which is the “one more detail about free page waits” mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Page cleaners handle background LRU flushing (because page cleaners are background
    threads). When a page cleaner flushes a dirty page from the LRU list, it also
    frees the page by adding it to the free list. This is primarily how InnoDB maintains
    the free page target (see [“Pages”](#pg-pages)) and avoids free page waits.
  prefs: []
  type: TYPE_NORMAL
- en: Although background LRU flushing is a background task, it is *not* limited by
    the configured InnoDB I/O capacity explained (`var.innodb_io_capacity` and `var.innodb_io_capacity_max`).^([7](ch06.html#idm45829110096368))
    It’s effectively limited (per buffer pool instance) by [`var.innodb_lru_scan_depth`](https://oreil.ly/fGGjJ).
    For various reasons beyond the scope of this book, this is not a problem in terms
    of excessive background storage I/O.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of LRU flushing is to flush and free (evict) the oldest pages. *Old*,
    as detailed in [“Data Age”](ch04.html#ap-data-age), means the least recently used
    pages, hence *LRU*. The intricate details of LRU flushing, the LRU list, and how
    it all relates to the buffer pool are beyond the scope of this book; but if you’re
    curious, start by reading [“Buffer Pool”](https://oreil.ly/OyBeI) in the MySQL
    manual. The important point is that LRU flushing frees pages and its maximum rate
    is the free page target (per second), not the configured InnoDB I/O capacity.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that crash course on InnoDB flushing, the following four metrics are now
    intelligible:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.buffer_flush_batch_total_pages`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.buffer_flush_adaptive_total_pages`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.buffer_LRU_batch_flush_total_pages`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.buffer_flush_background_total_pages`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All four metrics are counters that, when converted to rates, reveal page flush
    rates for each algorithm. `innodb.buffer_flush_batch_total_pages` is the total
    page flush rate for all algorithms. It’s a high-level rate that’s useful as a
    KPI for InnoDB: the total page flush rate should be normal and stable. If not,
    one of the metrics indicates which part of InnoDB is not flushing normally.'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.buffer_flush_adaptive_total_pages` is the number of pages flushed by
    adaptive flushing. `innodb.buffer_LRU_batch_flush_total_pages` is the number of
    pages flushed by background LRU flushing. Given the earlier explanation of these
    flushing algorithms, you know which parts of InnoDB they reflect: the transaction
    log and free pages, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.buffer_flush_background_total_pages` is included for completeness:
    it is the number of pages flushed by other algorithms described in [“Idle Flushing
    and Legacy Flushing”](#idle-flushing). If the rate of background page flushing
    is problematic, you will need to consult a MySQL expert because that’s not supposed
    to happen.'
  prefs: []
  type: TYPE_NORMAL
- en: Although different flushing algorithms have different rates, the storage system
    underlies all of them because flushing requires IOPS. If you’re running MySQL
    on spinning disks, for example, the storage system (both the storage bus and the
    storage device) simply do not provide many IOPS. If you run MySQL on high-end
    storage, then IOPS may never be an underlying issue. And if you’re running MySQL
    in the cloud, you can provision as many IOPS as you need, but the cloud uses network-attached
    storage, which is slow. Also remember that IOPS have latency—especially in the
    cloud—ranging from microseconds to milliseconds. This is deep knowledge verging
    on expert-level internals, but let’s keep going because it’s powerful knowledge
    worth learning.
  prefs: []
  type: TYPE_NORMAL
- en: Transaction log
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The final and perhaps most important spectrum: the transaction log, also known
    as the redo log. For brevity, it’s called *the log* when the context is clear
    and unambiguous, as it is here.'
  prefs: []
  type: TYPE_NORMAL
- en: The transaction log guarantees durability. When a transaction commits, all data
    changes are recorded in the transaction log and flushed to disk—which makes the
    data changes durable—and corresponding dirty pages remain in memory. (If MySQL
    crashes with dirty pages, the data changes are not lost because they were already
    flushed to disk in the transaction log.) Transaction log flushing is *not* page
    flushing. The two processes are separate but inextricable.
  prefs: []
  type: TYPE_NORMAL
- en: The InnoDB transaction log is a fixed-size ring buffer on disk, as shown in
    [Figure 6-7](#trx-log). By default, it comprises two physical log files. The size
    of each is configured by [`var.innodb_log_file_size`](https://oreil.ly/ItAxz).
    Or, as of MySQL 8.0.3, enabling [`var.innodb_dedicated_server`](https://oreil.ly/gv38o)
    automatically configures the log file size and other related system variables.
  prefs: []
  type: TYPE_NORMAL
- en: The transaction log contains data changes (technically, *redo logs*), not pages;
    but the data changes are linked to dirty pages in the buffer pool. When a transaction
    commits, its data changes are written to the head of the transaction log and flushed
    (synced) to disk, which advances the head clockwise, and the corresponding dirty
    pages are added to the flush list shown earlier in [Figure 6-6](#page-flushing).
    (In [Figure 6-7](#trx-log), the head and tail move clockwise, but this is only
    an illustration. Unless you have spinning disks, the transaction log does not
    literally move.) Newly written data changes overwrite old data changes for which
    the corresponding pages have been flushed.
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0607](assets/emsp_0607.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-7\. InnoDB transaction log
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'A simplified illustration and explanation of the InnoDB transaction log makes
    it appear serialized. But that is only an artifact of simplifying a complex process.
    The actual low-level implementation is highly concurrent: many user threads are
    committing changes to the transaction log in parallel.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Checkpoint age* is the length of the transaction log (in bytes) between the
    head and the tail. *Checkpointing* reclaims space in the transaction log by flushing
    dirty pages from the buffer pool, which allows the tail to advance. Once dirty
    pages have been flushed, the corresponding data changes in the transaction log
    can be overwritten with new data changes. Adaptive flushing implements checkpointing
    in InnoDB, which is why the checkpoint age is an input to the adaptive flushing
    algorithm shown in [Figure 6-6](#page-flushing).'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: By default, all data changes (redo logs) in the transaction log are durable
    (flushed to disk), but corresponding dirty pages in the buffer pool are not durable
    until flushed by checkpointing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Checkpointing advances the tail to ensure that the checkpoint age does not
    become too old (which really means *too large* because it’s measured in bytes,
    but *too old* is the more common phrase). But what happens if the checkpoint age
    becomes so old that the head meets the tail? Since the transaction log is a fixed-size
    ring buffer, the head can wrap around and meet the tail if the write rate consistently
    exceeds the flush rate. InnoDB won’t let this happen. There are two safeguard
    points called *async* and *sync*, as shown in [Figure 6-7](#trx-log). *Async*
    is the point at which InnoDB begins asynchronous flushing: writes are allowed,
    but the page flushing rate is increased to near maximum. Although writes are allowed,
    flushing will use so much InnoDB I/O capacity that you can (and should) expect
    a noticeable drop in overall server performance. *Sync* is the point at which
    InnoDB begins synchronous flushing: *all writes stop*, and page flushing takes
    over. Needless to say, that’s terrible for performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'InnoDB exposes metrics for the checkpoint age and the async flush point, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.log_lsn_checkpoint_age`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.log_max_modified_age_async`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.log_lsn_checkpoint_age` is a gauge metric measured in bytes, but the
    raw value is meaningless to humans (it ranges from zero to the log file size).
    What is meaningful to humans and critical to monitor is how close the checkpoint
    age is to the async flush point, which I call *transaction log utilization*:'
  prefs: []
  type: TYPE_NORMAL
- en: (innodb.log_lsn_checkpoint_age / innodb.log_max_modified_age_async) × 100
  prefs: []
  type: TYPE_NORMAL
- en: 'Transaction log utilization is conservative because the async flush point is
    at 6/8 (75%) of the log file size. Therefore, at 100% transaction log utilization,
    25% of the log is free to record new writes, but remember: server performance
    drops noticeably at the async flush point. It’s important to monitor and know
    when this point is reached. If you want to live dangerously, InnoDB exposes a
    metric for the sync flush point (which is at 7/8 [87.5%] of the log file size)
    that you can substitute for the async flush point metric (or monitor both): `innodb.log_max_modified_age_sync`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s one small but important detail about how queries log data changes to
    the transaction log: data changes are first written to an in-memory *log buffer*
    (not to be confused with the *log file* that refers to the actual on-disk transaction
    log), then the log buffer is written to the log file, and the log file is synced.
    I’m glossing over myriad details, but the point is: there’s an in-memory log buffer.
    If the log buffer is too small and a query has to wait for free space, InnoDB
    increments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.log_waits`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.log_waits` should be zero. If it isn’t, the log buffer size is configured
    by [`var.innodb_log_buffer_size`](https://oreil.ly/2I1cq). The default 16 MB is
    usually more than sufficient.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the transaction log comprises two physical files on disk (two files,
    but one logical log), writing and syncing data changes to disk are the most fundamental
    tasks. Two gauge metrics report how many of those tasks are pending—waiting to
    be completed:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.os_log_pending_writes`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`innodb.os_log_pending_fsyncs`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since writes and syncs are supposed to happen extremely quickly—nearly all write
    performance depends on it—these metrics should always be zero. If not, they indicate
    a low-level problem with either InnoDB or, more likely, the storage system—presuming
    other metrics are normal or were normal before pending writes and syncs. Don’t
    expect problems at this depth, but monitor it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, a simple but important metric that counts the number of
    bytes written to the transaction log:'
  prefs: []
  type: TYPE_NORMAL
- en: '`innodb.os_log_bytes_written`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s best practice to monitor total log bytes written per hour as a basis for
    determining log file size. Log file size is the product of system variables [`var​.inno​db_​log_file_size`](https://oreil.ly/sinUV)
    and [`var.innodb_log_files_in_group`](https://oreil.ly/0hYp1). Or, as of MySQL
    8.0.14, enabling [`var.innodb_dedicated_server`](https://oreil.ly/f2UqB) automatically
    configures both system variables. The default log file size is only 96 MB (two
    log files at 48 MB each). As an engineer using MySQL, not a DBA, I presume whoever
    is managing your MySQL has properly configured these system variables, but it’s
    wise to verify.
  prefs: []
  type: TYPE_NORMAL
- en: 'We made it: the end of InnoDB metrics. The spectrum of InnoDB metrics is much
    wider and deeper than presented here; these are only the most essential InnoDB
    metrics for analyzing MySQL performance. Moreover, significant changes were made
    to InnoDB from MySQL 5.7 to 8.0. For example, the internal implementation of the
    transaction log was rewritten and improved as of MySQL 8.0.11. There are other
    parts of InnoDB not covered here: double-write buffer, change buffer, adaptive
    hash index, and so on. I encourage you to learn more about InnoDB, for it is a
    fascinating storage engine. You can begin that journey at [“The InnoDB Storage
    Engine”](https://oreil.ly/s0PZk) in the MySQL manual.'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and Alerting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MySQL metrics reveal the spectrum of MySQL performance, and they’re also great
    for waking engineers in the middle of the night—otherwise known as monitoring
    and alerting.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and alerting are external to MySQL, so they cannot affect its performance,
    but I am compelled to address the following four topics because they are related
    to metrics and important to success with MySQL.
  prefs: []
  type: TYPE_NORMAL
- en: Resolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Resolution* means the frequency at which metrics are collected and reported:
    1 second, 10 seconds, 30 seconds, 5 minutes, and so on. Higher resolution entails
    higher frequency: 1 second is higher resolution than 30 seconds. Like a television,
    the higher the resolution, the more detail you see. And since “seeing is believing,”
    let’s see three charts of the same data over 30 seconds. The first chart, [Figure 6-8](#qps-at-1s),
    shows QPS values at maximum resolution: 1 second.'
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0608](assets/emsp_0608.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-8\. QPS at 1-second resolution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the first 20 seconds, QPS is normal and stable, bouncing between 100 and
    200 QPS. From 20 to 25 seconds, there is a 5-second stall (the 5 data points below
    100 QPS in the box). For the last five seconds, QPS spikes to an abnormally high
    value, which is common after a stall. This chart isn’t dramatic, but it’s realistic
    and it begins to illustrate a point that the next two charts bring into focus.
  prefs: []
  type: TYPE_NORMAL
- en: The second chart, [Figure 6-9](#qps-at-5s), is the exact same data but at 5-second
    resolution.
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0609](assets/emsp_0609.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-9\. QPS at 5-second resolution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'At 5-second resolution, some fine detail is lost, but critical details remain:
    normal and stable QPS in the first 20 seconds; the stall around 25 seconds; and
    the spike after the stall. This chart is acceptable for daily monitoring—especially
    considering that collecting, storing, and charting metrics at 1-second resolution
    is so difficult that it’s almost never done.'
  prefs: []
  type: TYPE_NORMAL
- en: The third chart, [Figure 6-10](#qps-at-10s), is the exact same data but at 10-second
    resolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'At 10-second resolution, nearly all detail is lost. According to the chart,
    QPS is stable and normal, but it’s misleading: QPS destabilized and was not normal
    for 10 seconds (five second stall and five second spike).'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the very least, collect KPIs (see [“Key Performance Indicators”](#kpi))
    at 5-second resolution or better. If possible, collect most of the metrics in
    [“Spectra”](#spectra) at 5-second resolution too, with the following exceptions:
    Admin, `SHOW`, and bad `SELECT` metrics can be collected slowly (10, 20, or 30
    seconds), and data size can be collected very slowly (5, 10, or 20 minutes).'
  prefs: []
  type: TYPE_NORMAL
- en: Strive for the highest resolution possible because, unlike query metrics that
    are logged, MySQL metrics are either collected or gone for all eternity.
  prefs: []
  type: TYPE_NORMAL
- en: '![emsp 0610](assets/emsp_0610.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-10\. QPS at 10-second resolution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Wild Goose Chase (Thresholds)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *threshold* is a static value past which a monitoring alert triggers, often
    times paging the engineer who’s on-call. Thresholds seem like a good and reasonable
    idea, but they don’t work. That’s a very strong claim, but it’s closer to the
    truth than the opposite—claiming that thresholds work.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is that a threshold also needs a *duration*: how long the metric
    value must remain past the threshold until the alert triggers. Consider the chart
    in [Figure 6-8](#qps-at-1s) from the previous section (QPS at 1-second resolution).
    Without a duration, a threshold at QPS less than 100 would trigger seven times
    in 30 seconds: the five second stall, and the third and thirteenth data points.
    That’s “too noisy” in the parlance of monitoring and alerting, so what about a
    threshold at QPS less than 50? Surely, a 50% drop in QPS—from 100 QPS to 50 QPS—signals
    a problem worth alerting a human. Sorry, the alert never triggers: the lowest
    data point is 50 QPS, which is not *less than* 50 QPS.'
  prefs: []
  type: TYPE_NORMAL
- en: This example seems contrived but it’s not, and it gets worse. Suppose you add
    a 5-second duration to the alert, and reset the threshold to QPS less than 100.
    Now the alert only triggers after the five-second stall. But what if the stall
    wasn’t a stall? What if there was a network blip that caused packet loss during
    those five seconds, so the problem was neither MySQL nor the application? The
    poor on-call human who was alerted is on a wild goose chase.
  prefs: []
  type: TYPE_NORMAL
- en: 'I know it seems like I’m tailoring the example to suit my point, but all joking
    aside: thresholds are notoriously difficult to perfect, where *perfect* means
    that it alerts only on truly legitimate problems—no false-positives.'
  prefs: []
  type: TYPE_NORMAL
- en: Alert on User Experience and Objective Limits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two proven solutions that work in lieu of thresholds:'
  prefs: []
  type: TYPE_NORMAL
- en: Alert on what users experience
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alert on *objective* limits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From [“North Star”](ch01.html#north-star) and [“Key Performance Indicators”](#kpi),
    there are only two MySQL metrics that users experience: response time and errors.
    These are reliable signals not only because users experience them, but because
    they cannot be false-positive. A change in QPS might be a legitimate change in
    user traffic. But a change in response time can only be explained by a change
    in response time. The same is true for errors.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: With microservices, the user might be another application. In that case, normal
    response times could be very low (tens of milliseconds), but the monitoring and
    alerting principles are the same.
  prefs: []
  type: TYPE_NORMAL
- en: Thresholds and duration are simpler for response time and errors, too, because
    we can imagine the abnormal conditions past the thresholds. For example, presume
    the normal P99 response time for an application is 200 milliseconds, and the normal
    error rate is 0.5 per second. If P99 response time increased to 1 second (or more)
    for a full a minute, would that be a bad user experience? If yes, then make those
    the threshold and duration. If errors increased to 10 per second for a full 20
    seconds, would that be a bad user experience? If yes, then make those the threshold
    and duration.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more concrete example, let’s clarify the implementation of the previous
    example where 200 milliseconds is the normal P99 response time. Measure and report
    P99 response time every five seconds (see [“Query Response Time”](#metrics-qrt)).
    Create a rolling one minute alert on the metric that triggers when the last 12
    values are greater than one second. (Since the metric is reported every five seconds,
    there are 60 / 5 seconds = 12 values/minute.) From a technical point of view,
    a sustained 5x increase in query response time is drastic and merits investigation—it’s
    probably an early warning that a larger problem is brewing and, if ignored, will
    cause an application outage. But the intention of the alert is more practical
    than technical: if users are used to subsecond responses from the application,
    then one-second responses are noticeably sluggish.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Objective limits are minimum or maximum values that MySQL cannot pass. These
    are common objective limits external to MySQL:'
  prefs: []
  type: TYPE_NORMAL
- en: Zero free disk space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero free memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 100% CPU utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 100% storage IOPS utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 100% network utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MySQL has many *max* system variables, but these are the most common ones that
    affect applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[`max_connections`](https://oreil.ly/0ODxA)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`max_prepared_stmt_count`](https://oreil.ly/jqNuk)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`max_allowed_packet`](https://oreil.ly/qM3R5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There’s one more object limit that has surprised more than one engineer: maximum
    [`AUTO_INCREMENT`](https://oreil.ly/tkXWP) value. MySQL does not have a native
    metric or method for checking if an `AUTO_INCREMENT` column is approaching its
    maximum value. Instead, common MySQL monitoring solutions create a metric by executing
    a SQL statement similar to [Example 6-7](#auto-inc-max), which was written by
    renowned MySQL expert Shlomi Noach in [“Checking for AUTO_INCREMENT capacity with
    single query”](https://oreil.ly/LJ64E).'
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-7\. SQL statement that checks maximum `AUTO_INCREMENT`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'What about the other two key performance indicators: QPS and threads running?
    Monitoring QPS and threads running is a best practice, but alerting on them is
    not. These metrics are pivotal when investigating a legitimate problem signaled
    by response time or errors, but otherwise they fluctuate too much to be reliable
    signals.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If this approach seems radical, remember: these are alerts for engineers using
    MySQL, not DBAs.'
  prefs: []
  type: TYPE_NORMAL
- en: Cause and Effect
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I won’t mince words: when MySQL is slow to respond, the application is the
    cause the vast majority (maybe 80%) of the time—in my experience—because the application
    drives MySQL. Without it, MySQL is idle. If the application isn’t the cause, there
    are a few other common causes of slow MySQL performance. Another application—any
    application, not just MySQL—is a likely culprit maybe 10% of the time, as I discuss
    later in [“Noisy Neighbors”](ch09.html#noisy-neighbors). Hardware, which includes
    the network, causes problems a mere 5% of the time because modern hardware is
    quite reliable (especially enterprise-grade hardware, which lasts longer [and
    costs more] than consumer-grade hardware). Last and least: I estimate only a 1%
    chance that MySQL is the root cause of its own slowness.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once identified, the cause is presumed to be the root cause, not a side effect
    of some prior, unseen cause. For example, application causes presume something
    like a poorly written query that, once deployed in production, immediately causes
    a problem in MySQL. Or, hardware causes presume something like a degraded storage
    system that’s working but significantly slower than usual, which causes MySQL
    to respond slowly. When this presumption is false—the identified cause is *not*
    the root cause—an especially pernicious situation occurs. Consider the following
    sequence of events:'
  prefs: []
  type: TYPE_NORMAL
- en: A network issue lasting 20 seconds causes significant packet loss or low-level
    network retries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The network issue causes query errors or timeouts (due to packet loss or retries,
    respectively).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both the application and MySQL log errors (query errors and client errors, respectively).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application retries queries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While retrying old queries, the application continues executing new queries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: QPS increases due to executing new and old queries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Utilization increases due to QPS increasing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Waits increase due to utilization increasing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Timeouts increase due to waits increasing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application retries queries again, which creates a feedback loop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'By the time you step into this situation, the problem is apparent but the root
    cause is not. You know that everything was normal and stable before the problem:
    no application changes or deployments; MySQL key performance indicators were normal
    and stable; and DBAs confirm that no work was done on their side. That’s what
    makes this situation especially pernicious: as far as you can tell, it shouldn’t
    be happening, but there’s no denying that it is.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Technically speaking, all causes are knowable because computers are finite
    and discrete. But practically speaking, causes are only as knowable as monitoring
    and logging allow. In this example, if you have exceptionally good networking
    monitoring and application logging (and access to the MySQL error log), you can
    figure out the root cause: the 20-second network blip. But that’s a lot easier
    said than done because in the midst of this situation—your application is down,
    customers are calling, and it’s 4:30 p.m. on a Friday—engineers are focused on
    fixing the problem, not elucidating its root cause. When focused on fixing the
    problem, it’s easy to see MySQL as the cause that needs to be fixed: make MySQL
    run faster and the application will be OK. But there is no way to fix MySQL in
    this sense—recall, [“MySQL Does Nothing”](ch04.html#mysql-does-nothing). Since
    everything was normal before the problem, the goal is to return to that normal,
    starting with the application because it drives MySQL. The correct solution depends
    on the application, but common tactics are: restarting the application, throttling
    incoming application requests, and disabling application features.'
  prefs: []
  type: TYPE_NORMAL
- en: I’m not favoring MySQL. The simple reality is that MySQL is a mature database
    with more than 20 years in the field. Moreover, as an open source database, it
    has been scrutinized by engineers from all over the world. At this juncture in
    the storied life of MySQL, inherent slowness is not its weakness. Rather than
    ask why MySQL is slow, a more powerful and effective question that leads to a
    root cause or immediate fix is “What is causing MySQL to run slowly?”
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter analyzed the spectra of MySQL metrics that are the most important
    for understanding the nature of the workload, which accounts for MySQL performance.
    The illuminating takeaway points are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'MySQL performance has two sides: query performance and server performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Query performance is input; server performance is output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normal and stable are whatever performance MySQL exhibits for your application
    on a typical day when everything is working properly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stability does not limit performance; it ensures that performance—at any level—is
    sustainable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQL KPIs are response time, errors, QPS, and threads running.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The field of metrics comprises six classes of metrics: response time, rate,
    utilization, wait, error, and access pattern (seven, if you count internal metrics).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Metric classes are related: rate increases utilization; utilization pushes
    back to decrease rate; high (maximum) utilization incurs wait; wait timeout incurs
    error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The spectra of MySQL metrics are vast; see [“Spectra”](#spectra).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Resolution* means the frequency at which metrics are collected and reported.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High resolution metrics (5 seconds or less) reveal important performance details
    that are lost in low resolution metrics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alert on what users experience (like response time) and objective limits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application issues (your application or another) are the most likely cause of
    slow MySQL performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQL server performance is revealed through a spectrum of metrics that are
    the figurative refraction of the workload through MySQL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next chapter investigates replication lag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Practice: Review Key Performance Indicators'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this practice is to know the normal and stable values of the four
    KPIs for MySQL, as addressed in [“Key Performance Indicators”](#kpi). To make
    this practice interesting first, write down what you think the KPI values are
    for your application. You probably have a good idea about QPS; what about response
    time (P99 or P999), errors, and threads running?
  prefs: []
  type: TYPE_NORMAL
- en: Start collecting the four [“Key Performance Indicators”](#kpi), if you’re not
    already. Your method depends on the software (or service) that you use to collect
    MySQL metrics. Any decent MySQL monitor should collect all four; if your current
    solution does not, seriously consider a better MySQL monitor because if it doesn’t
    collect key performance indicators, it’s unlikely to collect many of the metrics
    detailed in [“Spectra”](#spectra).
  prefs: []
  type: TYPE_NORMAL
- en: 'Review at least one full day of KPI metrics. Are the real values close to what
    you thought? If response time is higher than you thought, then you know where
    to begin: [“Query profile”](ch01.html#query-profile). If the rate of errors is
    higher than you thought, then query table `performance_schema.events_errors_summary_global_by_error`
    to see which error numbers are occurring. Use [“MySQL Error Message Reference”](https://oreil.ly/F9z9W)
    to look up the error code. If threads running is higher than you thought, diagnosis
    is tricky because a single thread executes different queries (presuming the application
    uses a connection pool). Start with the slowest queries in the query profile.
    If your query metric tool reports query load, focus on queries with the highest
    load; otherwise, focus on queries with the highest total query time. If necessary,
    investigate using the [Performance Schema `threads` table](https://oreil.ly/ZgtGW).'
  prefs: []
  type: TYPE_NORMAL
- en: Review the KPIs for different periods throughout the day. Are the values stable
    all day, or do they decrease in the middle of the night? Are there periods when
    the values are abnormal? Overall, what are the normal and stable KPI values for
    your application?
  prefs: []
  type: TYPE_NORMAL
- en: 'Practice: Review Alerts and Thresholds'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The goal of this practice is to help you sleep at night. Whereas charts for
    MySQL metrics are front and center, alerts—and configuration of those alerts—are
    usually hidden away. Consequently, engineers—especially newly hired engineers—do
    not know what alerts lurk in the darkness, waiting to page them while they sleep.
    Take a morning or afternoon to shine a light on all your alerts and how they are
    configured—their thresholds, if any. And while you’re at it: document the alerts
    (or update the current documentation). Review [“Wild Goose Chase (Thresholds)”](#thresholds)
    and [“Alert on User Experience and Objective Limits”](#alert-on), and adjust or
    remove superfluous alerts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal for alerting is simple: every page is legitimate and actionable. *Legitimate*
    means that something is already broken, or certain to break very soon, and it
    requires fixing right now. *Actionable* means that the engineer (who was paged)
    has the knowledge, skills, and access to fix it. This is possible with MySQL.
    Say *no* to the wild goose chase and *yes* to a good night’s sleep.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch06.html#idm45829110960368-marker)) The [MySQL worklog 5384](https://oreil.ly/2kFWK)
    explains how response time quantiles are implemented in the Performance Schema.
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch06.html#idm45829110678032-marker)) `Com_insert_select` and `Com_replace_select`
    are technically both reads and writes, but for simplicity I count them as writes.
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch06.html#idm45829110575632-marker)) “I’m Mr. Meeseeks, look at me!”
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch06.html#idm45829110547888-marker)) See my blog post [“MySQL Select and
    Sort Status Variables”](https://oreil.ly/OpJvS) for an in-depth explanation of
    all `Select_%` and `Sort_%` metrics.
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch06.html#idm45829110227344-marker)) You can disable durability, but that’s
    a terrible idea.
  prefs: []
  type: TYPE_NORMAL
- en: ^([6](ch06.html#idm45829110113632-marker)) The MySQL adaptive flushing algorithm
    was created in 2008 by renowned MySQL expert Yasufumi Kinoshita while working
    at Percona. See his blog post [“Adaptive checkpointing”](https://oreil.ly/8QG6X).
  prefs: []
  type: TYPE_NORMAL
- en: ^([7](ch06.html#idm45829110096368-marker)) For proof and a deep dive, read my
    blog post [“MySQL LRU Flushing and I/O Capacity”](https://oreil.ly/YHEcj).
  prefs: []
  type: TYPE_NORMAL
- en: '^([8](ch06.html#idm45829104102032-marker)) *Legacy flushing* is also called
    *dirty pages percentage flushing*, but I prefer my term because it’s simpler and
    frames it more accurately: *legacy* implies that it’s no longer current, which
    is true.'
  prefs: []
  type: TYPE_NORMAL
