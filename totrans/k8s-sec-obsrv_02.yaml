- en: Chapter 2\. Infrastructure Security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many Kubernetes configurations are insecure by default. In this chapter we will
    explore how to secure Kubernetes at the infrastructure level. It can be made more
    secure through the combination of host hardening to make the servers or VMs Kubernetes
    is hosted on more secure, cluster hardening to secure the Kubernetes control plane
    components, and network security to integrate the cluster with the surrounding
    infrastructure. Please note that the concepts discussed in this chapter apply
    to self-hosted Kubernetes clusters as well as managed Kubernetes clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Host hardening
  prefs: []
  type: TYPE_NORMAL
- en: This covers the choice of operating system, avoiding running nonessential processes
    on the hosts, and host-based firewalling.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster hardening
  prefs: []
  type: TYPE_NORMAL
- en: This covers a range of configuration and policy settings needed to harden the
    control plane, including configuring TLS certificates, locking down the Kubernetes
    datastore, encrypting secrets at rest, credential rotation, and user authentication
    and access control.
  prefs: []
  type: TYPE_NORMAL
- en: Network security
  prefs: []
  type: TYPE_NORMAL
- en: This covers securely integrating the cluster with the surrounding infrastructure,
    and in particular which network interactions between the cluster and the surrounding
    infrastructure are allowed, for control plane, host, and workload traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the details for each of these aspects and explore what is needed
    to build a secure infrastructure for your Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Host Hardening
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A secure host is an important building block for a secure Kubernetes cluster.
    When you think of a host, it is in the context of workloads that make up your
    Kubernetes cluster. We will now explore techniques to ensure a strong security
    posture for the host.
  prefs: []
  type: TYPE_NORMAL
- en: Choice of Operating System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Many enterprises standardize on a single operating system across all of their
    infrastructure, which means the choice may have already been made for you. However,
    if there is flexibility to choose an operating system, then it is worth considering
    a modern immutable Linux distribution specifically designed for containers. These
    distributions are advantageous for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: They often have newer kernels, which include the latest vulnerability fixes
    as well as up-to-date implementations of newer technologies such as eBPF, which
    can be leveraged by Kubernetes networking and security monitoring tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are designed to be immutable, which brings additional benefits for security.
    Immutability in this context means that the root filesystem is locked and cannot
    be changed by applications. Applications can only be installed using containers.
    This isolates applications from the root filesystem and significantly reduces
    the ability for malicious applications to compromise the host.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They often include the ability to self-update to newer versions, with the upstream
    versions being geared up for rapid releases to address security vulnerabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two popular examples of modern immutable Linux distributions designed for containers
    are Flatcar Container Linux (which was originally based on CoreOS Container Linux)
    and Bottlerocket (originally created and maintained by Amazon).
  prefs: []
  type: TYPE_NORMAL
- en: Whichever operating system you choose, it is good practice to monitor upstream
    security announcements so you know when new security vulnerabilities are identified
    and disclosed and to make sure you have processes in place to update your cluster
    to a newer version to address critical security vulnerabilities. Based on your
    assessment of these vulnerabilities, you will want to make a decision on whether
    to upgrade your cluster to a new version of the operating system. When you consider
    the choice of the operating system, you must also take into account shared libraries
    from the host operating system and understand their impact on containers that
    will be deployed on the host.
  prefs: []
  type: TYPE_NORMAL
- en: Another security best practice is to ensure that application developers do not
    depend on a specific version of the operating system or kernel, as this will not
    allow you to update the host operating system as needed.
  prefs: []
  type: TYPE_NORMAL
- en: Nonessential Processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each running host process is a potential attack vector for hackers. From a security
    perspective, it is best to remove any nonessential processes that may be running
    by default. If a process isn’t needed for the successful running of Kubernetes,
    management of your host, or security of your host, then it is best not to run
    the process. How you disable the process will depend on your particular setup
    (e.g., systemd configuration change or removing the initialization script from
    /etc/init.d/).
  prefs: []
  type: TYPE_NORMAL
- en: If you are using an immutable Linux distribution optimized for containers, then
    nonessential processes will have already been eliminated and you can only run
    additional processes/applications as containers.
  prefs: []
  type: TYPE_NORMAL
- en: Host-Based Firewalling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To further lock down the servers or VMs Kubernetes is hosted on, the host itself
    can be configured with local firewall rules to restrict which IP address ranges
    and ports are allowed to interact with the host.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your operating system, this can be done with traditional Linux
    admin tools such as iptables rules or firewalld configuration. It is important
    to make sure any such rules are compatible with both the Kubernetes control plane
    and whichever Kubernetes network plug-in you plan to use so they do not block
    the Kubernetes control plane, pod networking, or the pod network control plane.
    Getting these rules right, and keeping them up to date over time, can be a time-consuming
    process. In addition, if using an immutable Linux distribution, you may not easily
    be able to directly use these tools.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, some Kubernetes network plug-ins can help solve this problem for
    you. For example, several Kubernetes network plug-ins, like Weave Net, Kube-router,
    and Calico, include the ability to apply network policies. You should review these
    plug-ins and pick one that also supports applying network policies to the hosts
    themselves (rather than just to Kubernetes pods). This makes securing the hosts
    in the cluster significantly simpler and is largely operating system independent,
    including working with immutable Linux distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Always Research the Latest Best Practices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As new vulnerabilities or attack vectors are identified by the security research
    community, security best practices evolve over time. Many of these are well-documented
    online and are available for free.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the Center for Internet Security maintains free PDF guides with
    comprehensive configuration guidance to secure many of the most common operating
    systems. Known as CIS Benchmarks, they are an excellent resource for making sure
    you are covering the many important actions required to secure your host operating
    system. You can find an [up-to-date list of CIS Benchmarks on their website](https://oreil.ly/dpUnC).
    Please note there are Kubernetes-specific benchmarks, and we will discuss them
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster Hardening
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is insecure by default. So in addition to hardening the hosts that
    make up a cluster, it is important to harden the cluster itself. This can be done
    through a combination of Kubernetes component and configuration management, authentication
    and role-based access control (RBAC), and keeping the cluster updated with the
    latest versions of Kubernetes to ensure the cluster has the latest vulnerability
    fixes.
  prefs: []
  type: TYPE_NORMAL
- en: Secure the Kubernetes Datastore
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes uses etcd as its main datastore. This is where all cluster configuration
    and desired state is stored. Having access to the etcd datastore is essentially
    equivalent to having root login on all your nodes. Almost any other security measures
    you have put in place within the cluster become moot if a malicious actor gains
    access to the etcd datastore. They will have complete control over your cluster
    at that point, including the ability to run arbitrary containers with elevated
    privileges on any node.
  prefs: []
  type: TYPE_NORMAL
- en: The main way to secure etcd is to use the security features provided by etcd
    itself. These are based around x509 Public Key Infrastructure (PKI), using a combination
    of keys and certificates. They ensure that all data in transit is encrypted with
    TLS and all access is restricted with strong credentials. It is best to configure
    etcd with one set of credentials (key pairs and certificates) for peer communications
    between the different etcd instances, and another set of credentials for client
    communications from the Kubernetes API. As part of this configuration, etcd must
    also be configured with the details of certificate authority (CA) used to generate
    the client credentials.
  prefs: []
  type: TYPE_NORMAL
- en: Once etcd is configured correctly, only clients with valid certificates can
    access it. You must then configure the Kubernetes API server with the client certificate,
    key, and certificate authority so it can access etcd.
  prefs: []
  type: TYPE_NORMAL
- en: You can also use network-level firewall rules to restrict etcd access so it
    can only be accessed from Kubernetes control nodes (hosting the Kubernetes API
    server). Depending on your environment you can use a traditional firewall, virtual
    cloud firewall, or rules on the etcd hosts themselves (for example, a networking
    policy implementation that supports host endpoint protection) to block traffic.
    This is best done in addition to using etcd’s own security features as part of
    an in-depth defense strategy, since limiting access with firewall rules does not
    address the security need for Kubernetes’ sensitive data to be encrypted in transit.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to securing etcd access for Kubernetes, it is recommended to not
    use the Kubernetes etcd datastore for anything other than Kubernetes. In other
    words, do not store non-Kubernetes data within the datastore and do not give other
    components access to the etcd cluster. If you are running applications or infrastructure
    (within the cluster or external to the cluster) that uses etcd as a datastore,
    the best practice is to set up a separate etcd cluster for that. The arguable
    exception would be if the application or infrastructure was sufficiently privileged
    that a compromise to its datastore would also result in a complete compromise
    of Kubernetes. It is also very important to maintain backups of etcd and secure
    the backups so that it is possible to recover from failures like a failed upgrade
    or a security incident.
  prefs: []
  type: TYPE_NORMAL
- en: Secure the Kubernetes API Server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One layer up from the etcd datastore, the next set of crown jewels to be secured
    is the Kubernetes API server. As with etcd, this can be done using x509 PKI and
    TLS. The details of how to bootstrap a cluster in this way vary depending on the
    Kubernetes installation method you are using, but most methods include steps that
    create the required keys and certificates and distribute them to the other Kubernetes
    cluster components. It’s worth noting that some installation methods may enable
    insecure local ports for some components, so it is important to familiarize yourself
    with the settings of each component to identify potential unsecured traffic so
    you can take appropriate action to secure them.
  prefs: []
  type: TYPE_NORMAL
- en: Encrypt Kubernetes Secrets at Rest
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes can be configured to encrypt sensitive data it stores in etcd, such
    as Kubernetes secrets. This keeps the secrets safe from any attacker that may
    gain access to etcd or to an offline copy of etcd such as offline backup.
  prefs: []
  type: TYPE_NORMAL
- en: By default, Kubernetes does not encrypt secrets at rest, and when encryption
    is enabled, it only encrypts when a secret is written to etcd. Therefore, when
    enabling encryption at rest, it is important to rewrite all secrets (through standard
    kubectl apply or update commands) to trigger their encryption within etcd.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes supports a variety of encryption providers. It is important to pick
    the recommended encryption based on encryption best practices. The mainline recommended
    choice is AES-CBC with PKCS #7–based encryption. This provides very strong encryption
    using 32-byte keys and is relatively fast. There are two different providers that
    support this encryption:'
  prefs: []
  type: TYPE_NORMAL
- en: The local provider that runs entirely with Kubernetes and uses locally configured
    keys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The KMS provider that uses an external key management service (KMS) to manage
    the keys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The local provider stores its keys on the API server’s local disk. This therefore
    has the limitation that if the API server host is compromised, then all of your
    secrets become compromised. Depending on your security posture, this may be acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: The KMS provider uses a technique called *envelope encryption*. With envelope
    encryption, each secret is encrypted with a dynamically generated data encryption
    key (DEK). The DEK is then encrypted using a key encryption key (KEK) provided
    by the KMS, and the encrypted DEK is stored alongside the encrypted secret in
    etcd. The KEK is always hosted by the KMS as the central root of trust and is
    never stored within the cluster. Most large public cloud providers offer a cloud-based
    KMS service that can be used as the KMS provider in Kubernetes. For on-prem clusters
    there are third-party solutions, such as HashiCorp’s Vault, which can act as the
    KMS provider for the cluster. Because the detailed implementations vary, it is
    important to evaluate the mechanism through which the KMS authenticates the API
    server and whether a compromise to the API server host could in turn compromise
    your secrets and therefore offer only limited benefits compared with a local encryption
    provider.
  prefs: []
  type: TYPE_NORMAL
- en: If exceptionally high volumes of encrypted storage read/writes are anticipated,
    then using the secretbox encryption provider could potentially be faster. However,
    secretbox is a newer standard and at the time of writing has had less review than
    other encryption algorithms. It therefore may not be considered acceptable in
    environments that require high levels of review. In addition, secretbox is not
    yet supported by the KMS provider and must use a local provider, which stores
    the keys on the API server.
  prefs: []
  type: TYPE_NORMAL
- en: Encrypting Kubernetes secrets is the most common must-have encryption at-rest
    requirement, but note that you can also configure Kubernetes to encrypt storage
    of other Kubernetes resources if desired.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also worth noting there are third-party secret management solutions that
    can be used if you have requirements beyond the capabilities of Kubernetes secrets.
    One such solution, already mentioned as a potential KMS provider for envelope
    encryption in Kubernetes, is HashiCorp’s Vault. In addition to providing secure
    secrets management for Kubernetes, Vault can be used beyond the scope of Kubernetes
    to manage secrets more broadly across the enterprise if desired. Vault was also
    a very popular choice for plugging the major gap in earlier Kubernetes versions,
    which did not support the encryption of secrets at rest.
  prefs: []
  type: TYPE_NORMAL
- en: Rotate Credentials Frequently
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rotating credentials frequently makes it harder for attackers to make use of
    any compromised credential they may obtain. It is therefore a best practice to
    set short lifetimes on any TLS certificates or other credentials and automate
    their rotation. Most authentication providers can control how long issued certificates
    or service tokens are valid for, and it is best to use short lifetimes whenever
    possible, for example rotating keys every day or more frequently if they are particularly
    sensitive. This needs to include any service tokens used in external integrations
    or as part of the cluster bootstrap process.
  prefs: []
  type: TYPE_NORMAL
- en: Fully automating the rotation of credentials may require custom DevOps development
    work, but normally represents a good investment compared with attempting to manually
    rotate credentials on an ongoing basis.
  prefs: []
  type: TYPE_NORMAL
- en: When rotating keys for Kubernetes secrets stored at rest (as discussed in the
    previous section), local providers support multiple keys. The first key is always
    used to encrypt any new secret writes. For decryption, the keys are tried in order
    until the secret is successfully decrypted. As keys are encrypted only on writes,
    it is important to rewrite all secrets (through standard kubectl apply or update
    commands) to trigger their encryption with the latest keys. If the rotation of
    secrets is fully automated, then the write will happen as part of this process
    without requiring a separate step.
  prefs: []
  type: TYPE_NORMAL
- en: When using a KMS provider (rather than a local provider), the KEK can be rotated
    without requiring reencryption of all the secrets, which can reduce the performance
    impact of reencrypting all secrets if you have a large number of sizable secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Authentication and RBAC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous sections we primarily focused on securing programmatic/code
    access within the cluster. Equally important is to follow best practices for securing
    user interactions with the cluster. This includes creating separate user accounts
    for each user and using Kubernetes RBAC to grant users the minimal access they
    need to perform their role, following the principle of least privilege access.
    Usually it is better to do this using groups and roles, rather than assigning
    RBAC permissions to individual users. This makes it easier to manage privileges
    over time, both in terms of adjusting privileges for different groups of users
    when requirements change and for reducing the effort required to periodically
    review/audit the user privileges across the cluster to verify they are correct
    and up to date.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has limited built-in authentication capabilities for users, but can
    be integrated with most external enterprise authentication providers, such as
    public cloud provider IAM systems or on-prem authentication services, either directly
    or through third-party projects such as Dex (originally created by CoreOS). It
    is generally recommended to integrate with one of these external authentication
    providers rather than using Kubernetes basic auth or service account tokens, since
    external authentication providers typically have more user-friendly support for
    rotation of credentials, including the ability to specify password strength and
    rotation frequency timeframes.
  prefs: []
  type: TYPE_NORMAL
- en: Restricting Cloud Metadata API Access
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most public clouds provide a metadata API that is accessible locally from each
    host/VM instance. The APIs provide access to the instance’s cloud credentials,
    IAM permissions, and other potentially sensitive information about the instance.
    By default, these APIs are accessible by the Kubernetes pods running on an instance.
    Any compromised pod can use these credentials to elevate its intended privilege
    level within the cluster or to other cloud provider–hosted services the instance
    may have privileges to access.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address this security issue, the best practice is to:'
  prefs: []
  type: TYPE_NORMAL
- en: Provide any required pod IAM credentials following the cloud provider’s recommended
    mechanisms. For example, Amazon EKS allows you to assign a unique IAM role to
    a service account, Microsoft Azure’s AKS allows you to assign a managed identity
    to a pod, and Google Cloud’s GKE allows you to assign IAM permissions via Workload
    Identity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limit the cloud privileges of each instance to the minimum required to reduce
    the impact of any compromised access to the metadata API from the instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use network policies to block pod access to the metadata API. This can be done
    with per-namespace Kubernetes network policies, or preferably with extensions
    to Kubernetes network policies such as those offered by Calico, which enable a
    single network policy to apply across the whole of the cluster (without the need
    to create a new Kubernetes network policy each time a new namespace is added to
    the cluster). This topic is covered in more depth in the Default Deny and Default
    App Policy section of [Chapter 7](ch07.xhtml#network_policy).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable Auditing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes auditing provides a log of all actions within the cluster with configurable
    scope and levels of detail. Enabling Kubernetes audit logging and archiving audit
    logs on a secure service is recommended as an important source of forensic details
    in the event of needing to analyze a security breach.
  prefs: []
  type: TYPE_NORMAL
- en: 'The forensic review of the audit log can help answer questions such as:'
  prefs: []
  type: TYPE_NORMAL
- en: What happened, when, and where in the cluster?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who or what initiated it and from where?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, Kubernetes audit logs can be actively monitored to alert on suspicious
    activity using your own custom tooling or third-party solutions. There are many
    enterprise products that you can use to monitor Kubernetes audit logs and generate
    alerts based on configurable match criteria.
  prefs: []
  type: TYPE_NORMAL
- en: The details of what events are captured in Kubernetes audit logs are controlled
    using policy. The policy determines which events are recorded, for which resources,
    and with what level of detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each action being performed can generate a series of events, defined as stages:'
  prefs: []
  type: TYPE_NORMAL
- en: RequestReceived
  prefs: []
  type: TYPE_NORMAL
- en: Generated as soon as the audit handler receives the request
  prefs: []
  type: TYPE_NORMAL
- en: ResponseStarted
  prefs: []
  type: TYPE_NORMAL
- en: Generated when the response headers are sent, but before the response body is
    sent (generated only for long-running requests such as watches)
  prefs: []
  type: TYPE_NORMAL
- en: ResponseComplete
  prefs: []
  type: TYPE_NORMAL
- en: Generated when the response body has been completed
  prefs: []
  type: TYPE_NORMAL
- en: Panic
  prefs: []
  type: TYPE_NORMAL
- en: Generated when a panic occurs
  prefs: []
  type: TYPE_NORMAL
- en: 'The level of detail recorded for each event can be one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: None
  prefs: []
  type: TYPE_NORMAL
- en: Does not log the event at all
  prefs: []
  type: TYPE_NORMAL
- en: Metadata
  prefs: []
  type: TYPE_NORMAL
- en: Logs the request metadata (user, timestamp, resource, verb, etc.) but not the
    request details or response body
  prefs: []
  type: TYPE_NORMAL
- en: Request
  prefs: []
  type: TYPE_NORMAL
- en: Logs event metadata and the request body but not the response body
  prefs: []
  type: TYPE_NORMAL
- en: RequestResponse
  prefs: []
  type: TYPE_NORMAL
- en: Logs the full details of the event, including the metadata and request and response
    bodies
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes’ audit policy is very flexible and well documented in the main Kubernetes
    documentation. Included here are just a couple of simple examples to illustrate.
  prefs: []
  type: TYPE_NORMAL
- en: 'To log all requests at the metadata level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To omit the `RequestReceived` stage and to log pod changes at the `RequestResponse`
    level and configmap and secrets changes at the metadata level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This second example illustrates the important consideration of sensitive data
    in audit logs. Depending on the level of security around access to the audit logs,
    it may be essential to ensure the audit policy does not log details of secrets
    or other sensitive data. Just like the practice of encrypting secrets at rest,
    it is generally a good practice to always exclude sensitive details from your
    audit log.
  prefs: []
  type: TYPE_NORMAL
- en: Restrict Access to Alpha or Beta Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each Kubernetes release includes alpha and beta features. Whether these are
    enabled can be controlled by specifying feature gate flags for the individual
    Kubernetes components. As these features are in development, they can have limitations
    or bugs that result in security vulnerabilities. So it is a good practice to make
    sure that all alpha and beta features you do not intend to use are disabled.
  prefs: []
  type: TYPE_NORMAL
- en: Alpha features are normally (but not always) disabled by default. They might
    be buggy, and the support for the feature could radically change without backward
    compatibility, or be dropped in future releases. They are generally recommended
    for testing clusters only, not production clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Beta features are normally enabled by default. They can still change in non-backward-compatible
    ways between releases, but they are usually considered reasonably well tested
    and safe to enable. But as with any new feature, they are inherently more likely
    to have vulnerabilities because they have been used less and had less review.
  prefs: []
  type: TYPE_NORMAL
- en: Always assess the value an alpha or beta feature may provide against the security
    risk it represents, as well as the potential ops risk of non-backward-compatible
    changes of the features between releases.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrade Kubernetes Frequently
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is inevitable that new vulnerabilities will be discovered over time in any
    large software project. The Kubernetes developer community has a good track record
    of responding to newly discovered vulnerabilities in a timely manner. Severe vulnerabilities
    are normally fixed under embargo, meaning that the knowledge of the vulnerability
    is not made public until the developers have had time to produce a fix. Over time,
    the number of publicly known vulnerabilities for older Kubernetes versions grows,
    which can put older clusters at greater security risk.
  prefs: []
  type: TYPE_NORMAL
- en: To reduce the risk of your clusters being compromised, it is important to regularly
    upgrade your clusters, and to have in place the ability to urgently upgrade if
    a severe vulnerability is discovered.
  prefs: []
  type: TYPE_NORMAL
- en: All Kubernetes security updates and vulnerabilities are reported (once any embargo
    ends) via the public and free-to-join *kubernetes-announce* email group. Joining
    this group is highly recommended for anyone wanting to keep track of known vulnerabilities
    so they can minimize their security exposure.
  prefs: []
  type: TYPE_NORMAL
- en: Use a Managed Kubernetes Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One way to reduce the effort required to act on all of the advice in this chapter
    is to use one of the major public cloud managed Kubernetes services, such as EKS,
    AKS, GKE, or IKS. Using one of these services moves security from being 100% your
    own responsibility to being a shared responsibility model. Shared responsibility
    means there are many elements of security that the service includes by default,
    or can be easily configured to support, but that there are elements you still
    have to take responsibility for yourself in order to make the whole truly secure.
  prefs: []
  type: TYPE_NORMAL
- en: The details vary depending on which public cloud service you are using, but
    there’s no doubt that all of them do significant heavy lifting, which reduces
    the effort required to secure the cluster compared to if you are installing and
    managing the cluster yourself. In addition, there are plenty of resources available
    from the public cloud providers and from third parties that detail what you need
    to do as part of the shared responsibility model to fully secure your cluster.
    For example, one of these resources is CIS Benchmarks, as discussed next.
  prefs: []
  type: TYPE_NORMAL
- en: CIS Benchmarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed earlier in this chapter, CIS maintains free PDF guides with comprehensive
    configuration guidance to secure many of the most common operating systems. These
    guides, known as CIS Benchmarks, can be an invaluable resource to help you with
    host hardening.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to helping with host hardening, there are also CIS Benchmarks for
    Kubernetes itself, including configuration guidance for many of the popular managed
    Kubernetes services, which can help you implement much of the guidance in this
    chapter. For example, the GKE CIS Benchmark includes guidance on ensuring the
    cluster is configured with autoupgrade of nodes, and for using managing Kubernetes
    authentication and RBAC with Google Groups. These guides are highly recommended
    resources to keep up to date with the latest practical advice on the steps required
    to secure Kubernetes clusters.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the guides themselves, there are third-party tools available
    that can assess the status of a running cluster against many of these benchmarks.
    One popular tool is kube-bench, an open source project originally created by the
    team at Aqua Security. Or if you prefer a more packaged solution, then many enterprise
    products have CIS Benchmark and other security compliance tooling and alerting
    built into their cluster management dashboards. Having these kinds of tools in
    place, ideally running automatically at regular intervals, can be valuable for
    verifying the security posture of a cluster and ensuring that careful security
    measures that might have been put in place at cluster creation time are not accidentally
    lost or compromised as the cluster is managed and updated over time.
  prefs: []
  type: TYPE_NORMAL
- en: Network Security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When securely integrating the cluster with the surrounding infrastructure outside
    the scope of the cluster, network security is the primary consideration. There
    are two aspects to consider: how to protect the cluster from attack from outside
    the cluster and how to protect the infrastructure outside of the cluster from
    any compromised element inside the cluster. This applies at both the cluster workload
    level (i.e., Kubernetes pods) and the cluster infrastructure level (i.e., the
    Kubernetes control plane and the hosts on which the Kubernetes cluster is running).'
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to consider is whether or not the cluster needs to be accessible
    from the public internet, either directly (e.g., one or more nodes have public
    IP addresses) or indirectly (e.g., via a load balancer or similar that is reachable
    from the internet). If the cluster is accessible from the internet, then the number
    of attacks or probes from hackers is massively increased. So if there is not a
    strong requirement for the cluster to be accessible from the internet, then it
    is highly recommended to not allow any access at a routability level (i.e., ensuring
    there is no way of packets getting from the internet to the cluster). In an enterprise
    on-prem environment, this may equate to the choice of IP address ranges to use
    for the cluster and their routability within the enterprise network. If using
    a public cloud managed Kubernetes service, you may find these settings can be
    set only at cluster creation. For example, in GKE, whether the Kubernetes control
    plane is accessible from the internet can be set at cluster creation.
  prefs: []
  type: TYPE_NORMAL
- en: Network policy within the cluster is the next line of defense. Network policy
    can be used to restrict both workload and host communications to/from the cluster
    and the infrastructure outside of the cluster. It has the strong advantage of
    being workload aware (i.e., the ability to limit communication of groups of pods
    that make up an individual microservices) and being platform agnostic (i.e., the
    same techniques and policy language can be used in any environment, whether on-prem
    within the enterprise or in public cloud). Network policy is discussed in depth
    later in a dedicated chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is highly recommended to use perimeter firewalls, or their cloud
    equivalents such as security groups, to restrict traffic to/from the cluster.
    In most cases these are not Kubernetes workload aware, so they don’t understand
    individual pods and are therefore usually limited in granularity to treating the
    whole of the cluster as a single entity. Even with this limitation they add value
    as part of a defense strategy, though on their own they are unlikely to be sufficient
    for any security-conscious enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: 'If stronger perimeter defense is desired, there are strategies and third-party
    tools that can make perimeter firewalls or their cloud equivalents more effective:'
  prefs: []
  type: TYPE_NORMAL
- en: One approach is to designate a small number of specific nodes in the cluster
    as having a particular level of access to the rest of the network, which is not
    granted to the rest of the nodes in the cluster. Kubernetes taints can then be
    used to ensure that only workloads that need that special level of access are
    scheduled to those nodes. This way perimeter firewall rules can be set based on
    the IP addresses of the specific nodes to allow desired access, and all other
    nodes in the cluster are denied access outside the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In an on-prem environment, some Kubernetes network plug-ins allow you to use
    routable pod IP addresses (nonoverlay networks) and control the IP address ranges
    that the group of pods backing a particular microservice use. This allows perimeter
    firewalls to act on IP address ranges in a similar way as they do with traditional
    non-Kubernetes workloads. For example, you need to pick a network plug-in that
    supports nonoverlay networks on-prem that are routable across the broader enterprise
    networks and that has flexible IP address management capabilities to facilitate
    such an approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A variation of the previous is useful in any environment where it is not practical
    to make pod IP addresses routable outside of the cluster (e.g., when using an
    overlay network). In this scenario, the network traffic from pods appears to come
    from the IP address of the node as it uses source network address translation
    (SNAT). In order to address this, you can use a Kubernetes network plug-in that
    supports fine-grained control of egress NAT gateways. The egress NAT gateway feature
    supported by some Kubernetes network plug-ins allows this behavior to be changed
    so that the egress traffic for a set of pods is routed via specific gateways within
    the cluster that perform the SNAT, so the traffic appears to be coming from the
    gateway, rather than from the node hosting the pod. Depending on the network plug-in
    being used, the gateways can be allocated to specific IP address ranges or to
    specific nodes, which in turn allows perimeter firewall rules to act more selectively
    than treating the whole of the cluster as a single entity. There are a few options
    that support this functionality: Red Hat’s OpenShift SDN, Nirmata, and Calico
    all support egress gateways.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, some firewalls support some plug-ins or third-party tools that allow
    the firewall to be more aware of Kubernetes workloads, for example, by automatically
    populating IP address lists within the firewall with pod IP addresses (or node
    IP addresses of the nodes hosting particular pods). Or in a cloud environment,
    there are automatic programming rules that allow security groups to selectively
    act on traffic to/from Kubernetes pods, rather than operating only at the node
    level. This integration is very important for your cluster to help complement
    the security provided by firewalls. There are several tools in the market that
    allow this type of integration. It is important to choose a tool that supports
    these integrations with major firewall vendors and is native to Kubernetes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the previous section we discussed the importance of network security and
    how you can use network security to secure access to your Kubernetes cluster from
    traffic originating outside the cluster and also how to control access for traffic
    originating from within the cluster destined to hosts outside the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we discussed the following key concepts, which you should use
    to ensure you have a secure infrastructure for your Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: You need to ensure that the host is running an operating system that is secure
    and free from critical vulnerabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to deploy access controls on the host to control access to the host
    operating system and deploy controls for network traffic to and from the host.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to ensure a secure configuration for your Kubernetes cluster; securing
    the datastore and API server are key to ensuring you have a secure cluster configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, you need to deploy network security to control network traffic that
    originates from pods in the cluster and is destined to pods in the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
