- en: Appendix. Answers to Review Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chapter 2, “Cluster Setup”
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a file with the name `deny-egress-external.yaml` for defining the network
    policy. The network policy needs to set the Pod selector to `app=backend` and
    define the `Egress` policy type. Make sure to allow the port 53 for the protocols
    UDP and TCP. The namespace selector for the egress policy needs to use `{}` to
    select all namespaces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the `apply` command to instantiate the network policy object from the YAML
    file:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A Pod that does not match the label selection of the network policy can make
    a call to a URL outside of the cluster. In this case, the label assignment is
    `app=frontend`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*****   A Pod that does match the label selection of the network policy cannot
    make a call to a URL outside of the cluster. In this case, the label assignment
    is `app=backend`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'First, see if the Dashboard is already installed. You can check the namespace
    the Dashboard usually creates:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the namespace does not exist, you can assume that the Dashboard has not
    been installed yet. Install it with the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the ServiceAccount, ClusterRole, and ClusterRoleBinding. Make sure that
    the ClusterRole only allows listing Deployment objects. The following YAML manifest
    has been saved in the file `dashboard-observer-user.yaml`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the objects with the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following command to create a token for the ServiceAccount. The option
    `--duration 0s` ensures that the token will never expire. Copy the token that
    was rendered in the console output of the command:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the proxy command and open the link [*http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy*](http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy)
    in a browser:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Select the “Token” authentication method and paste the token you copied before.
    Sign into the Dashboard. You should see that only Deployment objects are listable
    (see [Figure A-1](#dashboard-deployments)).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: All other objects will say “There is nothing to display here.” [Figure A-2](#dashboard-pods)
    renders the list of Pods.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![ckss aa01](assets/ckss_aa01.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A-1\. The Dashboard view of Deployments is allowed
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: '![ckss aa02](assets/ckss_aa02.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A-2\. The Dashboard view of Pods is not permitted
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Download the API server binary with the following command:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, download the SHA256 file for the same binary, but a different version.
    The following command downloads the file for version 1.23.1:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Comparing the binary file with the checksum file results in a failure, as the
    versions do not match:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]****'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '****# Chapter 3, “Cluster Hardening”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a private key using the `openssl` executable. Provide an expressive
    file name, such as `jill.key`. The `-subj` option provides the username (CN) and
    the group (O). The following command uses the username `jill` and the group named
    `observer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrieve the base64-encoded value of the CSR file content with the following
    command. You will need it when creating a the CertificateSigningRequest object
    in the next step:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following script creates a CertificateSigningRequest object:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `certificate approve` command to approve the signing request and export
    the issued certificate:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the user to the kubeconfig file and add the context for the user. The cluster
    name used here is `minikube`. It might be different for your Kubernetes environment:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Role and RoleBinding. The following imperative commands assign the
    verbs `get`, `list`, and `watch` for Pods, ConfigMaps, and Secrets to the subject
    named `observer` of type `group`. The user `jill` is part of the group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Switch to the user context:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We’ll pick one permitted operation, listing ConfigMap objects. The user is
    authorized to map the call:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Listing nodes won’t be authorized. The user does not have the appropriate permissions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Switch back to the admin context:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the namespace `t23`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the service account `api-call` in the namespace:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a YAML manifest file with the name `pod.yaml`. The contents of the file
    define a Pod that makes an HTTPS GET call to the API server to retrieve the list
    of Services in the `default` namespace:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Pod with the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the logs of the Pod. The API call is not authorized, as shown in the
    following log output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the YAML manifest in the file `clusterrole.yaml`, as shown in the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reference the ClusterRole in a RoleBinding defined in the file `rolebinding.yaml`.
    The subject should list the service account `api-call` in the namespace `t23`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create both objects from the YAML manifests:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The API call running inside of the container should now be authorized and be
    allowed to list the Service objects in the `default` namespace. As shown in the
    following output, the namespace currently hosts at least one Service object, the
    `kubernetes.default` Service:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the token for the service account using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Change the existing Pod definition by deleting and recreating the live object.
    Add the attribute that disables automounting the token, as shown in the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The API server will allow the HTTPS request performed with the token of the
    service account to be authenticated and authorized:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The solution to this sample exercise requires a lot of manual steps. The following
    commands do not render their output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open an interactive shell to the control plane node using Vagrant:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upgrade `kubeadm` to version 1.26.1 and apply it:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Drain the node, upgrade the kubelet and `kubectl`, restart the kubelet, and
    uncordon the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The version of the node should now say v1.26.1\. Exit the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open an interactive shell to the first worker node using Vagrant. Repeat all
    of the following steps for the worker node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upgrade `kubeadm` to version 1.26.1 and apply it to the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Drain the node, upgrade the kubelet and `kubectl`, restart the kubelet, and
    uncordon the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The version of the node should now say v1.26.1\. Exit out of the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Chapter 4, “System Hardening”
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Shell into the worker node with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Identify the process exposing port 21\. One way to do this is by using the
    `lsof` command. The command that exposes the port is `vsftpd`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Alternatively, you could also use the `ss` command, as shown in the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The process `vsftpd` has been started as a service:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Shut down the service and deinstall the package:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Checking on the port, you will see that it is not listed anymore:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Exit out of the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Shell into the worker node with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the AppArmor profile at `/etc/apparmor.d/network-deny` using the command
    `sudo vim /etc/apparmor.d/network-deny`. The contents of the file should look
    as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Enforce the AppArmor profile by running the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You cannot modify the existing Pod object in order to add the annotation for
    AppArmor. You will need to delete the object first. Write the definition of the
    Pod to a file:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Edit the `pod.yaml` file to add the AppArmor annotation. For the relevant annotation,
    use the name of the container `network-call` as part of the key suffix and `localhost/network-deny`
    as the value. The suffix `network-deny` refers to the name of the AppArmor profile.
    The final content could look as follows after a little bit of cleanup:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Pod from the manifest. After a couple of seconds, the Pod should
    transition into the “Running” status:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'AppArmor prevents the Pod from making a network call. You can check the logs
    to verify:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Exit out of the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Shell into the worker node with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the target directory for the seccomp profiles:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the file `audit.json` in the directory `/var/lib/kubelet/seccomp/profiles`
    with the following content:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You cannot modify the existing Pod object in order to add the seccomp configuration
    via the security context. You will need to delete the object first. Write the
    definition of the Pod to a file:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Edit the `pod.yaml` file. Point the seccomp profile to the definition. The
    final content could look as follows after a little bit of cleanup:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Pod from the manifest. After a couple of seconds, the Pod should
    transition into the “Running” status:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should be able to find log entries for syscalls, e.g., for the `sleep`
    command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Exit out of the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Pod definition in the file `pod.yaml`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Pod and then check on the status. You will see that the status is
    “SysctlForbidden”:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The event log will tell you more about the reasoning:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Chapter 5, “Minimize Microservice Vulnerabilities”
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Define the Pod with the security settings in the file `busybox-security-context.yaml`.
    You can find the content of the following YAML manifest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Pod with the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Shell into the container and create the file. You will find that the file group
    is 2000, as defined by the security context:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Specify the namespace named `audited` in the file `psa-namespace.yaml`. Set
    the PSA label with `baseline` level and the `warn` mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the namespace from the YAML manifest:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can produce an error by using the following Pod configuration in the file
    `psa-pod.yaml`. The YAML manifest sets the attribute `hostNetwork: true`, which
    is not allowed for the [`baseline` level](https://oreil.ly/c8JEW):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Creating the Pod renders a warning message. The Pod will have been created
    nevertheless. You can prevent the creation of the Pod by configuring the PSA with
    the `restricted` level:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can install Gatekeeper with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The Gatekeeper library describes a ConstraintTemplate for defining [replica
    limits](https://oreil.ly/gyD1-). Inspect the YAML manifest described on the page.
    Apply the manifest with the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, define the Constraint with the YAML manifest in the file named `replica-limits-constraint.yaml`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Constraint with the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can see that a Deployment can only be created if the provided number of
    replicas falls within the range of the Constraint:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Configure encryption for etcd, as described in [“Encrypting etcd Data”](ch05.xhtml#encrypting-etcd-data).
    Next, create a new Secret with the following imperative command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can check the encrypted value of the Secret stored in etcd with the following
    command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open an interactive shell to the worker node using Vagrant:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the RuntimeClass with the following YAML manifest. The contents have
    been stored in the file `runtime-class.yaml`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the RuntimeClass object:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign the name of the RuntimeClass to the Pod using the `spec.runtimeClassName`
    attribute. The nginx Pod has been defined in the file `pod.yaml`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Pod object. The Pod will transition into the status “Running”:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Exit out of the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Chapter 6, “Supply Chain Security”
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The initial container image built with the provided Dockerfile has a size of
    998MB. You can produce and run the container image with the following commands.
    Run a quick `curl` command to see if the endpoint exposed by the application can
    be reached:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'One of the changes you can make is to avoid using a large base image. You could
    replace it with the `alpine` version of the node base image. Also, avoid pulling
    the `latest` image. Pick the Node.js version you actually want the application
    to run with. The following command uses a Dockerfile with the base image `node:19-alpine`,
    which reduces the container image size to 176MB:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can install Kyverno using Helm or by pointing to the YAML manifest available
    on the project’s GitHub repository. We’ll use the YAML manifest here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set up a YAML manifest file named `restrict-image-registries.yaml`. Add the
    following contents to the file. The manifest represents a ClusterPolicy that only
    allows the use of container images that start with `gcr.io/`. Make sure to assign
    the value `Enforce` to the attribute `spec.validationFailureAction`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the manifest with the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following commands to verify that the policy has become active. Any
    container image definition that doesn’t use the prefix `gcr.io/` will be denied:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the SHA256 hash for the image `nginx:1.23.3-alpine` with the search functionality
    of Docker Hub. The [search result](https://oreil.ly/a4o8E) will lead you to the
    tag of the image. On top of the page, you should find the digest `sha256:c1b9fe3c0c015486cf1e4a0ecabe78d05864475e279638e9713eb55f013f907f`.
    Use the digest instead of the tag in the Pod definition. The result is the following
    YAML manifest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The creation of the Pod should work:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you modify the SHA256 hash in any form and try to recreate the Pod, then
    Kubernetes would not allow you to pull the image.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Running Kubesec in a Docker container results in a whole bunch of suggestions,
    as shown in the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The fixed-up YAML manifest could look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Executing the `kubectl apply` command against the existing `setup.yaml` manifest
    will create the Pods named `backend`, `loop`, and `logstash` in the namespace
    `r61`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can check on them with the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the images of each Pod in the namespace `r61` using the `kubectl describe`
    command. The images used are `bmuschko/nodejs-hello-world:1.0.0`, `alpine:3.13.4`,
    and `elastic/logstash:7.13.3`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the Trivy executable to check vulnerabilities for all images:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you look closely at the list of vulnerabilities, you will find that all
    images contain issues with “CRITICAL” severity. As a result, delete all Pods:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Chapter 7, “Monitoring, Logging, and Runtime Security”
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Shell into the worker node with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inspect the command and arguments of the running Pod named `malicious`. You
    will see that it tries to append a message to the file `/etc/threat`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'One of Falco’s default rules monitors file operations that try to write to
    the `/etc` directory. You can find a message for every write attempt in standard
    output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the rule that produces the message in `/etc/falco/falco_rules.yaml` by
    searching for the string “etc opened for writing.” The rule looks as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Copy the rule to the file `/etc/falco/falco_rules.local.yaml` and modify the
    output definition, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Restart the Falco service, and find the changed output in the Falco logs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Edit the file `/etc/falco/falco.yaml` to change the output channel. Disable
    standard output, enable file output, and point the `file_output` attribute to
    the file `/var/log/falco.log`. The resulting configuration will look like the
    following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The log file will now append Falco log:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Exit out of the VM:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Pod named `hash` from the `setup.yaml` file. The command running
    in its container appends a hash to a file at `/var/config/hash.txt` in an infinite
    loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To make the container immutable, you will have to add configuration to the
    existing Pod definition. You have to set the root filesystem to read-only access
    and mount a Volume to the path `/var/config` to allow writing to the file named
    `hash.txt`. The resulting YAML manifest could look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Shell into the control plane node with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Edit the existing audit policy file at `/etc/kubernetes/audit/rules/audit-policy.yaml`.
    Add the rules asked about in the instructions. The content of the final audit
    policy file could look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Configure the API server to consume the audit policy file by editing the file
    `/etc/kubernetes/manifests/kube-apiserver.yaml`. Provide additional options, as
    requested. The relevant configuration needed is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'One of the logged resources is a ConfigMap on the `Metadata` level. The following
    command creates an exemplary ConfigMap object:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The audit log file will now contain an entry for the event:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Exit out of the VM:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE120]****'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
