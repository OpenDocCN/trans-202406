- en: Chapter 5\. Moving to Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In today’s world, consumers and business customers alike demand increasing speed.
    Complex, modern applications must deliver better results more quickly in areas
    like personalization, artificial intelligence, and fraud detection across verticals.
    Centrally managed and human-operated applications are a drain on struggling IT
    teams and provide diminishing returns; traditional application architecture can’t
    keep up with today’s huge data volume, global deployment, and demand for horizontal
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'PaaS and SaaS are paradigms that work best when they are elastic, scaling up
    and down to meet unpredictable demand. Unlike traditional monolithic on-premises
    applications, PaaS and SaaS must scale horizontally, adding physical or virtual
    resources immediately when needed. Because adding physical on-premises servers
    is often a slow process with a long lead time, this means that modern applications
    must be able to run anywhere: in on-premises environments, in cloud environments,
    or in hybrid environments that consist of a combination of the two.'
  prefs: []
  type: TYPE_NORMAL
- en: The answer that has emerged is to break up applications into microservices running
    in containers. This introduces complexity beyond what IT teams can be asked to
    manage manually, necessitating automated management, provisioning, load balancing,
    and fault resolution. These requirements are essentially the feature list of Kubernetes.
    Kubernetes is a platform that orchestrates collections of containers in a variety
    of environments, making it possible to build cloud native, microservices-based
    apps and run them anywhere. For this reason, Kubernetes has become the dominant
    way that companies deploy applications at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Even when DevOps teams have all the skills they need to run a production Kubernetes
    cluster, data storage remains challenging. Every application and service has its
    own storage needs, metadata, and way of handling state. Every kind of data has
    its own requirements around security, scalability, compliance, and availability.
    If that isn’t enough, the sheer number of applications and data types required
    for the enterprise means exponentially more complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of Kubernetes Adoption
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Few enterprises are starting from scratch. A typical enterprise runs large numbers
    of legacy applications originally designed to run on physical servers or VMs.
    While cloud native, containerized applications are the clear path forward, it
    isn’t practical to immediately abandon all the legacy applications that are powering
    the organization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adopting Kubernetes means investing in cloud native, containerized applications
    while supporting more traditional application architectures. Providing separate
    storage for both types of software is impractical both because of operational
    cost and because it slows down data processing. There are two approaches that
    can help: running containers inside VMs, or running VMs inside containers. An
    advantage of the latter approach is that it allows Kubernetes to manage the VMs
    where traditional applications are running, moving them as needed.'
  prefs: []
  type: TYPE_NORMAL
- en: Persistent storage is paramount for every organization as data volume grows.
    The enterprise requires seamless management of vast quantities of data, with stringent
    needs around data security, high availability, and disaster recovery. Data must
    be available in multiple locations, geographically controllable for compliance,
    and highly performant. Designed originally for stateless processes, Kubernetes
    isn’t natively suited to the data needs of enterprise companies.
  prefs: []
  type: TYPE_NORMAL
- en: To run applications at scale, the enterprise needs Kubernetes. But to run Kubernetes
    at scale, companies also need strategies to provide an underlying storage layer,
    decoupled from compute containers, which can support the needs of complex, large-scale
    business applications.
  prefs: []
  type: TYPE_NORMAL
- en: Running Large-Scale Systems on Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The key to running Kubernetes at scale is the ability to optimize resource allocation
    as demand changes, automatically scaling resources and services up and down as
    needed. Although Kubernetes lets you declaratively automate cluster management
    and compute resources, you still need additional tools to efficiently manage storage.
  prefs: []
  type: TYPE_NORMAL
- en: An important factor is to ensure that storage is allocated properly and not
    wasted. Because block storage was not originally designed for use by massive numbers
    of containers, resource efficiency in Kubernetes can be challenging. Out of the
    box, Kubernetes offers a limited number of volumes per host and doesn’t provide
    a wide range of tools for capabilities such as failover, backup, and disaster
    recovery. This often leads to overprovisioning of block storage by a factor of
    two or three, and a resultant decrease in application efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: On the public cloud, providers generally limit the number of block devices that
    can be attached to a single VM, leading to another kind of overprovisioning. If
    a VM has enough compute power to serve more containers than the provider allows,
    it becomes necessary at some point to provision an additional VM for storage.
    This drives up compute cost and increases management overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Data portability becomes a more important part of managing storage resources
    at scale. To maximize operational storage efficiency, it must be possible to move
    workloads to the most cost-effective storage. This means the enterprise must be
    able to move data and applications nimbly between environments, across providers,
    or from one team to another. Hyperconverged topology can help reduce cost and
    complexity, making it easier to scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'Software-defined storage, which abstracts away individual hardware and presents
    all available storage as a single pool, is one important component in running
    Kubernetes efficiently at scale, because it can support traditional applications
    as well as containerized workloads. You still need to make decisions about the
    underlying compute and storage hardware. Just running the compute and storage
    platforms requires a minimum set of resources on every node. Above that floor,
    you must make decisions about how much work each node should be capable of, such
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: How many apps will run on each node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many containers each node will support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much CPU each container gets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the same total cluster workload, you must decide whether to run a smaller
    number of more powerful nodes, or a larger number of less powerful nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud and hybrid environments make these questions easier to answer, because
    they allow you to start small and grow as needed by provisioning more compute
    and storage resources. There is no way to anticipate the needs of every possible
    application and workload. It’s impossible to plan a cluster that will work for
    everyone. By provisioning only what’s needed and scaling as you grow, you can
    continually tailor Kubernetes at scale to meet the needs of the enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most time-intensive and disruptive aspects of Kubernetes in production
    is storage capacity management. In highly dynamic environments, storage needs
    can be extremely volatile, making storage nearly impossible to manage without
    sophisticated tools and automation. The right storage management solution can
    help you provision storage intelligently to avoid waste while scaling on demand.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, the goal of running large-scale Kubernetes deployments is to serve
    enterprise applications, including PaaS and SaaS. These deployments must meet
    demands for data security, portability, compliance, locality, and availability,
    among others. Kubernetes can’t meet these business-critical needs without help.
    To meet the data needs of the marketplace, you need a coordinated storage layer
    that can manage the reliability and performance of container volumes, providing
    high availability, replication, storage tiering, disaster recovery, backup, and
    the other features that the modern enterprise application demands.
  prefs: []
  type: TYPE_NORMAL
