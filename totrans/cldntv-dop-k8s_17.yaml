- en: Chapter 15\. Observability and Monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第15章。可观测性和监控
- en: Nothing is ever completely right aboard a ship.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在船上，没有什么是完全正确的。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: William Langewiesche, *The Outlaw Sea*
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 威廉·兰格维奇，《违禁之海》
- en: In this chapter, we’ll consider the question of observability and monitoring
    for cloud native applications. What is observability? How does it relate to monitoring?
    How do you do monitoring, logging, metrics, and tracing in Kubernetes?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨云原生应用程序的可观测性和监控问题。什么是可观测性？它与监控有何关系？在 Kubernetes 中如何进行监控、日志记录、度量和跟踪？
- en: What Is Observability?
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是可观测性？
- en: '*Observability* may not be a familiar term to you, though it’s becoming increasingly
    popular as a way to express the larger world beyond traditional monitoring. Let’s
    tackle *monitoring* first before we see how observability extends it.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*可观测性*可能对您来说并不是一个熟悉的术语，尽管它作为表达传统监控之外更广阔世界的方式越来越流行。在我们看到可观测性如何扩展监控之前，让我们先解决*监控*这个问题。'
- en: What Is Monitoring?
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是监控？
- en: Is your website working right now? Go check; we’ll wait. The most basic way
    to know whether all your applications and services are working as they should
    is to look at them yourself. But when we talk about monitoring in a DevOps context,
    we mostly mean *automated monitoring*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你的网站现在能正常工作吗？去检查一下；我们会等你。了解所有应用程序和服务是否按预期工作的最基本方法是自己查看它们。但是在 DevOps 上下文中谈论监控时，我们大多数时候指的是*自动化监控*。
- en: Automated monitoring is checking the availability or behavior of a website or
    service, in some programmatic way, usually on a regular schedule, and usually
    with some automated way of alerting human engineers if there’s a problem. But
    what defines a problem?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化监控是以某种编程方式定期检查网站或服务的可用性或行为，并通常以自动化方式警告人类工程师是否存在问题。但问题的定义是什么？
- en: Closed-Box Monitoring
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 封闭箱监控
- en: Let’s take the simple case of a static website. If it’s not working at all,
    it just won’t respond, or you’ll see an error message in the browser. So the simplest
    possible monitoring check for this site is to fetch the home page and check the
    HTTP status code (200 indicates a successful request). You could do this with
    a command-line HTTP client such as `httpie` or `curl`. If the exit status from
    the client is nonzero, there was a problem fetching the website.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以静态网站为例。如果根本无法工作，它将不会响应，或者您会在浏览器中看到错误消息。因此，此站点的最简单监控检查是获取主页并检查 HTTP 状态码（200
    表示成功请求）。您可以使用命令行 HTTP 客户端（如`httpie`或`curl`）执行此操作。如果客户端的退出状态为非零，则表示获取网站时出现问题。
- en: But suppose something went wrong with the web server configuration, and although
    the server is working and responding with HTTP `200 OK` status, it is actually
    serving a blank page (or some sort of default or welcome page, or maybe the wrong
    site altogether). Our simplistic monitoring check won’t detect any issue because
    the HTTP request succeeds; however, the site is not working as expected for users.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但假设 Web 服务器配置出现问题，尽管服务器工作并响应 HTTP `200 OK` 状态，但实际上却提供空白页面（或某种默认或欢迎页面，或者可能是错误的网站）。我们简单的监控检查将无法检测到任何问题，因为
    HTTP 请求成功；然而，网站对用户而言并未按预期工作。
- en: A more sophisticated monitoring check might look for some specific text on the
    page that you know should be there, like the name of the organization. This would
    catch the problem of a misconfigured, but working, web server.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的监控检查可能会寻找页面上的特定文本，例如组织的名称。这将捕捉配置错误但工作正常的 Web 服务器问题。
- en: Beyond static pages
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超越静态页面
- en: You can imagine that more complex websites might need more complex monitoring.
    For example, if the site had a facility for users to log in, the monitoring check
    might also try to log in with a known test-user account and alert if the login
    fails. Or if the site had a search function, the check might fill in a text field
    with some search text, simulate clicking the search button, and verify that the
    results contain some expected text.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以想象更复杂的网站可能需要更复杂的监控。例如，如果网站具有用户登录功能，则监控检查可能还会尝试使用已知的测试用户帐户登录，并在登录失败时发出警报。或者如果网站具有搜索功能，则检查可能会填写文本字段以某些搜索文本，模拟点击搜索按钮，并验证结果中是否包含某些预期的文本。
- en: 'For simple websites, a yes/no answer to the question “Is it working?” may be
    sufficient. For cloud native applications, which tend to be more complex distributed
    systems, the question may turn into multiple questions:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于简单的网站，对于问题“它是否工作？”的肯定或否定答案可能已经足够。对于云原生应用程序来说，这些应用程序往往是更复杂的分布式系统，问题可能会变成多个问题：
- en: Is my application available everywhere in the world? Or only in some regions?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我的应用程序在全球各地都可用吗？还是只在某些地区？
- en: How long does it take to load for most of my users?
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数用户加载需要多长时间？
- en: What about users who may have slow download speeds?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于可能拥有较慢下载速度的用户怎么办？
- en: Are all of the features of my website working as intended?
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我网站的所有功能是否按预期工作？
- en: Are certain features working slowly or not at all, and how many users are affected?
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特定功能的工作速度慢或完全不起作用，影响了多少用户？
- en: If it relies on a third-party service, what happens to my application when that
    external service is faulty or unavailable?
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它依赖于第三方服务，当外部服务出现故障或不可用时，我的应用程序会发生什么？
- en: What happens when my cloud provider has an outage?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我的云提供商遇到故障时会发生什么？
- en: It starts to become clear that, in the world of monitoring cloud native distributed
    systems, not very much is clear at all.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 开始清楚地看到，在监控云原生分布式系统的世界中，并没有很多事情是清晰的。
- en: The limits of closed-box monitoring
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 闭盒监控的局限性
- en: 'However, no matter how complicated these checks get, they all fall into the
    same category of monitoring: *closed-box monitoring*. Closed-box checks, as the
    name suggests, observe only the external behavior of a system, without any attempt
    to observe what’s going on inside it.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 但无论这些检查变得多么复杂，它们都属于同一类监控：*闭盒监控*。正如其名称所示，闭盒检查只观察系统的外部行为，而不尝试观察其内部发生的事情。
- en: 'Until a few years ago, closed-box monitoring, as performed by popular tools
    such as Nagios, Icinga, Zabbix, Sensu, and Check_MK, was pretty much state of
    the art. To be sure, having *any* kind of automated monitoring of your systems
    is a huge improvement on having none. But there are a few limitations of closed-box
    checks:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 直到几年前，像Nagios、Icinga、Zabbix、Sensu和Check_MK等流行工具执行的闭盒监控基本上是技术的最前沿。确实，任何类型的系统自动监控相比没有监控都是一大进步。但是闭盒检查存在一些局限性：
- en: They can only detect predictable failures (for example, a website not responding).
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们只能检测可预测的故障（例如，网站无响应）。
- en: They only check the behavior of the parts of the system that are exposed to
    the outside.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们只检查系统外部暴露的部分的行为。
- en: They are passive and reactive; they only tell you about a problem *after* it’s
    happened.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们是被动和反应式的；他们只在问题发生*后*告诉你。
- en: They can answer the question “What’s broken?” but not the more important question
    “Why?”
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们可以回答“发生了什么问题？”的问题，但无法回答更重要的“为什么？”的问题。
- en: To answer the “why?” question, we need to move beyond traditional monitoring.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答“为什么？”的问题，我们需要超越传统的监控。
- en: There’s a further issue with this kind of *up*/*down* test; what does *up* even
    mean?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这种*up*/*down*测试还有另外一个问题；*up*究竟意味着什么？
- en: What Does “Up” Mean?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “Up”是什么意思？
- en: In operations we’re used to measuring the resilience and availability of our
    applications in *uptime*, usually measured as a percentage. For example, an application
    with 99% uptime was unavailable for no more than 1% of the relevant time period.
    99.9% uptime, referred to as *three nines*, translates to about nine hours downtime
    a year, which would be a good figure for the average web application. Four nines
    (99.99%) is less than an hour’s downtime per year, and five nines (99.999%) is
    about five minutes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在运维中，我们习惯于通过*uptime*来衡量应用程序的弹性和可用性，通常以百分比表示。例如，99%的可用性意味着在相关时间段内最多不可用1%。99.9%的可用性，称为*三个9*，相当于每年大约九小时的停机时间，对于平均网络应用来说是一个不错的指标。四个9（99.99%）意味着每年不到一个小时的停机时间，而五个9（99.999%）大约是五分钟。
- en: 'So, the more nines the better, you might think. But looking at things this
    way misses an important point:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，更多的“nines”越好，你可能会这样想。但是，用这种方式看待问题会忽略一个重要的观点：
- en: Nines don’t matter if users aren’t happy.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果用户不满意，百分比无关紧要。
- en: ''
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Charity Majors](https://red.ht/2FMZcMZ)'
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[查理·梅杰斯](https://red.ht/2FMZcMZ)'
- en: Nines don’t matter if users aren’t happy
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如果用户不满意，百分比无关紧要。
- en: 'As the saying goes, what gets measured gets maximized. So you’d better be very
    careful what you measure. If your service isn’t working for users, it doesn’t
    matter what your internal metrics say: *the service is down*. There are lots of
    ways a service can be making users unhappy, even if it’s nominally *up*.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 俗话说，被测量的东西会被最大化。因此，你最好非常小心你测量的内容。如果你的服务对用户不起作用，无论内部指标如何，都无关紧要：*服务已停止*。服务可能使用户不满意的方式有很多，即使它名义上是*up*。
- en: To take an obvious example, what if your website takes 10 seconds to load? It
    might work fine after that, but if it’s too slow to respond, it might as well
    be down completely. Users will just go elsewhere.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 举个明显的例子，如果您的网站加载需要10秒钟？加载后可能运行正常，但如果响应太慢，它可能就等同于完全不可用了。用户只会转而去其他地方。
- en: Traditional closed-box monitoring might attempt to deal with this problem by
    defining a load time of, say, five seconds as *up*, and anything over that is
    considered *down* and an alert generated. But what if users are experiencing all
    sorts of different load times, from 2 seconds to 10 seconds? With a hard threshold
    like this, you could consider the service *down* for some users, but *up* for
    others. What if load times are fine for users in North America, but unusable in
    Europe or Asia?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的封闭盒监控可能会尝试通过定义比如说五秒的加载时间为*上行*，超过这个时间就被视为*下行*并生成警报来解决这个问题。但是如果用户体验到各种不同的加载时间，从2秒到10秒呢？使用这样的硬阈值，对于一些用户来说服务可能被认为是*下行*，但对于其他用户来说是*上行*。如果加载时间对于北美的用户来说很好，但对于欧洲或亚洲的用户来说不可用呢？
- en: Cloud native applications are never “up”
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 云原生应用程序从来都不是“上行”
- en: While you could go on refining more complex rules and thresholds to enable us
    to give an *up*/*down* answer about the status of the service, the truth is that
    the question is irredeemably flawed. Distributed systems like cloud native applications
    are [never *up*](http://red.ht/2hMHwSL); they exist in a constant state of partially
    degraded service.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管您可以继续精细化更复杂的规则和阈值，以使我们能够对服务状态给出*上行*/*下行*的答复，但事实是这个问题已经彻底有缺陷了。像云原生应用这样的分布式系统[永远不会是“上行”](http://red.ht/2hMHwSL)；它们存在于一个持续部分降级服务的状态中。
- en: This is an example of a class of problems called [*gray failures*](https://oreil.ly/4r86k).^([1](ch15.html#idm45979374465760))
    Gray failures are, by definition, hard to detect, especially from a single point
    of view or with a single observation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一类称为[*灰色失败*](https://oreil.ly/4r86k).^([1](ch15.html#idm45979374465760))的问题的示例。灰色失败从单一视角或单一观察特别难以检测到。
- en: So while closed-box monitoring may be a good place to start your observability
    journey, it’s important to recognize that you shouldn’t stop there. Let’s see
    if we can do better.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管封闭盒监控可能是开始您可观察性之旅的好地方，但重要的是要意识到您不应该止步于此。让我们看看是否能做得更好。
- en: Logging
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 日志记录
- en: 'Most applications produce *logs* of some kind. Logs are a series of records,
    usually with some kind of timestamps to indicate when records were written, and
    in what order. For example, a web server records each request in its logs, including
    information such as:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数应用程序都会产生某种形式的*日志*。日志是一系列记录，通常带有某种时间戳，指示记录的编写时间和顺序。例如，Web服务器会在其日志中记录每个请求，包括诸如：
- en: The URI requested
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求的URI
- en: The IP address of the client
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端的IP地址
- en: The HTTP status of the response
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应的HTTP状态
- en: If the application encounters an error, it usually logs this fact, along with
    some information that may or may not be helpful for operators to figure out what
    caused the problem.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果应用程序遇到错误，通常会记录此事实，以及可能或可能不有助于运营商找出问题原因的一些信息。
- en: Often, logs from a wide range of applications and services will be *aggregated*
    into a central database (Elasticsearch, for example), where they can be queried
    and graphed to help with troubleshooting. Tools like Logstash and Kibana, or hosted
    services such as Splunk and Loggly, are designed to help you gather and analyze
    large volumes of log data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 经常，来自各种应用和服务的日志将被*汇总*到一个中央数据库（例如Elasticsearch），在那里可以查询和绘制图表以帮助解决问题。像Logstash和Kibana这样的工具，或者像Splunk和Loggly这样的托管服务，旨在帮助您收集和分析大量的日志数据。
- en: The limits of logging
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 日志的限制
- en: Logs can be useful, but they have their limitations too. The decision about
    what to log or not to log is taken by the programmer at the time the application
    is written. Therefore, like closed-box checks, logs can only answer questions
    or detect problems that can be predicted in advance.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 日志可能很有用，但它们也有其局限性。关于是否记录或不记录的决定是在编写应用程序时由程序员做出的。因此，就像封闭盒检查一样，日志只能回答事先可以预测的问题或检测问题。
- en: It can also be hard to extract information from logs, because every application
    writes logs in a different format, and operators often need to write customized
    parsers for each type of log record to turn it into usable numerical or event
    data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从日志中提取信息也可能很困难，因为每个应用程序都以不同的格式编写日志，并且运营商通常需要为每种类型的日志记录编写定制的解析器，将其转换为可用的数值或事件数据。
- en: Because logs have to record enough information to diagnose any conceivable kind
    of problem, they usually have a poor signal-to-noise ratio. If you log everything,
    it’s difficult and time-consuming to wade through hundreds of pages of logs to
    find the one error message you need. If you log only occasional errors, it’s hard
    to know what *normal* looks like.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因为日志必须记录足够的信息来诊断任何可能的问题，它们通常具有较低的信噪比。如果记录所有内容，则在尝试查找所需的一个错误消息时，浏览数百页日志非常困难和耗时。如果仅记录偶发错误，则很难知道*正常*看起来是什么样子。
- en: Using a standard format for your logs can greatly improve their usefulness.
    Logging events in something like JSON with a known structure will make it much
    easier to sift through the noise when trying to make sense of what the logs are
    saying.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标准格式记录日志可以极大地提高其实用性。在类似 JSON 的已知结构中记录事件将使在尝试理解日志内容时能够更轻松地筛选噪音。
- en: Logs are hard to scale
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 日志难以扩展
- en: Logs also don’t scale very well with traffic. If every user request generates
    a log line that has to be sent to the aggregator, you can end up using a lot of
    network bandwidth (which is thus unavailable to serve users), and your log aggregator
    can become a bottleneck.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 日志在处理流量方面也扩展不佳。如果每个用户请求都生成一个必须发送到聚合器的日志行，则可能会使用大量网络带宽（从而无法为用户提供服务），并且您的日志聚合器可能会成为瓶颈。
- en: 'Many hosted logging providers also charge by the volume of logs you generate,
    which is understandable but unfortunate: it incentivizes you financially to log
    less information, and to have fewer users and serve less traffic!'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 许多托管日志提供商还根据生成的日志量收费，这是可以理解的但不幸的：它在财务上激励您记录较少的信息，并减少用户并降低服务流量！
- en: 'The same applies to self-hosted logging solutions: the more data you store,
    the more hardware, storage, and network resources you have to pay for, and the
    more engineering time goes into merely keeping log aggregation working.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 自托管的日志解决方案也是如此：存储的数据越多，您需要支付的硬件、存储和网络资源就越多，而仅仅保持日志聚合工作也需要更多的工程时间。
- en: Is logging useful in Kubernetes?
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，日志记录是否有用？
- en: We talked a little about how containers generate logs and how you can inspect
    them directly in Kubernetes, in [“Viewing a Container’s Logs”](ch07.html#containerlogs).
    This is a useful debugging technique for individual containers.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍微谈了一下容器如何生成日志以及如何在 Kubernetes 中直接检查它们，在[“查看容器日志”](ch07.html#containerlogs)中。这对于单个容器是一种有用的调试技术。
- en: If you do use logging, you should use some form of structured data, like JSON,
    which can be automatically parsed (see [“The Observability Pipeline”](#o11ypipeline))
    rather than plain-text records.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您确实使用日志记录，应该使用某种结构化数据，比如 JSON，这样可以自动解析（参见[“可观测性管道”](#o11ypipeline)），而不是简单的文本记录。
- en: Centralized log aggregation with services like [Loki](https://oreil.ly/1r4BG)
    can be useful with Kubernetes applications, but it’s not the whole story. While
    there are some business use-cases for centralized logging (audit and security
    requirements, for example, or customer analytics), logs can’t give us all the
    information we need for true observability.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 集中日志聚合服务（如[Loki](https://oreil.ly/1r4BG)）对于 Kubernetes 应用程序非常有用，但这并非解决问题的全部。尽管集中日志有一些商业用例（例如审计和安全要求，或客户分析），日志不能提供我们实现真正可观察性所需的所有信息。
- en: For that, we need to look beyond logs, to something much more powerful.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要超越日志，寻找更强大的解决方案。
- en: Introducing Metrics
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入度量指标
- en: 'A more sophisticated way of gathering information about your services is to
    use *metrics*. As the name suggests, a metric is a numerical measure of something.
    Depending on the application, relevant metrics might include:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的收集服务信息的方式是使用*度量指标*。顾名思义，度量指标是某些事物的数值度量。根据应用程序的不同，相关的度量指标可能包括：
- en: The number of requests currently being processed
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前正在处理的请求数量
- en: The number of requests handled per minute (or per second, or per hour)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每分钟（或每秒、每小时）处理的请求数量
- en: The number of errors encountered when handling requests
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理请求时遇到的错误数量
- en: The average time it took to serve requests (or the peak time, or the 99th percentile)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务请求平均处理时间（或峰值时间、第99百分位数）
- en: 'It’s also useful to gather metrics about your infrastructure as well as your
    applications:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 收集基础架构以及应用程序的度量指标也非常有用：
- en: The CPU usage of individual processes or containers
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个进程或容器的 CPU 使用率
- en: The disk I/O activity of nodes and servers
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点和服务器的磁盘 I/O 活动
- en: The inbound and outbound network traffic of machines, clusters, or load balancers
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器、集群或负载均衡器的入站和出站网络流量
- en: Metrics help answer the “why?” question
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指标帮助回答“为什么？”的问题
- en: 'Metrics open up a new dimension of monitoring beyond simply finding out if
    something is *working* or *not working*. Like the speedometer in your car, or
    the temperature scale on your thermometer, they give you numerical information
    about what’s happening. Unlike logs, metrics can easily be processed in all sorts
    of useful ways: drawing graphs, taking statistics, or alerting on predefined thresholds.
    For example, your monitoring system might alert you if the error rate for an application
    exceeds 10% for a given time period.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 指标开启了一种新的监控维度，不仅仅是简单地查看某些东西是否*工作*或*不工作*。就像你车上的速度计或温度计上的温度刻度一样，它们为你提供了正在发生的数值信息。与日志不同，指标可以轻松地以各种有用的方式处理：绘制图表、进行统计或在预定义的阈值上发出警报。例如，你的监控系统可能会在应用程序的错误率在特定时间段内超过10%时向你发出警报。
- en: Metrics can also help answer the “why?” question about problems. For example,
    suppose users are experiencing long response times (high *latency*) from your
    app. You check your metrics, and you see that the spike in the *latency* metric
    coincides with a similar spike in the *CPU usage* metric for a particular machine
    or component. That immediately gives you a clue about where to start looking for
    the problem. The component may be wedged, or repeatedly retrying some failed operation,
    or its host node may have a hardware problem.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 指标还可以帮助回答关于问题“为什么？”的问题。例如，假设用户从您的应用程序中体验到长时间的响应时间（高*延迟*）。您检查了您的指标，发现*延迟*指标的峰值与特定机器或组件的*CPU使用*指标的类似峰值相一致。这立即为您提供了一个问题开始寻找问题的线索。组件可能被卡住，或者重复尝试某些失败的操作，或者其主机节点可能存在硬件问题。
- en: Metrics help predict problems
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指标有助于预测问题
- en: 'Also, metrics can be *predictive*: when things go wrong, it usually doesn’t
    happen all at once. Before a problem is noticeable to you or your users, an increase
    in some metric may indicate that trouble is on the way.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，指标可以是*预测性*的：当事情出错时，通常不会一下子就发生。在问题对您或您的用户可察觉之前，某些指标的增加可能表明麻烦即将来临。
- en: For example, the disk usage metric for a server may creep up and up over time,
    and eventually reach the point where the disk actually runs out of space and things
    start failing. If you alerted on that metric before it got into failure territory,
    you could prevent the failure from happening at all.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，服务器的磁盘使用率指标可能随着时间的推移而逐渐增加，最终达到磁盘实际上用完空间并开始失败的点。如果在它进入失败状态之前就对该指标发出警报，您可以完全防止失败的发生。
- en: Some systems even use machine learning techniques to analyze metrics, detect
    anomalies, and reason about the cause. This can be helpful, especially in complex
    distributed systems, but for most purposes, simply having a way to gather, graph,
    and alert on metrics is plenty good enough.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一些系统甚至使用机器学习技术分析指标，检测异常，并推断原因。这在复杂的分布式系统中尤其有用，但对于大多数目的来说，仅仅有一种收集、绘图和警报指标的方法就已经足够了。
- en: Metrics monitor applications from the inside
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指标监视应用程序的内部情况
- en: 'With closed-box checks, operators have to make guesses about the internal implementation
    of the app or service, and predict what kind of failures might happen and what
    effect this would have on external behavior. By contrast, metrics allow application
    developers to export key information about the hidden aspects of the system, based
    on their knowledge of how it actually works (and how it fails):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 通过闭盒检查，运营商必须猜测应用程序或服务的内部实现，并预测可能发生的故障以及这将对外部行为产生什么影响。相比之下，指标允许应用程序开发人员根据他们对系统实际运行方式（以及其失败方式）的了解，导出关键信息的隐藏方面：
- en: Stop reverse engineering applications and start monitoring from the inside.
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 停止逆向工程应用程序，从内部开始监控。
- en: ''
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Kelsey Hightower, Monitorama 2016](https://vimeo.com/173610242)'
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Kelsey Hightower, Monitorama 2016](https://vimeo.com/173610242)'
- en: Tools like Prometheus, StatsD, and Graphite, or hosted services such as Datadog,
    New Relic, and Dynatrace, are widely used to gather and manage metrics data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 工具如Prometheus、StatsD和Graphite，或者像Datadog、New Relic和Dynatrace这样的托管服务，被广泛用于收集和管理指标数据。
- en: We’ll talk much more in [Chapter 16](ch16.html#metrics) about metrics in the
    context of Kubernetes, including what kinds you should focus on, and what you
    should do with them. For now, let’s complete our survey of observability with
    a look at tracing.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第 16 章](ch16.html#metrics)详细讨论 Kubernetes 的度量标准，包括应重点关注的类型以及如何处理它们。现在，让我们通过观察跟踪来完成我们对可观测性的调查。
- en: Tracing
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪
- en: Another useful technique in the monitoring toolbox is *tracing*. It’s especially
    important in distributed systems. While metrics and logs tell you what’s going
    on with each individual component of your system, tracing follows a single user
    request through its whole life cycle.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在监控工具箱中，另一个有用的技术是*跟踪*。在分布式系统中尤为重要。虽然度量和日志可以告诉您系统每个单独组件的运行情况，但跟踪则是跟随单个用户请求的整个生命周期。
- en: 'Suppose you’re trying to figure out why some users are experiencing very high
    latency for requests. You check the metrics for each of your system components:
    load balancer, ingress, web server, application server, database, message bus,
    and so on; and everything appears normal. So what’s going on?'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您正试图弄清楚为什么一些用户的请求延迟非常高。您检查了系统每个组件的度量标准：负载均衡器、入口、Web 服务器、应用服务器、数据库、消息总线等等；一切看起来都正常。那么问题出在哪里呢？
- en: When you trace an individual (hopefully representative) request from the moment
    the user’s connection is opened to the moment it’s closed, you’ll get a picture
    of how that overall latency breaks down for each stage of the request’s journey
    through the system.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当您跟踪一个（希望是代表性的）请求，从用户连接打开到关闭，您将了解该请求在系统中每个阶段的整体延迟情况。
- en: For example, you may find that the time spent handling the request in each stage
    of the pipeline is normal, except for the database hop, which is one hundred times
    longer than normal. Although the database is working fine and its metrics show
    no problems, for some reason the application server is having to wait a very long
    time for requests to the database to complete.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可能会发现在管道的每个阶段处理请求所花费的时间都是正常的，除了数据库跳跃，其时间是正常时间的一百倍。尽管数据库运行良好，其度量显示没有问题，但出于某种原因，应用服务器必须等待数据库请求完成的时间非常长。
- en: Eventually you track down the problem to excessive packet loss over one particular
    network link between the application servers and the database server. Without
    the *request’s eye view* provided by distributed tracing, it’s hard to find problems
    like this.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，您发现问题是应用服务器与数据库服务器之间的某个特定网络链接上出现了严重的数据包丢失。如果没有分布式跟踪提供的*请求视角*，很难发现这类问题。
- en: Some popular distributed tracing tools include [Zipkin](https://zipkin.io),
    [Jaeger](https://www.jaegertracing.io), and [Lightstep](https://lightstep.com/product).
    Engineer Masroor Hasan has written a useful blog post, [“Distributed Tracing Infrastructure
    with Jaeger on Kubernetes”](https://oreil.ly/esVav) that describes how to use
    Jaeger for distributed tracing in Kubernetes.^([2](ch15.html#idm45979374404496))
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一些流行的分布式跟踪工具包括 [Zipkin](https://zipkin.io)，[Jaeger](https://www.jaegertracing.io)
    和 [Lightstep](https://lightstep.com/product)。工程师 Masroor Hasan 写了一篇有用的博文，[“使用
    Jaeger 在 Kubernetes 上进行分布式跟踪基础设施”](https://oreil.ly/esVav)，描述了如何在 Kubernetes 中使用
    Jaeger 进行分布式跟踪。^([2](ch15.html#idm45979374404496))
- en: The [OpenTracing framework](https://opentracing.io) (part of the CNCF) aims
    to provide a standard set of APIs and libraries for distributed tracing.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenTracing 框架](https://opentracing.io)（CNCF 的一部分）旨在为分布式跟踪提供一套标准的 API 和库。'
- en: '[Pixie](https://px.dev) is another interesting project that adds tracing and
    application profiling for Kubernetes applications, along with a rich query language
    that allows you to explore what is happening inside of the cluster.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pixie](https://px.dev) 是另一个有趣的项目，为 Kubernetes 应用程序添加了跟踪和应用程序性能分析功能，还提供了丰富的查询语言，让您可以探索集群内部发生的情况。'
- en: Observability
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可观测性
- en: Because the term *monitoring* means different things to different people—from
    plain old closed-box checks to a combination of metrics, logging, and tracing—it’s
    becoming common to use *observability* as a catch-all term that covers all these
    techniques. The observability of your system is a measure of how well instrumented
    it is, and how easily you can find out what’s going on inside it. Some people
    say that observability is a superset of monitoring, others that observability
    reflects a completely different mindset from traditional monitoring.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 因为*监控*这个术语对不同的人有不同的意义——从简单的闭盒检查到指标、日志和跟踪的组合，现在使用*可观察性*作为一个涵盖所有这些技术的总称越来越普遍。系统的可观察性衡量了它的仪表化程度，以及你能够多容易地了解其内部情况。有些人说可观察性是监控的超集，另一些人则认为可观察性反映了与传统监控完全不同的思维方式。
- en: Perhaps the most useful way to distinguish these terms is to say that monitoring
    tells you *whether the system is working*, while observability prompts you to
    ask *why it’s not working*, along with considering *how well it is performing*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 区分这些术语最有用的方法或许是说监控告诉你*系统是否工作*，而可观察性则促使你问*为什么它不工作*，并考虑*它的表现如何*。
- en: Observability is about understanding
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可观察性是关于理解
- en: 'More generally, observability is about *understanding*: understanding what
    your system does and how it does it. For example, if you roll out a code change
    that is designed to improve the performance of a particular feature by 10%, then
    observability can tell you whether or not it worked. If performance only went
    up a tiny bit, or worse, went down slightly, you need to revisit the code.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 更普遍地说，可观察性是关于*理解*：理解你的系统在做什么以及它是如何做到的。例如，如果你推出一个设计上能提高特定功能性能10%的代码更改，可观察性可以告诉你它是否起作用了。如果性能只提高了一点点，或者更糟的是稍微下降了，你需要重新审视代码。
- en: On the other hand, if performance went up 20%, the change exceeded your expectations,
    and maybe you need to think about why your predictions fell short. Observability
    helps you build and refine your mental model of how the different parts of your
    system interact.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果性能提高了20%，这种变化超出了你的预期，也许你需要考虑为什么你的预测不足。可观察性帮助你建立和完善系统不同部分相互作用的心理模型。
- en: Observability is also about *data*. We need to know what data to generate, what
    to collect, how to aggregate it (if appropriate), what results to focus on, and
    how to query and display them.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性也涉及*数据*。我们需要知道生成什么数据、收集什么数据、如何聚合数据（如果适用）、关注哪些结果，以及如何查询和展示它们。
- en: Software is opaque
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 软件是不透明的
- en: 'In traditional monitoring we have lots of data about the *machinery*: CPU loads,
    disk activity, network packets, and so on. But it’s hard to reason backward from
    that about what our *software* is doing. To do that, we need to instrument the
    software itself:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统监控中，我们拥有大量关于*机器*的数据：CPU负载、磁盘活动、网络数据包等等。但是从这些数据反推我们的*软件*在做什么是很困难的。要做到这一点，我们需要为软件本身添加仪表：
- en: Software is opaque by default; it must generate data in order to clue humans
    in on what it is doing. Observable systems allow humans to answer the question,
    “Is it working properly?”, and if the answer is no, to diagnose the scope of impact
    and identify what is going wrong.
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 软件默认是不透明的；它必须生成数据，以便让人类了解它在做什么。可观察的系统使人类能够回答“它是否正常工作？”这个问题，并且如果答案是否定的，还能够诊断影响范围并确定出现了什么问题。
- en: ''
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Christine Spang](https://oreil.ly/iJeFI)'
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[克里斯汀·斯潘格](https://oreil.ly/iJeFI)'
- en: Building an observability culture
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 建立可观察性文化
- en: Even more generally, observability is about *culture*. It’s a key tenet of the
    DevOps philosophy to close the loop between developing code and running it at
    scale in production. Observability is the primary tool for closing that loop.
    Developers and operations staff need to work closely together to instrument services
    for observability, and then figure out the best way to consume and act on the
    information it provides.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 更普遍地说，可观察性是关于*文化*的。它是DevOps哲学的关键原则，即在开发代码和在生产环境中运行代码之间闭环。可观察性是关闭这一环路的主要工具。开发人员和运维人员需要密切合作，为可观察性仪表化服务，并找出消费和处理所提供信息的最佳方法。
- en: The Observability Pipeline
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可观察性管道
- en: How does observability work, from a practical point of view? It’s common to
    have multiple data sources (logs, metrics, and so on) connected to various different
    data stores in a fairly ad hoc way.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际角度来看，可观察性是如何工作的？通常会有多个数据源（日志、指标等）以一种相当自发的方式连接到不同的数据存储中。
- en: For example, your logs might go to an ELK server, while metrics go to three
    or four different managed services, and traditional monitoring checks report to
    yet another service. This isn’t ideal.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您的日志可能会发送到 ELK 服务器，而指标可能会发送到三四个不同的托管服务，传统的监控检查报告可能会发送到另一个服务。这并不理想。
- en: For one thing, it’s hard to scale. The more data sources and stores you have,
    the more interconnections there are, and the more traffic over those connections.
    It doesn’t make sense to put engineering time into making all of those different
    kinds of connections stable and reliable.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一方面，难以扩展。数据源和存储越多，相互连接越多，连接上的流量就越多。把工程时间投入到使所有这些不同类型的连接稳定可靠并不合理。
- en: Also, the more tightly integrated your systems become with specific solutions
    or providers, the harder it is to change them or to try out alternatives.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，系统与特定解决方案或提供者的紧密集成，使得更改它们或尝试替代方案更加困难。
- en: 'An increasingly popular way to address this problem is the [*observability
    pipeline*](https://oreil.ly/Vyn5M):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的越来越流行的方法是[*可观察性管道*](https://oreil.ly/Vyn5M)：
- en: With an observability pipeline, we decouple the data sources from the destinations
    and provide a buffer. This makes the observability data easily consumable. We
    no longer have to figure out what data to send from containers, VMs, and infrastructure,
    where to send it, and how to send it. Rather, all the data is sent to the pipeline,
    which handles filtering it and getting it to the right places. This also gives
    us greater flexibility in terms of adding or removing data sinks, and it provides
    a buffer between data producers and consumers.
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用可观察性管道，我们将数据源与目的地解耦，并提供缓冲区。这使得可观察性数据易于消费。我们不再需要弄清楚应该从容器、虚拟机和基础设施发送什么数据，将其发送到哪里以及如何发送。相反，所有数据都发送到管道中，管道负责过滤并将其发送到正确的位置。这还使我们在添加或删除数据接收器方面具有更大的灵活性，并为数据生产者和消费者之间提供了缓冲区。
- en: ''
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tyler Treat
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Tyler Treat
- en: An observability pipeline brings great advantages. Now, adding a new data source
    is just a matter of connecting it to your pipeline. Similarly, a new visualization
    or alerting service just becomes another consumer of the pipeline.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性管道带来了很大的优势。现在，添加新的数据源只是将其连接到您的管道。类似地，新的可视化或警报服务只是管道的另一个消费者。
- en: Because the pipeline buffers data, nothing gets lost. If there’s a sudden surge
    in traffic and an overload of metrics data, the pipeline will buffer it rather
    than drop samples.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 由于管道会缓冲数据，因此不会丢失任何数据。如果流量突然激增并导致指标数据过载，管道会缓冲它，而不是丢弃样本。
- en: Using an observability pipeline requires a standard metrics format (see [“Prometheus”](ch16.html#prometheus))
    and, ideally, structured logging from applications using JSON or some other sensible
    serialized data format. Instead of emitting raw text logs, and parsing them later
    with fragile regular expressions, start with structured data from the very beginning.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 使用可观察性管道需要标准的指标格式（参见[“Prometheus”](ch16.html#prometheus)）以及理想情况下，应用程序使用 JSON
    或其他合理的序列化数据格式进行结构化日志记录。不要再发出原始文本日志，然后稍后用脆弱的正则表达式进行解析，而是从一开始就使用结构化数据。
- en: Monitoring in Kubernetes
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 监控
- en: So now that we understand a little more about what closed-box monitoring is
    and how it relates to observability in general, let’s see how it applies to Kubernetes
    applications.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对封闭盒监控及其与总体上的可观察性的关系有了更多理解，让我们看看它如何适用于 Kubernetes 应用程序。
- en: External Closed-Box Checks
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外部封闭盒检查
- en: As we’ve seen, closed-box monitoring can only tell you that your application
    is down. But that’s still very useful information. All kinds of things could be
    wrong with a cloud native application, and it might still be able to serve some
    requests acceptably. Engineers can work on fixing internal problems like slow
    queries and elevated error rates, without users really being aware of an issue.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，封闭盒监控只能告诉您应用程序已经宕机。但这仍然是非常有用的信息。云原生应用程序可能存在各种问题，但仍然可以接受某些请求。工程师可以致力于解决内部问题，如慢查询和增加的错误率，而用户并不真正意识到存在问题。
- en: 'However, a more serious class of problems results in a full-scale *outage*:
    the application is unavailable or not working for the majority of users. This
    is bad for the users, and depending on the application, it may be bad for your
    business as well. In order to detect an outage, your monitoring needs to consume
    the service in the same way that a user would.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，更严重的问题类别导致全面的*停机*：应用程序对大多数用户不可用或不起作用。这对用户来说是不好的，依赖于应用程序，这也可能对您的业务不利。为了检测停机情况，您的监控需要以与用户相同的方式使用服务。
- en: Monitoring mimics user behavior
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控模拟用户行为
- en: For example, if it’s an HTTP service, the monitoring system needs to make HTTP
    requests to it, not just TCP connections. If the service just returns static text,
    monitoring can check the text matches some expected string. Usually, it’s a little
    bit more complicated than that, but your checks can also be more robust.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果是HTTP服务，则监控系统需要向其发出HTTP请求，而不仅仅是TCP连接。如果服务只返回静态文本，监控可以检查文本是否与某些预期字符串匹配。通常情况比这复杂一点，但您的检查也可以更加健壮。
- en: 'In an outage situation, though, it’s quite likely that a simple text match
    will be sufficient to tell you the application is down. But making these closed-box
    checks from inside your infrastructure (for example, in Kubernetes) isn’t enough.
    An outage can result from all sorts of problems and failures between the user
    and the outside edge of your infrastructure, including:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在停机情况下，一个简单的文本匹配很可能足以告诉您应用程序已停止。但是仅在您的基础设施内（例如在Kubernetes中）进行这些封闭框检查是不够的。停机可能由用户与基础设施外部边缘之间的各种问题和故障导致，包括：
- en: Bad DNS records
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误的DNS记录
- en: Network partitions
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络分区
- en: Packet loss
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据包丢失
- en: Misconfigured routers
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置错误的路由器
- en: Missing or bad firewall rules
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失或错误的防火墙规则
- en: Cloud provider outage
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云提供商停机
- en: In all these situations, your internal metrics and monitoring might show no
    problems at all. Therefore, your top-priority observability task should be to
    monitor the availability of your services from some point external to your own
    infrastructure. There are many third-party services that can do this kind of monitoring
    for you, including Uptime Robot, Pingdom, and Wormly.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些情况下，您的内部指标和监控可能根本没有显示任何问题。因此，您的首要可观察性任务应该是从您自己的基础设施外部的某一点监控服务的可用性。有许多第三方服务可以为您执行此类监控，包括Uptime
    Robot、Pingdom和Wormly。
- en: Don’t build your own monitoring infrastructure
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不要建立自己的监控基础设施
- en: Most of these services have either a free tier, or fairly inexpensive subscriptions—and
    whatever you pay for them you should regard as an essential operating expense.
    Don’t bother trying to build your own external monitoring infrastructure; it’s
    not worth it. The cost of a year’s Pro subscription to Uptime Robot likely would
    not pay for a single hour of your engineers’ time.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数这些服务都有免费层或相当廉价的订阅，并且无论你为它们付费多少，都应将其视为必要的运营费用。不要试图建立自己的外部监控基础设施；这是不值得的。一年的Uptime
    Robot专业订阅费用可能还不足以支付你工程师一小时的工时费用。
- en: 'Look for the following critical features in an external monitoring provider:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在外部监控提供商中查找以下关键特性：
- en: HTTP/HTTPS checks
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP/HTTPS检查
- en: Detect if your TLS certificate is invalid or expired
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测您的TLS证书是否无效或已过期
- en: Keyword matching (alert when the keyword is missing *or* when it’s present)
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键词匹配（当关键词缺失时发出警报*或*当其存在时）
- en: Automatically create or update checks via an API
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过API自动创建或更新检查
- en: Alerts by email, SMS, webhook, or some other straightforward mechanism
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过电子邮件、短信、Webhook或其他直接机制发送警报
- en: Throughout this book we champion the idea of infrastructure as code, so it should
    be possible to automate your external monitoring checks with code as well. For
    example, Uptime Robot has a simple REST API for creating new checks, and you can
    automate it using a client library or command-line tool like [`uptimerobot`](https://oreil.ly/WP5eG).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们倡导基础设施即代码的理念，因此应该可以使用代码自动化您的外部监控检查。例如，Uptime Robot提供了一个简单的REST API用于创建新检查，并且您可以使用类似[`uptimerobot`](https://oreil.ly/WP5eG)的客户端库或命令行工具进行自动化。
- en: It doesn’t matter which external monitoring service you use, so long as you
    use one. But don’t stop there. In the next section, we’ll see what we can do to
    monitor the health of applications inside the Kubernetes cluster itself.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用哪种外部监控服务并不重要，只要使用一个。但不要止步于此。在下一节中，我们将看看如何监控Kubernetes集群内应用程序的健康状态。
- en: Internal Health Checks
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内部健康检查
- en: Cloud native applications fail in complex, unpredictable, and hard-to-detect
    ways. Applications have to be designed to be resilient and degrade gracefully
    in the face of unexpected failures, but ironically, the more resilient they are,
    the harder it is to detect these failures by closed-box monitoring.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生应用程序以复杂、难以预测和难以检测的方式失败。应用程序必须被设计为在面对意外故障时具有弹性，并且能够在封闭盒监控面前优雅地退化。但具有讽刺意味的是，它们越具有弹性，检测这些故障就越难以通过封闭盒监控来实现。
- en: To solve this problem, applications can, and should, do their own health checking.
    The developer of a particular feature or service is best placed to know what it
    needs to be *healthy*, and they can write code to check this that exposes the
    results in a way that can be monitored from outside the container (like an HTTP
    endpoint).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决这个问题，应用程序可以并且应该执行自己的健康检查。特定功能或服务的开发者最了解它所需的“健康”状况，并且他们可以编写代码来检查这一点，并以一种可以从容器外部监控结果的方式公开这些结果（例如
    HTTP 终端点）。
- en: Are users happy?
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户是否满意？
- en: Kubernetes gives us a simple mechanism for applications to advertise their liveness
    or readiness, as we saw in [“Liveness Probes”](ch05.html#liveness), so this is
    a good place to start. Usually, Kubernetes liveness or readiness probes are pretty
    simple; the application always responds “OK” to any requests. If it doesn’t respond,
    Kubernetes considers it to be down or unready.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 [“存活性探针”](ch05.html#liveness) 中看到的，Kubernetes 为应用程序提供了一个简单的机制来宣传它们的存活性或就绪性，所以这是一个很好的起点。通常，Kubernetes
    的存活性或就绪性探针非常简单；应用程序总是对任何请求回应“OK”。如果没有响应，Kubernetes 将认为其已宕机或未准备好。
- en: However, as many programmers know from bitter experience, just because a program
    runs, doesn’t necessarily mean it works correctly. A more sophisticated readiness
    probe should ask, “What does this application need in order to do its job?”
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如许多程序员从痛苦的经验中知道的那样，仅仅因为程序运行，并不一定意味着它能正常工作。一个更复杂的就绪性探针应该问：“这个应用程序为了完成工作需要什么？”
- en: For example, if it needs to talk to a database, it can check that it has a valid
    and responsive database connection. If it depends on other services, it can check
    the services’ availability. (If health checks are run frequently, they shouldn’t
    do anything too expensive that might affect serving requests from real users.)
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果需要与数据库交互，它可以检查是否有有效且响应迅速的数据库连接。如果依赖其他服务，它可以检查这些服务的可用性。（如果频繁运行健康检查，则不应执行会影响真实用户请求服务的昂贵操作。）
- en: Note that we’re still giving a binary yes/no response to the readiness probe.
    It’s just a more informed answer. What we’re trying to do is answer the question
    “Are users happy?” as accurately as possible.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们仍然对准备探测给出二进制的是/否响应。只是这是一个更为明智的回答。我们试图回答的问题是：“用户是否满意？”尽可能准确地回答这个问题。
- en: Services and circuit breakers
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务和熔断器
- en: As you know, if a container’s *liveness* check fails, Kubernetes will restart
    it automatically, in an exponential backoff loop. This isn’t really that helpful
    in the situation where there’s nothing wrong with the container, but one of its
    dependencies is failing. The semantics of a failed *readiness* check, on the other
    hand, is “I’m fine, but I can’t serve user requests at the moment.”
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所知，如果容器的“存活性”检查失败，Kubernetes 将自动以指数回退的循环重新启动它。但在容器没有问题的情况下，其某个依赖关系失败时，这并不真正有帮助。另一方面，失败的“就绪性”检查的语义是：“我没问题，但当前无法为用户请求提供服务。”
- en: In this situation, the container will be removed from any Services that it’s
    a backend for, and Kubernetes will stop sending it requests until it becomes ready
    again. This is a better way to deal with a failed dependency.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，容器将被从它是后端的任何服务中移除，并且 Kubernetes 将停止向其发送请求，直到它再次就绪。这是处理失败依赖关系的更好方法。
- en: Suppose you have a chain of 10 microservices, each of which depends on the next
    for some critical part of its work. The last service in the chain fails. The next-to-last
    service will detect this and start failing its readiness probe. Kubernetes will
    disconnect it, and the next service in line detects this, and so on up the chain.
    Eventually the frontend service will fail, and (hopefully) a closed-box monitoring
    alert will be tripped.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一条由 10 个微服务组成的链条，每个微服务都依赖于下一个微服务的某个关键部分工作。链条中最后一个服务失败了。倒数第二个服务会检测到这一点，并开始失败其准备探测。Kubernetes
    会将其断开连接，而下一个服务检测到这一点，依此类推。最终，前端服务将失败，并（希望）会触发封闭盒监控警报。
- en: Once the problem with the base service is fixed, or maybe cured by an automatic
    restart, all the other services in the chain will automatically become ready again
    in turn, without being restarted or losing any state. This is an example of what’s
    called a [*circuit breaker pattern*](https://oreil.ly/F3lKZ). When an application
    detects a downstream failure, it takes itself out of service (via the readiness
    check) to prevent any more requests being sent to it until the problem is fixed.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦基础服务的问题得到解决，或者可能通过自动重新启动来治愈，链中的所有其他服务将自动依次恢复就绪状态，而无需重新启动或丢失任何状态。这是所谓的[*断路器模式*](https://oreil.ly/F3lKZ)的一个例子。当应用检测到下游故障时，通过就绪检查将自己从服务中移出，以防止向其发送更多请求，直到问题解决为止。
- en: Graceful degradation
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优雅降级
- en: 'While a circuit breaker is useful for surfacing problems as soon as possible,
    you should design your services to avoid having the whole system fail when one
    or more component services are unavailable. Instead, try to make your services
    *degrade gracefully*: even if they can’t do everything they’re supposed to, maybe
    they can still do some things.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管断路器对尽快展现问题很有用，但您应该设计您的服务，避免在一个或多个组件服务不可用时使整个系统失败。相反，尝试使您的服务*优雅降级*：即使它们不能完成它们应该做的一切，也许它们仍然可以做一些事情。
- en: In distributed systems, we have to assume that services, components, and connections
    will fail mysteriously and intermittently more or less all the time. A resilient
    system can handle this without failing completely.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式系统中，我们必须假设服务、组件和连接将会以神秘和间歇性的方式经常失败。一个具有弹性的系统可以在不完全失败的情况下处理这一点。
- en: Summary
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: There’s a lot to say about the topic of monitoring and observability. We hope
    this chapter has given you some useful information about traditional monitoring
    techniques, what they can do and what they can’t do, and how things need to adapt
    in a cloud native environment.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 关于监控和可观测性的主题有很多要说的。我们希望本章为您提供了一些关于传统监控技术的有用信息，它们能做什么，不能做什么，以及在云原生环境中需要如何适应。
- en: The notion of *observability* introduces us to a bigger picture than traditional
    log files and closed-box checks. Metrics form an important part of this picture,
    and in the next and final chapter, we’ll take you on a deep dive into the world
    of metrics in Kubernetes.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*可观测性* 的概念使我们了解到比传统日志文件和封闭盒检查更广阔的视角。指标在这个视角中占据重要位置，在下一章也是最后一章中，我们将深入探讨 Kubernetes
    中指标的世界。'
- en: 'Before turning the page, though, you might like to recall these key points:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在翻页之前，你可能想起这些关键点：
- en: Closed-box monitoring checks observe the external behavior of a system to detect
    predictable failures.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 封闭盒监控检查观察系统的外部行为，以检测可预测的故障。
- en: 'Distributed systems expose the limitations of traditional monitoring because
    they’re not in either *up* or *down* states: they exist in a constant state of
    partially degraded service. In other words, nothing is ever completely right aboard
    a ship.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式系统暴露了传统监控的局限性，因为它们不处于*上*或*下*状态：它们存在于部分降级服务的不断状态。换句话说，在船上没有什么是完全正确的。
- en: Logs can be useful for post-incident troubleshooting, but they’re expensive
    to scale. Loki and ELK are popular centralized logging tools.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志对事后故障排除很有用，但它们的扩展成本高昂。Loki 和 ELK 是流行的集中式日志记录工具。
- en: Metrics open up a new dimension beyond simply *working*/*not working*, and give
    you continuous numerical time-series data on hundreds or thousands of aspects
    of your system. Prometheus is a popular option for aggregating application metrics.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标开启了一个新的维度，超越了简单的*工作*/*不工作*状态，并且为您的系统的数百或数千个方面提供了持续的数值时间序列数据。Prometheus 是聚合应用指标的一个流行选项。
- en: Metrics can help you answer the “why?” question, as well as identify problematic
    trends before they lead to outages.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标可以帮助您回答“为什么？”的问题，以及在导致停机之前识别问题趋势。
- en: Tracing records events with precise timing through the life cycle of an individual
    request to help you debug performance problems. Jaeger, Zipkin, and Pixie are
    some examples of tools that offer application tracing.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪通过个别请求的整个生命周期精确记录事件的时间，帮助您调试性能问题。Jaeger、Zipkin 和 Pixie 是提供应用程序跟踪的一些工具示例。
- en: Observability is the union of traditional monitoring, logging, metrics, and
    tracing, and all the other ways you can understand your system.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可观测性是传统监控、日志记录、指标和跟踪的结合，以及您可以了解系统的所有其他方式。
- en: Observability also represents a shift toward a team culture of engineering based
    on facts and feedback.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可观测性还代表了一个基于事实和反馈的工程团队文化的转变。
- en: 'It’s still important to check that your user-facing services are up, with external
    closed-box checks, but don’t try to build your own: use a third-party monitoring
    service like Uptime Robot.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依然很重要的是确保你的面向用户的服务处于运行状态，通过外部的闭合盒检查，但不要试图自己构建：使用像 Uptime Robot 这样的第三方监控服务。
- en: Nines don’t matter if users aren’t happy.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户不满意，99.999% 的可用性也毫无意义。
- en: '^([1](ch15.html#idm45979374465760-marker)) [“Gray failure: the Achilles’ heel
    of cloud-scale systems”](https://blog.acolyer.org), by Adrian Colyer, June 2017.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch15.html#idm45979374465760-marker)) [“云规模系统的致命弱点：灰失败”](https://blog.acolyer.org)，作者Adrian
    Colyer，2017年6月。
- en: ^([2](ch15.html#idm45979374404496-marker)) [“Distributed Tracing Infrastructure
    with Jaeger on Kubernetes”](https://medium.com/@masroor.hasan), by Masroor Hasan,
    September 2018.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch15.html#idm45979374404496-marker)) [“在 Kubernetes 上使用 Jaeger 的分布式跟踪基础设施”](https://medium.com/@masroor.hasan)，作者Masroor
    Hasan，2018年9月。
