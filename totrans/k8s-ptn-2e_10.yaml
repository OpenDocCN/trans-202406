- en: Chapter 7\. Batch Job
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 7 章\. 批处理作业
- en: The *Batch Job* pattern is suited for managing isolated atomic units of work.
    It is based on the Job resource, which runs short-lived Pods reliably until completion
    on a distributed environment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理作业模式适用于管理隔离的原子工作单元。它基于 Job 资源，在分布式环境中可靠地运行短暂的 Pods 直到完成。
- en: Problem
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'The main primitive in Kubernetes for managing and running containers is the
    Pod. There are different ways of creating Pods with varying characteristics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中用于管理和运行容器的主要原语是 Pod。有多种创建 Pods 的方式，具有不同的特性：
- en: Bare Pod
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 裸露 Pod
- en: It is possible to create a Pod manually to run containers. However, when the
    node such a Pod is running on fails, the Pod is not restarted. Running Pods this
    way is discouraged except for development or testing purposes. This mechanism
    is also known as *unmanaged* or *naked Pods*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 可以手动创建一个 Pod 来运行容器。但是，当运行此类 Pod 的节点发生故障时，不会重新启动该 Pod。除了开发或测试目的外，不鼓励以这种方式运行 Pods。此机制也被称为*非托管*或*裸露
    Pods*。
- en: ReplicaSet
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet
- en: This controller is used for creating and managing the lifecycle of Pods expected
    to run continuously (e.g., to run a web server container). It maintains a stable
    set of replica Pods running at any given time and guarantees the availability
    of a specified number of identical Pods. ReplicaSets are described in detail in
    [Chapter 11, “Stateless Service”](ch11.html#StatelessService).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此控制器用于创建和管理预期持续运行的 Pods（例如，运行 Web 服务器容器）。它在任何给定时间保持一组稳定的副本 Pods 并保证一定数量的相同 Pods
    的可用性。详细介绍 ReplicaSets 见[第 11 章，“无状态服务”](ch11.html#StatelessService)。
- en: DaemonSet
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet
- en: This controller runs a single Pod on every node and is used for managing platform
    capabilities such as monitoring, log aggregation, storage containers, and others.
    See [Chapter 9, “Daemon Service”](ch09.html#DaemonService), for a more detailed
    discussion.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此控制器在每个节点上运行一个单独的 Pod，并用于管理平台功能，如监控、日志聚合、存储容器等。详细讨论见[第 9 章，“守护进程服务”](ch09.html#DaemonService)。
- en: A common aspect of these Pods is that they represent long-running processes
    that are not meant to stop after a certain time. However, in some cases there
    is a need to perform a predefined finite unit of work reliably and then shut down
    the container. For this task, Kubernetes provides the Job resource.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 Pods 的一个共同特点是它们代表长时间运行的进程，不打算在一定时间后停止。然而，在某些情况下，需要可靠地执行预定义的有限工作单元，然后关闭容器。为此任务，Kubernetes
    提供了 Job 资源。
- en: Solution
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案
- en: A Kubernetes Job is similar to a ReplicaSet as it creates one or more Pods and
    ensures they run successfully. However, the difference is that, once the expected
    number of Pods terminate successfully, the Job is considered complete, and no
    additional Pods are started. A Job definition looks like [Example 7-1](#ex-job).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Job 类似于 ReplicaSet，因为它创建一个或多个 Pods 并确保它们成功运行。然而，不同之处在于，一旦期望数量的 Pods
    成功终止，Job 被视为完成，不会启动额外的 Pods。一个 Job 的定义看起来像[示例 7-1](#ex-job)。
- en: Example 7-1\. A Job specification
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-1\. Job 规范
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_batch_job_CO1-1)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_batch_job_CO1-1)'
- en: Job should run five Pods to completion, which all must succeed.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Job 应该运行五个 Pods 完成，所有 Pods 必须成功。
- en: '[![2](assets/2.png)](#co_batch_job_CO1-2)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_batch_job_CO1-2)'
- en: Two Pods can run in parallel.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 两个 Pod 可以并行运行。
- en: '[![3](assets/3.png)](#co_batch_job_CO1-3)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_batch_job_CO1-3)'
- en: Keep Pods for five minutes (300 seconds) before garbage-collecting them.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在回收之前，保留 Pods 五分钟（300 秒）。
- en: '[![4](assets/4.png)](#co_batch_job_CO1-4)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_batch_job_CO1-4)'
- en: Specifying the `restartPolicy` is mandatory for a Job. The possible values are
    `OnFailure` or `Never`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Job，指定 `restartPolicy` 是强制的。可能的值为 `OnFailure` 或 `Never`。
- en: One crucial difference between the Job and the ReplicaSet definition is the
    `.spec.template.spec.restartPolicy`. The default value for a ReplicaSet is `Always`,
    which makes sense for long-running processes that must always be kept running.
    The value `Always` is not allowed for a Job, and the only possible options are
    `OnFailure` or `Never`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Job 和 ReplicaSet 定义之间的一个关键区别是 `.spec.template.spec.restartPolicy`。ReplicaSet
    的默认值是 `Always`，适合必须一直运行的长时间进程。对于 Job，`Always` 不允许使用，唯一可能的选项是 `OnFailure` 或 `Never`。
- en: 'So why bother creating a Job to run a Pod only once instead of using bare Pods?
    Using Jobs provides many reliability and scalability benefits that make them the
    preferred option:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么要费心创建一个仅运行一次的 Job 而不使用裸露 Pods？使用 Jobs 提供了许多可靠性和可扩展性的优势，使它们成为首选选项：
- en: A Job is not an ephemeral in-memory task but a persisted one that survives cluster
    restarts.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A Job is not an ephemeral in-memory task but a persisted one that survives cluster
    restarts.
- en: 'When a Job is completed, it is not deleted but is kept for tracking purposes.
    The Pods that are created as part of the Job are also not deleted but are available
    for examination (e.g., to check the container logs). This is also true for bare
    Pods but only for `restartPolicy: OnFailure`. You can still remove the Pods of
    a Job after a certain time by specifying `.spec.ttlSecondsAfterFinished`.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'When a Job is completed, it is not deleted but is kept for tracking purposes.
    The Pods that are created as part of the Job are also not deleted but are available
    for examination (e.g., to check the container logs). This is also true for bare
    Pods but only for `restartPolicy: OnFailure`. You can still remove the Pods of
    a Job after a certain time by specifying `.spec.ttlSecondsAfterFinished`.'
- en: A Job may need to be performed multiple times. Using the `.spec.completions`
    field, it is possible to specify how many times a Pod should complete successfully
    before the Job itself is done.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A Job may need to be performed multiple times. Using the `.spec.completions`
    field, it is possible to specify how many times a Pod should complete successfully
    before the Job itself is done.
- en: When a Job has to be completed multiple times, it can also be scaled and executed
    by starting multiple Pods at the same time. That can be done by specifying the
    `.spec.parallelism` field.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: When a Job has to be completed multiple times, it can also be scaled and executed
    by starting multiple Pods at the same time. That can be done by specifying the
    `.spec.parallelism` field.
- en: A Job can be suspended by setting the field `.spec.suspend` to `true`. In this
    case, all active Pods are deleted and restarted if the Job is resumed (i.e., `.spec.suspend`
    set to `false` by the user).
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A Job can be suspended by setting the field `.spec.suspend` to `true`. In this
    case, all active Pods are deleted and restarted if the Job is resumed (i.e., `.spec.suspend`
    set to `false` by the user).
- en: If the node fails or when the Pod is evicted for some reason while still running,
    the scheduler places the Pod on a new healthy node and reruns it. Bare Pods would
    remain in a failed state as existing Pods are never moved to other nodes.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: If the node fails or when the Pod is evicted for some reason while still running,
    the scheduler places the Pod on a new healthy node and reruns it. Bare Pods would
    remain in a failed state as existing Pods are never moved to other nodes.
- en: All of this makes the Job primitive attractive for scenarios requiring some
    guarantees for the completion of a unit of work.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: All of this makes the Job primitive attractive for scenarios requiring some
    guarantees for the completion of a unit of work.
- en: 'The following two fields play major roles in the behavior of a Job:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 'The following two fields play major roles in the behavior of a Job:'
- en: '`.spec.completions`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`.spec.completions`'
- en: Specifies how many Pods should run to complete a Job.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Specifies how many Pods should run to complete a Job.
- en: '`.spec.parallelism`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`.spec.parallelism`'
- en: Specifies how many Pod replicas could run in parallel. Setting a high number
    does not guarantee a high level of parallelism, and the actual number of Pods
    may still be fewer (and in some corner cases, more) than the desired number (e.g.,
    because of throttling, resource quotas, not enough completions left, and other
    reasons). Setting this field to 0 effectively pauses the Job.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Specifies how many Pod replicas could run in parallel. Setting a high number
    does not guarantee a high level of parallelism, and the actual number of Pods
    may still be fewer (and in some corner cases, more) than the desired number (e.g.,
    because of throttling, resource quotas, not enough completions left, and other
    reasons). Setting this field to 0 effectively pauses the Job.
- en: '[Figure 7-1](#img-job) shows how the Job defined in [Example 7-1](#ex-job)
    with a completion count of 5 and a parallelism of 2 is processed.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 7-1](#img-job) 显示了在 [示例 7-1](#ex-job) 中定义的具有完成计数为 5 和并行性为 2 的作业的处理过程。'
- en: '![Parallel Batch Job with a fixed completion count](assets/kup2_0701.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![具有固定完成计数的并行批处理作业](assets/kup2_0701.png)'
- en: Figure 7-1\. Parallel Batch Job with a fixed completion count
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-1\. 具有固定完成计数的并行批处理作业
- en: 'Based on these two parameters, there are the following types of Jobs:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 'Based on these two parameters, there are the following types of Jobs:'
- en: Single Pod Jobs
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Single Pod Jobs
- en: This type is selected when you leave out both `.spec.completions` and `.spec.parallelism`
    or set them to their default values of 1\. Such a Job starts only one Pod and
    is completed as soon as the single Pod terminates successfully (with exit code
    0).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: This type is selected when you leave out both `.spec.completions` and `.spec.parallelism`
    or set them to their default values of 1\. Such a Job starts only one Pod and
    is completed as soon as the single Pod terminates successfully (with exit code
    0).
- en: Fixed completion count Jobs
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Fixed completion count Jobs
- en: For a fixed completion count Job, you should set `.spec.completions` to the
    number of completions needed. You can set `.spec.parallelism`, or leave it unset
    and it will default to 1\. Such a Job is considered completed after the `.spec.completions`
    number of Pods has completed successfully. [Example 7-1](#ex-job) shows this mode
    in action and is the best choice when we know the number of work items in advance
    and the processing cost of a single work item justifies the use of a dedicated
    Pod.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于固定完成计数的作业，应将`.spec.completions`设置为所需的完成数。您可以设置`.spec.parallelism`，或者将其未设置，它将默认为1。这种作业在`.spec.completions`数量的
    Pod 成功完成后被视为已完成。[示例 7-1](#ex-job)展示了这种模式的实际操作，当我们预先知道工作项的数量并且单个工作项的处理成本足以使用专用
    Pod 时，这是最佳选择。
- en: Work queue Jobs
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 工作队列作业
- en: For a work queue Job, you need to leave `.spec.completions` unset, and set `.spec.parallelism`
    to a number greater than one. A work queue Job is considered completed when at
    least one Pod has terminated successfully and all other Pods have terminated too.
    This setup requires the Pods to coordinate among themselves and determine what
    each one is working on so that they can finish in a coordinated fashion. For example,
    when a fixed but unknown number of work items is stored in a queue, parallel Pods
    can pick these up one by one to work on them. The first Pod that detects that
    the queue is empty and exits with success indicates the completion of the Job.
    The Job controller waits for all other Pods to terminate too. Since one Pod processes
    multiple work items, this Job type is an excellent choice for granular work items—when
    the overhead for one Pod per work item is not justified.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于工作队列作业，需要将`.spec.completions`设置为未设置，并将`.spec.parallelism`设置为大于1的数字。当至少一个 Pod
    成功终止且所有其他 Pod 也终止时，工作队列作业被视为已完成。这种设置要求 Pod 之间进行协调，并确定每个 Pod 正在处理的内容，以便它们可以协调完成。例如，当队列中存储了一个固定但未知数量的工作项时，并行的
    Pod 可以逐个获取这些工作项来处理。首个检测到队列为空并成功退出的 Pod 表明作业已完成。作业控制器等待所有其他 Pod 也终止。由于一个 Pod 处理多个工作项，这种作业类型非常适合细粒度的工作项，即当一个
    Pod 处理一个工作项的开销不合理时。
- en: Indexed Jobs
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 索引作业
- en: Similar to *Work queue Jobs*, you can distribute work items to individual Jobs
    without needing an external work queue. When using a fixed completion count and
    setting the completion mode `.spec.completionMode` to `Indexed`, every Pod of
    the Job gets an associated index ranging from 0 to `.spec.completions` - 1\. The
    assigned index is available to the containers through the Pod annotation `batch.kubernetes.io/job-completion-index`
    (see [Chapter 14, “Self Awareness”](ch14.html#SelfAwareness), to learn how this
    annotation can be accessed from your code) or directly via the environment variable
    `JOB_COMPLETION_INDEX` that is set to the index associated with this Pod. With
    this index at hand, the application can pick the associated work item without
    any external synchronization. [Example 7-2](#ex-job-indexed) shows a Job that
    processes the lines of a single file individually by separate Pods. A more realistic
    example would be an indexed Job used for video processing, where parallel Pods
    are processing a certain frame range calculated from the index.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于*工作队列作业*，您可以将工作项分配给单独的作业，而无需外部工作队列。当使用固定完成计数并将完成模式`.spec.completionMode`设置为`Indexed`时，作业的每个
    Pod 都会获得一个从0到`.spec.completions - 1`的关联索引。分配的索引可通过 Pod 注释`batch.kubernetes.io/job-completion-index`（请参阅[第14章，“自我意识”](ch14.html#SelfAwareness)，了解如何从代码中访问此注释）或直接通过环境变量`JOB_COMPLETION_INDEX`获取，该变量设置为与此
    Pod 关联的索引。有了这个索引，应用程序可以选择关联的工作项而无需任何外部同步。[示例 7-2](#ex-job-indexed)展示了一个根据作业索引逐个处理单个文件行的作业。更实际的例子是，使用索引作业进行视频处理，其中并行的
    Pod 正在处理从索引计算出的某个帧范围。
- en: Example 7-2\. An indexed Job selecting its work items based on a job index
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-2\. 一个根据作业索引选择其工作项的索引作业
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_batch_job_CO2-1)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_batch_job_CO2-1)'
- en: Enable an indexed completion mode.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 启用索引完成模式。
- en: '[![2](assets/2.png)](#co_batch_job_CO2-2)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_batch_job_CO2-2)'
- en: Run five Pods in parallel to completion.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 并行运行五个 Pod 以完成。
- en: '[![3](assets/3.png)](#co_batch_job_CO2-3)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_batch_job_CO2-3)'
- en: Execute a shell script that prints out a range of lines from a given file */logs/random.log*.
    This file is expected to have 50,000 lines of data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 执行一个打印给定文件*/logs/random.log*中一系列行的 Shell 脚本。预计该文件包含50,000行数据。
- en: '[![4](assets/4.png)](#co_batch_job_CO2-4)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_batch_job_CO2-4)'
- en: Calculate start and end line numbers.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 计算起始和结束行号。
- en: '[![5](assets/5.png)](#co_batch_job_CO2-5)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_batch_job_CO2-5)'
- en: Use `awk` to print out a range of line numbers (`NR` is the `awk`-internal line
    number when iterating over the file).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `awk` 打印一系列行号（`NR` 是在文件迭代过程中 `awk` 的内部行号）。
- en: '[![6](assets/6.png)](#co_batch_job_CO2-6)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_batch_job_CO2-6)'
- en: Mount the input data from an external volume. The volume is not shown here;
    you can find the full working definition in the [example repository](https://oreil.ly/PkVF0).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 挂载来自外部卷的输入数据。这里没有显示卷；您可以在[示例存储库](https://oreil.ly/PkVF0)中找到完整的工作定义。
- en: If you have an unlimited stream of work items to process, other controllers
    like ReplicaSet are the better choice for managing the Pods processing these work
    items.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有一个无限流的工作项需要处理，其他控制器如 ReplicaSet 更适合管理处理这些工作项的 Pods。
- en: Discussion
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论
- en: 'The Job abstraction is a pretty basic but also fundamental primitive that other
    primitives such as CronJobs are based on. Jobs help turn isolated work units into
    a reliable and scalable unit of execution. However, a Job doesn’t dictate how
    you should map individually processable work items into Jobs or Pods. That is
    something you have to determine after considering the pros and cons of each option:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Job 抽象是一个相当基础但也是基本的原语，其他原语如 CronJobs 就是基于它的。Jobs 帮助将孤立的工作单元转变为可靠且可扩展的执行单元。但是，Job
    并不规定您应该如何将可单独处理的工作项映射到 Jobs 或 Pods 中。这是您在考虑每个选项的利弊后需要确定的事项：
- en: One Job per work item
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作项一个 Job
- en: This option has the overhead of creating Kubernetes Jobs and also means the
    platform has to manage a large number of Jobs that are consuming resources. This
    option is useful when each work item is a complex task that has to be recorded,
    tracked, or scaled independently.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项需要创建 Kubernetes Jobs 的开销，同时意味着平台必须管理大量消耗资源的 Jobs。当每个工作项都是必须记录、跟踪或独立扩展的复杂任务时，这个选项非常有用。
- en: One Job for all work items
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一个工作项适合所有工作
- en: This option is right for a large number of work items that do not have to be
    independently tracked and managed by the platform. In this scenario, the work
    items have to be managed from within the application via a batch framework.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不需要由平台独立跟踪和管理的大量工作项，这个选项是正确的。在这种情况下，必须通过批处理框架从应用程序内部管理工作项。
- en: The Job primitive provides only the very minimum basics for scheduling work
    items. Any complex implementation has to combine the Job primitive with a batch
    application framework (e.g., in the Java ecosystem, we have Spring Batch and JBeret
    as standard implementations) to achieve the desired outcome.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Job 原语仅提供调度工作项的最基本功能。任何复杂的实现都必须将 Job 原语与批处理应用程序框架（例如，在 Java 生态系统中，我们有 Spring
    Batch 和 JBeret 作为标准实现）结合起来，以实现期望的结果。
- en: Not all services must run all the time. Some services must run on demand, some
    at a specific time, and some periodically. Using Jobs can run Pods only when needed
    and only for the duration of the task execution. Jobs are scheduled on nodes that
    have the required capacity, satisfy Pod placement policies, and take into account
    other container dependency considerations. Using Jobs for short-lived tasks rather
    than using long-running abstractions (such as ReplicaSet) saves resources for
    other workloads on the platform. All of that makes Jobs a unique primitive, and
    Kubernetes a platform supporting diverse workloads.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有服务都必须全天候运行。一些服务必须按需运行，一些在特定时间运行，一些定期运行。使用 Jobs 可以在需要时运行 Pods，并且只在任务执行期间运行。Jobs
    被调度到具有所需容量的节点上，满足 Pod 放置策略，并考虑其他容器依赖性考虑因素。对于短暂任务使用 Jobs 而不是使用长时间运行的抽象（例如 ReplicaSet），可以为平台上的其他工作负载节省资源。所有这些使得
    Jobs 成为一个独特的基元，而 Kubernetes 则支持多样化的工作负载。
- en: More Information
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多信息
- en: '[Batch Job Example](https://oreil.ly/PkVF0)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[批处理作业示例](https://oreil.ly/PkVF0)'
- en: '[Jobs](https://oreil.ly/I2Xum)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Jobs](https://oreil.ly/I2Xum)'
- en: '[Parallel Processing Using Expansions](https://oreil.ly/mNmhN)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用扩展进行并行处理](https://oreil.ly/mNmhN)'
- en: '[Coarse Parallel Processing Using a Work Queue](https://oreil.ly/W5aqH)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用工作队列进行粗粒度并行处理](https://oreil.ly/W5aqH)'
- en: '[Fine Parallel Processing Using a Work Queue](https://oreil.ly/-8FBt)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用工作队列进行精细并行处理](https://oreil.ly/-8FBt)'
- en: '[Indexed Job for Parallel Processing with Static Work Assignment](https://oreil.ly/2B2Nn)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用静态工作分配的索引作业进行并行处理](https://oreil.ly/2B2Nn)'
- en: '[Spring Batch on Kubernetes: Efficient Batch Processing at Scale](https://oreil.ly/8dLDo)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Kubernetes 上使用 Spring Batch：高效的批处理处理](https://oreil.ly/8dLDo)'
- en: '[JBeret Introduction](https://oreil.ly/YyYxy)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[JBeret 介绍](https://oreil.ly/YyYxy)'
