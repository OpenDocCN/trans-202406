<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 10. Deployments" data-type="chapter" epub:type="chapter"><div class="chapter" id="deployments_chapter">
<h1><span class="label">Chapter 10. </span>Deployments</h1>
<p>So far, you have seen how to package your applications as containers, create replicated sets of containers, and use Ingress controllers to load balance traffic to your services.<a data-primary="deployments" data-type="indexterm" id="ix_dply"/> You can use all of these objects (Pods, ReplicaSets, and Services) to build a single instance of your application. However, they do little to help you manage the daily or weekly cadence of releasing new versions of your application. Indeed, both Pods and ReplicaSets are expected to be tied to specific container images that don’t change.</p>
<p>The Deployment object exists to manage the release of new versions.<a data-primary="Deployment object" data-seealso="deployments" data-type="indexterm" id="idm45664076953280"/>  Deployments represent deployed applications in a way that transcends any particular version. Additionally, Deployments enable you to easily move from one version of your code to the next. This “rollout” process is specifiable and careful.<a data-primary="rollouts" data-seealso="deployments" data-type="indexterm" id="idm45664076951840"/> It waits for a user-configurable amount of time between upgrading individual Pods. It also uses health checks to ensure that the
new version of the application is operating correctly and stops the deployment if too many failures occur.</p>
<p>Using Deployments, you can simply and reliably roll out new software versions without downtime or errors. The actual mechanics of the software rollout performed by a Deployment are controlled by a Deployment controller that runs in the Kubernetes cluster itself. <a data-primary="controllers" data-secondary="Deployment" data-type="indexterm" id="idm45664076949856"/>This means you can let a Deployment proceed unattended and it will still operate correctly and safely. This makes it easy to integrate Deployments with numerous continuous delivery tools and services. Further, running server-side makes it safe to perform a rollout from places with poor or intermittent internet connectivity. Imagine rolling out a new version of your software from your phone while riding on the subway. Deployments make this possible and safe!</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>When Kubernetes was first released, one of the most popular demonstrations of its power was the “rolling update,” which showed how you could use a single command to seamlessly update a running application without any downtime and without losing requests. <a data-primary="rolling updates" data-type="indexterm" id="idm45664076947504"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="rolling-update" data-type="indexterm" id="idm45664076946800"/>This original demo was based on the <code>kubectl rolling-update</code> command, which is still available in the command-line tool, although its functionality has largely been subsumed by the Deployment object.</p>
</div>
<section data-pdf-bookmark="Your First Deployment" data-type="sect1"><div class="sect1" id="idm45664076944560">
<h1>Your First Deployment</h1>
<p>Like all objects in Kubernetes, a Deployment can be represented as a<a data-primary="deployments" data-secondary="creating" data-type="indexterm" id="idm45664076942576"/> declarative YAML object that provides the details about what you want to run. In the following case, the Deployment is requesting a single instance of the <code>kuard</code> application:</p>
<pre data-type="programlisting">apiVersion: apps/v1
kind: Deployment
metadata:
  name: kuard
  labels:
    run: kuard
spec:
  selector:
    matchLabels:
      run: kuard
  replicas: 1
  template:
    metadata:
      labels:
        run: kuard
    spec:
      containers:
      - name: kuard
        image: gcr.io/kuar-demo/kuard-amd64:blue</pre>
<p>Save this YAML file as <em>kuard-deployment.yaml</em>, then you can <a data-primary="kubectl tool" data-secondary="commands" data-tertiary="create" data-type="indexterm" id="idm45664076939424"/>create it using:</p>
<pre data-type="programlisting">$ <strong>kubectl create -f kuard-deployment.yaml</strong></pre>
<p>Let’s explore how Deployments actually work.<a data-primary="deployments" data-secondary="exploring workings of" data-type="indexterm" id="idm45664076936576"/> Just as we learned that ReplicaSets manage Pods, Deployments manage ReplicaSets.<a data-primary="ReplicaSets" data-secondary="Deployments managing" data-type="indexterm" id="idm45664076935472"/> As with
all relationships in Kubernetes, this relationship is defined by labels
and a label selector. <a data-primary="labels" data-secondary="label selectors" data-tertiary="for Deployment object" data-tertiary-sortas="Deployment" data-type="indexterm" id="idm45664076934288"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="get deployments" data-type="indexterm" id="idm45664076932800"/>You can see the label selector by looking at the
Deployment object:</p>
<pre data-type="programlisting">$ <strong>kubectl get deployments kuard \
  -o jsonpath --template {.spec.selector.matchLabels}</strong>

{"run":"kuard"}</pre>
<p>From this you can see that the Deployment is managing a ReplicaSet with
the label <code>run=kuard</code>. You can use this in a label selector query across
ReplicaSets to find that specific ReplicaSet:</p>
<pre data-type="programlisting">$ <strong>kubectl get replicasets --selector=run=kuard</strong>

NAME              DESIRED   CURRENT   READY     AGE
kuard-1128242161  1         1         1         13m</pre>
<p>Now let’s look at the relationship between a Deployment and a ReplicaSet in
action.<a data-primary="ReplicaSets" data-secondary="relationship with Deployment in action" data-type="indexterm" id="idm45664076927424"/> We can resize the Deployment using the imperative <code>scale</code> command:</p>
<pre data-type="programlisting">$ <strong>kubectl scale deployments kuard --replicas=2</strong>

deployment.apps/kuard scaled</pre>
<p>Now if we list that ReplicaSet again, we should see:</p>
<pre data-type="programlisting">$ <strong>kubectl get replicasets --selector=run=kuard</strong>

NAME              DESIRED   CURRENT   READY     AGE
kuard-1128242161  2         2         2         13m</pre>
<p>Scaling the<a data-primary="scaling" data-secondary="scaling both Deployment and ReplicaSet" data-type="indexterm" id="idm45664076922320"/> Deployment has also scaled the ReplicaSet it controls.</p>
<p>Now let’s try the opposite, scaling the ReplicaSet:</p>
<pre data-type="programlisting">$ <strong>kubectl scale replicasets kuard-1128242161 --replicas=1</strong>

replicaset.apps/kuard-1128242161 scaled</pre>
<p>Now <code>get</code> that ReplicaSet again:</p>
<pre data-type="programlisting">$ <strong>kubectl get replicasets --selector=run=kuard</strong>

NAME              DESIRED   CURRENT   READY     AGE
kuard-1128242161  2         2         2         13m</pre>
<p>That’s odd. Despite scaling the ReplicaSet to one replica, it still has two replicas as its desired state. What’s going on?</p>
<p>Remember, Kubernetes is an online, self-healing system. The top-level Deployment object is managing this ReplicaSet. When you adjust the number of replicas to one, it no longer matches the desired state of the Deployment, which has <code>replicas</code> set to <code>2</code>. The Deployment controller notices this and takes action to ensure the observed state matches the desired state, in this case readjusting the number of replicas back to two.</p>
<p>If you ever want to manage that ReplicaSet directly, you need to delete the Deployment. (Remember to set <code>--cascade</code> to <code>false</code>, or else it will delete the ReplicaSet and Pods as well!)<a data-primary="Deployment object" data-secondary="deleting" data-type="indexterm" id="idm45664076913488"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="delete" data-type="indexterm" id="idm45664076912432"/></p>
</div></section>
<section data-pdf-bookmark="Creating Deployments" data-type="sect1"><div class="sect1" id="idm45664076943616">
<h1>Creating Deployments</h1>
<p>Of course, as stated in the introduction, you should have a preference for
declarative management of your Kubernetes configurations. <a data-primary="deployments" data-secondary="creating" data-type="indexterm" id="idm45664076909776"/>This means
maintaining the state of your Deployments in YAML or JSON files on disk.</p>
<p>As a starting point, download<a data-primary="kubectl tool" data-secondary="commands" data-tertiary="get deployments" data-type="indexterm" id="idm45664076908288"/><a data-primary="YAML" data-secondary="deployment.yaml file" data-type="indexterm" id="idm45664076907040"/> this Deployment into a YAML file:</p>
<pre data-type="programlisting">$ <strong>kubectl get deployments kuard -o yaml &gt; kuard-deployment.yaml</strong>
$ <strong>kubectl replace -f kuard-deployment.yaml --save-config</strong></pre>
<p>If you look in the file, you will see something like this (note that we’ve removed a lot of read-only and default fields for readability). Pay attention to the annotations, selector, and strategy fields as they provide insight into Deployment-specific functionality:</p>
<pre data-type="programlisting">apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  creationTimestamp: null
  generation: 1
  labels:
    run: kuard
  name: kuard
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      run: kuard
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        run: kuard
    spec:
      containers:
      - image: gcr.io/kuar-demo/kuard-amd64:blue
        imagePullPolicy: IfNotPresent
        name: kuard
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status: {}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="replace" data-type="indexterm" id="idm45664076902112"/>You also need to run <code>kubectl replace --save-config</code>.  This adds an annotation so that, when applying changes in the future, <code>kubectl</code> will know what the last applied configuration was for smarter merging of configs. If you always use <code>kubectl apply</code>, this step is only required after the first time you create a Deployment using <code>kubectl create -f</code>.</p>
</div>
<p>The Deployment spec has a very similar structure to the
ReplicaSet spec.<a data-primary="specifications" data-secondary="Deployment" data-type="indexterm" id="idm45664076898080"/> There is a Pod template, which contains a number of containers that are created for each replica managed by the Deployment. <a data-primary="strategies" data-secondary="deployment" data-type="indexterm" id="idm45664076896832"/>In addition to the Pod specification, there is also a <code>strategy</code> object:</p>
<pre data-type="programlisting">...
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
...</pre>
<p>The <code>strategy</code> object dictates the different ways in which a rollout of
new software can proceed. <a data-primary="rollouts" data-secondary="strategies for" data-type="indexterm" id="idm45664076893248"/>There are two strategies supported by Deployments: <code>Recreate</code> and <code>RollingUpdate</code>. These are discussed in detail later in this chapter.<a data-primary="RollingUpdate strategy" data-type="indexterm" id="idm45664076891184"/><a data-primary="Recreate strategy" data-type="indexterm" id="idm45664076890480"/></p>
</div></section>
<section data-pdf-bookmark="Managing Deployments" data-type="sect1"><div class="sect1" id="idm45664076910960">
<h1>Managing Deployments</h1>
<p>As with all Kubernetes objects, you can get detailed information about
your Deployment via the <code>kubectl describe</code> command. <a data-primary="deployments" data-secondary="managing" data-type="indexterm" id="idm45664076887904"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="describe" data-type="indexterm" id="idm45664076886896"/>This command provides an overview of the Deployment configuration, which includes interesting fields like the Selector, Replicas, and Events:</p>
<pre data-type="programlisting">$ <strong>kubectl describe deployments kuard</strong>

Name:                   kuard
Namespace:              default
CreationTimestamp:      Tue, 01 Jun 2021 21:19:46 -0700
Labels:                 run=kuard
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               run=kuard
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 ...
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  run=kuard
  Containers:
   kuard:
    Image:        gcr.io/kuar-demo/kuard-amd64:blue
    Port:         &lt;none&gt;
    Host Port:    &lt;none&gt;
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   kuard-6d69d9fc5c (2/2 replicas created)
Events:
  Type    Reason             Age                   From                 Message
  ----    ------             ----                  ----                 -------
  Normal  ScalingReplicaSet  4m6s                  deployment-con...    ...
  Normal  ScalingReplicaSet  113s (x2 over 3m20s)  deployment-con...    ...
</pre>
<p>In the output of <code>describe</code>, there is a great deal of important information. Two of the most important pieces of information in the output are  <code>OldReplicaSets</code> and <code>NewReplicaSet</code>. These fields point to the ReplicaSet objects this Deployment is currently managing.<a data-primary="ReplicaSets" data-secondary="OldReplicaSets and NewReplicaSet fields in Deployment" data-type="indexterm" id="idm45664076881008"/><a data-primary="NewReplicaSet" data-type="indexterm" id="idm45664076879936"/><a data-primary="OldReplicaSets" data-type="indexterm" id="idm45664076879264"/> If a Deployment is in the middle of a rollout, both fields will be set to a value. If a rollout is complete, <code>OldReplicaSets</code> will be set to <code>&lt;none&gt;</code>.</p>
<p>In addition to the <code>describe</code> command, there is also the <code>kubectl rollout</code> command for Deployments.  <a data-primary="rollouts" data-secondary="kubectl rollout and rollout history commands" data-type="indexterm" id="idm45664076876128"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="rollout" data-type="indexterm" id="idm45664076875120"/>We will go into this command in more detail later on, but for now, know that you can use <code>kubectl rollout history</code> to obtain the history of rollouts associated with a particular Deployment. If you have a current Deployment in progress, you can use <code>kubectl rollout status</code> to obtain the current status of that rollout.</p>
</div></section>
<section data-pdf-bookmark="Updating Deployments" data-type="sect1"><div class="sect1" id="idm45664076872720">
<h1>Updating Deployments</h1>
<p>Deployments are declarative objects that describe a deployed application.<a data-primary="deployments" data-secondary="updating" data-type="indexterm" id="ix_dplyupd"/> The two most common operations on a Deployment are scaling and application updates.</p>
<section data-pdf-bookmark="Scaling a Deployment" data-type="sect2"><div class="sect2" id="idm45664076869616">
<h2>Scaling a Deployment</h2>
<p>Although we previously showed how to imperatively scale a Deployment using the <code>kubectl scale</code> command, the best practice is to manage your Deployments declaratively via the YAML files, then use those files to update your Deployment.<a data-primary="scaling" data-secondary="of deployments" data-secondary-sortas="deployments" data-type="indexterm" id="idm45664076867280"/><a data-primary="deployments" data-secondary="updating" data-tertiary="scaling a deployment" data-type="indexterm" id="idm45664076866032"/><a data-primary="YAML" data-secondary="deployment.yaml file" data-type="indexterm" id="idm45664076864816"/><a data-primary="replicas" data-secondary="increasing number of in deployment.yaml file" data-type="indexterm" id="idm45664076863872"/> To scale up a Deployment, you would edit your YAML file to increase the number of replicas:</p>
<pre data-type="programlisting">...
spec:
  replicas: 3
...</pre>
<p>Once you have saved and committed this change, you can update the Deployment using the <code>kubectl apply</code> command:</p>
<pre data-type="programlisting">$ <strong>kubectl apply -f kuard-deployment.yaml</strong></pre>
<p>This <a data-primary="kubectl tool" data-secondary="commands" data-tertiary="get deployments" data-type="indexterm" id="idm45664076859584"/>will update the desired state of the Deployment, causing it to increase the size of the ReplicaSet it manages and eventually create a new Pod managed by the Deployment:</p>
<pre data-type="programlisting">$ <strong>kubectl get deployments kuard</strong>

NAME    READY   UP-TO-DATE   AVAILABLE   AGE
kuard   3/3     3            3           10m</pre>
</div></section>
<section data-pdf-bookmark="Updating a Container Image" data-type="sect2"><div class="sect2" id="idm45664076856592">
<h2>Updating a Container Image</h2>
<p>The other common use case for updating a Deployment is to roll out a new version of the software running in one or more containers.<a data-primary="deployments" data-secondary="updating" data-tertiary="updating a container image" data-type="indexterm" id="idm45664076854800"/><a data-primary="containers" data-secondary="updating a container image" data-type="indexterm" id="idm45664076853536"/><a data-primary="YAML" data-secondary="deployment.yaml file" data-type="indexterm" id="idm45664076852576"/> To do this, you should likewise edit the Deployment YAML file, though in this case you are updating the container image, rather than the number of replicas:</p>
<pre data-type="programlisting">...
      containers:
      - image: gcr.io/kuar-demo/kuard-amd64:green
        imagePullPolicy: Always
...</pre>
<p>Annotate the template for the Deployment to
record some information about the update:</p>
<pre data-type="programlisting">...
spec:
  ...
  template:
    metadata:
      annotations:
        kubernetes.io/change-cause: "Update to green kuard"
...</pre>
<div data-type="caution"><h6>Caution</h6>
<p>Make sure you add this annotation to the template and not the Deployment itself, since the <code>kubectl apply</code> command uses this field in the Deployment object. <a data-primary="rollouts" data-secondary="change-cause annotation and" data-type="indexterm" id="idm45664076847488"/><a data-primary="change-cause annotation" data-type="indexterm" id="idm45664076846496"/><a data-primary="annotations" data-secondary="change-cause" data-type="indexterm" id="idm45664076845824"/>Also, do not update the <code>change-cause</code> annotation when doing simple scaling operations.  A modification of <code>change-cause</code> is a significant change to the template and will trigger a new rollout.</p>
</div>
<p>Again, you can use <code>kubectl apply</code> to update the Deployment:</p>
<pre data-type="programlisting">$ <strong>kubectl apply -f kuard-deployment.yaml</strong></pre>
<p>After you update the Deployment, it will trigger a rollout, which<a data-primary="kubectl tool" data-secondary="commands" data-tertiary="rollout status" data-type="indexterm" id="idm45664076841472"/><a data-primary="rollouts" data-secondary="monitoring status of" data-type="indexterm" id="idm45664076840144"/> you can then monitor via the <code>kubectl rollout</code> command:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout status deployments kuard</strong>
deployment "kuard" successfully rolled out</pre>
<p>You can see the old and new ReplicaSets managed by the Deployment along with the
images being used.  Both the old and new ReplicaSets are kept around in case you want to roll back:</p>
<pre data-type="programlisting">$ <strong>kubectl get replicasets -o wide</strong>

NAME               DESIRED   CURRENT   READY   ...   IMAGE(S)            ...
kuard-1128242161   0         0         0       ...   gcr.io/kuar-demo/   ...
kuard-1128635377   3         3         3       ...   gcr.io/kuar-demo/   ...</pre>
<p>If you<a data-primary="kubectl tool" data-secondary="commands" data-tertiary="rollout pause" data-type="indexterm" id="idm45664076834944"/><a data-primary="rollouts" data-secondary="pausing" data-type="indexterm" id="idm45664076833664"/> are in the middle of a rollout and you want to temporarily pause it (e.g., if you start seeing weird behavior in your
system that you want to investigate), you can use the <code>pause</code> command:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout pause deployments kuard</strong>
deployment.apps/kuard paused</pre>
<p>If, after investigation, you believe the rollout<a data-primary="kubectl tool" data-secondary="commands" data-tertiary="rollout resume" data-type="indexterm" id="idm45664076830304"/><a data-primary="rollouts" data-secondary="resuming" data-type="indexterm" id="idm45664076829056"/> can safely proceed,
you can use the <code>resume</code> command to start up where you left off:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout resume deployments kuard</strong>
deployment.apps/kuard resumed</pre>
</div></section>
<section data-pdf-bookmark="Rollout History" data-type="sect2"><div class="sect2" id="idm45664076856000">
<h2>Rollout History</h2>
<p>Kubernetes Deployments maintain a history of rollouts, which can be useful both for understanding the previous state of the Deployment and for rolling back to a specific <span class="keep-together">version</span>.</p>
<p>You can <a data-primary="rollouts" data-secondary="history of" data-type="indexterm" id="idm45664076823024"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="rollout history" data-type="indexterm" id="idm45664076822016"/>see the Deployment history by running:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout history deployment kuard</strong>

deployment.apps/kuard
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         Update to green kuard
</pre>
<p>The revision history is given in oldest to newest order. A unique revision number is incremented for each new rollout.  So far we have two: the initial Deployment and the update of the image to <code>kuard:green</code>.</p>
<p>If you are interested in more details about a particular revision,
you can add the <span class="keep-together"><code>--revision</code></span> flag to view details about that specific revision:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout history deployment kuard --revision=2</strong>

deployment.apps/kuard with revision #2
Pod Template:
  Labels:       pod-template-hash=54b74ddcd4
        run=kuard
  Annotations:  kubernetes.io/change-cause: Update to green kuard
  Containers:
   kuard:
    Image:      gcr.io/kuar-demo/kuard-amd64:green
    Port:       &lt;none&gt;
    Host Port:  &lt;none&gt;
    Environment:        &lt;none&gt;
    Mounts:     &lt;none&gt;
  Volumes:      &lt;none&gt;
</pre>
<p>Let’s do one more update for this example.<a data-primary="change-cause annotation" data-type="indexterm" id="idm45664076815152"/><a data-primary="annotations" data-secondary="change-cause" data-type="indexterm" id="idm45664076814448"/>  Update the <code>kuard</code> version back to <code>blue</code> by modifying the container version number and updating the <code>change-cause</code>
annotation.  Apply it with <code>kubectl apply</code>.  The history should now have three entries:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout history deployment kuard</strong>

deployment.apps/kuard
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         Update to green kuard
3         Update to blue kuard
</pre>
<p>Let’s say there is an issue with the latest release and you want to roll
back while you investigate.  <a data-primary="rollouts" data-secondary="undoing" data-type="indexterm" id="idm45664076809808"/><a data-primary="kubectl tool" data-secondary="commands" data-tertiary="rollout undo" data-type="indexterm" id="idm45664076808832"/>You can simply undo the last rollout:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout undo deployments kuard</strong>
deployment.apps/kuard rolled back</pre>
<p>The <code>undo</code> command works regardless of the stage of the rollout. You can undo both partially completed and fully completed rollouts. An undo of a rollout is actually simply a rollout in reverse (for example from v2 to v1, instead of from v1 to v2), and all of the same policies that control the rollout strategy apply to the undo strategy as well.<a data-primary="ReplicaSets" data-secondary="adjusting number in a Deployment" data-type="indexterm" id="idm45664076805104"/>  You can see that the Deployment object simply adjusts the desired replica counts in the managed ReplicaSets:</p>
<pre data-type="programlisting">$ <strong>kubectl get replicasets -o wide</strong>

NAME               DESIRED   CURRENT   READY   ...   IMAGE(S)            ...
kuard-1128242161   0         0         0       ...   gcr.io/kuar-demo/   ...
kuard-1570155864   0         0         0       ...   gcr.io/kuar-demo/   ...
kuard-2738859366   3         3         3       ...   gcr.io/kuar-demo/   ...</pre>
<div data-type="caution"><h6>Caution</h6>
<p>When using declarative files to control your production systems, you should, as much as possible, ensure that the checked-in manifests match what is actually running in your cluster. When you do a <code>kubectl rollout undo</code>, you are updating the production state in a way that isn’t reflected in your source control.</p>
<p>An alternative (and perhaps preferable) way to undo a rollout is to revert your YAML file and <code>kubectl apply</code> the previous version.  In this way, your “change tracked configuration” more closely tracks what is really running in your cluster.</p>
</div>
<p>Let’s look at the Deployment history again:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout history deployment kuard</strong>

deployment.apps/kuard
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
3         Update to blue kuard
4         Update to green kuard
</pre>
<p>Revision 2 is missing!  It turns out that when you roll back to a previous revision, the Deployment simply reuses the template and renumbers it so that it is the latest revision.  What was revision 2 before is now revision 4.</p>
<p>We previously saw that you can use the <code>kubectl rollout undo</code> command to
roll back to a previous version of a Deployment. <a data-primary="kubectl tool" data-secondary="commands" data-tertiary="rollout undo" data-type="indexterm" id="idm45664076796320"/>Additionally, you can roll back to a specific revision in the history using the <code>--to-revision</code> flag:</p>
<pre data-type="programlisting">$ <strong>kubectl rollout undo deployments kuard --to-revision=3</strong>
deployment.apps/kuard rolled back
$ <strong>kubectl rollout history deployment kuard</strong>
deployment.apps/kuard
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
4         Update to green kuard
5         Update to blue kuard
</pre>
<p>Again, the <code>undo</code> took revision 3, applied it, and renumbered it as revision 5.</p>
<p>Specifying a revision of <code>0</code> is a shorthand way of specifying the previous revision.  In this way, <code>kubectl rollout undo</code> is equivalent to <code>kubectl rollout undo --to-revision=0</code>.</p>
<p>By default, the last 10 revisions of a Deployment are kept attached to the Deployment object itself. It is recommended that if you have Deployments that you expect to keep around for a long time, you set a maximum history size for the Deployment revision history. For example, if you do a daily update, you may limit your revision history to 14, to keep a maximum of two weeks’ worth of revisions (if you don’t expect to need to roll back beyond two weeks).<a data-primary="revisionHistoryLimit property (Deployment)" data-type="indexterm" id="idm45664076789408"/></p>
<p>To accomplish this, use the <code>revisionHistoryLimit</code> property in the Deployment
<span class="keep-together">specification</span>:</p>
<pre data-type="programlisting">...
spec:
  # We do daily rollouts, limit the revision history to two weeks of
  # releases as we don't expect to roll back beyond that.
  revisionHistoryLimit: 14
...</pre>
</div></section>
</div></section>
<section data-pdf-bookmark="Deployment Strategies" data-type="sect1"><div class="sect1" id="idm45664076825200">
<h1>Deployment Strategies</h1>
<p>When it comes time to change the version of the software implementing your service, a Kubernetes deployment supports two different rollout strategies, <code>Recreate</code> and <code>RollingUpdate</code>.<a data-primary="deployments" data-secondary="updating" data-startref="ix_dplyupd" data-type="indexterm" id="idm45664076784016"/> Let’s look at each in turn.<a data-primary="strategies" data-secondary="deployment" data-type="indexterm" id="ix_stratDply"/><a data-primary="deployments" data-secondary="strategies for" data-type="indexterm" id="ix_dplystrt"/></p>
<section data-pdf-bookmark="Recreate Strategy" data-type="sect2"><div class="sect2" id="idm45664076780048">
<h2>Recreate Strategy</h2>
<p>The <code>Recreate</code> strategy is the simpler of the two. <a data-primary="deployments" data-secondary="strategies for" data-tertiary="Recreate" data-type="indexterm" id="idm45664076778160"/><a data-primary="Recreate strategy" data-type="indexterm" id="idm45664076776912"/>It simply updates the ReplicaSet it manages to use the new image and terminates all of the Pods associated with the Deployment. The ReplicaSet notices that it no longer has any replicas and re-creates all Pods using the new image. Once the Pods are re-created, they are running the new version.</p>
<p>While this strategy is fast and simple, it will result in workload downtime. Because of this, the <code>Recreate</code> strategy should be used only for test Deployments where a service downtime is acceptable.</p>
</div></section>
<section data-pdf-bookmark="RollingUpdate Strategy" data-type="sect2"><div class="sect2" id="idm45664076774528">
<h2>RollingUpdate Strategy</h2>
<p>The <code>RollingUpdate</code> strategy is the generally preferable strategy for any user-facing service. <a data-primary="deployments" data-secondary="strategies for" data-tertiary="RollingUpdate" data-type="indexterm" id="ix_dplystrtRU"/><a data-primary="RollingUpdate strategy" data-type="indexterm" id="ix_RollUpd"/>While it is slower than <code>Recreate</code>, it is also significantly more sophisticated and robust. Using <code>RollingUpdate</code>, you can roll out a new version of your service while it is still receiving user traffic, without any downtime.</p>
<p>As you might infer from the name, the <code>RollingUpdate</code> strategy works by
updating a few Pods at a time, moving incrementally until all of the Pods are running the new version of your software.</p>
<section data-pdf-bookmark="Managing multiple versions of your service" data-type="sect3"><div class="sect3" id="idm45664076767760">
<h3>Managing multiple versions of your service</h3>
<p>Importantly, this means that for a while, both the new and the
old version of your service will be receiving requests and serving
traffic. This has important implications for how you build your
software. Namely, it is critically important that each version of your
software, and each of its clients, is capable of
talking interchangeably with both a slightly older and a slightly newer
version of your software.</p>
<p>Consider the following scenario: you are in the middle of rolling out your frontend software; half of your servers are running version 1, and half are running version 2. A user makes an initial request to your service and downloads a client-side JavaScript library that implements your UI. This request is serviced by a version 1 server, and thus the user receives the version 1 client library. This client library runs in the user’s browser and makes subsequent API requests to your service. These API requests happen to be routed to a version 2 server; thus, version 1 of your JavaScript client library is talking to version 2 of your API server. If you haven’t ensured compatibility between these versions, your application won’t function correctly.</p>
<p>At first, this might seem like an extra burden. But in truth, you always had this problem; you may just not have noticed. Concretely, a user can make a request at time <code>t</code> just before you initiate an update. This request is serviced by a version 1 server. At <code>t_1</code>, you update your service to version 2. At <code>t_2</code>, the version 1 client code running on the user’s browser runs and hits an API endpoint being operated by a version 2 server. No matter how you update your software, you have to maintain backward and forward compatibility for reliable updates. The nature of the <code>RollingUpdate</code> strategy simply makes that more clear and explicit.</p>
<p>This doesn’t just apply to JavaScript clients—it’s true of client libraries that are compiled into other services that make calls to your service. Just because you updated doesn’t mean they have updated their client libraries. This sort of backward compatibility is critical to decoupling your service from systems that depend on your service. If you don’t formalize your APIs and decouple yourself, you are forced to carefully manage your rollouts with all of the other systems that call into your service. This kind of tight coupling makes it extremely hard to produce the necessary agility to be able to push out new software every week, let alone every hour or every day. In the decoupled architecture shown in <a data-type="xref" href="#fig1201">Figure 10-1</a>, the frontend is isolated from the backend via an API contract and a load balancer, whereas in the coupled architecture, a thick client compiled into the frontend is used to connect directly to the backends.</p>
<figure><div class="figure" id="fig1201">
<img alt="kur3 1001" height="562" src="assets/kur3_1001.png" width="1196"/>
<h6><span class="label">Figure 10-1. </span>Diagrams of decoupled (left) and coupled (right) application <span class="keep-together">architectures</span></h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="Configuring a rolling update" data-type="sect3"><div class="sect3" id="idm45664076758368">
<h3>Configuring a rolling update</h3>
<p><code>RollingUpdate</code> is a fairly generic strategy; it can be used to update
a variety of applications in a variety of settings.<a data-primary="RollingUpdate strategy" data-secondary="configuring" data-type="indexterm" id="idm45664076756320"/> Consequently, the
rolling update itself is quite configurable; you can tune its behavior
to suit your particular needs. There are two parameters you
can use to tune the rolling update behavior: <code>maxUnavailable</code> and <span class="keep-together"><code>maxSurge</code></span>.</p>
<p>The <code>maxUnavailable</code> parameter sets the maximum number of Pods that
can be unavailable during a rolling update.<a data-primary="maxUnavailable parameter" data-type="indexterm" id="idm45664076752976"/><a data-primary="RollingUpdate strategy" data-secondary="configuring" data-tertiary="maxUnavailable parameter" data-type="indexterm" id="idm45664076752208"/> It can either be set to
an absolute number (e.g., <code>3</code>, meaning a maximum of three Pods can be
unavailable) or to a percentage (e.g., <code>20%</code>, meaning a
maximum of 20% of the desired number of replicas can be unavailable).
Generally speaking, using a percentage is a good approach for most
services, since the value is correctly applied regardless of
the desired number of replicas in the Deployment. However, there
are times when you may want to use an absolute number (e.g.,
limiting the maximum unavailable Pods to one).</p>
<p>At its core, the <code>maxUnavailable</code> parameter helps tune how quickly a
rolling update proceeds. For example, if you set <code>maxUnavailable</code> to
<code>50%</code>, then the rolling update will immediately scale the old ReplicaSet
down to 50% of its original size. If you have four replicas, it will
scale it down to two replicas. The rolling update will then replace
the removed Pods by scaling the new ReplicaSet up to two replicas, for
a total of four replicas (two old, two new). It will then scale
the old ReplicaSet down to zero replicas, for a total size of two new
replicas. Finally, it will scale the new ReplicaSet up to four
replicas, completing the rollout. Thus, with <code>maxUnavailable</code> set
to <code>50%</code>, the rollout completes in four steps, but with
only 50% of the service capacity at times.</p>
<p>Consider what happens if we instead set <code>maxUnavailable</code> to <code>25%</code>. In
this situation, each step is only performed with a single replica
at a time and thus it takes twice as many steps for the rollout to
complete, but availability only drops to a minimum of 75% during the
rollout. This illustrates how <code>maxUnavailable</code> allows us to trade
rollout speed for availability.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The observant among you will notice that the <code>Recreate</code> strategy is
identical to the <code>RollingUpdate</code> strategy with <code>maxUnavailable</code>
set to <code>100%</code>.</p>
</div>
<p>Using reduced capacity to achieve a successful rollout is useful either
when your service has cyclical traffic patterns (for example, if there’s much less traffic at night) or when you have limited resources, so scaling to larger than the current maximum number of replicas isn’t possible.</p>
<p>However, there are situations where you don’t want to fall below
100% capacity, but you are willing to temporarily use additional
resources to perform a rollout.<a data-primary="RollingUpdate strategy" data-secondary="configuring" data-tertiary="maxSurge parameter" data-type="indexterm" id="idm45664076740592"/> In these situations, you
can set the <code>maxUnavailable</code> parameter to <code>0</code>, and instead control
the rollout using the <code>maxSurge</code> parameter. Like <code>maxUnavailable</code>,
<code>maxSurge</code> can be specified either as a specific number or a percentage.</p>
<p>The <code>maxSurge</code> parameter controls how many extra resources can be
created to achieve a rollout. To illustrate how this works, imagine a service with 10 replicas. We set <code>maxUnavailable</code> to <code>0</code>
and <code>maxSurge</code> to <code>20%</code>. The first thing the rollout will do is
scale the new ReplicaSet up by 2 replicas, for a total of 12 (120%) in the service. It will then scale the old ReplicaSet down
to 8 replicas, for a total of 10 (8 old, 2 new) in the service. This process proceeds until the rollout is complete. At any time, the capacity of the service is guaranteed to be at least 100% and
the maximum extra resources used for the rollout are limited to an
additional 20% of all resources.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Setting <code>maxSurge</code> to <code>100%</code> is equivalent to a blue/green Deployment.
The Deployment controller first scales the new version up to 100% of
the old version. Once the new version is healthy, it immediately
scales the old version down to 0%.<a data-primary="deployments" data-secondary="strategies for" data-startref="ix_dplystrtRU" data-tertiary="RollingUpdate" data-type="indexterm" id="idm45664076731472"/><a data-primary="RollingUpdate strategy" data-startref="ix_RollUpd" data-type="indexterm" id="idm45664076729952"/></p>
</div>
</div></section>
</div></section>
<section data-pdf-bookmark="Slowing Rollouts to Ensure Service Health" data-type="sect2"><div class="sect2" id="idm45664076757776">
<h2>Slowing Rollouts to Ensure Service Health</h2>
<p>Staged rollouts are meant to ensure that the rollout results in a healthy, stable service running the new software version.<a data-primary="strategies" data-secondary="deployment" data-tertiary="slowing rollouts to ensure service health" data-type="indexterm" id="idm45664076727136"/><a data-primary="deployments" data-secondary="strategies for" data-tertiary="slowing rollouts to ensure service health" data-type="indexterm" id="idm45664076725792"/><a data-primary="services" data-secondary="ensuring health by slowing rollouts" data-type="indexterm" id="idm45664076724544"/> To do this, the Deployment controller always waits until a Pod reports that it is ready before moving on to update the next Pod.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The Deployment controller examines the Pod’s status as
determined by its readiness checks.<a data-primary="readiness probes" data-type="indexterm" id="idm45664076722272"/> Readiness checks are part of the
Pod’s health checks, described in detail in <a data-type="xref" href="ch05.xhtml#pods">Chapter 5</a>. If you want to use Deployments to reliably roll out your
software, you <em>have</em> to specify readiness health checks for the
containers in your Pod. Without these checks, the Deployment controller
is running without knowing the Pod’s status.</p>
</div>
<p>Sometimes, however, simply noticing that a Pod has become ready doesn’t
give you sufficient confidence that the Pod is actually behaving
correctly. Some error conditions don’t occur immediately.
For example, you could have a serious memory leak that takes
a few minutes to show up, or you could have a bug that is only
triggered by 1% of all requests.  In most real-world scenarios, you
want to wait a period of time to have high confidence that the
new version is operating correctly before you move on to updating
the next Pod.<a data-primary="minReadySeconds parameter" data-type="indexterm" id="idm45664076719520"/></p>
<p class="pagebreak-before less_space">For Deployments, this time to wait is defined by the <code>minReadySeconds</code>
parameter:</p>
<pre data-type="programlisting">...
spec:
  minReadySeconds: 60
...</pre>
<p>Setting <code>minReadySeconds</code> to <code>60</code> indicates that the Deployment must
wait for 60 seconds <em>after</em> seeing a Pod become healthy before
moving on to updating the next Pod.</p>
<p>In addition to waiting for a Pod to become healthy,
you also want to set a timeout that limits how long the system will
wait.<a data-primary="timeout for deployments" data-type="indexterm" id="idm45664076714640"/> Suppose, for example, the new version of your service has a bug
and immediately deadlocks. It will never become ready, and in the
absence of a timeout, the Deployment controller will stall your
rollout forever.</p>
<p>The correct behavior in such a situation is to time out the rollout.
This in turn marks the rollout as failed. This failure status can
be used to trigger alerting that can indicate to an operator that
there is a problem with the rollout.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>At first blush, timing out a rollout might seem like an unnecessary
complication. However, increasingly, things like rollouts are being
triggered by fully automated systems with little to no human involvement. In such a situation, timing out becomes a critical
exception, which can either trigger an automated rollback of the
release or create a ticket/event that triggers human intervention.</p>
</div>
<p>In order to set the timeout period, you will use the Deployment parameter <code>progressDeadlineSeconds</code>:</p>
<pre data-type="programlisting">...
spec:
  progressDeadlineSeconds: 600
...</pre>
<p>This example sets the progress deadline to 10 minutes.<a data-primary="progressDeadlineSeconds parameter" data-type="indexterm" id="idm45664076709712"/> If
any particular stage in the rollout fails to progress in 10 minutes,
then the Deployment is marked as failed, and all attempts to move
the Deployment forward are halted.</p>
<p>It is important to note that this timeout is given in terms of
Deployment <em>progress</em>, not the overall length of a Deployment. In this context, progress is defined as any time the Deployment creates or deletes a Pod. When that happens, the timeout clock is reset to zero. <a data-type="xref" href="#fig1202">Figure 10-2</a> shows the Deployment life cycle.</p>
<figure><div class="figure" id="fig1202">
<img alt="kur3 1002" height="405" src="assets/kur3_1002.png" width="905"/>
<h6><span class="label">Figure 10-2. </span>The Kubernetes Deployment life cycle</h6>
</div></figure>
</div></section>
</div></section>
<section data-pdf-bookmark="Deleting a Deployment" data-type="sect1"><div class="sect1" id="idm45664076704576">
<h1>Deleting a Deployment</h1>
<p>If you ever want to delete a <a data-primary="strategies" data-secondary="deployment" data-startref="ix_stratDply" data-type="indexterm" id="idm45664076703088"/><a data-primary="deployments" data-secondary="strategies for" data-startref="ix_dplystrt" data-type="indexterm" id="idm45664076701840"/><a data-primary="deployments" data-secondary="deleting" data-type="indexterm" id="idm45664076700624"/>Deployment, you can do it with the imperative command:</p>
<pre data-type="programlisting">$ <strong>kubectl delete deployments kuard</strong></pre>
<p>You can also do it using the <a data-primary="kubectl tool" data-secondary="commands" data-tertiary="delete" data-type="indexterm" id="idm45664076698032"/><a data-primary="YAML" data-secondary="deployment.yaml file" data-type="indexterm" id="idm45664076696784"/>declarative YAML file you created earlier:</p>
<pre data-type="programlisting">$ <strong>kubectl delete -f kuard-deployment.yaml</strong></pre>
<p>In either case, by default, deleting a Deployment deletes the entire
service. The means it will delete not just the Deployment,
but also any ReplicaSets it manages, as well as
any Pods the ReplicaSets manage. As with ReplicaSets, if
this is not the desired behavior, you can use the <code>--cascade=false</code>
flag to delete only the Deployment object.</p>
</div></section>
<section data-pdf-bookmark="Monitoring a Deployment" data-type="sect1"><div class="sect1" id="idm45664076693328">
<h1>Monitoring a Deployment</h1>
<p>If a Deployment fails to make progress after a specified amount of time,
it will time out.<a data-primary="deployments" data-secondary="monitoring" data-type="indexterm" id="idm45664076691664"/><a data-primary="failed deployment" data-type="indexterm" id="idm45664076690688"/> When this happens, the status of the Deployment will transition to a failed state. This status can be obtained from the <code>status.conditions</code> array, where there will be a <code>Condition</code> whose <code>Type</code> is <code>Progressing</code> and whose <code>Status</code> is <code>False</code>. A Deployment in such a state has failed and will not progress further. To set how long the Deployment controller should wait before transitioning into this state, use the <code>spec.progressDeadlineSeconds</code> field.</p>
</div></section>
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45664076686416">
<h1>Summary</h1>
<p>Ultimately, the primary goal of Kubernetes is to make
it easy for you to build and deploy reliable distributed systems.
This means not just instantiating the application once, but
managing the regularly scheduled rollout of new versions of that
software service. Deployments are a critical piece of reliable rollouts and rollout management for your services. In the next chapter we will cover DaemonSets, which ensure only a single copy of a Pod is running across a set of nodes in a Kubernetes cluster.<a data-primary="deployments" data-startref="ix_dply" data-type="indexterm" id="idm45664076685088"/></p>
</div></section>
</div></section></div></body></html>