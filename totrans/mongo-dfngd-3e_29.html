<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 23. Making Backups"><div class="chapter" id="chapter-backup"><h1><span class="label">Chapter 23. </span>Making Backups</h1><p>It<a data-type="indexterm" data-primary="administration, of servers" data-secondary="backups" id="ASback23"/><a data-type="indexterm" data-primary="server administration" data-secondary="backups" id="SAbackup23"/> is important to make regular backups of your system. Backups
  are good protection against most types of failure, and very little can’t be
  solved by restoring from a clean backup. This chapter covers the common
  options for making backups:</p><ul><li><p>Single-server backups, including snapshot backup and restore
      procedure</p></li><li><p>Special considerations for backing up replica sets</p></li><li><p>Baking up a sharded cluster</p></li></ul><p>Backups are only useful if you are confident about deploying them in
  an emergency. Thus, for any backup technique you choose, be sure to practice
  both making backups and restoring from them until you are comfortable with
  the restore procedure.</p><section data-type="sect1" data-pdf-bookmark="Backup Methods"><div class="sect1" id="idm45882333915656"><h1>Backup Methods</h1><p>There<a data-type="indexterm" data-primary="backups" data-secondary="options for" id="idm45882333914744"/> are a number of options for backing up<a data-type="indexterm" data-primary="clusters" data-secondary="backup options" id="idm45882333913432"/> clusters in MongoDB. MongoDB Atlas<a data-type="indexterm" data-primary="MongoDB Atlas" id="idm45882333912152"/>, the official MongoDB cloud service, provides both
    continuous backups and cloud provider snapshots. Continuous backups take
    incremental backups of data in your cluster, ensuring your backups are
    typically just a few seconds behind the operating system. Cloud provider
    snapshots provide localized backup storage using the snapshot
    functionality of the cluster’s cloud service provider (e.g., Amazon Web
    Services, Microsoft Azure, or Google Cloud Platform). The best backup
    solution for the majority of scenarios is continuous backups.</p><p>MongoDB also provides backup capability through Cloud
    Manager<a data-type="indexterm" data-primary="Cloud Manager" id="idm45882333910360"/> and Ops Manager<a data-type="indexterm" data-primary="Ops Manager" id="idm45882333909320"/>. Cloud Manager is a hosted backup, monitoring, and
    automation service for MongoDB. Ops Manager is an on-premise solution that
    has similar functionality to Cloud Manager.</p><p>For individuals and teams managing MongoDB clusters directly, there
    are several backup strategies. We will outline these strategies in the
    rest of this chapter.</p></div></section><section data-type="sect1" data-pdf-bookmark="Backing Up a Server"><div class="sect1" id="idm45882333907688"><h1>Backing Up a Server</h1><p>There<a data-type="indexterm" data-primary="servers" data-secondary="backing up" id="Sback23"/><a data-type="indexterm" data-primary="backups" data-secondary="servers" data-tertiary="what to backup" id="idm45882333905336"/> are a variety of ways to create backups. Regardless of the
    method, making a backup can cause strain on a system: it generally
    requires reading all your data into memory. Thus, backups should generally
    be done on replica set secondaries (as opposed to the primary) or, for
    standalone servers, at an off time.</p><p>The techniques in this section apply to any <em class="filename">mongod</em>, whether a standalone server or a member
    of a replica set, unless otherwise noted.</p><section data-type="sect2" data-pdf-bookmark="Filesystem Snapshot"><div class="sect2" id="idm45882333902488"><h2>Filesystem Snapshot</h2><p>Filesystem<a data-type="indexterm" data-primary="files and filesystems" data-secondary="filesystem snapshots" id="FFsnap23"/><a data-type="indexterm" data-primary="backups" data-secondary="servers" data-tertiary="filesystem snapshots" id="Bssnap23"/><a data-type="indexterm" data-primary="snapshots" id="snap23"/> snapshots use system-level tools to create copies of the
      device that holds MongoDB’s data files. These methods complete quickly
      and work reliably, but require additional system configuration outside
      of MongoDB.</p><p>MongoDB 3.2 added support for volume-level backup<a data-type="indexterm" data-primary="volume-level backup" id="idm45882333896392"/> of MongoDB instances using the WiredTiger storage engine
      when those instances’ data files and journal files reside on separate
      volumes. However, to create a coherent backup, the database must be
      locked and all writes to the database must be suspended during the
      backup process.</p><p>Prior to MongoDB 3.2, creating volume-level backups of MongoDB
      instances using WiredTiger required that the data files and journal
      reside on the same volume.</p><p>Snapshots work by creating pointers between the live data and a
      special snapshot volume. These pointers are theoretically equivalent to
      “hard links.” As the working data diverges from the snapshot, the
      snapshot process uses a copy-on-write strategy. As a result, the
      snapshot only stores modified data.</p><p>After making the snapshot, you mount the snapshot image on your
      filesystem and copy data from the snapshot. The resulting backup
      contains a full copy of all data.</p><p>The database must be valid when the snapshot takes place. This
      means that all writes accepted by the database need to be fully written
      to disk: either to the journal or to data files. If there are writes
      that are not on disk when the backup occurs, the backup will not reflect
      these changes.</p><p>For the WiredTiger storage engine, the data files reflect a
      consistent state as of the last checkpoint. Checkpoints occur every
      minute.</p><p>Snapshots create an image of an entire disk or volume. Unless you
      need to back up your entire system, consider isolating your MongoDB data
      files, journal (if applicable), and configuration on one logical disk
      that doesn’t contain any other data. <span class="keep-together">Alternatively</span>, store all MongoDB
      data files on a dedicated device so that you can make backups without
      duplicating extraneous data.</p><p>Ensure that you copy data from snapshots onto other systems. This
      ensures that data is safe from site failures.</p><p>If your <em>mongod</em> instance has journaling
      enabled, then you can use any kind of filesystem or volume/block-level
      snapshot tool to create backups.</p><p>If you manage your own infrastructure on a Linux-based system,
      configure your system using the Linux Logical Volume Manager
      (LVM)<a data-type="indexterm" data-primary="Linux Logical Volume Manager (LVM)" id="idm45882333889560"/> to provide your disk packages and provide snapshot
      capability. LVM allows for the flexible combination and division of
      physical disk partitions, enabling dynamically resizable filesystems.
      You can also use LVM-based setups within a cloud/virtualized
      environment.</p><p>In the initial setup of LVM, first we assign disk partitions to
      physical volumes <code>(pvcreate)</code>, then one
      or more of these are then assigned to a volume group <code>(vgcreate)</code>, and then we create logical volumes
      <code>(lvcreate)</code> referring to the volume
      groups. We can build a filesystem on the logical volume <code>(mkfs)</code>, which when created can be mounted for
      use <code>(mount)</code>.</p><section data-type="sect3" data-pdf-bookmark="Snapshot backup and restore procedure"><div class="sect3" id="idm45882333887928"><h3>Snapshot backup and restore procedure</h3><p>This section provides an overview of a simple backup process
        using LVM on a Linux system. While the tools, commands, and paths may
        be (slightly) different on your system, the following steps provide a
        high-level overview of the backup operation.</p><p>Only use the following procedure as a guideline for a backup
        system and infrastructure. Production backup systems must consider a
        number of application-specific requirements and factors unique to
        specific environments.</p><p>To create a snapshot with LVM, issue a command as <code>root</code> in the following format:</p><pre data-type="programlisting"># lvcreate --size 100M --snapshot --name mdb-snap01 /dev/vg0/mongodb</pre><p>This command creates an LVM snapshot (with the <code>--snapshot</code> option) named <code>mdb-snap01</code> of the <code>mongodb</code> volume in the <code>vg0</code> volume group, which will be located at
        <code>/dev/vg0/mdb-snap01</code>. The location
        and paths to your systems, volume groups, and devices may vary
        slightly depending on your operating system’s LVM
        <span class="keep-together">configuration</span>.</p><p>The snapshot has a cap of 100 MB, because of the parameter
        <code>--size 100M</code>. This size does not
        reflect the total amount of the data on the disk, but rather the
        amount of differences between the current state of
        <em>/dev/vg0/mongodb</em> and the snapshot
        (<em>/dev/vg0/mdb-snap01</em>).</p><p>The snapshot will exist when the command returns. You can
        restore directly from the snapshot at any time, or create a new
        logical volume and restore from the snapshot to the alternate
        image.</p><p>While snapshots are great for creating high-quality backups
        quickly, they are not ideal as a format for storing backup data.
        Snapshots typically depend and reside on the same storage
        infrastructure as the original disk images. Therefore, it’s crucial
        that you archive these snapshots and store them elsewhere.</p><p>After creating a snapshot, mount the snapshot and copy the data
        to separate storage. Alternatively, take a block-level copy of the
        snapshot image, such as with the following procedure:</p><p><code># umount
        /dev/vg0/mdb-snap01</code></p><p><code># dd if=/dev/vg0/mdb-snap01 | gzip &gt;
        mdb-snap01.gz</code></p><p>This command sequence does the following:</p><ul><li><p>Ensures that the <em>/dev/vg0/mdb-snap01</em>
            device is not mounted</p></li><li><p>Performs a block-level copy of the entire snapshot image
            using the <code>dd</code> command and
            compresses the result in a gzipped file in the current working
            directory</p></li></ul><div data-type="warning" epub:type="warning"><h6>Warning</h6><p>The <code>dd</code> command will create
          a large <em>.gz</em> file in your current working
          directory. Make sure that you run <em>this command</em>
          in a filesystem that has enough free space.</p></div><p>To restore a snapshot created with LVM, issue the following
        sequence of commands:</p><p><code># lvcreate --size 1G --name mdb-new
        vg0</code></p><p><code># gzip -d -c mdb-snap01.gz | dd
        of=/dev/vg0/mdb-new</code></p><p><code># mount /dev/vg0/mdb-new
        /srv/mongodb</code></p><p>This sequence does the following:</p><ul><li><p>Creates a new logical volume named
            <em>mdb-new</em>, in the <em>/dev/vg0</em>
            volume group. The path to the new device will be
            <em>/dev/vg0/mdb-new</em>. You can use a different
            name, and change 1G to your desired volume size.</p></li><li><p>Uncompresses and unarchives the
            <em>mdb-snap01.gz</em> file into the
            <em>mdb-new</em> disk image.</p></li><li><p>Mounts the <em>mdb-new</em> disk image to the
            <em>/srv/mongodb</em> directory. Modify the mount
            point to correspond to your MongoDB data file location or other
            location as needed.</p></li></ul><p>The restored snapshot will have a stale <code>mongod.lock</code> file. If you do not remove this
        file from the snapshot, MongoDB may assume that the stale lock file
        indicates an unclean shutdown. If you’re running with <code>storage.journal.enabled</code> enabled and you do
        not use <code>db.fsyncLock()</code>, you do not
        need to remove the <code>mongod.lock</code>
        file. If you use <code>db.fsyncLock()</code> you
        will need to remove the lock.</p><p>To restore a backup without writing to a compressed
        <em>.gz</em> file, use the following sequence of
        commands:</p><p><code># umount
        /dev/vg0/mdb-snap01</code></p><p><code># lvcreate --size 1G --name mdb-new
        vg0</code></p><p><code># dd if=/dev/vg0/mdb-snap01
        of=/dev/vg0/mdb-new</code></p><p><code># mount /dev/vg0/mdb-new
        /srv/mongodb</code></p><p>You can implement off-system backups using the combined process
        and SSH. This sequence is identical to procedures explained
        previously, except that it archives and compresses the backup on a
        remote system using SSH:</p><p><code>umount
        /dev/vg0/mdb-snap01</code></p><p><code>dd if=/dev/vg0/mdb-snap01 | ssh
        username@example.com gzip &gt; 
        /opt/backup/mdb-snap01.gz</code></p><p><code>lvcreate --size 1G --name mdb-new
        vg0</code></p><p><code>ssh username@example.com gzip -d -c
        /opt/backup/mdb-snap01.gz | dd of=/dev/vg0/mdb-new</code></p><p><code>mount /dev/vg0/mdb-new
        /srv/mongodb</code></p><p>Starting in MongoDB 3.2, for the purpose of volume-level backup
        of MongoDB instances using WiredTiger, the data files and the journal
        are no longer required to reside on a single volume. However, the
        database must be locked and all writes to the database must be
        suspended during the backup process to ensure the consistency of the
        backup.</p><p>If your <em>mongod</em> instance is either running
        without journaling or has the journal files on a separate volume, you
        must flush all writes to disk and lock the database to prevent writes
        during the backup process. If you have a replica set configuration,
        then for your backup use a secondary that is not receiving reads
        (i.e., a hidden member).</p><p class="pagebreak-before">To<a data-type="indexterm" data-primary="db.fsyncLock()" id="idm45882333851896"/> do this, issue the <code>db.fsyncLock()</code> method in the <code>mongo</code> shell:</p><pre data-type="programlisting" data-code-language="javascript"><code>&gt; db.fsyncLock();</code></pre><p>Then perform the backup operation described previously.</p><p>After the snapshot completes, unlock the database by issuing the
        following command in the <code>mongo</code>
        shell:</p><pre data-type="programlisting" data-code-language="javascript"><code class="o">&gt;</code> <code class="nx">db</code><code class="p">.</code><code class="nx">fsyncUnlock</code><code class="p">();</code></pre><p>This<a data-type="indexterm" data-startref="snap23" id="idm45882333844632"/><a data-type="indexterm" data-startref="Bssnap23" id="idm45882333843896"/><a data-type="indexterm" data-startref="FFsnap23" id="idm45882333843128"/> process is described more fully in
        the following section.</p></div></section></div></section><section data-type="sect2" data-pdf-bookmark="Copying Data Files"><div class="sect2" id="idm45882333902184"><h2>Copying Data Files</h2><p>Another<a data-type="indexterm" data-primary="files and filesystems" data-secondary="copying data files" id="idm45882333841240"/><a data-type="indexterm" data-primary="data" data-secondary="copying data files" id="idm45882333840104"/><a data-type="indexterm" data-primary="backups" data-secondary="servers" data-tertiary="copying data files" id="idm45882333839000"/> way of creating single-server backups is to make a copy
      of everything in the data directory. Because you cannot copy all of the
      files at the same moment without filesystem support, you must prevent
      the data files from changing while you are making the copy.
      This<a data-type="indexterm" data-primary="db.fsyncLock()" id="idm45882333837192"/> can be accomplished with a command called <code>fsyncLock<a data-type="indexterm" data-primary="fsyncLock command" id="idm45882333835944"/></code>:</p><pre data-type="programlisting" data-code-language="javascript"><code class="o">&gt;</code> <code class="nx">db</code><code class="p">.</code><code class="nx">fsyncLock</code><code class="p">()</code></pre><p>This command <span class="firstterm">locks</span> the database against any
      further writes and then flushes all dirty data to disk
      (<span class="firstterm"><code>fsync</code></span>),
      ensuring that the files in the data directory have the latest consistent
      information and are not changing.</p><p>Once this command has been run, <em class="filename">mongod</em> will enqueue all incoming writes. It
      will not process any further writes until it has been unlocked. Note
      that this command stops writes to <em>all</em> databases
      (not just the one <em>db</em> is connected to).</p><p>Once the <code>fsyncLock</code> command
      returns, copy all of the files in your data directory to a backup
      location. On Linux, this can be done with a command such as:</p><pre data-type="programlisting">$ cp -R /data/db/* /mnt/external-drive/backup</pre><p>Make sure that you copy absolutely every file and folder from the
      data directory to the backup location. Excluding files or directories
      may make the backup unusable or <span class="keep-together">corrupt</span>.</p><p>Once you have finished copying the data, unlock the database to
      allow it to take writes again:</p><pre data-type="programlisting" data-code-language="javascript"><code class="o">&gt;</code> <code class="nx">db</code><code class="p">.</code><code class="nx">fsyncUnlock</code><code class="p">()</code></pre><p>Your database will begin handling writes again normally.</p><p>Note that there are some locking issues with authentication and
      <code>fsyncLock</code>. If you are using
      authentication, do not close the shell between calling <code class="function">fsyncLock</code> and <span class="keep-together"><code class="function">fsyncUnlock</code></span>. If you disconnect, you
      may be unable to reconnect and have to restart <code>mongod</code>. The <code>fsyncLock</code> setting does not persist between
      restarts; <code>mongod</code> will always start up
      unlocked.</p><p>As an alternative to <code>fsyncLock</code>,
      you can instead shut down <em class="filename">mongod</em>,
      copy the files, and then start <em class="filename">mongod</em> back up again. Shutting down <em class="filename">mongod</em> effectively flushes all changes to
      disk and prevents new writes from occurring during the backup.</p><p>To restore from the copy of the data directory, ensure that
      <em class="filename">mongod</em> is not running and that the
      data directory you want to restore into is empty. Copy the backed-up
      data files to the data directory, and then start <em class="filename">mongod</em>. For example, the following command
      would restore the files backed up with the command shown earlier:</p><pre data-type="programlisting">$ cp -R /mnt/external-drive/backup/* /data/db/
$ mongod -f mongod.conf</pre><p>Despite the warnings about partial data directory copies, you can
      use this method to back up individual databases if you know what to copy
      and where they are using the <code>--directoryperdb</code> option.
      To back up an individual database (called, say, <em class="filename">myDB</em>), which is only available if you are
      using the<a data-type="indexterm" data-primary="--directoryperdb" data-primary-sortas="directoryperdb" id="idm45882333789560"/> <code class="option">--directoryperdb</code> option, copy the entire
      <em class="filename">myDB</em> directory. Partial data
      directory copies are only possible with the
      <code>--directoryperdb</code> option.</p><p>You can restore specific databases by copying just the files with
      the correct database name into your data directory. You must be starting
      from a clean shutdown to restore piecemeal like this. If you had a crash
      or a hard shutdown, do not attempt to restore a single database from the
      backup: replace the entire directory and start the <em class="filename">mongod</em> to allow the journal files to be
      replayed.</p><div data-type="warning" epub:type="warning"><h6>Warning</h6><p>Never use <code class="function">fsyncLock</code> in
        conjunction with <em class="filename">mongodump</em>
        (described next). Depending on what else your database is doing,
        <em class="filename">mongodump</em> may hang forever if the
        database is locked.</p></div></div></section><section data-type="sect2" data-pdf-bookmark="Using mongodump"><div class="sect2" id="idm45882333884712"><h2>Using mongodump</h2><p>The<a data-type="indexterm" data-primary="mongodump" id="mongodump23"/><a data-type="indexterm" data-primary="backups" data-secondary="servers" data-tertiary="using mongodump" id="idm45882333757512"/> final way of making a single-server backup is to use
      <em class="filename">mongodump</em>. <em class="filename">mongodump</em> is mentioned last because it has
      some downsides. It is slower (both to get the backup and to restore from
      it) and it has some issues with replica sets, which are discussed in
      <a data-type="xref" href="#sect1-rs-backup">“Specific Considerations for Replica Sets”</a>. However, it also has some benefits:
      it is a good way to back up individual databases, collections, and even
      subsets of collections.</p><p><em class="filename">mongodump</em> has a variety of
      options that you can see by running <code>mongodump
      --help</code>. Here, we will focus on the most useful ones to use for
      backing up.</p><p>To back up all databases, simply run <em class="filename">mongodump</em>. If you are running <em class="filename">mongodump</em> on the same machine as the
      <em class="filename">mongod</em>, you can simply specify the
      port <em class="filename">mongod</em> is running on:</p><pre data-type="programlisting">$ mongodump -p 31000</pre><p><em class="filename">mongodump</em> will create a
      <em class="filename">dump</em> directory<a data-type="indexterm" data-primary="dump directory" id="idm45882333725896"/> in the current directory, which contains a dump of all
      your data. This <em class="filename">dump</em> directory is
      organized by database and by collection into folders and subfolders. The
      actual data is stored in <em class="filename">.bson</em>
      files, which merely contain every document in a collection in BSON,
      concatenated together. You can examine <em class="filename">.bson</em> files using the<a data-type="indexterm" data-primary="bsondump tool" id="idm45882333722552"/> <em class="filename">bsondump</em> tool, which
      comes with MongoDB.</p><p>You do not even need to have a server running to use <em class="filename">mongodump</em>. You can use the <span class="keep-together"><code class="option">--dbpath</code></span> option to
      specify your data directory, and <em class="filename">mongodump</em> will use the data files to copy
      data:</p><pre data-type="programlisting" data-code-language="javascript"><code class="nx">$</code> <code class="nx">mongodump</code> <code class="o">--</code><code class="nx">dbpath</code> <code class="o">/</code><code class="nx">data</code><code class="o">/</code><code class="nx">db</code></pre><p>You should not use <code class="option">--dbpath</code> if <em class="filename">mongod</em> is running.</p><p>One issue with <em class="filename">mongodump</em> is
      that it is not an instantaneous backup: the system may be taking writes
      while the backup occurs. Thus, you might end up with a situation where
      user A begins a backup that causes <em>mongodump</em> to
      dump the database <em>A</em>, but while this is happening
      user B drops <em>A</em>. However, <em class="filename">mongodump</em> has already dumped it, so you’ll
      end up with a snapshot of the data that is inconsistent with the state
      on the original server.</p><p>To avoid this, if you are running <em class="filename">mongod</em> with <code class="option">--replSet</code>, you
      can use <em class="filename">mongodump</em>’s
      <code class="option">--oplog</code> option. This will keep track of all operations
      that occur on the server while the dump is taking place, so these
      operations can be replayed when the backup is restored. This gives you a
      consistent point-in-time snapshot of data from the source server.</p><p>If you pass <em class="filename">mongodump</em> a
      replica set connection string (e.g., <code>"<em><code>setName</code></em>/<em><code>seed1</code></em>,<em><code>seed2</code></em>,<em><code>seed3</code></em>"</code>),
      it will automatically select the primary to dump from. If you want to
      use a secondary, you can specify a <code>read preference</code>.
      The <code>read preference</code> can be specified by
      <code>--uri connection string</code>, by the <code>uri
      readPreferenceTags</code> option, or by the
      <code>--readPreference</code> command-line option. For more
      details on the various settings and options, please see <a href="https://oreil.ly/GH3-O">the
      <em class="filename">mongodump</em> MongoDB documentation page</a>.
      </p><p>To restore from a <em class="filename">mongodump</em>
      backup, use the <em class="filename">mongorestore</em>
      tool:</p><pre data-type="programlisting" data-code-language="javascript"><code class="nx">$</code> <code class="nx">mongorestore</code> <code class="o">-</code><code class="nx">p</code> <code class="mi">31000</code> <code class="o">--</code><code class="nx">oplogReplay</code> <code class="nx">dump</code><code class="o">/</code></pre><p>If you used the <code class="option">--oplog</code> option to dump the
      database, you must use the <span class="keep-together"><code class="option">--oplogReplay</code></span> option with
      <em class="filename">mongorestore</em> to get the
      point-in-time snapshot.</p><p>If you are replacing data on a running server, you may (or may
      not) wish to use the <code>--drop</code> option,
      which drops a collection before restoring it.</p><p>The behavior of <em class="filename">mongodump</em> and
      <em class="filename">mongorestore<a data-type="indexterm" data-primary="mongorestore" id="idm45882333652264"/></em> has changed over time. To prevent
      compatibility issues, try to use the same version of both utilities (you
      can see their versions by running <code>mongodump
      --version</code> and <code>mongorestore
      --version</code>).</p><div data-type="warning" epub:type="warning"><h6>Warning</h6><p>From MongoDB version 4.2 and up, you cannot use either <em class="filename">mongodump</em> or <em class="filename">mongorestore</em> as a strategy for backing up a
        sharded cluster. These tools do not maintain the atomicity guarantees
        of transactions across shards.</p></div><section data-type="sect3" data-pdf-bookmark="Moving collections and databases with mongodump and&#10;        mongorestore"><div class="sect3" id="idm45882333647976"><h3>Moving collections and databases with mongodump and
        mongorestore</h3><p>You<a data-type="indexterm" data-primary="databases" data-secondary="moving with mongodump" id="idm45882333647064"/><a data-type="indexterm" data-primary="collections" data-secondary="moving with mongodump" id="idm45882333645928"/> can restore into an entirely different database and
        collection than you dumped from. This can be useful if different
        environments use different database names (say, <em class="filename">dev</em> and <em class="filename">prod</em>) but the same collection names.</p><p>To restore a <em class="filename">.bson</em> file
        into a specific database and collection, specify the targets on the
        command line:</p><pre data-type="programlisting">$ mongorestore --db newDb --collection someOtherColl dump/oldDB/oldColl.bson</pre><p>It is also possible to use these tools with SSH to perform data
        migration without any disk I/O using the archive feature of these
        tools. This simplifies three stages into one operation, when
        previously you had to back up to disk, then copy those backup files to
        a target server, and then run <em class="filename">mongorestore</em> on that server to restore the
        backups:</p><pre data-type="programlisting">$ ssh eoin@proxy.server.com mongodump --host source.server.com\ --archive 
        | ssh eoin@target.server.com mongorestore --archive</pre><p>Compression can be combined with the archive feature of these
        tools to further reduce the size of the information sent while
        performing a data migration. Here is the same SSH data migration
        example using both the archive and compression features of these
        tools:</p><pre data-type="programlisting">$ ssh eoin@proxy.server.com mongodump --host source.server.com\ --archive 
        --gzip | ssh eoin@target.server.com mongorestore --archive --gzip</pre></div></section><section data-type="sect3" data-pdf-bookmark="Administrative complications with unique indexes"><div class="sect3" id="idm45882333638216"><h3>Administrative complications with unique indexes</h3><p>If<a data-type="indexterm" data-primary="indexes" data-secondary="unique" id="idm45882333637240"/> you have a unique index (other than <code>"_id"</code>) on any of your collections, you
        should consider using a different type of backup than <em class="filename">mongodump</em>/<em class="filename">mongorestore</em>. Unique indexes require that
        the data does not change in ways that would violate the unique index
        constraint during the copy. The safest way to ensure this is to choose
        a method that “freezes” the data, then make a backup as described in
        either of the previous two sections.</p><p>If you are determined to use <em class="filename">mongodump</em>/<em class="filename">mongorestore</em>, you may need to preprocess
        your data when you restore from a<a data-type="indexterm" data-startref="mongodump23" id="idm45882333615240"/><a data-type="indexterm" data-startref="Sback23" id="idm45882333614408"/> backup.</p></div></section></div></section></div></section><section data-type="sect1" data-pdf-bookmark="Specific Considerations for Replica Sets"><div class="sect1" id="sect1-rs-backup"><h1>Specific Considerations for Replica Sets</h1><p>The<a data-type="indexterm" data-primary="replica sets, components of" data-secondary="backups" id="idm45882333612392"/><a data-type="indexterm" data-primary="backups" data-secondary="replica sets" id="idm45882333611192"/> main additional consideration when backing up a replica set
    is that as well as the data, you must also capture the state of the
    replica set to ensure an accurate point-in-time snapshot of your
    deployment is made.</p><p>Generally, you should make backups from a secondary: this keeps load
    off of the primary, and you can lock a secondary without affecting your
    application (so long as your application isn’t sending it read requests).
    You can use any of the three methods outlined previously to back up a
    replica set member, but a filesystem snapshot or data file copy is
    recommended. Either of these techniques can be applied to replica set
    secondaries with no modification.</p><p><em class="filename">mongodump</em> is not quite as
    simple to use when replication is enabled. First, if you are using
    <em class="filename">mongodump</em>, you must take your backups
    using the <code class="option">--oplog</code> option to get a point-in-time snapshot;
    otherwise the backup’s state won’t match the state of any other members in
    the cluster. You must also create an oplog when you restore from a
    <em class="filename">mongodump</em> backup, or the restored
    member will not know where it was synced to.</p><p>To restore a replica set member from a <em class="filename">mongodump</em> backup, start the target replica set
    member as a standalone server with an empty data directory and run
    <em class="filename">mongorestore</em> on it (as described in
    the previous section) with the <code class="option">--oplogReplay</code> option. Now
    it should have a complete copy of the data, but it still needs an oplog.
    Create an oplog using the <code class="function">createCollection</code> command:</p><pre data-type="programlisting" data-code-language="javascript"><code class="o">&gt;</code> <code class="nx">use</code> <code class="nx">local</code>
<code class="o">&gt;</code> <code class="nx">db</code><code class="p">.</code><code class="nx">createCollection</code><code class="p">(</code><code class="s2">"oplog.rs"</code><code class="p">,</code> <code class="p">{</code><code class="s2">"capped"</code> <code class="o">:</code> <code class="kc">true</code><code class="p">,</code> <code class="s2">"size"</code> <code class="o">:</code> <code class="mi">10000000</code><code class="p">})</code></pre><p>Specify the size of the collection in bytes. See <a data-type="xref" href="ch13.xhtml#sect1-resize-oplog">“Resizing the Oplog”</a> for advice on oplog sizing.</p><p>Now you need to populate the oplog. The easiest way to do this is to
    restore the <em class="filename">oplog.bson</em> backup file
    from the dump into the <em class="filename">local.oplog.rs</em>
    collection:</p><pre data-type="programlisting">$ mongorestore -d local -c oplog.rs dump/oplog.bson</pre><p>Note that this is not a dump of the oplog itself (<em class="filename">dump/local/oplog.rs.bson</em>), but rather of the
    oplog operations that occurred during the dump. Once this <em class="filename">mongorestore</em> is complete, you can restart this
    server as a replica set member.</p></div></section><section data-type="sect1" data-pdf-bookmark="Specific Considerations for Sharded Clusters"><div class="sect1" id="idm45882333759528"><h1>Specific Considerations for Sharded Clusters</h1><p>The<a data-type="indexterm" data-primary="sharding, configuration of" data-secondary="backups" id="idm45882333574728"/><a data-type="indexterm" data-primary="clusters" data-secondary="backup options" id="idm45882333573624"/> main additional consideration when backing up a sharded
    cluster using the approaches in this chapter is that you can only back up
    the pieces when they are active, and sharded clusters are impossible to
    “perfectly” back up while active: you can’t get a snapshot of the entire
    state of the cluster at a point in time. However, this limitation is
    generally sidestepped by the fact that as your cluster gets bigger, it
    becomes less and less likely that you’d ever have to restore the whole
    thing from a backup. Thus, when dealing with a sharded cluster, we focus
    on backing up pieces: the config servers and the replica sets
    individually. If you need the ability to back up the whole cluster to a
    particular point in time or would prefer an automated solution, you can
    avail yourself of MongoDB’s Cloud Manager or Atlas backup feature.</p><p>Turn off the balancer before performing any of these operations on a
    sharded cluster (either backup or restore). You cannot get a consistent
    snapshot of the world with chunks flying around. See <a data-type="xref" href="ch17.xhtml#sect1-balancer">“Balancing Data”</a> for instructions on turning the balancer on
    and off.</p><section data-type="sect2" data-pdf-bookmark="Backing Up and Restoring an Entire Cluster"><div class="sect2" id="idm45882333570056"><h2>Backing Up and Restoring an Entire Cluster</h2><p>When a cluster is very small or in development, you may want to
      actually dump and restore the entire thing. You can accomplish this by
      turning off the balancer and then running <em class="filename">mongodump</em> through the <em class="filename">mongos</em>. This creates a backup of all of the
      shards on whatever machine <em class="filename">mongodump</em> is running on.</p><p>To restore from this type of backup, run <em class="filename">mongorestore</em> connected to a <em class="filename">mongos</em>.</p><p>Alternatively, after turning off the balancer you can take
      filesystem or data directory backups of each shard and the config
      servers. However, you will inevitably get copies from each at slightly
      different times, which may or may not be a problem. Also, as soon as you
      turn on the balancer and a migrate occurs, some of the data you backed
      up from one shard will no longer be there.</p></div></section><section data-type="sect2" data-pdf-bookmark="Backing Up and Restoring a Single Shard"><div class="sect2" id="idm45882333564264"><h2>Backing Up and Restoring a Single Shard</h2><p>Most often, you’ll only need to restore a single shard in a
      cluster. If you are not too picky, you can restore from a backup of that
      shard using one of the single-server methods just described.</p><p>There is one important issue to be aware of, however. Suppose you
      make a backup of your cluster on Monday. On Thursday, your disk melts
      down and you have to restore from the backup. In the intervening days,
      new chunks may have moved to this shard. Your backup of the shard from
      Monday will not contain these new chunks. You may be able to use a
      config server backup to figure out where the disappearing chunks lived
      on Monday, but it is a lot more difficult than simply restoring the
      shard. In most cases, restoring the shard and losing the data in those
      chunks is the preferable route.</p><p>You can connect directly to a shard to restore from a
      backup<a data-type="indexterm" data-startref="SAbackup23" id="idm45882333561960"/><a data-type="indexterm" data-startref="ASback23" id="idm45882333561128"/> (instead of going through <em class="filename">mongos</em>).</p></div></section></div></section></div></section></div>



  </body></html>