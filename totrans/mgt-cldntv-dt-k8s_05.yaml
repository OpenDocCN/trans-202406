- en: Chapter 4\. Automating Database Deployment on Kubernetes with Helm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how to deploy both single-node and multinode
    databases on Kubernetes by hand, creating one element at a time. We did things
    the “hard way” on purpose to help maximize your understanding of using Kubernetes
    primitives to set up the compute, network, and storage resources that a database
    requires. Of course, this doesn’t represent the experience of running databases
    in production on Kubernetes, for a couple of reasons.
  prefs: []
  type: TYPE_NORMAL
- en: First, teams typically don’t deploy databases by hand, one YAML file at a time.
    That can get pretty tedious. And even combining the configurations into a single
    file could start to get pretty complicated, especially for more sophisticated
    deployments. Consider the increase in the amount of configuration required in
    [Chapter 3](ch03.html#databases_on_kubernetes_the_hard_way) for Cassandra as a
    multinode database compared with the single-node MySQL deployment. This won’t
    scale for large enterprises.
  prefs: []
  type: TYPE_NORMAL
- en: Second, while deploying a database is great, what about keeping it running over
    time? You need your data infrastructure to remain reliable and performant over
    the long haul, and data infrastructure is known for requiring a lot of care and
    feeding. Put another way, the task of running a system is often divided into “day
    one” (the joyous day when you deploy an application to production) and “day two”
    (every day after the first, when you need to operate and evolve your application
    while maintaining high availability).
  prefs: []
  type: TYPE_NORMAL
- en: These considerations around database deployment and operations mirror the larger
    industry trends toward DevOps, an approach in which development teams take a more
    active role in supporting applications in production. DevOps practices include
    the use of automation tools for CI/CD of applications, shortening the amount of
    time it takes for code to get from a developer’s desktop into production.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll look at tools that help standardize the deployment of
    databases and other applications. These tools take an infrastructure as code (IaC)
    approach, allowing you to represent software installation and configuration options
    in a format that can be executed automatically, reducing the overall amount of
    configuration code you have to write. We’ll also emphasize data infrastructure
    operations in these next two chapters and carry that theme throughout the remainder
    of the book.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Applications with Helm Charts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s start by taking a look at a tool that helps you manage the complexity
    of managing configurations: [Helm](https://helm.sh). This package manager for
    Kubernetes is open source and a CNCF [graduated project](https://oreil.ly/cDjD3).
    The concept of a package manager is a common one across multiple programming languages,
    such as `pip` for Python, the Node Package Manager (NPM) for JavaScript, and Ruby’s
    Gems feature. Package managers for specific operating systems also exist, such
    as Apt for Linux, or Homebrew for macOS. As shown in [Figure 4-1](#helmcomma_a_package_manager_for_kuberne),
    the essential elements of a package manager system are the packages, the registries
    where the packages are stored, and the package manager application (or *client*),
    which helps the chart developers register charts and allows chart users to locate,
    install, and update packages on their local systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Helm, a package manager for Kubernetes](assets/mcdk_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. Helm, a package manager for Kubernetes
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Helm extends the package management concept to Kubernetes, with some interesting
    differences. If you’ve worked with one of the package managers listed previously,
    you’ll be familiar with the idea that a package consists of a binary (executable
    code) as well as metadata describing the binary, such as its functionality, API,
    and installation instructions. In Helm, the packages are called *charts*. Charts
    describe how to build a Kubernetes application piece by piece by using the Kubernetes
    resources for compute, networking, and storage introduced in previous chapters,
    such as Pods, Services, and PersistentVolumeClaims. For compute workloads, the
    descriptions point to container images that reside in public or private container
    registries.
  prefs: []
  type: TYPE_NORMAL
- en: Helm allows charts to reference other charts as dependencies, which provides
    a great way to compose applications by creating assemblies of charts. For example,
    you could define an application such as the WordPress/MySQL example from the previous
    chapter by defining a chart for your WordPress deployment that referenced a chart
    defining a MySQL deployment that you wish to reuse. Or, you might even find a
    Helm chart that defines an entire WordPress application including the database.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Environment Prerequisites
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The examples in this chapter assume you have access to a Kubernetes cluster
    with a couple of characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: The cluster should have at least three Worker Nodes, in order to demonstrate
    mechanisms Kubernetes provides to allow you to request Pods to be spread across
    a cluster. You can create a simple cluster on your desktop by using an open source
    distribution called kind. See the kind quick start guide for instructions on installing
    kind and [creating a multinode cluster](https://oreil.ly/8nOHi). The code for
    this example also contains a configuration file you may find useful to create
    a simple three-node kind cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will also need a StorageClass that supports dynamic provisioning. You may
    wish to follow the instructions in [“StorageClasses”](ch02.html#storageclasses)
    for installing a simple StorageClass and provisioner that expose local storage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Helm to Deploy MySQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To make things a bit more concrete, let’s use Helm to deploy the databases
    you worked with in [Chapter 3](ch03.html#databases_on_kubernetes_the_hard_way).
    First, if it’s not already on your system, you’ll need to install Helm by using
    the [documentation](https://oreil.ly/tUPWL) on the Helm website. Next, add the
    Bitnami Helm repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The Bitnami Helm repository contains a variety of Helm charts to help you deploy
    infrastructure such as databases, analytics engines, and log management systems,
    as well as applications including ecommerce, customer relationship management
    (CRM), and you guessed it: WordPress. You can find the source code for the charts
    in the Bitnami Charts repository on [GitHub](https://oreil.ly/lmcml). The *README*
    for this repo provides helpful instructions for using the charts in various Kubernetes
    distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s use the Helm chart provided in the `bitnami` repository to deploy
    MySQL. In Helm’s terminology, each deployment is known as a *release*. The simplest
    possible release that you could create using this chart would look something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you execute this command, it will create a release called `mysql` using
    the Bitnami MySQL Helm chart with its default settings. As a result, you’d have
    a single MySQL node. Since you’ve already deployed a single node of MySQL manually
    in [Chapter 3](ch03.html#databases_on_kubernetes_the_hard_way), let’s do something
    a bit more interesting this time and create a MySQL cluster. To do this, you’ll
    create a *values.yaml* file with contents like the following, or you can reuse
    the [sample](https://oreil.ly/tsnuT) provided in the source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The settings in this *values.yaml* file let Helm know that you want to use options
    in the Bitnami MySQL Helm chart to deploy MySQL in a replicated architecture in
    which there is a primary node and two secondary nodes.
  prefs: []
  type: TYPE_NORMAL
- en: MySQL Helm Chart Configuration Options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you examine the default [*values.yaml* file](https://oreil.ly/SGsN5) provided
    with the Bitnami MySQL Helm chart, you’ll see quite a few options available beyond
    the simple selections shown here. The configurable values include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Images to pull and their locations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes StorageClass that will be used to generate PersistentVolumes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security credentials for user and administrator accounts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQL configuration settings for primary and secondary replicas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of secondary replicas to create
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Details of liveness, readiness probes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Affinity and anti-affinity settings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing high availability of the database using Pod disruption budgets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many of these concepts you’ll be familiar with already, and others like affinity
    and Pod disruption budgets are covered later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’ve created the *values.yaml* file, you can start the cluster using
    this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the command, you’ll see the status of the install from Helm,
    plus instructions that are provided with the chart under `NOTES`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We’ve omitted the notes here since they are a bit lengthy. They describe suggested
    commands for monitoring the status as MySQL initializes, how clients and administrators
    can connect to the database, how to upgrade the database, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Use Namespaces to Help Isolate Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we did not specify a Namespace, the Helm release has been installed in
    the default Kubernetes Namespace unless you’ve separately configured a Namespace
    in your [kubeconfig](https://oreil.ly/C2vOM). If you want to install a Helm release
    in its own Namespace in order to work with its resources more effectively, you
    could run something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This creates a Namespace called `mysql` and installs the `mysql` release inside
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'To obtain information about the Helm releases you’ve created, use the `helm
    list` command, which produces output such as this (formatted for readability):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If you haven’t installed the release in its own Namespace, it’s still simple
    to see the compute resources that Helm has created on your behalf by running `kubectl
    get all`, because they have all been labeled with the name of your release. It
    may take several minutes for all the resources to initialize, but when complete,
    it will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, Helm has created two StatefulSets, one for primary replicas
    and one for secondary replicas. The `mysql-primary` StatefulSet is managing a
    single MySQL Pod containing a primary replica, while the `mysql-secondary` StatefulSet
    is managing two MySQL Pods containing secondary replicas. See if you can determine
    which Kubernetes Worker Node each MySQL replica is running on by using the `kubectl
    describe pod` command.
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding output, you’ll also notice two Services created for each
    StatefulSet, one a headless service and another that has a dedicated IP address.
    Since `kubectl get all` tells you about only compute resources and services, you
    might also be wondering about the storage resources. To check on these, run the
    `kubectl get pv` command. Assuming you have a StorageClass installed that supports
    dynamic provisioning, you should see PersistentVolumes that are bound to PersistentVolumeClaims
    named `data-mysql-primary-0`, `data-mysql-secondary-0`, and `data-mysql-secondary-1`.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the resources we’ve discussed, installing the chart has also
    resulted in the creation of a few additional resources that we’ll explore next.
  prefs: []
  type: TYPE_NORMAL
- en: Namespaces and Kubernetes Resource Scope
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have chosen to install your Helm release in a Namespace, you’ll need
    to specify the Namespace on most of your `kubectl get` commands in order to see
    the created resources. The exception is `kubectl get pv`, because PersistentVolumes
    are one of the Kubernetes resources that are not Namespaced; that is, they can
    be used by Pods in any Namespace. To learn more about which Kubernetes resources
    in your cluster are Namespaced and which are not, run the command `kubectl api-resources`.
  prefs: []
  type: TYPE_NORMAL
- en: How Helm Works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Did you wonder what happened when you executed the `helm install` command with
    a provided values file? To understand what’s going on, let’s take a look at the
    contents of a Helm chart, as shown in [Figure 4-2](#customizing_a_helm_release_using_a_valu).
    As we discuss these contents, it will also be helpful to look at the [source code](https://oreil.ly/xQbvb)
    of the MySQL Helm chart you just installed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Customizing a Helm release using a values.yaml file](assets/mcdk_0402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. Customizing a Helm release using a values.yaml file
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Looking at the contents of a Helm chart, you’ll notice the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[README file](https://oreil.ly/i7XBa)'
  prefs: []
  type: TYPE_NORMAL
- en: This explains how to use the chart. These instructions are provided along with
    the chart in registries.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chart.yaml file](https://oreil.ly/zZb2Y)'
  prefs: []
  type: TYPE_NORMAL
- en: This contains metadata about the chart such as its name, publisher, version,
    keywords, and any dependencies on other charts. These properties are useful when
    searching Helm registries to find charts.
  prefs: []
  type: TYPE_NORMAL
- en: '[values.yaml file](https://oreil.ly/mhfhZ)'
  prefs: []
  type: TYPE_NORMAL
- en: This lists out the configurable values supported by the chart and their default
    values. These files typically contain a good number of comments that explain the
    available options. For the Bitnami MySQL Helm chart, a lot of options are available,
    as we’ve noted.
  prefs: []
  type: TYPE_NORMAL
- en: '[templates directory](https://oreil.ly/F21Lg)'
  prefs: []
  type: TYPE_NORMAL
- en: This contains [Go templates](https://oreil.ly/diTnu) that define the chart.
    The templates include a [*Notes.txt*](https://oreil.ly/v0aky) file used to generate
    the output you saw previously after executing the `helm install` command, and
    one or more YAML files that describe a pattern for a Kubernetes resource. These
    YAML files may be organized in subdirectories (for example, the [template](https://oreil.ly/iKedl)
    that defines a StatefulSet for MySQL primary replicas). Finally, a *_helpers.tpl*
    file describes how to use the templates. Some of the templates may be used multiple
    times or not at all, depending on the selected configuration values.
  prefs: []
  type: TYPE_NORMAL
- en: When you execute the `helm install` command, the Helm client makes sure it has
    an up-to-date copy of the chart you’ve named by checking with the source repository.
    Then it uses the template to generate YAML configuration code, overriding default
    values from the chart’s *values.yaml* file with any values you’ve provided. It
    then uses the `kubectl` command to apply this configuration to your currently
    configured Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’d like to see the configuration that a Helm chart will produce before
    applying it, you can use the handy `template` command. It supports the same syntax
    as the `install` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Running this command will produce quite a bit of output, so you may want to
    redirect it to a file (append `> values-template.yaml` to the command) so you
    can take a longer look. Alternatively, you can look at the [copy](https://oreil.ly/DhEtc)
    we have saved in the source code repository.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll notice that several types of resources are created, as summarized in
    [Figure 4-3](#deploying_mysql_using_the_bitnami_helm). Many of the resources shown
    have been discussed, including the StatefulSets for managing the primary and secondary
    replicas, each with its own service (the chart also creates headless services
    that are not shown in the figure). Each Pod has its own PersistentVolumeClaim
    that is mapped to a unique PersistentVolume.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-3](#deploying_mysql_using_the_bitnami_helm) also includes resource
    types we haven’t discussed previously. Notice first that each StatefulSet has
    an associated ConfigMap that is used to provide a common set of configuration
    settings to its Pods. Next, notice the Secret named `mysql`, which stores passwords
    needed for accessing various interfaces exposed by the database nodes. Finally,
    a ServiceAccount resource is applied to every Pod created by this Helm release.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s focus on some interesting aspects of this deployment, including the usage
    of labels, ServiceAccounts, Secrets, and ConfigMaps.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying MySQL using the Bitnami Helm chart](assets/mcdk_0403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. Deploying MySQL using the Bitnami Helm chart
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Labels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you look through the output from the `helm template`, you’ll notice that
    the resources have a common set of labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: These labels help identify the resources as being part of the `mysql` application
    and indicate that they are managed by Helm using a specific chart version. The
    labels are useful for selecting resources, which is often useful in defining configurations
    for other resources.
  prefs: []
  type: TYPE_NORMAL
- en: ServiceAccounts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes clusters make a distinction between human users and applications
    for access control purposes. A ServiceAccount is a Kubernetes resource that represents
    an application and what it is allowed to access. For example, a ServiceAccount
    may be given access to some portions of the Kubernetes API, or access to one or
    more secrets containing privileged information such as login credentials. This
    latter capability is used in your Helm installation of MySQL to share credentials
    between Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every Pod created in Kubernetes has a ServiceAccount assigned to it. If you
    do not specify one, the default ServiceAccount is used. Installing the MySQL Helm
    chart creates a ServiceAccount called `mysql`. You can see the specification for
    this resource in the generated template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this ServiceAccount has access to a Secret called `mysql`, which
    we’ll discuss shortly. A ServiceAccount can also have an additional type of Secret
    known as an `imagePullSecret`. These Secrets are used when an application needs
    to use images from a private registry.
  prefs: []
  type: TYPE_NORMAL
- en: By default, a ServiceAccount does not have any access to the Kubernetes API.
    To give this ServiceAccount the access it needs, the MySQL Helm chart creates
    a Role specifying the Kubernetes resources and operations, and a RoleBinding to
    associate the ServiceAccount to the Role. We’ll discuss ServiceAccounts and role-based
    access in [Chapter 5](ch05.html#automating_database_management_on_kuber).
  prefs: []
  type: TYPE_NORMAL
- en: Secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you learned in [Chapter 2](ch02.html#managing_data_storage_on_kubernetes),
    a Secret provides secure access to information you need to keep private. Your
    `mysql` Helm release contains a Secret called `mysql` containing login credentials
    for the MySQL instances themselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The three passwords represent different types of access: the `mysql-root-password`
    provides administrative access to the MySQL node, while the `mysql-replication-password`
    is used for nodes to communicate for the purposes of data replication between
    nodes. The `mysql-password` is used by client applications to access the database
    to write and read data.'
  prefs: []
  type: TYPE_NORMAL
- en: ConfigMaps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Bitnami MySQL Helm chart creates Kubernetes ConfigMap resources to represent
    the configuration settings used for Pods that run the MySQL primary and secondary
    replica nodes. ConfigMaps store configuration data as key-value pairs. For example,
    the ConfigMap created by the Helm chart for the primary replicas looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the key is the name `my.cnf`, which represents a filename, and
    the value is a multiline set of configuration settings that represent the contents
    of a configuration file (which we’ve abbreviated here). Next, look at the definition
    of the StatefulSet for the primary replicas. Notice that the contents of the ConfigMap
    are mounted as a read-only file inside each template, according to the Pod specification
    for the StatefulSet (again, we’ve omitted some detail to focus on key areas):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Mounting the ConfigMap as a volume in a container results in the creation of
    a read-only file in the mount directory that is named according to the key and
    has the value as its content. For our example, mounting the ConfigMap in the Pod’s
    `mysql` container results in the creation of the file */opt/bitnami/mysql/conf/my.cnf*.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is one of several ways that ConfigMaps can be used in Kubernetes applications:'
  prefs: []
  type: TYPE_NORMAL
- en: As described in the [Kubernetes documentation](https://oreil.ly/yoEYv), you
    could choose to store configuration data in more granular key-value pairs, which
    also makes it easier to access individual values in your application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also reference individual key-value pairs as environment variables you
    pass to a container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, applications can access ConfigMap contents via the Kubernetes API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More Configuration Options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have a Helm release with a working MySQL cluster, you can point
    an application to it, such as WordPress. Why not try seeing if you can adapt the
    WordPress deployment from [Chapter 3](ch03.html#databases_on_kubernetes_the_hard_way)
    to point to the MySQL cluster you’ve created here?
  prefs: []
  type: TYPE_NORMAL
- en: For further learning, you could also compare your resulting configuration with
    that produced by the Bitnami WordPress Helm chart, which uses MariaDB instead
    of MySQL but is otherwise quite similar.
  prefs: []
  type: TYPE_NORMAL
- en: Updating Helm Charts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you’re running a Helm release in a production environment, chances are you’re
    going to need to maintain it over time. You might want to update a Helm release
    for various reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: A new version of a chart is available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A new version of an image used by your application is available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to change the selected options.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To check for a new version of a chart, execute the `helm repo update` command.
    Running this command with no options looks for updates in all of the chart repositories
    you have configured for your Helm client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you’ll want to make any desired updates to your configured values. If
    you’re upgrading to a new version of a chart, make sure to check the release notes
    and documentation of the configurable values. It’s a good idea to test out an
    upgrade before applying it. The `--dry-run` option allows you to do this, producing
    similar values to the `helm template` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Using an Overlay Configuration File
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One useful option you could use for the upgrade is to specify values you wish
    to override in a new configuration file, and apply both the new and old, something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Configuration files are applied in the order they appear on the command line,
    so if you use this approach, make sure your overridden values file appears after
    your original values file.
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve applied the upgrade, Helm sets about its work, updating only those
    resources in the release that are affected by your configuration changes. If you’ve
    specified changes to the Pod template for a StatefulSet, the Pods will be restarted
    according to the update policy specified for the StatefulSet, as we discussed
    in [“StatefulSet lifecycle management”](ch03.html#statefulset_life_cycle_management).
  prefs: []
  type: TYPE_NORMAL
- en: Uninstalling Helm Charts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you are finished using your Helm release, you can uninstall it by name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that Helm does not remove any of the PersistentVolumeClaims or PersistentVolumes
    that were created for this Helm chart, following the behavior of StatefulSets
    discussed in [Chapter 3](ch03.html#databases_on_kubernetes_the_hard_way).
  prefs: []
  type: TYPE_NORMAL
- en: Using Helm to Deploy Apache Cassandra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now let’s switch gears and look at deploying Apache Cassandra by using Helm.
    In this section, you’ll use another chart provided by Bitnami, so there’s no need
    to add another repository. You can find the implementation of this chart on [GitHub](https://oreil.ly/WzvXp).
    Helm provides a quick way to see the metadata about this chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'After reviewing the metadata, you’ll also want to learn about the configurable
    values. You can examine the [*values.yaml* file](https://oreil.ly/z69Z7) in the
    GitHub repo, or use another option on the `show` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The list of options for this chart is shorter than the list for the MySQL chart,
    because Cassandra doesn’t have the concept of primary and secondary replicas.
    However, you’ll certainly see similar options for images, StorageClasses, security,
    liveness and readiness probes, and so on. Some configuration options are unique
    to Cassandra, such as those having to do with JVM settings and seed nodes (as
    discussed in [Chapter 3](ch03.html#databases_on_kubernetes_the_hard_way)).
  prefs: []
  type: TYPE_NORMAL
- en: One interesting feature of this chart is the ability to export metrics from
    Cassandra nodes. If you set `metrics.enabled=true`, the chart will inject a sidecar
    container into each Cassandra Pod that exposes a port that can be scraped by Prometheus.
    Other values under `metrics` configure what metrics are exported, the collection
    frequency, and more. While we won’t use this feature here, metrics reporting is
    a key part of managing data infrastructure we’ll cover in [Chapter 6](ch06.html#integrating_data_infrastructure_in_a_ku).
  prefs: []
  type: TYPE_NORMAL
- en: 'For a simple three-node Cassandra configuration, you could set the replica
    count to 3 and set other configuration values to their defaults. However, since
    you’re overriding only a single configuration value, this is a good time to take
    advantage of Helm’s support for setting values on the command line, instead of
    providing a *values.yaml* file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As discussed previously, you can use the `helm template` command to check the
    configuration before installing it, or look at the file we’ve saved on GitHub.
    However, since you’ve already created the release, you can also use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Looking through the resources in the YAML, you’ll see that a similar set of
    infrastructure has been established, as shown in [Figure 4-4](#deploying_apache_cassandra_using_the_bi).
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A ServiceAccount referencing a Secret, which contains the password for the `cassandra`
    administrator account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A single StatefulSet, with a headless Service used to reference its Pods. The
    Pods are spread evenly across the available Kubernetes Worker Nodes, which we’ll
    discuss in the next section. The Service exposes Cassandra ports used for intra-node
    communication (`7000`, with `7001` used for secure communication via TLS), administration
    via JMX (`7199`), and client access via CQL (`9042`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Deploying Apache Cassandra using the Bitnami Helm chart](assets/mcdk_0404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-4\. Deploying Apache Cassandra using the Bitnami Helm chart
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This configuration represents a simple Cassandra topology, with all three nodes
    in a single Datacenter and rack. This simple topology reflects one of the limitations
    of this chart—it does not provide the ability to create a Cassandra cluster consisting
    of multiple Datacenters and racks. To create a more complex deployment, you’d
    have to install multiple Helm releases, using the same `clusterName` (in this
    case, you’re using the default name `cassandra`), but a different Datacenter and
    rack per deployment. You’d also need to obtain the IP address of a couple of nodes
    in the first Datacenter to use as `additionalSeeds` when configuring the releases
    for the other racks.
  prefs: []
  type: TYPE_NORMAL
- en: Affinity and Anti-Affinity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As shown in [Figure 4-4](#deploying_apache_cassandra_using_the_bi), the Cassandra
    nodes are spread evenly across the Worker Nodes in your cluster. To verify this
    in your own Cassandra release, you could run something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, each Cassandra node is running on a different Worker Node. If
    your Kubernetes cluster has at least three Worker Nodes and no other workloads,
    you’ll likely observe similar behavior. While it is true that this even allocation
    could happen naturally in a cluster that has an even load across Worker Nodes,
    this is probably not the case in your production environment. However, to promote
    maximum availability of your data, we want to try to honor the intent of Cassandra’s
    architecture to run nodes on different machines in order to promote high availability.
  prefs: []
  type: TYPE_NORMAL
- en: 'To help guarantee this isolation, the Bitnami Helm chart uses Kubernetes’s
    affinity capabilities, specifically anti-affinity. If you examine the generated
    configuration for the Cassandra StatefulSet, you’ll see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: As shown here, the Pod template specification lists three possible types of
    affinity, with only the `podAntiAffinity` being defined. What do these concepts
    mean?
  prefs: []
  type: TYPE_NORMAL
- en: Pod affinity
  prefs: []
  type: TYPE_NORMAL
- en: The preference that a Pod is scheduled onto a node where another specific Pod
    is running. For example, Pod affinity could be used to colocate a web server with
    its cache.
  prefs: []
  type: TYPE_NORMAL
- en: Pod anti-affinity
  prefs: []
  type: TYPE_NORMAL
- en: The opposite of Pod affinity—that is, a preference that a Pod not be scheduled
    on a node where another identified Pod is running. This is the constraint used
    in this example, as we’ll discuss shortly.
  prefs: []
  type: TYPE_NORMAL
- en: Node affinity
  prefs: []
  type: TYPE_NORMAL
- en: A preference that a Pod be run on a node with specific characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Each type of affinity can be expressed as either hard or soft constraints. These
    are known as `requiredDuringSchedulingIgnoredDuringExecution` and `preferredDuringSchedulingIgnoredDuringExecution`.
    The first constraint specifies rules that must be met before a Pod is scheduled
    on a node, while the second specifies a preference that the scheduler will attempt
    to meet but may relax if necessary in order to schedule the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: '`IgnoredDuringExcecution` implies that the constraints apply only when the
    Pods are first scheduled. In the future, new `RequiredDuringExecution` options
    will be added called `requiredDuringSchedulingRequiredDuringExecution` and `requiredDuringSchedulingRequiredDuringExecution`.
    These will ask Kubernetes to evict Pods (that is, move them to another node) that
    no longer meet the criteria—for example, by a change in their labels.'
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the preceding example, the Pod template specification for the Cassandra
    StatefulSet specifies an anti-affinity rule using the labels that are applied
    to each Cassandra Pod. The net effect is that Kubernetes will try to spread the
    Pods across the available Worker Nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Those are the highlights of looking at the Bitnami Helm chart for Cassandra.
    To clean things up, uninstall the Cassandra release:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'If you don’t want to work with Bitnami Helm charts any longer, you can also
    remove the repository from your Helm client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: More Kubernetes Scheduling Constraints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes supports additional mechanisms for providing hints to its scheduler
    about Pod placement. One of the simplest is [NodeSelectors](https://oreil.ly/05hSU),
    which is very similar to node affinity, but with a less expressive syntax that
    can match on one or more labels by using AND logic. Since you may or may not have
    the required privileges to attach labels to Worker Nodes in your cluster, Pod
    affinity is often a better option. [Taints and tolerations](https://oreil.ly/fbkTB)
    are another mechanism that can be used to configure Worker Nodes to repel specific
    Pods from being scheduled on those nodes.
  prefs: []
  type: TYPE_NORMAL
- en: In general, you want to be careful to understand all of the constraints you’re
    putting on the Kubernetes scheduler from various workloads so as not to overly
    constrain its ability to place Pods. See the Kubernetes documentation for more
    information on [scheduling constraints](https://oreil.ly/aUWsi). We’ll also look
    at how Kubernetes allows you to plug in different schedulers in [“Alternative
    Schedulers for Kubernetes”](ch09.html#alternative_schedulers_for_kubernetes).
  prefs: []
  type: TYPE_NORMAL
- en: Helm, CI/CD, and Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Helm is a powerful tool focused on one primary task: deploying complex applications
    to Kubernetes clusters. To get the most benefit from Helm, you’ll want to consider
    how it fits into your larger CI/CD toolset:'
  prefs: []
  type: TYPE_NORMAL
- en: Automation servers such as [Jenkins](https://www.jenkins.io) automatically build,
    test, and deploy software according to scripts known as *jobs*. These jobs are
    typically run based on predefined triggers, such as a commit to a source repository.
    Helm charts can be referenced in jobs to install an application under test and
    its supporting infrastructure in a Kubernetes cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IaC automation tools such as [Terraform](https://www.terraform.io) allow you
    to define templates and scripts that describe how to create infrastructure in
    a variety of cloud environments. For example, you could write a Terraform script
    that automates the creation of a new VPC within a specific cloud provider and
    the creation of a new Kubernetes cluster within that VPC. The script could then
    use Helm to install applications within the Kubernetes cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While overlaps certainly occur in the capabilities these tools provide, you’ll
    want to consider the strengths and limitations of each as you construct your toolset.
    For this reason, we want to make sure to note that Helm has limitations when it
    comes to managing the operations of applications that it deploys. To get a good
    picture of the challenges involved, we spoke to a practitioner who has built assemblies
    of Helm charts to manage a complex database deployment. This discussion begins
    to introduce concepts like Kubernetes Custom Resource Definitions (CRDs) and the
    operator pattern, both of which we’ll cover in depth in [Chapter 5](ch05.html#automating_database_management_on_kuber).
  prefs: []
  type: TYPE_NORMAL
- en: As John Sanda notes in his commentary, Helm is a powerful tool for scripting
    the deployment of applications consisting of multiple Kubernetes resources, but
    can be less effective at managing more complex operational tasks. As you’ll see
    in the chapters to come, a common pattern used for data infrastructure and other
    complex applications is to use a Helm chart to deploy an operator, which can then
    in turn manage both the deployment and lifecycle of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you’ve learned how a package management tool like Helm can
    help you manage the deployment of applications on Kubernetes, including your database
    infrastructure. Along the way, you’ve also learned how to use some additional
    Kubernetes resources like ServiceAccounts, Secrets, and ConfigMaps. Now it’s time
    to round out our discussion of running databases on Kubernetes. In the next chapter,
    we’ll take a deeper dive into managing database operations on Kubernetes by using
    the operator pattern.
  prefs: []
  type: TYPE_NORMAL
