<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 2. Creating and Running Containers" data-type="chapter" epub:type="chapter"><div class="chapter" id="Containers">
<h1><span class="label">Chapter 2. </span>Creating and Running Containers</h1>
<p>Kubernetes is a platform for creating, deploying, and managing distributed
applications. These applications come in many different shapes and sizes, but
ultimately, they are all comprised of one or more programs that run on
individual machines. These programs accept input, manipulate data, and then
return the results. Before we can even consider building a distributed system,
we must first consider how to build the <em>application container images</em> that
contain these programs and make up the pieces of our distributed system.<a data-primary="application container images" data-type="indexterm" id="idm45664093441072"/></p>
<p>Application programs are typically comprised of a language runtime, libraries,
and your source code. In many cases, your application relies on external shared
libraries such as <code>libc</code> and <code>libssl</code>. These external libraries are generally
shipped as shared components in the OS that you have installed on a particular
machine.<a data-primary="libraries, external and shared" data-type="indexterm" id="idm45664093439056"/></p>
<p>This dependency on shared libraries causes problems when an application
developed on a programmer’s laptop has a dependency on a shared library that
isn’t available when the program is rolled out to the production OS. Even when
the development and production environments share the exact same version of the
OS, problems can occur when developers forget to include dependent asset files
inside a package that they deploy to production.</p>
<p>The traditional methods of running multiple programs on a single machine require
that all of these programs share the same versions of shared libraries on the
system. If the different programs are developed by different teams or
organizations, these shared dependencies add needless complexity and coupling
between these teams.</p>
<p>A program can only execute successfully if it can be reliably deployed onto the
machine where it should run. Too often the state of the art for deployment
involves running imperative scripts, which inevitably have twisty and byzantine
failure cases. This makes the task of rolling out a new version of all or parts
of a distributed system a labor-intensive and difficult task.</p>
<p>In <a data-type="xref" href="ch01.xhtml#introduction">Chapter 1</a>, we argued strongly for the value of immutable images and
infrastructure. This immutability is exactly what the container image provides.
As we will see, it easily solves all the problems of dependency management and
encapsulation just described.<a data-primary="immutability" data-secondary="immutable images and infrastructure" data-type="indexterm" id="idm45664093435584"/></p>
<p>When working with applications, it’s often helpful to package them in a way that
makes sharing them with others easy. <a data-primary="registries" data-secondary="container" data-type="indexterm" id="idm45664093434096"/><a data-primary="Docker" data-secondary="packaging an executable and pushing it to remote registry" data-type="indexterm" id="idm45664093433120"/><a data-primary="Docker" data-type="indexterm" id="idm45664093432128"/>Docker, the default tool most people use for containers, makes it easy to package an executable and push it to a remote registry
where it can later be pulled by others. At the time of writing, container
registries are available in all of the major public clouds, and services to build
images in the cloud are also available in many of them. You can also run your
own registry using open source or commercial systems. These registries make it
easy for users to manage and deploy private images, while image-builder services
provide easy integration with continuous delivery systems.</p>
<p>For this chapter, and the remainder of the book, we are going to work with a
simple example application that we built to help show this
workflow in action. You can find the application <a href="https://oreil.ly/unTLs">on GitHub</a>.</p>
<p>Container images bundle a program and its dependencies into a single artifact under a root filesystem. The most popular container image format is the Docker
image format, which has been standardized by the Open Container Initiative to the
OCI image format. Kubernetes supports both Docker- and OCI-compatible images via
Docker and other runtimes. Docker images also include additional metadata used
by a container runtime to start a running application instance based on the
contents of the container image.</p>
<p>This chapter covers the following topics:</p>
<ul>
<li>
<p>How to package an application using the Docker image format</p>
</li>
<li>
<p>How to start an application using the Docker container runtime</p>
</li>
</ul>
<section data-pdf-bookmark="Container Images" data-type="sect1"><div class="sect1" id="idm45664093427008">
<h1>Container Images</h1>
<p>For nearly
everyone, their first interaction with any
container technology is with a container image.<a data-primary="container images" data-type="indexterm" id="ix_cntnrimg"/> A <em>container image</em> is a binary
package that encapsulates all of the files necessary to run a program inside of
an OS container. Depending on how you first experiment with containers, you will
either build a container image from your local filesystem or download a
preexisting image from a <em>container registry</em>. In
either case, once the container image is present on your computer, you can run
that image to produce a running application inside an OS container.</p>
<p>The most popular and widespread container image format is the Docker image
format, which was developed by the Docker open source project for packaging,
distributing, and running containers using the
<code>docker</code> command. <a data-primary="container images" data-secondary="Docker format" data-type="indexterm" id="idm45664093080304"/>Subsequently, work has begun by Docker, Inc., and others to
standardize the container image format via the Open Container Initiative (OCI)
project.<a data-primary="OCI (Open Container Initiative)" data-type="indexterm" id="idm45664093079008"/><a data-primary="Open Container Initiative (OCI)" data-type="indexterm" id="idm45664093078368"/> While the OCI standard achieved a 1.0 release milestone in mid-2017,
adoption of these standards is proceeding slowly. The Docker image format
continues to be the de facto standard and is made up of a series of filesystem
layers. <a data-primary="layering (container)" data-type="indexterm" id="idm45664093077552"/><a data-primary="overlay filesystem" data-type="indexterm" id="idm45664093076880"/>Each layer adds, removes, or modifies files from the preceding layer in
the filesystem. This is an example of an <em>overlay</em> filesystem. The overlay
system is used both when packaging up the image and when the image is actually
being used. During runtime, there are a variety of different concrete
implementations of such filesystems, including <code>aufs</code>, <code>overlay</code>, and
<code>overlay2</code>.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45664093074016">
<h5>Container Layering</h5>
<p>The phrases “Docker image format” and “container images” may be a bit confusing.
The image isn’t a single file but rather a specification for a manifest file that
points to other files. The manifest and associated files are often treated by
users as a unit.  The level of indirection allows for more efficient storage and
transmittal. Associated with this format is an API for uploading and downloading
images to an image registry.</p>
<p>Container images are
constructed with a series of filesystem layers, where each layer inherits and
modifies the layers that came before it. To help explain this in detail, let’s
build some containers. Note that for correctness, the ordering of the layers
should be bottom up, but for ease of understanding, we take the opposite
approach:</p>
<pre data-type="programlisting">.
└── container A: a base operating system only, such as Debian
    └── container B: build upon #A, by adding Ruby v2.1.10
    └── container C: build upon #A, by adding Golang v1.6</pre>
<p>At this point we have three containers: A, B, and C. B and C are <em>forked</em> from A
and share nothing besides the base container’s files. Taking it further, we can
build on top of B by adding Ruby on Rails (version 4.2.6). We may also want to support a
legacy application that requires an older version of Ruby on Rails (e.g., version
3.2.x). We can build a container image to support that application based on B
also, planning to someday migrate the app to version 4:</p>
<pre data-type="programlisting">. (continuing from above)
└── container B: build upon #A, by adding Ruby v2.1.10
    └── container D: build upon #B, by adding Rails v4.2.6
    └── container E: build upon #B, by adding Rails v3.2.x</pre>
<p>Conceptually, each container image layer builds upon a previous one. Each parent
reference is a pointer. While the example here is a simple set of containers,
other real-world containers can be part of a larger extensive directed
acyclic graph.</p>
</div></aside>
<p>Container images are typically combined with <a data-primary="configurations" data-secondary="container configuration file" data-type="indexterm" id="idm45664093068176"/>a container configuration file,
which provides instructions on how to set up the container environment and
execute an application entry point. The container configuration often includes
information on how to set up networking, namespace isolation, resource
constraints (cgroups), and what <code>syscall</code> restrictions should be placed on a
running container instance. The container root filesystem and configuration file
are typically bundled using the Docker image format.</p>
<p>Containers <a data-primary="containers" data-secondary="system and application" data-type="indexterm" id="idm45664093066416"/>fall into two main categories:</p>
<ul>
<li>
<p>System containers</p>
</li>
<li>
<p>Application containers</p>
</li>
</ul>
<p>System containers seek to mimic virtual machines and often run a full boot
process.<a data-primary="system containers" data-type="indexterm" id="idm45664093062656"/> They often include a set of system services typically found in a VM,
such as <code>ssh</code>, <code>cron</code>, and <code>syslog</code>. When Docker was new, these types of
containers were much more common. Over time, they have come to be seen as poor
practice and application containers have gained favor.</p>
<p>Application containers differ from system containers in that they commonly run a
single program.<a data-primary="application containers" data-type="indexterm" id="idm45664093130224"/> While running a single program per container might seem like an
unnecessary constraint, it provides the perfect level of granularity for
composing scalable applications and is a design philosophy that is leveraged
heavily
by Pods.<a data-primary="container images" data-startref="ix_cntnrimg" data-type="indexterm" id="idm45664093129152"/> We will examine
how Pods work in detail in <a data-type="xref" href="ch05.xhtml#pods">Chapter 5</a>.</p>
</div></section>
<section data-pdf-bookmark="Building Application Images with Docker" data-type="sect1"><div class="sect1" id="idm45664093127152">
<h1>Building Application Images with Docker</h1>
<p>In general, container orchestration systems<a data-primary="Docker" data-secondary="building application container images with" data-type="indexterm" id="ix_Dckimgappc"/><a data-primary="application container images" data-secondary="building with Docker" data-type="indexterm" id="i_appCIbld"/> like Kubernetes are focused on
building and deploying distributed systems made up of application containers.
Consequently, we will focus on application containers for the remainder of this
chapter.</p>
<section data-pdf-bookmark="Dockerfiles" data-type="sect2"><div class="sect2" id="idm45664093122528">
<h2>Dockerfiles</h2>
<p>A Dockerfile can be used to automate the
creation of a Docker container image.<a data-primary="Dockerfiles" data-secondary="automating container image creation with" data-type="indexterm" id="idm45664093120560"/><a data-primary="application container images" data-secondary="building with Docker" data-tertiary="using Dockerfiles" data-type="indexterm" id="idm45664093119552"/></p>
<p>Let’s start by building<a data-primary="Node.js, building image for an application" data-type="indexterm" id="idm45664093117936"/> an application image for a simple Node.js program.  This
example would be very similar for many other dynamic languages, like Python or
Ruby.<a data-primary="npm/Node/Express apps" data-type="indexterm" id="idm45664093116912"/></p>
<p>The simplest of npm/Node/Express apps has two files: <em>package.json</em> (<a data-type="xref" href="#package-json">Example 2-1</a>) and
<em>server.js</em> (<a data-type="xref" href="#server-js">Example 2-2</a>).  Put these in a directory and then run <code>npm install express --save</code>
to establish a dependency on Express and install it.</p>
<div data-type="example" id="package-json">
<h5><span class="label">Example 2-1. </span>package.json</h5>
<pre data-code-language="json" data-type="programlisting"><code class="p">{</code><code class="w"/>
<code class="w">  </code><code class="nt">"name"</code><code class="p">:</code><code class="w"> </code><code class="s2">"simple-node"</code><code class="p">,</code><code class="w"/>
<code class="w">  </code><code class="nt">"version"</code><code class="p">:</code><code class="w"> </code><code class="s2">"1.0.0"</code><code class="p">,</code><code class="w"/>
<code class="w">  </code><code class="nt">"description"</code><code class="p">:</code><code class="w"> </code><code class="s2">"A sample simple application for Kubernetes Up &amp; Running"</code><code class="p">,</code><code class="w"/>
<code class="w">  </code><code class="nt">"main"</code><code class="p">:</code><code class="w"> </code><code class="s2">"server.js"</code><code class="p">,</code><code class="w"/>
<code class="w">  </code><code class="nt">"scripts"</code><code class="p">:</code><code class="w"> </code><code class="p">{</code><code class="w"/>
<code class="w">    </code><code class="nt">"start"</code><code class="p">:</code><code class="w"> </code><code class="s2">"node server.js"</code><code class="w"/>
<code class="w">  </code><code class="p">},</code><code class="w"/>
<code class="w">  </code><code class="nt">"author"</code><code class="p">:</code><code class="w"> </code><code class="s2">""</code><code class="w"/>
<code class="p">}</code><code class="w"/></pre></div>
<div data-type="example" id="server-js">
<h5><span class="label">Example 2-2. </span>server.js</h5>
<pre data-code-language="js" data-type="programlisting"><code class="kd">var</code> <code class="nx">express</code> <code class="o">=</code> <code class="nx">require</code><code class="p">(</code><code class="s1">'express'</code><code class="p">);</code>

<code class="kd">var</code> <code class="nx">app</code> <code class="o">=</code> <code class="nx">express</code><code class="p">();</code>
<code class="nx">app</code><code class="p">.</code><code class="nx">get</code><code class="p">(</code><code class="s1">'/'</code><code class="p">,</code> <code class="kd">function</code> <code class="p">(</code><code class="nx">req</code><code class="p">,</code> <code class="nx">res</code><code class="p">)</code> <code class="p">{</code>
  <code class="nx">res</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="s1">'Hello World!'</code><code class="p">);</code>
<code class="p">});</code>
<code class="nx">app</code><code class="p">.</code><code class="nx">listen</code><code class="p">(</code><code class="mi">3000</code><code class="p">,</code> <code class="kd">function</code> <code class="p">()</code> <code class="p">{</code>
  <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Listening on port 3000!'</code><code class="p">);</code>
  <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'  http://localhost:3000'</code><code class="p">);</code>
<code class="p">});</code></pre></div>
<p>To package this up as a Docker image, create two additional files:
<em>.dockerignore</em> (<a data-type="xref" href="#dockerignore">Example 2-3</a>) and the Dockerfile (<a data-type="xref" href="#dockerfile-node">Example 2-4</a>). The Dockerfile is a recipe for how to build
the container image, while <em>.dockerignore</em> defines the set of files that
should be ignored when copying files into the image.<a data-primary=".dockerignore file" data-primary-sortas="dockerignore" data-type="indexterm" id="idm45664080634752"/> A full description of the syntax of the Dockerfile is available on the <a href="https://dockr.ly/2XUanvl">Docker website</a>.</p>
<div data-type="example" id="dockerignore">
<h5><span class="label">Example 2-3. </span>.dockerignore</h5>
<pre data-type="programlisting">node_modules</pre></div>
<div data-type="example" id="dockerfile-node">
<h5><span class="label">Example 2-4. </span>Dockerfile</h5>
<pre data-code-language="dockerfile" data-type="programlisting"><code class="c"># Start from a Node.js 16 (LTS) image </code><a class="co" href="#callout_creating_and_running_containers_CO1-1" id="co_creating_and_running_containers_CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code class="k">FROM</code><code class="w"> </code><code class="s">node:16</code><code>
</code><code>
</code><code class="c"># Specify the directory inside the image in which all commands will run </code><a class="co" href="#callout_creating_and_running_containers_CO1-2" id="co_creating_and_running_containers_CO1-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
</code><code class="k">WORKDIR</code><code class="w"> </code><code class="s">/usr/src/app</code><code>
</code><code>
</code><code class="c"># Copy package files and install dependencies </code><a class="co" href="#callout_creating_and_running_containers_CO1-3" id="co_creating_and_running_containers_CO1-3"><img alt="3" height="12" src="assets/3.png" width="12"/></a><code>
</code><code class="k">COPY</code><code class="w"> </code><code>package*.json</code><code> </code><code>./</code><code>
</code><code class="k">RUN</code><code class="w"> </code><code>npm</code><code> </code><code>install</code><code>
</code><code class="k">RUN</code><code class="w"> </code><code>npm</code><code> </code><code>install</code><code> </code><code>express</code><code>
</code><code>
</code><code class="c"># Copy all of the app files into the image </code><a class="co" href="#callout_creating_and_running_containers_CO1-4" id="co_creating_and_running_containers_CO1-4"><img alt="4" height="12" src="assets/4.png" width="12"/></a><code>
</code><code class="k">COPY</code><code class="w"> </code><code>.</code><code> </code><code>.</code><code>
</code><code>
</code><code class="c"># The default command to run when starting the container </code><a class="co" href="#callout_creating_and_running_containers_CO1-5" id="co_creating_and_running_containers_CO1-5"><img alt="5" height="12" src="assets/5.png" width="12"/></a><code>
</code><code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="w"> </code><code class="s2">"npm"</code><code class="p">,</code><code class="w"> </code><code class="s2">"start"</code><code class="w"> </code><code class="p">]</code></pre></div>
<dl class="calloutlist">
<dt><a class="co" href="#co_creating_and_running_containers_CO1-1" id="callout_creating_and_running_containers_CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Every Dockerfile builds on other container images. This line specifies that
we are starting from the <code>node:16</code> image on the Docker Hub.  This is a
preconfigured image with Node.js 16.</p></dd>
<dt><a class="co" href="#co_creating_and_running_containers_CO1-2" id="callout_creating_and_running_containers_CO1-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>This line sets the work directory in the container image for all following
<span class="keep-together">commands</span>.</p></dd>
<dt><a class="co" href="#co_creating_and_running_containers_CO1-3" id="callout_creating_and_running_containers_CO1-3"><img alt="3" height="12" src="assets/3.png" width="12"/></a></dt>
<dd><p>These three lines initialize the dependencies for Node.js.  First, we copy the
package files into the image. This will include <em>package.json</em> and
<em>package-lock.json</em>. The <code>RUN</code> command then runs the correct command <em>in the
container</em> to install the necessary dependencies.</p></dd>
<dt><a class="co" href="#co_creating_and_running_containers_CO1-4" id="callout_creating_and_running_containers_CO1-4"><img alt="4" height="12" src="assets/4.png" width="12"/></a></dt>
<dd><p>Now we copy the rest of the program files into the image.  This will include
everything except <em>node_modules</em>, as that is excluded via the <em>.dockerignore</em>
file.</p></dd>
<dt><a class="co" href="#co_creating_and_running_containers_CO1-5" id="callout_creating_and_running_containers_CO1-5"><img alt="5" height="12" src="assets/5.png" width="12"/></a></dt>
<dd><p>Finally, we specify the command that should be run when the container is run.</p></dd>
</dl>
<p>Run the following command to create the <code>simple-node</code> Docker image:</p>
<pre data-type="programlisting">$ <strong>docker build -t simple-node .</strong></pre>
<p>When you want to run this image, you can do it with the following command. Navigate to <span><em>http://localhost:3000</em></span> to access the program running in the
container:</p>
<pre data-type="programlisting">$ <strong>docker run --rm -p 3000:3000 simple-node</strong></pre>
<p>At this point, our <code>simple-node</code> image lives in the local Docker registry where
the image was built and is only accessible to a single machine. The true power
of Docker comes from the ability to share images across thousands of machines
and the broader Docker community.</p>
</div></section>
<section data-pdf-bookmark="Optimizing Image Sizes" data-type="sect2"><div class="sect2" id="idm45664093121936">
<h2>Optimizing Image Sizes</h2>
<p>There are several gotchas people encounter when they begin to experiment with container images that lead to
overly large images.<a data-primary="application container images" data-secondary="building with Docker" data-tertiary="optimizing image sizes" data-type="indexterm" id="idm45664080476608"/> The first thing to remember is that files that are removed
by subsequent layers in the system are actually still present in the images;
they’re just inaccessible. Consider the following situation:</p>
<pre data-type="programlisting">.
└── layer A: contains a large file named 'BigFile'
    └── layer B: removes 'BigFile'
        └── layer C: builds on B by adding a static binary</pre>
<p>You might think that <em>BigFile</em> is no longer present in this image. After all,
when you run the image, it is no longer accessible. But in fact it is still
present in layer A, which means that whenever you push or pull the image,
<em>BigFile</em> is still transmitted through the network, even if you can no longer
access it.</p>
<p>Another pitfall revolves around image caching and
building. <a data-primary="layering (container)" data-secondary="changes to layers" data-type="indexterm" id="idm45664080473232"/>Remember that each layer is an independent delta from the layer below
it. Every time you change a layer, it changes every layer that comes after it.
Changing the preceding layers means that they need to be rebuilt, repushed, and
repulled to deploy your image to development.</p>
<p>To understand this more fully, consider two images:</p>
<pre data-type="programlisting">.
└── layer A: contains a base OS
    └── layer B: adds source code server.js
        └── layer C: installs the 'node' package</pre>
<p>versus:</p>
<pre data-type="programlisting">.
└── layer A: contains a base OS
    └── layer B: installs the 'node' package
        └── layer C: adds source code server.js</pre>
<p>It seems obvious that both of these images will behave identically, and indeed
the first time they are pulled, they do. However, consider what happens when
<em>server.js</em> changes. In the second case, it is only that change that needs to be pulled
or pushed, but in the first case, both <em>server.js</em> and the layer providing the
<code>node</code> package need to be pulled and pushed, since the <code>node</code> layer is dependent
on the <em>server.js</em> layer. In general, you want to order your layers from least
likely to change to most likely to change in order to optimize the image size
for pushing and pulling. This is why, in
<a data-type="xref" href="#dockerfile-node">Example 2-4</a>, we copy the <em>package*.json</em> files and install dependencies
before copying the rest of the program files. A developer is going to update and
change the program files much more often than the dependencies.</p>
</div></section>
<section data-pdf-bookmark="Image Security" data-type="sect2"><div class="sect2" id="idm45664080477584">
<h2>Image Security</h2>
<p>When it comes to security,
there are no shortcuts. <a data-primary="security" data-secondary="application container image" data-type="indexterm" id="idm45664080465200"/><a data-primary="application container images" data-secondary="building with Docker" data-tertiary="image security" data-type="indexterm" id="idm45664080464352"/>When building images that will ultimately run in a
production Kubernetes cluster, be sure to follow best practices for packaging
and distributing applications. For example, don’t build containers with
passwords baked in—and this includes not just in the final layer, but any layers
in the image. One of the counterintuitive problems introduced by container
layers is that deleting a file in one layer doesn’t delete that file from
preceding layers. It still takes up space, and it can be accessed by anyone with
the right tools—an enterprising attacker can simply create an image that only
consists of the layers that contain the password.<a data-primary="secrets" data-secondary="never mixing with images" data-type="indexterm" id="idm45664080463136"/></p>
<p>Secrets and images should <em>never</em> be mixed. If you do so, you will be hacked,
and you
will bring shame to your entire company or department. We all want to be on TV
someday, but there are better ways to go about that.</p>
<p>Additionally, because container images are narrowly focused on running individual applications, a best practice is to minimize
the files within the container image. Every additional library in an image
provides a potential vector for vulnerabilities to appear in your application.
Depending on the language, you can achieve very small images with a very
tight set of dependencies. This smaller set ensures that your image isn’t
exposed to vulnerabilities in libraries it would never use.<a data-primary="Docker" data-secondary="building application container images with" data-startref="ix_Dckimgappc" data-type="indexterm" id="idm45664080461136"/><a data-primary="application container images" data-secondary="building with Docker" data-startref="i_appCIbld" data-type="indexterm" id="idm45664080460048"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Multistage Image Builds" data-type="sect1"><div class="sect1" id="idm45664080458704">
<h1>Multistage Image Builds</h1>
<p>One of the most common ways to accidentally<a data-primary="multistage image builds" data-type="indexterm" id="idm45664080457136"/> build large images is to do the
actual program compilation as part of the construction of the application
container image.<a data-primary="container images" data-secondary="multistage builds" data-type="indexterm" id="idm45664080456400"/> Compiling code as part of the image build feels natural, and it
is the easiest way to build a container image from your program. The trouble
with doing this is that it leaves all of the unnecessary development tools,
which are usually quite large, lying around inside your image and slowing
down your deployments.</p>
<p>To resolve this problem, Docker introduced <em>multistage builds</em>. <a data-primary="Docker" data-secondary="multistage image builds" data-type="indexterm" id="idm45664080454656"/>With
multistage builds, rather than producing a single image, a Docker file can
actually produce multiple images. Each image is considered a stage.
Artifacts can be copied from preceding stages to the current stage.</p>
<p>To illustrate this concretely, we will look at how to build our example
application, <code>kuard</code>. This is a somewhat complicated application that involves a
React.js frontend (with its own build process) that then gets embedded into a Go
program. The Go program runs a backend API server that the <em>React.js</em> frontend
interacts with.<a data-primary="Go language" data-secondary="program running backend API server for kuard example application" data-type="indexterm" id="idm45664080452528"/><a data-primary="React.js" data-type="indexterm" id="idm45664080451680"/></p>
<p>A simple Dockerfile might<a data-primary="Dockerfiles" data-secondary="kuard application example" data-type="indexterm" id="idm45664080450656"/> look like this:</p>
<pre data-code-language="dockerfile" data-type="programlisting"><code class="k">FROM</code><code class="w"> </code><code class="s">golang:1.17-alpine</code>

<code class="c"># Install Node and NPM</code>
<code class="k">RUN</code><code class="w"> </code>apk update <code class="o">&amp;&amp;</code> apk upgrade <code class="o">&amp;&amp;</code> apk add --no-cache git nodejs bash npm

<code class="c"># Get dependencies for Go part of build</code>
<code class="k">RUN</code><code class="w"> </code>go get -u github.com/jteeuwen/go-bindata/...
<code class="k">RUN</code><code class="w"> </code>go get github.com/tools/godep
<code class="k">RUN</code><code class="w"> </code>go get github.com/kubernetes-up-and-running/kuard

<code class="k">WORKDIR</code><code class="w"> </code><code class="s">/go/src/github.com/kubernetes-up-and-running/kuard</code>

<code class="c"># Copy all sources in</code>
<code class="k">COPY</code><code class="w"> </code>. .

<code class="c"># This is a set of variables that the build script expects</code>
<code class="k">ENV</code><code class="w"> </code><code class="nv">VERBOSE</code><code class="o">=</code><code class="m">0</code>
<code class="k">ENV</code><code class="w"> </code><code class="nv">PKG</code><code class="o">=</code>github.com/kubernetes-up-and-running/kuard
<code class="k">ENV</code><code class="w"> </code><code class="nv">ARCH</code><code class="o">=</code>amd64
<code class="k">ENV</code><code class="w"> </code><code class="nv">VERSION</code><code class="o">=</code><code class="nb">test</code>

<code class="c"># Do the build. This script is part of incoming sources.</code>
<code class="k">RUN</code><code class="w"> </code>build/build.sh

<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="w"> </code><code class="s2">"/go/bin/kuard"</code><code class="w"> </code><code class="p">]</code></pre>
<p>This Dockerfile produces a container image containing a static executable, but
it also contains all of the Go development tools and the tools to build the
<em>React.js</em> frontend and the source code for the application, neither of which are
needed by the final application. The image, across all layers, adds up to over
500 MB.</p>
<p>To see how we would do this with multistage builds, examine <a data-primary="Dockerfiles" data-secondary="multistage build for kuard example application" data-type="indexterm" id="idm45664080406512"/>the following multistage
Dockerfile:</p>
<pre data-code-language="dockerfile" data-type="programlisting"><code class="c"># STAGE 1: Build</code>
<code class="k">FROM</code><code class="w"> </code><code class="s">golang:1.17-alpine</code><code class="w"> </code><code class="k">AS</code><code class="w"> </code><code class="s">build</code>

<code class="c"># Install Node and NPM</code>
<code class="k">RUN</code><code class="w"> </code>apk update <code class="o">&amp;&amp;</code> apk upgrade <code class="o">&amp;&amp;</code> apk add --no-cache git nodejs bash npm

<code class="c"># Get dependencies for Go part of build</code>
<code class="k">RUN</code><code class="w"> </code>go get -u github.com/jteeuwen/go-bindata/...
<code class="k">RUN</code><code class="w"> </code>go get github.com/tools/godep

<code class="k">WORKDIR</code><code class="w"> </code><code class="s">/go/src/github.com/kubernetes-up-and-running/kuard</code>

<code class="c"># Copy all sources in</code>
<code class="k">COPY</code><code class="w"> </code>. .

<code class="c"># This is a set of variables that the build script expects</code>
<code class="k">ENV</code><code class="w"> </code><code class="nv">VERBOSE</code><code class="o">=</code><code class="m">0</code>
<code class="k">ENV</code><code class="w"> </code><code class="nv">PKG</code><code class="o">=</code>github.com/kubernetes-up-and-running/kuard
<code class="k">ENV</code><code class="w"> </code><code class="nv">ARCH</code><code class="o">=</code>amd64
<code class="k">ENV</code><code class="w"> </code><code class="nv">VERSION</code><code class="o">=</code><code class="nb">test</code>

<code class="c"># Do the build. Script is part of incoming sources.</code>
<code class="k">RUN</code><code class="w"> </code>build/build.sh

<code class="c"># STAGE 2: Deployment</code>
<code class="k">FROM</code><code class="w"> </code><code class="s">alpine</code>

<code class="k">USER</code><code class="w"> </code><code class="s">nobody:nobody</code>
<code class="k">COPY</code><code class="w"> </code>--from<code class="o">=</code>build /go/bin/kuard /kuard

<code class="k">CMD</code><code class="w"> </code><code class="p">[</code><code class="w"> </code><code class="s2">"/kuard"</code><code class="w"> </code><code class="p">]</code></pre>
<p>This Dockerfile produces two images.<a data-primary="build image" data-type="indexterm" id="idm45664080330848"/> The first is the <em>build</em> image, which
contains the Go compiler, <em>React.js</em> toolchain, and source code for the program. The
second is the <em>deployment</em> image, which simply <a data-primary="deployment image" data-type="indexterm" id="idm45664080290240"/>contains the compiled binary.
Building a container image using multistage builds can reduce your final
container image size by hundreds of megabytes and thus dramatically speed up
your deployment times, since generally, deployment latency is gated on network
performance. The final image produced from this Dockerfile is somewhere around
20 MB.</p>
<p>These scripts are present in the <code>kuard</code> repository on <a href="https://oreil.ly/6c9MX">GitHub</a> and you can
build and run this image with the following commands:</p>
<pre data-type="programlisting">
# Note: if you are running on Windows you may need to fix line-endings using:
# --config core.autocrlf=input
$ <strong>git clone https://github.com/kubernetes-up-and-running/kuard</strong>
$ <strong>cd kuard</strong>
$ <strong>docker build -t kuard .</strong>
$ <strong>docker run --rm -p 8080:8080 kuard</strong></pre>
</div></section>
<section data-pdf-bookmark="Storing Images in a Remote Registry" data-type="sect1"><div class="sect1" id="idm45664080458112">
<h1>Storing Images in a Remote Registry</h1>
<p>What good is a container
image if it’s only available on a single machine?</p>
<p>Kubernetes relies on the fact that images described in a Pod manifest are
available across every machine in the cluster.<a data-primary="container images" data-secondary="storing in remote registry" data-type="indexterm" id="idm45664080283360"/><a data-primary="Docker" data-secondary="storing images in remote registry" data-type="indexterm" id="idm45664080247168"/><a data-primary="registries" data-secondary="container" data-tertiary="storing container images in remote registry" data-type="indexterm" id="idm45664080246320"/> One option for getting this image
to all machines in the cluster would be to export the <code>kuard</code> image and import it on each of them. We can’t think of anything more tedious
than managing Docker images this way. The process of manually importing and
exporting Docker images has human error written all over it. Just say no!</p>
<p>The standard within the Docker community is to store Docker images in a remote
registry. There are tons of options when it comes to Docker registries, and what
you choose will be largely based on your needs in terms of security
and collaboration <span class="keep-together">features</span>.</p>
<p>Generally speaking, the first choice you need to make regarding a registry is
whether to use a private or a public registry.<a data-primary="private container registries" data-type="indexterm" id="idm45664080242992"/>  Public registries allow anyone
to download images stored in the registry, while private registries require
authentication to download images. In choosing public versus private, it’s
helpful to consider your use case.<a data-primary="public container registries" data-type="indexterm" id="idm45664080242144"/></p>
<p>Public registries are great for sharing images with the world because they
allow for easy, unauthenticated use of the container images. You can easily
distribute your software as a container image and have confidence that users
everywhere will have the exact same experience.</p>
<p>In contrast, a private registry is best for storing applications that are
private to your service and that you don’t want the world to use. Additionally, private registries often provide better availability and security guarantees because they are specific to you and your images rather than serving the world.</p>
<p>Regardless, to push an image, you need to authenticate to the registry.<a data-primary="docker login command" data-type="indexterm" id="idm45664080240016"/> You can
generally do this with the <code>docker login</code> command, though there are some
differences for certain registries.<a data-primary="authentication" data-secondary="with container registries" data-secondary-sortas="container" data-type="indexterm" id="idm45664080238800"/><a data-primary="cloud" data-secondary="container registries" data-type="indexterm" id="idm45664080237536"/>  In the examples in this book we are pushing to the
Google Cloud Platform registry, called the
Google Container Registry (GCR); other clouds, including Azure and Amazon Web Services (AWS), also have
hosted container registries.<a data-primary="Docker Hub" data-type="indexterm" id="idm45664080236464"/> For new users hosting publicly readable images,
the <a href="https://hub.docker.com">Docker Hub</a> is a great place to
start.</p>
<p>Once you are logged in, you can tag the <code>kuard</code> image by prepending the target
Docker registry.<a data-primary="tags" data-secondary="kuard application example with target Docker registry" data-type="indexterm" id="idm45664080234176"/> You can also append an identifier that is usually used for the version or variant of that image, separated by a colon (<code>:</code>):</p>
<pre data-type="programlisting">$ <strong>docker tag kuard gcr.io/kuar-demo/kuard-amd64:blue</strong></pre>
<p>Then you<a data-primary="docker push command" data-type="indexterm" id="idm45664080231168"/> can push the <code>kuard</code> image:</p>
<pre data-type="programlisting">$ <strong>docker push gcr.io/kuar-demo/kuard-amd64:blue</strong></pre>
<p>Now that the <code>kuard</code> image is available on a remote
registry, it’s time to deploy it using Docker. When we pushed the image to GCR, it was marked as public, so it will be available everywhere without authentication.</p>
</div></section>
<section data-pdf-bookmark="The Container Runtime Interface" data-type="sect1"><div class="sect1" id="idm45664080227696">
<h1>The Container Runtime Interface</h1>
<p>Kubernetes provides an API for describing an
application deployment, but relies on a container runtime to set up an
application container using the container-specific APIs native to the target OS.<a data-primary="CRI (Container Runtime Interface)" data-type="indexterm" id="ix_CRI"/>
On a Linux system that means configuring cgroups and namespaces. The interface
to this container runtime is defined by the Container Runtime Interface (CRI) standard.<a data-primary="Container Runtime Interface" data-see="CRI" data-type="indexterm" id="idm45664080224880"/><a data-primary="Docker" data-secondary="Container Runtime Interface implementation, containerd-cri" data-type="indexterm" id="idm45664080223920"/> The CRI API is implemented by a number of different programs, including
the <code>containerd-cri</code> built by Docker and the <code>cri-o</code> implementation contributed by Red Hat. When you install the Docker tooling, the <code>containerd</code>
runtime is also installed and used by the Docker daemon.</p>
<p>Starting with release 1.25 of Kubernetes, only container runtimes
that support the CRI will work with Kubernetes.
Fortunately, managed Kubernetes providers have made this transition nearly
automatic for users of managed Kubernetes.</p>
<section data-pdf-bookmark="Running Containers with Docker" data-type="sect2"><div class="sect2" id="idm45664080221120">
<h2>Running Containers with Docker</h2>
<p>In Kubernetes, containers <a data-primary="CRI (Container Runtime Interface)" data-secondary="running containers with Docker" data-type="indexterm" id="idm45664080219552"/><a data-primary="containers" data-secondary="running with Docker" data-type="indexterm" id="idm45664080218496"/><a data-primary="Docker" data-secondary="running containers with" data-type="indexterm" id="idm45664080217552"/>are usually launched by a daemon on each node
called the <em>kubelet</em>; however, it’s easier to get started with containers using the
Docker command-line tool.<a data-primary="docker run command" data-type="indexterm" id="idm45664080215904"/> The Docker CLI tool can be used to deploy
containers. To deploy a container from the <code>gcr.io/kuar-demo/kuard-amd64:blue</code>
image, run the following command:</p>
<pre data-type="programlisting">$ <strong>docker run -d --name kuard \
  --publish 8080:8080 \
  gcr.io/kuar-demo/kuard-amd64:blue</strong></pre>
<p>This command starts the <code>kuard</code> container
and maps ports 8080 on your local machine to 8080 in the container. The
<code>--publish</code> option can be shortened to <code>-p</code>. <a data-primary="port forwarding" data-type="indexterm" id="idm45664080211616"/>This forwarding is necessary
because each container gets its own IP address, so listening on <em>localhost</em>
inside the container doesn’t cause you to listen on your machine. Without the
port forwarding, connections will be inaccessible to your machine.  The <span class="keep-together"><code>-d</code></span> option specifies that this should run in the background (daemon), while <code>--name kuard</code> gives the container a friendly name.</p>
</div></section>
<section data-pdf-bookmark="Exploring the kuard Application" data-type="sect2"><div class="sect2" id="idm45664080208624">
<h2>Exploring the kuard Application</h2>
<p><code>kuard</code> exposes a simple web interface, which you <a data-primary="CRI (Container Runtime Interface)" data-secondary="exploring kuard example application" data-type="indexterm" id="idm45664080206832"/>can load by pointing
your browser at <span><em>http://localhost:3000</em></span> or via the command line:</p>
<pre data-type="programlisting">$ <strong>curl http://localhost:8080</strong></pre>
<p><code>kuard</code> also exposes a number of interesting functions that we will explore
later on in this book.</p>
</div></section>
<section data-pdf-bookmark="Limiting Resource Usage" data-type="sect2"><div class="sect2" id="idm45664080202896">
<h2>Limiting Resource Usage</h2>
<p>Docker enables applications to use fewer resources by exposing the underlying cgroup technology provided by the Linux
kernel.<a data-primary="resource management" data-secondary="limiting resource usage" data-type="indexterm" id="idm45664080201568"/><a data-primary="CRI (Container Runtime Interface)" data-secondary="limiting resource usage" data-type="indexterm" id="idm45664080200592"/> These capabilities are likewise used by Kubernetes to limit the resources each Pod uses.</p>
<section data-pdf-bookmark="Limiting memory resources" data-type="sect3"><div class="sect3" id="idm45664080199216">
<h3>Limiting memory resources</h3>
<p>One of the key benefits to running applications within a container is the
ability to restrict resource utilization.<a data-primary="memory" data-secondary="limiting use of memory resources" data-type="indexterm" id="idm45664080197648"/><a data-primary="CRI (Container Runtime Interface)" data-secondary="limiting memory resource usage" data-type="indexterm" id="idm45664080196608"/> This allows multiple applications to
coexist on the same hardware and ensures fair usage.<a data-primary="docker run command" data-type="indexterm" id="idm45664080195392"/></p>
<p>To limit <code>kuard</code> to 200 MB of memory and 1 GB of swap space, use the <code>--memory</code>
and <code>--memory-swap</code> flags with the <code>docker run</code> command.</p>
<p>Stop and remove the current <code>kuard</code> container:</p>
<pre data-type="programlisting">$ <strong>docker stop kuard</strong>
$ <strong>docker rm kuard</strong></pre>
<p>Then start another <code>kuard</code> container using the appropriate flags to limit memory
usage:</p>
<pre data-type="programlisting">$ <strong>docker run -d --name kuard \
  --publish 8080:8080 \
  --memory 200m \
  --memory-swap 1G \
  gcr.io/kuar-demo/kuard-amd64:blue</strong></pre>
<p>If the program in the container uses too much memory, it will be terminated.</p>
</div></section>
<section data-pdf-bookmark="Limiting CPU resources" data-type="sect3"><div class="sect3" id="idm45664080187696">
<h3>Limiting CPU resources</h3>
<p>Another critical resource on a machine is the CPU.<a data-primary="CRI (Container Runtime Interface)" data-secondary="limiting CPU usage" data-type="indexterm" id="idm45664080186304"/><a data-primary="CPUs" data-secondary="limiting utilization by applications" data-type="indexterm" id="idm45664080185312"/><a data-primary="docker run command" data-type="indexterm" id="idm45664080184352"/> Restrict CPU utilization
using the <code>--cpu-shares</code> flag with the <code>docker run</code>  command:</p>
<pre data-type="programlisting">$ <strong>docker run -d --name kuard \
  --publish 8080:8080 \
  --memory 200m \
  --memory-swap 1G \
  --cpu-shares 1024 \
  gcr.io/kuar-demo/kuard-amd64:blue</strong></pre>
</div></section>
</div></section>
</div></section>
<section data-pdf-bookmark="Cleanup" data-type="sect1"><div class="sect1" id="idm45664080181200">
<h1>Cleanup</h1>
<p>Once you are done <a data-primary="CRI (Container Runtime Interface)" data-startref="ix_CRI" data-type="indexterm" id="idm45664080179568"/><a data-primary="container images" data-secondary="deleting" data-type="indexterm" id="idm45664080178544"/><a data-primary="docker rmi command" data-type="indexterm" id="idm45664080177600"/>building an
image, you can delete it with the <code>docker rmi</code> <span class="keep-together">command</span>:</p>
<pre data-type="programlisting">docker rmi &lt;<em>tag-name</em>&gt;</pre>
<p>or:</p>
<pre data-type="programlisting">docker rmi &lt;<em>image-id</em>&gt;</pre>
<p>Images <a data-primary="tags" data-secondary="deleting container images by tag name" data-type="indexterm" id="idm45664080172400"/>can either be deleted via their tag name (e.g.,
<code>gcr.io/kuar-demo/kuard-amd64:blue</code>) or via their image ID. As with all ID values
in the <code>docker</code> tool, the image ID can be shortened as long as it remains
unique. Generally only three or four characters of the ID are necessary.</p>
<p>It’s important to note that unless you explicitly delete an image, it will live
on your system forever, <em>even</em> if you build a new image with an identical name.
Building this new image simply moves the tag to the new image; it doesn’t delete
or replace the old image.</p>
<p>Consequently, as you iterate while you are creating a new image, you will often
create many, many different images that take up unnecessary space on
your computer. To see the images currently on your machine, you can use the <code>docker images</code>
command. You can then delete tags you are no longer using.</p>
<p>Docker provides a tool called <code>docker system prune</code> for doing general cleanup.
This will remove all stopped containers, all untagged images, and all unused
image layers cached as part of the build process.<a data-primary="docker system prune command" data-type="indexterm" id="idm45664080167456"/>  Use it carefully.</p>
<p>A slightly more sophisticated approach is to set up a <code>cron</code> job to run an image
garbage collector. For example, you can easily run <code>docker system prune</code> as a recurring <code>cron</code> job, once per day or once per hour, depending on how many images you are creating.</p>
</div></section>
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45664080180608">
<h1>Summary</h1>
<p>Application containers provide a clean abstraction for applications, and when
packaged in the Docker image format, applications become easy to build, deploy,
and distribute. Containers also provide isolation between applications running
on the same machine, which helps avoid dependency conflicts.</p>
<p>In future chapters, we’ll see how the ability to mount external directories means
we can run not only stateless applications in a container, but also applications
like MySQL and others that generate lots of data.</p>
</div></section>
</div></section></div></body></html>