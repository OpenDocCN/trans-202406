- en: Chapter 15\. Measuring Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many third-party tools for measuring performance in a JavaScript app,
    but the browser also has some handy tools built in for capturing performance metrics.
  prefs: []
  type: TYPE_NORMAL
- en: The Navigation Timing API is used to capture performance data about the initial
    page load. You can inspect how long the page took to load, how long it took for
    the DOM to become interactive, and more. It returns a set of timestamps that indicate
    when each event happened during the page load.
  prefs: []
  type: TYPE_NORMAL
- en: The Resource Timing API lets you inspect how long it took to download resources
    and make network requests. This covers page resources such as HTML files, CSS
    files, JavaScript files, and images. It also covers asynchronous requests such
    as those made with the Fetch API.
  prefs: []
  type: TYPE_NORMAL
- en: The User Timing API is a way to calculate the elapsed time of arbitrary operations.
    You can create performance *marks*, which are points in time, and *measures*,
    which are calculated durations between marks.
  prefs: []
  type: TYPE_NORMAL
- en: All of these APIs create performance entries in a buffer on the page. This is
    a single collection of all types of performance entries. You can inspect this
    buffer at any time, and you can also use `PerformanceObserver` to listen asynchronously
    for new performance entries to be added.
  prefs: []
  type: TYPE_NORMAL
- en: Performance entries use high-precision timestamps. Time is measured in milliseconds,
    but can also contain fractional portions that, in some browsers, can have microsecond
    accuracy. In the browser, these timestamps are stored as `DOMHighResTimeStamp`
    objects. These are numbers that start at zero when the page loads and represent
    the time since the page load that a given entry happened.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter’s recipes explore solutions for gathering performance metrics.
    What you do with those metrics is up to you. You can use the Fetch or Beacon API
    to send the performance metrics to an API for collection and later analysis.
  prefs: []
  type: TYPE_NORMAL
- en: You can use these performance metrics during development for debugging purposes,
    or leave them in to collect real performance metrics from your users. These can
    be sent to an analytics service for aggregation and analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring Page Load Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to gather information about the timing of page load events.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look up the single performance entry with a type of `navigation`, and retrieve
    the navigation timestamps from the performance entry object (see [Example 15-1](#example15-1)).
    You can then calculate the interval between these timestamps to figure out the
    time taken for various page load events.
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-1\. Looking up the navigation timing performance entry
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This object has a lot of properties. [Table 15-1](#table15-1) lists a few examples
    of useful calculations you can perform.
  prefs: []
  type: TYPE_NORMAL
- en: Table 15-1\. Navigation timing calculations
  prefs: []
  type: TYPE_NORMAL
- en: '| Metric | Start time | End time |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Time to first byte | `startTime` | `responseStart` |'
  prefs: []
  type: TYPE_TB
- en: '| Time to DOM interactive | `startTime` | `domInteractive` |'
  prefs: []
  type: TYPE_TB
- en: '| Total load time | `startTime` | `loadEventEnd` |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `startTime` property of the navigation timing performance entry is always
    0.
  prefs: []
  type: TYPE_NORMAL
- en: This entry doesn’t only contain timing information. It also contains information
    such as the amount of data transferred, the HTTP response code, and the page URL.
    This information is useful to determine how quickly your application becomes responsive
    when it first loads.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring Resource Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to get information about requests for the resources loaded on the page.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Find the resource performance entries in the performance buffer (see [Example 15-2](#example15-2)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-2\. Getting the resource performance entries
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You’ll get one entry for each resource on the page. Resources include CSS files,
    JavaScript files, images, and any other requests by the page.
  prefs: []
  type: TYPE_NORMAL
- en: For each resource, you can calculate how long it took to load by taking the
    difference between the `startTime` and `responseEnd` properties. The URL of the
    resource is available in the `name` property.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Any network requests you make with the Fetch API also show up as a resource.
    This makes this API useful for profiling the real-world performance of your REST
    API endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: When the page first loads, the performance buffer includes an entry for all
    resources requested during the initial page load. Subsequent requests are added
    to the performance buffer as they are made.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the Slowest Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to get a list of the resources that took the longest to load.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sort and filter the list of resource performance entries. Since this list is
    just an array, you can call methods such as `sort` and `slice` on it. To find
    how long the resource took to load, take the difference between its `responseEnd`
    and `startTime` timestamps.
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 15-3](#code_findSlowest) shows how to find the five slowest-loading
    resources.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-3\. Finding the five slowest-loading resources
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key is the `sort` call. This compares each pair of load times and sorts
    the whole list in descending order of load times. Then, the `slice` call is just
    taking the first five elements of the sorted array.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to instead get a list of the five fastest-loading resources, you
    can just reverse the order in which the load times are compared (see [Example 15-4](#example15-4)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-4\. Finding the 5 fastest resources
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The reversed comparison means the array is sorted in ascending order rather
    than descending order. The `slice` call now returns the five fastest-loading resources.
  prefs: []
  type: TYPE_NORMAL
- en: Finding Timings for a Specific Resource
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to look up the timings for requests for a specific resource.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use the method `window.performance.getEntriesByName` to look up resources by
    a specific URL (see [Example 15-5](#example15-5)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-5\. Finding all resource timings for a specific URL
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The name of a resource entry is its URL. The first argument to `getEntriesByName`
    is the URL. The second argument indicates that you’re interested in resource timings.
  prefs: []
  type: TYPE_NORMAL
- en: If there were multiple requests for the given URL, you’ll get multiple resource
    entries in the returned array.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling Rendering Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to record the time it takes to render some data on the page.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Create a performance mark just before the rendering begins. Once rendering is
    complete, create another mark. Then you can create a *measure* between the two
    marks to record how long the rendering took.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have a `DataView` component that can be used to render some data
    in the page (see [Example 15-6](#code_renderData)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-6\. Measuring rendering performance
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `measure` object contains the start time and the calculated duration of
    the measure.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whenever you create performance marks and measures, they are added to the page’s
    performance buffer to look up later. For example, if you wanted to look up the
    `render` measure at a later time, you could use `window.performance.getEntriesByName`
    (see [Example 15-7](#example15-7)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-7\. Looking up a measure by name
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Marks and measures can also contain data associated with them by passing the
    `detail` option. For example, when rendering the data in [Example 15-6](#code_renderData),
    you can pass the data itself as metadata when creating the measure.
  prefs: []
  type: TYPE_NORMAL
- en: When creating a measure in this way, you need to include the start and end marks
    inside the options object (see [Example 15-8](#example15-8)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-8\. Measuring rendering performance with data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Later, when you look up this performance entry, the detail metadata is available
    in the measure’s `detail` property.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling Multistep Tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to gather performance data for a multistep process. You want to get
    the time for the whole sequence, but also the time for individual steps. For example,
    you might want to load some data from an API and then do some processing with
    that data. In this case, you want to know the time for the API request, the time
    for the processing, and also the total time taken.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Create multiple marks and measures. You can use a given mark in more than one
    measure calculation.
  prefs: []
  type: TYPE_NORMAL
- en: In [Example 15-9](#example15-9), there’s an API that returns some user transactions.
    Once the transactions are received, you want to run some analytics on the transaction
    data. Finally, the analytics data is sent to another API.
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-9\. Profiling a multistep process
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Once the process has finished and marks have been taken, you can use those marks
    to generate several measures, as shown in [Example 15-10](#code_measures).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-10\. Generating measures
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example shows how you can create multiple marks and measures to gather
    performance data on a set of tasks. A given mark can be used more than once, in
    multiple measures. [Example 15-10](#code_measures) creates a measure for each
    step of the process, then generates a final measure for the entire task’s duration.
    This is done by taking the first mark of the download task and the last mark of
    the upload task, and calculating a measure between them.
  prefs: []
  type: TYPE_NORMAL
- en: Listening for Performance Entries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to be notified of new performance entries so that you can report them
    to an analytics service. For example, consider the scenario where you want to
    be notified of performance statistics every time an API request is made.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use a `PerformanceObserver` to listen for new performance entries of the desired
    type. For API requests, the type would be `resource` (see [Example 15-11](#code_performanceObserver)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-11\. Using a `PerformanceObserver`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `PerformanceObserver` fires for every network request, including the one
    you make to your analytics service. For this reason, [Example 15-11](#code_performanceObserver)
    checks to make sure a given entry is not the analytics endpoint before sending
    the request. Without this check, you end up in an infinite loop of POST requests.
    When a network request is made, the observer fires and you send the POST request.
    This creates a new performance entry, which calls the observer again. Each POST
    to the analytics service triggers a new observer callback.
  prefs: []
  type: TYPE_NORMAL
- en: To prevent a high volume of requests in a short period to your analytics service,
    for a real application you may want to collect performance entries in a buffer.
    Once the buffer reaches a certain size, you can send all the entries from the
    buffer in a single request (see [Example 15-12](#example15-12)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 15-12\. Sending performance entries in batches
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
