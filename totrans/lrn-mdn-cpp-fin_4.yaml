- en: Chapter 5\. Linear Algebra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear algebra is an essential part of computational finance, and as such it
    is a necessary and fundamental component for financial C++ software development.
    Options existing at present in the Standard Library are mostly limited to the
    `valarray` container, to be discussed briefly below. Over the last 15 years or
    so, some very good open source matrix algebra libraries have emerged that have
    been adopted by the financial software industry, as well as other computationally
    intensive domains such as data science and medical research. Progress is also
    being made toward linear algebra capabilities eventually being adopted into the
    Standard Library in C++23 and C++26.
  prefs: []
  type: TYPE_NORMAL
- en: As C++ did not have all the convenient built-in multidimensional array capabilities
    that came with Fortran platforms, quantitative programmers making the transition
    to C++ back in the 1990‚Äôs often found themselves in an inconvenient situation
    with limited options. These included building up this functionality mostly from
    scratch, wrestling with interfaces to numerical Fortran libraries such as BLAS
    and LAPACK, or somehow convincing management to invest in a third-party C++ commercial
    library.
  prefs: []
  type: TYPE_NORMAL
- en: Contrived DIY solutions that were sometimes employed, based on what was available
    in C++ at the time, included representing a matrix as a `vector` of `vector`(s),
    or holding data in a two-dimensional dynamic C-array. Neither of these was particular
    palatable, with the former being cumbersome and inefficient, and the latter exposing
    the software to the risks associated with raw pointers and dynamic memory management.
    One seemingly useful feature available in the Standard Library, but not without
    controversy, was `std::valarray`. It has survived to the current day, and it provides
    vectorized operations and functions highly suitable for matrix and vector math.
    Its pros and cons will be presented momentarily.
  prefs: []
  type: TYPE_NORMAL
- en: The situation has improved substantially over the years with the release of
    multiple open-source linear algebra libraries for C++. Among these, two that have
    gained considerable critical mass in computational finance are the [Eigen](https://eigen.tuxfamily.org)
    library **{1}**, and [Armadillo](http://arma.sourceforge.net) **{2}**. A third
    option that has risen to some prominence in high-performance computing (HPC) is
    the [Blaze](https://bitbucket.org/blaze-lib/blaze) library **{3}**. An earlier
    library, [uBLAS](https://www.boost.org/doc/libs/1_81_0/libs/numeric/ublas/doc/index.html),
    **{4}** is also available as part of the Boost libraries; however, it does not
    include the matrix decompositions and other capabilities available in the aforementioned
    offerings.
  prefs: []
  type: TYPE_NORMAL
- en: As a side note, open source R interface packages are available for each of these
    libraries. **{5}** These packages enable the integration of C++ code dependent
    on one or more of these libraries into R packages, usually to enhance run-time
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: More recently, NVIDIA has released [GPU-accelerated C++ linear algebra libraries](https://developer.nvidia.com/gpu-accelerated-libraries#linear-algebra)
    as part of its HPC SDK. **{6}**.
  prefs: []
  type: TYPE_NORMAL
- en: A comparative list of both open source and commercial C++ linear algebra libraries,
    including those mentioned here, can be found on [Wikipedia](https://en.wikipedia.org/wiki/Comparison_of_linear_algebra_libraries).**{7}**
    A more in-depth view of the Eigen library follows later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: New features planned for C++23 and C++26 look set to finally provide the Standard
    Library with long overdue robust and well-supported linear algebra capabilities.
    Central among these new features is the `std::mdspan` multi-dimensional array
    representation planned for C++23\. C++26 should then be updated with both a standardized
    interface to external BLAS-compatible libraries, as well as its own set of linear
    algebra facilities.
  prefs: []
  type: TYPE_NORMAL
- en: Below, we will first take a trip back in time and examine convenient mathematical
    features of `valarray`, and then demonstrate how it can be used as a proxy for
    a matrix. Following that, we will dive into the Eigen library of the present and
    demonstrate the basic matrix operations, along with matrix decompositions frequently
    used in financial modeling. Finally, a glimpse of the proposals for near-future
    Standard Library releases will also be presented.
  prefs: []
  type: TYPE_NORMAL
- en: valarray and Matrix Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The workhorse STL container `std::vector`, as we have seen, is an option for
    representing a vector in the mathematical sense. Common vector arithmetic, such
    as inner products, can be performed using STL algorithms. However, having been
    ‚Äúdesigned to be a general mechanism for holding values‚Ä¶‚Äãand to fit into the architecture
    of containers, iterators, and algorithms‚Äù {2.5 Stroustrup, Tour 2E} **{8}**, the
    common arithmetic vector operators such as addition and multiplication were not
    included as members in its implementation.
  prefs: []
  type: TYPE_NORMAL
- en: A Standard Library container class separate from the STL, called `valarray`,
    does support arithmetic operators and provides ‚Äúoptimizations that are often considered
    essential for serious numerical work‚Äù {ibid}. With slice and stride functions
    also accompanying the `valarray` class, it can also facilitate representation
    arrays of higher dimension, in particular a matrix.
  prefs: []
  type: TYPE_NORMAL
- en: While `valarray` has these very useful properties that would seem to make it
    an obvious choice for matrix math, it has played to mixed reviews. This dates
    back to its original specification which was never fully complete due to debates
    over whether to require a new technique at the time, expression templates (to
    be introduced shortly), that can significantly optimize performance. In the end,
    this was not mandated. As a result, [‚Äúinitial implementations were slow, and thus
    users did not want to rely on it.‚Äù](https://wg21.link/p1673) **{9}**
  prefs: []
  type: TYPE_NORMAL
- en: As of the time of this writing, however, two of the mainstream Standard Library
    distributions have implemented expression template versions of `valarray`, namely
    those that accompany the gcc and Clang compilers. In addition, the [Intel oneAPI
    DPC++/C++ Compiler](https://www.intel.com/content/www/us/en/developer/articles/tool/oneapi-standalone-components.html#dpcpp-cpp)
    **{10}** ships with its own high-performance implementation of `valarray`. And
    as an incidental remark, specializations of `begin` and `end` functions were included
    as enhancements in C++11.
  prefs: []
  type: TYPE_NORMAL
- en: 'The moral of the story seems to be: know the capabilities of the implementation
    you intend to use. If its performance is suitable for your needs, then it can
    potentially be a very convenient option for matrix/vector operations, and vectorized
    versions of common mathematical functions. In addition, examining the properties
    of `valarray` may provide some context for future linear algebra enhancements
    planned for the Standard Library, with similar functionality in some cases, even
    though the implementations behind the scenes will be considerably different.'
  prefs: []
  type: TYPE_NORMAL
- en: Arithmetic Operators and Math functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `valarray` container supports the standard arithmetic operators on an element-by-element
    basis, as well as scalar multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the vector sum expression <math alttext="3 bold v 1 plus one-half
    bold v 2"><mrow><mn>3</mn> <msub><mi>ùêØ</mi> <mn>1</mn></msub> <mo>+</mo> <mfrac><mn>1</mn>
    <mn>2</mn></mfrac> <msub><mi>ùêØ</mi> <mn>2</mn></msub></mrow></math> can be naturally
    transcribed from a mathematical statement into C++ using `valarray` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The result is
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Element-by-element* multiplication is also implemented with the `*` operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This gives us
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The dot (or inner) product of <math alttext="v 1"><msub><mi>v</mi> <mn>1</mn></msub></math>
    and <math alttext="v 2"><msub><mi>v</mi> <mn>2</mn></msub></math> is easily obtained
    by summing the preceding result by invoking the `sum()` member function on the
    `valarray` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to `sum`, `valarray` also has `max` and `min` functions, along
    with an `apply(.)` member function that applies an auxiliary function similar
    to `std::transform`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: A subset of the `cmath` functions is conveniently defined for vectorized operations
    on the entirety of a `valarray`. For example, the following operations will return
    a `valarray` containing the images of the respective functions applied to each
    element in `v1` and `neg_val` below. Note that we can also negate each element
    in the same way as a plain numerical type with the subtraction operator.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, as of C++11, specializations of the `begin` and `end` functions analagous
    to those provided for STL containers have been implemented for `valarray`. A simple
    example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Given the `apply(.)` member function on `valarray` and the built-in vectorized
    mathematical functions that are already available, STL algorithms `for_each` and
    `transform` might not be needed as often in the case of `valarray` compared to
    STL containers, however.
  prefs: []
  type: TYPE_NORMAL
- en: valarray as a Matrix Proxy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`valarray` provides the facilities to represent multidimensional arrays. In
    our case, we are specifically concerned with representing a two-dimensional array
    as a proxy for a matrix. This can be achieved with the `slice(.)` member function
    that can extract a reference to an individual row or column.'
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate this, let us first lighten the notation by defining the alias
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, create a `valarray` object `val`, with the code formatted in a way to
    make it look like a 4 <math alttext="times"><mo>√ó</mo></math> 3 matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The first row can be retrieved using the `std::slice` function, defined for
    a `valarray`, using the square bracket operator.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'What this says is:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the first element of the `valarray`: index 0, value = 1.0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose 3 elements, beginning with the first
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a *stride* of 1, which in this case means to choose three consecutive
    rowwise elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Similarly, the second column can be retrieved, using in this case a stride
    of 3, the number of columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: It is important to note the `slice(.)` function returns a lighter `slice_array`
    type‚Äâ‚Äî‚Äâthat acts as a reference to the selected elements‚Äâ‚Äî‚Äârather than a full
    `valarray`. It does not, however, provide the necessary member functions and operators
    to access individual elements or compute, say, new rows comprising a matrix product.
    If we want to apply these functions to row or column data, we will need to construct
    corresponding new `valarray` objects. This will be seen in the next example, computing
    the dot product of a row in one matrix by the column in another, a necessary option
    in carrying out matrix multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate this, suppose we have a 5 <math alttext="times"><mo>√ó</mo></math>
    3 and a 3 <math alttext="times"><mo>√ó</mo></math> 5 matrix, each represented as
    a `valarray`. Note that we are also storing the number of rows and columns of
    each in separate variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If we were to apply matrix multiplication, it would require taking the dot
    product of each row of the first ‚Äúmatrix‚Äù by each column of the second. As an
    example, in order to get the dot product of the third row by the second column,
    we would first need the slice for each:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'However, neither element-by-element multiplication nor the `sum()` member function
    is defined on a `slice_array`, so we need to construct corresponding `valarray`
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The dot product is then computed in the usual way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Caution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As previously noted, a `slice_array` acts as a reference to a block within
    a `valarray`. Operations and member functions such as `\*` and `sum` are not defined
    on `slice_array`, but assignment operators such as `*=` and `+=` are. Therefore,
    modification of a `slice_array` such as in the following example will also be
    reflected in the `valarray` itself. If we take the first row of `va01` as a slice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: and then apply assignment operators
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: then the `valarray` contents would be
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In summary, `valarray` conveniently provides the ability to apply mathematical
    operators and functions on an entire array, similar to Fortran 90, as well as
    more math-focused languages such as R and Matlab . As a reminder, however, performance
    can be highly dependent on the implementation used in your Standard Library distribution.
  prefs: []
  type: TYPE_NORMAL
- en: More information about `valarray`, its history, and its pros and cons can be
    found in [the online supplemental chapter accompanying Josuttis, _The C++ Standard
    Library, second edition](http://www.cppstdlib.com/cppstdlib_supplementary.pdf)).
    **{11}**
  prefs: []
  type: TYPE_NORMAL
- en: Subsequent to `valarray` and C++98, there have been some very positive developments
    regarding linear algebra in C++, some of which will now be presented.
  prefs: []
  type: TYPE_NORMAL
- en: Eigen
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first release of the Eigen library became available in 2006\. Since then,
    it has been expanded to version 3.4.0 as of August of 2021\. Starting with version
    3.3.1, it has been licensed under the reasonably liberal Mozilla Public License
    (MPL) 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: Eigen is comprised of template code that makes inclusion into other C++ projects
    very easy, in that in its standard installation there is no linking necessary
    to external binary files. Its incorporation of expression templates, facilitating
    lazy evaluation, provides for enhanced computational performance. It also received
    a a further boost in popularity after being chosen for incorporation into the
    well-respected [TensorFlow](https://www.tensorflow.org) **{12}** machine learning
    library, as well as the [Stan Math Library](https://mc-stan.org/users/interfaces/math).
    **{13}** More background on its suitability and popularity in finance is presented
    in a recent [Quantstart](https://www.quantstart.com/articles/Eigen-Library-for-Matrix-Algebra-in-C/)
    article **{14}**.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the Eigen library is very well documented, with a tutorial and examples
    to help the newcomer get up and running quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Lazy Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lazy evaluation defers and minimizes the number of operations required in matrix
    and vector operations. Expression templates in C++ are used to encapsulate arithmetic
    operations ‚Äì that is, expressions ‚Äì inside templates such that they are delayed
    until they are actually needed. This can reduce the total number of operations,
    assignments, and temporary objects that are created when using conventional approaches.
  prefs: []
  type: TYPE_NORMAL
- en: An example of lazy evaluation that follows is based on a more comprehensive
    and illustrative discussion in the book by [Peter Gottschling on modern C++ for
    scientific programing](https://www.pearson.com/en-us/subject-catalog/p/discovering-modern-c-/P200000000286/9780136677642).
    **{15}**
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you have four vectors in the mathematical sense, each with the same
    fixed number of elements, say
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="bold v 1 comma bold v 2 comma bold v 3 comma bold v 4" display="block"><mrow><msub><mi>ùêØ</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>ùêØ</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>ùêØ</mi>
    <mn>3</mn></msub> <mo>,</mo> <msub><mi>ùêØ</mi> <mn>4</mn></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: and you wish to store their sum in a vector *y*. The traditional approach would
    be to define the addition operator, take successive sums and store them in temporary
    objects, ultimately computing the final sum and assigning it to *y*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In code, the operator could be defined in the generic sense such that vector
    addition would be defined for any arithmetic type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Computing the sum of four vectors as follows
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 4 - 1 = 3 `vector` instances created (two temporary plus one final `y` instance)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (4 - 1) <math alttext="times"><mo>√ó</mo></math> 3 assignments of `double` variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the number of vectors (say *m*) and the number of elements in each vector
    (say *n*) get larger, this generalizes to
  prefs: []
  type: TYPE_NORMAL
- en: 'm ‚Äì 1 `vector` objects allocated on the heap: m - 2 temporary, plus one return
    object (`y`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis m minus 1 right-parenthesis n"><mrow><mo>(</mo>
    <mi>m</mi> <mo>-</mo> <mn>1</mn> <mo>)</mo> <mi>n</mi></mrow></math> assignments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With lazy evaluation, we can reduce the total number of steps, and thus improve
    efficiency for ‚Äúlarge‚Äù *m* and *n*. More specifically, this can be accomplished
    by delaying the addition until all the data is ready, and then only at that time
    perform the sums for each element in the result. In code, this could be accomplished
    by writing a function as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Now, in this case,
  prefs: []
  type: TYPE_NORMAL
- en: There are *no* temporary `vector` objects created; only the `sum` result is
    necessary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of assignments is reduced to *n* = 4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Eigen documentation provides additional background in the section [Lazy
    Evaluation and Aliasing](https://eigen.tuxfamily.org/dox/TopicLazyEvaluation.html).
  prefs: []
  type: TYPE_NORMAL
- en: The previous example demonstrates how lazy evaluation can work, but the obvious
    problem is it would be unrealistic to write individual sum functions for all possible
    fixed numbers of vectors. Generalizing with expression templates is a far more
    challenging problem that will not be included here, but more information can be
    found in the Gottschling book {ibid 12}, as well as in Chapter 27 of the comprehensive
    book on C++ templates by [Vandevoorde, Josuttis, and Gregor](http://tmplbook.com/)
    **{16}**.
  prefs: []
  type: TYPE_NORMAL
- en: Like any other optimization tool, it should not be applied blindly in the belief
    it will automatically make your code more efficient, as again there are cases
    where performance could actually be degraded.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, for a very interesting presentation of a real-world case study of expression
    templates in financial risk management, a talk on the subject [presented by Bowie
    Owens at CppCon 2019](https://www.youtube.com/watch?v=4IUCBx5fIv0) **{17}** is
    very well worth watching.
  prefs: []
  type: TYPE_NORMAL
- en: Eigen Matrices and Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The heart of the Eigen library is, not surprisingly, the `Matrix` template class.
    It is scoped with the `Eigen` namespace and requires the `Dense` header file be
    included. At the time of this writing, corresponding module imports have not yet
    been standardized. This means the header file will need to be included in the
    global fragment of a module.
  prefs: []
  type: TYPE_NORMAL
- en: The `Matrix` class carries six template parameters, but a variety of aliases
    are provided as specific types. These include fixed square matrix dimensions up
    to a maximum of four, as well as dynamic types for arbitrary numbers of rows and
    columns. The numerical type that a `Matrix` holds is also a template parameter,
    but this setting is also incorporated into individual aliases. For example, the
    following code will construct and display a fixed 3 <math alttext="times"><mo>√ó</mo></math>
    3 matrix of `double` values, and a 4 <math alttext="times"><mo>√ó</mo></math> 4
    matrix of `int`s. Braced (uniform) initialization by row can be used to load the
    data at construction.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Note also that the `<<` stream operator is overloaded, so the result can be
    easily displayed on the screen (in row-major order).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Individual rows and columns can also be accessed, using 0-based indexing. The
    first column of the first matrix, and the third column of the second, for example
    are obtained with respective accessor functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following screen output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Technically speaking, the type returned by either the `row` or `col` accessor
    is an `Eigen::Block`. It is similar to a `slice_array` accessed from a `valarray`,
    in that it acts as a lighter weight reference to the data. Unlike `slice_array`,
    it does not carry any mathematical operators such as `+=`.
  prefs: []
  type: TYPE_NORMAL
- en: For most of the financial examples considered in this book, the dimensions of
    a matrix will not be known a priori, nor will they necessarily be of a square
    matrix. In addition, the contents will usually be real numbers. For these reasons,
    we will primarily be concerned with the Eigen dynamic form for `double` types,
    aliased as `Eigen::MatrixXd`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As just mentioned, we will primarily use the dynamic Eigen `MatrixXd` form of
    a matrix (with `d` indicating `double` numerical elements); however, member and
    non-member functions will usually apply to any class derived from the `Matrix`
    template class. Where these functions are discussed, their relations with `Matrix`
    rather than `MatrixXd` may also be mentioned. Similarly, vector representation
    in Eigen will use `VectorXd`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Linear algebra will inevitably involve subscripts and superscripts, eg <math
    alttext="x Subscript i j"><msub><mi>x</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></math>
    , where in mathematical notation *i* might run from 1 to *m*, and *j* from 1 to
    *n*. However, C++ is 0-indexed, so a mathematical statement where *i* = 1 will
    be represented by `i = 0` in C++, *j* = *n* by `j = n - 1`, and so forth.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Construction of a `MatrixXd` can take on many forms. Data can be entered as
    before in row-major order, with the number of rows and columns implied by uniform
    initialization of individual rows. Alternatively, the dimensions can be used as
    constructor arguments, with the data input by streaming in row-major order. And,
    one more approach is to set each element one-by-one. An example of each is shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note that the round bracket operator serves as both a mutator and an accessor,
    as demonstrated in the third example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two special cases, where either the number of columns or rows is one, are aliased
    as `VectorXd` and `RowVectorXd`. Construction options are similar to the `MatrixXd`
    examples above, again as shown in the Eigen documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Matrix and Vector Math Operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Matrix addition and subtraction are are conveniently implemented as overloads
    of the `+` and `-` operators, not unlike `valarray`. Similarly, these apply to
    vectors. Unlike `valarray`, however, the multiplication operator `*` refers to
    matrix multiplication rather than an element-by-element product. A separate set
    of functions is available for a wide range of element-by-element operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To multiply two matrices `A` and `B`, the code follows in natural mathematical
    order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us as output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Caution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the Eigen documentation, it is strongly recommended to ‚Äúnot use the auto
    keywords with Eigen‚Äôs expressions, unless you are 100% sure about what you are
    doing. In particular, do not use the auto keyword as a replacement for a `Matrix<>`
    type.‚Äù
  prefs: []
  type: TYPE_NORMAL
- en: The reasons behind this require an advanced discussion about templates that
    tie in with lazy evaluation. Lazy Evaluation provides advantages in efficiency,
    but it also can involve return types using `auto` that might be in the form of
    a reference rather than a full `Matrix` type. This can result in unexpected or
    undefined behavior. It becomes less of an issue as you become more familiar with
    various Eigen types, but for this introductory presentation, we will mostly heed
    this admonishment.
  prefs: []
  type: TYPE_NORMAL
- en: More information can be found [in the documentation](https://eigen.tuxfamily.org/dox/TopicPitfalls.html).
    **{18}**
  prefs: []
  type: TYPE_NORMAL
- en: 'The `*` operator is also overloaded for matrix-vector and row vector-matrix
    multiplication. As an example, suppose we have a portfolio of three funds, with
    correlation matrix of the returns and the vector of individual fund volatilities
    given (annualized). As is a typical problem, we might need to construct the covariance
    matrix given the data in this form in order to calculate the portfolio volatility.
    First, to form the covariance matrix, we would pre- and post-multiply the correlation
    matrix by diagonal matrices containing the fund volatilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Note how the `VectorXd` member function `asDiagonal()` conveniently forms a
    diagonal matrix with the vector elements along the diagonal.
  prefs: []
  type: TYPE_NORMAL
- en: Then, given a vector of fund weights <math alttext="omega"><mi>œâ</mi></math>
    adding to 1, the portfolio volatility is then the square root of the quadratic
    form
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="omega Superscript sans-serif upper T Baseline bold upper Sigma
    omega" display="block"><mrow><msup><mi>œâ</mi> <mi>ùñ≥</mi></msup> <mi>Œ£</mi> <mi>œâ</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'where <math alttext="bold upper Sigma"><mi>Œ£</mi></math> is the covariance
    matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'For element-by-element matrix multiplication, use the `cwiseProduct` member
    function. As an example, to multiply the individual elements in matrices of like
    dimension, say <math alttext="bold upper A"><mi>ùêÄ</mi></math> and <math alttext="bold
    upper B Superscript sans-serif upper T"><msup><mi>ùêÅ</mi> <mi>ùñ≥</mi></msup></math>
    , we would write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: There is in fact a set of `cwise...` (meaning *coefficient-wise*) member functions
    on an Eigen `Matrix` that perform element-by-element operations on two compatible
    matrices, such as `cwiseQuotient` and `cwiseNotEqual`. There are also unary `cwise`
    member functions that return the absolute value and square root of each element.
    These can be found in the [Eigen documentation](https://eigen.tuxfamily.org/dox/group__QuickRefPage.html#title6)
    here. **{19}**
  prefs: []
  type: TYPE_NORMAL
- en: The result of the `*` operator when applied to two vectors depends upon which
    vector is transposed. For two vectors u and v, the dot (inner) product is computed
    as
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="bold u Superscript sans-serif upper T Baseline bold v" display="block"><mrow><msup><mi>ùêÆ</mi>
    <mi>ùñ≥</mi></msup> <mi>ùêØ</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'while the outer product results when the transpose is applied to v:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><msup><mstyle style="font-weight:bold"><mi>u</mi> <mi>v</mi></mstyle>
    <mi>T</mi></msup></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'So, one needs to be careful when using the `*` operator with vectors. Suppose
    we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The respective results of the following vector multiplications will be different:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The first would result in a real value of 2.5, while the second would give
    us a singular 3 <math alttext="times"><mo>√ó</mo></math> 3 matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: To make life easier, Eigen provides a member function, `dot`, on the `VectorXd`
    class. By instead writing
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: it should perhaps make it clearer which product we want. The result would be
    the same as before, plus the operation is commutative.
  prefs: []
  type: TYPE_NORMAL
- en: STL Compatibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A very nice feature of both the Eigen `Vector` and `Matrix` classes is their
    compatibility with the Standard Template Library. This means you can iterate through
    an Eigen container, apply STL algorithms, and exchange data with STL containers.
  prefs: []
  type: TYPE_NORMAL
- en: STL and `VectorXd`
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As a first example, suppose you wish to generate 12 random variates from a
    t-distribution and place the results in a `VectorXd` container. The process is
    essentially the same as what we saw using a `std::vector` and applying the `std::generate`
    algorithm with a lambda auxiliary function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Prior to the recent Eigen 3.4 release, the `begin` and `end` member functions
    were not defined. In this case, you would need to instead use the `data` and `size`
    functions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Non-modifying algorithms such as `std::max_element` are also valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Numeric algorithms, for example `std::inner_product`, can also be applied:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The cleaner C++20 range versions are also supported on `VectorXd`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Constructing a Matrix from STL Container Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Matrix data can also be obtained from STL containers. This is convenient, as
    data can often arrive via interfaces from other sources where Eigen might not
    be included. The key is to use an `Eigen::Map`, which sets up a reference to (view
    of) the `vector` data rather than taking a copy of it.
  prefs: []
  type: TYPE_NORMAL
- en: As a first example, data residing in a `std::vector` container can be transferred
    to an `Eigen::Map`, which in turn can be used as the constructor argument for
    a `MatrixXd`. Note that the `Map` takes in a pointer to the first element in the
    `vector` (using the `data` member function), and the number of rows and columns,
    in its constructor.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, `mtx_map` will provide row/column access to the data. Note that
    unlike creating a `MatrixXd` as before with an initializer list of data, the order
    will be column-major rather than row-major. Using `cout` yields the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'As a `Map` is a lighter weight view of the data in `v`, it does not carry with
    it all of the functionality as found on a `Matrix` object, in a sense similar
    to a slice taken from a`valarray`. If you need this functionality, then you can
    construct a `MatrixXd` instance by putting the `Map` object in its constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The default arrangement of the data in a `Map` will be in *column-major order*,
    which is different from the earlier `MatrixXd` examples constructed with numerical
    data. If row-major is required, you can specify row-major at the outset, but this
    will require an `Eigen::Matrix` template parameter with storage explicitly set
    to `RowMajor`, as `MatrixXd` does not have its own template parameter for storage
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'If the matrix is square, you can just transpose the `Map` in place to put it
    in row-major order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is then:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Attempting to transpose a non-square matrix using `Map` can result in a program
    crash. In this case, you will need to create a full `MatrixXd` object before applying
    `transposeInPlace`.
  prefs: []
  type: TYPE_NORMAL
- en: Applying STL Algorithms to a Matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'STL algorithms can also be applied to matrices row by row, or column by column.
    Suppose we have a 4 <math alttext="times"><mo>√ó</mo></math> 3 matrix as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The `rowwise()` member function on an Eigen `Matrix` sets up an iteration by
    row. Each `row` is a reference to (view of) the respective data, so we can square
    each element of the matrix in place as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The `colwise()` member function is similar, in this case sorting each column
    of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: The end result after applying both algorithms gives us
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Each element has been squared, and each column has been rearranged in ascending
    order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Financial programmers often need to write code that will compute the log returns
    on a set of equity or fund prices. For example, suppose we have a set of 11 monthly
    prices for three ETF‚Äôs, in the following three columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step in computing log returns is to compute the natural log of each
    price. This can be done by applying the `transform` algorithm row by row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, to get the log returns, we need to subtract from each log price its predecessor.
    For this, we can apply the `adjacent_difference` numeric algorithm to each column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This result is still an 11 <math alttext="times"><mo>√ó</mo></math> 3 matrix,
    with the first row still containing the logs of the prices in the first row.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'What we want are the monthly returns alone, so we need to remove the first
    row. This can be achieved by applying the `seq` function, introduced in Eigen
    3.4, which provides an intuitive way of extracting a submatrix view (an `Eigen::Block`)
    from a `Matrix` object. The example here shows how to extract all rows below the
    first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'What this says is:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with the second row (index 1) and include all rows down to the last row:
    `Eigen::seq(1, Eigen::last)`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Take all columns from the first (index 0) to the last: `Eigen::seq(0, Eigen::last)`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use this submatrix data alone in the constructor for the resulting `returns_mtx`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The results held in `returns_mtx` are then the log returns alone:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, suppose the portfolio allocation is fixed at 35%, 40%, and 25% for each
    respective fund (columnwise). We can get the monthly portfolio returns by multiplying
    the vector of allocations by `returns_mtx`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The result is
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Matrix Decompositions and Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Matrix decompositions are of course essential for a variety of financial engineering
    problems. Below, we will discuss a few examples.
  prefs: []
  type: TYPE_NORMAL
- en: Systems of Linear Equations and the LU Decomposition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Systems of linear equations are ubiquitous in finance and economics, particularly
    in optimization, hedging, and forecasting problems. To show how solutions can
    be found in Eigen, let us just look at a generic problem and implement it in code.
    The LU (Lower/Upper-triangular matrix) decomposition is a common approach in numerical
    methods. As opposed to coding it ourselves, Eigen can get the job done in two
    lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we want to solve the following system of linear equations for <math
    alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> , <math alttext="x 2"><msub><mi>x</mi>
    <mn>2</mn></msub></math> , and <math alttext="x 3"><msub><mi>x</mi> <mn>3</mn></msub></math>
    :'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="3 x 1 minus 5 x 2 plus x 3 equals 0" display="block"><mrow><mn>3</mn>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo> <mn>5</mn> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>=</mo> <mn>0</mn></mrow></math><math
    alttext="minus x 1 minus x 2 plus x 3 equals negative 4" display="block"><mrow><mo>-</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>=</mo> <mo>-</mo> <mn>4</mn></mrow></math><math
    alttext="2 x 1 minus 4 x 2 plus x 3 equals negative 1" display="block"><mrow><mn>2</mn>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo> <mn>4</mn> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>=</mo> <mo>-</mo> <mn>1</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This sets up the usual matrix equation
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="bold upper A bold x equals bold b" display="block"><mrow><mi>ùêÄùê±</mi>
    <mo>=</mo> <mi>ùêõ</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="bold x equals Start 1 By 3 Matrix 1st Row 1st Column x 1 2nd
    Column x 2 3rd Column x 3 EndMatrix Superscript sans-serif upper T" display="block"><mrow><mi>ùê±</mi>
    <mo>=</mo> <msup><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>1</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The matrix <math alttext="bold upper A"><mi>ùêÄ</mi></math> contains the coefficients,
    and the column vector <math alttext="bold b"><mi>ùêõ</mi></math> contains the constants
    on the right-hand side of the equations. The LU algorithm decomposes the matrix
    <math alttext="bold upper A"><mi>ùêÄ</mi></math> into the product of lower- and
    upper-triangular matrices <math alttext="bold upper L"><mi>ùêã</mi></math> and <math
    alttext="bold upper U"><mi>ùêî</mi></math> in order to solve for <math alttext="bold
    x"><mi>ùê±</mi></math> .
  prefs: []
  type: TYPE_NORMAL
- en: 'In Eigen, form the matrix <math alttext="bold upper A"><mi>ùêÄ</mi></math> and
    the vector <math alttext="bold b"><mi>ùêõ</mi></math> :'
  prefs: []
  type: TYPE_NORMAL
- en: _
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to create an instance of the `Eigen::FullPivLU` class with
    template parameter `MatrixXd`. This sets up the LU decomposition. To find the
    vector containing the solution, all that is left to do is call the `solve(.)`
    member function on this object. This means two lines of code, as promised:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The solution for `x` is then (from top to bottom <math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> , <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    , <math alttext="x 3"><msub><mi>x</mi> <mn>3</mn></msub></math> )
  prefs: []
  type: TYPE_NORMAL
- en: _
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Several other decomposition methods are available in Eigen for solving linear
    systems, where as is often the case a choice between speed and accuracy needs
    to be considered. The LU decomposition in the example above is among the best
    for accuracy, although there are others that may be faster but do not offer the
    same level of stability. The complete list can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Basic linear solving](http://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html)
    **{20}**'
  prefs: []
  type: TYPE_NORMAL
- en: 'A comparison of the matrix decomposition methods in Eigen is also available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Catalogue of decompositions offered by Eigen](http://eigen.tuxfamily.org/dox/group__TopicLinearAlgebraDecompositions.html)
    **{21}**'
  prefs: []
  type: TYPE_NORMAL
- en: Fund Tracking with Multiple Regression and the Singular Value Decomposition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another common programming problem in finance is fund tracking with multiple
    regression. Examples include
  prefs: []
  type: TYPE_NORMAL
- en: Tracking whether a fund of hedge funds is following its stated allocation targets
    by regressing its returns on a set of hedge fund style index returns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking the sensitivity of a portfolio to changes in different market sectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking the goodness of fit of mutual funds offered in guaranteed investment
    products such as variable annuities, with respect to their respective fund group
    benchmarks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In multiple regression, one is tasked with finding a vector
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove beta With caret equals Start 1 By 4 Matrix 1st
    Row 1st Column beta 1 2nd Column beta 2 3rd Column  ellipsis 4th Column beta Subscript
    n EndMatrix Superscript sans-serif upper T Baseline slash slash ModifyingAbove
    beta With caret equals Start 1 By 4 Matrix 1st Row 1st Column beta 1 2nd Column
    beta 2 3rd Column  ellipsis 4th Column beta Subscript n EndMatrix Superscript
    down-tack Baseline slash slash Start 1 By 4 Matrix 1st Row 1st Column beta 1 2nd
    Column beta 2 3rd Column  ellipsis 4th Column beta Subscript n Baseline EndMatrix
    slash slash ModifyingAbove beta With caret equals Start 1 By 4 Matrix 1st Row
    1st Column beta 1 2nd Column beta 2 3rd Column  ellipsis 4th Column beta Subscript
    n Baseline EndMatrix slash slash ModifyingAbove beta With caret equals Start 1
    By 4 Matrix 1st Row 1st Column beta 1 2nd Column beta 2 3rd Column  ellipsis 4th
    Column beta Subscript n EndMatrix Superscript sans-serif upper T Baseline slash
    slash Start 1 By 3 Matrix 1st Row 1st Column w Subscript t Superscript left-parenthesis
    1 right-parenthesis Baseline 2nd Column  ellipsis 3rd Column w Subscript t Superscript
    left-parenthesis m right-parenthesis Baseline EndMatrix slash slash ModifyingAbove
    beta With caret equals left-bracket beta 1 beta 2 ellipsis beta Subscript n Baseline
    right-bracket Superscript sans-serif upper T" display="block"><mrow><mover accent="true"><mi>Œ≤</mi>
    <mo>^</mo></mover> <mo>=</mo> <msup><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>Œ≤</mi>
    <mn>1</mn></msub></mtd> <mtd><msub><mi>Œ≤</mi> <mn>2</mn></msub></mtd> <mtd><mo>‚ãØ</mo></mtd><mtd><msub><mi>Œ≤</mi>
    <mi>n</mi></msub></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi></msup> <mo>/</mo>
    <mo>/</mo> <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover> <mo>=</mo> <msup><mfenced
    open="[" close="]"><mtable><mtr><mtd><msub><mi>Œ≤</mi> <mn>1</mn></msub></mtd>
    <mtd><msub><mi>Œ≤</mi> <mn>2</mn></msub></mtd> <mtd><mo>‚ãØ</mo></mtd><mtd><msub><mi>Œ≤</mi>
    <mi>n</mi></msub></mtd></mtr></mtable></mfenced> <mi>‚ä§</mi></msup> <mo>/</mo>
    <mo>/</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>Œ≤</mi> <mn>1</mn></msub></mtd>
    <mtd><msub><mi>Œ≤</mi> <mn>2</mn></msub></mtd> <mtd><mo>‚ãØ</mo></mtd> <mtd><msub><mi>Œ≤</mi>
    <mi>n</mi></msub></mtd></mtr></mtable></mfenced> <mo>/</mo> <mo>/</mo> <mover
    accent="true"><mi>Œ≤</mi> <mo>^</mo></mover> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><msub><mi>Œ≤</mi>
    <mn>1</mn></msub></mrow></mtd> <mtd><msub><mi>Œ≤</mi> <mn>2</mn></msub></mtd> <mtd><mo>‚ãØ</mo></mtd>
    <mtd><msub><mi>Œ≤</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced> <mo>/</mo>
    <mo>/</mo> <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover> <mo>=</mo> <msup><mfenced
    open="[" close="]"><mtable><mtr><mtd><mrow><msub><mi>Œ≤</mi> <mn>1</mn></msub></mrow></mtd>
    <mtd><msub><mi>Œ≤</mi> <mn>2</mn></msub></mtd> <mtd><mo>‚ãØ</mo></mtd><mtd><msub><mi>Œ≤</mi>
    <mi>n</mi></msub></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi></msup> <mo>/</mo>
    <mo>/</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><msubsup><mi>w</mi> <mi>t</mi>
    <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msubsup></mtd> <mtd><mo>‚ãØ</mo></mtd>
    <mtd><msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></mtd></mtr></mtable></mfenced>
    <mo>/</mo> <mo>/</mo> <mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover> <mo>=</mo>
    <msup><mrow><mo>[</mo><msub><mi>Œ≤</mi> <mn>1</mn></msub> <msub><mi>Œ≤</mi> <mn>2</mn></msub>
    <mo>‚ãØ</mo><msub><mi>Œ≤</mi> <mi>n</mi></msub> <mo>]</mo></mrow> <mi>ùñ≥</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: that satisfies the matrix form of the normal equations
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mover><mi>ùõÉ</mi> <mo stretchy="false" style="math-style:normal;math-depth:0;">^</mo></mover>
    <mo>=</mo> <msup><mrow><mo fence="true" form="prefix">[</mo> <mtable columnalign="center"><mtr><mtd><mrow><msup><mi
    mathvariant="bold">X</mi> <mi>ùñ≥</mi></msup> <mi mathvariant="bold">X</mi></mrow></mtd></mtr></mtable>
    <mo fence="true" form="postfix">]</mo></mrow> <mrow><mo>‚àí</mo> <mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mi>ùñ≥</mi></msup> <mi mathvariant="bold">Y</mi>
    <mo lspace="0em" rspace="0em">‚ÅÑ</mo> <mo lspace="0em" rspace="0em">‚ÅÑ</mo> <mover><mi>ùõÉ</mi>
    <mo stretchy="false" style="math-style:normal;math-depth:0;">^</mo></mover> <mo>=</mo>
    <mo form="prefix" stretchy="false">[</mo> <msup><mi mathvariant="bold">X</mi>
    <mi>ùñ≥</mi></msup> <mi mathvariant="bold">X</mi> <msup><mo form="postfix" stretchy="false">]</mo>
    <mrow><mo>‚àí</mo> <mn>1</mn></mrow></msup> <msup><mi mathvariant="bold">X</mi>
    <mi>ùñ≥</mi></msup> <mi>ùê≤</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="bold upper X"><mi>ùêó</mi></math> is the design matrix containing
    *p* columns of independent variable data, and *n* observations (rows), with the
    number of observations *n* ‚Äúcomfortably‚Äù greater than the number of data columns
    *p* to ensure stability. This is typically the case in these types of fund tracking
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For fund tracking applications, the intercept term <math alttext="beta 0"><msub><mi>Œ≤</mi>
    <mn>0</mn></msub></math> can usually be dropped, so it is omitted here. For regression
    cases where an intercept is required, a final column of ones needs to be appended
    to the design matrix when using Eigen. _
  prefs: []
  type: TYPE_NORMAL
- en: A commonly employed solution is the compact Singular Value Decomposition (SVD),
    which replaces the matrix <math alttext="bold upper X"><mi>ùêó</mi></math> with
    the decomposition <math alttext="bold upper U bold upper Sigma bold upper V Superscript
    upper T"><mrow><mi>ùêî</mi> <mi>Œ£</mi> <msup><mi>ùêï</mi> <mi>T</mi></msup></mrow></math>
    , where <math alttext="bold upper U"><mi>ùêî</mi></math> is an <math alttext="n
    times p"><mrow><mi>n</mi> <mo>√ó</mo> <mi>p</mi></mrow></math> matrix, <math alttext="bold
    upper V"><mi>ùêï</mi></math> is <math alttext="p times p"><mrow><mi>p</mi> <mo>√ó</mo>
    <mi>p</mi></mrow></math> , and <math alttext="bold upper Sigma"><mi>Œ£</mi></math>
    is a <math alttext="p times p"><mrow><mi>p</mi> <mo>√ó</mo> <mi>p</mi></mrow></math>
    diagonal matrix of strictly positive values. Making this substitution in the original
    formula for <math alttext="ModifyingAbove beta With caret"><mover accent="true"><mi>Œ≤</mi>
    <mo>^</mo></mover></math> , we get
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove beta With caret equals bold upper V bold upper
    Sigma bold upper U Superscript sans-serif upper T Baseline bold y" display="block"><mrow><mover
    accent="true"><mi>Œ≤</mi> <mo>^</mo></mover> <mo>=</mo> <mi>ùêï</mi> <mi>Œ£</mi> <msup><mi>ùêî</mi>
    <mi>ùñ≥</mi></msup> <mi>ùê≤</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Eigen provides two SVD solvers that can be used for obtaining the least squares
    estimates of the regression coefficients. The first of these, as described in
    the Eigen documentation, is the [Jacobi SVD decomposition of a rectangular matrix_](https://eigen.tuxfamily.org/dox-devel/classEigen_1_1JacobiSVD.html)
    **{22}**. The documentation also states the Jacobi version is recommended for
    design matrices of 16 columns or less, which is sometimes sufficient for fund
    tracking problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The way this works is given the design matrix predictor data contained in a
    `MatrixXd X`, Eigen sets up the SVD logic inside the class template `Eigen::JacobiSVD`.
    Then, given the response data contained in a `VectorXd Y`, solving for <math alttext="ModifyingAbove
    beta With caret"><mover accent="true"><mi>Œ≤</mi> <mo>^</mo></mover></math> is
    again just two lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The `Eigen::ComputeThinU | Eigen::ComputeThinV` bitwise-or parameter instructs
    the program to use the compact version of SVD. If the full SVD is desired, then
    the above `JacobiSVD` instantiation would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the <math alttext="bold upper U"><mi>ùêî</mi></math> matrix will
    be <math alttext="n times n"><mrow><mi>n</mi> <mo>√ó</mo> <mi>n</mi></mrow></math>
    , and <math alttext="bold upper Sigma"><mi>Œ£</mi></math> will be an <math alttext="n
    times p"><mrow><mi>n</mi> <mo>√ó</mo> <mi>p</mi></mrow></math> pseudoinverse.
  prefs: []
  type: TYPE_NORMAL
- en: There are no default settings.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, suppose we have three sector ETF‚Äôs and wish to examine their
    relationship to the broader market (eg the S&P 500), and suppose we have 30 daily
    observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The design matrix will contain the three ETF returns and is stored in a `MatrixXd`
    called `X`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the market returns are stored in a `VectorXd` array `Y`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Obtaining the regression coefficients is just a matter of compiling and running
    the SVD using the two lines of code shown at the outset, which gives us for `beta`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The <math alttext="bold upper U"><mi>ùêî</mi></math> and <math alttext="bold
    upper V"><mi>ùêï</mi></math> matrices can also be obtained if desired, along with
    the <math alttext="bold upper Sigma"><mi>Œ£</mi></math> matrix, using the following
    accessor functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: An alternative SVD solver, the [*Bidiagonal Divide and Conquer SVD*](https://eigen.tuxfamily.org/dox-devel/classEigen_1_1BDCSVD.html),
    **{23}** is also available in Eigen. Per the documentation, it is recommended
    for design matrices with greater than 16 columns for better performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The setup is the same as the Jacobi case, but using the `BDCSVD` class in place
    of `JacobiSVD`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: It should be noted Eigen also provides QR decompositions as well as the capability
    of just coding in the normal equations with Eigen matrices and operations. As
    noted in the documentation, [*Solving linear least squares systems*](https://eigen.tuxfamily.org/dox-devel/group__LeastSquares.html),
    these can be faster than SVD methods, but they can be less accurate. **{24}**
    These are alternatives you might want to consider if speed is an issue, but under
    the right conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Correlated Random Equity Paths and the Cholesky Decomposition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Cholesky decomposition is a popular tool in finance for generating correlated
    Monte Carlo equity path simulations. For example, when pricing basket options,
    covariances between movements in the basket securities need to be accounted for,
    specifically in generating correlated random normal draws. This is in contrast
    to generating a random price path for a single underlying security, as we saw
    in Chapter 8:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper S Subscript t Baseline equals upper S Subscript t minus
    1 Baseline e Superscript left-parenthesis StartFraction r minus sigma squared
    Over 2 EndFraction right-parenthesis normal upper Delta t plus sigma epsilon Super
    Subscript t Superscript StartRoot normal upper Delta t EndRoot" display="block"><mrow><msub><mi>S</mi>
    <mi>t</mi></msub> <mo>=</mo> <msub><mi>S</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <msup><mi>e</mi> <mrow><mrow><mo>(</mo><mfrac><mrow><mi>r</mi><mo>-</mo><msup><mi>œÉ</mi>
    <mn>2</mn></msup></mrow> <mn>2</mn></mfrac><mo>)</mo></mrow><mi>Œî</mi><mi>t</mi><mo>+</mo><mi>œÉ</mi><msub><mi>Œµ</mi>
    <mi>t</mi></msub> <msqrt><mrow><mi>Œî</mi><mi>t</mi></mrow></msqrt></mrow></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where again <math alttext="epsilon Subscript t Baseline tilde upper N left-parenthesis
    0 comma 1 right-parenthesis"><mrow><msub><mi>Œµ</mi> <mi>t</mi></msub> <mo>‚àº</mo>
    <mi>N</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <mn>1</mn> <mo>)</mo></mrow></mrow></math>
    , <math alttext="sigma"><mi>œÉ</mi></math> is the equity volatility, and <math
    alttext="r"><mi>r</mi></math> represents the risk-free interest rate,
  prefs: []
  type: TYPE_NORMAL
- en: In the case of a basket option, we now need to generate a path for each of say
    *m* assets at each time <math alttext="t"><mi>t</mi></math> , where the <math
    alttext="sigma epsilon Subscript t"><mrow><mi>œÉ</mi> <msub><mi>Œµ</mi> <mi>t</mi></msub></mrow></math>
    term is replaced by a random term <math alttext="w Subscript t Superscript left-parenthesis
    i right-parenthesis"><msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup></math>
    that is again based on a standard normal draw, but whose fluctuations also contain
    correlations with the other assets in the basket. Therefore, we need to generate
    a set of prices <math alttext="StartSet upper S Subscript t Superscript left-parenthesis
    i right-parenthesis Baseline EndSet"><mfenced separators="" open="{" close="}"><msubsup><mi>S</mi>
    <mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup></mfenced></math>
    where
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper S Subscript t Superscript left-parenthesis 1 right-parenthesis
    Baseline equals upper S Subscript t minus 1 Superscript left-parenthesis 1 right-parenthesis
    Baseline e Superscript left-parenthesis StartFraction r minus sigma squared Over
    2 EndFraction right-parenthesis normal upper Delta t plus w Super Subscript t
    Super Superscript left-parenthesis 1 right-parenthesis Superscript StartRoot normal
    upper Delta t EndRoot Baseline left-parenthesis asterisk right-parenthesis" display="block"><mrow><msubsup><mi>S</mi>
    <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msubsup> <mo>=</mo> <msubsup><mi>S</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msubsup>
    <msup><mi>e</mi> <mrow><mrow><mo>(</mo><mfrac><mrow><mi>r</mi><mo>-</mo><msup><mi>œÉ</mi>
    <mn>2</mn></msup></mrow> <mn>2</mn></mfrac><mo>)</mo></mrow><mi>Œî</mi><mi>t</mi><mo>+</mo><msubsup><mi>w</mi>
    <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msubsup> <msqrt><mrow><mi>Œî</mi><mi>t</mi></mrow></msqrt></mrow></msup>
    <mrow><mo>(</mo> <mo>*</mo> <mo>)</mo></mrow></mrow></math><math alttext="period"
    display="block"><mo>.</mo></math><math alttext="period" display="block"><mo>.</mo></math><math
    alttext="period" display="block"><mo>.</mo></math><math alttext="upper S Subscript
    t Superscript left-parenthesis m right-parenthesis Baseline equals upper S Subscript
    t minus 1 Superscript left-parenthesis m right-parenthesis Baseline e Superscript
    left-parenthesis StartFraction r minus sigma squared Over 2 EndFraction right-parenthesis
    normal upper Delta t plus w Super Subscript t Super Superscript left-parenthesis
    m right-parenthesis Superscript StartRoot normal upper Delta t EndRoot" display="block"><mrow><msubsup><mi>S</mi>
    <mi>t</mi> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup> <mo>=</mo> <msubsup><mi>S</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup>
    <msup><mi>e</mi> <mrow><mrow><mo>(</mo><mfrac><mrow><mi>r</mi><mo>-</mo><msup><mi>œÉ</mi>
    <mn>2</mn></msup></mrow> <mn>2</mn></mfrac><mo>)</mo></mrow><mi>Œî</mi><mi>t</mi><mo>+</mo><msubsup><mi>w</mi>
    <mi>t</mi> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup> <msqrt><mrow><mi>Œî</mi><mi>t</mi></mrow></msqrt></mrow></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: for each asset <math alttext="i equals 1 comma ellipsis comma m"><mrow><mi>i</mi>
    <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>‚ãØ</mo> <mo>,</mo> <mi>m</mi></mrow></math>
    at each time step <math alttext="t Subscript j Baseline comma j equals 1 comma
    ellipsis comma n"><mrow><msub><mi>t</mi> <mi>j</mi></msub> <mo>,</mo> <mi>j</mi>
    <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>‚ãØ</mo> <mo>,</mo> <mi>n</mi></mrow></math>
    . Our task is to calculate the random but correlated vector
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 1 By 3 Matrix 1st Row 1st Column w Subscript t Superscript
    left-parenthesis 1 right-parenthesis 2nd Column  ellipsis 3rd Column w Subscript
    t Superscript left-parenthesis m right-parenthesis EndMatrix Superscript sans-serif
    upper T" display="block"><msup><mfenced open="[" close="]"><mtable><mtr><mtd><msubsup><mi>w</mi>
    <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msubsup></mtd> <mtd><mo>‚ãØ</mo></mtd><mtd><msubsup><mi>w</mi>
    <mi>t</mi> <mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></mtd></mtr></mtable></mfenced>
    <mi>ùñ≥</mi></msup></math>
  prefs: []
  type: TYPE_NORMAL
- en: for each time <math alttext="t"><mi>t</mi></math> . This is where the Cholesky
    decomposition ‚Äì available in Eigen ‚Äì comes into play. For an <math alttext="n
    times n"><mrow><mi>n</mi> <mo>√ó</mo> <mi>n</mi></mrow></math> covariance matrix
    <math alttext="bold upper Sigma"><mi>Œ£</mi></math> , assuming it is positive definite,
    will have a Cholesky decomposition
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="bold upper Sigma equals upper L upper L Superscript sans-serif
    upper T" display="block"><mrow><mi>Œ£</mi> <mo>=</mo> <mi>L</mi> <msup><mi>L</mi>
    <mi>ùñ≥</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where *L* is a lower triangular matrix. Then, for a vector of standard normal
    variates <math alttext="bold z"><mi>ùê≥</mi></math> ,
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 1 By 4 Matrix 1st Row 1st Column z 1 2nd Column z 2 3rd
    Column  ellipsis 4th Column z Subscript m EndMatrix Superscript sans-serif upper
    T" display="block"><msup><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>z</mi>
    <mn>1</mn></msub></mtd> <mtd><msub><mi>z</mi> <mn>2</mn></msub></mtd> <mtd><mo>‚ãØ</mo></mtd><mtd><msub><mi>z</mi>
    <mi>m</mi></msub></mtd></mtr></mtable></mfenced> <mi>ùñ≥</mi></msup></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'the <math alttext="n times 1"><mrow><mi>n</mi> <mo>√ó</mo> <mn>1</mn></mrow></math>
    vector generated by <math alttext="bold upper L bold z Superscript sans-serif
    upper T"><mrow><mi>ùêã</mi> <msup><mi>ùê≥</mi> <mi>ùñ≥</mi></msup></mrow></math> will
    provide a set of correlated volatilities that can be used to generate in a single
    time step a random scenario of prices for each underlying security. For each time
    step <math alttext="t"><mi>t</mi></math> , we replace <math alttext="bold z"><mi>ùê≥</mi></math>
    with <math alttext="bold z Subscript bold t"><msub><mi>ùê≥</mi> <mi>ùê≠</mi></msub></math>
    to then arrive at our desired result:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="bold w Subscript bold t Baseline equals bold upper L bold z Subscript
    t Superscript sans-serif upper T" display="block"><mrow><msub><mi>ùê∞</mi> <mi>ùê≠</mi></msub>
    <mo>=</mo> <msubsup><mi>ùêãùê≥</mi> <mi>t</mi> <mi>ùñ≥</mi></msubsup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This can then be extended an arbitrary number of n time steps by placing each
    vector <math alttext="bold z Subscript bold t"><msub><mi>ùê≥</mi> <mi>ùê≠</mi></msub></math>
    into a column of a matrix, say <math alttext="bold upper Z"><mi>ùêô</mi></math>
    . Then, we can generate the entire set of vectors of correlated random variables
    in one step, and place the results in a matrix
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="bold upper W equals bold upper L bold upper Z" display="block"><mrow><mi>ùêñ</mi>
    <mo>=</mo> <mi>ùêãùêô</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Eigen provides a Cholesky decomposition of a `MatrixXd` object, using the `Eigen::LLT`
    class template with parameter `MatrixXd`. It again consists of creating an object
    of this class, and then calling a member function, `matrixL`, which returns the
    matrix <math alttext="bold upper L"><mi>ùêã</mi></math> above.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, suppose we have four securities in the basket, with the following
    covariance matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The Cholesky decomposition is set up when the matrix data is used to construct
    the `Eigen::LLT` object. Calling the member function `matrixL()` computes the
    decomposition and returns the resulting lower triangle matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: This gives us
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Suppose now there will be six time steps in the Monte Carlo model over a period
    of one year. This means we will need six vectors containing four standard normal
    variates each. For this, we can use the Standard Library `<random>` functions
    and generate a 4 <math alttext="times"><mo>√ó</mo></math> 6 matrix, and place the
    random vectors in consecutive columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a `MatrixXd` object with four rows and six columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step will be to populate this matrix with uncorrelated standard normal
    draws. As we did previously (in Chapter 8), we can set up a random engine and
    distribution, and capture these in a lambda to generate the standard normal variates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Because each column in a `MatrixXd` can be accessed as a `VectorXd`, we can
    again iterate columnwise through the matrix and apply the `std::ranges::transform`
    algorithm to each in a range-based `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'This interim result would resemble the following, with actual results depending
    on the compiler (in this case using the Microsoft Visual Studio 2022 compiler):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: Then, to get the *correlated* normal values, multiply the above result by the
    Cholesky matrix, and reassign `corr_norms` to the result.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'This result, which corresponds to the matrix <math alttext="bold upper W"><mi>ùêñ</mi></math>
    in the mathematical derivation, comes out to be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Each successive column in `corr_norms` will provide a set of four correlated
    random variates that can be substituted in for <math alttext="w Subscript t Superscript
    left-parenthesis 1 right-parenthesis Baseline ellipsis w Subscript t Superscript
    left-parenthesis 4 right-parenthesis"><mrow><msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msubsup>
    <mo>‚ãØ</mo> <msubsup><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo><mn>4</mn><mo>)</mo></mrow></msubsup></mrow></math>
    at each time <math alttext="t equals 1 comma ellipsis comma 6"><mrow><mi>t</mi>
    <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>‚ãØ</mo> <mo>,</mo> <mn>6</mn></mrow></math>
    in (*) above. First, we will need the spot prices of the four underlying equities,
    which can be stored in an Eigen `VectorXd` (pretend they are retrieved from a
    live market feed). For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will need a matrix in which to store a random price path for each equity,
    starting with each spot price, to be stored in an additional first column, making
    it a 4 <math alttext="times"><mo>√ó</mo></math> 7 matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Suppose then, the time to maturity is one year, divided into six equal time
    steps. From this, we can get the <math alttext="normal upper Delta t"><mrow><mi>Œî</mi>
    <mi>t</mi></mrow></math> value, say `dt`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Each successive price for a given underlying equity, as shown in (*), can be
    computed in a lambda, where `price` is the previous price in the scenario, and
    `vol` is the volatility of the particular equity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, for each underlying equity at each time step, we can set up an iteration
    and call the lambda at each step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: For this example, the results are
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: Again, results may vary due to differences in the implementation of `<random>`
    between different Standard Library releases among vendors.
  prefs: []
  type: TYPE_NORMAL
- en: Yield Curve Dynamics and Principal Components Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Principal Components Analysis (PCA) is a go-to tool for determining the sources
    and magnitudes of variation that drive changes in the shape of a yield curve.
    Given a covariance matrix of daily changes in yields spanning a range of bond
    maturities, PCA is employed by first calculating the eigenvalues of this matrix,
    and ordering them from highest to lowest. Then, the weightings are calculated
    by dividing each eigenvalue by the some of all the eigenvalues.
  prefs: []
  type: TYPE_NORMAL
- en: Empirical research has shown the contribution of first three eigenvalues will
    comprise nearly the entirety of the weightings, where the first weighting corresponds
    to parallel shifts in the yield curve, the second corresponds to variations in
    its ‚Äútilt‚Äù or ‚Äúslope‚Äù, and the third to the curvature. The reasons and details
    behind this can be found in Chapter 18 of the very fine computational finance
    book by [Ruppert and Matteson](https://link.springer.com/book/10.1007/978-1-4939-2614-5)
    **{25}**, and in Chapter 3 of the classic text on interest rate derivatives by
    Rebonato **{26}**.
  prefs: []
  type: TYPE_NORMAL
- en: Rigorous statistical tests exist for measuring significance, but the weights
    alone can provide a relative estimated measure of each source of variation.
  prefs: []
  type: TYPE_NORMAL
- en: Section 18.2 of the text by Ruppert and Matteson {op cit 25} provides an excellent
    example on how to apply principal components analysis to publicly available US
    Treasury yield data {put URL here}. The resulting covariance matrix‚Äâ‚Äî‚Äâinput as
    constructor data for the following `MatrixXd` object, is based on fluctuations
    in differenced [US Treasury yields](https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&field_tdr_date_value_month=202212)
    **{28}** for eleven different maturities, ranging from one month to 30 years.
    The underlying data is taken from the period from January 1990 to October 2008.
  prefs: []
  type: TYPE_NORMAL
- en: To calculate the eigenvalues, first load the covariance matrix data into the
    upper triangular region of a `MatrixXd` instance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'As a real symmetric matrix is trivially self-adjoint (no complex components),
    Eigen can apply a function `selfadjointView<.>()` to an upper (or lower) triangular
    matrix to define a view of a symmetric covariance matrix. The eigenvalues (all
    real) can then be obtained by applying the `eigenvalues()` function on the symmetric
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to determine the weight of each principal component, we need to divide
    each eigenvalue by the sum of all the eigenvalues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, to view the results in order of the principal components, the
    weighted values need to be arranged from largest to smallest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Examining the contents of `eigenvals`, we would find the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: From this, we can see the effects of parallel shifts and the ‚Äútilt‚Äù of the yield
    curve are the dominant effects, with relative weights of 67.2% and and 21.3%,
    while the curvature effect is smaller at 7.4%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Future Directions: Linear Algebra in the Standard Library'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Three proposals related to linear algebra have been submitted to the ISO C++
    committee.
  prefs: []
  type: TYPE_NORMAL
- en: '`std::mdspan`: [A polymorphic multidimensional array reference (P0009)](https://wg21.link/p0009)
    **{28}**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A free function linear algebra interface based on the BLAS (P1673)](https://wg21.link/p1673)
    **{29}**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Add linear algebra support to the C++ standard library (P1385)](https://wg21.link/p1385)
    **{30}**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mdspan` (P0009) can impose a multidimensional array structure on a reference
    to a container, such as an STL `vector`. Using the example of a `vector` containing
    the data, and a referring `mdspan` representing a matrix, the number of rows and
    columns are set at construction of the `mdspan`. An `mdspan` can also take the
    form of higher dimensional arrays, but for our purposes we will concern ourselves
    with the two-dimensional case for matrix representations. `mdspan` is officially
    slated for release in C++23.'
  prefs: []
  type: TYPE_NORMAL
- en: The second proposal (P1673) is for a standard interface to external linear algebra
    ‚Äúbased on the dense Basic Linear Algebra Subroutines (BLAS)‚Äù, corresponding ‚Äúto
    a subset of the BLAS Standard.‚Äù {op cit 29}. In other words, code could be written
    independently of whichever external linear algebra library is used, making code
    maintenance much easier and less error-prone. As noted in the proposal, the ‚Äúinterface
    is designed in the spirit of the C++ Standard Library‚Äôs algorithms‚Äù, and ‚Äúuses
    mdspan‚Ä¶‚Äã, to represent matrices and vectors‚Äù {ibid}. Furthermore, the ‚Äúinterface
    is designed in the spirit of the C++ Standard Library‚Äôs algorithms"{ibid}. It
    is currently planned for C++26.
  prefs: []
  type: TYPE_NORMAL
- en: The third proposal (P1385) is to provide actual BLAS-type functionality within
    the Standard Library. Its primary goal is to ‚Äúprovide a (sic) matrix vocabulary
    types for representing the mathematical objects and fundamental operations relevant
    to linear algebra‚Äù (op cit {30}). This proposal is also currently planned for
    release with C++26.
  prefs: []
  type: TYPE_NORMAL
- en: mdspan (P0009)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned above, for representing a matrix, `mdspan` establishes a reference
    to a contiguous container and then imposes the number of rows and columns. If
    these parameters are known at compile time, creating an `mdspan` is easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: Note that `mdspan` uses the `data()` member function on `vector` to access its
    contents.
  prefs: []
  type: TYPE_NORMAL
- en: In `mdspan` parlance, rows and columns are referred to as *extents*, with the
    number of rows and columns accessed by the index of each, 0 for rows and 1 for
    columns. The total number of extents is referred to as the *rank*, so in this
    case, the rank is 2\. For higher-order multidimensional arrays, the rank would
    be greater than two.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The term *rank* as applied to `mdspan` is not the same as the mathematical definition
    of the rank of a matrix. This naming might unfortunately seem confusing, but it‚Äôs
    something one should be aware of.
  prefs: []
  type: TYPE_NORMAL
- en: 'Elements of the `mdspan` object will be accessible with another new feature
    in C++23, namely the square bracket operator with multiple indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a welcome improvement, as it will no longer be necessary to put each
    index in a separate bracket pair, as was the case with C-style arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'The run-time result of the previous nested loop displays a 3 <math alttext="times"><mo>√ó</mo></math>
    2 matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to define a matrix with different dimensions to the same
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Applying the same loop above, but replacing `mds1` with `mds2` would then display
    as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: One thing to be careful of is modifying data in the `mdspan` object or in the
    original `vector` will change it in both locations due to the referential relationship
    between the two. For example, modification of the last element of the vector
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: will show up in both of the `mdspan` objects. `mds1` becomes
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: and `mds2` is now
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: Likewise, changing the value of an element in `mds2` will be reflected in both
    `mds1` and the vector `v`.
  prefs: []
  type: TYPE_NORMAL
- en: In quant finance applications, it will often be the case where the fixed number
    of rows and columns are not known at compile time. Suppose `m` and `n` are the
    numbers of rows and columns to be determined at runtime. These dimensions can
    be set dynamically by replacing the fixed settings of 2 and 3 in the previous
    example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'with the `std::extents{m, n}` object, as shown in the `mdspan` definition here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: The `std::extents{m, n}` parameter represents the number of elements in each
    extent‚Äâ‚Äî‚Äâie in each row (`m`) and column (`n`)‚Äâ‚Äî‚Äâwhich are determined dynamically
    at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pretend we have the following data set at runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Using these as inputs to the `dynamic_mdspan(.)` function above will then generate
    a 3 <math alttext="times"><mo>√ó</mo></math> 2 `mdspan` matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The above examples make use of *Class Template Auto Deduction*, commonly referred
    to as *CTAD*. Both `mdspan` and `extents` are class templates, but because `w`
    in the example just above is a `vector` of `double` types, and the size of the
    `vector` being of type `size_t`, when substituted in for `vec` in the `dynamic_mdspan`
    function, the compiler will deduce that the `mdspan` and `extents` objects are
    to use `double` and `size_t` as template parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Without CTAD, the function would be written something like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: The discussion in this chapter will rely on CTAD, but in cases where more generality
    is required, it will be necessary to to write out the template arguments in full.
  prefs: []
  type: TYPE_NORMAL
- en: 'One more thing to note is in each of the examples so far, `mdspan` will arrange
    the data in row-major order by default. Arranging it in column-major order requires
    defining a `layout_left` policy *mapping*, in this case called `col_major`, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: The corresponding column-major matrix can then be defined by substituting this
    mapping in the extents argument in the `mdspan` constructor.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is the column-major version of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Row-major order can also be set explicitly with the `std::layout_right` mapping.
  prefs: []
  type: TYPE_NORMAL
- en: The `mdspan` proposal also includes a ‚Äúslicing‚Äù function called `submdspan(.)`
    to return a reference to an individual row or column from a matrix represented
    by an mdspan. More generally, this would extend to subsets of higher-dimensional
    arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'Returning to the row-major integer 3 <math alttext="times"><mo>√ó</mo></math>
    2 `mds1` example, if we wanted to extract a reference to the first row (index
    0), it could be obtained as follows, with the index in the first extent (row)
    argument of `submdspan`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'This would give us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: Rows 2 and 3 could also be referenced by replacing the `0` with `1` and `2`,
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'By explicitly setting the second (column) extent argument to the column size
    less 1, we could also access the last column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'This would then be comprised of:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: As `submdspan` is a reference (view) to an `mdspan` containing a row or column,
    it will obviate generating an additional `mdspan`, in contrast to the issue with
    a `slice_array` taken from a `valarray`. Any public member function on `mdspan`
    can be applied to a `submdspan`. On the downside, this would not include the vectorized
    mathematical operators or functions that are provided with `valarray`, although
    a different approach to the operators will be provided in `P1673`, to be discussed
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the flip side, also because it is a reference, modifying an element of a
    `submdspan` will also modify the underlying `mdspan` object. Suppose the last
    element in `col_last` is reset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'The original `mds1` would then become:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: One final remark is a proposal for a multi-dimensional array (P1684), called
    `mdarray`, is also in review. As noted in the [proposal](https://wg21.link/p1684)
    **{31}**, "`mdarray` is as similar as possible to mdspan, except with container
    semantics instead of reference semantics‚Äù. In other words, an `mdarray` object
    ‚Äúowns‚Äù its data‚Äâ‚Äî‚Äâsimilar to a `vector`‚Äâ‚Äî‚Äâas opposed to existing as a reference
    to data ‚Äúowned‚Äù by another container as in the case of `mdspan`. The earliest
    it would be released is also C++26.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The code examples for `mdspan` above can be compiled in C++20 using the working
    code currently available on the [P1673 GitHub site](https://github.com/kokkos/mdspan/blob/stable/include/experimental/__p0009_bits/mdspan.hpp)
    **{31}**. Installation and building instructions are included with the repository,
    but two particular items to know are first, the code is currently under the namespace
    `std::experimental`, and second, as the square bracket operator for multiple indices
    is set for C++23, you can replace it with the round bracket operator for C++20
    and earlier; viz,
  prefs: []
  type: TYPE_NORMAL
- en: _
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: BLAS Interface (P1673)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This proposal is for ‚Äúa C++ Standard Library dense linear algebra interface
    based on the dense Basic Linear Algebra Subroutines (BLAS)‚Äù {op cit 29}, also
    simply referred to as ‚ÄústdBLAS‚Äù. BLAS libraries date back a number of decades
    and were originally written in Fortran, but it evolved into a standard in the
    early 2000‚Äôs, with implementations in other languages such as C (OpenBLAS) and
    CUDA C++ (NVIDIA) now available, as well as C bindings to Fortran.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortran BLAS distributions support four numerical types : `FLOAT`, `DOUBLE`,
    `COMPLEX`, and `DOUBLE COMPLEX`. The C++ equivalents are `float`, `double`, `std::complex<float>`,
    and `std::complex<double>`. BLAS libraries contain several matrix formats (standard,
    symmetric, upper/lower triangular), matrix and vector operations such as element-by-element
    addition and matrix/vector multiplication.'
  prefs: []
  type: TYPE_NORMAL
- en: With implementation of this proposal, it would be possible to apply the same
    C++ code base to any compatible library containing BLAS functionality, provided
    an interface has been made available, presumably by the library vendor. This will
    allow for portable code, independent of the underlying library being used. It
    remains to be seen at this stage which vendors will eventually come on board,
    but one major development is NVIDIA‚Äôs implementation both of `mdspan` and stdBLAS,
    now available in their [HPC SDK](https://developer.nvidia.com/hpc-sdk) **{33}**.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted stdBLAS itself would only provide access to a particular
    subset of matrix operations‚Äâ‚Äî‚Äâto be discussed next‚Äâ‚Äî‚Äâeven if the underlying library
    provides additional features such as matrix decompositions, linear and least squares
    solvers, etc.
  prefs: []
  type: TYPE_NORMAL
- en: BLAS functions are preceded by the type contained in the matrix and/or vector
    to which they are applied. For example, the function for multiplication of a matrix
    by a vector is of the form
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: where the `x` can be `S`, `D`, `C`, or `Z`, meaning single precision (`REAL`
    in Fortran), double precision (`DOUBLE`), complex (`COMPLEX`), and double precision
    complex (`DOUBLE COMPLEX`) respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The C++ equivalent in the proposal, `matrix_vector_product` would instead take
    in `mdspan` objects representing a matrix and a vector. For example, we can look
    at a case involving `double` values, using `m` and `n` for the number of rows
    and columns as before.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, performing the multiplication, the vector product is stored in `y`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: The following table provides a subset of BLAS functions proposed in P1673 that
    should be useful in financial programming. The BLAS functions are assumed to be
    double precision, and any given matrix/vector expressions can be assumed to be
    of appropriate dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-1\. Selected BLAS Functions in Proposal P1673
  prefs: []
  type: TYPE_NORMAL
- en: '| BLAS Function | P1673 Function | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| DSCAL | `scale` | Scalar multiplication of a vector |'
  prefs: []
  type: TYPE_TB
- en: '| DCOPY | `copy` | Copy a vector into another |'
  prefs: []
  type: TYPE_TB
- en: '| DAXPY | `add` | Calculates <math alttext="alpha bold x plus bold y"><mrow><mi>Œ±</mi>
    <mi>ùê±</mi> <mo>+</mo> <mi>ùê≤</mi></mrow></math> , vectors <math alttext="bold x"><mi>ùê±</mi></math>
    & <math alttext="bold y"><mi>ùê≤</mi></math> , scalar <math alttext="alpha"><mi>Œ±</mi></math>
    |'
  prefs: []
  type: TYPE_TB
- en: '| DDOT | `dot` | Dot product of two vectors |'
  prefs: []
  type: TYPE_TB
- en: '| DNRM2 | `vector_norm2` | Euclidean norm of a vector |'
  prefs: []
  type: TYPE_TB
- en: '| DGEMV | `matrix_vector_product` | Calculates <math alttext="alpha bold upper
    A bold x plus beta bold y"><mrow><mi>Œ±</mi> <mi>ùêÄùê±</mi> <mo>+</mo> <mi>Œ≤</mi>
    <mi>ùê≤</mi></mrow></math> , matrix <math alttext="bold upper A"><mi>ùêÄ</mi></math>
    , vector <math alttext="bold y"><mi>ùê≤</mi></math> , scalars <math alttext="alpha"><mi>Œ±</mi></math>
    & <math alttext="beta"><mi>Œ≤</mi></math> |'
  prefs: []
  type: TYPE_TB
- en: '| DSYMV | `symmetric_matrix_vector_product` | Same as DGEMV (`matrix_vector_product`)
    but where <math alttext="bold upper A"><mi>ùêÄ</mi></math> is symmetric |'
  prefs: []
  type: TYPE_TB
- en: '| DGEMM | `matrix_product` | Calculates <math alttext="alpha bold upper A bold
    upper B plus beta bold upper C"><mrow><mi>Œ±</mi> <mi>ùêÄùêÅ</mi> <mo>+</mo> <mi>Œ≤</mi>
    <mi>ùêÇ</mi></mrow></math> , for matrices <math alttext="bold upper A"><mi>ùêÄ</mi></math>
    , <math alttext="bold upper B"><mi>ùêÅ</mi></math> , & <math alttext="bold upper
    C"><mi>ùêÇ</mi></math> , and scalars <math alttext="alpha"><mi>Œ±</mi></math> & <math
    alttext="beta"><mi>Œ≤</mi></math> |'
  prefs: []
  type: TYPE_TB
- en: Linear Algebra (P1385)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The authors of this proposal specifically recognized the importance of linear
    algebra in financial modeling, along with other applications such as medical imaging,
    machine learning, and high performance computing. {op cit 28}.
  prefs: []
  type: TYPE_NORMAL
- en: 'Initial technical requirements for a linear algebra library in C++ were outlined
    in a [preceding proposal (P1166)](https://wg21.link/p1166) **{34}**, directly
    quoted here (in italics):'
  prefs: []
  type: TYPE_NORMAL
- en: '*The set of types and functions should be the minimal set required to perform
    functions in finite dimensional spaces. This includes*:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A matrix template*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Binary operations for addition, subtraction and multiplication of matrices*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Binary operations for scalar multiplication and division of matrices*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building on this, the P1385 proposal states two primary goals, namely that the
    library should be easy to use, with ‚Äúrun-time computational performance that is
    close to what {users} could obtain with an equivalent sequence of function calls
    to a more ‚Äútraditional‚Äù linear algebra library, such as LAPACK, Blaze, Eigen,
    etc.‚Äù {op cit 30}
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, a matrix is generically represented by a *MathObj* type, and
    an *engine* ‚Äúis an implementation type that manages the resources associated with
    a *MathObj* instance.‚Äù Discussions are ongoing over the details, but ‚Äúa *MathObj*
    might own the memory in which it stores its elements, or it might employ some
    non-owning view type, like `mdspan`, to manipulate elements owned by some other
    object‚Äù. {ibid}. An *engine* object is proposed to be a private member on a *MathObj*,
    and a *MathObj* may have either fixed or dynamic dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: More details should emerge over the next few years on the form the P1385 linear
    albegra library will assume, but for now, this hopefully provides an initial high-level
    glimpse of something that should be a very welcome addition to C++ for financial
    software developers.
  prefs: []
  type: TYPE_NORMAL
- en: Summary (Linear Algebra Proposals)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recalling the results we saw with `valarray`, with the above proposals in place,
    some of the same convenient functionality should be in place by C++26, this time
    with rigorous, efficient, and consistent specifications that should avoid the
    problems that plagued `valarray`. While `mdspan` differs from `valarray` as a
    non-owning reference, it will still allow array storage, such as a `vector`, to
    be adapted to a matrix proxy by specifiying the number of rows and columns. `submdspan`
    will assume a similar role as a `valarray` slice, but without the performance
    penalty due to object copy. P1673 will provide a common interface to libraries
    containing BLAS functions, and function naming, as as with `matrix_vector_product`,
    will be more expressive than their cryptic Fortran equivalents such as `DGEMV(.)`.
    And, the `+`, `-`, and `*` operators in P1385 will provide the ability to to implement
    linear algebra expressions in a natural mathematical format similar to the results
    we saw with `valarray`.
  prefs: []
  type: TYPE_NORMAL
- en: This is an exciting development that will finally provide efficient and reliable
    methods for implementing basic matrix calculations that are long overdue for C++.
    Hopefully we will also eventually see implementations of P1673 BLAS interfaces
    for popular open source libraries such as Eigen and others mentioned above, but
    as of the time of this writing, this remains to be seen.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has examined the past, present, and expected future of two-dimensional
    array management and linear algebra in C++. `valarray`, dating back to C++98,
    offered matrix-like capabilities for which quantitative developers certainly would
    have found ample use cases. It is unforunate it never received the attention and
    support of the Committee and community, even as C++ was being touted in the late
    1990‚Äôs as the language of the future for computational finance. For specific compilers,
    it might remain a viable option, but given the inconsistency of its implementations
    across Standard Library vendors, it can limit code reuse across different platforms.
  prefs: []
  type: TYPE_NORMAL
- en: In the late 2000‚Äôs, high quality open-source linear algebra libraries such as
    Eigen and Armadillo came on the scene and were well-received by the financial
    quant C++ programming community. In the present day, these libraries contain not
    only much of the same functionality found in the BLAS standard, but also a plethora
    of matrix decompositions that are frequently used in financial applications.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the future also looks brighter for ISO C++ with the three proposals‚Äâ‚Äî‚Äâ`mdspan`
    (P0009), BLAS interface (P1673), and linear algebra library (P1385)‚Äâ‚Äî‚Äâslated for
    inclusion in the Standard Library within the next three years. These are arguably
    features that are long overdue, but they will provide a big step in satisfying
    demand not just from the financial industry, but also other computationally intensive
    domains.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: US Daily Treasury Par Yield Curve Rates [*https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&field_tdr_date_value_month=202211*](https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&field_tdr_date_value_month=202211)
    _
  prefs: []
  type: TYPE_NORMAL
- en: '[Supplemental Chapter, _The C++ Standard Library, 2E](http://www.cppstdlib.com/cppstdlib_supplementary.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '{2.5} Stroustrup, *A Tour of C++* (2E, but now in 3E)'
  prefs: []
  type: TYPE_NORMAL
- en: Quantstart article on Eigen [*https://www.quantstart.com/articles/Eigen-Library-for-Matrix-Algebra-in-C/*](https://www.quantstart.com/articles/Eigen-Library-for-Matrix-Algebra-in-C/)
  prefs: []
  type: TYPE_NORMAL
- en: Gottschling _Discovering Modern C++
  prefs: []
  type: TYPE_NORMAL
- en: Bowie Owens, CppCon 2019, [*https://www.youtube.com/watch?v=4IUCBx5fIv0*](https://www.youtube.com/watch?v=4IUCBx5fIv0)
  prefs: []
  type: TYPE_NORMAL
- en: 'More information on the Jacobi and Bidiagonal Divide and Conquer SVD classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Two-sided Jacobi SVD decomposition of a rectangular matrix](https://eigen.tuxfamily.org/dox-devel/classEigen_1_1JacobiSVD.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Bidiagonal Divide and Conquer SVD](https://eigen.tuxfamily.org/dox-devel/classEigen_1_1BDCSVD.html)'
  prefs: []
  type: TYPE_NORMAL
- en: asciidoctor-latex -b html Ch10_v10_Split_LinearAlgebraOnly.adoc
  prefs: []
  type: TYPE_NORMAL
- en: '{5} Rcpp Packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[RcppEigen](https://cran.r-project.org/web/packages/RcppEigen/vignettes/RcppEigen-Introduction.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[RcppArmadillo](https://cran.r-project.org/web/packages/RcppArmadillo/vignettes/RcppArmadillo-intro.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[RcppBlaze3](https://github.com/ChingChuan-Chen/RcppBlaze3)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Boost Headers, including uBLAS](https://www.rdocumentation.org/packages/BH/versions/1.78.0-0)'
  prefs: []
  type: TYPE_NORMAL
