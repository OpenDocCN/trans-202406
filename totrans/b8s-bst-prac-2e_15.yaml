- en: Chapter 15\. Building Higher-Level Application Patterns on Top of Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s no secret that Kubernetes is a complex system. Although it simplifies the
    deployment and operations of distributed applications, it does little to make
    the development of such systems easy. In fact, when adding new concepts and artifacts
    for the developer to interact with, it adds a layer of complexity in the service
    of simplified operations. Consequently, in many environments, it makes sense to
    develop higher-level abstractions to provide more developer-friendly primitives
    on top of Kubernetes. Additionally, in many large companies, it makes sense to
    standardize the way in which applications are configured and deployed so that
    everyone adheres to the same operational best practices. This can also be achieved
    by developing higher-level abstractions so that developers automatically adhere
    to these principles. However, developing these abstractions can hide important
    details from the developer and might introduce a walled garden. This limits or
    complicates the development of certain applications or the integration of existing
    solutions. Throughout the development of the cloud, the tension between the flexibility
    of infrastructure and the power of the platform has been a constant. Designing
    the appropriate higher-level abstractions enables us to walk an ideal path through
    this divide.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to Developing Higher-Level Abstractions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When considering how to develop a higher-level primitive on top of Kubernetes,
    there are two basic approaches. The first is to wrap Kubernetes as an implementation
    detail. With this approach, developers who consume your platform should be largely
    unaware that they are running on top of Kubernetes; instead, they should think
    of themselves as consumers of the platform you supply, and thus Kubernetes is
    an implementation detail.
  prefs: []
  type: TYPE_NORMAL
- en: The second option is to use the extensibility capabilities built into Kubernetes
    itself. The Kubernetes Server API is quite flexible, and you can dynamically add
    arbitrary new resources to the Kubernetes API. With this approach, your new higher-level
    resources coexist alongside the built-in Kubernetes objects, and the users use
    the built-in tooling for interacting with all the Kubernetes resources, both built-in
    ones and extensions. This extension model results in an environment in which Kubernetes
    is still front and center for your developers but with additions that reduce complexity
    and make it easier to use.
  prefs: []
  type: TYPE_NORMAL
- en: How do you choose the approach that is appropriate? It depends on the goals
    for the abstraction layer that you are building. If you are constructing a fully
    isolated, integrated environment in which you have strong confidence that users
    will not need to “break glass” and escape, and where ease of use is an important
    characteristic, the first option is a great choice. A good example of this would
    be building a machine learning pipeline. The domain is relatively well understood.
    The data scientists who are your users are likely not familiar with Kubernetes.
    Enabling these data scientists to rapidly get their work done and focus on their
    domains rather than distributed systems is the primary goal. As a result, building
    a complete abstraction on top of Kubernetes makes the most sense.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, when building a higher-level developer abstraction—for example,
    an easy way to deploy Java applications—it is a far better choice to extend Kubernetes
    rather than wrap it, for two reasons. First, the domain of application development
    is extraordinarily broad. It will be difficult for you to anticipate all the requirements
    and use cases for your developers, especially as the applications and business
    iterate and change over time. The other reason is to ensure that you can continue
    to take advantage of the Kubernetes ecosystem of tools. There are countless cloud
    native tools for monitoring, continuous delivery, and more. Extending rather than
    replacing the Kubernetes API ensures that you can continue to use these tools
    and new ones as they are developed. Additionally, when you choose to extend rather
    than obfuscate the Kubernetes API, it is relatively straightforward to find people
    with industry experience in Kubernetes. Experience building applications in a
    bespoke application platform that exists only in your environment is definitionally
    rare.
  prefs: []
  type: TYPE_NORMAL
- en: Extending Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Because every layer that you might build over Kubernetes is unique, it is beyond
    the scope of this book to describe how you might build such a layer to extend
    Kubernetes. But the tools and techniques for extending Kubernetes are generic
    to any construction you might do on top of Kubernetes, so we’ll spend time covering
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Extending Kubernetes Clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A complete how-to for extending a Kubernetes cluster is a large topic and more
    completely covered in other books like [*Managing Kubernetes*](https://oreil.ly/6kUUX)
    and [*Kubernetes: Up and Running*](https://oreil.ly/fdRA3) (O’Reilly). Rather
    than going over the same material here, this section focuses on providing an understanding
    of how to use Kubernetes extensibility.'
  prefs: []
  type: TYPE_NORMAL
- en: Extending the Kubernetes cluster involves understanding the touch points for
    resources in Kubernetes. There are three related technical solutions. The first
    is the *sidecar*. Sidecar containers (shown in [Figure 15-1](#fig-sidecar-design))
    have been popularized in the context of service meshes. These containers run alongside
    a main application container to provide additional capabilities that are decoupled
    from the main application and often maintained by a separate team. For example,
    in service meshes, a sidecar might provide transparent mutual Transport Layer
    Security (mTLS) authentication to a containerized application. You can use sidecars
    to add capabilities to your user-defined applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![images/figure-16-1.png](assets/kbp2_1501.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15-1\. The sidecar design
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Within the industry the sidecar approach has become increasingly popular, and
    many projects use it to deliver services alongside the developer’s containers.
    A great example is the [Dapr](https://dapr.io) (Distributed Application Runtime)
    project. Dapr is an open source project within the CNCF that implements a sidecar
    for applications that delivers many capabilities like encryption, key/value store,
    pub/sub queues, and much more with a very simple, consistent API. Sidecars like
    Dapr can be used as modular building blocks for a platform that you are developing
    on top of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the entire goal of this effort was to make a developer’s life easier,
    but if we require that they learn about and know how to use sidecars, we’ve actually
    made the problem worse. Fortunately, additional tools for extending Kubernetes
    simplify things. In particular, Kubernetes features *admission controllers*. Admission
    controllers are interceptors that read Kubernetes API requests prior to them being
    stored (or “admitted”) into the cluster’s backing store. You can use these admission
    controllers to validate or modify API objects. In the context of sidecars, you
    can use them to automatically add sidecars to all pods created in the cluster
    so that developers do not need to know about the sidecars to reap their benefits.
    [Figure 15-2](#figure-admission-control) illustrates how admission controllers
    interact with the Kubernetes API.
  prefs: []
  type: TYPE_NORMAL
- en: '![images/figure-16-2.png](assets/kbp2_1502.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15-2\. Admission controllers
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The utility of admission controllers isn’t limited to adding sidecars. You can
    also use them to validate objects submitted by developers to Kubernetes. For example,
    you could implement a *linter* (a tool that analyzes code) for Kubernetes that
    ensures developers submit pods and other resources that follow best practices
    for using Kubernetes. A common mistake for developers is to not reserve resources
    for their application. For those circumstances, an admission controller–based
    linter could intercept such requests and reject them. Of course, you should also
    leave an escape hatch (for example, a special annotation) so that advanced users
    can opt out of the lint rule, as appropriate. We discuss the importance of escape
    hatches later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we’ve only covered ways to augment existing applications and to ensure
    that developers follow best practices—we haven’t really covered how to add higher-level
    abstractions. This is where custom resource definitions (CRDs) come into play.
    CRDs are a way to dynamically add new resources to an existing Kubernetes cluster.
    For example, using CRDs, you could add a new ReplicatedService resource to a Kubernetes
    cluster. When a developer creates an instance of a ReplicatedService, it turns
    around to Kubernetes and creates corresponding Deployment and Service resources.
    Thus, the ReplicatedService is a convenient developer abstraction for a common
    pattern. CRDs are generally implemented by a control loop that is deployed into
    the cluster itself to manage these new resource types.
  prefs: []
  type: TYPE_NORMAL
- en: Extending the Kubernetes User Experience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adding new resources to your cluster is a great way to provide new capabilities,
    but to truly take advantage of them, it’s often useful to extend the Kubernetes
    user experience (UX) as well. By default, the Kubernetes tooling is unaware of
    custom resources and other extensions and thus treats them in a very generic and
    not particularly user-friendly manner. Extending the Kubernetes command line can
    provide an enhanced user experience.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, the tool used for accessing Kubernetes is the `kubectl` command-line
    tool. Fortunately, it too has been built for extensibility. `kubectl` plug-ins
    are binaries that have a name like `kubectl-foo`, where `foo` is the name of the
    plug-in. When you invoke `kubectl foo ...` on the command line, the invocation
    is in turn routed to an invocation of the plug-in binary. Using `kubectl` plug-ins,
    you can define new experiences that deeply understand the new resources that you
    have added to your cluster. You are free to implement whatever kind of experiences
    are suitable while at the same time taking advantage of the familiarity of the
    `kubectl` tooling. This is especially valuable because it means that you don’t
    need to teach developers about a new tool set. Likewise, you can gradually introduce
    Kubernetes-native concepts as the developers advance their Kubernetes knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking to build graphical interfaces for your Kubernetes-based platform,
    several tools can help. In particular the open source [Headlamp project](https://oreil.ly/2-4fB)
    is a library that enables easy construction of web-based, mobile, or desktop applications
    for interacting with Kubernetes infrastructure. Using a tool like Headlamp enables
    you to rapidly create a custom developer experience that perfectly fits your platform
    and its needs.
  prefs: []
  type: TYPE_NORMAL
- en: Making Containerized Development Easier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before they can even deploy an application to Kubernetes, a developer must first
    containerize that application. Though building containers is second nature for
    those familiar with the cloud native ecosystem, for many it is a daunting task
    that prevents even getting started with modern application development.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, several open source tools can help jump start your development.
    Tools like [Draft](https://draft.sh) and [Skaffold](https://oreil.ly/H4DzY) will
    automatically generate a Dockerfile for a particular language or development environment.
  prefs: []
  type: TYPE_NORMAL
- en: If developers are familiar with the buildpack idea from cloud foundry or other
    platforms, there are also tools like [Paketo](https://paketo.io) that provide
    easy-to-use and vetted container images for building applications in popular languages
    as well as command-line tools to get started easily.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a “Push-to-Deploy” Experience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most popular features of many PaaS products is “push to deploy,”
    meaning that a single push of code to a Git repository results in the application
    deploying to a cloud environment. Though this has previously been the domain of
    large-scale managed PaaS solutions, it is now very easy to build a similar experience
    using CI/CD solutions like GitHub Actions, Azure DevOps, or other continuous-build
    tooling.
  prefs: []
  type: TYPE_NORMAL
- en: With a properly designed pipeline, once a developer pushes code into their Git
    repository, it is automatically tested, built, packaged into a container image,
    and pushed to a container registry.
  prefs: []
  type: TYPE_NORMAL
- en: Once the new version of the container image is present in the container registry,
    it is a simple step to use another Git commit combined with GitOps to push that
    image out to a running application.
  prefs: []
  type: TYPE_NORMAL
- en: Combining GitHub actions and GitOps can enable your developers to achieve fast
    deployment while also staying true to the cloud native ecosystem and ideas like
    Infrastructure as Code (IaC).
  prefs: []
  type: TYPE_NORMAL
- en: Design Considerations When Building Platforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Countless platforms have been built to enable developer productivity. Given
    the opportunity to observe all the places where these platforms have succeeded
    and failed, you can develop a common set of patterns and considerations to learn
    from the experience of others. Following these design guidelines can help to ensure
    that the platform you build is successful instead of a “legacy” dead end from
    which you must eventually move away.
  prefs: []
  type: TYPE_NORMAL
- en: Support Exporting to a Container Image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you are building a platform, many designs provide simplicity by enabling
    the user to simply supply code (e.g., a function in Function as a Service [FaaS])
    or a native package (e.g., a JAR file in Java) instead of a complete container
    image. This approach has a great deal of appeal because it lets the user stay
    within the confines of their well-understood tools and development experience.
    The platform handles the containerization of the application for them.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with this approach, however, comes when the developer encounters
    the limitations of the programming environment that you have given them. Perhaps
    it’s because they need a specific version of a language runtime to work around
    a bug. Or it might be that they need to package additional resources or executables
    that aren’t part of the way you have structured the automatic containerization
    of the application.
  prefs: []
  type: TYPE_NORMAL
- en: No matter the reason, hitting this wall is an ugly moment for the developer,
    because it is a moment when they suddenly must learn a great deal more about how
    to package their application, when all they really wanted to do was to extend
    it slightly to fix a bug or deliver a new feature.
  prefs: []
  type: TYPE_NORMAL
- en: However, it doesn’t need to be this way. If you support the exporting of your
    platform’s programming environment into a generic container, the developer using
    your platform doesn’t need to start from scratch and learn everything there is
    to know about containers. Instead, they have a complete working container image
    that represents their current application (i.e., the container image containing
    their function and the node runtime). Given this starting point, they can then
    make the small tweaks necessary to adapt the container image to their needs. This
    sort of gradual degradation and incremental learning dramatically smooths the
    path from higher-level platform down into lower-level infrastructure. It also
    increases the general utility of the platform because using it doesn’t introduce
    steep cliffs for developers.
  prefs: []
  type: TYPE_NORMAL
- en: Support Existing Mechanisms for Service and Service Discovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another common story of platforms is that they evolve and interconnect with
    other systems. Many developers might be very happy and productive in your platform,
    but any real-world application will span both the platform that you build and
    lower-level Kubernetes applications as well as *other* platforms. Connections
    to legacy databases or open source applications built for Kubernetes will always
    be a part of a sufficiently large application.
  prefs: []
  type: TYPE_NORMAL
- en: Because of this need for interconnectivity, it’s critically important that the
    core Kubernetes primitives for services and service discovery are used and exposed
    by any platform that you construct. Don’t reinvent the wheel in the interest of
    improved platform experience, because in doing so you will be creating a walled
    garden incapable of interacting with the broader world.
  prefs: []
  type: TYPE_NORMAL
- en: If you expose the applications defined in your platform as Kubernetes Services,
    any application anywhere within your cluster will be able to consume your applications
    regardless of whether they are running in your higher-level platform. Likewise,
    if you use the Kubernetes DNS servers for service discovery, you will be able
    to connect from your higher-level application platform to other applications running
    in the cluster, even if they are not defined in your higher-level platform. It
    might be tempting to build something better or easier to use, but interconnectivity
    across different platforms is the common design pattern for any application of
    sufficient age and complexity. You will always regret the decision to build a
    walled garden.
  prefs: []
  type: TYPE_NORMAL
- en: Building Application Platforms Best Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although Kubernetes provides powerful tools for operating software, it does
    considerably less to enable developers to build applications. It is often necessary
    to build platforms on top of Kubernetes to make developers more productive and/or
    Kubernetes easier. When building such platforms, you’ll benefit from keeping the
    following best practices in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Use admission controllers to limit and modify API calls to the cluster. An admission
    controller can validate (and reject invalid) Kubernetes resources. A mutating
    admission controller can automatically modify API resources to add new sidecars
    or other changes that users might not even need to know about.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `kubectl` plug-ins to extend the Kubernetes user experience by adding new
    tools to the existing command-line tool. In rare occasions, a purpose-built tool
    might be more appropriate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When building platforms on top of Kubernetes, think carefully about the platform’s
    users and how their needs will evolve. Making things simple and easy to use is
    clearly a good goal, but if this also leads to users that are trapped and unable
    to be successful without rewriting everything outside of your platform, it will
    ultimately be a frustrating (and unsuccessful) experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is a fantastic tool for simplifying the deployment and operation
    of software; unfortunately, it is not always the most developer-friendly or productive
    environment. Because of this, a common task is to build a higher-level platform
    on top of Kubernetes to make it more approachable and usable by the average developer.
    This chapter described several approaches for designing such a higher-level system
    and provided a summary of the core extensibility infrastructure available in Kubernetes.
    It concluded with lessons and design principles drawn from our observation of
    other platforms that have been built on top of Kubernetes, with the hope that
    they can guide the design of your platform.
  prefs: []
  type: TYPE_NORMAL
