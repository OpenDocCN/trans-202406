- en: Chapter 18\. Handling Duplicates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 18.0 Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Tables or result sets sometimes contain duplicate rows. In some cases this
    is acceptable. For example, if you conduct a web poll that records date and client
    IP number along with the votes, duplicate rows may be permitted because it’s possible
    for large numbers of votes to appear to originate from the same IP number for
    an Internet service that routes traffic from its customers through a single proxy
    host. In other cases, duplicates are unacceptable, and you’ll want to take steps
    to avoid them. Operations involved in handling duplicate rows include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Preventing duplicates from being created in the first place. If each row in
    a table is intended to represent a single entity (such as a person, an item in
    a catalog, or a specific observation in an experiment), the occurrence of duplicates
    makes it impossible to refer to each row unambiguously, so it’s best to make sure
    duplicates never occur.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Counting the number of duplicates to determine whether they are present and
    to what extent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying duplicated values (or the rows containing them) so you can see where
    they occur.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eliminating duplicates to ensure that each row is unique. This may involve removing
    rows from a table to leave only unique rows or selecting a result set in such
    a way that no duplicates appear in the output. For example, to display a list
    of the states in which you have customers, you probably don’t want a long list
    of state names from all customer records. A list showing each state name only
    once suffices and is easier to understand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Several tools are at your disposal for dealing with duplicate rows. Choose
    them according to the objective that you want to achieve:'
  prefs: []
  type: TYPE_NORMAL
- en: When you create a table, include a primary key or unique index to prevent duplicates
    from being added to the table. MySQL uses the index as a constraint to enforce
    the requirement that each row in the table contains a unique key in the indexed
    column or columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conjunction with a unique index, the `INSERT` `IGNORE` and `REPLACE` statements
    enable you to handle insertion of duplicate rows gracefully without generating
    errors. For bulk-loading operations, the same options are available in the form
    of the `IGNORE` or `REPLACE` modifiers for the `LOAD` `DATA` statement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To determine whether a table contains duplicates, use `GROUP` `BY` to categorize
    rows into groups, and `COUNT()` to see how many rows are in each group. [Chapter 10](ch10.xhtml#nch-sum)
    describes these techniques in the context of producing summaries, but they’re
    useful for duplicate counting and identification as well. A counting summary groups
    values into categories to determine how frequently each one occurs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SELECT` `DISTINCT` removes duplicate rows from a result set (see [Recipe 5.4](ch05.xhtml#nch-select-select-nodup)
    for more information). For an existing table that already contains duplicates,
    you can select unique rows into a second table and use it to replace the original
    table. Or, if you determine that there are *`n`* identical rows in a table, you
    can use `DELETE` … `LIMIT` to eliminate *`n`*–1 instances from that specific set
    of rows.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scripts related to the examples shown in this chapter are located in the *dups*
    directory of the `recipes` distribution. For scripts that create the tables used
    here, look in the *tables* directory.
  prefs: []
  type: TYPE_NORMAL
- en: 18.1 Preventing Duplicates from Occurring in a Table
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to prevent a table from ever containing duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use a `PRIMARY` `KEY` or a `UNIQUE` index.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To ensure that rows in a table are unique, some column or combination of columns
    must be required to contain unique values in each row. When this requirement is
    satisfied, you can refer to any row in the table unambiguously by using its unique
    identifier. To make sure a table has this characteristic, include a `PRIMARY`
    `KEY` or `UNIQUE` index in the table structure. The following table contains no
    such index, so it permits duplicate rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To prevent multiple rows with the same first and last name values from being
    created in this table, add a `PRIMARY` `KEY` to its definition. When you do this,
    the indexed columns must be `NOT` `NULL`, because a `PRIMARY` `KEY` prohibits
    `NULL` values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The presence of a unique index in a table normally causes an error to occur
    if you insert a row into the table that duplicates an existing row in the column
    or columns that define the index. [Recipe 18.3](#nch-dups-dups-errors) discusses
    how to handle such errors or modify MySQL’s duplicate-handling behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to enforce uniqueness is to add a `UNIQUE` index rather than a
    `PRIMARY` `KEY` to a table. The two types of indexes are similar, but a `UNIQUE`
    index can be created on columns that permit `NULL` values. For the `person` table,
    it’s likely that you’d require both the first and last names to be filled in.
    If so, you still declare the columns as `NOT` `NULL`, and the following table
    definition is effectively equivalent to the preceding one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If a `UNIQUE` index does happen to permit `NULL` values, `NULL` is special because
    it is the one value that can occur multiple times. The rationale for this is that
    it is not possible to know whether one unknown value is the same as another, so
    multiple unknown values are permitted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, you might want the `person` table to reflect the real world, in
    which people do sometimes have the same name. In this case, you cannot set up
    a unique index based on the name columns, because duplicate names must be permitted.
    Instead, each person must be assigned some sort of unique identifier, which becomes
    the value that distinguishes one row from another. In MySQL, it’s common to accomplish
    this by using an `AUTO_INCREMENT` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, when you create a row with an `id` value of `NULL`, MySQL assigns
    that column a unique ID automatically. Another possibility is to assign identifiers
    externally and use those IDs as unique keys. For example, citizens in a given
    country might have unique taxpayer ID numbers. If so, those numbers can serve
    as the basis for a unique index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If an existing table already contains duplicate rows that you want to remove,
    see [Recipe 18.5](#nch-dups-dups-elim-table). [Chapter 15](ch15.xhtml#nch-sequences)
    further discusses `AUTO_INCREMENT` columns.
  prefs: []
  type: TYPE_NORMAL
- en: 18.2 Having More than One Unique Key in the Table
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need two or more column sets in the table to have unique values.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Define as many unique keys as needed.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It maybe possible that two or more column combinations that need to have unique
    values independently from each other. For example, table `person` from the last
    example in the [Recipe 18.1](#nch-dups-dups-prevent), has a column `tax_id` representing
    a taxpayer ID, thus needs to store unique values. Still you may want to keep unique
    index on `(last_name, first_name)`. This way you can be sure that each person
    has its own taxpayer ID and any taxpayer ID belongs to the only one person.
  prefs: []
  type: TYPE_NORMAL
- en: Any table can have at most one primary key. Therefore you need to choose which
    key will be primary and which will be secondary unique key. As we describe in
    [Recipe 21.2](ch21.xhtml#nch-queryperf-queryperf-create-index-innodbpk) primary
    keys for InnoDB storage engine are included into all secondary indexes and it
    is critical for performance to define them using the smallest data type possible.
    Therefore it is straightforward to define primary key for the `tax_id` column
    and a key on `(last_name, first_name)` as a secondary unique index.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting table definition will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 18.3 Dealing with Duplicates When Loading Rows into a Table
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You’ve created a table with a unique index to prevent duplicate values in the
    indexed column or columns. But this results in an error if you attempt to insert
    a duplicate row, and you want to avoid having to deal with such errors.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One approach is to just ignore the error. Another is to use an `INSERT` `IGNORE`,
    `REPLACE`, or `INSERT` … `ON` `DUPLICATE` `KEY` `UPDATE` statement, each of which
    modifies MySQL’s duplicate-handling behavior. For bulk-loading operations, `LOAD`
    `DATA` has modifiers that enable you to specify how to handle duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By default, MySQL generates an error when you insert a row that duplicates
    an existing unique key value. Suppose that the `person` table has the following
    structure, with a unique index on the `last_name` and `first_name` columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'An attempt to insert a row with duplicate values in the indexed columns results
    in an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If you issue the statements from the *mysql* program interactively, you can
    simply say, <q>Okay, that didn’t work,</q> ignore the error, and continue. But
    if you write a program to insert the rows, an error may terminate the program.
    One way to avoid this is to modify the program’s error-handling behavior to trap
    the error and then ignore it. See [Recipe 4.2](ch04.xhtml#nch-api-api-error) for
    information about error-handling techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent the error from occurring in the first place, you might consider
    using a two-query method to solve the duplicate-row problem:'
  prefs: []
  type: TYPE_NORMAL
- en: Issue a `SELECT` to check whether the row is already present.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Issue an `INSERT` if the row is not present.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'But that doesn’t really work: another client might insert the same row after
    the `SELECT` and before the `INSERT`, in which case the error would still occur
    for your `INSERT`. To make sure that doesn’t happen, you could use a transaction
    or lock the tables, but then you’ve gone from two statements to four. MySQL provides
    three single-query solutions to the problem of handling duplicate rows. Choose
    from among them depending on the duplicate-handling behavior you want:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep the original row when a duplicate occurs, use `INSERT` `IGNORE` rather
    than `INSERT`. If the row duplicates no existing row, MySQL inserts it as usual.
    If the row is a duplicate, the `IGNORE` keyword tells MySQL to discard it silently
    without generating an error:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The row count value indicates whether the row was inserted or ignored. From
    within a program, you can obtain this value by checking the rows-affected function
    provided by your API (see [Recipe 4.4](ch04.xhtml#nch-api-api-statement) and [Recipe
    12.1](ch12.xhtml#nch-meta-meta-rows)).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To replace the original row with the new one when a duplicate occurs, use `REPLACE`
    rather than `INSERT`. If the row is new, it’s inserted just as with `INSERT`.
    If it’s a duplicate, the new row replaces the old one:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The rows-affected value in the second case is 2 because the original row is
    deleted and the new row is inserted in its place.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To modify columns of an existing row when a duplicate occurs, use `INSERT`
    … `ON` `DUPLICATE` `KEY` `UPDATE`. If the row is new, it’s inserted. If it’s a
    duplicate, the `ON` `DUPLICATE` `KEY` `UPDATE` clause indicates how to modify
    the existing row in the table. In other words, this statement can insert or update
    a row as necessary. The rows-affected count indicates what happened: 1 for an
    insert, 2 for an update.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`INSERT` `IGNORE` is more efficient than `REPLACE` because it doesn’t actually
    insert duplicates. Thus, it’s most applicable when you just want to make sure
    a copy of a given row is present in a table. `REPLACE`, on the other hand, is
    often more appropriate for tables in which other nonkey columns need to be replaced.
    `INSERT` … `ON` `DUPLICATE` `KEY` `UPDATE` is appropriate when you must insert
    a record if it doesn’t exist, but just update some of its columns if the new record
    is a duplicate in the indexed columns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that you maintain a table named `passtbl` for a web application that
    contains email addresses and password hash values, and that is indexed by email
    address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'How do you create new rows for new users, but change passwords of existing
    rows for existing users? Here’s a typical algorithm for handling row maintenance:'
  prefs: []
  type: TYPE_NORMAL
- en: Issue a `SELECT` to check whether a row already exists with a given `email`
    value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If no such row exists, add a new one with `INSERT`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the row does exist, update it with `UPDATE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'These steps must be performed within a transaction or with the tables locked
    to prevent other users from changing the tables while you’re using them. In MySQL,
    you can use `REPLACE` to simplify both cases to the same single-statement operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If no row with the given email address exists, MySQL creates a new one. Otherwise,
    MySQL replaces it, in effect updating the `password` column of the row associated
    with the address.
  prefs: []
  type: TYPE_NORMAL
- en: '`INSERT` `IGNORE` and `REPLACE` are useful when you know exactly what values
    should be stored in the table when you attempt to insert a row. That’s not always
    the case. For example, you might want to insert a row if it doesn’t exist, but
    update only certain parts of it otherwise. This commonly occurs when you use a
    table for counting. Suppose that you record votes for candidates in polls, using
    the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The primary key is the combination of poll and candidate number. The table
    should be used like this:'
  prefs: []
  type: TYPE_NORMAL
- en: For the first vote received for a given poll candidate, insert a new row with
    a vote count of 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For subsequent votes for that candidate, increment the vote count of the existing
    record.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Neither `INSERT` `IGNORE` nor `REPLACE` are appropriate here because for all
    votes except the first, you don’t know what the vote count should be. `INSERT`
    … `ON` `DUPLICATE` `KEY` `UPDATE` works better here. The following example shows
    how it works, beginning with an empty table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'For the first `INSERT`, no row for the candidate exists, so the row is inserted.
    For the second `INSERT`, the row exists, so MySQL just updates the vote count.
    With `INSERT` … `ON` `DUPLICATE` `KEY` `UPDATE`, you need not check whether the
    row exists; MySQL does it for you. The row count indicates what action the `INSERT`
    statement performs: 1 for a new row and 2 for an update to an existing row.'
  prefs: []
  type: TYPE_NORMAL
- en: The techniques just described have the benefit of eliminating overhead that
    might otherwise be required for a transaction. But this benefit comes at the price
    of portability because they all involve MySQL-specific syntax. If portability
    is a high priority, you might prefer to use a transactional approach as we discuss
    in [Chapter 20](ch20.xhtml#nch-xact).
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For bulk record-loading operations in which you use the `LOAD` `DATA` statement
    to load a set of rows from a file into a table, control duplicate-row handling
    using the statement’s `IGNORE` and `REPLACE` modifiers. These produce behavior
    analogous to that of the `INSERT` `IGNORE` and `REPLACE` statements. For more
    information, see [Recipe 13.1](ch13.xhtml#nch-xfer-xfer-load-data).
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 15.12](ch15.xhtml#nch-sequences-seq-counter) further demonstrates the
    use of `INSERT` … `ON` `DUPLICATE` `KEY` `UPDATE` for initializing and updating
    counts.'
  prefs: []
  type: TYPE_NORMAL
- en: 18.4 Counting and Identifying Duplicates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to determine whether a table contains duplicates, and to what extent
    they occur. Or you want to see the rows that contain the duplicated values.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use a counting summary that displays duplicated values. To see the rows in which
    the duplicated values occur, join the summary to the original table to display
    the matching rows.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose that your website has a sign-up page that enables visitors to add themselves
    to your mailing list to receive periodic product catalog mailings. But you forgot
    to include a unique index in the table when you created it, and now you suspect
    that some people are signed up multiple times. Perhaps they forgot they were already
    on the list, or perhaps people added friends to the list who were already signed
    up. Either way, the result of having duplicate rows is that you mail out duplicate
    catalogs. This is an additional expense to you, and it annoys the recipients.
    This section discusses how to determine whether there are duplicate rows in a
    table, how prevalent they are, and how to display them. (For tables that do contain
    duplicates, [Recipe 18.5](#nch-dups-dups-elim-table) describes how to eliminate
    them.)
  prefs: []
  type: TYPE_NORMAL
- en: 'To determine whether duplicates occur in a table, use a counting summary (a
    topic covered in [Chapter 10](ch10.xhtml#nch-sum)). Summary techniques can be
    applied to identifying and counting duplicates by grouping rows with `GROUP` `BY`
    and counting the rows in each group using `COUNT()`. For the examples here, assume
    that catalog recipients are listed in a table named `catalog_list` that has the
    following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose that you define <q>duplicate</q> using the `last_name` and `first_name`
    columns. That is, recipients with the same name are assumed to be the same person.
    The following statements characterize the table and assess the existence and extent
    of duplicate values:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The total number of rows in the table:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The number of distinct names:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The number of rows containing duplicated names:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The fraction of the rows that contain unique or nonunique names:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Those statements help you characterize the extent of duplicates, but they don’t
    show you which values are duplicated. To see the duplicated names in the `catalog_list`
    table, use a summary statement that displays the nonunique values along with the
    counts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The statement includes a `HAVING` clause that restricts the output to include
    only those names that occur more than once. In general, to identify sets of values
    that are duplicated, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Determine which columns contain the values that may be duplicated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List those columns in the column selection list, along with `COUNT(*)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List the columns in the `GROUP` `BY` clause as well.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a `HAVING` clause that eliminates unique values by requiring group counts
    to be greater than one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Queries constructed that way have the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'It’s easy to generate duplicate-finding queries like that within a program,
    given database and table names and a nonempty set of column names. For example,
    here is a Perl function `make_dup_count_query()` that generates the proper query
    for finding and counting duplicated values in the specified columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`make_dup_count_query()` returns the query as a string. If you invoke it like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'the resulting value of `$str` is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: What you do with the query string is up to you. You can execute it from within
    the script that creates it, pass it to another program, or write it to a file
    for execution later. The *dups* directory of the `recipes` distribution contains
    a script named *dup_count.pl* that you can use to try the function (as well as
    some translations into other languages). [Recipe 18.5](#nch-dups-dups-elim-table)
    discusses use of `make_dup_count_query()` to implement a duplicate-removal technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'Summary techniques are useful for assessing the existence of duplicates, how
    often they occur, and displaying which values are duplicated. But if duplicates
    are determined using only a subset of a table’s columns, a summary in itself cannot
    display the entire content of the rows that contain the duplicate values. (For
    example, the summaries shown thus far display counts of duplicated names in the
    `catalog_list` table or the names themselves, but don’t show the addresses associated
    with those names.) To see the original rows containing the duplicate names, join
    the summary information to the table from which it’s generated. The following
    example shows how to do this to display the `catalog_list` rows that contain duplicated
    names. The summary is written to a temporary table, which then is joined to the
    `catalog_list` table to produce the rows that match those names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 18.5 Eliminating Duplicates from a Table
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to remove duplicate rows from a table, leaving only unique rows.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Select the unique rows from the table into a second table, then use that table
    to replace the original one. Or use `DELETE` … `LIMIT` *`n`* to remove all but
    one instance of a specific set of duplicate rows.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 18.1](#nch-dups-dups-prevent) discusses how to prevent duplicates from
    being added to a table by creating it with a unique index. However, if you forget
    to include the index when you create a table, you may discover later that it contains
    duplicates and that it’s necessary to apply some sort of duplicate-removal technique.
    The `catalog_list` table used earlier is an example of this because it contains
    several instances in which the same person appears multiple times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To eliminate duplicates, you may use one of these two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the table’s unique rows into another table, then use that table to replace
    the original one. This works when <q>duplicate</q> means <q>the entire row is
    the same as another.</q>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To remove duplicates for a specific set of duplicate rows, use `DELETE` … `LIMIT`
    *`n`* to remove all but one row.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This recipe discusses each duplicate-removal method. When deciding upon which
    method to choose for your circumstance, consider these questions::'
  prefs: []
  type: TYPE_NORMAL
- en: Does the method require the table to have a unique index?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the columns in which duplicate values occur may contain `NULL`, will the
    method remove duplicate `NULL` values?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the method prevent duplicates from occurring in the future?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing duplicates using table replacement
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If a row is considered to duplicate another only if the entire row is the same,
    one way to eliminate duplicates from a table is to select its unique rows into
    a new table that has the same structure, and then replace the original table with
    the new one:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new table that has the same structure as the original one. `CREATE`
    `TABLE` … `LIKE` is useful for this (see [Recipe 6.1](ch06.xhtml#nch-tblmgmt-tblmgmt-clone)):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `INSERT` `INTO` … `SELECT` `DISTINCT` to select the unique rows from the
    original table into the new one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select rows from the `tmp` table to verify that the new table contains no duplicates:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After creating the new `tmp` table that contains unique rows, use it to replace
    the original `catalog_list` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The effective result of this procedure is that `catalog_list` no longer contains
    duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: This table-replacement method works in the absence of an index (although it
    might be slow for large tables). For tables that contain duplicate `NULL` values,
    it removes those duplicates. It does not prevent the occurrence of duplicates
    in the future.
  prefs: []
  type: TYPE_NORMAL
- en: This method requires rows to be completely identical to be considered duplicates.
    Thus, it treats as distinct those rows for Wallace Baxter that have slightly different
    `street` values.
  prefs: []
  type: TYPE_NORMAL
- en: 'If duplicates are defined only with respect to a subset of the columns in the
    table, create a new table that has a unique index for those columns, select rows
    into it using `INSERT` `IGNORE`, and replace the original table with the new one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The unique index prevents rows with duplicate key values from being inserted
    into `tmp`, and `IGNORE` tells MySQL not to stop with an error if a duplicate
    is found. One shortcoming of this method is that if the indexed columns can contain
    `NULL` values, you must use a `UNIQUE` index rather than a `PRIMARY` `KEY`, in
    which case the index will not remove duplicate `NULL` keys. (`UNIQUE` indexes
    permit multiple `NULL` values.) This method does prevent occurrence of duplicates
    in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Removing duplicates of a particular row
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can use `LIMIT` to restrict the effect of a `DELETE` statement to a subset
    of the rows that it otherwise would delete. This makes the statement applicable
    to removing duplicate rows. Suppose that the original unindexed `catalog_list`
    table contains duplicates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'To remove the extra instances of each name, do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This technique works in the absence of a unique index, and it eliminates duplicate
    `NULL` values. It’s handy for removing duplicates only for a specific set of rows
    within a table. However, if there are many different sets of duplicates to remove,
    this is not a procedure you’d want to carry out by hand. The process can be automated
    by using the techniques discussed earlier in [Recipe 18.4](#nch-dups-dups-count)
    for determining which values are duplicated. There, we wrote a `make_dup_count_query()`
    function to generate the statement needed to count the number of duplicate values
    in a given set of columns in a table. The result of that statement can be used
    to generate a set of `DELETE` … `LIMIT` *`n`* statements that remove duplicate
    rows and leave only unique rows. The *dups* directory of the `recipes` distribution
    contains code that shows how to generate these statements.
  prefs: []
  type: TYPE_NORMAL
- en: In general, using `DELETE` … `LIMIT` *`n`* is likely to be slower than removing
    duplicates by using a second table or by adding a unique index. Those methods
    keep the data on the server side and let the server do all the work. `DELETE`
    … `LIMIT` *`n`* involves a lot of client-server interaction because it uses a
    `SELECT` statement to retrieve information about duplicates, followed by several
    `DELETE` statements to remove instances of duplicated rows. Also, this technique
    does not prevent duplicates from occurring in the future.
  prefs: []
  type: TYPE_NORMAL
