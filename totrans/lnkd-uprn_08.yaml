- en: 'Chapter 8\. Linkerd Policy: Overview and Server-Based Policy'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 Linkerd 策略：概述和基于服务器的策略
- en: Microservices applications, as we discussed in [Chapter 7](ch07.html#LUAR_mtls_and_certs),
    require a different level of network security than more traditional monoliths.
    mTLS gives you the secure communications and workload identity that you need to
    start tackling this level of network security—but it’s Linkerd’s *policy* mechanisms
    that provide the ability to use that identity to control how workloads can talk
    to each other in your environment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第7章](ch07.html#LUAR_mtls_and_certs)中讨论的那样，微服务应用需要比传统的单体应用更高级别的网络安全性。mTLS
    提供了你需要的安全通信和工作负载身份，但是正是 Linkerd 的*策略*机制提供了利用这些身份来控制环境中工作负载如何相互通信的能力。
- en: 'Linkerd supports two kinds of policy mechanisms: *Server-based* and *route-based*.
    Since policy is the single most complex area of Linkerd, we’ll provide an overview
    and cover Server-based policy in this chapter, then tackle route-based policy
    in [Chapter 9](ch09.html#LUAR_route_policy).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd 支持两种策略机制：*基于服务器*和*基于路由*。由于策略是 Linkerd 最复杂的领域，我们将提供概述，并在本章节讨论基于服务器的策略，然后在[第9章](ch09.html#LUAR_route_policy)中介绍基于路由的策略。
- en: Linkerd Policy Overview
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Linkerd 策略概述
- en: 'All Linkerd policy mechanisms are based on *explicit authorization*: Linkerd
    starts out assuming that it should allow nothing and must be explicitly told what
    requests should be allowed. This lines up nicely with the zero trust model and
    makes it straightforward to reason about permissions, since policy resources are
    always *permitting* things to happen.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 Linkerd 策略机制都基于*显式授权*：Linkerd 最初假定不应允许任何事情，必须明确告知允许哪些请求。这与零信任模型完全一致，并且使得权限推理变得简单，因为策略资源始终在*允许*某些操作。
- en: 'Don’t panic, though; this doesn’t mean a policy is always a morass of hundreds
    of resources. Linkerd allows setting a *default policy* at the cluster, namespace,
    and Pod levels, with policy settings at more specific levels overriding policy
    settings at more general levels: Pods override namespaces, which override cluster-wide
    settings, as shown in [Figure 8-1](#linkerd-policy-default-settings).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，不要惊慌；这并不意味着策略总是由数百个资源构成的一团乱麻。Linkerd 允许在集群、命名空间和 Pod 级别设置*默认策略*，并且更具体级别的策略设置会覆盖更一般级别的策略设置：Pod
    覆盖命名空间，命名空间覆盖集群范围的设置，正如[图8-1](#linkerd-policy-default-settings)所示。
- en: '![luar 0801](assets/luar_0801.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![luar 0801](assets/luar_0801.png)'
- en: Figure 8-1\. Different Linkerd default policy settings
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1\. 不同的 Linkerd 默认策略设置
- en: 'It may seem strange to talk about defaults overriding defaults. Here, “default”
    is in contrast to the other kind of policy setting that Linkerd supports: using
    *dynamic policy resources*. The default policy is simply the policy that applies
    when no dynamic resource is present for a given request.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 谈论默认覆盖默认可能看起来很奇怪。这里，“默认”是指 Linkerd 支持的另一种策略设置类型的对比：使用*动态策略资源*。默认策略就是在没有针对特定请求的动态资源存在时应用的策略。
- en: Policy is always enforced along Pod boundaries, since the Pod is the basic unit
    managed by Linkerd. It’s not possible, for example, to write a policy that will
    affect communications with a single container in a Pod.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 策略始终沿 Pod 边界执行，因为 Pod 是由 Linkerd 管理的基本单元。例如，不可能编写一个会影响 Pod 中单个容器通信的策略。
- en: Linkerd Default Policy
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linkerd 默认策略
- en: 'Linkerd has the following default policy options:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd 有以下默认策略选项：
- en: '`all-unauthenticated`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '`all-unauthenticated`'
- en: Allow all traffic, whether authenticated or not.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 允许所有流量，无论是否经过身份验证。
- en: '`cluster-unauthenticated`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`cluster-unauthenticated`'
- en: Allow all traffic from *this cluster*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 允许来自*本集群*的所有流量。
- en: '`all-authenticated`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`all-authenticated`'
- en: Allow traffic from all meshed clients.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 允许来自所有网格化客户端的流量。
- en: '`cluster-authenticated`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`cluster-authenticated`'
- en: Allow traffic from meshed clients in *this cluster*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 允许来自*本集群*中的网格化客户端的流量。
- en: '`deny`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`deny`'
- en: Deny everything.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 否认一切。
- en: The distinction between `all` and `cluster` is relevant only if you’re using
    multicluster (as discussed in [Chapter 12](ch12.html#LUAR_multicluster)). In a
    multicluster setting, `all` includes clients from other clusters, whereas `cluster`
    does not, as shown in [Figure 8-2](#linkerd-all-vs-cluster). If you’re not using
    multicluster, the two are equivalent.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`all` 和 `cluster` 的区别仅在于当你使用多集群时才相关（正如我们在[第12章](ch12.html#LUAR_multicluster)中讨论的那样）。在多集群设置中，`all`
    包括来自其他集群的客户端，而 `cluster` 则不包括，如[图8-2](#linkerd-all-vs-cluster)所示。如果不使用多集群，则两者是等效的。'
- en: '![luar 0802](assets/luar_0802.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![luar 0802](assets/luar_0802.png)'
- en: Figure 8-2\. `all` versus `cluster`
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-2\. `all` vs `cluster`
- en: 'The cluster default policy is set at install time with the `proxy.defaultInboundPolicy`
    value, as shown in [Example 8-1](#EX10-cluster-default). If not set, the cluster
    default policy will be `all-unauthenticated`: this allows absolutely any request,
    mirroring Kubernetes’s default wide-open stance. Linkerd uses this default to
    ensure that users who don’t want or need to use policy (or who just haven’t gotten
    to that point in hardening their clusters yet) won’t be negatively impacted when
    they install Linkerd.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 集群默认策略在安装时使用`proxy.defaultInboundPolicy`值设置，如[示例8-1](#EX10-cluster-default)所示。如果未设置，集群默认策略将是`all-unauthenticated`：这允许绝对任何请求，反映了Kubernetes的默认宽松姿态。Linkerd使用此默认值确保在安装Linkerd时不想或不需要使用策略（或者只是还没有加固集群到达该点的用户）不会受到负面影响。
- en: Why the Permissive Default Policy?
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么采用宽松的默认策略？
- en: Linkerd’s default `all-unauthenticated` is obviously not good for security,
    and we *strongly* advise you to pick a different cluster default for production
    installations.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd的默认`all-unauthenticated`显然对安全性不利，我们*强烈*建议您选择不同的集群默认值用于生产安装。
- en: However, as a practical matter, literally any other base default almost guarantees
    that installing Linkerd into a running application would break things. Ultimately,
    `all-unauthenticated` as the base default is the only way to allow Linkerd to
    do no harm when first brought into an application, and that’s *why* it’s the base
    default.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，实际上，几乎任何其他的基本默认都几乎可以确保在运行中的应用程序中安装Linkerd会导致问题。最终，`all-unauthenticated`作为基本默认是在首次引入应用程序时确保Linkerd不会造成任何伤害的唯一方法，这就是*为什么*它是基本默认。
- en: Example 8-1\. Setting the cluster default policy
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例8-1\. 设置集群默认策略
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To override the default for a namespace, workload, or Pod, you’ll use the `config.linkerd.io/default-inbound-policy`
    annotation, setting it to one of the values listed earlier, as shown here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要覆盖命名空间、工作负载或Pod的默认值，您将使用`config.linkerd.io/default-inbound-policy`注释，将其设置为前面列出的值之一，如下所示：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Linkerd Policy Resources
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linkerd策略资源
- en: 'To override the default policy, you use policy resources, which are CRDs that
    configure which requests should be permitted:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要覆盖默认策略，您将使用策略资源，这些资源是CRD，配置应该允许哪些请求：
- en: Server
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Server
- en: Describes one or more Pods and one port on those Pods
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 描述一个或多个Pod及其上的一个端口
- en: HTTPRoute
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP路由
- en: Describes a subset of the HTTP traffic to a given Server
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 描述给定Server的HTTP流量子集
- en: MeshTLSAuthentication
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: MeshTLSAuthentication
- en: Describes one or more mesh identities
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 描述一个或多个网格身份
- en: NetworkAuthentication
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 网络认证
- en: Describes one or more IP addresses
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 描述一个或多个IP地址
- en: AuthorizationPolicy
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: AuthorizationPolicy
- en: Binds a Server or HTTPRoute to mesh or network authentications
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将Server或HTTPRoute绑定到网格或网络认证
- en: These resources work together as shown in [Figure 8-3](#linkerd-policy-resources);
    for example, an AuthorizationPolicy can link a Server and a MeshTLSAuthentication
    to permit a specific set of mesh identities to access the Server.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些资源如[图8-3](#linkerd-policy-resources)所示共同工作；例如，一个AuthorizationPolicy可以将Server和MeshTLSAuthentication链接起来，以允许特定集合的网格身份访问Server。
- en: '![luar 0803](assets/luar_0803.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![luar 0803](assets/luar_0803.png)'
- en: Figure 8-3\. Linkerd policy resources
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3\. Linkerd策略资源
- en: Let’s take a closer look at each of these resources and how they’re used to
    configure Linkerd policy.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地查看每个资源以及它们如何用于配置Linkerd策略。
- en: Server
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Server
- en: 'We talked about the Server resource briefly in [Chapter 4](ch04.html#LUAR_meshing_workloads).
    Server resources are specific to Linkerd; they allow describing a single specific
    port of a workload. For example, the Server in [Example 8-2](#EX10-server) describes
    the `http` port of the `foo` workload, which is the set of Pods with the `app:
    foo` label. This Server also notes that that port carries HTTP/1.1 traffic.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在[第4章](ch04.html#LUAR_meshing_workloads)简要讨论了Server资源。Server资源是Linkerd特有的；它们允许描述工作负载的单个特定端口。例如，[示例8-2](#EX10-server)中的Server描述了`foo`工作负载的`http`端口，该工作负载是具有`app:
    foo`标签的Pod集合。该Server还指出该端口处理HTTP/1.1流量。'
- en: Example 8-2\. A Server resource
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例8-2\. 一个Server资源
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that Server is a namespaced resource that must appear in the same namespace
    as the Pods it needs to match.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Server是一个命名空间资源，必须出现在与其需要匹配的Pod相同的命名空间中。
- en: HTTPRoute
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HTTP路由
- en: HTTPRoute is a Gateway API resource that describes specific HTTP requests. We’ll
    discuss HTTPRoute more in [Chapter 9](ch09.html#LUAR_route_policy).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: HTTPRoute是一个Gateway API资源，描述特定的HTTP请求。我们将在[第9章](ch09.html#LUAR_route_policy)更详细地讨论HTTPRoute。
- en: MeshTLSAuthentication
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MeshTLSAuthentication
- en: MeshTLSAuthentication describes a particular set of mesh identities. Any workload
    running with one of the listed identities will match the MeshTLSAuthentication.
    For example, [Example 8-3](#EX10-4) shows a MeshTLSAuthentication for the single
    identity `foo.foo-ns.serviceaccount.identity.linkerd.cluster.local`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: MeshTLSAuthentication 描述了一组特定的网格标识。任何具有列出的标识之一的工作负载都将匹配 MeshTLSAuthentication。例如，[示例
    8-3](#EX10-4) 显示了用于单个标识 `foo.foo-ns.serviceaccount.identity.linkerd.cluster.local`
    的 MeshTLSAuthentication。
- en: Example 8-3\. A MeshTLSAuthentication resource
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-3\. 一个 MeshTLSAuthentication 资源
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: MeshTLSAuthentication is a namespaced resource. It will typically be placed
    in the same namespace as the workloads it’s associated with, although this isn’t
    a strict requirement.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: MeshTLSAuthentication 是一个命名空间资源。通常会放置在与其相关的工作负载相同的命名空间中，尽管这不是一个严格的要求。
- en: NetworkAuthentication
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NetworkAuthentication
- en: A NetworkAuthentication resource describes a set of IP address CIDR ranges.
    Any request coming from one of the listed ranges will match the NetworkAuthentication.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: NetworkAuthentication 资源描述一组 IP 地址 CIDR 范围。来自列出范围中任何一个的请求都将匹配 NetworkAuthentication。
- en: Given that Linkerd makes such a big deal about using workload identity rather
    than network identity, it may seem strange that the NetworkAuthentication resource
    exists at all; however, as a practical matter, it can be useful at times when
    managing unmeshed clients.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到 Linkerd 强调使用工作负载标识而不是网络标识，可能会觉得 NetworkAuthentication 资源存在有些奇怪；然而，在管理未网格化的客户端时，它在某些时候确实很有用。
- en: NetworkAuthentication is a namespaced resource. It will typically be placed
    in the same namespace as the workloads it’s associated with, although this isn’t
    a strict requirement.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: NetworkAuthentication 是一个命名空间资源。通常会放置在与其相关的工作负载相同的命名空间中，尽管这不是一个严格的要求。
- en: AuthorizationPolicy
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 授权策略
- en: Linkerd AuthorizationPolicy resources *permit access* to a *target* for some
    *required authentications*. The target, at present, must be a Server or an HTTPRoute.
    The required authentications must be one or more MeshTLSAuthentication or NetworkAuthentication
    resources.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd 授权策略资源 *允许访问* 目标以进行一些 *必需的身份验证*。目标目前必须是服务器或 HTTP 路由之一。所需的身份验证必须是一个或多个
    MeshTLSAuthentication 或 NetworkAuthentication 资源。
- en: AuthorizationPolicy is a namespaced resource. It will typically be placed in
    the same namespace as the workloads it’s associated with, although this isn’t
    a strict requirement.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 授权策略是一个命名空间资源。通常会放置在与其相关的工作负载相同的命名空间中，尽管这不是一个严格的要求。
- en: We’ll go deeper into the individual objects as we begin actually using policy
    to lock down our cluster.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始实际使用策略来锁定我们的集群时，我们将深入研究各个对象。
- en: Server-Based Policy Versus Route-Based Policy
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于服务器的策略与基于路由的策略的比较
- en: Server-based policy gets its name because it relies on Linkerd Server resources.
    You’ll note that while the Server resource describes a workload and port, it does
    *not* describe anything about requests. This means that Server-based policy can’t
    differentiate separate requests to a given Server, instead requiring every request
    going to a Server to adhere to the same policy.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 基于服务器的策略得名于它依赖于 Linkerd 服务器资源。您会注意到，虽然服务器资源描述了工作负载和端口，但并没有 *描述* 请求的任何内容。这意味着基于服务器的策略无法区分发往给定服务器的单独请求，而是要求发往服务器的每个请求都遵循相同的策略。
- en: Route-based policy (which we’ll discuss in [Chapter 9](ch09.html#LUAR_route_policy)),
    on the other hand, *does* get to take request details into account. It is a more
    powerful—and also more complex—mechanism.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，路由策略（我们将在[第9章](ch09.html#LUAR_route_policy)讨论）确实会考虑请求细节。这是一种更强大、也更复杂的机制。
- en: Server-Based Policy with the emojivoto Application
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于 emojivoto 应用程序的基于服务器的策略
- en: 'We’ll use the [emojivoto sample application](https://oreil.ly/g7fDb) to illustrate
    working with policy in Linkerd. For reference, [Figure 8-4](#emojivoto-policy-overview)
    shows our end goal: the entire emojivoto application will be protected from accesses
    that shouldn’t happen.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 [emojivoto 示例应用程序](https://oreil.ly/g7fDb) 来说明在 Linkerd 中使用策略。作为参考，[图
    8-4](#emojivoto-policy-overview) 显示了我们的最终目标：整个 emojivoto 应用程序将受到保护，防止未授权的访问。
- en: '![luar 0804](assets/luar_0804.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![luar 0804](assets/luar_0804.png)'
- en: Figure 8-4\. emojivoto policy overview
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-4\. emojivoto 策略概览
- en: In this chapter, we’ll guide you through a few different patterns you can adopt
    for your cluster, each of which will progressively lock down your applications
    and what they can communicate with.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将引导您通过几种不同的模式来设置您的集群，每种模式都将逐步限制应用程序及其通信能力。
- en: Configuring the Default Policy
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置默认策略
- en: The first step we can take to lock down our clusters is also one of the most
    impactful and wide-ranging. Linkerd provides a straightforward mechanism for setting
    the default inbound policy for all of our proxies. In this section we’re going
    to show you how to set the default inbound policy at the cluster and namespace
    level.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以采取的第一步来锁定我们的集群之一也是影响力和广泛性最大的措施之一。Linkerd 提供了一个简单的机制来设置所有代理的默认入站策略。在本节中，我们将展示如何在集群和命名空间级别设置默认的入站策略。
- en: Cluster default policy
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集群默认策略
- en: Let’s start by setting the default policy for the entire cluster. Remember,
    when you install Linkerd, the default policy for the whole cluster is `all-unauthenticated`,
    which allows absolutely any request, mirroring Kubernetes’s default wide-open
    stance.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从设置整个集群的默认策略开始。记住，当你安装 Linkerd 时，整个集群的默认策略是`all-unauthenticated`，允许绝对任何请求，这与
    Kubernetes 的默认开放态度一致。
- en: 'We’ll start by switching the default policy for the cluster to `all-authenticated`.
    This will require that all connections to meshed Pods come from other Pods that
    are in the mesh. This is good for security, but adds some operational overhead
    since you’ll need to carve out exceptions for any nonmeshed applications that
    you want to continue being able to talk to meshed Pods. For example, imagine that
    you have a nonmeshed monitoring tool: when you flip the default to `all-authenticated`,
    it will suddenly be unable to talk to your meshed Pods, and you’ll either need
    to mesh the monitoring tool or add an exception to your Linkerd policy for it.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将集群的默认策略切换为`all-authenticated`。这将要求所有连接到网络内的 Pod 的连接都来自于网络内的其他 Pod。这对安全性有好处，但会增加一些运维开销，因为你需要为任何想要继续与网络内的
    Pod 进行通信的非网络化应用程序划出例外。例如，想象一下，你有一个非网络化的监控工具：当你将默认设置为`all-authenticated`时，它将突然无法与你的网络内的
    Pod 进行通信，你要么需要将监控工具加入到网络中，要么为它添加 Linkerd 策略的例外。
- en: To Deny or Not to Deny
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 是拒绝还是不拒绝
- en: In a perfect world, your entire cluster would have its default policy set to
    `deny`. This is absolutely the best practice from a security perspective, but
    if you’re starting with an existing application, adding Linkerd with the default
    set to `deny` is very likely to break things unless you know *all* of the different
    traffic that you’ll need to permit. In practice, that’s rare if you weren’t already
    working with fine-grained security tools.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想情况下，整个集群的默认策略应设置为`deny`。从安全的角度来看，这绝对是最佳实践，但如果你正在处理现有的应用程序，并且将 Linkerd 的默认设置为`deny`，很可能会导致一些问题，除非你已经知道所有需要允许的不同流量。实际上，如果你没有使用精细化安全工具来工作，这种情况是很少见的。
- en: An effective and practical compromise can be to start with `all-unauthenticated`,
    then use Linkerd’s observability tools to determine what traffic should be permitted
    before gradually tightening security via `all-authenticated` or `cluster-authenticated`
    on the way to `deny`. Also remember that you can switch specific namespaces to
    `deny` as steps toward getting the whole cluster to `deny`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有效且实际的妥协可以是从`all-unauthenticated`开始，然后使用 Linkerd 的可观察性工具确定哪些流量应被允许，然后逐步通过`all-authenticated`或`cluster-authenticated`来加强安全性，最终达到`deny`。还要记住，你可以将特定的命名空间切换到`deny`，作为逐步使整个集群达到`deny`的步骤之一。
- en: In a *nonproduction* environment, of course, the broad stroke of just flipping
    everything to `deny` and watching what breaks is a *great* way to see exactly
    what communications are happening that you haven’t thought of yet. Just don’t
    go there in production!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在*非生产*环境中，当然，简单地将所有东西都切换到`deny`并观察可能会发生什么问题是了解哪些通信正在进行而你还没有考虑到的一个*很好的*方法。但在生产环境中不要这样做！
- en: Because the cluster-wide policy is a global setting, we’ll configure it using
    Helm. In [Example 8-4](#EX10-5), we’ll use `helm upgrade` to change Linkerd’s
    settings without changing the version of Linkerd you have installed. This example
    assumes you’re using Linkerd 2.13.4.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因为集群范围的策略是一个全局设置，我们将使用 Helm 进行配置。在示例 [8-4](#EX10-5) 中，我们将使用`helm upgrade`来修改
    Linkerd 的设置，而不改变你已安装的 Linkerd 版本。这个示例假设你正在使用 Linkerd 2.13.4。
- en: Example 8-4\. Cluster policy
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-4\. 集群策略
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Namespace default policy
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命名空间默认策略
- en: Going further, we can flip the `emojivoto` namespace to `deny` to further protect
    our application, as shown in [Example 8-5](#EX10-namespace). Once we do this,
    *all* traffic in the namespace will be denied unless we explicitly authorize it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 更进一步，我们可以将`emojivoto`命名空间切换到`deny`，以进一步保护我们的应用程序，如示例 [8-5](#EX10-namespace)
    所示。一旦这样做，该命名空间内的所有流量都将被拒绝，除非我们明确授权。
- en: Example 8-5\. Namespace policy
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-5\. 命名空间策略
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Timing Matters
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间很重要
- en: Linkerd’s default inbound policy is read by your proxies at startup time. It
    is not read dynamically. This is important for operators to be aware of because
    it means any changes you make only take effect when your Pods are created. If
    you change the default inbound policy for the cluster or a namespace, those changes
    will only take effect after the Pods in your namespace are re-created. Pod-level
    inbound policy changes will take effect when the Kubernetes API restarts the modified
    Pods, so they will effectively get applied as soon as you modify the Deployments,
    StatefulSets, or DaemonSets in question.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd的默认入站策略在代理启动时由您的代理读取。它不是动态读取的。这对操作员来说很重要，因为这意味着您所做的任何更改只有在创建Pod时才会生效。如果您更改了集群或命名空间的默认入站策略，则这些更改仅在重新创建命名空间中的Pod后才会生效。Pod级别的入站策略更改将在Kubernetes
    API重新启动修改的Pod时生效，因此它们将在您修改相关的Deployments、StatefulSets或DaemonSets后立即生效。
- en: With that, we’ve managed to block communication between our workloads in the
    `emojivoto` namespace…and *everything* is broken. To make the app work again,
    we need to start allowing necessary traffic again with *dynamic policy*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些设置，我们成功地阻止了`emojivoto`命名空间中工作负载之间的通信……而*一切*都瘫痪了。为了使应用程序重新正常工作，我们需要开始再次允许必要的流量，采用*动态策略*。
- en: Configuring Dynamic Policy
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置动态策略
- en: 'As demonstrated, it’s not very useful just to use defaults to block everything.
    It’s time to look at how to use our dynamic policy resources to allow useful,
    necessary traffic to flow. We’ll start with a fairly simple concept: many organizations
    treat namespaces as logical boundaries between applications or teams, so it often
    makes sense to allow workloads in the same namespace to talk to each other. This
    is commonly called *namespace isolation*.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如示例所示，仅仅使用默认设置来阻止所有内容并不是很有用。现在是时候看看如何使用我们的动态策略资源来允许有用的、必要的流量流动了。我们将从一个相当简单的概念开始：许多组织将命名空间视为应用程序或团队之间的逻辑边界，因此通常允许同一命名空间中的工作负载相互通信是有意义的。这通常被称为*命名空间隔离*。
- en: Namespace isolation
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命名空间隔离
- en: 'With namespace isolation, we can easily restrict traffic in a namespace exclusively
    to those workloads that share that namespace. In our example, we’ll start by permitting
    traffic within the `emojivoto` namespace as long as the source and destination
    identities are *both* within this single namespace. This makes sense for the emojivoto
    application because the only things running in its namespace are parts of emojivoto itself:
    it’s a natural result of the idea that the application is contained within a single
    namespace.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命名空间隔离，我们可以轻松地限制命名空间中的流量仅限于共享该命名空间的工作负载。在我们的示例中，我们将开始允许`emojivoto`命名空间内的流量，只要源和目标身份都在同一个命名空间中。对于emojivoto应用程序来说，这是有意义的，因为其命名空间中运行的唯一内容是emojivoto本身的部分：这是该应用程序仅包含在单个命名空间中的自然结果。
- en: Identities, Not IP Addresses
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 身份而非IP地址
- en: Note that we said “source and destination *identities*.” Everything Linkerd
    does with policy is based on the workload identity, not the workload’s IP address
    or anything else about the network. The workloads don’t even need to be in the
    same cluster, as long as the identities line up.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们说的是“源和目的地*身份*”。Linkerd对策略的所有操作都基于工作负载身份，而不是工作负载的IP地址或网络的任何其他内容。只要身份匹配，工作负载甚至不需要在同一个集群中，也可以正常运行。
- en: 'We’ll set up namespace isolation for `emojivoto` in [Example 8-6](#EX10-namespace-isolation).
    Fair warning: this will look complex. The inline comments are very important to
    fully understand exactly what’s going on in this example.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[示例 8-6](#EX10-namespace-isolation)中为`emojivoto`设置命名空间隔离。公平警告：这看起来很复杂。内联注释对完全理解此示例的所有内容非常重要。
- en: Example 8-6\. Namespace isolation for `emojivoto`
  id: totrans-103
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-6\. 对`emojivoto`进行命名空间隔离
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: What’s in a Name?
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 名字的重要性
- en: Linkerd Server objects are the core construct that allows us to apply policy
    to our applications. They work by matching Pods based on some selection criteria
    and then selecting a port *by the port’s name*. Kubernetes will allow you to create
    Pods without adding a name to a port, so you must be sure that when using Linkerd
    policy in your cluster, every port in your applications has a value set for its
    name.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd服务器对象是允许我们对应用程序应用策略的核心构造。它们通过基于某些选择标准匹配Pod，然后选择一个端口*根据端口的名称*。Kubernetes允许您创建没有将名称添加到端口的Pod，因此在使用Linkerd策略时，必须确保应用程序中的每个端口都为其名称设置了一个值。
- en: We know that was a lot of YAML! Policy definition is the most labor-intensive
    task you’ll need to undertake to use Linkerd. Luckily for all of us, policy is
    an opt-in feature that you can prepare for in advance of turning it on. We *strongly*
    recommend you thoroughly test all your policy objects in a nonproduction environment
    before applying them to a live environment.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道这是大量的 YAML！策略定义是您在使用 Linkerd 时需要承担的最费力的任务。幸运的是，策略是一个可选择的功能，您可以在启用之前提前准备好。我们*强烈建议*您在将所有策略对象应用于生产环境之前，在非生产环境中彻底测试它们。
- en: Test Early, Test Often
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**早期测试，经常测试**'
- en: This bears repeating. *Policy is complex* and easy to get wrong. We *strongly*
    encourage that you test your policy definitions in a nonproduction environment
    before taking them to production.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这点需要重申。*策略很复杂*，容易出错。我们*强烈建议*在将策略定义应用于生产环境之前，在非生产环境中测试您的策略定义。
- en: Allowing Linkerd Viz
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 允许 Linkerd Viz
- en: 'At this point, we’ve isolated the `emojivoto` namespace within the cluster:
    nothing from outside the namespace gets to speak with anything inside the namespace.
    Unfortunately, this will break things like monitoring applications and ingress
    controllers. This is decidedly less than ideal: while we’ve done a lot to secure
    our `emojivoto` namespace, we’ve caused other problems. For example, we’ve left
    any potential operations folks with little to no ability to monitor what our emojivoto
    workloads are doing.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们已经在集群中隔离了`emojivoto`命名空间：来自命名空间外部的任何内容都无法与命名空间内部的任何内容通信。不幸的是，这会导致监控应用程序和入口控制器等功能中断。这显然不是理想的状态：虽然我们已经做了很多工作来保护我们的`emojivoto`命名空间，但却导致了其他问题。例如，我们让任何潜在的操作人员几乎无法监控我们的
    emojivoto 工作负载在做什么。
- en: To fix this, we can use dynamic policy resources that reference identities from
    *outside* the namespace. In [Example 8-7](#EX10-viz) we’ll walk you through installing
    Linkerd Viz and allowing it to poll your applications, as shown in [Figure 8-5](#emojivoto-allowing-viz).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决这个问题，我们可以使用引用来自*命名空间外部*身份的动态策略资源。在[示例 8-7](#EX10-viz)中，我们将指导您安装 Linkerd Viz
    并允许其轮询您的应用程序，如[图 8-5](#emojivoto-allowing-viz)所示。
- en: '![luar 0805](assets/luar_0805.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![luar 0805](assets/luar_0805.png)'
- en: Figure 8-5\. emojivoto policy allowing Linkerd Viz
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-5\. emojivoto 策略允许 Linkerd Viz
- en: Example 8-7\. Let there be Viz!
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-7\. 让 Viz 来临吧！
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With that complete, we’ve now walked through what you need to do to isolate
    traffic within a namespace but still allow in an external monitoring tool like
    the Linkerd Viz extension. You now have the basic knowledge required to begin
    isolating your own workloads by namespace with Linkerd’s policy tools. Next, we’ll
    get a little more granular and only allow specific service accounts to access
    our workloads.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些步骤后，我们已经详细介绍了如何在命名空间内部隔离流量，但仍允许外部监控工具（如 Linkerd Viz 扩展）进入。您现在具备开始使用 Linkerd
    的策略工具隔离自己工作负载所需的基本知识。接下来，我们将更详细地说明只允许特定服务账户访问我们的工作负载。
- en: Locking down by port and identity
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 按端口和身份锁定
- en: Namespace isolation goes a long way to further hardening our environment, but
    we can go further than that. With the isolation we’ve applied so far, any request
    is allowed as long as the calling workload and the called workload are both in
    the `emojivoto` namespace, but this is probably more permissive than we really
    need. To go a little further, we can be explicit about which accounts are allowed
    to talk to which workloads—but of course, that requires knowing exactly which
    communications are truly required by the application.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间隔离在进一步加固我们环境方面发挥了重要作用，但我们可以做得更多。到目前为止，我们已经应用的隔离允许任何请求，只要调用工作负载和被调用工作负载都在`emojivoto`命名空间内部即可，但这可能比我们实际需要的更宽松。为了更进一步，我们可以明确指出哪些账户被允许与哪些工作负载通信——但这当然需要准确了解应用程序真正需要的通信情况。
- en: Figuring out those requirements by inspecting code is tedious and error-prone,
    but fortunately we can do better than that by using tools like Linkerd Viz (or
    its commercial cousins from Buoyant) to help us map our application’s communication
    and build our policy objects.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查代码来弄清楚这些需求是繁琐且容易出错的，但幸运的是，我们可以利用像 Linkerd Viz（或其商业版本 Buoyant 的衍生产品）这样的工具来帮助我们映射应用程序的通信并构建我们的策略对象。
- en: 'We need only a single Linkerd Viz CLI command to see which workloads are communicating
    with one another in the `emojivoto` namespace:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在`emojivoto`命名空间中，我们只需使用一个 Linkerd Viz CLI 命令即可查看哪些工作负载正在相互通信。
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will produce a list of Deployments that are communicating with one another
    in this namespace. Deployments listed under the `SRC` column are the sources (clients)
    for requests; those listed under `DST` are the destinations (servers).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个在此命名空间中相互通信的部署列表。在 `SRC` 列下列出的部署是请求的源（客户端）；在 `DST` 列下列出的是目标（服务器）。
- en: 'If you’d prefer to investigate using the Viz dashboard rather than its CLI,
    you can run:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您更喜欢使用 Viz 仪表板而不是其 CLI 进行调查，您可以运行：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The Viz dashboard is out of scope for this book, but it’s fairly intuitive,
    and we encourage you to poke around in it if you haven’t had the chance to use
    it before.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Viz 仪表板不在本书的讨论范围内，但它相当直观，我们鼓励您在没有使用过的情况下去试试。
- en: From the output we can see the connections between our emojivoto workloads,
    as shown in [Figure 8-6](#emojivoto-app-connections).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中，我们可以看到我们的 emojivoto 工作负载之间的连接，如 [图 8-6](#emojivoto-app-connections) 所示。
- en: '![luar 0806](assets/luar_0806.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![luar 0806](assets/luar_0806.png)'
- en: Figure 8-6\. emojivoto inter-workload communications
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-6\. emojivoto 工作负载间通信
- en: 'emojivoto is a very simple application, so there are only three connections:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: emojivoto 是一个非常简单的应用程序，因此只有三个连接：
- en: '`vote-bot` talks to the `web` Deployment.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vote-bot` 与 `web` 部署进行通信。'
- en: '`web` communicates with `voting`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`web` 与 `voting` 进行通信。'
- en: '`web` communicates with `emoji`.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`web` 与 `emoji` 进行通信。'
- en: With that, we can begin building policy. We’ll start by gathering the Subject
    names on our individual workloads, as shown in [Example 8-8](#EX10-gather-names).
    We’ll need to gather the names for `vote-bot` and `web`. We don’t need to allow
    `voting` or `emoji` to communicate with any other services, as neither of them
    act as clients for any other services.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们可以开始构建策略。我们将从收集各自工作负载上的主体名称开始，如 [示例 8-8](#EX10-gather-names) 所示。我们需要收集
    `vote-bot` 和 `web` 的名称。我们不需要允许 `voting` 或 `emoji` 与任何其他服务通信，因为它们都不作为任何其他服务的客户端。
- en: Example 8-8\. Gathering Subject names
  id: totrans-138
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-8\. 收集主体名称
- en: '[PRE13]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: What’s in a Name?
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 名字的含义？
- en: Why does the `vote-bot` workload get an identity named “default” while the `web`
    workload gets one named “web”? If you look carefully at the `vote-bot` and `web`
    Deployments, you’ll find that `web` specifies which ServiceAccount to use, but
    `vote-bot` does not…so `vote-bot` gets the default. *This is not a best practice*.
    In a perfect world, every workload would get its own ServiceAccount.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么 `vote-bot` 工作负载得到一个名为“default”的身份，而 `web` 工作负载得到一个名为“web”的身份？如果您仔细查看 `vote-bot`
    和 `web` 的部署，您会发现 `web` 指定了要使用的 ServiceAccount，但 `vote-bot` 没有……所以 `vote-bot` 得到了默认的。*这不是最佳实践*。在理想的情况下，每个工作负载都应该有自己的
    ServiceAccount。
- en: We’re showing this because while it’s not ideal, it’s *very* common to see this
    default ServiceAccount in use when trying to set up policy for applications that
    weren’t designed with zero trust in mind—and you may need to create new ServiceAccounts
    in addition to creating policy resources!
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示这个是因为尽管这不是理想的，但在试图为未设计为零信任的应用程序设置策略时，看到这种默认 ServiceAccount 的使用是*非常*常见的，并且您可能需要创建新的
    ServiceAccount 以及创建策略资源！
- en: With those two Subject names, we can update our policy to be much more explicit
    about who is allowed to talk to whom in the `emojivoto` namespace. It’s worth
    remembering that in the previous section we created a number of policy objects
    that allow the emojivoto workloads to talk to each other. In [Example 8-9](#EX10-less-permissive),
    we’ll be reusing some and removing others in order to move from a more permissive
    to less permissive security posture, as shown in [Figure 8-7](#emojivoto-less-permissive).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这两个主体名称，我们可以更新我们的策略，更明确地规定在 `emojivoto` 命名空间中允许谁与谁通信。值得记住，在前一节中，我们创建了多个策略对象，允许
    emojivoto 工作负载相互通信。在 [示例 8-9](#EX10-less-permissive) 中，我们将重新使用一些并删除其他对象，以从更宽松的安全姿态转向更少宽松的姿态，如
    [图 8-7](#emojivoto-less-permissive) 所示。
- en: '![luar 0807](assets/luar_0807.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![luar 0807](assets/luar_0807.png)'
- en: Figure 8-7\. emojivoto less permissive model
  id: totrans-145
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-7\. emojivoto 较不宽松的模型
- en: Server-Side Policy
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务器端策略
- en: In Linkerd, the workload-based policy engine enforces all policy decisions on
    the server side. When we configure `deny` as the default in our environment, we
    have to go through each server individually to ensure all its clients have been
    explicitly allowed.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Linkerd 中，基于工作负载的策略引擎在服务器端执行所有策略决策。当我们在环境中将 `deny` 配置为默认选项时，我们必须逐个检查每台服务器，确保其所有客户端都已明确允许。
- en: Example 8-9\. Restricting interapp communication
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-9\. 限制应用间通信
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Order of Operations
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作顺序
- en: As we moved from namespace-wide permissions to more specific permissions, we
    created our new policy objects before removing the namespace-wide permissions.
    If we had inverted the order, we would have disrupted communication between the
    emojivoto workloads.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们从命名空间范围的权限转向更具体的权限时，我们在移除命名空间范围的权限之前创建了新的策略对象。如果我们颠倒了顺序，就可能会破坏 emojivoto
    工作负载之间的通信。
- en: You have now further restricted access to the apps in the `emojivoto` namespace.
    Now communication between your workloads will occur only if it has been explicitly
    authorized by your platform team. Every denial is logged by the Linkerd proxy,
    and your security team can use these logs to identify malicious behavior in your
    clusters. Hopefully you can see how this sort of hardening dramatically reduces
    the risk of an intrusion in your environment and, with proper monitoring and logging,
    dramatically increases the likelihood that suspicious behavior will be caught.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在进一步限制了对 `emojivoto` 命名空间中应用程序的访问。现在，只有在您的平台团队明确授权的情况下，您的工作负载之间才会发生通信。Linkerd
    代理会记录每次拒绝，并且您的安全团队可以使用这些日志来识别集群中的恶意行为。希望您能看到这种加固方式如何显著降低环境中入侵的风险，并且通过适当的监控和日志记录，显著增加捕捉可疑行为的可能性。
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Linkerd’s Server-based policy is its oldest policy mechanism, but it’s still
    incredibly effective in a great many situations. Server-based policy gives you
    the ability to set known, trustworthy defaults while also making it straightforward
    to tune everything for your application, and Linkerd’s Tap ability lets you quickly
    get a sense of what you need to sort out.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd 的基于服务器的策略是其最古老的策略机制，但在许多情况下仍然非常有效。基于服务器的策略使您能够设置已知的、可信的默认值，同时也可以简单地调整应用程序的所有内容，Linkerd
    的 Tap 功能使您能够快速了解需要解决的问题。
