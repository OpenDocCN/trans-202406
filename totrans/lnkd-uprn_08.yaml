- en: 'Chapter 8\. Linkerd Policy: Overview and Server-Based Policy'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices applications, as we discussed in [Chapter 7](ch07.html#LUAR_mtls_and_certs),
    require a different level of network security than more traditional monoliths.
    mTLS gives you the secure communications and workload identity that you need to
    start tackling this level of network security—but it’s Linkerd’s *policy* mechanisms
    that provide the ability to use that identity to control how workloads can talk
    to each other in your environment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'Linkerd supports two kinds of policy mechanisms: *Server-based* and *route-based*.
    Since policy is the single most complex area of Linkerd, we’ll provide an overview
    and cover Server-based policy in this chapter, then tackle route-based policy
    in [Chapter 9](ch09.html#LUAR_route_policy).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Linkerd Policy Overview
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All Linkerd policy mechanisms are based on *explicit authorization*: Linkerd
    starts out assuming that it should allow nothing and must be explicitly told what
    requests should be allowed. This lines up nicely with the zero trust model and
    makes it straightforward to reason about permissions, since policy resources are
    always *permitting* things to happen.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'Don’t panic, though; this doesn’t mean a policy is always a morass of hundreds
    of resources. Linkerd allows setting a *default policy* at the cluster, namespace,
    and Pod levels, with policy settings at more specific levels overriding policy
    settings at more general levels: Pods override namespaces, which override cluster-wide
    settings, as shown in [Figure 8-1](#linkerd-policy-default-settings).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0801](assets/luar_0801.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Figure 8-1\. Different Linkerd default policy settings
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It may seem strange to talk about defaults overriding defaults. Here, “default”
    is in contrast to the other kind of policy setting that Linkerd supports: using
    *dynamic policy resources*. The default policy is simply the policy that applies
    when no dynamic resource is present for a given request.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Policy is always enforced along Pod boundaries, since the Pod is the basic unit
    managed by Linkerd. It’s not possible, for example, to write a policy that will
    affect communications with a single container in a Pod.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Linkerd Default Policy
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Linkerd has the following default policy options:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '`all-unauthenticated`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Allow all traffic, whether authenticated or not.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '`cluster-unauthenticated`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Allow all traffic from *this cluster*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '`all-authenticated`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Allow traffic from all meshed clients.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '`cluster-authenticated`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Allow traffic from meshed clients in *this cluster*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '`deny`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Deny everything.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: The distinction between `all` and `cluster` is relevant only if you’re using
    multicluster (as discussed in [Chapter 12](ch12.html#LUAR_multicluster)). In a
    multicluster setting, `all` includes clients from other clusters, whereas `cluster`
    does not, as shown in [Figure 8-2](#linkerd-all-vs-cluster). If you’re not using
    multicluster, the two are equivalent.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0802](assets/luar_0802.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: Figure 8-2\. `all` versus `cluster`
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The cluster default policy is set at install time with the `proxy.defaultInboundPolicy`
    value, as shown in [Example 8-1](#EX10-cluster-default). If not set, the cluster
    default policy will be `all-unauthenticated`: this allows absolutely any request,
    mirroring Kubernetes’s default wide-open stance. Linkerd uses this default to
    ensure that users who don’t want or need to use policy (or who just haven’t gotten
    to that point in hardening their clusters yet) won’t be negatively impacted when
    they install Linkerd.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Why the Permissive Default Policy?
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linkerd’s default `all-unauthenticated` is obviously not good for security,
    and we *strongly* advise you to pick a different cluster default for production
    installations.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: However, as a practical matter, literally any other base default almost guarantees
    that installing Linkerd into a running application would break things. Ultimately,
    `all-unauthenticated` as the base default is the only way to allow Linkerd to
    do no harm when first brought into an application, and that’s *why* it’s the base
    default.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-1\. Setting the cluster default policy
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To override the default for a namespace, workload, or Pod, you’ll use the `config.linkerd.io/default-inbound-policy`
    annotation, setting it to one of the values listed earlier, as shown here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Linkerd Policy Resources
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To override the default policy, you use policy resources, which are CRDs that
    configure which requests should be permitted:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Server
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Describes one or more Pods and one port on those Pods
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: HTTPRoute
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Describes a subset of the HTTP traffic to a given Server
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: MeshTLSAuthentication
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Describes one or more mesh identities
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: NetworkAuthentication
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Describes one or more IP addresses
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: AuthorizationPolicy
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Binds a Server or HTTPRoute to mesh or network authentications
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: These resources work together as shown in [Figure 8-3](#linkerd-policy-resources);
    for example, an AuthorizationPolicy can link a Server and a MeshTLSAuthentication
    to permit a specific set of mesh identities to access the Server.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0803](assets/luar_0803.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: Figure 8-3\. Linkerd policy resources
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let’s take a closer look at each of these resources and how they’re used to
    configure Linkerd policy.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Server
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We talked about the Server resource briefly in [Chapter 4](ch04.html#LUAR_meshing_workloads).
    Server resources are specific to Linkerd; they allow describing a single specific
    port of a workload. For example, the Server in [Example 8-2](#EX10-server) describes
    the `http` port of the `foo` workload, which is the set of Pods with the `app:
    foo` label. This Server also notes that that port carries HTTP/1.1 traffic.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-2\. A Server resource
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that Server is a namespaced resource that must appear in the same namespace
    as the Pods it needs to match.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: HTTPRoute
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: HTTPRoute is a Gateway API resource that describes specific HTTP requests. We’ll
    discuss HTTPRoute more in [Chapter 9](ch09.html#LUAR_route_policy).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: MeshTLSAuthentication
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MeshTLSAuthentication describes a particular set of mesh identities. Any workload
    running with one of the listed identities will match the MeshTLSAuthentication.
    For example, [Example 8-3](#EX10-4) shows a MeshTLSAuthentication for the single
    identity `foo.foo-ns.serviceaccount.identity.linkerd.cluster.local`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-3\. A MeshTLSAuthentication resource
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: MeshTLSAuthentication is a namespaced resource. It will typically be placed
    in the same namespace as the workloads it’s associated with, although this isn’t
    a strict requirement.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: NetworkAuthentication
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A NetworkAuthentication resource describes a set of IP address CIDR ranges.
    Any request coming from one of the listed ranges will match the NetworkAuthentication.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Given that Linkerd makes such a big deal about using workload identity rather
    than network identity, it may seem strange that the NetworkAuthentication resource
    exists at all; however, as a practical matter, it can be useful at times when
    managing unmeshed clients.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: NetworkAuthentication is a namespaced resource. It will typically be placed
    in the same namespace as the workloads it’s associated with, although this isn’t
    a strict requirement.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: AuthorizationPolicy
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Linkerd AuthorizationPolicy resources *permit access* to a *target* for some
    *required authentications*. The target, at present, must be a Server or an HTTPRoute.
    The required authentications must be one or more MeshTLSAuthentication or NetworkAuthentication
    resources.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: AuthorizationPolicy is a namespaced resource. It will typically be placed in
    the same namespace as the workloads it’s associated with, although this isn’t
    a strict requirement.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: We’ll go deeper into the individual objects as we begin actually using policy
    to lock down our cluster.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Server-Based Policy Versus Route-Based Policy
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Server-based policy gets its name because it relies on Linkerd Server resources.
    You’ll note that while the Server resource describes a workload and port, it does
    *not* describe anything about requests. This means that Server-based policy can’t
    differentiate separate requests to a given Server, instead requiring every request
    going to a Server to adhere to the same policy.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Route-based policy (which we’ll discuss in [Chapter 9](ch09.html#LUAR_route_policy)),
    on the other hand, *does* get to take request details into account. It is a more
    powerful—and also more complex—mechanism.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Server-Based Policy with the emojivoto Application
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ll use the [emojivoto sample application](https://oreil.ly/g7fDb) to illustrate
    working with policy in Linkerd. For reference, [Figure 8-4](#emojivoto-policy-overview)
    shows our end goal: the entire emojivoto application will be protected from accesses
    that shouldn’t happen.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0804](assets/luar_0804.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: Figure 8-4\. emojivoto policy overview
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this chapter, we’ll guide you through a few different patterns you can adopt
    for your cluster, each of which will progressively lock down your applications
    and what they can communicate with.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the Default Policy
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step we can take to lock down our clusters is also one of the most
    impactful and wide-ranging. Linkerd provides a straightforward mechanism for setting
    the default inbound policy for all of our proxies. In this section we’re going
    to show you how to set the default inbound policy at the cluster and namespace
    level.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Cluster default policy
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s start by setting the default policy for the entire cluster. Remember,
    when you install Linkerd, the default policy for the whole cluster is `all-unauthenticated`,
    which allows absolutely any request, mirroring Kubernetes’s default wide-open
    stance.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start by switching the default policy for the cluster to `all-authenticated`.
    This will require that all connections to meshed Pods come from other Pods that
    are in the mesh. This is good for security, but adds some operational overhead
    since you’ll need to carve out exceptions for any nonmeshed applications that
    you want to continue being able to talk to meshed Pods. For example, imagine that
    you have a nonmeshed monitoring tool: when you flip the default to `all-authenticated`,
    it will suddenly be unable to talk to your meshed Pods, and you’ll either need
    to mesh the monitoring tool or add an exception to your Linkerd policy for it.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: To Deny or Not to Deny
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a perfect world, your entire cluster would have its default policy set to
    `deny`. This is absolutely the best practice from a security perspective, but
    if you’re starting with an existing application, adding Linkerd with the default
    set to `deny` is very likely to break things unless you know *all* of the different
    traffic that you’ll need to permit. In practice, that’s rare if you weren’t already
    working with fine-grained security tools.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: An effective and practical compromise can be to start with `all-unauthenticated`,
    then use Linkerd’s observability tools to determine what traffic should be permitted
    before gradually tightening security via `all-authenticated` or `cluster-authenticated`
    on the way to `deny`. Also remember that you can switch specific namespaces to
    `deny` as steps toward getting the whole cluster to `deny`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: In a *nonproduction* environment, of course, the broad stroke of just flipping
    everything to `deny` and watching what breaks is a *great* way to see exactly
    what communications are happening that you haven’t thought of yet. Just don’t
    go there in production!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Because the cluster-wide policy is a global setting, we’ll configure it using
    Helm. In [Example 8-4](#EX10-5), we’ll use `helm upgrade` to change Linkerd’s
    settings without changing the version of Linkerd you have installed. This example
    assumes you’re using Linkerd 2.13.4.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-4\. Cluster policy
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Namespace default policy
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Going further, we can flip the `emojivoto` namespace to `deny` to further protect
    our application, as shown in [Example 8-5](#EX10-namespace). Once we do this,
    *all* traffic in the namespace will be denied unless we explicitly authorize it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-5\. Namespace policy
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Timing Matters
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linkerd’s default inbound policy is read by your proxies at startup time. It
    is not read dynamically. This is important for operators to be aware of because
    it means any changes you make only take effect when your Pods are created. If
    you change the default inbound policy for the cluster or a namespace, those changes
    will only take effect after the Pods in your namespace are re-created. Pod-level
    inbound policy changes will take effect when the Kubernetes API restarts the modified
    Pods, so they will effectively get applied as soon as you modify the Deployments,
    StatefulSets, or DaemonSets in question.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: With that, we’ve managed to block communication between our workloads in the
    `emojivoto` namespace…and *everything* is broken. To make the app work again,
    we need to start allowing necessary traffic again with *dynamic policy*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Dynamic Policy
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As demonstrated, it’s not very useful just to use defaults to block everything.
    It’s time to look at how to use our dynamic policy resources to allow useful,
    necessary traffic to flow. We’ll start with a fairly simple concept: many organizations
    treat namespaces as logical boundaries between applications or teams, so it often
    makes sense to allow workloads in the same namespace to talk to each other. This
    is commonly called *namespace isolation*.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Namespace isolation
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With namespace isolation, we can easily restrict traffic in a namespace exclusively
    to those workloads that share that namespace. In our example, we’ll start by permitting
    traffic within the `emojivoto` namespace as long as the source and destination
    identities are *both* within this single namespace. This makes sense for the emojivoto
    application because the only things running in its namespace are parts of emojivoto itself:
    it’s a natural result of the idea that the application is contained within a single
    namespace.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Identities, Not IP Addresses
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note that we said “source and destination *identities*.” Everything Linkerd
    does with policy is based on the workload identity, not the workload’s IP address
    or anything else about the network. The workloads don’t even need to be in the
    same cluster, as long as the identities line up.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll set up namespace isolation for `emojivoto` in [Example 8-6](#EX10-namespace-isolation).
    Fair warning: this will look complex. The inline comments are very important to
    fully understand exactly what’s going on in this example.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-6\. Namespace isolation for `emojivoto`
  id: totrans-103
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: What’s in a Name?
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linkerd Server objects are the core construct that allows us to apply policy
    to our applications. They work by matching Pods based on some selection criteria
    and then selecting a port *by the port’s name*. Kubernetes will allow you to create
    Pods without adding a name to a port, so you must be sure that when using Linkerd
    policy in your cluster, every port in your applications has a value set for its
    name.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: We know that was a lot of YAML! Policy definition is the most labor-intensive
    task you’ll need to undertake to use Linkerd. Luckily for all of us, policy is
    an opt-in feature that you can prepare for in advance of turning it on. We *strongly*
    recommend you thoroughly test all your policy objects in a nonproduction environment
    before applying them to a live environment.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Test Early, Test Often
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This bears repeating. *Policy is complex* and easy to get wrong. We *strongly*
    encourage that you test your policy definitions in a nonproduction environment
    before taking them to production.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Allowing Linkerd Viz
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At this point, we’ve isolated the `emojivoto` namespace within the cluster:
    nothing from outside the namespace gets to speak with anything inside the namespace.
    Unfortunately, this will break things like monitoring applications and ingress
    controllers. This is decidedly less than ideal: while we’ve done a lot to secure
    our `emojivoto` namespace, we’ve caused other problems. For example, we’ve left
    any potential operations folks with little to no ability to monitor what our emojivoto
    workloads are doing.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: To fix this, we can use dynamic policy resources that reference identities from
    *outside* the namespace. In [Example 8-7](#EX10-viz) we’ll walk you through installing
    Linkerd Viz and allowing it to poll your applications, as shown in [Figure 8-5](#emojivoto-allowing-viz).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0805](assets/luar_0805.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: Figure 8-5\. emojivoto policy allowing Linkerd Viz
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Example 8-7\. Let there be Viz!
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With that complete, we’ve now walked through what you need to do to isolate
    traffic within a namespace but still allow in an external monitoring tool like
    the Linkerd Viz extension. You now have the basic knowledge required to begin
    isolating your own workloads by namespace with Linkerd’s policy tools. Next, we’ll
    get a little more granular and only allow specific service accounts to access
    our workloads.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Locking down by port and identity
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Namespace isolation goes a long way to further hardening our environment, but
    we can go further than that. With the isolation we’ve applied so far, any request
    is allowed as long as the calling workload and the called workload are both in
    the `emojivoto` namespace, but this is probably more permissive than we really
    need. To go a little further, we can be explicit about which accounts are allowed
    to talk to which workloads—but of course, that requires knowing exactly which
    communications are truly required by the application.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Figuring out those requirements by inspecting code is tedious and error-prone,
    but fortunately we can do better than that by using tools like Linkerd Viz (or
    its commercial cousins from Buoyant) to help us map our application’s communication
    and build our policy objects.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'We need only a single Linkerd Viz CLI command to see which workloads are communicating
    with one another in the `emojivoto` namespace:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will produce a list of Deployments that are communicating with one another
    in this namespace. Deployments listed under the `SRC` column are the sources (clients)
    for requests; those listed under `DST` are the destinations (servers).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’d prefer to investigate using the Viz dashboard rather than its CLI,
    you can run:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The Viz dashboard is out of scope for this book, but it’s fairly intuitive,
    and we encourage you to poke around in it if you haven’t had the chance to use
    it before.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: From the output we can see the connections between our emojivoto workloads,
    as shown in [Figure 8-6](#emojivoto-app-connections).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0806](assets/luar_0806.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
- en: Figure 8-6\. emojivoto inter-workload communications
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'emojivoto is a very simple application, so there are only three connections:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '`vote-bot` talks to the `web` Deployment.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`web` communicates with `voting`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`web` communicates with `emoji`.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that, we can begin building policy. We’ll start by gathering the Subject
    names on our individual workloads, as shown in [Example 8-8](#EX10-gather-names).
    We’ll need to gather the names for `vote-bot` and `web`. We don’t need to allow
    `voting` or `emoji` to communicate with any other services, as neither of them
    act as clients for any other services.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-8\. Gathering Subject names
  id: totrans-138
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: What’s in a Name?
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why does the `vote-bot` workload get an identity named “default” while the `web`
    workload gets one named “web”? If you look carefully at the `vote-bot` and `web`
    Deployments, you’ll find that `web` specifies which ServiceAccount to use, but
    `vote-bot` does not…so `vote-bot` gets the default. *This is not a best practice*.
    In a perfect world, every workload would get its own ServiceAccount.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: We’re showing this because while it’s not ideal, it’s *very* common to see this
    default ServiceAccount in use when trying to set up policy for applications that
    weren’t designed with zero trust in mind—and you may need to create new ServiceAccounts
    in addition to creating policy resources!
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: With those two Subject names, we can update our policy to be much more explicit
    about who is allowed to talk to whom in the `emojivoto` namespace. It’s worth
    remembering that in the previous section we created a number of policy objects
    that allow the emojivoto workloads to talk to each other. In [Example 8-9](#EX10-less-permissive),
    we’ll be reusing some and removing others in order to move from a more permissive
    to less permissive security posture, as shown in [Figure 8-7](#emojivoto-less-permissive).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 0807](assets/luar_0807.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: Figure 8-7\. emojivoto less permissive model
  id: totrans-145
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Server-Side Policy
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Linkerd, the workload-based policy engine enforces all policy decisions on
    the server side. When we configure `deny` as the default in our environment, we
    have to go through each server individually to ensure all its clients have been
    explicitly allowed.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-9\. Restricting interapp communication
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Order of Operations
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we moved from namespace-wide permissions to more specific permissions, we
    created our new policy objects before removing the namespace-wide permissions.
    If we had inverted the order, we would have disrupted communication between the
    emojivoto workloads.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们从命名空间范围的权限转向更具体的权限时，我们在移除命名空间范围的权限之前创建了新的策略对象。如果我们颠倒了顺序，就可能会破坏 emojivoto
    工作负载之间的通信。
- en: You have now further restricted access to the apps in the `emojivoto` namespace.
    Now communication between your workloads will occur only if it has been explicitly
    authorized by your platform team. Every denial is logged by the Linkerd proxy,
    and your security team can use these logs to identify malicious behavior in your
    clusters. Hopefully you can see how this sort of hardening dramatically reduces
    the risk of an intrusion in your environment and, with proper monitoring and logging,
    dramatically increases the likelihood that suspicious behavior will be caught.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在进一步限制了对 `emojivoto` 命名空间中应用程序的访问。现在，只有在您的平台团队明确授权的情况下，您的工作负载之间才会发生通信。Linkerd
    代理会记录每次拒绝，并且您的安全团队可以使用这些日志来识别集群中的恶意行为。希望您能看到这种加固方式如何显著降低环境中入侵的风险，并且通过适当的监控和日志记录，显著增加捕捉可疑行为的可能性。
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Linkerd’s Server-based policy is its oldest policy mechanism, but it’s still
    incredibly effective in a great many situations. Server-based policy gives you
    the ability to set known, trustworthy defaults while also making it straightforward
    to tune everything for your application, and Linkerd’s Tap ability lets you quickly
    get a sense of what you need to sort out.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd 的基于服务器的策略是其最古老的策略机制，但在许多情况下仍然非常有效。基于服务器的策略使您能够设置已知的、可信的默认值，同时也可以简单地调整应用程序的所有内容，Linkerd
    的 Tap 功能使您能够快速了解需要解决的问题。
