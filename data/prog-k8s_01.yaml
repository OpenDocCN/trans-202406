- en: Chapter 1\. Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Programming Kubernetes can mean different things to different people. In this
    chapter, we’ll first establish the scope and focus of this book. Also, we will
    share the set of assumptions about the environment we’re operating in and what
    you’ll need to bring to the table, ideally, to benefit most from this book. We
    will define what exactly we mean by programming Kubernetes, what Kubernetes-native
    apps are, and, by having a look at a concrete example, what their characteristics
    are. We will discuss the basics of controllers and operators, and how the event-driven
    Kubernetes control plane functions in principle. Ready? Let’s get to it.
  prefs: []
  type: TYPE_NORMAL
- en: What Does Programming Kubernetes Mean?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We assume you have access to a running Kubernetes cluster such as Amazon EKS,
    Microsoft AKS, Google GKE, or one of the OpenShift offerings.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You will spend a fair amount of time developing *locally* on your laptop or
    desktop environment; that is, the Kubernetes cluster against which you’re developing
    is local, rather than in the cloud or in your datacenter. When developing locally,
    you have a number of options available. Depending on your operating system and
    other preferences you might choose one (or maybe even more) of the following solutions
    for running Kubernetes locally: [kind](https://kind.sigs.k8s.io), [k3d](http://bit.ly/2Ja1LaH),
    or [Docker Desktop](https://dockr.ly/2PTJVLL).^([1](ch01.html#idm46336877072840))'
  prefs: []
  type: TYPE_NORMAL
- en: 'We also assume that you are a Go programmer—that is, you have experience or
    at least basic familiarity with the Go programming language. Now is a good time,
    if any of those assumptions do not apply to you, to train up: for Go, we recommend
    [*The Go Programming Language*](https://www.gopl.io) by Alan A. A. Donovan and
    Brian W. Kernighan (Addison-Wesley) and [*Concurrency in Go*](http://bit.ly/2tdCt5j)
    by Katherine Cox-Buday (O’Reilly). For Kubernetes, check out one or more of the
    following books:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Kubernetes in Action*](http://bit.ly/2Tb8Ydo) by Marko Lukša (Manning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Kubernetes: Up and Running*, 2nd Edition](https://oreil.ly/2SaANU4) by Kelsey
    Hightower et al. (O’Reilly)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Cloud Native DevOps with Kubernetes*](https://oreil.ly/2BaE1iq) by John Arundel
    and Justin Domingus (O’Reilly)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Managing Kubernetes*](https://oreil.ly/2wtHcAm) by Brendan Burns and Craig
    Tracey (O’Reilly)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Kubernetes Cookbook*](http://bit.ly/2FTgJzk) by Sébastien Goasguen and Michael
    Hausenblas (O’Reilly)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Why do we focus on programming Kubernetes in Go? Well, an analogy might be
    useful here: Unix was written in the C programming language, and if you wanted
    to write applications or tooling for Unix you would default to C. Also, in order
    to extend and customize Unix—even if you were to use a language other than C—you
    would need to at least be able to read C.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, Kubernetes and many related cloud-native technologies, from container runtimes
    to monitoring such as Prometheus, are written in Go. We believe that the majority
    of native applications will be Go-based and hence we focus on it in this book.
    Should you prefer other languages, keep an eye on the [kubernetes-client](http://bit.ly/2xfSrfT)
    GitHub organization. It may, going forward, contain a client in your favorite
    programming language.
  prefs: []
  type: TYPE_NORMAL
- en: 'By “programming Kubernetes” in the context of this book, we mean the following:
    you are about to develop a Kubernetes-native application that directly interacts
    with the API server, querying the state of resources and/or updating their state.
    We do not mean running off-the-shelf apps, such as WordPress or Rocket Chat or
    your favorite enterprise CRM system, oftentimes called *commercially available
    off-the-shelf* (COTS) apps. Besides, in [Chapter 7](ch07.html#ch_shipping), we
    do not really focus too much on operational issues, but mainly look at the development
    and testing phase. So, in a nutshell, this book is about developing genuinely
    cloud-native applications. [Figure 1-1](#apps-on-kube) might help you soak that
    in better.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Different types of apps running on Kubernetes](assets/prku_0101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-1\. Different types of apps running on Kubernetes
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As you can see, there are different styles at your disposal:'
  prefs: []
  type: TYPE_NORMAL
- en: Take a COTS such as Rocket Chat and run it on Kubernetes. The app itself is
    not aware it runs on Kubernetes and usually doesn’t have to be. Kubernetes controls
    the app’s lifecycle—find node to run, pull image, launch container(s), carry out
    health checks, mount volumes, and so on—and that is that.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a bespoke app, something you wrote from scratch, with or without having
    had Kubernetes as the runtime environment in mind, and run it on Kubernetes. The
    same modus operandi as in the case of a COTS applies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The case we focus on in this book is a cloud-native or Kubernetes-native application
    that is fully aware it is running on Kubernetes and leverages Kubernetes APIs
    and resources to some extent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The price you pay developing against the Kubernetes API pays off: on the one
    hand you gain portability, as your app will now run in any environment (from an
    on-premises deployment to any public cloud provider), and on the other hand you
    benefit from the clean, declarative mechanism Kubernetes provides.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on to a concrete example now.
  prefs: []
  type: TYPE_NORMAL
- en: A Motivational Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To demonstrate the power of a Kubernetes-native app, let’s assume you want to
    implement `at`—that is, [schedule the execution of a command](http://bit.ly/2L4VqzU)
    at a given time.
  prefs: []
  type: TYPE_NORMAL
- en: 'We call this [`cnat`](http://bit.ly/2RpHhON) or cloud-native `at`, and it works
    as follows. Let’s say you want to execute the command `echo "Kubernetes native
    rocks!"` at 2 a.m. on July 3, 2019\. Here’s what you would do with `cnat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Behind the scenes, the following components are involved:'
  prefs: []
  type: TYPE_NORMAL
- en: A custom resource called `cnat.programming-kubernetes.info/cnrex`, representing
    the schedule.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A controller to execute the scheduled command at the correct time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, a `kubectl` plug-in for the CLI UX would be useful, allowing simple
    handling via commands like `kubectl` `at` `"02:00 Jul 3"` `echo` `"Kubernetes
    native rocks!"` We won’t write this in this book, but you can refer to [the Kubernetes
    documentation for instructions](http://bit.ly/2J1dPuN).
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the book, we will use this example to discuss aspects of Kubernetes,
    its inner workings, and how to extend it.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the more advanced examples in Chapters [8](ch08.html#ch_custom-api-servers)
    and [9](ch09.html#ch_advanced-topics), we will simulate a pizza restaurant with
    pizza and topping objects in the cluster. See [“Example: A Pizza Restaurant”](ch08.html#aggregation-example)
    for details.'
  prefs: []
  type: TYPE_NORMAL
- en: Extension Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes is a powerful and inherently extensible system. In general, there
    are multiple ways to customize and/or extend Kubernetes: using [configuration
    files and flags](http://bit.ly/2KteqbA) for control plane components like the
    `kubelet` or the Kubernetes API server, and through a number of defined extension
    points:'
  prefs: []
  type: TYPE_NORMAL
- en: So-called [cloud providers](http://bit.ly/2FpHInw), which were traditionally
    in-tree as part of the controller manager. As of 1.11, Kubernetes makes out-of-tree
    development possible by providing a [custom `cloud-controller-manager` process
    to integrate with a cloud](http://bit.ly/2WWlcxk). Cloud providers allow the use
    of cloud provider–specific tools like load balancers or Virtual Machines (VMs).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary `kubelet` plug-ins for [network](http://bit.ly/2L1tPzm), [devices](http://bit.ly/2XthLgM)
    (such as GPUs), [storage](http://bit.ly/2x7Unaa), and [container runtimes](http://bit.ly/2Zzh1Eq).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary `kubectl` [plug-ins](http://bit.ly/2FmH7mu).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access extensions in the API server, such as the [dynamic admission control
    with webhooks](http://bit.ly/2DwR2Y3) (see [Chapter 9](ch09.html#ch_advanced-topics)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom resources (see [Chapter 4](ch04.html#ch_crds)) and custom controllers;
    see the following section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom API servers (see [Chapter 8](ch08.html#ch_custom-api-servers)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scheduler extensions, such as using a [webhook](http://bit.ly/2xcg4FL) to implement
    your own scheduling decisions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Authentication](http://bit.ly/2Oh6DPS) with webhooks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the context of this book we focus on custom resources, controllers, webhooks,
    and custom API servers, along with the Kubernetes [extension patterns](http://bit.ly/2L2SJ1C).
    If you’re interested in other extension points, such as storage or network plug-ins,
    check out the [official documentation](http://bit.ly/2Y0L1J9).
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a basic understanding of the Kubernetes extension patterns
    and the scope of this book, let’s move on to the heart of the Kubernetes control
    plane and see how we can extend it.
  prefs: []
  type: TYPE_NORMAL
- en: Controllers and Operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section you’ll learn about controllers and operators in Kubernetes and
    how they work.
  prefs: []
  type: TYPE_NORMAL
- en: Per the [Kubernetes glossary](http://bit.ly/2IWGlxz), a *controller* implements
    a control loop, watching the shared state of the cluster through the API server
    and making changes in an attempt to move the current state toward the desired
    state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we dive into the controller’s inner workings, let’s define our terminology:'
  prefs: []
  type: TYPE_NORMAL
- en: Controllers can act on core resources such as deployments or services, which
    are typically part of the [Kubernetes controller manager](http://bit.ly/2WUAEVy)
    in the control plane, or can watch and manipulate user-defined custom resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operators are controllers that encode some operational knowledge, such as application
    lifecycle management, along with the custom resources defined in [Chapter 4](ch04.html#ch_crds).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naturally, given that the latter concept is based on the former, we’ll look
    at controllers first and then discuss the more specialized case of an operator.
  prefs: []
  type: TYPE_NORMAL
- en: The Control Loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In general, the control loop looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Read the state of resources, preferably event-driven (using watches, as discussed
    in [Chapter 3](ch03.html#ch_client-go)). See [“Events”](#controller-events) and
    [“Edge- Versus Level-Driven Triggers”](#edge-vs-level) for details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the state of objects in the cluster or the cluster-external world. For
    example, launch a pod, create a network endpoint, or query a cloud API. See [“Changing
    Cluster Objects or the External World”](#controller-change-world) for details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update status of the resource in step 1 via the API server in `etcd`. See [“Optimistic
    Concurrency”](#optimistic-concurrency) for details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat cycle; return to step 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No matter how complex or simple your controller is, these three steps—read resource
    state ˃ change the world ˃ update resource status—remain the same. Let’s dig a
    bit deeper into how these steps are actually implemented in a Kubernetes controller.
    The control loop is depicted in [Figure 1-2](#controller-loop-overview), which
    shows the typical moving parts, with the main loop of the controller in the middle.
    This main loop is continuously running inside of the controller process. This
    process is usually running inside a pod in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes control loop](assets/prku_0102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-2\. Kubernetes control loop
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'From an architectural point of view, a controller typically uses the following
    data structures (as discussed in detail in [Chapter 3](ch03.html#ch_client-go)):'
  prefs: []
  type: TYPE_NORMAL
- en: Informers
  prefs: []
  type: TYPE_NORMAL
- en: Informers watch the desired state of resources in a scalable and sustainable
    fashion. They also implement a resync mechanism (see [“Informers and Caching”](ch03.html#informers)
    for details) that enforces periodic reconciliation, and is often used to make
    sure that the cluster state and the assumed state cached in memory do not drift
    (e.g., due bugs or network issues).
  prefs: []
  type: TYPE_NORMAL
- en: Work queues
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, a work queue is a component that can be used by the event handler
    to handle queuing of state changes and help to implement retries. In `client-go`
    this functionality is available via the [*workqueue* package](http://bit.ly/2x7zyeK)
    (see [“Work Queue”](ch03.html#workqueue)). Resources can be requeued in case of
    errors when updating the world or writing the status (steps 2 and 3 in the loop),
    or just because we have to reconsider the resource after some time for other reasons.
  prefs: []
  type: TYPE_NORMAL
- en: For a more formal discussion of Kubernetes as a declarative engine and state
    transitions, read [“The Mechanics of Kubernetes”](http://bit.ly/2IV2lcb) by Andrew
    Chen and Dominik Tornow.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now take a closer look at the control loop, starting with Kubernetes event-driven
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Events
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Kubernetes control plane heavily employs events and the principle of loosely
    coupled components. Other distributed systems use remote procedure calls (RPCs)
    to trigger behavior. Kubernetes does not. Kubernetes controllers watch changes
    to Kubernetes objects in the API server: adds, updates, and removes. When such
    an event happens, the controller executes its business logic.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in order to launch a pod via a deployment, a number of controllers
    and other control plane components work together:'
  prefs: []
  type: TYPE_NORMAL
- en: The deployment controller (inside of `kube-controller-manager`) notices (through
    a deployment informer) that the user creates a deployment. It creates a replica
    set in its business logic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The replica set controller (again inside of `kube-controller-manager`) notices
    (through a replica set informer) the new replica set and subsequently runs its
    business logic, which creates a pod object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The scheduler (inside the `kube-scheduler` binary)—which is also a controller—notices
    the pod (through a pod informer) with an empty `spec.nodeName` field. Its business
    logic puts the pod in its scheduling queue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Meanwhile the `kubelet`—another controller—notices the new pod (through its
    pod informer). But the new pod’s `spec.nodeName` field is empty and therefore
    does not match the `kubelet`’s node name. It ignores the pod and goes back to
    sleep (until the next event).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The scheduler takes the pod out of the work queue and schedules it to a node
    that has enough free resources by updating the `spec.nodeName` field in the pod
    and writing it to the API server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `kubelet` wakes up again due to the pod update event. It again compares
    the `spec.nodeName` with its own node name. The names match, and so the `kubelet`
    starts the containers of the pod and reports back that the containers have been
    started by writing this information into the pod status, back to the API server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The replica set controller notices the changed pod but has nothing to do.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eventually the pod terminates. The `kubelet` will notice this, get the pod object
    from the API server and set the “terminated” condition in the pod’s status, and
    write it back to the API server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The replica set controller notices the terminated pod and decides that this
    pod must be replaced. It deletes the terminated pod on the API server and creates
    a new one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, a number of independent control loops communicate purely through
    object changes on the API server and events these changes trigger through informers.
  prefs: []
  type: TYPE_NORMAL
- en: These events are sent from the API server to the informers inside the controllers
    via watches (see [“Watches”](ch03.html#client-go-watches))—that is, streaming
    connections of watch events. All of this is mostly invisible to the user. Not
    even the API server audit mechanism makes these events visible; only the object
    updates are visible. Controllers often use log output, though, when they react
    on events.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to learn more about events, read Michael Gasch’s blog post [“Events,
    the DNA of Kubernetes”](http://bit.ly/2MZwbl6), where he provides more background
    and examples.
  prefs: []
  type: TYPE_NORMAL
- en: Edge- Versus Level-Driven Triggers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s step back a bit and look more abstractly at how we can structure business
    logic implemented in controllers, and why Kubernetes has chosen to use events
    (i.e., state changes) to drive its logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two principled options to detect state change (the event itself):'
  prefs: []
  type: TYPE_NORMAL
- en: Edge-driven triggers
  prefs: []
  type: TYPE_NORMAL
- en: At the point in time the state change occurs, a handler is triggered—for example,
    from no pod to pod running.
  prefs: []
  type: TYPE_NORMAL
- en: Level-driven triggers
  prefs: []
  type: TYPE_NORMAL
- en: The state is checked at regular intervals and if certain conditions are met
    (for example, pod running), then a handler is triggered.
  prefs: []
  type: TYPE_NORMAL
- en: The latter is a form of polling. It does not scale well with the number of objects,
    and the latency of controllers noticing changes depends on the interval of polling
    and how fast the API server can answer. With many asynchronous controllers involved,
    as described in [“Events”](#controller-events), the result is a system that takes
    a long time to implement the users’ desire.
  prefs: []
  type: TYPE_NORMAL
- en: The former option is much more efficient with many objects. The latency mostly
    depends on the number of worker threads in the controller’s processing events.
    Hence, Kubernetes is based on events (i.e., edge-driven triggers).
  prefs: []
  type: TYPE_NORMAL
- en: In the Kubernetes control plane, a number of components change objects on the
    API server, with each change leading to an event (i.e., an edge). We call these
    components *event sources* or *event producers*. On the other hand, in the context
    of controllers, we’re interested in consuming events—that is, when and how to
    react to an event (via an informer).
  prefs: []
  type: TYPE_NORMAL
- en: In a distributed system there are many actors running in parallel, and events
    come in asynchronously in any order. When we have a buggy controller logic, some
    slightly wrong state machine, or an external service failure, it is easy to lose
    events in the sense that we don’t process them completely. Hence, we have to take
    a deeper look at how to cope with errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Figure 1-3](#edge-vs-level-overview) you can see different strategies at
    work:'
  prefs: []
  type: TYPE_NORMAL
- en: An example of an edge-driven-only logic, where potentially the second state
    change is missed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An example of an edge-triggered logic, which always gets the latest state (i.e.,
    level) when processing an event. In other words, the logic is edge-triggered but
    level-driven.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An example of an edge-triggered, level-driven logic with additional resync.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Trigger options (edge vs. level)](assets/prku_0103.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-3\. Trigger options (edge-driven versus level-driven)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Strategy 1 does not cope well with missed events, whether because broken networking
    makes it lose events, or because the controller itself has bugs or some external
    cloud API was down. Imagine that the replica set controller would replace pods
    only when they terminate. Missing events would mean that the replica set would
    always run with fewer pods because it never reconciles the whole state.
  prefs: []
  type: TYPE_NORMAL
- en: Strategy 2 recovers from those issues when another event is received because
    it implements its logic based on the latest state in the cluster. In the case
    of the replica set controller, it will always compare the specified replica count
    with the running pods in the cluster. When it loses events, it will replace all
    missing pods the next time a pod update is received.
  prefs: []
  type: TYPE_NORMAL
- en: Strategy 3 adds continuous resync (e.g., every five minutes). If no pod events
    come in, it will at least reconcile every five minutes, even if the application
    runs very stably and does not lead to many pod events.
  prefs: []
  type: TYPE_NORMAL
- en: Given the challenges of pure edge-driven triggers, the Kubernetes controllers
    typically implement the third strategy.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to learn more about the origins of the triggers and the motivations
    for level triggering with reconciliation in Kubernetes, read James Bowes’s article,
    [“Level Triggering and Reconciliation in Kubernetes”](http://bit.ly/2FmLLAW).
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the discussion of the different, abstract ways to detect external
    changes and to react on them. The next step in the control loop of [Figure 1-2](#controller-loop-overview)
    is to change the cluster objects or to change the external world following the
    spec. We’ll look at it now.
  prefs: []
  type: TYPE_NORMAL
- en: Changing Cluster Objects or the External World
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this phase, the controller changes the state of the objects it is supervising.
    For example, the `ReplicaSet` controller in the [controller manager](http://bit.ly/2WUAEVy)
    is supervising pods. On each event (edge-triggered), it will observe the current
    state of its pods and compare that with the desired state (level-driven).
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the act of changing the resource state is domain- or task-specific, we
    can provide little guidance. Instead, we’ll keep looking at the `ReplicaSet` controller
    we introduced earlier. `ReplicaSet`s are used in deployments, and the bottom line
    of the respective controller is: maintain a user-defined number of identical pod
    replicas. That is, if there are fewer pods than the user specified—for example,
    because a pod died or the replica value has been increased—the controller will
    launch new pods. If, however, there are too many pods, it will select some for
    termination. The entire business logic of the controller is available via [the
    *replica_set.go* package](http://bit.ly/2L4eKxa), and the following excerpt of
    the Go code deals with the state change (edited for clarity):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that the controller computes the difference between specification
    and current state in the line `diff` `:= len(filteredPods) - int(*(rs.Spec.Replicas))`
    and then implements two cases depending on that:'
  prefs: []
  type: TYPE_NORMAL
- en: '`diff` `<` `0`: Too few replicas; more pods must be created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`diff` `>` `0`: Too many replicas; pods must be deleted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also implements a strategy to choose pods where it is least harmful to delete
    them in `getPodsToDelete`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Changing the resource state does not, however, necessarily mean that the resources
    themselves have to be part of the Kubernetes cluster. In other words, a controller
    can change the state of resources that are located outside of Kubernetes, such
    as a cloud storage service. For example, the [AWS Service Operator](http://bit.ly/2ItJcif)
    allows you to manage AWS resources. Among other things, it allows you to manage
    S3 buckets—that is, the S3 controller is supervising a resource (the S3 bucket)
    that exists outside of Kubernetes, and the state changes reflect concrete phases
    in its lifecycle: an S3 bucket is created and at some point deleted.'
  prefs: []
  type: TYPE_NORMAL
- en: This should convince you that with a custom controller you can manage not only
    core resources, like pods, and custom resources, like our `cnat` example, but
    even compute or store resources that exist outside of Kubernetes. This makes controllers
    very flexible and powerful integration mechanisms, providing a unified way to
    use resources across platforms and environments.
  prefs: []
  type: TYPE_NORMAL
- en: Optimistic Concurrency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [“The Control Loop”](#controller-loop), we discussed in step 3 that a controller—after
    updating cluster objects and/or the external world according to the spec—writes
    the results into the status of the resource that triggered the controller run
    in step 1.
  prefs: []
  type: TYPE_NORMAL
- en: This and actually any other write (also in step 2) can go wrong. In a distributed
    system, this controller is probably only one of many that update resources. Concurrent
    writes can fail because of write conflicts.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand what’s happening, let’s step back a bit and have a look
    at [Figure 1-4](#scheduling-archs).^([2](ch01.html#idm46336867946120))
  prefs: []
  type: TYPE_NORMAL
- en: '![Scheduling architectures in distributed systems](assets/prku_0104.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-4\. Scheduling architectures in distributed systems
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The source defines Omega’s parallel scheduler architecture as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Our solution is a new parallel scheduler architecture built around shared state,
    using lock-free optimistic concurrency control, to achieve both implementation
    extensibility and performance scalability. This architecture is being used in
    Omega, Google’s next-generation cluster management system.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'While Kubernetes inherited a lot of traits and lessons learned from [Borg](http://bit.ly/2XNSv5p),
    this specific, transactional control plane feature comes from Omega: in order
    to carry out concurrent operations without locks, the Kubernetes API server uses
    optimistic concurrency.'
  prefs: []
  type: TYPE_NORMAL
- en: This means, in a nutshell, that if and when the API server detects concurrent
    write attempts, it rejects the latter of the two write operations. It is then
    up to the client (controller, scheduler, `kubectl`, etc.) to handle a conflict
    and potentially retry the write operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following demonstrates the idea of optimistic concurrency in Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The code shows a retry loop that gets the latest object `foo` in each iteration,
    then tries to update the world and `foo`’s status to match `foo`’s spec. The changes
    done before the `Update` call are optimistic.
  prefs: []
  type: TYPE_NORMAL
- en: The returned object `foo` from the `client.Get` call contains a *resource version*
    (part of the embedded `ObjectMeta` struct—see [“ObjectMeta”](ch03.html#ObjectMeta)
    for details), which will tell `etcd` on the write operation behind the `client.Update`
    call that another actor in the cluster wrote the `foo` object in the meantime.
    If that’s the case, our retry loop will get a *resource version conflict error*.
    This means that the optimistic concurrency logic failed. In other words, the `client.Update`
    call is also optimistic.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The resource version is actually the `etcd` key/value version. The resource
    version of each object is a string in Kubernetes that contains an integer. This
    integer comes directly from `etcd`. `etcd` maintains a counter that increases
    each time the value of a key (which holds the object’s serialization) is modified.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the API machinery code the resource version is (more or less consequently)
    handled like an arbitrary string, but with some ordering on it. The fact that
    integers are stored is just an implementation detail of the current `etcd` storage
    backend.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a concrete example. Imagine your client is not the only actor
    in the cluster that modifies a pod. There is another actor, namely the `kubelet`,
    that constantly modifies some fields because a container is constantly crashing.
    Now your controller reads the pod object’s latest state like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now assume the controller needs several seconds with its updates to the world.
    Seven seconds later, it tries to update the pod it read—for example, it sets an
    annotation. Meanwhile, the `kubelet` has noticed yet another container restart
    and updated the pod’s status to reflect that; that is, `resourceVersion` has increased
    to 58.
  prefs: []
  type: TYPE_NORMAL
- en: 'The object your controller sends in the update request has `resourceVersion:
    57`. The API server tries to set the `etcd` key for the pod with that value. `etcd`
    notices that the resource versions do not match and reports back that 57 conflicts
    with 58\. The update fails.'
  prefs: []
  type: TYPE_NORMAL
- en: The bottom line of this example is that for your controller, you are responsible
    for implementing a retry strategy and for adapting if an optimistic operation
    failed. You never know who else might be manipulating state, whether other custom
    controllers or core controllers such as the deployment controller.
  prefs: []
  type: TYPE_NORMAL
- en: 'The essence of this is: *conflict errors are totally normal in controllers.
    Always expect them and handle them gracefully*.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to point out that optimistic concurrency is a perfect fit for
    level-based logic, because by using level-based logic you can just rerun the control
    loop (see [“Edge- Versus Level-Driven Triggers”](#edge-vs-level)). Another run
    of that loop will automatically undo optimistic changes from the previous failed
    optimistic attempt, and it will try to update the world to the latest state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s move on to a specific case of custom controllers (along with custom resources):
    the operator.'
  prefs: []
  type: TYPE_NORMAL
- en: Operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Operators as a concept in Kubernetes were introduced by CoreOS in 2016\. In
    his seminal blog post, [“Introducing Operators: Putting Operational Knowledge
    into Software”](http://bit.ly/2ZC4Rui), CoreOS CTO Brandon Philips defined operators
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A Site Reliability Engineer (SRE) is a person [who] operates an application
    by writing software. They are an engineer, a developer, who knows how to develop
    software specifically for a particular application domain. The resulting piece
    of software has an application’s operational domain knowledge programmed into
    it.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[…]'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We call this new class of software Operators. An Operator is an application-specific
    controller that extends the Kubernetes API to create, configure, and manage instances
    of complex stateful applications on behalf of a Kubernetes user. It builds upon
    the basic Kubernetes resource and controller concepts but includes domain or application-specific
    knowledge to automate common tasks.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In the context of this book, we will use operators as Philips describes them
    and, more formally, require that the following three conditions hold (see also
    [Figure 1-5](#operator-conceptual)):'
  prefs: []
  type: TYPE_NORMAL
- en: There’s some domain-specific operational knowledge you’d like to automate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best practices for this operational knowledge are known and can be made
    explicit—for example, in the case of a Cassandra operator, when and how to re-balance
    nodes, or in the case of an operator for a service mesh, how to create a route.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The artifacts shipped in the context of the operator are:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of *custom resource definitions* (CRDs) capturing the domain-specific
    schema and custom resources following the CRDs that, on the instance level, represent
    the domain of interest.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A custom controller, supervising the custom resources, potentially along with
    core resources. For example, the custom controller might spin up a pod.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![The concept of an operator](assets/prku_0105.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-5\. The concept of an operator
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Operators have [come a long way](http://bit.ly/2x5TSNw) from the conceptual
    work and prototyping in 2016 to the launch of [OperatorHub.io](https://operatorhub.io)
    by Red Hat (which acquired CoreOS in 2018 and continued to build out the idea)
    in early 2019\. See [Figure 1-6](#operatorhub) for a screenshot of the hub in
    mid-2019 sporting some 17 operators, ready to be used.
  prefs: []
  type: TYPE_NORMAL
- en: '![OperatorHub.io screen shot](assets/prku_0106.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-6\. OperatorHub.io screenshot
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this first chapter we defined the scope of our book and what we expect from
    you. We explained what we mean by programming Kubernetes and defined Kubernetes-native
    apps in the context of this book. As preparation for later examples, we also provided
    a high-level introduction to controllers and operators.
  prefs: []
  type: TYPE_NORMAL
- en: So, now that you know what to expect from the book and how you can benefit from
    it, let’s jump into the deep end. In the next chapter, we’ll take a closer look
    at the Kubernetes API, the API server’s inner workings, and how you can interact
    with the API using command-line tools such as `curl`.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch01.html#idm46336877072840-marker)) For more on this topic, see Megan
    O’Keefe’s [“A Kubernetes Developer Workflow for MacOS”](http://bit.ly/2WXfzu1),
    *Medium*, January 24, 2019; and Alex Ellis’s blog post, [“Be KinD to yourself”](http://bit.ly/2XkK9C1),
    December 14, 2018.
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch01.html#idm46336867946120-marker)) Source: [“Omega: Flexible, Scalable
    Schedulers for Large Compute Clusters”](http://bit.ly/2PjYZ59), by Malte Schwarzkopf
    et al., Google AI, 2013.'
  prefs: []
  type: TYPE_NORMAL
