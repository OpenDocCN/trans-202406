- en: Chapter 7\. Introduction to the Aggregation Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Many applications require data analysis of one form or another. MongoDB provides
    powerful support for running analytics natively using the aggregation framework.
    In this chapter, we introduce this framework and some of the fundamental tools
    it provides. We’ll cover:'
  prefs: []
  type: TYPE_NORMAL
- en: The aggregation framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregation stages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregation expressions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregation accumulators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter we’ll dive deeper and look at more advanced aggregation
    features, including the ability to perform joins across collections.
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines, Stages, and Tunables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aggregation framework is a set of analytics tools within MongoDB that allow
    you to do analytics on documents in one or more collections.
  prefs: []
  type: TYPE_NORMAL
- en: The aggregation framework is based on the concept of a pipeline. With an aggregation
    pipeline we take input from a MongoDB collection and pass the documents from that
    collection through one or more stages, each of which performs a different operation
    on its inputs ([Figure 7-1](#fig0701)). Each stage takes as input whatever the
    stage before it produced as output. The inputs and outputs for all stages are
    documents—a stream of documents, if you will.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/mdb3_0701.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. The aggregation pipeline
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you’re familiar with pipelines in a Linux shell, such as bash, this is a
    very similar idea. Each stage has a specific job that it does. It expects a specific
    form of document and produces a specific output, which is itself a stream of documents.
    At the end of the pipeline we get access to the output, in much the same way that
    we would by executing a find query. That is, we get a stream of documents back
    that we can then use to do additional work, whether it’s creating a report of
    some kind, generating a website, or some other type of task.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s dive in a little deeper and consider the individual stages. An individual
    stage of an aggregation pipeline is a data processing unit. It takes in a stream
    of input documents one at a time, processes each document one at a time, and produces
    an output stream of documents one at a time ([Figure 7-2](#fig0702)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/mdb3_0702.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. Stages of the aggregation pipeline
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Each stage provides a set of knobs, or *tunables*, that we can control to parameterize
    the stage to perform whatever task we’re interested in doing. A stage performs
    a generic, general-purpose task of some kind, and we parameterize the stage for
    the particular collection that we’re working with and exactly what we would like
    that stage to do with those documents.
  prefs: []
  type: TYPE_NORMAL
- en: These tunables typically take the form of operators that we can supply that
    will modify fields, perform arithmetic operations, reshape documents, or do some
    sort of accumulation task or a variety of other things.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start looking at some concrete examples, there’s one more aspect of
    pipelines that is especially important to keep in mind as you begin to work with
    them. Frequently, we want to include the same type of stage multiple times within
    a single pipeline ([Figure 7-3](#fig0703)). For example, we may want to perform
    an initial filter so that we don’t have to pass the entire collection into our
    pipeline. Later, following some additional processing, we might then want to filter
    further, applying a different set of criteria.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/mdb3_0703.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-3\. Repeated stages in the aggregation pipeline
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To recap, pipelines work with MongoDB collections. They’re composed of stages,
    each of which does a different data processing task on its input and produces
    documents as output to be passed to the next stage. Finally, at the end of the
    processing, a pipeline produces output that we can then do something with in our
    application or that we can send to a collection for later use. In many cases,
    in order to perform the analysis we need to do, we will include the same type
    of stage multiple times within an individual pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Getting Started with Stages: Familiar Operations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started developing aggregation pipelines, we will look at building some
    pipelines that involve operations that are already familiar to you. For this we
    will look at the *match*, *project*, *sort*, *skip*, and *limit* stages.
  prefs: []
  type: TYPE_NORMAL
- en: To work through these aggregation examples, we will use a collection of company
    data. The collection has a number of fields that specify details about the companies,
    such as name, a short description of the company, and when the company was founded.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also fields describing the rounds of funding a company has gone through,
    important milestones for the company, whether or not the company has been through
    an initial public offering (IPO), and, if so, the details of the IPO. Here’s an
    example document containing data on Facebook, Inc.:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'As our first aggregation example, let’s do a simple filter looking for all
    companies that were founded in 2004:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This is equivalent to the following operation using `find`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s add a project stage to our pipeline to reduce the output to just
    a few fields per document. We’ll exclude the `"_id"` field, but include `"name"`
    and `"founded_year"`. Our pipeline will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run this, we get output that looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s unpack this aggregation pipeline in a little more detail. The first thing
    you will notice is that we’re using the `aggregate` method. This is the method
    we call when we want to run an aggregation query. To aggregate, we pass in an
    aggregation pipeline. A pipeline is an array with documents as elements. Each
    of the documents must stipulate a particular stage operator. In this example,
    we have a pipeline that has two stages: a match stage for filtering and a project
    stage with which we’re limiting the output to just two fields per document.'
  prefs: []
  type: TYPE_NORMAL
- en: The match stage filters against the collection and passes the resulting documents
    to the project stage one at a time. The project stage then performs its operation,
    reshaping the documents, and passes the output out of the pipeline and back to
    us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s extend our pipeline a bit further to include a limit stage. We’re
    going to match using the same query, but we’ll limit our result set to five and
    then project out the fields we want. For simplicity, let’s limit our output to
    just the names of each company:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we’ve constructed this pipeline so that we limit before the project
    stage. If we ran the project stage first and then the limit, as in the following
    query, we would get exactly the same results, but we’d have to pass hundreds of
    documents through the project stage before finally limiting the results to five:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Regardless of what types of optimizations the MongoDB query planner might be
    capable of in a given release, you should always consider the efficiency of your
    aggregation pipeline. Ensure that you are limiting the number of documents that
    need to be passed on from one stage to another as you build your pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: This requires careful consideration of the entire flow of documents through
    a pipeline. In the case of the preceding query, we’re only interested in the first
    five documents that match our query, regardless of how they are sorted, so it’s
    perfectly fine to limit as our second stage.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if the order matters, then we’ll need to sort before the limit stage.
    Sorting works in a manner similar to what we have seen already, except that in
    the aggregation framework, we specify sort as a stage within a pipeline as follows
    (in this case, we will sort by name in ascending order):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following result from our *companies* collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note that we’re looking at a different set of five companies now, getting instead
    the first five documents in alphanumeric order by name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s take a look at including a skip stage. Here, we sort first,
    then skip the first 10 documents and again limit our result set to 5 documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Let’s review our pipeline one more time. We have five stages. First, we’re filtering
    the *companies* collection, looking only for documents where the `"founded_year"`
    is `2004`. Then we’re sorting based on the name in ascending order, skipping the
    first 10 matches, and limiting our end results to 5\. Finally, we pass those five
    documents on to the project stage, where we reshape the documents such that our
    output documents contain just the company name.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we’ve looked at constructing pipelines using stages that perform operations
    that should already be familiar to you. These operations are provided in the aggregation
    framework because they are necessary for the types of analytics that we’ll want
    to accomplish using stages discussed in later sections. As we move through the
    rest of this chapter, we will take a deep dive into the other operations that
    the aggregation framework provides.
  prefs: []
  type: TYPE_NORMAL
- en: Expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we move deeper into our discussion of the aggregation framework, it is important
    to have a sense of the different types of expressions available for use as you
    construct aggregation pipelines. The aggregation framework supports many different
    classes of expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Boolean* expressions allow us to use AND, OR, and NOT expressions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Set* expressions allow us to work with arrays as sets. In particular, we can
    get the intersection or union of two or more sets. We can also take the difference
    of two sets and perform a number of other set operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Comparison* expressions enable us to express many different types of range
    filters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Arithmetic* expressions enable us to calculate the ceiling, floor, natural
    log, and log, as well as perform simple arithmetic operations like multiplication,
    division, addition, and subtraction. We can even do more complex operations, such
    as calculating the square root of a value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*String* expressions allow us to concatenate, find substrings, and perform
    operations having to do with case and text search operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Array* expressions provide a lot of power for manipulating arrays, including
    the ability to filter array elements, slice an array, or just take a range of
    values from a specific array.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Variable* expressions, which we won’t dive into too deeply, allow us to work
    with literals, expressions for parsing date values, and conditional expressions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Accumulators* provide the ability to calculate sums, descriptive statistics,
    and many other types of values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: $project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we’re going to take a deeper dive into the project stage and reshaping documents,
    exploring the types of reshaping operations that should be most common in the
    applications that you develop. We have seen some simple projections in aggregation
    pipelines, and now we’ll take a look at some that are a little more complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s look at promoting nested fields. In the following pipeline, we
    are doing a match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'As an example of the relevant fields for documents in our *companies* collection,
    let’s again look at a portion of the Facebook document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Going back to our match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'we are filtering for all companies that had a funding round in which Greylock
    Partners participated. The permalink value, `"greylock"`, is the unique identifier
    for such documents. Here is another view of the Facebook document with just the
    relevant fields displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The project stage we have defined in this aggregation pipeline will suppress
    the `"_id"` and include the `"name"`. It will also promote some nested fields.
    This project uses dot notation to express field paths that reach into the `"ipo"`
    field and the `"funding_rounds"` field to select values from those nested documents
    and arrays. This project stage will make those the values of top-level fields
    in the documents it produces as output, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In the output, each document has a `"name"` field and a `"funders"` field. For
    those companies that have gone through an IPO, the `"ipo"` field contains the
    year the company went public and the `"valuation"` field contains the value of
    the company at the time of the IPO. Note that in all of these documents, these
    are top-level fields and the values for those fields were promoted from nested
    documents and arrays.
  prefs: []
  type: TYPE_NORMAL
- en: The `$` character used to specify the values for `ipo`, `valuation`, and `funders`
    in our project stage indicates that the values should be interpreted as field
    paths and used to select the value that should be projected for each field, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: One thing you might have noticed is that we’re seeing multiple values printed
    out for `funders`. In fact, we’re seeing an array of arrays. Based on our review
    of the Facebook example document, we know that all of the funders are listed within
    an array called `"investments"`. Our stage specifies that we want to project the
    `financial_org.permalink` value for each entry in the `"investments"` array, for
    every funding round. So, an array of arrays of funders’ names is built up.
  prefs: []
  type: TYPE_NORMAL
- en: In later sections we will look at how to perform arithmetic and other operations
    on strings, dates, and a number of other value types to project documents of all
    shapes and sizes. Just about the only thing we can’t do from a project stage is
    change the data type for a value.
  prefs: []
  type: TYPE_NORMAL
- en: $unwind
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with array fields in an aggregation pipeline, it is often necessary
    to include one or more unwind stages. This allows us to produce output such that
    there is one output document for each element in a specified array field.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/mdb3_0704.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-4\. $unwind takes an array from the input document and creates an output
    document for each element in that array
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the example in [Figure 7-4](#fig0704), we have an input document that has
    three keys and their corresponding values. The third key has as its value an array
    with three elements. `$unwind` if run on this type of input document and configured
    to unwind the `key3` field will produce documents that look like those shown at
    the bottom of [Figure 7-4](#fig0704). The thing that might not be intuitive to
    you about this is that in each of these output documents there will be a `key3`
    field, but that field will contain a single value rather than an array value,
    and there will be a separate document for each one of the elements that were in
    this array. In other words, if there were 10 elements in the array, the unwind
    stage would produce 10 output documents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go back to our *companies* example, and take a look at the use of an
    unwind stage. We’ll start with the following aggregation pipeline. Note that in
    this pipeline, as in the previous section, we are simply matching on a specific
    funder and promoting values from embedded `funding_rounds` documents using a project
    stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, here’s an example of the data model for documents in this collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Our aggregation query will produce results such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The query produces documents that have arrays for both `"amount"` and `"year"`,
    because we’re accessing the `"raised_amount"` and `"funded_year"` for every element
    in the `"funding_rounds"` array.
  prefs: []
  type: TYPE_NORMAL
- en: To fix this, we can include an unwind stage before our project stage in this
    aggregation pipeline, and parameterize this by specifying that it is the `"funding_rounds"`
    array that should be unwound ([Figure 7-5](#fig0705)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/mdb3_0705.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-5\. The outline of our aggregation pipeline so far, matching for “greylock”
    then unwinding the “funding_rounds”, and finally projecting out the name, amount,
    and year for each of the funding rounds
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Returning again to our Facebook example, we can see that for each funding round
    there is a `"raised_amount"` field and a `"funded_year"` field.
  prefs: []
  type: TYPE_NORMAL
- en: 'The unwind stage will produce an output document for each element of the `"funding_rounds"`
    array. In this example our values are strings, but regardless of the type of value,
    the unwind stage will produce an output document for each one. Here’s the updated
    aggregation query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The unwind stage produces an exact copy of every one of the documents that
    it receives as input. All the fields will have the same key and value, with the
    exception of the `"funding_rounds"` field. Rather than being an array of `"funding_rounds"`
    documents, instead it will have a value that is a single document, which corresponds
    to an individual funding round:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s add an additional field to our output documents. In doing so, we’ll
    actually identify a small problem with this aggregation pipeline as currently
    written:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'In adding the `"funder"` field we now have a field path value that will access
    the `"investments"` field of the `"funding_rounds"` embedded document that it
    gets from the unwind stage and, for the financial organization, selects the permalink
    value. Note that this is very similar to what we’re doing in our match filter.
    Let’s have a look at our output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: To understand what we’re seeing here, we need to go back to our document and
    look at the `"investments"` field.
  prefs: []
  type: TYPE_NORMAL
- en: The `"funding_rounds.investments"` field is itself an array. Multiple funders
    can participate in each funding round, so `"investments"` will list every one
    of those funders. Looking at the results, as we originally saw with the `"raised_amount"`
    and `"funded_year"` fields, we’re now seeing an array for `"funder"` because `"investments"`
    is an array-valued field.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem is that because of the way we’ve written our pipeline, many
    documents are passed to the project stage that represent funding rounds that Greylock
    did not participate in. We can see this by looking at the funding rounds for Farecast.
    This problem stems from the fact that our match stage selects all companies where
    Greylock participated in at least one funding round. If we are interested in considering
    only those funding rounds in which Greylock actually participated, we need to
    figure out a way to filter differently.
  prefs: []
  type: TYPE_NORMAL
- en: One possibility is to reverse the order of our unwind and match stages—that
    is to say, do the unwind first and then do the match. This guarantees that we
    will only match documents coming out of the unwind stage. But in thinking through
    this approach, it quickly becomes clear that, with unwind as the first stage,
    we would be doing a scan through the entire collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'For efficiency, we want to match as early as possible in our pipeline. This
    enables the aggregation framework to make use of indexes, for example. So, in
    order to select only those funding rounds in which Greylock participated, we can
    include a second match stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This pipeline will first filter for companies where Greylock participated in
    at least one funding round. It will then unwind the funding rounds and filter
    again, so that only documents that represent funding rounds that Greylock actually
    participated in will be passed on to the project stage.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned at the beginning of this chapter, it is often the case that we
    need to include multiple stages of the same type. This is a good example: we’re
    filtering to reduce the number of documents that we’re looking at initially by
    narrowing down our set of documents for consideration to those for which Greylock
    participated in at least one funding round. Then, through our unwind stage, we
    end up with a number of documents that represent funding rounds from companies
    that Greylock did, in fact, fund, but individual funding rounds that Greylock
    did not participate in. We can get rid of all the funding rounds we’re not interested
    in by simply including another filter, using a second match stage.'
  prefs: []
  type: TYPE_NORMAL
- en: Array Expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let’s turn our attention to array expressions. As part of our deep dive,
    we’ll take a look at using array expressions in project stages.
  prefs: []
  type: TYPE_NORMAL
- en: The first expression we’ll examine is a filter expression. A filter expression
    selects a subset of the elements in an array based on filter criteria.
  prefs: []
  type: TYPE_NORMAL
- en: 'Working again with our *companies* dataset, we’ll match using the same criteria
    for funding rounds in which Greylock participated. Take a look at the `rounds`
    field in this pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The `rounds` field uses a filter expression. The `$filter` operator is designed
    to work with array fields and specifies the options we must supply. The first
    option to `$filter` is `input`. For `input`, we simply specify an array. In this
    case, we use a field path specifier to identify the `"funding_rounds"` array found
    in documents in our *companies* collection. Next, we specify the name we’d like
    to use for this `"funding_rounds"` array throughout the rest of our filter expression.
    Then, as the third option, we need to specify a condition. The condition should
    provide criteria used to filter whatever array we’ve provided as input, selecting
    a subset. In this case, we’re filtering such that we only select elements where
    the `"raised_amount"` for a `"funding_round"` is greater than or equal to 100
    million.
  prefs: []
  type: TYPE_NORMAL
- en: In specifying the condition, we’ve made use of `$$`. We use `$$` to reference
    a variable defined within the expression we’re working in. The `as` clause defines
    a variable within our filter expression. This variable has the name `"round"`
    because that’s what we labeled it in the `as` clause. This is to disambiguate
    a reference to a variable from a field path. In this case, our comparison expression
    takes an array of two values and will return `true` if the first value provided
    is greater than or equal to the second value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s consider what documents the project stage of this pipeline will produce,
    given this filter. The output documents will have `"name"`, `"founded_year"`,
    and `"rounds"` fields. The values for `"rounds"` will be arrays composed of the
    elements that match our filter condition: that the raised amount is greater than
    $100,000,000.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the match stage that follows, as we did previously, we will simply filter
    the input documents for those that were funded in some way by Greylock. Documents
    output by this pipeline will resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Only the `"rounds"` array items for which the raised amount exceeds $100,000,000
    will pass through the filter. In the case of Dropbox, there is just one round
    that meets that criterion. You have a lot of flexibility in how you set up filter
    expressions, but this is the basic form and provides a concrete example of a use
    case for this particular array expression.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s look at the array element operator. We’ll continue working with
    funding rounds, but in this case we simply want to pull out the first round and
    the last round. We might be interested, for example, in seeing when these rounds
    occurred or in comparing their amounts. These are things we can do with date and
    arithmetic expressions, as we’ll see in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `$arrayElemAt` operator enables us to select an element at a particular
    slot within an array. The following pipeline provides an example of using `$arrayElemAt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note the syntax for using `$arrayElemAt` within a project stage. We define a
    field that we want projected out and as the value specify a document with `$arrayElemAt`
    as the field name and a two-element array as the value. The first element should
    be a field path that specifies the array field we want to select from. The second
    element identifies the slot within that array that we want. Remember that arrays
    are 0-indexed.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, the length of an array is not readily available. To select array
    slots starting from the end of the array, use negative integers. The last element
    in an array is identified with `-1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple output document for this aggregation pipeline would resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Related to `$arrayElemAt` is the `$slice` expression. This allows us to return
    not just one but multiple items from an array in sequence, beginning with a particular
    index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Here, again with the `funding_rounds` array, we begin at index 1 and take three
    elements from the array. Perhaps we know that in this dataset the first funding
    round isn’t all that interesting, or we simply want some early ones but not the
    very first one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Filtering and selecting individual elements or slices of arrays are among the
    more common operations we need to perform on arrays. Probably the most common,
    however, is determining an array’s size or length. To do this we can use the `$size`
    operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: When used in a project stage, a `$size` expression will simply provide a value
    that is the number of elements in the array.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ve explored some of the most common array expressions. There
    are many more, and the list grows with each release. Please review the [Aggregation
    Pipeline Quick Reference in the MongoDB documentation](https://oreil.ly/ZtUES)
    for a summary of all expressions that are available.
  prefs: []
  type: TYPE_NORMAL
- en: Accumulators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, we’ve covered a few different types of expressions. Next, let’s
    look at what accumulators the aggregation framework has to offer. Accumulators
    are essentially another type of expression, but we think about them in their own
    class because they calculate values from field values found in multiple documents.
  prefs: []
  type: TYPE_NORMAL
- en: Accumulators the aggregation framework provides enable us to perform operations
    such as summing all values in a particular field (`$sum`), calculating an average
    (`$avg`), etc. We also consider `$first` and `$last` to be accumulators because
    these consider values in all documents that pass through the stage in which they
    are used. `$max` and `$min` are two more examples of accumulators that consider
    a stream of documents and save just one of the values they see. We can use `$mergeObjects`
    to combine multiple documents into a single document.
  prefs: []
  type: TYPE_NORMAL
- en: We also have accumulators for arrays. We can `$push` values onto an array as
    documents pass through a pipeline stage. `$addToSet` is very similar to `$push`
    except that it ensures no duplicate values are included in the resulting array.
  prefs: []
  type: TYPE_NORMAL
- en: Then there are some expressions for calculating descriptive statistics⁠—for
    example, for calculating the standard deviation of a sample and of a population.
    Both work with a stream of documents that pass through a pipeline stage.
  prefs: []
  type: TYPE_NORMAL
- en: Prior to MongoDB 3.2, accumulators were available only in the group stage. MongoDB
    3.2 introduced the ability to access a subset of accumulators within the project
    stage. The primary difference between the accumulators in the group stage and
    the project stage is that in the project stage accumulators such as `$sum` and
    `$avg` must operate on arrays within a single document, whereas accumulators in
    the group stage, as we’ll see in a later section, provide you with the ability
    to perform calculations on values across multiple documents.
  prefs: []
  type: TYPE_NORMAL
- en: That’s a quick overview of accumulators to provide some context and set the
    stage for our deep dive into examples.
  prefs: []
  type: TYPE_NORMAL
- en: Using Accumulators in Project Stages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll begin with an example of using an accumulator in a project stage. Note
    that our match stage filters for documents that contain a `"funding_rounds"` field
    and for which the `funding_rounds` array is not empty:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Because the value for `$funding_rounds` is an array within each company document,
    we can use an accumulator. Remember that in project stages accumulators must work
    on an array-valued field. In this case, we’re able to do something pretty cool
    here. We are easily identifying the largest value in an array by reaching into
    an embedded document within that array and projecting the max value in the output
    documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'As another example, let’s use the `$sum` accumulator to calculate the total
    funding for each company in our collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This is just a taste of what you can do using accumulators in project stages.
    Again, you’re encouraged to review the [Aggregation Pipeline Quick Reference in
    the MongoDB docs](https://oreil.ly/SZiFx) for a complete overview of the accumulator
    expressions available.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Grouping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Historically, accumulators were the province of the group stage in the MongoDB
    aggregation framework. The group stage performs a function that is similar to
    the SQL `GROUP BY` command. In a group stage, we can aggregate together values
    from multiple documents and perform some type of aggregation operation on them,
    such as calculating an average. Let’s take a look at an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we’re using a group stage to aggregate together all companies based on
    the year they were founded, then calculate the average number of employees for
    each year. The output for this pipeline resembles the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The output includes documents that have a document as their `"_id"` value, and
    then a report on the average number of employees. This is the type of analysis
    we might do as a first step in assessing the correlation between the year in which
    a company was founded and its growth, possibly normalizing for how old the company
    is.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the pipeline we built has two stages: a group stage and a sort
    stage. Fundamental to the group stage is the `"_id"` field that we specify as
    part of the document. This is the value of the `$group` operator itself, using
    a very strict interpretation.'
  prefs: []
  type: TYPE_NORMAL
- en: We use this field to define what the group stage uses to organize the documents
    that it sees. Since the group stage is first, the `aggregate` command will pass
    all documents in the *companies* collection through this stage. The group stage
    will take every document that has the same value for `"founded_year"` and treat
    them as a single group. In constructing the value for this field, this stage will
    use the `$avg` accumulator to calculate an average number of employees for all
    companies with the same `"founded_year"`.
  prefs: []
  type: TYPE_NORMAL
- en: You can think of it this way. Each time the group stage encounters a document
    with a specific founding year, it adds the value for `"number_of_employees"` from
    that document to a running sum of the number of employees and adds one to a count
    of the number of documents seen so far for that year. Once all documents have
    passed through the group stage, it can then calculate the average using that running
    sum and count for every grouping of documents it identified based on the year
    of founding.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this pipeline, we sort the documents into descending order by
    `average_number_of_employees`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at another example. One field we’ve not yet considered in the *companies*
    dataset is the relationships. The `relationships` field appears in documents in
    the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The `"relationships"` field gives us the ability to dive in and look for people
    who have, in one way or another, been associated with a relatively large number
    of companies. Let’s take a look at this aggregation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We’re matching on `relationships.person`. If we look at our Facebook example
    document, we can see how relationships are structured and get a sense for what
    it means to do this. We are filtering for all relationships for which `"person"`
    is not `null`. Then we project out all relationships for documents that match.
    We will pass only relationships to the next stage in the pipeline, which is unwind.
    We unwind the relationships so that every relationship in the array comes through
    to the group stage that follows. In the group stage, we use a field path to identify
    the person within each `"relationship"` document. All documents with the same
    `"person"` value will be grouped together. As we saw previously, it’s perfectly
    fine for a document to be the value around which we group. So, every match to
    a document for a first name, last name, and permalink for a person will be aggregated
    together. We use the `$sum` accumulator to count the number of relationships in
    which each person has participated. Finally, we sort into descending order. The
    output for this pipeline resembles the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Tim Hanlon is the individual who has participated in the most relationships
    with companies in this collection. It could be that Mr. Hanlon has actually had
    a relationship with 28 companies, but we can’t know that for sure, because it’s
    also possible that he has had multiple relationships with one or more companies,
    each with a different title. This example illustrates a very important point about
    aggregation pipelines: make sure you fully understand what it is you’re working
    with as you do calculations, particularly when you’re calculating aggregate values
    using accumulator expressions of some kind.'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we can say that Tim Hanlon appears 28 times in `"relationships"`
    documents throughout the companies in our collection. We would have to dig a little
    deeper to see exactly how many unique companies he was associated with, but we’ll
    leave the construction of that pipeline to you as an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: The _id Field in Group Stages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we go any further with our discussion of the group stage, let’s talk
    a little more about the `_id` field and look at some best practices for constructing
    values for this field in group aggregation stages. We’ll walk through a few examples
    that illustrate several different ways in which we commonly group documents. As
    our first example, consider this pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for this pipeline resembles the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In our output we have documents with two fields: `"_id"` and `"companies"`.
    Each of these documents contains a list of the companies founded in whatever the
    `"founded_year"` is, `"companies"` being an array of company names.'
  prefs: []
  type: TYPE_NORMAL
- en: Notice here how we’ve constructed the `"_id"` field in the group stage. Why
    not just provide the founding year rather than putting it inside a document with
    a field labeled `"founded_year"`. The reason we don’t do it that way is that if
    we don’t label the group value, it’s not explicit that we are grouping on the
    year in which the company was founded. In order to avoid confusion, it is a best
    practice to explicitly label values on which we group.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some circumstances it might be necessary to use another approach in which
    our `_id` value is a document composed of multiple fields. In this case, we’re
    actually grouping documents on the basis of their founding year and category code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'It is perfectly fine to use documents with multiple fields as our `_id` value
    in group stages. In other cases, it might also be necessary to do something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, we’re grouping documents based on the year in which the companies
    had their IPO, and that year is actually a field of an embedded document. It is
    common practice to use field paths that reach into embedded documents as the value
    on which to group in a group stage. In this case, the output will resemble the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the examples in this section use an accumulator we haven’t seen before:
    `$push`. As the group stage processes documents in its input stream, a `$push`
    expression will add the resulting value to an array that it builds throughout
    its run. In the case of the preceding pipeline, the group stage is building an
    array composed of company names.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our final example is one we’ve already seen, but it’s included here for the
    sake of completeness:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example where we were grouping on IPO year, we used a field
    path that resolved to a scalar value—the IPO year. In this case, our field path
    resolves to a document containing three fields: `"first_name`“, `"last_name"`,
    and `"permalink"`. This demonstrates that the group stage supports grouping on
    document values.'
  prefs: []
  type: TYPE_NORMAL
- en: You’ve now seen several ways in which we can construct `_id` values in group
    stages. In general, bear in mind that what we want to do here is make sure that
    in our output, the semantics of our `_id` value are clear.
  prefs: []
  type: TYPE_NORMAL
- en: Group Versus Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To round out our discussion of the group aggregation stage, we’ll take a look
    at a couple of additional accumulators that are not available in the project stage.
    This is to encourage you to think a little more deeply about what we can do in
    a project stage with respect to accumulators, and what we can do in group. As
    an example, consider this aggregation query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Here, we begin by filtering for documents for which the array `funding_rounds`
    is not empty. Then we unwind `funding_rounds`. Therefore, the sort and group stages
    will see one document for each element of the `funding_rounds` array for every
    company.
  prefs: []
  type: TYPE_NORMAL
- en: Our sort stage in this pipeline sorts on first year, then month, then day, all
    in ascending order. This means that this stage will output the oldest funding
    rounds first. And as you are aware from [Chapter 5](ch05.xhtml#chapter_d1e5128),
    we can support this type of sort with a compound index.
  prefs: []
  type: TYPE_NORMAL
- en: In the group stage that follows the sort, we group by company name and use the
    `$push` accumulator to construct a sorted array of funding rounds. The `funding_rounds`
    array will be sorted for each company because we sorted all funding rounds, globally,
    in the sort stage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Documents output from this pipeline will resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: In this pipeline, with `$push`, we are accumulating an array. In this case,
    we have specified our `$push` expression so that it adds documents to the end
    of the accumulation array. Since the funding rounds are in chronological order,
    pushing onto the end of the array guarantees that the the funding amounts for
    each company are sorted in chronological order.
  prefs: []
  type: TYPE_NORMAL
- en: '`$push` expressions only work in group stages. This is because group stages
    are designed to take an input stream of documents and accumulate values by processing
    each document in turn. Project stages, on the other hand, work with each document
    in their input stream individually.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at one other example. This is a little longer, but it builds
    on the previous one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we are unwinding `funding_rounds` and sorting chronologically. However,
    in this case, instead of accumulating an array of entries, each entry representing
    a single `funding_rounds`, we are using two accumulators we’ve not yet seen in
    action: `$first` and `$last`. A `$first` expression simply saves the first value
    that passes through the input stream for the stage. A `$last` expression simply
    tracks the values that pass through the group stage and hangs onto the last one.'
  prefs: []
  type: TYPE_NORMAL
- en: As with `$push`, we can’t use `$first` and `$last` in project stages because,
    again, project stages are not designed to accumulate values based on multiple
    documents streaming through them. Rather, they are designed to reshape documents
    individually.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to `$first` and `$last`, we also use `$sum` in this example to calculate
    the total number of funding rounds. For this expression we can just specify the
    value, `1`. A `$sum` expression like this simply serves to count the number of
    documents that it sees in each grouping.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, this pipeline includes a fairly complex project stage. However, all
    it is really doing is making the output prettier. Rather than show the `first_round`
    values, or entire documents for the first and last funding rounds, this project
    stage creates a summary. Note that this maintains good semantics, because each
    value is clearly labeled. For `first_round` we’ll produce a simple embedded document
    that contains just the essential details of amount, article, and year, pulling
    those values from the original funding round document that will be the value of
    `$first_round`. The project stage does something similar for `$last_round`. Finally,
    this project stage just passes through to output documents the `num_rounds` and
    `total_raised` values for documents it receives in its input stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'Documents output from this pipeline resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: And with that, we’ve concluded an overview of the group stage.
  prefs: []
  type: TYPE_NORMAL
- en: Writing Aggregation Pipeline Results to a Collection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two specific stages, `$out` and `$merge`, that can write documents
    resulting from the aggregation pipeline to a collection. You can use only one
    of these two stages, and it must be the last stage of an aggregation pipeline.
    `$merge` was introduced in MongoDB version 4.2 and is the preferred stage for
    writing to a collection, if available. `$out` has some limitations: it can only
    write to the same database, it overwrites any existing collection if present,
    and it cannot write to a sharded collection. `$merge` can write to any database
    and collection, sharded or not. `$merge` can also incorporate results (insert
    new documents, merge with existing documents, fail the operation, keep existing
    documents, or process all documents with a custom update) when working with an
    existing collection. But the real advantage of using `$merge` is that it can create
    on-demand materialized views, where the content of the output collection is incrementally
    updated when the pipeline is run.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have covered a number of different accumulators, some that
    are available in the project stage, and we’ve also covered how to think about
    when to use group versus project when considering various accumulators. Next,
    we’ll take a look at transactions in MongoDB.
  prefs: []
  type: TYPE_NORMAL
