- en: Chapter 12\. Multicluster Communication with Linkerd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every Kubernetes cluster represents a single security and operational failure
    domain. As you look at scaling out your platform to accommodate more teams, more
    customers, and more use cases, you will inevitably run into the question of how
    you want to distribute your apps. Do you want to use large regional clusters with
    all your production apps in one place? Do you want to use purpose-built clusters
    for each app or each team? Most teams end up somewhere in the middle, with some
    shared clusters and some purpose-built for certain apps or categories of apps.
  prefs: []
  type: TYPE_NORMAL
- en: Linkerd aims to make the technical implementation problems around running multiple
    clusters easier to solve.
  prefs: []
  type: TYPE_NORMAL
- en: Types of Multicluster Setups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Linkerd supports two styles of multicluster configurations: *gateway-based
    multicluster* and *Pod-to-Pod multicluster*. Gateway-based multicluster setups
    are easier to deploy; Pod-to-Pod setups offer more advanced functionality. You
    can choose which is best for a given situation, and you can even use both in the
    same cluster at the same time, if desired.'
  prefs: []
  type: TYPE_NORMAL
- en: Gateway-Based Multicluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Linkerd’s gateway-based multicluster setup routes communications between clusters
    through a special workload that Linkerd calls a gateway, which is reachable via
    a LoadBalancer Service. This means that gateway-based multicluster connections
    don’t require any particularly demanding network configuration: all that’s required
    for gateway-based multicluster communications is that Pods in a given cluster
    can connect to the LoadBalancer of the other cluster’s gateway, no matter how
    that happens. The network also doesn’t need to be secure: Linkerd will take care
    of that with its usual mTLS.'
  prefs: []
  type: TYPE_NORMAL
- en: The gateway-based multicluster architecture is shown in [Figure 12-1](#gateway-based-multicluster).
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 1201](assets/luar_1201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-1\. Gateway multicluster architecture
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The numbers in the diagram show the number of network hops made when the `vote-bot`
    in cluster 1 talks to `web` in cluster 2, which then talks to `vote` back in cluster
    1\. (This actually happens in emojivoto.) Following the path, you’ll see a total
    of six hops. This can complicate things sometimes, which led to the development
    of Pod-to-Pod multicluster.
  prefs: []
  type: TYPE_NORMAL
- en: Pod-to-Pod Multicluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Pod-to-Pod multicluster configuration, by contrast, relies on your Pods being
    able to talk *directly* to each other, even across cluster boundaries. This can
    be quite a bit more challenging to set up, because your cluster provider needs
    to be able to support it. If you’re creating your own bare-metal clusters, this
    is probably quite possible. If you’re using a cloud provider, it will depend on
    the provider.
  prefs: []
  type: TYPE_NORMAL
- en: The Pod-to-Pod multicluster architecture is shown in [Figure 12-2](#gatewayless-multicluster).
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 1202](assets/luar_1202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-2\. Pod-to-Pod multicluster architecture
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Following the path from `vote-bot` to `web` and back to `vote` here, we see
    only two hops, the same as we would see in a single cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Gateways Versus Pod-to-Pod
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with many things in computing, the mode to choose depends on your situation:'
  prefs: []
  type: TYPE_NORMAL
- en: The gateway-based multicluster mode is unquestionably simpler to set up; Pod-to-Pod
    requires more advanced networking support.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pod-to-Pod is marginally faster than gateway-based, since there’s no hop through
    a gateway. With Linkerd this tends to be negligible, though.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A potentially more important concern is that in a gateway-based multicluster
    setup, any call from another cluster will appear as having the identity *of the
    gateway*, not the actual originating workload.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another important concern is that in Pod-to-Pod mode, the Linkerd `destination`
    service also needs to be able to connect to the remote Kubernetes API server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember that the two modes can coexist in the same cluster as long as you have
    the correct IP connectivity. You have an enormous amount of flexibility in how
    you work with multicluster communications.
  prefs: []
  type: TYPE_NORMAL
- en: Multicluster Certificates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whichever kind of multicluster setup you decide to use, your clusters’ trust
    hierarchies need a common root for Linkerd to establish a multicluster connection
    between clusters. By far the easiest way to do this is to have them share a common
    trust anchor, as shown in [Figure 12-3](#multicluster-trust-hierarchy-2). This
    also implies that if you want clusters to be isolated from each other, they *must
    not* share the same trust anchor!
  prefs: []
  type: TYPE_NORMAL
- en: '![luar 1203](assets/luar_1203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-3\. A multicluster trust hierarchy
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The simplest way to manage this is usually to have a single trust anchor for
    each environment level (Dev, UAT, Production, Test, etc.), so that, for example,
    development clusters can peer with each other but not with production clusters.
    Likewise, it’s often simplest to set up a CA for each of these levels, too, so
    that each CA needs to worry about only one kind of certificate.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t Share Identity Issuers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even in multicluster setups, your clusters should not share identity issuer
    certificates. Keeping the identity issuers separate is important both for being
    certain of where a given workload identity originated and for simplifying the
    operational aspects of rotating the identity issuers.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, the needs of your environment will dictate how you set up certificates
    and CAs.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-Cluster Service Discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The last piece of the multicluster puzzle is service discovery: how do workloads
    in one cluster know where to find workloads in other clusters? Linkerd tackles
    this problem with the *service mirror*, which is a part of the control plane supplied
    by the Multicluster extension.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As its name implies, the service mirror arranges for Services in one cluster
    to appear in other clusters. Exactly how it sets up the mirrored Services depends
    on the type of multicluster configuration you’re using:'
  prefs: []
  type: TYPE_NORMAL
- en: Gateway-based multicluster
  prefs: []
  type: TYPE_NORMAL
- en: Connections to a mirrored Service will be redirected to the gateway in front
    of the original Service. The gateway then knows how to carry the requests on to
    a real Pod, including endpoint selection, policy enforcement, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Pod-to-Pod multicluster
  prefs: []
  type: TYPE_NORMAL
- en: Connections to a mirrored Service will simply transit the network directly to
    the other Pod. The Linkerd proxy next to the workload making the connection knows
    which endpoints are available directly, so it handles load balancing, policy enforcement,
    etc.
  prefs: []
  type: TYPE_NORMAL
- en: 'The service mirror doesn’t blindly mirror every Service; it only mirrors those
    with a `mirror.linkerd.io/exported` label. The value of the label, again, depends
    on the multicluster mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mirror.linkerd.io/exported: true`'
  prefs: []
  type: TYPE_NORMAL
- en: For gateway-based multicluster configurations. The service mirror will expect
    there to be a gateway for the remote cluster, and it will set up the mirrored
    Service to use it.
  prefs: []
  type: TYPE_NORMAL
- en: '`mirror.linkerd.io/exported: remote-discovery`'
  prefs: []
  type: TYPE_NORMAL
- en: For Pod-to-Pod multicluster configurations. The service mirror will set up the
    mirrored Service to go directly to the original Pods.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also worth noting that the service mirror needs permission to talk to the
    remote cluster’s Kubernetes API server. Credentials for this are handled by the
    Linkerd Link resource, created with the `linkerd multicluster link` CLI command.
  prefs: []
  type: TYPE_NORMAL
- en: Links and GitOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Link resources are actually a little bit more imperative than they should be:
    running the `linkerd multicluster link` command creates a credentials Secret,
    a Link resource, and the service mirror controller. Unfortunately, it’s extremely
    hard to replicate everything without actually running the command right now.'
  prefs: []
  type: TYPE_NORMAL
- en: With all of that background, we can start setting up an example multicluster
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up for Multicluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multicluster Linkerd *always* requires that you be able to route IP traffic
    between your clusters. In some cases, it also requires that all clusters have
    distinct, nonoverlapping cluster and service CIDR ranges.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, ensuring that these requirements are met is a bit outside the scope
    of the service mesh! However, to demonstrate a multicluster setup in this chapter,
    we’ll be creating two k3d clusters, and we’ll need to make sure the requirements
    are met when we do so. We’ll call out where we’re doing k3d-specific infrastructure
    things as we go.
  prefs: []
  type: TYPE_NORMAL
- en: First, as shown in [Example 12-1](#EX-mc-creating-clusters), we’ll create two
    k3d clusters attached to the same Docker network, and we’ll give them independent
    cluster and service CIDRs so that we can use this setup either for gateway-based
    multicluster or for Pod-to-Pod multicluster mode.
  prefs: []
  type: TYPE_NORMAL
- en: This entire block is k3d-specific, unsurprisingly!
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-1\. Creating clusters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that both clusters are told to use the same Docker network (`--network=mc-network`),
    but they have independent, nonoverlapping CIDR ranges.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll continue by setting up IP routing between clusters, as shown in [Example 12-2](#EX-mc-ip-routing).
    The `docker exec` commands here are k3d-specific, but the idea of running the
    `ip route add` command on the Nodes themselves is actually not k3d-specific.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-2\. Setting up IP routing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Once we have routing set up, it’s time to create new certificates using `step`,
    as shown in [Example 12-3](#EX-mc-create-certs). As noted previously, you’ll need
    to use the same trust anchor for every cluster, no matter what kind of cluster
    you’re using.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-3\. Creating certificates for multicluster
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Finally, given our certificates, we can install Linkerd and the Viz extension!
    This is shown in [Example 12-4](#EX-mc-install-linkerd).
  prefs: []
  type: TYPE_NORMAL
- en: Be Careful of Contexts!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have personally made far more mistakes than we’d care to admit to when working
    with multicluster setups. A truly embarrassing amount of the time, the problem
    was because we ran a `kubectl` command against the wrong cluster—so pay attention
    to those `--context` arguments!
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, just set up a window for each cluster and work that way. This
    works well if you have separate Kubernetes configuration files and can set the
    `KUBECONFIG` variable differently depending on which cluster you want.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-4\. Installing Linkerd
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we have to decide whether we’re using a gateway-based or Pod-to-Pod
    multicluster architecture, because what we do from this point forward changes.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing with a Gateway-Based Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want a Pod-to-Pod setup, skip ahead to [“Continuing with a Pod-to-Pod
    Setup”](#continuing_with_a_pod-to-pod_setup_ch12_LUAR_multicluster_1708965399165).
  prefs: []
  type: TYPE_NORMAL
- en: To continue with gateway-based multicluster mode, we install the Linkerd Multicluster
    extension as shown in [Example 12-5](#EX-mc-install-with-gateways). This extension
    also ships with the core Linkerd CLI, so you needn’t install an extra command
    to use it. This is the default way to install Linkerd Multicluster, since gateway-based
    multicluster mode predates Pod-to-Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-5\. Installing Linkerd Multicluster with gateways
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: After that, we’ll need to link our clusters together using the gateways, as
    shown in [Example 12-6](#EX-mc-link-with-gateways).
  prefs: []
  type: TYPE_NORMAL
- en: k3d and --api-server-address
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'k3d clusters are weird: they always create Kubernetes contexts that say that
    the Kubernetes API server is on localhost. With our multicluster setup on the
    same Docker network, our `cluster1` cannot use localhost to talk to `cluster2`,
    or vice versa.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, for k3d, we have to use `--api-server-address` to override the address
    with a routable IP address for the other cluster. This is specific to k3d.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-6\. Linking the clusters with gateways
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: At this point, skip ahead to [“Multicluster Gotchas”](#directions_and_contexts_ch12).
  prefs: []
  type: TYPE_NORMAL
- en: Continuing with a Pod-to-Pod Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want a gateway-based setup, go back to [“Continuing with a Gateway-Based
    Setup”](#continuing_with_a_gateway-based_setup_ch12_LUAR_multicluster_1708965417142).
  prefs: []
  type: TYPE_NORMAL
- en: To continue with Pod-to-Pod multicluster mode, we install the Linkerd Multicluster
    extension as shown in [Example 12-7](#EX-mc-install-pod-to-pod), using the `--gateway
    false` flag.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-7\. Installing Linkerd Multicluster Pod-to-Pod
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now we need to link our clusters, as shown in [Example 12-8](#EX-mc-link-pod-to-pod).
    Again, we need the `--gateway false` flag (and we only need `--api-server-address`
    for k3d).
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-8\. Linking the clusters Pod-to-Pod
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Multicluster Gotchas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Irrespective of whether you’re setting up for gateway-based multicluster or
    Pod-to-Pod multicluster, there are two things that are always very important to
    bear in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Directions, contexts, and links
  prefs: []
  type: TYPE_NORMAL
- en: Every `linkerd multicluster link` command creates a unidirectional link. Running
    a `link` command in the `cluster1` context and applying it to the `cluster2` context
    is giving `cluster2` the permissions and DNS information needed to communicate
    with `cluster1`. Basically, running the `link` command in the `cluster1` context
    gathers information and credentials *about* `cluster1`; applying it in the `cluster2`
    context gives everything *to* `cluster2`.
  prefs: []
  type: TYPE_NORMAL
- en: In our example setup (whether gateway or Pod-to-Pod), we run two links, one
    in each direction. In most two-cluster setups, this makes sense, but it’s definitely
    not required.
  prefs: []
  type: TYPE_NORMAL
- en: Checking Your connections
  prefs: []
  type: TYPE_NORMAL
- en: We’ve helped a lot of folks troubleshoot their multicluster setups, and the
    most common problem we’ve seen is a lack of connectivity between the clusters.
    When you’re debugging multicluster setups, the first thing to check is *always*
    to make sure that you have the appropriate connectivity between your clusters.
  prefs: []
  type: TYPE_NORMAL
- en: You can usually do this very effectively simply by running a Pod in one cluster
    with tools like `curl`, `dig`, etc., and then trying to make simple HTTP calls
    to the other cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and Connecting an Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, we have our clusters connected, and we need to begin taking advantage
    of our links. In [Example 12-9](#EX-mc-install-emojivoto) we will deploy the [emojivoto
    sample application](https://oreil.ly/qfGlx) across two clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-9\. Deploying a multicluster application
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: At this point, the Pods will be running in each cluster, but they have no information
    about how to talk to each other. You can verify this simply by looking at the
    Services in each cluster, as shown in [Example 12-10](#EX-mc-check-services).
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-10\. Checking the Services in each cluster
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'To make emojivoto work in our scenario, we’ll need to mirror services across
    the clusters. For each Service we want exported, we’ll add the `mirror.link⁠erd.io/exported`
    label to it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re using gateway-based multicluster mode, use `mirror.link⁠erd.io/exported:
    true`, as shown in [Example 12-11](#EX-mc-export-with-gateways).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you’re using Pod-to-Pod multicluster mode, use `mirror.link⁠erd.io/exported:
    remote-discovery`, as shown in [Example 12-12](#EX-mc-export-pod-to-pod).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example 12-11\. Exporting Services with gateways
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Example 12-12\. Exporting Services Pod-to-Pod
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In either case, if you check the Services in the `emojivoto` namespace, as shown
    in [Example 12-13](#EX-mc-check-mirrored-services), you’ll see the mirrored Services.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-13\. Checking on mirrored Services
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: If using Pod-to-Pod multicluster mode, you can also use `linkerd diagnostics
    endpoints` to check that everything is working correctly, as shown in [Example 12-14](#EX-mc-diag-endpoints).
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-14\. Checking on Service endpoints
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As implied by [Example 12-14](#EX-mc-diag-endpoints), mirrored Services appear
    as `*serviceName-clusterName*`; for example, the `emoji-svc` mirrored from `cluster2`
    into `cluster1` will appear as `emoji-svc-cluster2`.
  prefs: []
  type: TYPE_NORMAL
- en: This is a rare case where, by default, the application may have to change to
    work with Linkerd. The manifests that we applied in [Example 12-9](#EX-mc-install-emojivoto)
    have already been tweaked so that the emojivoto app uses the mirrored Service
    names, but you can also use an HTTPRoute and a placeholder Service to redirect
    traffic.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we want all traffic for `emoji-svc` to be redirected to
    `emoji-svc-cluster2`. We could start by creating a Service named `emoji-svc` with
    no `selector`, so that it’s simply not possible for that Service to match any
    Pods. This is shown in [Example 12-15](#EX-mc-placeholder-service).
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-15\. A placeholder `emoji-svc` Service
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We can then associate an HTTPRoute with the placeholder Service to redirect
    all the traffic, as shown in [Example 12-16](#EX-mc-redirect-placeholder).
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-16\. Redirecting all traffic to the placeholder `emoji-svc` Service
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Checking Traffic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, traffic should be flowing across clusters and the emojivoto application
    should be working, as you should be able to see by pointing a web browser to the
    `web-svc` service in `cluster1`, as shown in [Example 12-17](#EX-mc-browser-time).
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-17\. Checking out emojivoto with a browser
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You can also watch traffic flowing in the Linkerd Viz dashboard, accessible
    by running either command shown in [Example 12-18](#EX-mc-viz), or by using the
    CLI commands in [Example 12-19](#EX-mc-viz-cli).
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-18\. Multicluster Linkerd Viz dashboard
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Example 12-19\. Multicluster Linkerd Viz CLI
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: However you look at it, you should be able to see traffic flowing across clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Policy in Multicluster Environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There’s one more thing to cover before we close out the chapter. Linkerd policy
    is applicable not just within but also between clusters. However, as you saw in
    Figures [12-1](#gateway-based-multicluster) and [12-2](#gatewayless-multicluster),
    the two modes work differently. When using gateway-based multicluster mode, the
    gateway itself is where you need to apply any cross-cluster policy. It will accept
    policy configurations like any other workload in the mesh.
  prefs: []
  type: TYPE_NORMAL
- en: Pod-to-Pod multicluster mode has the advantage of preserving the identity of
    the originating workload when you make multicluster requests. That means you can
    set a policy directly on your target workload to only accept requests from the
    services that need to access it.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered how multicluster architecture works in Linkerd and showed
    you how to set it up in a local environment. Linkerd’s multicluster features are
    robust, powerful, and used at scale by some of the largest organizations in the
    world. Consider how a multicluster setup could impact your environment and if
    it’s a good addition to your platform.
  prefs: []
  type: TYPE_NORMAL
