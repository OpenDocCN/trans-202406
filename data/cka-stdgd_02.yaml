- en: Chapter 2\. Cluster Architecture, Installation, and Configuration
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章. 集群架构、安装和配置
- en: According to the name of the chapter, the first section of the curriculum refers
    to typical tasks you’d expect of a Kubernetes administrator. Those tasks include
    understanding the architectural components of a Kubernetes cluster, setting up
    a cluster from scratch, and maintaining a cluster going forward.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 根据章节名称，课程的第一部分涉及您对Kubernetes管理员预期的典型任务。这些任务包括理解Kubernetes集群的架构组件、从头开始设置集群以及在之后维护集群。
- en: Interestingly, this section also covers the security aspects of a cluster, more
    specifically role-based access control (RBAC). You are expected to understand
    how to map permissions for operations to API resources for a set of users or processes.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，本节还涵盖了集群的安全方面，特别是基于角色的访问控制（RBAC）。您需要了解如何将操作的权限映射到一组用户或进程的API资源。
- en: At the end of this chapter, you will understand the tools and procedures for
    installing and maintaining a Kubernetes cluster. Moreover, you’ll know how to
    configure RBAC for representative, real-world use cases.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章末尾，您将了解安装和维护Kubernetes集群的工具和流程。此外，您还将了解如何针对典型的实际用例配置RBAC。
- en: 'At a high level, this chapter covers the following concepts:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 高级别来看，本章涵盖以下概念：
- en: Understanding RBAC
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解RBAC
- en: Installing of a cluster with `kubeadm`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`kubeadm`安装集群
- en: Upgrading a version of a Kubernetes cluster with `kubeadm`
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`kubeadm`升级Kubernetes集群版本
- en: Backing up and restoring etcd with `etcdctl`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`etcdctl`备份和恢复etcd
- en: Understanding a highly available Kubernetes cluster
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解高可用性的Kubernetes集群
- en: Role-Based Access Control
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于角色的访问控制
- en: In Kubernetes you need to be authenticated before you are allowed to make a
    request to an API resource. A cluster administrator usually has access to all
    resources and operations. The easiest way to operate a cluster is to provide everyone
    with an admin account. While “admin access for everyone” sounds fantastic as you
    grow your business, it comes with a considerable amount of risk. Users may accidentally
    delete a Secret Kubernetes object, which likely breaks one or many applications
    and therefore has a tremendous impact on end users. As you can imagine, this approach
    is not a good idea for production environments that run mission-critical applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，在允许对API资源进行请求之前，您需要经过身份验证。集群管理员通常可以访问所有资源和操作。操作集群的最简单方式是提供每个人一个管理员帐户。尽管“每个人都有管理员访问权限”听起来很棒，但随着业务的发展，这带来了相当大的风险。用户可能会意外删除一个Secret
    Kubernetes对象，这可能会破坏一个或多个应用程序，因此对最终用户造成巨大影响。可以想象，这种方法对运行关键应用程序的生产环境并不是一个好主意。
- en: As with other production systems, only certain users should have full access,
    whereas the majority of users have read-only access (and potentially access to
    mutate the system) depending on the role. For example, application developers
    do not need to manage cluster nodes. They only need to tend to the objects required
    to run and configure their application.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他生产系统一样，只有特定用户应该拥有完全访问权限，而大多数用户根据角色仅具有只读访问权限（并可能访问以改变系统）。例如，应用程序开发人员不需要管理集群节点。他们只需要管理运行和配置其应用程序所需的对象。
- en: RBAC defines policies for users, groups, and processes by allowing or disallowing
    access to manage API resources. Enabling and configuring RBAC is mandatory for
    any organization with a strong emphasis on security. For the exam, you need to
    understand the involved RBAC API resource types and how to create and configure
    them in different scenarios.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: RBAC通过允许或禁止访问管理API资源来定义用户、组和进程的策略。对于安全重视的任何组织而言，启用和配置RBAC都是必需的。考试中，您需要理解涉及的RBAC
    API资源类型以及如何在不同场景下创建和配置它们。
- en: RBAC High-Level Overview
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RBAC高级概述
- en: 'RBAC helps with implementing a variety of use cases:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: RBAC有助于实现多种用例：
- en: Establishing a system for users with different roles to access a set of Kubernetes
    resources
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立一个允许具有不同角色的用户访问一组Kubernetes资源的系统
- en: Controlling processes running in a Pod and the operations they can perform via
    the Kubernetes API
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Kubernetes API控制运行在Pod中的进程及其操作
- en: Limiting the visibility of certain resources per namespace
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制每个命名空间中某些资源的可见性
- en: RBAC consists of three key building blocks, as shown in [Figure 2-1](#rbac_key_building_blocks).
    Together, they connect API primitives and their allowed operations to the so-called
    subject, which is a user, a group, or a ServiceAccount.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: RBAC 由三个关键构建块组成，如[图 2-1](#rbac_key_building_blocks)所示。它们将 API 原语及其允许的操作与所谓的主体（用户、组或
    ServiceAccount）连接起来。
- en: 'The following list breaks down the responsibilities by terminology:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表按术语分解了职责：
- en: Subject
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 主体
- en: The user or process that wants to access a resource
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 想要访问资源的用户或进程
- en: Resource
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 资源
- en: The Kubernetes API resource type (e.g., a Deployment or node)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes API 资源类型（例如 Deployment 或节点）
- en: Verb
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 动词
- en: The operation that can be executed on the resource (e.g., creating a Pod or
    deleting a Service)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 可对资源执行的操作（例如创建 Pod 或删除 Service）
- en: '![ckas 0201](Images/ckas_0201.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![ckas 0201](Images/ckas_0201.png)'
- en: Figure 2-1\. RBAC key building blocks
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1\. RBAC 的关键构建块
- en: Creating a Subject
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建主体
- en: In the context of RBAC, you can use a user account, service account, or a group
    as a subject. Users and groups are not stored in etcd, the Kubernetes database,
    and are meant for processes running outside of the cluster. Service accounts exists
    as objects in Kubernetes and are used by processes running inside of the cluster.
    In this section, you’ll learn how to create them.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RBAC 的上下文中，您可以使用用户帐户、服务帐户或组作为主体。用户和组不存储在 etcd、Kubernetes 数据库中，而是用于运行在集群外的进程。服务帐户作为
    Kubernetes 中的对象存在，并由运行在集群内的进程使用。本节将教您如何创建它们。
- en: User accounts and groups
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户帐户和组
- en: Kubernetes does not represent a user as with an API resource. The user is meant
    to be managed by the administrator of a Kubernetes cluster, which then distributes
    the credentials of the account to the real person or to be used by an external
    process.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 不像 API 资源那样表示用户。用户由 Kubernetes 集群的管理员管理，然后将帐户的凭据分发给真实人员或供外部进程使用。
- en: Calls to the API server with a user need to be authenticated. Kubernetes offers
    a variety of authentication methods for those API requests. [Table 2-1](#authentication_strategies_for_managing_rbac_subjects)
    shows different ways of authenticating RBAC subjects.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 需要对使用用户的 API 请求进行身份验证。Kubernetes 为这些 API 请求提供了多种身份验证方法。表 2-1（#authentication_strategies_for_managing_rbac_subjects）显示了管理
    RBAC 主体的不同身份验证方式。
- en: Table 2-1\. Authentication strategies for managing RBAC subjects
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-1\. 用于管理 RBAC 主体的认证策略
- en: '| Authentication strategy | Description |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 认证策略 | 描述 |'
- en: '| --- | --- |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| X.509 client certificate | Uses an OpenSSL client certificate to authenticate
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| X.509 客户端证书 | 使用 OpenSSL 客户端证书进行身份验证 |'
- en: '| Basic authentication | Uses username and password to authenticate |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 基本身份验证 | 使用用户名和密码进行身份验证 |'
- en: '| Bearer tokens | Uses OpenID (a flavor of OAuth2) or webhooks as a way to
    authenticate |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Bearer 令牌 | 使用 OpenID（OAuth2 的一种变体）或 Webhook 进行身份验证 |'
- en: 'To keep matters simple, the following steps demonstrate the creation of a user
    that uses an OpenSSL client certificate to authenticate. Those actions have to
    be performed with the cluster-admin Role object. During the exam, you will not
    have to create a user yourself. You can assume that the relevant setup has been
    performed for you. Therefore, you will not need to memorize the following steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为简化操作，以下步骤演示了使用 OpenSSL 客户端证书创建用户的过程。这些操作必须使用 cluster-admin 角色对象执行。在考试期间，您不需要自己创建用户。可以假设相关设置已为您执行。因此，您无需记忆以下步骤：
- en: 'Log into the Kubernetes control plane node and create a temporary directory
    that will hold the generated keys. Navigate into the directory:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到 Kubernetes 控制平面节点，并创建一个临时目录，用于保存生成的密钥。进入该目录：
- en: '[PRE0]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a private key using the `openssl` executable. Provide an expressive
    file name, such as `<username>.key`:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `openssl` 可执行文件创建私钥。提供一个具有表达性的文件名，例如 `<username>.key`：
- en: '[PRE1]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create a certificate sign request (CSR) in a file with the extension `.csr`.
    You need to provide the private key from the previous step. The `-subj` option
    provides the username (CN) and the group (O). The following command uses the username
    `johndoe` and the group named `cka-study-guide`. To avoid assigning the user to
    a group, leave off the /O component of the assignment:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文件中创建证书签名请求（CSR），其扩展名为`.csr`。您需要提供上一步骤中的私钥。`-subj` 选项提供了用户名（CN）和组（O）。以下命令使用用户名
    `johndoe` 和名为 `cka-study-guide` 的组。如果不想将用户分配到组中，请省略 /O 组件的赋值：
- en: '[PRE2]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Lastly, sign the CSR with the Kubernetes cluster certificate authority (CA).
    The CA can usually be found in the directory `/etc/kubernetes/pki` and needs to
    contain the files `ca.crt` and `ca.key`. We are going to use minikube here, which
    stores those files in the directory pass:[<code>~/.minikube</code>. The following
    command signs the CSR and makes it valid for 364 days:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 Kubernetes 集群证书颁发机构（CA）对 CSR 进行签名。CA 通常位于目录`/etc/kubernetes/pki`中，并且需要包含文件`ca.crt`和`ca.key`。我们在这里将使用
    minikube，它将这些文件存储在目录 pass:[<code>~/.minikube</code>] 中。以下命令对 CSR 进行签名，并使其在 364
    天内有效：
- en: '[PRE3]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create the user in Kubernetes by setting a user entry in kubeconfig for `johndoe`.
    Point to the CRT and key file. Set a context entry in kubeconfig for `johndoe`:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在 kubeconfig 中为`johndoe`设置用户条目来在 Kubernetes 中创建用户。指向 CRT 和 key 文件。在 kubeconfig
    中为`johndoe`设置上下文条目：
- en: '[PRE4]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To switch to the user, use the context named `johndoe-context`. You can check
    the current context using the command `config current-context`:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要切换到名为`johndoe-context`的上下文，请使用命令`config current-context`检查当前上下文：
- en: '[PRE5]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ServiceAccount
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ServiceAccount
- en: A user represents a real person who commonly interacts with the Kubernetes cluster
    using the `kubectl` executable or the UI dashboard. Some service applications
    like [Helm](https://helm.sh) running inside of a Pod need to interact with the
    Kubernetes cluster by making requests to the API server via RESTful HTTP calls.
    For example, a Helm chart would define multiple Kubernetes objects required for
    a business application. Kubernetes uses a ServiceAccount to authenticate the Helm
    service process with the API server through an authentication token. This ServiceAccount
    can be assigned to a Pod and mapped to RBAC rules.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 用户代表一个真实的人，通常使用`kubectl`可执行文件或 UI 仪表板与 Kubernetes 集群进行交互。某些服务应用程序（如 [Helm](https://helm.sh)
    在 Pod 内运行时）需要通过 RESTful HTTP 调用向 API 服务器发出请求与 Kubernetes 集群进行交互。例如，Helm chart
    将定义业务应用程序所需的多个 Kubernetes 对象。Kubernetes 使用 ServiceAccount 通过认证令牌验证 Helm 服务进程与
    API 服务器的身份。此 ServiceAccount 可以分配给 Pod 并映射到 RBAC 规则。
- en: A Kubernetes cluster already comes with a ServiceAccount, the `default` ServiceAccount
    that lives in the `default` namespace. Any Pod that doesn’t explicitly assign
    a ServiceAccount uses the `default` ServiceAccount.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群已经配备了一个 ServiceAccount，即`default` ServiceAccount，位于`default`命名空间中。任何未明确分配
    ServiceAccount 的 Pod 都会使用`default` ServiceAccount。
- en: 'To create a custom ServiceAccount imperatively, run the `create serviceaccount`
    command:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要想命令式地创建自定义 ServiceAccount，请运行`create serviceaccount`命令：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The declarative way to create a ServiceAccount looks very straightforward. You
    simply provide the appropriate `kind` and a name, as shown in [Example 2-1](#a_yaml_manifest_defining_a_serviceaccount).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 ServiceAccount 的声明方式非常直接。只需提供适当的`kind`和名称，如[示例 2-1](#a_yaml_manifest_defining_a_serviceaccount)所示。
- en: Example 2-1\. A YAML manifest defining a ServiceAccount
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-1\. 定义一个 ServiceAccount 的 YAML 清单
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Listing ServiceAccounts
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出 ServiceAccounts
- en: 'Listing the ServiceAccounts can be achieved with the `get serviceaccounts`
    command. As you can see in the following output, the `default` namespace lists
    the `default` ServiceAccount and the custom ServiceAccount we just created:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`get serviceaccounts`命令列出 ServiceAccounts。正如您在以下输出中所看到的，`default`命名空间列出了`default`
    ServiceAccount 和我们刚刚创建的自定义 ServiceAccount：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Rendering ServiceAccount Details
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 渲染 ServiceAccount 详细信息
- en: 'Upon object creation, the API server creates a Secret holding the API token
    and assigns it to the ServiceAccount. The Secret and token names use the ServiceAccount
    name as a prefix. You can discover the details of a ServiceAccount using the `describe
    serviceaccount` command, as shown here:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在对象创建时，API 服务器会创建一个包含 API 令牌的 Secret，并将其分配给 ServiceAccount。Secret 和令牌名称使用 ServiceAccount
    名称作为前缀。您可以使用`describe serviceaccount`命令查看 ServiceAccount 的详细信息，如下所示：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Consequently, you should be able to find a Secret object for the `default`
    and the `build-bot` ServiceAccount:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您应该能够找到用于`default`和`build-bot` ServiceAccount 的 Secret 对象：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Assigning a ServiceAccount to a Pod
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将 ServiceAccount 分配给 Pod
- en: 'For a ServiceAccount to take effect, it needs to be assigned to a Pod running
    the application intended to make API calls. Upon Pod creation, you can use the
    command-line option `--serviceaccount` in conjunction with the `run` command:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要使 ServiceAccount 生效，它需要分配给运行预期进行 API 调用的应用程序的 Pod。在 Pod 创建时，您可以与`run`命令一起使用命令行选项`--serviceaccount`：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Alternatively, you can directly assign the ServiceAccount in the YAML manifest
    of a Pod, Deployment, Job, or CronJob using the field `serviceAccountName`. [Example 2-2](#a_yaml_manifest_assigning_a_serviceaccount_to_a_pod)
    shows the definition of a ServiceAccount to a Pod.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以直接在Pod、Deployment、Job或CronJob的YAML清单中分配ServiceAccount，使用字段 `serviceAccountName`。[示例 2-2](#a_yaml_manifest_assigning_a_serviceaccount_to_a_pod)展示了将ServiceAccount定义给Pod的示例。
- en: Example 2-2\. A YAML manifest assigning a ServiceAccount to a Pod
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-2\. 将ServiceAccount分配给Pod的YAML清单
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Understanding RBAC API Primitives
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解RBAC API基元
- en: 'With those key concepts in mind, let’s take a look at the Kubernetes API primitives
    that implement the RBAC functionality:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些关键概念，让我们来看看实现RBAC功能的Kubernetes API基元：
- en: Role
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Role
- en: The Role API primitive declares the API resources and their operations this
    rule should operate on. For example, you may want to say “allow listing and deleting
    of Pods,” or you may express “allow watching the logs of Pods,” or even both with
    the same Role. Any operation that is not spelled out explicitly is disallowed
    as soon as it is bound to the subject.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Role API基元声明了此规则应操作的API资源及其操作。例如，您可能想说“允许列出和删除Pods”，或者您可以表达“允许监视Pods的日志”，甚至两者同时用相同的Role。一旦绑定到主体，任何未显式列出的操作将被禁止。
- en: RoleBinding
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: RoleBinding
- en: The RoleBinding API primitive *binds* the Role object to the subject(s). It
    is the glue for making the rules active. For example, you may want to say “bind
    the Role that permits updating Services to the user John Doe.”
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: RoleBinding API基元 *绑定* 了Role对象到主体(s)。这是使规则生效的粘合剂。例如，您可能想说“将允许更新服务的Role绑定给用户John
    Doe”。
- en: '[Figure 2-2](#rbac_primitives) shows the relationship between the involved
    API primitives. Keep in mind that the image renders only a selected list of API
    resource types and operations.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-2](#rbac_primitives)展示了涉及的API基元之间的关系。请记住，该图像仅呈现了一组选定的API资源类型和操作。'
- en: '![ckas 0202](Images/ckas_0202.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![ckas 0202](Images/ckas_0202.png)'
- en: Figure 2-2\. RBAC primitives
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-2\. RBAC基元
- en: The following sections demonstrate the namespace-wide usage of Roles and RoleBindings,
    but the same operations and attributes apply to cluster-wide Roles and RoleBindings,
    discussed in [“Namespace-wide and Cluster-wide RBAC”](#cluster-wide-rbac).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的章节展示了Roles和RoleBindings的命名空间范围的使用方法，但是相同的操作和属性也适用于集群范围的Roles和RoleBindings，详见[“命名空间范围和集群范围的RBAC”](#cluster-wide-rbac)。
- en: Default User-Facing Roles
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 默认面向用户的Roles
- en: Kubernetes defines a set of default Roles. You can assign them to a subject
    via a RoleBinding or define your own, custom Roles depending on your needs. [Table 2-2](#default_user_facing_roles)
    describes the default user-facing Roles.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes定义了一组默认的Roles。您可以通过RoleBinding分配它们给主体，或根据需要定义自己的自定义Roles。[表 2-2](#default_user_facing_roles)描述了默认的面向用户的Roles。
- en: Table 2-2\. Default User-Facing Roles
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表2-2\. 默认面向用户的Roles
- en: '| Default ClusterRole | Description |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 默认ClusterRole | 描述 |'
- en: '| --- | --- |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| cluster-admin | Allows read and write access to resources across all namespaces.
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| cluster-admin | 允许跨所有命名空间对资源进行读写访问。 |'
- en: '| admin | Allows read and write access to resources in namespace including
    Roles and RoleBindings. |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| admin | 允许在命名空间中对资源进行读写访问，包括Roles和RoleBindings。 |'
- en: '| edit | Allows read and write access to resources in namespace except Roles
    and RoleBindings. Provides access to Secrets. |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| edit | 允许在命名空间中对资源进行读写访问，但不包括Roles和RoleBindings。提供对Secrets的访问权限。 |'
- en: '| view | Allows read-only access to resources in namespace except Roles, RoleBindings,
    and Secrets. |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| view | 允许在命名空间中对资源进行只读访问，但不包括Roles、RoleBindings和Secrets。 |'
- en: To define new Roles and RoleBindings, you will have to use a context that allows
    for creating or modifying them, that is, cluster-admin or admin.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要定义新的Roles和RoleBindings，您需要使用允许创建或修改它们的上下文，即cluster-admin或admin。
- en: Creating Roles
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建Roles
- en: 'Roles can be created imperatively with the `create role` command. The most
    important options for the command are `--verb` for defining the verbs aka operations,
    and `--resource` for declaring a list of API resources. The following command
    creates a new Role for the resources Pod, Deployment, and Service with the verbs
    `list`, `get`, and `watch`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `create role` 命令来命令式地创建Roles。命令的最重要选项是 `--verb` 用于定义动词（即操作），以及 `--resource`
    用于声明一组API资源。以下命令创建了一个新的Role，允许对Pod、Deployment和Service资源进行 `list`、`get` 和 `watch`
    操作：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Declaring multiple verbs and resources for a single imperative `create role`
    command can be declared as a comma-separated list for the corresponding command-line
    option or as multiple arguments. For example, `--verb=list,get,watch` and `--verb=list
    --verb=get --verb=watch` carry the same instructions. You may also use the wildcard
    “*” to refer to all verbs or resources.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单个命令行选项的多个动词和资源，可以声明为相应命令行选项的逗号分隔列表或作为多个参数。例如，`--verb=list,get,watch` 和 `--verb=list
    --verb=get --verb=watch` 执行相同的指令。您还可以使用通配符“*”引用所有动词或资源。
- en: The command-line option `--resource-name` spells out one or many object names
    that the policy rules should apply to. A name of a Pod could be `nginx` and listed
    here with its name. Providing a list of resource names is optional. If no names
    have been provided, then the provided rules apply to all objects of a resource
    type.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 命令行选项`--resource-name`会列出一个或多个策略规则应用的对象名称。Pod的名称可以是`nginx`，在这里列出其名称。提供资源名称列表是可选的。如果没有提供名称，则提供的规则适用于该资源类型的所有对象。
- en: The declarative approach can become a little lengthy. As you can see in [Example 2-3](#a_yaml_manifest_defining_a_role),
    the section `rules` lists the resources and verbs. Resources with an API group,
    like Deployments that use the API version `apps/v1`, need to explicitly declare
    it under the attribute `apiGroups`. All other resources (e.g., Pods and Services),
    simply use an empty string as their API version doesn’t contain a group. Be aware
    that the imperative command for creating a Role automatically determines the API
    group.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 声明式方法可能会变得有些冗长。如您在[示例 2-3](#a_yaml_manifest_defining_a_role)中所见，`rules`部分列出了资源和动词。具有API组的资源，例如使用API版本`apps/v1`的Deployments，需要在属性`apiGroups`下显式声明。所有其他资源（例如Pods和Services）只需使用空字符串，因为它们的API版本不包含组。请注意，创建角色的命令会自动确定API组。
- en: Example 2-3\. A YAML manifest defining a Role
  id: totrans-101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-3\. 一个定义Role的YAML清单
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Listing Roles
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出Roles
- en: 'Once the Role has been created, its object can be listed. The list of Roles
    renders only the name and the creation timestamp. Each of the listed roles does
    not give away any of its details:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Role创建完成，可以列出其对象。Roles列表只呈现名称和创建时间戳。列出的每个角色都不透露任何详细信息：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Rendering Role Details
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 渲染Role详细信息
- en: 'You can inspect the details of a Role using the `describe` command. The output
    renders a table that maps a resource to its permitted verbs. This cluster has
    no resources created, so the list of resource names in the following console output
    is empty:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`describe`命令检查Role的详细信息。输出呈现了将资源映射到其允许的动词的表格。此集群尚未创建资源，因此下面控制台输出的资源名称列表为空：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Creating RoleBindings
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建RoleBindings
- en: 'The imperative command creating a RoleBinding object is `create rolebinding`.
    To bind a Role to the RoleBinding, use the `--role` command-line option. The subject
    type can be assigned by declaring the options `--user`, `--group`, or `--serviceaccount`.
    The following command creates the RoleBinding with the name `read-only-binding`
    to the user called `johndoe`:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 创建RoleBinding对象的命令是`create rolebinding`。要将Role绑定到RoleBinding，请使用`--role`命令行选项。可以通过声明选项`--user`、`--group`或`--serviceaccount`来分配主体类型。以下命令将RoleBinding命名为`read-only-binding`并绑定到名为`johndoe`的用户：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[Example 2-4](#a_yaml_manifest_defining_a_rolebinding) shows a YAML manifest
    representing the RoleBinding. You can see from the structure that a role can be
    mapped to one or many subjects. The data type is an array indicated by the dash
    character under the attribute `subjects`. At this time, only the user `johndoe`
    has been assigned.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 2-4](#a_yaml_manifest_defining_a_rolebinding) 展示了代表RoleBinding的YAML清单。您可以从结构中看到，一个角色可以映射到一个或多个主体。数据类型是由属性`subjects`下的破折号字符指示的数组。此时，只有用户`johndoe`已分配。'
- en: Example 2-4\. A YAML manifest defining a RoleBinding
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-4\. 一个定义RoleBinding的YAML清单
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Listing RoleBindings
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出RoleBindings
- en: 'The most important information the list of RoleBindings gives away is the associated
    Role. The following command shows that the RoleBinding `read-only-binding` has
    been mapped to the Role `read-only`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: RoleBindings列表中最重要的信息是关联的Role。以下命令显示了RoleBinding `read-only-binding`已映射到Role
    `read-only`：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The output does not provide an indication of the subjects. You will need to
    render the details of the object for more information, as described in the next
    section.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 输出不提供主体的指示。您需要渲染对象的详细信息以获取更多信息，如下一节所述。
- en: Rendering RoleBinding Details
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 渲染RoleBinding详细信息
- en: 'RoleBindings can be inspected using the `describe` command. The output renders
    a table of subjects and the assigned role. The following example renders the descriptive
    representation of the RoleBinding named `read-only-binding`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`describe`命令检查RoleBindings。输出呈现主体和分配角色的表格。以下示例呈现了名为`read-only-binding`的RoleBinding的描述表示：
- en: '[PRE20]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Seeing the RBAC Rules in Effect
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看正在生效的RBAC规则
- en: 'Let’s see how Kubernetes enforces the RBAC rules for the scenario we set up
    so far. First, we’ll create a new Deployment with the `cluster-admin` credentials.
    In Minikube, this user is assigned to the context `minikube`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Kubernetes如何对我们迄今设置的场景执行RBAC规则。首先，我们将使用`cluster-admin`凭据创建一个新的Deployment。在Minikube中，此用户分配给上下文`minikube`：
- en: '[PRE21]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we’ll switch the context for the user `johndoe`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将为用户`johndoe`切换上下文：
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Remember that the user `johndoe` is permitted to list deployments. We’ll verify
    that by using the `get deployments` command:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，用户`johndoe`被允许列出deployments。我们将使用`get deployments`命令验证：
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The RBAC rules only allow listing Deployments, Pods, and Services. The following
    command tries to list the ReplicaSets, which results in an error:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: RBAC规则只允许列出Deployments、Pods和Services。以下命令尝试列出ReplicaSets，结果出现错误：
- en: '[PRE24]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'A similar behavior can be observed when trying to use other verbs than `list`,
    `get`, or `watch`. The following command tries to delete a Deployment:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用除`list`、`get`或`watch`以外的其他动词时，会观察到类似的行为。以下命令尝试删除一个Deployment：
- en: '[PRE25]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'At any given time, you can check a user’s permissions with the `auth can-i`
    command. The command gives you the option to list all permissions or check a specific
    permission:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何时候，您可以使用`auth can-i`命令检查用户的权限。该命令为您提供列出所有权限或检查特定权限的选项：
- en: '[PRE26]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Namespace-wide and Cluster-wide RBAC
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命名空间范围和集群范围的RBAC
- en: 'Roles and RoleBindings apply to a particular namespace. You will have to specify
    the namespace at the time of creating both objects. Sometimes, a set of Roles
    and Rolebindings needs to apply to multiple namespaces or even the whole cluster.
    For a cluster-wide definition, Kubernetes offers the API resource types ClusterRole
    and ClusterRoleBinding. The configuration elements are effectively the same. The
    only difference is the value of the `kind` attribute:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 角色和RoleBindings适用于特定命名空间。在创建这两个对象时，您必须指定命名空间。有时，一组角色和Rolebindings需要应用于多个命名空间甚至整个集群。对于集群范围的定义，Kubernetes提供了API资源类型ClusterRole和ClusterRoleBinding。配置元素实际上是相同的。唯一的区别是`kind`属性的值：
- en: To define a cluster-wide Role, use the imperative subcommand `clusterrole` or
    the kind `ClusterRole` in the YAML manifest.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要定义集群范围的Role，请使用命令`clusterrole`或在YAML清单中使用`ClusterRole`种类。
- en: To define a cluster-wide RoleBinding, use the imperative subcommand `clusterrolebinding`
    or the kind `ClusterRoleBinding` in the YAML manifest.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要定义集群范围的RoleBinding，请使用命令`clusterrolebinding`或在YAML清单中使用`ClusterRoleBinding`种类。
- en: Aggregating RBAC Rules
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合RBAC规则
- en: Existing ClusterRoles can be aggregated to avoid having to redefine a new, composed
    set of rules that likely leads to duplication of instructions. For example, say
    you wanted to combine a user-facing role with a custom Role. An aggregated ClusterRule
    can merge rules via label selection without having to copy-paste the existing
    rules into one.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 可以聚合现有的ClusterRoles以避免不必要地重新定义新的组合规则集，这可能导致指令的重复。例如，假设您想将一个面向用户的角色与自定义角色合并。聚合的ClusterRole可以通过标签选择合并规则，而无需将现有规则复制粘贴到一个文件中。
- en: Say we defined two ClusterRoles shown in Examples [2-5](#a_yaml_manifest_defining_a_clusterrole_for_listing_pods)
    and [2-6](#a_yaml_manifest_defining_a_clusterrole_for_deleting_services). The
    ClusterRole `list-pods` allows for listing Pods and the ClusterRole `delete-services`
    allows for deleting Services.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们定义了两个示例中显示的集群角色，[2-5](#a_yaml_manifest_defining_a_clusterrole_for_listing_pods)和[2-6](#a_yaml_manifest_defining_a_clusterrole_for_deleting_services)。集群角色`list-pods`允许列出Pods，而集群角色`delete-services`允许删除Services。
- en: Example 2-5\. A YAML manifest defining a ClusterRole for listing Pods
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-5\. 定义用于列出Pods的ClusterRole的YAML清单
- en: '[PRE27]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Example 2-6\. A YAML manifest defining a ClusterRole for deleting Services
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-6\. 定义用于删除Services的ClusterRole的YAML清单
- en: '[PRE28]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: To aggregate those rules, ClusterRoles can specify an `aggregationRule`. This
    attribute describes the label selection rules. [Example 2-7](#a_yaml_manifest_defining_a_clusterrole_with_aggregated_fules)
    shows an aggregated ClusterRole defined by an array of `matchLabels` criteria.
    The ClusterRole does not add its own rules as indicated by `rules:` `[]`; however,
    there’s no limiting factor that would disallow it.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 要聚合这些规则，ClusterRole 可以指定一个 `aggregationRule`。这个属性描述了标签选择规则。[示例 2-7](#a_yaml_manifest_defining_a_clusterrole_with_aggregated_fules)
    展示了一个通过 `matchLabels` 条件数组定义的聚合 ClusterRole。ClusterRole 不会添加自己的规则，如 `rules:` `[]`
    所示；但是，没有限制因素会阻止它。
- en: Example 2-7\. A YAML manifest defining a ClusterRole with aggregated rules
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-7\. 使用聚合规则定义 ClusterRole 的 YAML 清单
- en: '[PRE29]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can verify the proper aggregation behavior of the ClusterRole by describing
    the object. You can see in the following output that both ClusterRoles, `list-pods`
    and `delete-services`, have been taken into account:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 通过描述对象可以验证 ClusterRole 的正确聚合行为。您可以在以下输出中看到，`list-pods` 和 `delete-services` 这两个
    ClusterRole 都已经被考虑进去了：
- en: '[PRE30]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: For more information on ClusterRole label selection rules, see the [official
    documentation](https://oreil.ly/J6k3m). The page also explains how to aggregate
    the default user-facing ClusterRoles.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 ClusterRole 标签选择规则的更多信息，请参阅 [官方文档](https://oreil.ly/J6k3m)。页面还解释了如何聚合默认用户面向的
    ClusterRole。
- en: Creating and Managing a Kubernetes Cluster
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和管理 Kubernetes 集群
- en: 'When thinking about the typical tasks of a Kubernetes administrator, I am sure
    that at least one of the following bread-and-butter activities comes to mind:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当考虑 Kubernetes 管理员的典型任务时，我确信以下至少一种基本活动会浮现在脑海中：
- en: Bootstrapping a control plane node
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引导控制平面节点
- en: Bootstrapping worker nodes and joining them to the cluster
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引导工作节点并将它们加入集群
- en: Upgrading a cluster to a newer version
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级集群到较新版本
- en: The low-level command-line tool for performing cluster bootstrapping operations
    is called `kubeadm`. It is not meant for provisioning the underlying infrastructure.
    That’s the purpose of infrastructure automation tools like Ansible and Terraform.
    To install `kubeadm`, follow the [installation instructions](https://oreil.ly/gKq4m)
    in the official Kubernetes documentation.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 执行集群引导操作的低级命令行工具称为 `kubeadm`。它不适用于提供基础设施。这是像 Ansible 和 Terraform 这样的基础设施自动化工具的用途。要安装
    `kubeadm`，请按照官方 Kubernetes 文档中的 [安装说明](https://oreil.ly/gKq4m) 进行操作。
- en: While not explicitly stated in the CKA frequently asked questions (FAQ) page,
    you can assume that the `kubeadm` executable has been preinstalled for you. The
    following sections describe the processes for creating and managing a Kubernetes
    cluster on a high level and will use `kubeadm` heavily. For more detailed information,
    see the step-by-step Kubernetes reference documentation I will point out for each
    of the tasks.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在 CKA 常见问题（FAQ）页面中没有明确说明，但可以假定 `kubeadm` 可执行文件已经预先安装好了。接下来的章节将高层次地描述创建和管理
    Kubernetes 集群的流程，并且将大量使用 `kubeadm`。有关每个任务的详细信息，请参阅逐步 Kubernetes 参考文档。
- en: Installing a Cluster
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装集群
- en: The most basic topology of a Kubernetes cluster consists of a single node that
    acts as the control plane and the worker node at the same time. By default, many
    developer-centric Kubernetes installations like minikube or Docker Desktop start
    with this configuration. While a single-node cluster may be a good option for
    a Kubernetes playground, it is not a good foundation for scalability and high-availability
    reasons. At the very least, you will want to create a cluster with a single control
    plane and one or many nodes handling the workload.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群的最基本拓扑结构包括一个既作为控制平面又作为工作节点的单节点。默认情况下，许多面向开发者的 Kubernetes 安装，如 minikube
    或 Docker Desktop，从这种配置开始。虽然单节点集群可能是 Kubernetes 实验场的一个不错选择，但出于可扩展性和高可用性的考虑，它并不是一个良好的基础。至少，您希望创建一个带有单个控制平面和一个或多个节点处理工作负载的集群。
- en: This section explains how to install a cluster with a single control plane and
    one worker node. You can repeat the worker node installation process to add more
    worker nodes to the cluster. You can find a full description of the [installation
    steps](https://oreil.ly/8visY) in the official Kubernetes documentation. [Figure 2-3](#cluster_installation_process)
    illustrates the installation process.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本节说明了如何使用单个控制平面和一个工作节点安装集群。您可以重复工作节点安装过程，以向集群添加更多工作节点。您可以在官方 Kubernetes 文档的
    [安装步骤](https://oreil.ly/8visY) 中找到完整描述。[图 2-3](#cluster_installation_process)
    说明了安装过程。
- en: '![ckas 0203](Images/ckas_0203.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![ckas 0203](Images/ckas_0203.png)'
- en: Figure 2-3\. Process for a cluster installation process
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-3\. 集群安装流程图
- en: Initializing the Control Plane Node
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初始化控制平面节点后
- en: Start by initializing the control plane on the control plane node. The control
    plane is the machine responsible for hosting the API server, etcd, and other components
    important to managing the Kubernetes cluster.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 首先在控制平面节点上初始化控制平面。控制平面是负责托管 API 服务器、etcd 和其他重要组件以管理 Kubernetes 集群的机器。
- en: 'Open an interactive shell to the control plane node using the `ssh` command.
    The following command targets the control plane node named `kube-control-plane`
    running Ubuntu 18.04.5 LTS:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `ssh` 命令打开交互式 shell 到名为 `kube-control-plane` 的运行 Ubuntu 18.04.5 LTS 的控制平面节点：
- en: '[PRE31]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Initialize the control plane using the `kubeadm init` command. You will need
    to add the following two command-line options: provide the IP addresses for the
    Pod network with the option `--pod-network-cidr`. With the option `--apiserver-advertise-address`,
    you can declare the IP address the API Server will advertise to listen on.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `kubeadm init` 命令初始化控制平面。您需要添加以下两个命令行选项：使用 `--pod-network-cidr` 选项为 Pod 网络提供
    IP 地址范围。使用 `--apiserver-advertise-address` 选项可以声明 API 服务器将要监听的 IP 地址。
- en: The console output renders a `kubeadm join` command. Keep that command around
    for later. It is important for joining worker nodes to the cluster in a later
    step.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 控制台输出显示了一个 `kubeadm join` 命令。请将该命令保留以备后用。这是后续步骤中将工作节点加入集群的重要步骤。
- en: Retrieving the join command for worker nodes
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取工作节点的加入命令
- en: You can always retrieve the `join` command by running `kubeadm token create
    --print-join-command` on the control plane node should you lose it.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您丢失了 `join` 命令，可以在控制平面节点上运行 `kubeadm token create --print-join-command` 来获取它。
- en: 'The following command uses `172.18.0.0/16` for the Classless Inter-Domain Routing
    (CIDR) and IP address `10.8.8.10` for the API server:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令使用 `172.18.0.0/16` 作为无类域间路由（CIDR）的地址范围，API 服务器使用 IP 地址 `10.8.8.10`：
- en: '[PRE32]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'After the `init` command has finished, run the necessary commands from the
    console output to start the cluster as nonroot user:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`init` 命令完成后，请从控制台输出中运行必要的命令以非 root 用户身份启动集群：'
- en: '[PRE33]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You must deploy a [Container Network Interface (CNI) plugin](https://oreil.ly/t6eJ7)
    so that Pods can communicate with each other. You can pick from a wide range of
    networking plugins listed in the [Kubernetes documentation](https://oreil.ly/1Y7MF).
    Popular plugins include Flannel, Calico, and Weave Net. Sometimes you will see
    the term “add-ons” in the documentation, which is synonymous with plugin.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须部署[容器网络接口（CNI）插件](https://oreil.ly/t6eJ7)，以便 Pod 之间可以通信。您可以从 [Kubernetes
    文档](https://oreil.ly/1Y7MF) 中列出的多种网络插件中进行选择。流行的插件包括 Flannel、Calico 和 Weave Net。有时文档中会出现与插件同义的术语“add-ons”。
- en: 'The CKA exam will most likely ask you to install a specific add-on. Most of
    the installation instructions live on external web pages, not permitted to be
    used during the exam. Make sure that you search for the relevant instructions
    in the official Kubernetes documentation. For example, you can find the installation
    instructions for Weave Net [here](https://oreil.ly/86YpI). The following command
    installs the Weave Net objects:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: CKA 考试很可能要求您安装特定的 add-on。大多数安装说明存储在外部网页上，在考试期间不允许使用。请确保在官方 Kubernetes 文档中搜索相关指南。例如，您可以在[这里](https://oreil.ly/86YpI)找到
    Weave Net 的安装说明。以下命令安装 Weave Net 对象：
- en: '[PRE34]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Verify that the control plane node indicates the “Ready” status using the command
    `kubectl get nodes`. It might take a couple of seconds before the node transitions
    from the “NotReady” status to the “Ready” status. You have an issue with your
    node installation in case the status transition does not occur. Refer to [Chapter 7](ch07.xhtml#troubleshooting)
    for debugging strategies:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令 `kubectl get nodes` 验证控制平面节点显示为“Ready”状态。节点从“NotReady”状态转换到“Ready”状态可能需要几秒钟时间。如果状态未发生转换，则表示节点安装存在问题。参考[第7章](ch07.xhtml#troubleshooting)进行故障排除策略：
- en: '[PRE35]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Exit the control plane node using the `exit` command:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `exit` 命令退出控制平面节点：
- en: '[PRE36]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Joining the Worker Nodes
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加入工作节点
- en: Worker nodes are responsible for handling the workload scheduled by the control
    plane. Examples of workloads are Pods, Deployments, Jobs, and CronJobs. To add
    a worker node to the cluster so that it can be used, you will have to run a couple
    of commands, as described next.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点负责处理由控制平面调度的工作负载。工作负载的示例包括 Pods、Deployments、Jobs 和 CronJobs。要将工作节点添加到集群中以便使用，您将需要运行一些命令，如下所述。
- en: 'Open an interactive shell to the worker node using the `ssh` command. The following
    command targets the worker node named `kube-worker-1` running Ubuntu 18.04.5 LTS:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `ssh` 命令打开到运行 Ubuntu 18.04.5 LTS 的名为 `kube-worker-1` 的工作节点的交互式 shell：
- en: '[PRE37]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Run the `kubeadm join` command provided by the `kubeadm init` console output
    on the control plane node. The following command shows an example. Remember that
    the token and SHA256 hash will be different for you:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在控制平面节点的 `kubeadm init` 控制台输出提供的 `kubeadm join` 命令。以下命令显示了一个示例。请记住，对于您来说，令牌和
    SHA256 哈希将不同：
- en: '[PRE38]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'You won’t be able to run the `kubectl get nodes` command from the worker node
    without copying the administrator kubeconfig file from the control plane node.
    Follow the [instructions](https://oreil.ly/AIM8a) in the Kubernetes documentation
    to do so or log back into the control plane node. Here, we are just going to log
    back into the control plane node. You should see that the worker node has joined
    the cluster and is in a “Ready” status:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不从控制平面节点复制管理员 kubeconfig 文件，您将无法从工作节点运行 `kubectl get nodes` 命令。请按照 Kubernetes
    文档中的 [说明](https://oreil.ly/AIM8a) 或重新登录到控制平面节点。在这里，我们只是要重新登录到控制平面节点。您应该看到工作节点已加入集群并处于“Ready”状态：
- en: '[PRE39]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: You can repeat the process for any other worker node you want to add to the
    cluster.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为要添加到集群的任何其他工作节点重复此过程。
- en: Managing a Highly Available Cluster
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理高可用性集群
- en: Single control plane clusters are easy to install; however, they present an
    issue when the node is lost. Once the control plane node becomes unavailable,
    any ReplicaSet running on a worker node cannot re-create a Pod due to the inability
    to talk back to the scheduler running on a control plane node. Moreover, clusters
    cannot be accessed externally anymore (e.g., via `kubectl`), as the API server
    cannot be reached.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 单控制平面集群易于安装；然而，当节点丢失时会出现问题。一旦控制平面节点不可用，运行在工作节点上的任何 ReplicaSet 由于无法与运行在控制平面节点上的调度器通信，就无法重新创建
    Pod。此外，集群不再可以从外部访问（例如，通过 `kubectl`），因为无法连接到 API 服务器。
- en: High-availability (HA) clusters help with scalability and redundancy. For the
    exam, you will need to have a basic understanding about configuring them and their
    implications. Given the complexity of standing up an HA cluster, it’s unlikely
    that you’ll be asked to perform the steps during the exam. For a full discussion
    on setting up HA clusters, see the [relevant page](https://oreil.ly/17ZDL) in
    the Kubernetes documentation.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性（HA）集群有助于扩展性和冗余性。在考试中，您需要基本了解如何配置它们及其影响。考虑到建立 HA 集群的复杂性，不太可能在考试中要求您执行这些步骤。要了解如何设置
    HA 集群，请参阅 Kubernetes 文档中的 [相关页面](https://oreil.ly/17ZDL)。
- en: The *stacked etcd topology* involves creating two or more control plane nodes
    where etcd is colocated on the node. [Figure 2-4](#stacked_etcd_topology) shows
    a representation of the topology with three control plane nodes.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*堆叠的 etcd 拓扑* 涉及创建两个或多个 etcd 与节点共存的控制平面节点。[图 2-4](#stacked_etcd_topology) 显示了具有三个控制平面节点的拓扑表示。'
- en: '![ckas 0204](Images/ckas_0204.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![ckas 0204](Images/ckas_0204.png)'
- en: Figure 2-4\. Stacked etcd topology with three control plane nodes
  id: totrans-197
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-4\. 具有三个控制平面节点的堆叠 etcd 拓扑
- en: Each of the control plane nodes hosts the API server, the scheduler, and the
    controller manager. Worker nodes communicate with the API server through a load
    balancer. It is recommended to operate this cluster topology with a minimum of
    three control plane nodes for redundancy reasons due to the tight coupling of
    etcd to the control plane node. By default, `kubeadm` will create an etcd instance
    when joining a control plane node to the cluster.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 每个控制平面节点托管 API 服务器、调度器和控制器管理器。工作节点通过负载均衡器与 API 服务器通信。建议出于冗余原因操作此集群拓扑，至少需要三个控制平面节点，因为
    etcd 与控制平面节点的紧密耦合。默认情况下，`kubeadm` 在将控制平面节点加入集群时会创建一个 etcd 实例。
- en: The *external etcd node* topology separates etcd from the control plane node
    by running it on a dedicated machine. [Figure 2-5](#external_etcd_node_topology)
    shows a setup with three control plane nodes, each of which run etcd on a different
    machine.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '*外部 etcd 节点*拓扑结构通过在专用机器上运行 etcd 将其与控制平面节点分离。[图 2-5](#external_etcd_node_topology)展示了一个设置，其中三个控制平面节点在不同的机器上运行
    etcd。'
- en: '![ckas 0205](Images/ckas_0205.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![ckas 0205](Images/ckas_0205.png)'
- en: Figure 2-5\. External etcd node topology
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-5\. 外部 etcd 节点拓扑结构
- en: Similar to the stacked etcd topology, each control plane node hosts the API
    server, the scheduler, and the controller manager. The worker nodes communicate
    with them through a load balancer. The main difference here is that the etcd instances
    run on a separate host. This topology decouples etcd from other control plane
    functionality and therefore has less of an impact on redundancy when a control
    plane node is lost. As you can see in the illustration, this topology requires
    twice as many hosts as the stacked etcd topology.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于堆叠的 etcd 拓扑结构，每个控制平面节点托管 API 服务器、调度器和控制器管理器。工作节点通过负载均衡器与它们通信。这里的主要区别是，etcd
    实例在单独的主机上运行。这种拓扑将 etcd 与其他控制平面功能解耦，因此在控制平面节点丢失时对冗余性影响较小。正如图示所示，这种拓扑结构需要的主机数是堆叠
    etcd 拓扑结构的两倍。
- en: Upgrading a Cluster Version
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 升级集群版本
- en: Over time, you will want to upgrade the Kubernetes version of an existing cluster
    to pick up bug fixes and new features. The upgrade process has to be performed
    in a controlled manner to avoid the disruption of workload currently in execution
    and to prevent the corruption of cluster nodes.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，您会希望将现有集群的 Kubernetes 版本升级，以获取 bug 修复和新功能。必须以受控的方式执行升级过程，以避免当前执行的工作负载中断，并防止集群节点的损坏。
- en: It is recommended to upgrade from a minor version to a next higher one (e.g.,
    from 1.18.0 to 1.19.0), or from a patch version to a higher one (e.g., from 1.18.0
    to 1.18.3). Abstain from jumping up multiple minor versions to avoid unexpected
    side effects. You can find a full description of the [upgrade steps](https://oreil.ly/2dCfk)
    in the official Kubernetes documentation. [Figure 2-6](#cluster_version_upgrade)
    illustrates the upgrade process.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 建议从次要版本升级到下一个更高版本（例如，从 1.18.0 到 1.19.0），或从补丁版本升级到更高版本（例如，从 1.18.0 到 1.18.3）。避免跨越多个次要版本跳跃，以避免意外副作用。您可以在官方
    Kubernetes 文档中找到关于[升级步骤](https://oreil.ly/2dCfk)的完整描述。[图 2-6](#cluster_version_upgrade)展示了升级过程。
- en: '![ckas 0206](Images/ckas_0206.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![ckas 0206](Images/ckas_0206.png)'
- en: Figure 2-6\. Process for a cluster version upgrade
  id: totrans-207
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 集群版本升级过程
- en: Upgrading control plane nodes
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 升级控制平面节点
- en: As explained earlier, a Kubernetes cluster may employ one or many control plane
    nodes to better support high-availability and scalability concerns. When upgrading
    a cluster version, this change needs to happen for control plane nodes one at
    a time.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Kubernetes 集群可能使用一个或多个控制平面节点来更好地支持高可用性和可扩展性问题。在升级集群版本时，需要逐个处理控制平面节点。
- en: 'Pick one of the control plane nodes that contains the kubeconfig file (located
    at `/etc/kubernetes/admin.conf`), and open an interactive shell to the control
    plane node using the `ssh` command. The following command targets the control
    plane node named `kube-control-plane` running Ubuntu 18.04.5 LTS:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个包含 kubeconfig 文件（位于 `/etc/kubernetes/admin.conf`）的控制平面节点，并使用 `ssh` 命令打开控制平面节点的交互式
    shell。以下命令针对名为 `kube-control-plane` 的控制平面节点，运行 Ubuntu 18.04.5 LTS：
- en: '[PRE40]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'First, check the nodes and their Kubernetes versions. In this setup, all nodes
    run on version 1.18.0\. We are dealing with only a single control plane node and
    a single worker node:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，检查节点及其 Kubernetes 版本。在此设置中，所有节点都运行在版本 1.18.0 上。我们只处理一个控制平面节点和一个工作节点：
- en: '[PRE41]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Start by upgrading the `kubeadm` version. Identify the version you’d like to
    upgrade to. On Ubuntu machines, you can use the following `apt-get` command. The
    version format usually includes a patch version (e.g., `1.20.7-00`). Check the
    Kubernetes documentation if your machine is running a different operating system:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 开始升级 `kubeadm` 版本。确定您希望升级到的版本。在 Ubuntu 机器上，您可以使用以下 `apt-get` 命令。版本格式通常包括一个补丁版本（例如
    `1.20.7-00`）。如果您的机器运行不同的操作系统，请查阅 Kubernetes 文档：
- en: '[PRE42]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Upgrade `kubeadm` to a target version. Say you’d want to upgrade to version
    `1.19.0-00`. The following series of commands installs `kubeadm` with that specific
    version and checks the currently installed version to verify:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 将`kubeadm`升级到目标版本。比如你想升级到版本`1.19.0-00`。以下一系列命令安装具有该特定版本的`kubeadm`并检查当前安装的版本以进行验证：
- en: '[PRE43]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Check which versions are available to upgrade to and validate whether your
    current cluster is upgradable. You can see in the output of the following command
    that we could upgrade to version `1.19.12`. For now, we’ll stick with `1.19.0`:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 检查可升级到哪些版本，并验证当前集群是否可升级。你可以在以下命令的输出中看到我们可以升级到版本`1.19.12`。现在，我们将继续使用`1.19.0`：
- en: '[PRE44]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'As described in the console output, we’ll start the upgrade for the control
    plane. The process may take a couple of minutes. You may have to upgrade the CNI
    plugin as well. Follow the provider instructions for more information:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 正如控制台输出中所述，我们将开始控制平面的升级。此过程可能需要几分钟。您可能还需要升级 CNI 插件。请按照提供者的说明获取更多信息：
- en: '[PRE45]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Drain the control plane node by evicting the workload. Any new workload won’t
    be schedulable on the node until uncordoned:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 通过驱逐工作负载来排空控制平面节点。在取消针对该节点的调度之前，任何新的工作负载都无法被调度：
- en: '[PRE46]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Upgrade the kubelet and the `kubectl` tool to the same version:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 将 kubelet 和`kubectl`工具升级到相同版本：
- en: '[PRE47]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Restart the kubelet process:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 重新启动 kubelet 进程：
- en: '[PRE48]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Reenable the control plane node back so that the new workload can become schedulable:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 重新启用控制平面节点，以便新的工作负载可以被调度：
- en: '[PRE49]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The control plane nodes should now show the usage of Kubernetes 1.19.0:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面节点现在应显示 Kubernetes 1.19.0 的使用情况：
- en: '[PRE50]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Exit the control plane node using the `exit` command:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`exit`命令退出控制平面节点：
- en: '[PRE51]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Upgrading worker nodes
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 升级工作节点
- en: 'Pick one of the worker nodes, and open an interactive shell to the node using
    the `ssh` command. The following command targets the worker node named `kube-worker-1`
    running Ubuntu 18.04.5 LTS:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个工作节点，并使用`ssh`命令打开到该节点的交互式 shell。以下命令针对名为`kube-worker-1`的运行 Ubuntu 18.04.5
    LTS 的工作节点：
- en: '[PRE52]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Upgrade `kubeadm` to a target version. This is the same command you used for
    the control plane node, as explained earlier:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 将`kubeadm`升级到目标版本。这与前面用于控制平面节点的相同命令一样：
- en: '[PRE53]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Upgrade the kubelet configuration:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 升级 kubelet 配置：
- en: '[PRE54]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Drain the worker node by evicting the workload. Any new workload won’t be schedulable
    on the node until uncordoned:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 通过驱逐工作负载来排空工作节点。在取消针对该节点的调度之前，任何新的工作负载都无法被调度：
- en: '[PRE55]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Upgrade the kubelet and the `kubectl` tool with the same command used for the
    control plane node:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与控制平面节点相同的命令升级 kubelet 和`kubectl`工具的版本：
- en: '[PRE56]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Restart the kubelet process:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 重新启动 kubelet 进程：
- en: '[PRE57]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Reenable the worker node so that the new workload can become schedulable:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 重新启用工作节点，以便新的工作负载可以被调度：
- en: '[PRE58]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Listing the nodes should now show version 1.19.0 for the worker node. You won’t
    be able to run `kubectl get nodes` from the worker node without copying the administrator
    kubeconfig file from the control plane node. Follow the [instructions](https://oreil.ly/NGHaQ)
    in the Kubernetes documentation to do so or log back into the control plane node:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在列出的节点应显示工作节点版本 1.19.0。你无法在工作节点上运行`kubectl get nodes`，除非从控制平面节点复制管理员 kubeconfig
    文件。请按照 Kubernetes 文档中的[说明](https://oreil.ly/NGHaQ)进行操作，或重新登录到控制平面节点：
- en: '[PRE59]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Exit the worker node using the `exit` command:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`exit`命令退出工作节点：
- en: '[PRE60]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Backing Up and Restoring etcd
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备份和恢复 etcd
- en: Kubernetes stores both the declared and observed states of the cluster in the
    distributed etcd key-value store. It’s important to have a backup plan in place
    that can help you with restoring the data in case of data corruption. Backing
    up the data should happen periodically in short time frames to avoid losing as
    little historical data as possible.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 将集群的声明和观察状态存储在分布式 etcd 键值存储中。重要的是要制定一个备份计划，以帮助在数据损坏时恢复数据。定期进行数据备份是很重要的，以尽可能减少历史数据的丢失。
- en: The backup process stores the ectd data in a so-called snapshot file. This snapshot
    file can be used to restore the etcd data at any given time. You can encrypt the
    snapshot file to protect sensitive information. The tool `etcdctl` is central
    to the backup and restore procedure.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 备份过程将 etcd 数据存储在所谓的快照文件中。可以随时使用此快照文件恢复 etcd 数据。可以加密快照文件以保护敏感信息。工具`etcdctl`在备份和恢复过程中是至关重要的。
- en: As an administrator, you will need to understand how to use the tool for both
    operations. You may need to install `etcdctl` if it is not available on the control
    plane node yet. You can find [installation instructions](https://oreil.ly/CrI28)
    in the etcd GitHub repository. [Figure 2-7](#backing_up_restoring_etcd) visualizes
    the etcd backup and restoration process.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 作为管理员，你需要了解如何使用该工具执行这两个操作。如果控制平面节点上尚未安装`etcdctl`，则可能需要安装它。你可以在etcd GitHub存储库中找到[安装说明](https://oreil.ly/CrI28)。[图2-7](#backing_up_restoring_etcd)展示了etcd备份和恢复过程。
- en: '![ckas 0207](Images/ckas_0207.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![ckas 0207](Images/ckas_0207.png)'
- en: Figure 2-7\. Process for a backing up and restoring etcd
  id: totrans-258
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-7\. etcd备份和恢复过程
- en: Depending on your cluster topology, your cluster may consist of one or many
    etcd instances. Refer to the section “High-Availability Cluster Setup” for more
    information on how to set it up. The following sections explain a single-node
    etcd cluster setup. You can find [additional instructions](https://oreil.ly/PvS5u)
    on the backup and restoration process for multinode etcd clusters in the official
    Kubernetes documentation.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的集群拓扑结构，你的集群可能包含一个或多个etcd实例。参考“高可用集群设置”部分，了解如何设置它。以下部分解释了单节点etcd集群设置。你可以在官方Kubernetes文档中找到有关多节点etcd集群备份和恢复过程的[附加说明](https://oreil.ly/PvS5u)。
- en: Backing Up etcd
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: etcd的备份
- en: 'Open an interactive shell to the machine hosting etcd using the `ssh` command.
    The following command targets the control plane node named `kube-control-plane`
    running Ubuntu 18.04.5 LTS:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`ssh`命令打开托管etcd的机器上的交互式shell。以下命令针对名为`kube-control-plane`的控制平面节点，运行的是Ubuntu
    18.04.5 LTS：
- en: '[PRE61]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Check the installed version of `etcdctl` to verify that the tool has been installed.
    On this node, the version is 3.4.14:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 检查`etcdctl`的安装版本，以验证该工具是否已安装。在此节点上，版本为3.4.14：
- en: '[PRE62]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Etcd is deployed as a Pod in the `kube-system` namespace. Inspect the version
    by describing the Pod. In the following output, you will find that the version
    is 3.4.13-0:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: Etcd作为`kube-system`命名空间中的一个Pod部署。通过描述Pod来检查其版本。在下面的输出中，你会发现版本是3.4.13-0：
- en: '[PRE63]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The same `describe` command reveals the configuration of the etcd service.
    Look for the value of the option `--listen-client-urls` for the endpoint URL.
    In the following output, the host is `localhost`, and the port is `2379`. The
    server certificate is located at `/etc/kubernetes/pki/etcd/server.crt` defined
    by the option `--cert-file`. The CA certificate can be found at `/etc/kubernetes/pki/etcd/ca.crt`
    specified by the option `--trusted-ca-file`:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的`describe`命令显示了etcd服务的配置。查找选项`--listen-client-urls`的值，以获取端点URL。在下面的输出中，主机是`localhost`，端口是`2379`。服务器证书位于`/etc/kubernetes/pki/etcd/server.crt`，由选项`--cert-file`定义。CA证书位于`/etc/kubernetes/pki/etcd/ca.crt`，由选项`--trusted-ca-file`指定：
- en: '[PRE64]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Use the `etcdctl` command to create the backup with version 3 of the tool.
    For a good starting point, copy the command from the [official Kubernetes documentation](https://oreil.ly/LuM2P).
    Provide the mandatory command-line options `--cacert`, `--cert`, and `--key`.
    The option `--endpoints` is not needed as we are running the command on the same
    server as etcd. After running the command, the file `/tmp/etcd-backup.db` has
    been created:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`etcdctl`命令创建版本为3的工具备份。作为一个良好的起点，从[官方Kubernetes文档](https://oreil.ly/LuM2P)复制命令。提供必需的命令行选项`--cacert`、`--cert`和`--key`。因为我们在与etcd相同的服务器上运行命令，所以不需要`--endpoints`选项。运行命令后，文件`/tmp/etcd-backup.db`已创建：
- en: '[PRE65]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Exit the node using the `exit` command:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`exit`命令退出节点：
- en: '[PRE66]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Restoring etcd
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 恢复etcd
- en: You created a backup of etcd and stored it in a safe space. There’s nothing
    else to do at this time. Effectively, it’s your insurance policy that becomes
    relevant when disaster strikes. In the case of a disaster scenario, the data in
    etcd gets corrupted or the machine managing etcd experiences a physical storage
    failure. That’s the time when you want to pull out the etcd backup for restoration.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 你创建了etcd的备份并将其存储在安全的位置。此时无需执行其他操作。实际上，这是你的保险政策，当遭遇灾难时会变得重要。在灾难场景下，etcd中的数据被损坏或管理etcd的机器遇到物理存储故障时，你就需要提取etcd备份进行恢复。
- en: 'To restore etcd from the backup, use the `etcdctl snapshot restore` command.
    At a minimum, provide the `--data-dir` command-line option. Here, we are using
    the data directory `/tmp/from-backup`. After running the command, you should be
    able to find the restored backup in the directory `/var/lib/from-backup`:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 要从备份中恢复 etcd，请使用 `etcdctl snapshot restore` 命令。至少提供 `--data-dir` 命令行选项。在这里，我们使用数据目录
    `/tmp/from-backup`。运行命令后，您应该能够在目录 `/var/lib/from-backup` 中找到恢复的备份：
- en: '[PRE67]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Edit the YAML manifest of the etcd Pod, which can be found at `/etc/kubernetes/manifests/etcd.yaml`.
    Change the value of the attribute `spec.volumes.hostPath` with the name `etcd-data`
    from the original value `/var/lib/etcd` to `/var/lib/from-backup`:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑 etcd Pod 的 YAML 清单，该清单位于 `/etc/kubernetes/manifests/etcd.yaml`。将属性 `spec.volumes.hostPath`
    的值从原始值 `/var/lib/etcd` 更改为 `/var/lib/from-backup`：
- en: '[PRE68]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The `etcd-kube-control-plane` Pod will be re-created, and it points to the
    restored backup directory:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '`etcd-kube-control-plane` Pod 将重新创建，并指向恢复的备份目录：'
- en: '[PRE69]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: In case the Pod doesn’t transition into the “Running” status, try to delete
    it manually with the command `kubectl delete pod etcd-kube-control-plane -n kube-system`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Pod 不能转换为“运行”状态，请尝试使用命令 `kubectl delete pod etcd-kube-control-plane -n kube-system`
    手动删除它。
- en: 'Exit the node using the `exit` command:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `exit` 命令退出节点：
- en: '[PRE70]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Summary
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Production-ready Kubernetes clusters should employ security policies to control
    which users and what processes can manage objects. Role-based access control (RBAC)
    defines those rules. RBAC introduces specific API resources that map subjects
    to the operations allowed for particular objects. Rules can be defined on a namespace
    or cluster level using the API resource types Role, ClusterRole, RoleBinding,
    and ClusterRoleBinding. To avoid duplication of rules, ClusterRoles can be aggregated
    with the help of label selection.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 生产就绪的 Kubernetes 集群应该使用安全策略来控制哪些用户和进程可以管理对象。基于角色的访问控制（RBAC）定义了这些规则。RBAC 引入了特定的
    API 资源，将主体映射到特定对象允许的操作。规则可以在命名空间或集群级别使用 API 资源类型 Role、ClusterRole、RoleBinding
    和 ClusterRoleBinding 来定义。为了避免规则重复，可以使用标签选择来聚合 ClusterRoles。
- en: As a Kubernetes administrator, you need to be familiar with typical tasks involving
    the management of the cluster nodes. The primary tool for installing new nodes
    and upgrading a node version is `kubeadm`. The cluster topology of such a cluster
    can vary. For optimal results with redundancy and scalability, consider configuring
    the cluster with a high-availability setup that uses three or more control plane
    nodes and dedicated etcd hosts.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 Kubernetes 管理员，您需要熟悉涉及管理集群节点的典型任务。安装新节点和升级节点版本的主要工具是 `kubeadm`。此类集群的集群拓扑可以有所不同。为了实现冗余和可扩展性的最佳结果，请考虑配置具有三个或更多控制平面节点和专用
    etcd 主机的高可用设置。
- en: Backing up the etcd database should be performed as a periodic process to prevent
    the loss of crucial data in the event of a node or storage corruption. You can
    use the tool `etcdctl` to back up and restore etcd from the control plane node
    or via an API endpoint.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 定期备份 etcd 数据库以防止节点或存储损坏时关键数据的丢失是一个必要的过程。您可以使用工具 `etcdctl` 从控制平面节点或通过 API 端点备份和还原
    etcd。
- en: Exam Essentials
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考试要点
- en: Know how to define RBAC rules
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 知道如何定义 RBAC 规则。
- en: 'Defining RBAC rules involves a couple of moving parts: the subject defined
    by users, groups, and ServiceAccounts; the RBAC-specific API resources on the
    namespace and cluster level; and, finally, the verbs that allow the corresponding
    operations on the Kubernetes objects. Practice the creation of subjects, and how
    to tie them together to form the desired access rules. Ensure that you verify
    the correct behavior with different constellations.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 RBAC 规则涉及几个关键部分：由用户、组和ServiceAccounts定义的主体；命名空间和集群级别上的 RBAC 特定 API 资源；最后是允许在
    Kubernetes 对象上执行相应操作的动词。练习创建主体，并学会如何将它们结合起来形成所需的访问规则。确保使用不同的组合验证正确的行为。
- en: Know how to create and manage a Kubernetes cluster
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 知道如何创建和管理 Kubernetes 集群。
- en: Installing new cluster nodes and upgrading the version of an existing cluster
    node are typical tasks performed by a Kubernetes administrator. You do not need
    to memorize all the steps involved. The documentation provides a step-by-step,
    easy-to-follow manual for those operations. For upgrading a cluster version, it
    is recommended to jump up by a single minor version or multiple patch versions
    before tackling the next higher version. High-availability clusters help with
    redundancy and scalability. For the exam, you will need to understand the different
    HA topologies though it’s unlikely that you’ll have to configure one of them as
    the process would involve a suite of different hosts.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 安装新的集群节点和升级现有集群节点的版本是Kubernetes管理员执行的典型任务。您不需要记住涉及的所有步骤。文档提供了这些操作的逐步易于遵循的手册。对于升级集群版本，建议先跳过一个单个次要版本或多个补丁版本，然后再处理下一个更高版本。高可用性集群有助于实现冗余和可扩展性。在考试中，您需要理解不同的HA拓扑，尽管您不太可能配置其中一个，因为这个过程涉及一套不同的主机。
- en: Practice backing up and restoring etcd
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 练习备份和恢复etcd。
- en: The process for etcd disaster recovery is not as well documented as you’d expect.
    Practice the backup and a restoration process hands-on a couple of times to get
    the hang of it. Remember to point the control plane node(s) to the restored snapshot
    file to recover the data.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: etcd灾难恢复过程的文档并不像你预期的那样完善。动手练习几次备份和恢复过程，以掌握操作技巧。记得将控制平面节点指向恢复的快照文件以恢复数据。
- en: Sample Exercises
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例练习
- en: Solutions to these exercises are available in the [Appendix](app01.xhtml#appendix-a).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的解答可在[附录](app01.xhtml#appendix-a)中找到。
- en: Create the ServiceAccount named `api-access` in a new namespace called `apps`.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在名为`apps`的新命名空间中创建名为`api-access`的ServiceAccount。
- en: Create a ClusterRole with the name `api-clusterrole`, and create a ClusterRoleBinding
    named `api-clusterrolebinding`. Map the ServiceAccount from the previous step
    to the API resources `pods` with the operations `watch`, `list`, and `get`.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建名为`api-clusterrole`的ClusterRole，并创建名为`api-clusterrolebinding`的ClusterRoleBinding。将上一步骤中的ServiceAccount映射到API资源`pods`，操作为`watch`、`list`和`get`。
- en: Create a Pod named `operator` with the image `nginx:1.21.1` in the namespace
    `apps`. Expose the container port 80\. Assign the ServiceAccount `api-access`
    to the Pod. Create another Pod named `disposable` with the image `nginx:1.21.1`
    in the namespace `rm`. Do not assign the ServiceAccount to the Pod.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在名为`apps`的命名空间中创建一个名为`operator`的Pod，使用镜像`nginx:1.21.1`。暴露容器端口80。将ServiceAccount`api-access`分配给Pod。在命名空间`rm`中创建另一个名为`disposable`的Pod，使用镜像`nginx:1.21.1`。不要为Pod分配ServiceAccount。
- en: Open an interactive shell to the Pod named `operator`. Use the command-line
    tool `curl` to make an API call to list the Pods in the namespace `rm`. What response
    do you expect? Use the command-line tool `curl` to make an API call to delete
    the Pod `disposable` in the namespace `rm`. Does the response differ from the
    first call? You can find information about how to interact with Pods using the
    API via HTTP in the [reference guide](https://oreil.ly/SZls9).
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开名为`operator`的Pod的交互式shell。使用命令行工具`curl`调用API列出命名空间`rm`中的Pods。你期望得到什么响应？使用命令行工具`curl`调用API删除命名空间`rm`中的Pod`disposable`。与第一次调用相比，响应有何不同？你可以在[参考指南](https://oreil.ly/SZls9)中找到有关通过HTTP与Pod交互的信息。
- en: Navigate to the directory *app-a/ch02/upgrade-version* of the checked-out GitHub
    repository [*bmuschko/cka-study-guide*](https://oreil.ly/jUIq8). Start up the
    VMs running the cluster using the command `vagrant up`. Upgrade all nodes of the
    cluster from Kubernetes 1.20.4 to 1.21.2\. The cluster consists of a single control
    plane node named `k8s-control-plane`, and three worker nodes named `worker-1`,
    `worker-2`, and `worker-3`. Once done, shut down the cluster using `vagrant destroy
    -f`.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到检出的GitHub仓库[*bmuschko/cka-study-guide*](https://oreil.ly/jUIq8)的目录*app-a/ch02/upgrade-version*。使用命令`vagrant
    up`启动运行集群的虚拟机。将集群的所有节点从Kubernetes 1.20.4升级到1.21.2。集群包括一个名为`k8s-control-plane`的单个控制平面节点，以及三个名为`worker-1`、`worker-2`和`worker-3`的工作节点。完成后，使用`vagrant
    destroy -f`关闭集群。
- en: '*Prerequisite:* This exercise requires the installation of the tools [Vagrant](https://oreil.ly/sasln)
    and [VirtualBox](https://oreil.ly/9Cvg9).'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*先决条件:* 此练习需要安装工具[Vagrant](https://oreil.ly/sasln)和[VirtualBox](https://oreil.ly/9Cvg9)。'
- en: Navigate to the directory *app-a/ch02/backup-restore-etcd* of the checked-out
    GitHub repository [*bmuschko/cka-study-guide*](https://oreil.ly/jUIq8). Start
    up the VMs running the cluster using the command `vagrant up`. The cluster consists
    of a single control plane node named `k8s-control-plane` and two worker nodes
    named `worker-1` and `worker-2`. The `etcdctl` tool has been preinstalled on the
    node `k8s-control-plane`. Back up etcd to the snapshot file `/opt/etcd.bak`. Restore
    etcd from the snapshot file. Use the data directory `/var/bak`. Once done, shut
    down the cluster using `vagrant destroy -f`.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入已检出的 GitHub 仓库 [*bmuschko/cka-study-guide*](https://oreil.ly/jUIq8) 的目录 *app-a/ch02/backup-restore-etcd*。使用命令
    `vagrant up` 启动运行集群的虚拟机（VMs）。该集群包括一个名为 `k8s-control-plane` 的控制平面节点和两个名为 `worker-1`
    和 `worker-2` 的工作节点。节点 `k8s-control-plane` 上预安装了 `etcdctl` 工具。将 etcd 备份到快照文件 `/opt/etcd.bak`。从快照文件恢复
    etcd。使用数据目录 `/var/bak`。完成后，使用 `vagrant destroy -f` 停止集群。
- en: '*Prerequisite:* This exercise requires the installation of the tools [Vagrant](https://oreil.ly/sasln)
    and [VirtualBox](https://oreil.ly/9Cvg9).'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*先决条件:* 此练习需要安装工具 [Vagrant](https://oreil.ly/sasln) 和 [VirtualBox](https://oreil.ly/9Cvg9)。'
