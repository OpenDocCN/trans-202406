- en: Chapter 14\. Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developers write code. Often they write a lot of code. The web of dependencies
    between objects and other services is often complex and not easily discernible;
    objects depend on other objects to work property. Making a change in even relatively
    simple codebases in one place can cause a bug or a crash in another part of the
    codebase. The house of cards that is your app can come quickly crashing down.
  prefs: []
  type: TYPE_NORMAL
- en: Where does testing fit into all this? Testing is a way to provide developers
    with a level of confidence that the changes being made are not unknowingly affecting
    other parts of the application. Ideally, these tests would be automated and deterministic
    so as not to be subject to the unpredictable whims of humanity, in which error
    and poor judgment often present themselves. Fortunately, most modern platforms
    have testing built in. Both Android and iOS have full-featured and incredibly
    powerful testing tools that can be used to assist in developing code. Let’s see
    how these tools work.
  prefs: []
  type: TYPE_NORMAL
- en: Tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you’ll learn to:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up and run unit tests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up and run integration tests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Android
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AOSP defines and differentiates a few different types of tests:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests
  prefs: []
  type: TYPE_NORMAL
- en: These are highly focused tests that run on a single class, usually a single
    method in that class. If a unit test fails, you should know exactly where in your
    code the issue is. They have low fidelity since in the real world, your app involves
    much more than the execution of one method or class. They should be fast enough
    to run every time you change your code.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests
  prefs: []
  type: TYPE_NORMAL
- en: These test the interaction of several classes to make sure they behave as expected
    when used together. One way to structure integration tests is to have them test
    a single feature, such as the ability to save a task. They test a larger scope
    of code than unit tests but are still optimized to run fast versus having full
    fidelity.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end tests
  prefs: []
  type: TYPE_NORMAL
- en: Test a combination of features working together. They are slow because they
    test large portions of the app and simulate real usage closely. They have the
    highest fidelity and tell you that your application actually works as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: Testing in Android might be a little different than testing you’ve encountered
    before. The nomenclature and categorization has some overlap and doesn’t always
    use the same semantic you might find in other computer sciences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with unit testing. Unit testing in Android is very similar to unit
    testing you might encounter in any number of frameworks or languages. We generally
    use a framework called JUnit, but even that’s not strictly necessary. A unit test
    should be highly focused and identify a very specific point in your code, so a
    failed unit test should be simple to correct. For example, if you have a method
    that multiples two numbers and returns the product, a unit test might invoke this
    method with some predetermined numbers to ensure the output is as expected. Let’s
    say your class looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You might start with an exceedingly simple test, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: Remember that local tests like these go in the IDE-generated *test* folder under
    the *src* parent directory. Instrumented tests—tests that will run in an actual
    or emulated device—go in the *androidTest* subfolder. See [Figure 14-1](#figures_android_topics_testing_directories)
    and the accompanying text for a little deeper dive.
  prefs: []
  type: TYPE_NORMAL
- en: While this test may seem simple, it is critical in case a refactor is made later
    by developers who may not even be aware of the class or method. However, it’s
    pretty obvious that there’s a limit to the usefulness of very basic tests like
    this. Even for a simple method like `Maths.multiply`, consider all the possible
    circumstances that might produce interesting results.
  prefs: []
  type: TYPE_NORMAL
- en: Static typing in Java reduces these outliers by a really impressive amount—since
    the datatype of both parameters is `int`, we never need to worry about `null`
    values, or values greater or less than a 32-bit signed number.
  prefs: []
  type: TYPE_NORMAL
- en: Using Android testing guidelines, unit tests are also known as “small tests,”
    and the framework recommends that 70% of your test should be small/unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: Moving up the testing pyramid we find medium and large tests. Medium tests generally
    correlate with what might otherwise be known as integration tests—tests that rely
    on multiple logic blocks, classes, or methods to produce some expected result.
    Android testing guidelines suggest 20% of your tests should be medium tests. A
    medium, integration test might check login credentials. Are the strings supplied
    empty? Do they conform to expected patterns, like email formats or password masks?
    If the user data is local to the device, the integration test might check if authentication
    is successful, while apps using remote authentication may simply check if the
    method succeeded enough to issue the login HTTP request and may test that request
    as well for appropriate headers, body, encryption, and target.
  prefs: []
  type: TYPE_NORMAL
- en: Some integration tests may be instrumented. An instrumented test is one that
    runs on a real device or an emulator, receives gesture events, relies on the system
    clock, and draws pixels to the screen.
  prefs: []
  type: TYPE_NORMAL
- en: The [Robolectric library](http://robolectric.org) is very popular with Android
    developers and is a great option to support integration tests. As of Google I/O
    2018, Robolectric 4 was released in conjunction with AndroidX testing, which replaces
    much of the Robolectric libraries. Much of this is opaque to the user and shouldn’t
    cause too much disruption in your existing test code. Start at [the developer
    docs for AndroidX texting](https://oreil.ly/Wnp8A) if you want a complete walk-through
    of AndroidX versus Robolectic, how they work together, and how to get the most
    mileage out of each in your specific circumstance.
  prefs: []
  type: TYPE_NORMAL
- en: We suggest you stick to Robolectric 4, and make sure the documentation you’re
    using is for that version. Robolectric and AndroidX testing do quite a bit of
    the boilerplate for you, including some mocking of Android framework classes,
    Activity life cycle emulation, and additional support functionality like the `Shadows`
    system, which allows you to easily mock any existing class and reassign logic.
    For example you could create a `ShadowThread` class that just runs itself on the
    main thread when `start` is called, rather than spinning up a new thread, or a
    `ShadowThreadPoolExecutor` that just runs its queue immediately, synchronously
    and serially, either of which can dramatically reduce the difficulty of testing
    asynchronous applications.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests using AndroidX and Robolectric require you to familiarize
    yourself with some additional libraries. We’ll provide a couple of examples, but
    a complete tutorial on testing is well outside the scope of this chapter. Make
    sure you visit the [Android developer docs](https://oreil.ly/EpCMX) if you’d like
    a deep dive into Android testing.
  prefs: []
  type: TYPE_NORMAL
- en: Finally we have large tests, also known as end-to-end tests. End-to-end tests
    are usually instrumented and might encompass an entire “activity.” For example,
    consider an app that features postcard functionality, where the user can use the
    device’s camera to capture an image; the app decorates it with other graphics
    or graphical information, converts it to a stream, and uploads the image data
    to a server, where the user is authenticated and the image is saved so the user
    can retrieve or share it. An end-to-end test might start this process and test
    that the image is responsive and only available to share operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instrumented testing is sometimes called “UI testing,” but really integration
    tests run outside of an instrumented environment could qualify as well. When tests
    are instrumented, however, you’ll want to engage another toolset: Espresso. Espresso
    has fluent syntax and a functional paradigm. The Espresso UI testing library can
    emulate clicks and scrolls and text input and even allows you to record user inputs
    to run and compare UI output to your expectations. If you want to know more about
    Espresso UI testing, visit [the documentation](https://oreil.ly/ziFOJ).'
  prefs: []
  type: TYPE_NORMAL
- en: In the following, you’ll find out how to write and execute both unit and integration
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: As soon as you create a project in Android Studio, you’ll find test directories
    immediately available. The easiest way to see and interact with those directories
    is to use the Android view of the project display dropdown.
  prefs: []
  type: TYPE_NORMAL
- en: Open your application module (usually just named “app”) and then the “java”
    subdirectory. Inside of that, you’ll find at least three directories. The first
    you’ll see is your main source code, which will have a name identical to your
    package (e.g., “my.site.appname”). There will be two directories just under that,
    with the same name, but with an additional label in a dimmed color, in parentheses,
    indicating “(test)” or “(androidTest)” ([Figure 14-1](#figures_android_topics_testing_directories)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Android Studio Test Directories](assets/nmdv_1401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-1\. Android Studio test directories
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The first folder will hold all your source code. The folder with the “(test)”
    label will hold your unit and integration tests. The last folder labeled “(androidTest)”
    are for Espresso UI tests, which we will not be covering in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Whether you set up your initial project configuration to default to Java or
    Kotlin, you’ll see the same structure. If you later add files of the opposite
    type (if your project was set up for Kotlin, but you add Java files, or vice versa),
    you’ll find each of these directories duplicated—one per language for source,
    unit and integration tests, and UI tests.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up and Run Unit Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Both JUnit- and Robolectric-based tests will go in the directory labeled “(test),”
    which we’ll refer to simply as the “test directory” from here on.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you open this folder, you’ll find an example test class has already been
    created, usually named “ExampleUnitTest.” It will also import the basic JUnit
    `assert` static methods. It might have something simple already included, like:'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the most basic implementation of a unit test. A unit test proves out
    one functional unit of code. The preceding example isn’t terribly useful since
    all statements are within the test itself, but let’s consider a slightly more
    useful example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To test this simple class, we might write a unit test like so:'
  prefs: []
  type: TYPE_NORMAL
- en: Note that `assert` methods expect an “actual” value (one produced by your logic)
    and an “expected” value (what the result of that logic should produce). These
    are compared, and if they do not match (or if they do not match the implied outcome
    from specific `assert` methods like `assertTrue` or `assertFalse`), they simply
    throw an `Exception`; when the proposition fails, these `Exception` instances
    are `caught` by the testing framework in order to organize and track what tests
    pass or fail.
  prefs: []
  type: TYPE_NORMAL
- en: For procedural code, where the same inputs always produce the same outputs,
    unit tests are almost always appropriate and almost always helpful. For state-based
    environments (in object-oriented programming like much of Java and Kotlin), things
    can get a little trickier.
  prefs: []
  type: TYPE_NORMAL
- en: When you’re integrating your code into a framework, like AOSP, you’ll rely on
    certain framework features, classes, and values, and will want to “integrate”
    your logic. These tests can become more difficult, and when dealing with things
    like `Activity` interaction and life cycle, can become extremely difficult to
    manage from scratch. It’s for this reason that the Robolectric library was created—this
    provides a way to interact with framework features like those just mentioned in
    a simple way.
  prefs: []
  type: TYPE_NORMAL
- en: Note that Robolectric is moving to become part of the overall “Android Test”
    framework, and speakers around both Robolectric and AndroidX testing seemed to
    indicate at the last Google I/O event before this book was published that the
    Robolectric pieces will soon be removed in favor of Android-specific APIs, merged
    with them, or replaced by identical APIs in the new AndroidX packages. So far,
    it seems like there is some real value in AndroidX testing. Using Espresso syntax
    for both local and instrumented UI testing could be a huge gain for any team,
    but at the same time, even a year later we’ve found some nontrivial bugs that
    are likely being worked on but have prevented our team from migrating fully.
  prefs: []
  type: TYPE_NORMAL
- en: When tests have to be integrated with other code, especially opaque toolsets
    like the one used by Android to paint pixels on the screen, you might be really
    limited in the tests that are not only helpful, but feasible. When writing tests,
    consider return on investment (ROI). You’ll often hear the term “coverage”; this
    generally indicates how much of your code is being tested, but in reality there
    are a number of ways to compute coverage—some people use the total number of lines
    that are references, other people consider statements or even logical branching.
    If 100% coverage is required on a team of one or two, on a new product that needs
    feature work to succeed, you (and your team) may have to determine the best and
    most realistic approach to testing for your specific needs. Depending on your
    definition of coverage, it might be impossible to achieve 100% coverage. In the
    preceding `Calculator.add` test, we can assume that one (or a few) tests like
    the one in the example are sufficient, and we don’t think anyone would propose
    testing every possible value of adding any two integers, *but* you might want
    to test what happens when two integers are added that exceed the maximum integer
    value on your system, or what happens when negative or null values are passed
    in. As we said, it’s up to you and your team to define testing scope, requirements,
    coverage, and best practices, and these can vary wildly between organizations,
    or even between teams within organizations or individuals within teams.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up and Run Integration Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned, integration tests prove how well your logic functions as logical
    flow, rather than a single unit. Let’s use an example to touch on the main points;
    this uses Robolectric shadows and annotations and AndroidX `ActivityScenario`s
    for `Context` references and life cycle:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s break down this code:'
  prefs: []
  type: TYPE_NORMAL
- en: The `@RunWith` annotation simply tells the testing system that we’re using the
    JUnit4 runner.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `@Config` annotation can be used for a number of configuration settings,
    but in this case we’re indicating we want to use the `ShadowAsyncTask` class.
    Let’s assume this class overrode the default behavior of the `AsyncTask` that
    submits the job to a new `Thread` to just run the job on the existing thread.
    That means any asynchronous operations we do using `AsyncTask` have just become
    both synchronous and serial, and much easier to predict and control when testing
    behavior.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `@Before` annotation indicates a setup method that fires before any test
    method is invoked. In our setup method, we initialize the AndroidX `Intents` class
    so that we can examine or intercept pending or received intents, so we might determine
    if a button tap does send an intent to start some `Activity`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `@After` annotation is the opposite of `@Before` and is performed after
    each test returns. Here, we simply release the `Intents` functionality and dereference
    the member-level `Activity`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each of your tests should be annotated with `@Test`. The name of the method
    may seem unwieldy, but follows the convention of “given-when-then,” so we can
    differentiate pieces of functionality that may seem very similar at first glance.
    In these specific tests, we use the fluent style of Espresso APIs to check that
    a couple `View` instances are visible, to receive and submit the credentials input
    by a user.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that in the preceding example, we are using Espresso APIs inside a local
    test—not an instrumented test. Prior to AndroidX, this was not possible, and all
    Espresso code ran only in devices or emulated device environments.
  prefs: []
  type: TYPE_NORMAL
- en: iOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are great tools built into Xcode to facilitate testing within iOS. Primarily
    tests in iOS are segmented into unit and UI tests, with UI testing being a bit
    like automated integration tests depending on how the tests are run and set up.
    Without further ado, let’s dive into writing some unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up and Run Unit Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to write and run unit tests for an iOS app, it’s important to first
    add a new target to the Xcode project. You can do this by going to File > New
    > Target in the application menu bar. From there, you can add a new iOS Unit Testing
    Bundle to create a unit testing target that Xcode can build and run. Follow the
    prompts (it’s generally all right to use the defaults) and click Finish to add
    the target to the project. Doing this will create a new folder to contain the
    unit tests themselves and—depending on how the project has been set up—a new target
    will be added in the *Products* folder within the file tree on the left side of
    Xcode with the extension *.xctest*. This is the bundle that is built that contains
    all your unit tests and libraries; it can be targeted just like the `.app` target
    that is your application bundle, which means libraries specific to the test bundle
    can be added, such as third-party libraries that make writing tests easier or
    have different functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Once the testing target has been added, you can add a new suite of tests to
    the project by going to File > New > File, selecting Unit Test Case Class, and
    giving a name for the class and file. The conventional approach to file naming
    in Xcode is to name the file and class after the object being tested. This isn’t
    a hard-and-fast rule, but generally it’s adhered to in most projects. For example,
    an class named `Calculator` might have a corresponding test suite named `CalculatorTests`
    with different tests being ran against it.
  prefs: []
  type: TYPE_NORMAL
- en: Convention over configuration is the name of the game with regards to testing
    in Xcode, and you’ll see this come up again and again, most prominently in adding
    tests to be run. Let’s see what that looks like.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our hypothetical `CalculatorTests` class, we can add a new test by opening
    up *CalculatorTests.swift* and adding a new method to this class that begins with
    `test`. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The convention part of this is that Xcode recognizes each test in a test case
    file by the fact that its method name begins with “test.” If you were to run the
    test suite by going to Product > Test, then that test will run, and it’ll receive
    a green checkmark beside it in Xcode to indicate that it’s been successful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at the whole test case class instead of the individual test.
    For example, right now, `CalculatorTests` looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: There are a few things to note here. To begin, `CalculatorTests` inherits from
    `XCTestCase`, which is the place where all individual tests live as methods on
    a test case. We also have our `testExample` test at the bottom of the file. This
    is a test that will run and requires some type of assertions to check for success
    or failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a number of assertions that are possible, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '`XCTAssert()`, which takes an expression that returns a boolean'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`XCTAssertFalse()` and `XCTAssertTrue()`, which check for a specific boolean
    value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`XCTAssertEquals()` and `XCTAssertNotEqual()`, which check for equality between
    objects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`XCTAssertNil()` and `XCTAssertNotNil()`, which check for a `nil` condition'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In order to use these assert macros, just add them within the method body like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This will generate a failing test because `success` is set to `false` on the
    preceding line. When the validity is checked and it’s `true`, that test fails.
    Assertions are fairly straightforward to use, and you can string them along for
    multiple assertions within a test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the test case, there are also `setUp()` and `tearDown()` methods. These
    are standard methods that are called every time a test is run within this class
    to—you guessed it—set up the test and subject under test and tear down the test
    afterwards. As an example, we could create an instance of our `Calculator` that’s
    being tested and store it under a `sut` variable so that we can reference it easily
    and tear it down after we’re finished so our test methods are not littered with
    construction logic. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Occasionally, it’ll be necessary to run tests on asynchronous functionality.
    This is tough because the test method will return before the test actually runs
    in the asynchronous code. This can be pretty tough to debug and work around. However,
    with test expectations in the testing framework, this is not too tough. Here’s
    an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we first create an expectation to fulfill in the asynchronous
    code that’s executed. In our fake `shareToTwitter(:)` method, we are passing a
    closure in that executes after sharing our calculator’s result to Twitter. We
    check to see if `success` is `true` and if it is, we call `fulfill()` on that
    expectation to let Xcode know the test passed or we call `XCTFail()` to indicate
    a failure has occurred. Finally, we call `waitForExpectations(timeout::)` to indicate
    that we are waiting for expectations to complete with a timeout value of two seconds.
    If we don’t have expectations completed by then, we call `XCTFail()` to indicate
    the test has failed as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We hope it’s apparent that unit testing isn’t as scary as maybe you once thought
    it was in Xcode and iOS. Let’s take a look at another beast, which has been tamed:
    integration tests through the use of UI testing in iOS.'
  prefs: []
  type: TYPE_NORMAL
- en: What We’ve Learned
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve looked at our how testing in Android and iOS are both complete systems
    capable of testing assertions in a way that’s consistent, quick, and painless.
    Writing unit tests is often overlooked, but you’ll find—over time—that the initial
    time investment pays dividends in the future as the stability of changes to the
    application are run against expectations of existing behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve covered how different technologies of Android and iOS interact
    with each other, let’s do something fun. Let’s build an app. Check out [Part II](part02.html#part_2_app)
    to get started!
  prefs: []
  type: TYPE_NORMAL
